{"overall": {"Bleu_1": 0.28706954686213, "Bleu_2": 0.1949736357805088, "Bleu_3": 0.1251665373205911, "Bleu_4": 0.0787562595454219, "METEOR": 0.23129566946380214, "ROUGE_L": 0.27323952077715646, "CIDEr": 0.00017353746033072065, "SPICE": 0.21283371067208012}, "imgToEval": {"281533": {"image_id": 281533, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.1671899541887144, "Bleu_3": 0.1024430114193944, "Bleu_4": 0.06775934642896438, "METEOR": 0.24017848920523024, "ROUGE_L": 0.25507765830346474, "CIDEr": 2.717355502790897e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.2727272727272727, "f": 0.2553191489361702, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a large red dog sitting on the floor in front of a flat-screen TV. The dog appears to be watching the TV intently, possibly captivated by the content displayed on the screen. The TV is positioned on the left side of the room, while the dog is situated on the right"}, "397773": {"image_id": 397773, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.11722658350807154, "Bleu_3": 6.89076821568532e-07, "Bleu_4": 1.6807563750229034e-09, "METEOR": 0.23360930401519892, "ROUGE_L": 0.25702247191011235, "CIDEr": 1.3860027813019776e-07, "SPICE": {"All": {"pr": 0.35, "re": 0.2692307692307692, "f": 0.3043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a delicious pasta dish served on a white plate. The dish is topped with a generous amount of cheese, making it a cheesy pasta dish. The plate is filled with a variety of ingredients, including several pieces of broccoli, which are"}, "371250": {"image_id": 371250, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.086841684284798, "Bleu_3": 5.323069753321686e-07, "Bleu_4": 1.324562934342616e-09, "METEOR": 0.1898210990536765, "ROUGE_L": 0.270509977827051, "CIDEr": 2.0122802366919518e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a brown leather couch with a pineapple print on the pillows. The couch is positioned in the center of the room, and there is a remote control placed on a small table in front of it. The table is located on the left side of the couch. The room"}, "573877": {"image_id": 573877, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.21398889174339228, "Bleu_3": 0.13736495494745896, "Bleu_4": 0.08402453643289479, "METEOR": 0.23448206855036932, "ROUGE_L": 0.29137917961937976, "CIDEr": 1.5307487552245244e-10, "SPICE": {"All": {"pr": 0.4, "re": 0.2727272727272727, "f": 0.3243243243243243, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a white cat sitting in front of a laptop computer, seemingly watching the screen. The cat is positioned close to the laptop, with its head and body almost entirely visible. The laptop screen displays a variety of content, including multiple web pages and a few images. The cat appears to be intrigu"}, "181859": {"image_id": 181859, "Bleu_1": 0.3199999999936, "Bleu_2": 0.27994168488385013, "Bleu_3": 0.18691807486410375, "Bleu_4": 1.9306965035248335e-05, "METEOR": 0.28863477974851376, "ROUGE_L": 0.34879288437102923, "CIDEr": 8.500984501078312e-10, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3157894736842105, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a gray and white cat sitting in a bathroom sink, appearing relaxed and comfortable. The sink is made of marble, and the cat is positioned in the middle of it.\n\nIn the bathroom, there is a mirror on the wall above the sink, and a bottle can"}, "119939": {"image_id": 119939, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.2241462600435509, "Bleu_3": 0.1787283477483194, "Bleu_4": 0.14127271129810476, "METEOR": 0.29495787271786, "ROUGE_L": 0.26105563480741795, "CIDEr": 3.6101647013516356e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.3076923076923077, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two young men riding skateboards down a sidewalk in front of a building. One of the skateboarders is closer to the left side of the scene, while the other is positioned more towards the right. Both skateboarders are wearing backpacks, with one back"}, "385320": {"image_id": 385320, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.14540168172223333, "Bleu_3": 0.10022433611412393, "Bleu_4": 1.2517970591861958e-05, "METEOR": 0.18353194847069262, "ROUGE_L": 0.2506849315068493, "CIDEr": 1.0054754958260656e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.2857142857142857, "f": 0.2608695652173913, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.8, "f": 0.47058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a young child, possibly a toddler, brushing their teeth with a toothbrush. The child is wearing a Minnie Mouse shirt, which adds a playful touch to the scene. The toothbrush is held in the child's hand, and the child appears"}, "490415": {"image_id": 490415, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.21718612137739748, "Bleu_3": 0.1666049839536587, "Bleu_4": 0.09806713568284028, "METEOR": 0.26475981676517235, "ROUGE_L": 0.25894481503941785, "CIDEr": 2.203276616456413e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13793103448275862, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man standing in a grassy field, flying a kite high in the sky. The kite is visible in the upper part of the scene, soaring above the man. There are several other people in the field, some of them standing closer to the man flying the kite, while others"}, "432293": {"image_id": 432293, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.22631728213415836, "Bleu_3": 0.1379749595894305, "Bleu_4": 0.0911809908906992, "METEOR": 0.23098009614361964, "ROUGE_L": 0.30049261083743845, "CIDEr": 1.350842649679745e-06, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.24, "f": 0.2727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a large, uncooked pizza sitting on a wooden cutting board. The pizza is topped with a variety of ingredients, including tomatoes, shrimp, and cheese. The pizza is placed on a dining table, which occupies most of the background."}, "256301": {"image_id": 256301, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.15639188177115004, "Bleu_3": 0.09798321550063374, "Bleu_4": 1.1653898241136167e-05, "METEOR": 0.15761275031226385, "ROUGE_L": 0.19588953114964675, "CIDEr": 6.436107919790915e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.20689655172413793, "f": 0.21052631578947367, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a group of people standing on a platform in front of a large clock, which is prominently displayed on a building. The clock is positioned towards the right side of the scene, and the people are scattered around it, with some standing closer to the clock and others further away.\n\nThere"}, "361103": {"image_id": 361103, "Bleu_1": 0.37037037036351167, "Bleu_2": 0.2643505285677732, "Bleu_3": 0.15915712754507227, "Bleu_4": 0.09429247282859671, "METEOR": 0.220534999582069, "ROUGE_L": 0.38006230529595014, "CIDEr": 4.448880186056298e-08, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image depicts a busy city street with a man standing in front of a cell phone store, possibly looking at a cell phone or waiting for someone. There are several other people walking around the area, some of them carrying handbags.\n\nA traffic light is visible on the left side of the scene"}, "567562": {"image_id": 567562, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.14746720993983883, "Bleu_4": 0.12160144681459327, "METEOR": 0.29926435449259836, "ROUGE_L": 0.3652694610778443, "CIDEr": 1.5711712668083118e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a woman and two children sitting around a dining table, enjoying a meal together. The table is filled with various food items, including multiple pizzas, sandwiches, and a bowl. There are also several bottles and cups placed on the table, suggesting that they are"}, "448320": {"image_id": 448320, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1504179432467115, "Bleu_4": 0.09604167742854731, "METEOR": 0.2333215890630258, "ROUGE_L": 0.33174711080897346, "CIDEr": 4.267907769078609e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet situated next to a sink. The sink is a large, brown bowl-shaped basin, which is placed on a countertop. Above the sink, there is a mirror that reflects the bathroom's interior.\n\nIn addition"}, "14874": {"image_id": 14874, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.1268434288177822, "Bleu_4": 0.10683334564397808, "METEOR": 0.2654661609923835, "ROUGE_L": 0.27128335451080055, "CIDEr": 3.062041876897751e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a man standing in the snow, wearing a blue jacket and black pants. He is posing in front of two snow skis, which are placed upright in the snow. The skis are positioned on either side of the man, with one on his left and the other"}, "373713": {"image_id": 373713, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.08720922498013364, "Bleu_4": 1.0899268608532945e-05, "METEOR": 0.20001181635458262, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.2640492799796813e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a group of three men sitting in a room, engaged in a discussion. They are all wearing lanyards, which suggests they might be attending an event or conference. Two of the men are sitting on chairs, while the third man is standing.\n\nIn the room, there is"}, "539326": {"image_id": 539326, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.17104186372845756, "Bleu_3": 0.08599680891572582, "Bleu_4": 1.0903316619846374e-05, "METEOR": 0.2791930484438715, "ROUGE_L": 0.3202099737532808, "CIDEr": 4.112872426939819e-10, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.14285714285714285, "f": 0.1081081081081081, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image depicts a large herd of cattle grazing in a lush green field. There are at least 14 cows visible in the scene, scattered across the field. Some cows are closer to the foreground, while others are further away, creating a sense of depth in the image."}, "20059": {"image_id": 20059, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.16367090728932468, "Bleu_4": 0.14050458184787668, "METEOR": 0.24574644991502276, "ROUGE_L": 0.27371794871794874, "CIDEr": 1.737651781799063e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.16129032258064516, "f": 0.18518518518518517, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features two zebras grazing on grass in a lush green field. They are standing close to each other, with one zebra positioned slightly behind the other. The zebras are focused on eating the grass, which is abundant in the field. The scene is set in a"}, "530520": {"image_id": 530520, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.1647705109111272, "Bleu_3": 0.11766213984418193, "Bleu_4": 0.07593264650632311, "METEOR": 0.2654997309106347, "ROUGE_L": 0.22536945812807885, "CIDEr": 3.740458080116833e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features two men sitting on the grass, each using a laptop. They are positioned close to each other, with one man on the left and the other on the right. Both men are wearing glasses, and they appear to be engaged in their respective tasks.\n\nIn the background, there are"}, "117337": {"image_id": 117337, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1556997888288053, "Bleu_3": 0.11914512632603338, "Bleu_4": 0.09473323931830074, "METEOR": 0.16587362014203572, "ROUGE_L": 0.24646464646464644, "CIDEr": 1.8824230742230405e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image is a collage of various items, including a collection of oranges, a blue umbrella, a typewriter, and a cake. The oranges are scattered throughout the collage, with some placed in the top left, top right, and bottom left sections. The blue umbrella is"}, "256504": {"image_id": 256504, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.09356392870058139, "Bleu_3": 5.486731100334785e-07, "Bleu_4": 1.3350097003360843e-09, "METEOR": 0.16450244854627785, "ROUGE_L": 0.21095100864553315, "CIDEr": 1.7701092046607317e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13793103448275862, "f": 0.1568627450980392, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man and a woman lying in bed, each using a laptop computer. They are positioned close to each other, with the woman on the left side and the man on the right side of the bed. The laptops are placed on their respective laps, and they appear to be focused on"}, "265472": {"image_id": 265472, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.12121830534381621, "Bleu_3": 0.06739562828886043, "Bleu_4": 8.983577738158223e-06, "METEOR": 0.20871873654253265, "ROUGE_L": 0.23797139141742527, "CIDEr": 1.09225367263076e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.16666666666666666, "f": 0.16216216216216214, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a plate with a delicious breakfast meal consisting of bacon, bananas, and powdered sugar. The bacon is placed on the left side of the plate, while the bananas are scattered across the plate, with some on the top and others on the bottom. The plate is placed"}, "441083": {"image_id": 441083, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.16870903059432618, "Bleu_4": 0.13162056532389085, "METEOR": 0.24621094696412674, "ROUGE_L": 0.34997131382673546, "CIDEr": 5.705562224811799e-09, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.3333333333333333, "f": 0.3404255319148936, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a black dog sticking its head out of a car window, enjoying the breeze and the view. The dog appears to be wearing a chain, which is visible as it sticks its head out of the window.\n\nThe car is driving down a street, and there are several"}, "126958": {"image_id": 126958, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.24468219368158126, "Bleu_3": 0.13290914070381443, "Bleu_4": 1.4720536435426588e-05, "METEOR": 0.20715579880965265, "ROUGE_L": 0.28785708266621723, "CIDEr": 1.00960131793907e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a room with a blue wall and a doorway. A clock is mounted on the wall above the door, making it a prominent feature in the room. The doorway leads to a bathroom, as indicated by the presence of a mirror on the wall.\n\nIn the room, there is a"}, "484075": {"image_id": 484075, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.2264554068245216, "Bleu_3": 0.1600854244658392, "Bleu_4": 0.09565657435362714, "METEOR": 0.2516242416791831, "ROUGE_L": 0.34269662921348315, "CIDEr": 6.767337646409561e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.42105263157894735, "f": 0.326530612244898, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.7777777777777778, "f": 0.6363636363636364, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image features a wooden desk with a computer setup on it. A silver laptop is placed on the desk, accompanied by a keyboard and a mouse. A monitor is also present on the desk, positioned in front of the laptop.\n\nIn addition to the computer equipment, there are several books scattered"}, "274528": {"image_id": 274528, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.12577746725443983, "Bleu_4": 1.434424417587908e-05, "METEOR": 0.17823096720132775, "ROUGE_L": 0.22235722964763066, "CIDEr": 8.906036267183581e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10714285714285714, "f": 0.1276595744680851, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a blue truck parked next to a white car, with a large banner advertising a cycling event hanging from the back of the truck. The banner is promoting a cycling event, possibly a race or a group ride, and is likely meant to attract attention and promote"}, "286820": {"image_id": 286820, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.06567895774161787, "Bleu_3": 4.448553400606041e-07, "Bleu_4": 1.163734197858576e-09, "METEOR": 0.1253863751617051, "ROUGE_L": 0.1561100447856686, "CIDEr": 7.157065262362507e-12, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3333333333333333, "f": 0.29411764705882354, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two white smartphones placed side by side on a green cloth. Both phones are turned on and displaying their home screens, showcasing various apps and icons. The screens are filled with different icons, including a clock, a music player, and a weather app. The phones are placed in"}, "69236": {"image_id": 69236, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.1412331707135344, "Bleu_3": 7.569000412718941e-07, "Bleu_4": 1.7618777384959807e-09, "METEOR": 0.17229422094675545, "ROUGE_L": 0.19551282051282048, "CIDEr": 2.631286604337445e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.21428571428571427, "f": 0.21428571428571427, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a park bench situated in a grassy area, with a beautiful view of a city skyline in the background. The bench is positioned near a bush, providing a sense of privacy and tranquility. The skyline is illuminated by the lights of the city, creating a"}, "333237": {"image_id": 333237, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.22622654834606154, "Bleu_3": 0.14255337633579895, "Bleu_4": 1.536322160466025e-05, "METEOR": 0.26753337078961087, "ROUGE_L": 0.24956165984804207, "CIDEr": 9.43685653826396e-12, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image is an old black and white photograph of a bedroom in a hotel. The room features a large bed with a white bedspread, situated in the center of the room. There are two chairs in the room, one near the left side and the other near the right side. A mirror is also"}, "285258": {"image_id": 285258, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.13453455879664997, "Bleu_3": 7.126876576918604e-07, "Bleu_4": 1.6486383890708068e-09, "METEOR": 0.1741786543873291, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.2027148620169146e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21428571428571427, "f": 0.21818181818181817, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a lively scene of two dogs playing together in a grassy field. One dog is standing on its hind legs, while the other dog is lying on its back, appearing to be playfully wrestling with the standing dog. The standing dog is wearing a blue collar, adding a touch"}, "574454": {"image_id": 574454, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.11009637651016171, "Bleu_3": 6.55680898648204e-07, "Bleu_4": 1.60955965059484e-09, "METEOR": 0.14809499325615277, "ROUGE_L": 0.1643097643097643, "CIDEr": 5.8148113510729034e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3157894736842105, "f": 0.2926829268292683, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image captures a lively scene at the beach, where several people are enjoying water sports. There are at least five people visible in the water, with some of them riding surfboards and others parasailing. The surfers are skillfully riding the waves, while the parasail"}, "57703": {"image_id": 57703, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.27653315937200973, "Bleu_3": 0.21077375551703442, "Bleu_4": 0.14054311981084247, "METEOR": 0.2563441089674066, "ROUGE_L": 0.3051907442151345, "CIDEr": 4.4545320822177057e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a group of people walking their dogs in a wooded area. There are five dogs in total, with one dog being held by a person on a leash. The other dogs are walking around the area, exploring the woods.\n\nThere are three people in the scene, with one"}, "70294": {"image_id": 70294, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.07387419460030926, "Bleu_4": 9.42924728285967e-06, "METEOR": 0.1905611559337989, "ROUGE_L": 0.24355464293862653, "CIDEr": 2.818321756345773e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a blue and white bus parked at a bus stop, likely waiting for passengers. The bus is positioned close to a building, possibly a bus station or a terminal. The bus stop is marked with a red line, indicating the designated area for passengers to wait.\n\nThere are a few people"}, "279769": {"image_id": 279769, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.11065666703226194, "Bleu_3": 0.06342171440889113, "Bleu_4": 8.583294598130882e-06, "METEOR": 0.20368280015357124, "ROUGE_L": 0.22235722964763066, "CIDEr": 2.2783259526427362e-10, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.375, "f": 0.3636363636363636, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a wooden dining table with a white napkin on it. On the napkin, there are two bananas placed side by side, one being a regular banana and the other being a plantain. The bananas are placed on top of the napkin, which is covering the table. The"}, "541474": {"image_id": 541474, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 6.47433787030964e-07, "Bleu_4": 1.558500916173644e-09, "METEOR": 0.18172281482479866, "ROUGE_L": 0.20158625247851947, "CIDEr": 1.280126026657269e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a person skiing down a snow-covered slope, with their skis visible as they make their way down the hill. The skier is wearing a white helmet and appears to be enjoying the thrill of the descent. The scene is set against a blue sky, adding to"}, "217561": {"image_id": 217561, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.1630820182599269, "Bleu_3": 8.330762903217117e-07, "Bleu_4": 1.893260841337042e-09, "METEOR": 0.17869415807560138, "ROUGE_L": 0.23461538461538461, "CIDEr": 4.994318320745761e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a dining table set for a meal, with a white plate at the center of the table. On the plate, there is a toothbrush and a tube of toothpaste, indicating that someone is preparing to brush their teeth. The table is also set with silverware"}, "303778": {"image_id": 303778, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.20159019488753482, "Bleu_3": 0.13370981749106947, "Bleu_4": 1.4786996528680024e-05, "METEOR": 0.3028551138026482, "ROUGE_L": 0.2896142433234421, "CIDEr": 7.892409572112665e-12, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1111111111111111, "f": 0.10256410256410256, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a baseball game in progress, with a baseball player standing on the field holding a bat. The player is wearing a baseball uniform and appears to be preparing to hit the ball. The scene also includes a baseball glove, which is located near the center of the image.\n\nIn the"}, "40426": {"image_id": 40426, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.21932534684462168, "Bleu_3": 0.16230866627293947, "Bleu_4": 0.09928716555998014, "METEOR": 0.2530066838144535, "ROUGE_L": 0.30367143746110764, "CIDEr": 5.1876077878778997e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10714285714285714, "f": 0.12244897959183672, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a kitchen counter with a blender and a bowl of food, likely ice cream, placed next to it. The blender is filled with strawberries, and a spoon is resting inside the bowl, ready to be used. The counter also has a few bottles and"}, "324291": {"image_id": 324291, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.17496355305240635, "Bleu_3": 0.08607650943307255, "Bleu_4": 1.0792921564506728e-05, "METEOR": 0.20877848990467263, "ROUGE_L": 0.2901307966706302, "CIDEr": 5.609230363538007e-09, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.18181818181818182, "f": 0.20512820512820512, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man and a young girl riding a small horse together in a grassy field. The man is holding the reins, guiding the horse as they enjoy their time outdoors. The girl is seated on the horse, likely learning how to ride or simply having fun.\n\nThe"}, "96241": {"image_id": 96241, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.07377445721117037, "Bleu_3": 4.743300325935381e-07, "Bleu_4": 1.208698453218432e-09, "METEOR": 0.18041507344895977, "ROUGE_L": 0.21266705403834982, "CIDEr": 2.063447739831541e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16666666666666666, "f": 0.1923076923076923, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a black and red steam engine train traveling down the tracks, with a woman and a child standing nearby. The woman is wearing a skirt and appears to be looking at the train. The child is standing close to the woman, possibly observing the train as well.\n\nThere are a"}, "326911": {"image_id": 326911, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 8.377724227293196e-07, "Bleu_4": 1.890841333722765e-09, "METEOR": 0.22806304212872003, "ROUGE_L": 0.27354260089686094, "CIDEr": 4.697825065788081e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a sidewalk with two dogs standing next to each other. One dog is positioned closer to the left side of the sidewalk, while the other dog is on the right side. Both dogs appear to be looking at something, possibly a bicycle parked nearby.\n\nThe bicycle"}, "209222": {"image_id": 209222, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.22303564279534369, "Bleu_3": 0.1949468589728759, "Bleu_4": 0.17631348764627738, "METEOR": 0.3633164127955402, "ROUGE_L": 0.35442220787604906, "CIDEr": 7.002764766299638e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a man sitting on a bench in a park, enjoying a drink from a bottle. He is positioned on the right side of the bench, with his back facing the camera. The bench is located in the middle of the scene, surrounded by several other benches."}, "362293": {"image_id": 362293, "Bleu_1": 0.3399999999932, "Bleu_2": 0.204040812239959, "Bleu_3": 0.09536688923870477, "Bleu_4": 1.1655307824388146e-05, "METEOR": 0.23815824508761838, "ROUGE_L": 0.2494158878504673, "CIDEr": 1.3813289707270352e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.26666666666666666, "f": 0.2105263157894737, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a horse-drawn carriage traveling down a city street, with two people riding in the carriage. The horse is positioned in the middle of the street, pulling the carriage along.\n\nThere are several cars parked or driving along the street, with one car on the left side of"}, "144481": {"image_id": 144481, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.1630820182599269, "Bleu_3": 8.330762903217117e-07, "Bleu_4": 1.893260841337042e-09, "METEOR": 0.19147207902595656, "ROUGE_L": 0.27371794871794874, "CIDEr": 8.338422374032556e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a museum display with two large, ornate vases placed on a blue surface. The vases are adorned with intricate artwork, depicting scenes of people and figures. One of the vases is positioned closer to the left side of the display, while the other is situated"}, "433804": {"image_id": 433804, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.09701425001261196, "Bleu_3": 5.76976768606882e-07, "Bleu_4": 1.4143550190666944e-09, "METEOR": 0.17910486605280462, "ROUGE_L": 0.21441124780316342, "CIDEr": 1.696600409588053e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2, "f": 0.1951219512195122, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a small white boat speeding through the water, surrounded by palm trees. The boat is moving quickly, leaving a trail of water behind it. There are several people on the boat, enjoying the ride and the beautiful scenery.\n\nIn total, there are five people visible on the boat"}, "142815": {"image_id": 142815, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1978218215826409, "Bleu_3": 0.1311863860222524, "Bleu_4": 0.08156879226605328, "METEOR": 0.24131704051069655, "ROUGE_L": 0.308080808080808, "CIDEr": 3.89212587914625e-11, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.20833333333333334, "f": 0.2380952380952381, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a man sitting on a bed, with another man standing over him, holding a camera. The man sitting on the bed appears to be the subject of the video being recorded. The standing man is focused on capturing the scene, possibly for a video blog or a vlog.\n\nThe bed is"}, "85292": {"image_id": 85292, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.09712858623387621, "Bleu_3": 5.697810303144272e-07, "Bleu_4": 1.3868787330575517e-09, "METEOR": 0.21721813153129788, "ROUGE_L": 0.2507339988256019, "CIDEr": 6.765769501154134e-12, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a red train traveling down the tracks, with a fence visible in the background. The train is carrying a large number of orange train cars, which are attached to the engine. The train appears to be moving along the tracks, possibly transporting goods or passengers. The scene captures the essence"}, "500423": {"image_id": 500423, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.18663625434394554, "Bleu_3": 8.806579930933404e-07, "Bleu_4": 1.922484999501258e-09, "METEOR": 0.22901848764524563, "ROUGE_L": 0.26472411655300687, "CIDEr": 5.2842533853159525e-12, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.24, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a white and orange train parked at a train station. The train is positioned on the left side of the platform, occupying a significant portion of the scene. The platform is empty, with no passengers visible in the image.\n\nThere are two people in the background, one located near the"}, "196280": {"image_id": 196280, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.25807943616605344, "Bleu_3": 0.18090535667325908, "Bleu_4": 1.9152496907021117e-05, "METEOR": 0.23236313026387917, "ROUGE_L": 0.2848565710473649, "CIDEr": 3.77872211346415e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image is a black and white photo of a young boy standing in a kitchen, preparing food. He is reaching for a pot on the stove, possibly cooking a meal. The kitchen is equipped with various utensils and appliances, including a sink, an oven, and a"}, "84752": {"image_id": 84752, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.12094486170917773, "Bleu_3": 6.825571246936573e-07, "Bleu_4": 1.630426121875635e-09, "METEOR": 0.16498564822853995, "ROUGE_L": 0.22426470588235295, "CIDEr": 9.531137168552488e-09, "SPICE": {"All": {"pr": 0.24, "re": 0.2222222222222222, "f": 0.23076923076923075, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a large red and white fighter jet parked on a concrete base, likely in a museum or an airfield. The jet is prominently displayed, drawing attention to its impressive size and design.\n\nIn the background, there are several cars parked in a parking lot, with"}, "222317": {"image_id": 222317, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.2303502213753046, "Bleu_3": 0.18788657958799498, "Bleu_4": 0.14344244175879078, "METEOR": 0.28958723260103475, "ROUGE_L": 0.34099378881987574, "CIDEr": 2.468698324227356e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a brown dog lying on a couch, comfortably resting on a blanket. The couch is situated in a living room, and there is a chair nearby. A clock can be seen hanging on the wall above the couch, and a remote control is placed on the couch,"}, "544421": {"image_id": 544421, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 0.07901769277795581, "Bleu_4": 1.0290348647814142e-05, "METEOR": 0.21406461480880093, "ROUGE_L": 0.29186602870813394, "CIDEr": 1.454316867694851e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3157894736842105, "f": 0.3, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a delicious chocolate cake decorated to resemble a mountain scene. The cake is placed on a white plate, and it is adorned with various elements to create a realistic landscape.\n\nThere are several trees and a house on the cake, adding to the mountain"}, "526827": {"image_id": 526827, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 0.08411954328528157, "Bleu_4": 1.0608359163741716e-05, "METEOR": 0.20265989386210012, "ROUGE_L": 0.22333414693678305, "CIDEr": 9.613758975647091e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.23529411764705882, "f": 0.23529411764705882, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a close-up of a pair of scissors with a red handle, placed on a green surface. The scissors are open, and they are positioned in the center of the scene. There are also several other pairs of scissors scattered around the green surface, with some of them"}, "527529": {"image_id": 527529, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.14254579382569355, "Bleu_3": 0.07358334830308164, "Bleu_4": 9.448049464513672e-06, "METEOR": 0.18753016550422905, "ROUGE_L": 0.18908865468071917, "CIDEr": 3.6210591392119155e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a white cat standing on a table, reaching into a black purse or bag. The cat appears to be curiously exploring the contents of the bag, possibly searching for something to eat or play with. The cat's tail is stretched out as it leans over the bag, giving the"}, "152785": {"image_id": 152785, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.22303564279534369, "Bleu_3": 0.1742636863918258, "Bleu_4": 0.13630005416960525, "METEOR": 0.28839666752367116, "ROUGE_L": 0.3078864353312303, "CIDEr": 1.1346878503323377e-09, "SPICE": {"All": {"pr": 0.28125, "re": 0.391304347826087, "f": 0.3272727272727273, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image depicts a herd of elephants walking across a dry grass field during sunset. There are nine elephants in total, with some of them walking closer to the foreground and others further in the background. The elephants are spread out across the field, with some walking in pairs"}, "516212": {"image_id": 516212, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.2762575317769765, "Bleu_3": 0.23850742807947223, "Bleu_4": 0.20739633400820326, "METEOR": 0.37960613124623127, "ROUGE_L": 0.4555071561916615, "CIDEr": 1.2388608639596103e-07, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.23529411764705882, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a cat sitting on top of a microwave oven in a kitchen. The cat appears to be looking down, possibly observing its surroundings or the food inside the microwave. The microwave is placed on a counter, and there is a toilet paper roll nearby."}, "403378": {"image_id": 403378, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.11375929179665137, "Bleu_3": 6.415924230513621e-07, "Bleu_4": 1.5315603357857856e-09, "METEOR": 0.18486234326869147, "ROUGE_L": 0.19074421513445905, "CIDEr": 4.040098319539681e-11, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a woman standing in front of a mirror, holding it up to her face. She appears to be crying, with her eyes filled with tears. The room has a candlelit atmosphere, with several lit candles placed around the space. The candles are positioned at various heights and distances"}, "216051": {"image_id": 216051, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.21969401454816964, "Bleu_3": 0.16899693052245884, "Bleu_4": 0.14088835237919498, "METEOR": 0.27910660566400164, "ROUGE_L": 0.2921655833048238, "CIDEr": 4.4626343166637564e-11, "SPICE": {"All": {"pr": 0.1875, "re": 0.20689655172413793, "f": 0.19672131147540986, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image features a woman sitting on a wooden bench, accompanied by her dog. The dog is sitting on her lap, and they both seem to be enjoying their time together. The bench is located in a park, surrounded by trees and a fence.\n\nThere are a few other people in the"}, "543043": {"image_id": 543043, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.17039568890752202, "Bleu_3": 0.13243488460776973, "Bleu_4": 0.1092026284593417, "METEOR": 0.2636919110002018, "ROUGE_L": 0.29397590361445786, "CIDEr": 1.481725190358514e-10, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2692307692307692, "f": 0.3111111111111111, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a red sports car parked in front of a junkyard, which is filled with various items such as a boat, a bus, and a truck. The boat is situated in the middle of the junkyard, while the bus and truck are located towards the right side of the scene"}, "392493": {"image_id": 392493, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.07923964199176128, "Bleu_4": 1.0198056661125237e-05, "METEOR": 0.20667463868436875, "ROUGE_L": 0.22578655151141266, "CIDEr": 5.751906235521518e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13793103448275862, "f": 0.1509433962264151, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a lively scene with a kite flying in the sky above a city street. The kite is colorful and appears to be made of strings, creating a mesmerizing visual effect. The street is lined with parked cars, including a few trucks, and a few people can"}, "524681": {"image_id": 524681, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.24371914504394585, "Bleu_3": 0.17875107029587906, "Bleu_4": 0.12233520189533796, "METEOR": 0.31447576458815424, "ROUGE_L": 0.27949599083619703, "CIDEr": 2.9104539013121243e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a group of people standing on a sandy beach, watching a kite flying in the sky. There are at least five people visible in the scene, with some standing closer to the water and others further back on the beach. The kite is soaring high in the sky, capturing the attention"}, "265816": {"image_id": 265816, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.12121830534381622, "Bleu_3": 6.739562828886045e-07, "Bleu_4": 1.59753113202508e-09, "METEOR": 0.19870926772723532, "ROUGE_L": 0.21759809750297268, "CIDEr": 1.1256596453779053e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.21428571428571427, "f": 0.24489795918367344, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.38461538461538464, "f": 0.4545454545454546, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a man driving a horse-drawn carriage down a street. The horse is positioned on the left side of the carriage, and the man is sitting in the carriage, guiding the horse. The carriage is moving down the street, and the man appears to be enjoying the ride."}, "528984": {"image_id": 528984, "Bleu_1": 0.4130434782518904, "Bleu_2": 0.21422819563434162, "Bleu_3": 0.12777430468865322, "Bleu_4": 0.08345753069453976, "METEOR": 0.29303733183778247, "ROUGE_L": 0.28968792401628224, "CIDEr": 5.355355202560115e-07, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.2692307692307692, "f": 0.25, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image depicts a snowy ski slope with a large group of people skiing and snowboarding down the hill. There are at least 14 people visible in the scene, some of them skiing and others snowboarding. The skiers and snowboarders are scattered across the slope, with"}, "565776": {"image_id": 565776, "Bleu_1": 0.3913043478175804, "Bleu_2": 0.26375218935251743, "Bleu_3": 0.16801713501101306, "Bleu_4": 0.1024821120796751, "METEOR": 0.2513878520269909, "ROUGE_L": 0.32317880794701986, "CIDEr": 7.579251378243414e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image showcases a large, well-equipped kitchen with a center island. The kitchen features a variety of appliances, including a refrigerator on the left side, an oven in the middle, and a sink on the right side. There is also a microwave placed above the o"}, "208132": {"image_id": 208132, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.23008949664965453, "Bleu_3": 0.19629015411831666, "Bleu_4": 0.1584450133694868, "METEOR": 0.31739400059895395, "ROUGE_L": 0.3930872876391329, "CIDEr": 5.413292731715283e-10, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1111111111111111, "f": 0.12, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a person sitting at a dining table with a plate of food in front of them. The plate contains a sandwich, a pickle, and a side of fries. There are also two cups on the table, one near the person and another further away.\n\nThe person is se"}, "37017": {"image_id": 37017, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.28284271246901765, "Bleu_3": 0.1869180748641801, "Bleu_4": 0.10800109661445374, "METEOR": 0.33797405659010976, "ROUGE_L": 0.3285457809694794, "CIDEr": 1.4656466753995698e-10, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.25, "f": 0.27450980392156865, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a black dog standing in a kitchen, looking directly at the camera. The dog is wearing a red collar, and it appears to be the main focus of the scene.\n\nThe kitchen is equipped with a refrigerator on the left side and an oven on the right side"}, "20536": {"image_id": 20536, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.2355932146939368, "Bleu_3": 0.15467190426812086, "Bleu_4": 0.09576248453510562, "METEOR": 0.28964254351133273, "ROUGE_L": 0.32555036691127415, "CIDEr": 2.6283299042823452e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a white toilet with a roll of toilet paper on the back of the tank. The toilet is situated in a bathroom stall, and there are two additional rolls of toilet paper on the wall, one above the other. The toilet paper is neat"}, "289264": {"image_id": 289264, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.1428571428542566, "Bleu_3": 0.09473945732893252, "Bleu_4": 1.1597748989748828e-05, "METEOR": 0.20255189602916793, "ROUGE_L": 0.27128335451080055, "CIDEr": 4.1786480860608664e-10, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.11764705882352941, "f": 0.0909090909090909, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a brown dog sitting in a window sill, looking out of the window. The dog appears to be wearing a red collar, and it is positioned near the center of the scene. The window provides a view of the outdoors, allowing the dog to observe its surroundings."}, "18014": {"image_id": 18014, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.1580407329280035, "Bleu_3": 8.218171224115561e-07, "Bleu_4": 1.884595804598033e-09, "METEOR": 0.18573797678275292, "ROUGE_L": 0.28259430840502975, "CIDEr": 2.982717608948594e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.13043478260869565, "f": 0.1276595744680851, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a delicious pizza with various toppings, including peppers and chicken, sitting on top of a box. The pizza is cut into slices, making it easy to serve and enjoy. The pizza is placed on a dining table, which occupies the majority of the scene."}, "381123": {"image_id": 381123, "Bleu_1": 0.3399999999932, "Bleu_2": 0.24989793834546398, "Bleu_3": 0.17329313830999216, "Bleu_4": 0.10257973212183878, "METEOR": 0.24579023443235823, "ROUGE_L": 0.326397146254459, "CIDEr": 5.4738086902175984e-09, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.20833333333333334, "f": 0.18867924528301888, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a sandy beach with a row of colorful kayaks and canoes lined up on the shore. There are a total of nine boats in various sizes and colors, creating a vibrant scene. Some of the boats are closer to the water's edge, while others are further"}, "19608": {"image_id": 19608, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 0.09139586978860176, "Bleu_4": 1.1611347030414458e-05, "METEOR": 0.23166066718277814, "ROUGE_L": 0.26212400245549416, "CIDEr": 2.0073825469972196e-06, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09523809523809523, "f": 0.08333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a serene scene of a large bird, possibly a pelican, swimming in a pond. The bird is situated in the middle of the pond, surrounded by a lush green environment.\n\nIn the background, a person is riding a bicycle, enjoying the out"}, "497348": {"image_id": 497348, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1456862718139933, "Bleu_3": 7.618427528743762e-07, "Bleu_4": 1.7513564291613392e-09, "METEOR": 0.2279413342022041, "ROUGE_L": 0.25386444708680145, "CIDEr": 1.3159341834646684e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a red car parked on the side of a road, near a no-through road sign. The car is positioned close to the sign, and there is a fence nearby. The scene also includes a few other cars parked further down the road.\n\nIn addition to the cars,"}, "437594": {"image_id": 437594, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.09251566147567657, "Bleu_4": 1.1274892861583804e-05, "METEOR": 0.20241376229951105, "ROUGE_L": 0.3315217391304348, "CIDEr": 1.485714769414699e-09, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a woman sitting at a desk, working on her laptop. She is focused on the screen, which is displaying a webpage. The laptop is placed on a table, and the woman is seated in a chair.\n\nIn the room, there is a brick wall visible, adding a unique touch"}, "413404": {"image_id": 413404, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.1591372845179993, "Bleu_3": 0.07769326548712255, "Bleu_4": 9.69881251488752e-06, "METEOR": 0.19213591439938096, "ROUGE_L": 0.2096700274977085, "CIDEr": 2.3824805999273974e-13, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a park with a circular area surrounded by trees and benches. There are three benches in the scene, with one located near the center of the circular area and the other two situated closer to the edges. The park is situated next to a building, and a truck can be seen parked nearby"}, "332775": {"image_id": 332775, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.14580296087694455, "Bleu_3": 0.0967137615427347, "Bleu_4": 1.184204612229436e-05, "METEOR": 0.25657092239481005, "ROUGE_L": 0.31504196255648803, "CIDEr": 1.7969581281828335e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.20689655172413793, "f": 0.24000000000000002, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a cat sitting inside a black suitcase, which is placed on a bed. The cat appears to be looking out of the suitcase, possibly curious about its surroundings or seeking attention. The bed occupies the majority of the scene, with the suitcase being the main focus."}, "530624": {"image_id": 530624, "Bleu_1": 0.255813953482423, "Bleu_2": 0.19116707482361836, "Bleu_3": 0.12125252078651538, "Bleu_4": 1.4529580794887106e-05, "METEOR": 0.2948294639309753, "ROUGE_L": 0.3400696864111499, "CIDEr": 1.834269036996691e-07, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a brown dog lying on a bed, covered by a blanket. The dog appears to be sleeping or resting comfortably under the blanket. The bed is covered with a floral comforter, adding a cozy and inviting atmosphere to the scene."}, "139113": {"image_id": 139113, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.20016827936980822, "Bleu_3": 0.1313848528695593, "Bleu_4": 0.09664193952427368, "METEOR": 0.2975452022940595, "ROUGE_L": 0.2872277810476751, "CIDEr": 6.095136237912446e-11, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06896551724137931, "f": 0.09090909090909091, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a man playing soccer on a field, holding a soccer ball in his hands. He appears to be in the middle of a game, possibly taking a break or preparing to throw the ball. Another person is visible in the background, possibly watching the game or waiting for their turn to play."}, "192858": {"image_id": 192858, "Bleu_1": 0.42857142856268227, "Bleu_2": 0.2988071523274369, "Bleu_3": 0.15604075333783504, "Bleu_4": 1.6952707578778213e-05, "METEOR": 0.2776307240416963, "ROUGE_L": 0.38808559861191444, "CIDEr": 1.2869410497513456e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10714285714285714, "f": 0.1276595744680851, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a group of young girls gathered around a dining table, enjoying a meal together. They are sharing a large pizza placed on a pizza pan, with several slices already missing. The girls are sitting on chairs, with some of them smiling and posing for the camera."}, "482742": {"image_id": 482742, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.13644420572458105, "Bleu_3": 7.396917719335283e-07, "Bleu_4": 1.731749067280523e-09, "METEOR": 0.19388393512457283, "ROUGE_L": 0.21942446043165467, "CIDEr": 3.7850574571266616e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.12121212121212122, "f": 0.1379310344827586, "fn": 29.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a man riding a bicycle down a street, carrying a large box on the back of his bike. The box appears to be filled with bottles, possibly for sale or transportation. The man is wearing a backpack, which is also visible on his back.\n\nThe"}, "398818": {"image_id": 398818, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.15182109665359528, "Bleu_3": 0.07942711818418766, "Bleu_4": 1.0272436745896128e-05, "METEOR": 0.2399525846093642, "ROUGE_L": 0.2293233082706767, "CIDEr": 1.4026888156839516e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a countertop with two ripe bananas prominently displayed. The bananas are placed next to each other, with one banana slightly to the left of the other. The bananas are yellow and appear to be in good condition.\n\nIn the background, there is a water bottle"}, "305871": {"image_id": 305871, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.1428571428542566, "Bleu_3": 0.09473945732893252, "Bleu_4": 1.1597748989748828e-05, "METEOR": 0.1741489997467364, "ROUGE_L": 0.21759809750297268, "CIDEr": 2.079432591098176e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16, "f": 0.15094339622641512, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a street sign on a pole, indicating the direction to San Carlos. The sign is positioned on the side of a street, with a blue sky visible in the background. The street sign is accompanied by a one-way sign, providing guidance to drivers and pedestrians.\n\nIn the"}, "443818": {"image_id": 443818, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.12121830534381621, "Bleu_3": 0.08491317075202563, "Bleu_4": 1.0683334564397808e-05, "METEOR": 0.2076519534663003, "ROUGE_L": 0.19830949284785435, "CIDEr": 4.472078563025778e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08695652173913043, "f": 0.0909090909090909, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a small brown dog lying on a soft, fluffy bed. The dog is comfortably resting on the bed, which is placed on a white surface. The dog appears to be enjoying its time on the bed, possibly sleeping or relaxing. The bed provides a cozy and inv"}, "421109": {"image_id": 421109, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.08979301819262463, "Bleu_4": 0.06199874625320648, "METEOR": 0.2758517440695587, "ROUGE_L": 0.29397590361445786, "CIDEr": 2.4526525008199837e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a large brown horse standing in a grassy field, with its head turned to the side. The horse appears to be walking or trotting across the field, possibly enjoying the open space and the surrounding environment.\n\nIn the background, there are several other horses, some of which are closer"}, "416660": {"image_id": 416660, "Bleu_1": 0.3157894736786704, "Bleu_2": 0.22528177844080394, "Bleu_3": 0.14041178671043472, "Bleu_4": 0.08461633959192502, "METEOR": 0.21502814367564493, "ROUGE_L": 0.24413950829045164, "CIDEr": 1.6173285847732647e-13, "SPICE": {"All": {"pr": 0.35, "re": 0.5384615384615384, "f": 0.4242424242424242, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.8571428571428571, "f": 0.7058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image is a black and white photograph of a city street with a group of people standing outside a jewelry store. There are at least five people visible in the scene, with some of them looking into the store window. One person is standing closer to the left side of the image, while the others are"}, "322845": {"image_id": 322845, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.25900956329042873, "Bleu_3": 0.20824540717562975, "Bleu_4": 0.1631375845321065, "METEOR": 0.29503647204218386, "ROUGE_L": 0.308080808080808, "CIDEr": 3.436798439561314e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.23529411764705882, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a stop sign with a red background, prominently displayed in front of a building. The stop sign is positioned on a pole, and it is located near a railroad crossing sign. The scene appears to be set in a rustic environment, with the building and the stop sign giving the impression"}, "304361": {"image_id": 304361, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.12875644765560088, "Bleu_4": 0.08004346926940502, "METEOR": 0.2724887642061387, "ROUGE_L": 0.27961037898010965, "CIDEr": 2.8705075875430436e-12, "SPICE": {"All": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a young child standing in a room, holding a remote control in their hands. The child appears to be focused on the remote, possibly playing a video game or adjusting the television settings.\n\nThe room has a few other items in it, including a chair located in the background and a backpack"}, "446917": {"image_id": 446917, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.14564381624761055, "Bleu_3": 0.07901421228222158, "Bleu_4": 1.0410380146216557e-05, "METEOR": 0.1809589536931028, "ROUGE_L": 0.24063116370808676, "CIDEr": 1.054258824612054e-06, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.3684210526315789, "f": 0.32558139534883723, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a blue backpack with a banana sticking out of it. The banana is placed in the backpack's pocket, and it appears to be ripe. The backpack is positioned on the ground, and the banana is the main focus of the scene."}, "234676": {"image_id": 234676, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.19402850002522387, "Bleu_3": 0.09158935294477763, "Bleu_4": 1.124795146748506e-05, "METEOR": 0.14784599631546275, "ROUGE_L": 0.2238532110091743, "CIDEr": 2.2355600077506763e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures a lively beach scene with several people enjoying their time near the ocean. There are at least 12 people visible in the scene, some of them standing on the beach and others in the water. A few of them are holding surfboards, indicating that they are likely surfers."}, "343692": {"image_id": 343692, "Bleu_1": 0.42553191488456316, "Bleu_2": 0.3041495323296952, "Bleu_3": 0.2310491353153974, "Bleu_4": 0.17029245450294905, "METEOR": 0.2867321299997588, "ROUGE_L": 0.3449421057355713, "CIDEr": 1.3844186686816666e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a silver scooter parked in front of a yellow building. The scooter is positioned close to a yellow sign, which is mounted on the wall. The sign appears to be a traffic hazard warning, alerting people to potential dangers in the area. The scooter"}, "293011": {"image_id": 293011, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.19828123627050095, "Bleu_3": 0.09559831570949828, "Bleu_4": 1.1870650306785609e-05, "METEOR": 0.24021286757241822, "ROUGE_L": 0.3244372684965333, "CIDEr": 9.09020054151783e-07, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2222222222222222, "f": 0.22641509433962265, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a birthday cake designed to look like an airplane. The cake is decorated with blue frosting and has a red and blue color scheme. The cake is placed on a red tray, and it is adorned with candles, making it a delightful and fest"}, "104625": {"image_id": 104625, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.21514162331122882, "ROUGE_L": 0.21908296420447745, "CIDEr": 5.051849144366536e-12, "SPICE": {"All": {"pr": 0.5263157894736842, "re": 0.3225806451612903, "f": 0.39999999999999997, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 10.0}, "Relation": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8888888888888888, "re": 0.6666666666666666, "f": 0.761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 8.0}}, "caption": "The image features a cat sitting on a TV stand, attentively watching a soccer game on the television. The cat is positioned in the foreground, with the TV screen in the background. The soccer game is being played by two teams, with one team on the left side of the screen and the"}, "175612": {"image_id": 175612, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 0.07063108368194851, "Bleu_4": 9.57049894254339e-06, "METEOR": 0.19125724405913988, "ROUGE_L": 0.24887800897592818, "CIDEr": 2.2179499514030216e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a toy figure of a man holding a skateboard. The toy is positioned in the center of the scene, with the skateboard held in front of it. The toy appears to be a cartoon-like character, possibly a Simpsons toy, given its distinct"}, "43448": {"image_id": 43448, "Bleu_1": 0.4347826086862004, "Bleu_2": 0.3108349360732723, "Bleu_3": 0.18746034392462774, "Bleu_4": 0.11125382292156775, "METEOR": 0.2353463944184796, "ROUGE_L": 0.32317880794701986, "CIDEr": 0.0004726346817312924, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.2857142857142857, "f": 0.2758620689655172, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two elephants in a zoo enclosure, with one being a baby elephant and the other being a larger adult elephant. The baby elephant is standing next to the adult elephant, which is grazing on some grass. The elephants are surrounded by a l"}, "528705": {"image_id": 528705, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.08939035350783202, "Bleu_4": 1.1103081472064331e-05, "METEOR": 0.18442800880889534, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.0086115194306996e-09, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.3333333333333333, "f": 0.31818181818181823, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a person wearing a red coat, holding a brown teddy bear in their arms. The teddy bear is wearing a red and white shirt, and it appears to be a stuffed animal. The person is standing in front of a tree, which is visible in the background."}, "319221": {"image_id": 319221, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.23218786590068996, "Bleu_3": 0.15674138067961096, "Bleu_4": 0.09844457464005989, "METEOR": 0.2725796699606137, "ROUGE_L": 0.2748455200823893, "CIDEr": 4.4068347560221317e-07, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.2, "f": 0.15789473684210528, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a dining table with a tray filled with various plates of food. The tray is topped with a selection of vegetables, including broccoli and asparagus, as well as a bowl of sauce. There are multiple bowls of food on the tray,"}, "338903": {"image_id": 338903, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.08377724227293193, "Bleu_4": 1.063298221330347e-05, "METEOR": 0.18122159368394913, "ROUGE_L": 0.27354260089686094, "CIDEr": 2.562852912207998e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a white plate filled with a delicious breakfast consisting of bananas and cereal. There are several banana slices scattered across the plate, with some placed closer to the center and others towards the edges. The cereal is mixed in with the bananas, creating a visually appealing"}, "364993": {"image_id": 364993, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.17204158993311794, "Bleu_3": 8.898958910772614e-07, "Bleu_4": 2.036143756474482e-09, "METEOR": 0.18650438563628552, "ROUGE_L": 0.24583557227297154, "CIDEr": 3.447218746861664e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13793103448275862, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a person holding a large sandwich in their hand, showcasing its various ingredients. The sandwich is filled with meat, lettuce, and pickles, making it a delicious and hearty meal. The person is holding the sandwich in front of a dining table,"}, "37616": {"image_id": 37616, "Bleu_1": 0.3399999999932, "Bleu_2": 0.24989793834546398, "Bleu_3": 0.18667437435977016, "Bleu_4": 0.1533924774063909, "METEOR": 0.33935585665738066, "ROUGE_L": 0.3335358444714459, "CIDEr": 2.97118240618292e-09, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.27586206896551724, "f": 0.2857142857142857, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image depicts a man standing in a living room, holding a box in his hand. The living room is furnished with a couch, a chair, and a dining table. There are several books scattered around the room, some on the table and others on the floor.\n\nIn addition to"}, "157756": {"image_id": 157756, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.28253466077593814, "Bleu_3": 0.18430810234248915, "Bleu_4": 0.12579787892080235, "METEOR": 0.2480692626703275, "ROUGE_L": 0.3124644280022766, "CIDEr": 5.278767710172042e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a large clock tower standing tall in the middle of a city street. The clock is prominently displayed on the side of the tower, making it a focal point in the scene. The street is bustling with activity, as several cars and a truck are driving by, and multiple people"}, "516508": {"image_id": 516508, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.11851923038388859, "Bleu_4": 0.09033511771965559, "METEOR": 0.20245601569158167, "ROUGE_L": 0.29501684083254165, "CIDEr": 8.06885791348348e-12, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.25, "f": 0.20833333333333331, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a large clock mounted on a wall, with a window above it. The clock is positioned in the center of the scene, and the window above it allows natural light to illuminate the clock face. The clock's face is adorned with Roman numerals, making it a classic and elegant"}, "520528": {"image_id": 520528, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.13609999140195853, "Bleu_4": 0.08513012360711482, "METEOR": 0.27033836440830733, "ROUGE_L": 0.3051907442151345, "CIDEr": 2.5708533983090866e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.1875, "f": 0.14634146341463414, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a young boy wearing a blue shirt and a baseball glove, standing on a baseball field. He is in the process of throwing a baseball, which is captured in mid-air. The boy appears to be focused and determined as he prepares to make the throw.\n\nThe baseball field"}, "37675": {"image_id": 37675, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.11215443081631235, "Bleu_3": 0.07850304593348241, "Bleu_4": 0.05549736159877403, "METEOR": 0.2288380859784547, "ROUGE_L": 0.25507765830346474, "CIDEr": 5.89275984431871e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.21739130434782608, "f": 0.23255813953488372, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a serene scene of two horses grazing in a grassy field near a large, old church. The horses are positioned on the left side of the scene, with one closer to the foreground and the other slightly further back. The church is a prominent structure in the background, with its tall"}, "232383": {"image_id": 232383, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.26766404732330973, "Bleu_3": 0.19277913491330886, "Bleu_4": 0.10996285329040202, "METEOR": 0.25160016501339416, "ROUGE_L": 0.26787954830614796, "CIDEr": 3.082019250785591e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a cat sitting on top of a laptop computer, looking at the camera. The cat is positioned in the center of the laptop, with its head peeking over the screen. The laptop is open and turned on, displaying a blue screen.\n\nIn the background, there is a book placed"}, "137658": {"image_id": 137658, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.15891043153801604, "Bleu_3": 0.07810454645155356, "Bleu_4": 9.783773730343155e-06, "METEOR": 0.2462590636292642, "ROUGE_L": 0.24110671936758893, "CIDEr": 2.4681303633868314e-12, "SPICE": {"All": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a person holding a cell phone in their hand, with the phone's screen facing upwards. The cell phone is placed inside a pocket or a bag, which is located on the left side of the person's hand. The person's hand is visible on the left side of the image,"}, "209322": {"image_id": 209322, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.23063280200236536, "Bleu_3": 0.15138000825437875, "Bleu_4": 1.6662810872720654e-05, "METEOR": 0.306619616248148, "ROUGE_L": 0.2952973720608575, "CIDEr": 1.0493083471987451e-08, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3181818181818182, "f": 0.3181818181818182, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a white toilet with a blue and white tiled wall, sitting in a bathroom. The toilet is positioned under a sink, which is located on the left side of the bathroom. The sink is accompanied by a mirror above it.\n\nThere are several rolls of"}, "128644": {"image_id": 128644, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.17614871215260033, "Bleu_3": 8.770015703255858e-07, "Bleu_4": 1.967646828106159e-09, "METEOR": 0.17254511793506289, "ROUGE_L": 0.2663423153692615, "CIDEr": 7.278779480342154e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features an old, small airplane parked on a wet runway. The airplane is positioned on its side, with its nose pointing upwards. The runway appears to be wet, possibly due to rain or other weather conditions.\n\nThere are two people visible in the scene, one standing"}, "342675": {"image_id": 342675, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.19802950859148932, "Bleu_3": 0.15769573216073673, "Bleu_4": 0.12447904522737402, "METEOR": 0.23439280977795712, "ROUGE_L": 0.29397590361445786, "CIDEr": 1.7801866210914258e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.25, "f": 0.18604651162790697, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a man standing next to a red train, possibly waiting to board or just observing the train. The train is quite large and occupies a significant portion of the scene. The man is wearing a hat and a jacket, and he is holding a handbag.\n\nThere are a few"}, "200234": {"image_id": 200234, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.12839858194733528, "Bleu_4": 0.08236272606528804, "METEOR": 0.1936316311934562, "ROUGE_L": 0.2908967044196542, "CIDEr": 5.442517948255954e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.42105263157894735, "f": 0.372093023255814, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a young boy playing with a frisbee in a park. He is bending over and holding the frisbee in his hand, possibly preparing to throw it. The park is equipped with several picnic tables and benches, providing a comfortable space for people to relax and enjoy"}, "545390": {"image_id": 545390, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.19026059765810296, "Bleu_3": 0.15354390128889117, "Bleu_4": 0.12201289225771661, "METEOR": 0.2385291534799211, "ROUGE_L": 0.29397590361445786, "CIDEr": 2.870824309745147e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08695652173913043, "f": 0.0851063829787234, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a woman sitting at a dining table, holding a large pizza in her hands. She is smiling and appears to be enjoying the moment. The table is surrounded by several chairs, with one chair on the left side of the table and another on the right side.\n\nIn the"}, "43073": {"image_id": 43073, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 0.07777190244898266, "Bleu_4": 1.0056053706911773e-05, "METEOR": 0.16985035833290635, "ROUGE_L": 0.2208811104405552, "CIDEr": 1.2114461990150136e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a young boy with blonde hair, sitting in front of a pink wall. He is smiling and appears to be enjoying the moment. A hairdryer is being used on his hair, likely to dry it after a bath or a haircut. The boy is wearing a"}, "188651": {"image_id": 188651, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 8.206702275709718e-07, "Bleu_4": 1.85183396023708e-09, "METEOR": 0.1988857983634816, "ROUGE_L": 0.23252858958068615, "CIDEr": 5.863690462793586e-11, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a cat sitting underneath a car, likely seeking shelter or comfort. The cat is positioned in the middle of the scene, with its body partially visible. The car is parked on the street, and the cat appears to be relaxed and enjoying its time underneath the vehicle."}, "484551": {"image_id": 484551, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.20550493309104514, "Bleu_3": 0.11909718541937828, "Bleu_4": 0.07662616731096747, "METEOR": 0.2194678243466354, "ROUGE_L": 0.2507045561296383, "CIDEr": 1.133458022259946e-10, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2, "f": 0.25925925925925924, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.38461538461538464, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a woman wearing an orange shirt, sitting on a boat in the ocean. She is smiling and appears to be enjoying her time on the boat. The boat is positioned in the middle of the ocean, with the woman sitting on the front of the boat.\n\nThere are a"}, "396224": {"image_id": 396224, "Bleu_1": 0.4090909090816116, "Bleu_2": 0.27588029391667884, "Bleu_3": 0.12191693142366877, "Bleu_4": 1.4499467512222076e-05, "METEOR": 0.2290020693588118, "ROUGE_L": 0.29985955056179775, "CIDEr": 8.064732607126912e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a dining table with a white tablecloth, set for a meal. On the table, there is a plate of food, including a turkey dinner, carrots, and bread. The table is also adorned with a wine glass, a cup, and a bowl."}, "255067": {"image_id": 255067, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.15639188177115004, "Bleu_3": 0.11216278231474784, "Bleu_4": 0.08624849693567765, "METEOR": 0.2379959801477155, "ROUGE_L": 0.30198019801980197, "CIDEr": 1.9799839356392928e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.06451612903225806, "f": 0.07272727272727274, "fn": 29.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a large white polar bear in a pool of water, possibly a zoo enclosure. The bear is standing on its hind legs and appears to be playing with a blue object, which could be a toy or a piece of equipment. The bear's front paws are on the object, and"}, "479129": {"image_id": 479129, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.23632829671335462, "Bleu_3": 0.16934714128636405, "Bleu_4": 0.12120981066002942, "METEOR": 0.24792772066866794, "ROUGE_L": 0.31282051282051276, "CIDEr": 1.1645337852718207e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14814814814814814, "f": 0.16666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a white plate with a delicious dessert consisting of a banana split and a scoop of ice cream. The banana is sliced and placed on the plate, with the ice cream and sauce surrounding it. The banana split is topped with a sprig of mint"}, "363887": {"image_id": 363887, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.20402970888419056, "Bleu_3": 0.12276317177256986, "Bleu_4": 0.0805263299613596, "METEOR": 0.2801581595438859, "ROUGE_L": 0.2848565710473649, "CIDEr": 5.051060023834006e-08, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.19230769230769232, "f": 0.19230769230769232, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features an old, rusted red fire truck parked on a dirt road. The truck is surrounded by a grassy area, and it appears to be in a somewhat neglected state. The truck is parked in front of a building, possibly a barn or a house."}, "441969": {"image_id": 441969, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.15604694598027796, "Bleu_3": 7.668414781936143e-07, "Bleu_4": 1.7078913122640403e-09, "METEOR": 0.1579748135119617, "ROUGE_L": 0.22858672376873657, "CIDEr": 4.774254310337756e-13, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2608695652173913, "f": 0.2727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a glass table with a potted plant on top of it, placed in a room with a glass wall. The table is surrounded by several potted plants, creating a cozy and green atmosphere. The plants are placed in various positions around the table, with some closer to the glass wall and others further"}, "410225": {"image_id": 410225, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.10067569617030046, "Bleu_4": 1.2138611630520416e-05, "METEOR": 0.23732810321519932, "ROUGE_L": 0.26521739130434785, "CIDEr": 1.8467653340341449e-09, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.2, "f": 0.24137931034482762, "fn": 28.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.35714285714285715, "f": 0.41666666666666663, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a dining table with a bowl of cereal and a cup of coffee placed on it. The bowl of cereal is positioned towards the left side of the table, while the cup of coffee is located towards the right side. There are two laptops on the table,"}, "277073": {"image_id": 277073, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.1184508853673932, "Bleu_3": 0.08420468458150739, "Bleu_4": 0.06002231367460855, "METEOR": 0.21446345906440276, "ROUGE_L": 0.15752098127824402, "CIDEr": 1.250024259601037e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14814814814814814, "f": 0.16326530612244897, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image depicts a busy city street with a man and a woman riding a motorcycle. The man is driving the motorcycle, while the woman is seated behind him. They are surrounded by various vehicles, including cars and a truck, which are all moving in different directions.\n\nThere are"}, "41011": {"image_id": 41011, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.08760206462900565, "Bleu_4": 1.0878661088479764e-05, "METEOR": 0.21836327406734882, "ROUGE_L": 0.25831820931639443, "CIDEr": 2.61977172194252e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man wearing a suit and tie, riding a horse in a field. The man appears to be dressed in formal attire, possibly for a special event or occasion. The horse is positioned in the center of the scene, with the man sitting comfortably on its back.\n\nIn"}, "343821": {"image_id": 343821, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.14280110945625535, "Bleu_3": 0.10767861130247745, "Bleu_4": 0.0849267048928488, "METEOR": 0.2250818686249388, "ROUGE_L": 0.2238532110091743, "CIDEr": 2.19833566328941e-11, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08695652173913043, "f": 0.09523809523809525, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a family of swans swimming together in a body of water. There are four swans in total, with two adult swans and two baby swans. The adult swans are positioned on the left side of the image, while the baby swans are on the right side. The family"}, "530620": {"image_id": 530620, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1295047816452144, "Bleu_3": 0.0685787273497866, "Bleu_4": 8.91763149698053e-06, "METEOR": 0.14014665389800285, "ROUGE_L": 0.1737891737891738, "CIDEr": 3.922129302272558e-12, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.10344827586206896, "f": 0.10909090909090909, "fn": 26.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image features a group of people working together to load a large kite onto a truck. The kite is positioned on the ground, and the people are in the process of attaching it to the truck. There are at least five people visible in the scene, with some standing closer to the tr"}, "22113": {"image_id": 22113, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.23782574707262866, "Bleu_3": 0.16540015368980918, "Bleu_4": 0.09802862511748141, "METEOR": 0.2713345129808743, "ROUGE_L": 0.29397590361445786, "CIDEr": 1.5561869783425626e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.20833333333333334, "f": 0.22727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a red and green fire hydrant sitting on a sidewalk. The fire hydrant is positioned near a fence, and it appears to be in a somewhat dirty condition. The hydrant is surrounded by grass, and there is a brick wall in the background. The scene also includes a bench"}, "82836": {"image_id": 82836, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.22404481344004462, "Bleu_3": 0.14538903521362667, "Bleu_4": 1.5907005514231726e-05, "METEOR": 0.21184098473881108, "ROUGE_L": 0.2858816637375513, "CIDEr": 1.4394587608997717e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a sandy beach with a group of five birds standing on the sand. The birds are spread out along the beach, with some closer to the water and others further back. The scene captures the beauty of the beach and the birds enjoying their time near the ocean."}, "538925": {"image_id": 538925, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.24094636829087762, "Bleu_3": 0.10441355063931192, "Bleu_4": 1.228358533448228e-05, "METEOR": 0.25494006518353524, "ROUGE_L": 0.27774615822424586, "CIDEr": 1.302422509827543e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.25, "f": 0.22857142857142856, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bedroom with a large bed situated in the center of the room. The bed is covered with a white sheet and a blanket, giving it a clean and inviting appearance. A brown blanket is also placed on the bed, adding a touch of warmth and color to the room."}, "440189": {"image_id": 440189, "Bleu_1": 0.41666666665798613, "Bleu_2": 0.32616403651985376, "Bleu_3": 0.26448523592528983, "Bleu_4": 0.20137842728658817, "METEOR": 0.25270447792319944, "ROUGE_L": 0.39845605700712583, "CIDEr": 4.0784393973054885e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.26666666666666666, "f": 0.2580645161290323, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a young boy standing on a sandy beach, holding a red frisbee in his hand. He appears to be enjoying his time at the beach, possibly preparing to play with the frisbee.\n\nThere are several other people scattered across the beach, some closer to the"}, "32777": {"image_id": 32777, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.21398889174339228, "Bleu_3": 0.15118969592806583, "Bleu_4": 0.1073737962825756, "METEOR": 0.28341715671750706, "ROUGE_L": 0.21542083578575633, "CIDEr": 2.0434701146007446e-13, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a train station with a blue and yellow train parked on the tracks. A man is standing next to the train, looking at his cell phone. There are several other people in the scene, some of them closer to the train and others further away.\n\nIn addition to the train, there are"}, "50679": {"image_id": 50679, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 8.081987454730765e-07, "Bleu_4": 1.8117138691105226e-09, "METEOR": 0.2376773116363106, "ROUGE_L": 0.2167219327333018, "CIDEr": 6.896483999003603e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a single orange sitting on a paved road, surrounded by several cars parked nearby. The orange is positioned in the center of the scene, drawing attention to itself. The cars are parked in various orientations, with some closer to the foreground and others further in the background. The scene"}, "86250": {"image_id": 86250, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2126329371370835, "Bleu_3": 0.12526923159832437, "Bleu_4": 0.08129805989202789, "METEOR": 0.23157041551683386, "ROUGE_L": 0.2675438596491228, "CIDEr": 4.7683426419122715e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man sitting on the floor in a living room, surrounded by various furniture and decorations. He is wearing a white shirt and appears to be in a relaxed position, possibly meditating or simply enjoying his time.\n\nThe living room is furnished with a couch"}, "482432": {"image_id": 482432, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.29807746344154457, "Bleu_3": 0.22311191588712714, "Bleu_4": 0.15448396989750968, "METEOR": 0.2279257882426952, "ROUGE_L": 0.2952973720608575, "CIDEr": 1.7979477074918445e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.22727272727272727, "f": 0.23809523809523808, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a bathroom sink with a toothbrush placed next to a tube of Aveeno Active Brightening Skin Daily Exfoliating Scrub. The toothbrush is positioned on the left side of the sink, while the scrub is on the right side. The"}, "330880": {"image_id": 330880, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.2853175519564256, "Bleu_3": 0.23308491541228354, "Bleu_4": 0.1714165581280074, "METEOR": 0.3337670569851746, "ROUGE_L": 0.44552647595861233, "CIDEr": 4.382259504526275e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.23529411764705882, "f": 0.22857142857142856, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a man sitting at a dining table in a restaurant, looking at a large pizza placed in front of him. The pizza is topped with various ingredients, including ham, cheese, and spinach. The man appears to be contemplating whether to eat the pizza or"}, "201934": {"image_id": 201934, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.2807284211697214, "Bleu_3": 0.21147125246896165, "Bleu_4": 0.1551207146056763, "METEOR": 0.24851198385164192, "ROUGE_L": 0.28773584905660377, "CIDEr": 6.425231052866718e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 8.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.8333333333333334, "f": 0.5882352941176471, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a white bus parked on the side of a road, next to a fence. The bus is positioned in front of a parking lot filled with various cars. There are at least 13 cars visible in the parking lot, with some parked closer to the bus and others further"}, "579462": {"image_id": 579462, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.08330762903217113, "Bleu_4": 1.0646588104484678e-05, "METEOR": 0.20830748051247927, "ROUGE_L": 0.308080808080808, "CIDEr": 2.630649363754287e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a woman in a floral dress, standing in a bedroom and pulling a suitcase. She is in the process of packing her belongings, possibly preparing for a trip. The suitcase is placed on a bed, and the woman is focused on her task.\n\nThe bedroom"}, "183657": {"image_id": 183657, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.15861031714066393, "Bleu_3": 7.850304593348245e-07, "Bleu_4": 1.7549806678208954e-09, "METEOR": 0.15944377435501755, "ROUGE_L": 0.2053872053872054, "CIDEr": 3.638338763117688e-12, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.3333333333333333, "f": 0.2777777777777778, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a bowl filled with oranges floating on a body of water, possibly a lake or a pond. The bowl is placed in the middle of the water, and the oranges are visible inside it. The scene appears to be set in a winter environment, as the water appears to be fro"}, "352652": {"image_id": 352652, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.1942571724677524, "Bleu_3": 0.14357582278478706, "Bleu_4": 1.559798449251792e-05, "METEOR": 0.3152761600223053, "ROUGE_L": 0.3190005810575247, "CIDEr": 3.360907610525983e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a parking lot with a car covered in snow, making it difficult to see the car's color. The car is parked next to a parking meter, which is also covered in snow. The parking meter is positioned on the side of the car, and it appears to be stuck"}, "339823": {"image_id": 339823, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.16026009915056863, "Bleu_4": 0.12799998273815197, "METEOR": 0.31036779879620224, "ROUGE_L": 0.3386798272671191, "CIDEr": 1.4832799051815767e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a woman wearing an orange dress, standing under a black umbrella. She is holding the umbrella above her head, possibly to protect herself from the sun or rain. The woman appears to be smiling, enjoying her time under the umbrella. The scene is set against a"}, "203690": {"image_id": 203690, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.20174997577993367, "Bleu_3": 0.12184699455548438, "Bleu_4": 1.4239605151896117e-05, "METEOR": 0.28776874670740304, "ROUGE_L": 0.2781758957654723, "CIDEr": 2.541540917801578e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a beach scene with a man walking along the shore, carrying a surfboard. He is wearing a wetsuit, indicating that he is likely preparing for a surfing session. The man is walking towards the water, possibly to enter the ocean and enjoy some surfing."}, "344614": {"image_id": 344614, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.21798903029455755, "Bleu_3": 0.15404300269030785, "Bleu_4": 0.12109305928332115, "METEOR": 0.20778383865626202, "ROUGE_L": 0.2853801169590643, "CIDEr": 2.8240761338883744e-12, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.16666666666666666, "f": 0.2040816326530612, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a large clock tower standing tall in the middle of a city. The clock tower is prominently visible, with its two clocks clearly visible on the sides. The tower is situated in front of a tall building, which adds to the urban atmosphere of the scene.\n\nIn addition to the clock"}, "573549": {"image_id": 573549, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.15352206215446232, "Bleu_3": 0.09616829261227482, "Bleu_4": 0.0643091979619629, "METEOR": 0.1256742091179924, "ROUGE_L": 0.21095100864553315, "CIDEr": 8.955707667327015e-14, "SPICE": {"All": {"pr": 0.2, "re": 0.23809523809523808, "f": 0.21739130434782608, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image depicts a group of people gathered on a sidewalk near a theater. There are at least six people in the scene, with some standing closer to the theater and others further away. A man is standing near the center of the scene, while a woman is standing closer to the right side of"}, "522941": {"image_id": 522941, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.10987673829748816, "Bleu_4": 1.2961487777593183e-05, "METEOR": 0.22452539644182726, "ROUGE_L": 0.26521739130434785, "CIDEr": 1.24647912059118e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a large elephant with a painted face, standing on a dirt ground. The elephant is surrounded by several people, some of whom are standing close to it, while others are further away. There are at least 12 people in the scene, with some of them possibly interacting"}, "511662": {"image_id": 511662, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.08979301819262463, "Bleu_4": 0.06199874625320648, "METEOR": 0.2185444460448997, "ROUGE_L": 0.22241127856101123, "CIDEr": 5.887215157990854e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3157894736842105, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 1.0, "f": 0.7499999999999999, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a large cruise ship docked at a tropical beach, surrounded by palm trees. The ship is positioned in the middle of the scene, with a few smaller boats scattered around it. Some of these boats are closer to the shore, while others are further away.\n\nIn addition to the"}, "377371": {"image_id": 377371, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.24743582964759447, "Bleu_3": 0.1733654040140036, "Bleu_4": 0.10316499681152426, "METEOR": 0.28140803345572496, "ROUGE_L": 0.28824571766095686, "CIDEr": 5.7927826751961e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a wooden cutting board with a knife on top of it, slicing up some nuts. The nuts are spread across the cutting board, with some of them already chopped and others waiting to be sliced. The cutting board is placed on a dining table, which occupies"}, "170813": {"image_id": 170813, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.09073607102736221, "Bleu_4": 1.1055858618542048e-05, "METEOR": 0.25111556056920453, "ROUGE_L": 0.28355607205113303, "CIDEr": 2.0308257975816145e-11, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.22727272727272727, "f": 0.20408163265306123, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a man sitting on a park bench, working on his laptop. He is positioned in the middle of the bench, with the laptop placed on his lap. The bench is located in a park setting, surrounded by trees and grass. The man appears to be focused on his work, possibly"}, "347210": {"image_id": 347210, "Bleu_1": 0.3199999999936, "Bleu_2": 0.21380899352561972, "Bleu_3": 0.12395961884568825, "Bleu_4": 1.418847468492011e-05, "METEOR": 0.22115606589651648, "ROUGE_L": 0.22732919254658387, "CIDEr": 1.5459881070315771e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a park with a long row of trees, creating a serene and peaceful atmosphere. In the middle of the scene, there is a wooden bench situated on the side of the path, inviting visitors to sit and enjoy the surroundings. The bench is positioned in the shade"}, "175494": {"image_id": 175494, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1010152544531381, "Bleu_3": 0.06010242872773111, "Bleu_4": 8.288569027871298e-06, "METEOR": 0.20954678762510698, "ROUGE_L": 0.23303196230739842, "CIDEr": 8.453391957598611e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2608695652173913, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a black and brown dog lying on a bed, which is covered with a colorful comforter. The dog appears to be resting or sleeping on the bed, possibly enjoying the cozy atmosphere.\n\nIn the room, there is a clock on the wall, and a radio is"}, "265879": {"image_id": 265879, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.18890811128268284, "Bleu_3": 0.15384794941215046, "Bleu_4": 0.12282557003450978, "METEOR": 0.3194545872631655, "ROUGE_L": 0.38496844520940904, "CIDEr": 7.169810837634129e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 40.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.25, "f": 0.34782608695652173, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man sitting at a dining table with a plate of food in front of him. He is wearing a black shirt and has a beard. The table is set with various items, including a wine glass, a fork, a knife, and a bottle. There are also a"}, "433998": {"image_id": 433998, "Bleu_1": 0.4313725490111496, "Bleu_2": 0.278652218402176, "Bleu_3": 0.18506727929166306, "Bleu_4": 0.12748069422146444, "METEOR": 0.21262946036936298, "ROUGE_L": 0.33608815426997246, "CIDEr": 0.08576200018768407, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress, with a pitcher in the middle of throwing a pitch. The pitcher is wearing a baseball uniform and is in the process of releasing the ball. The scene is set on a baseball field, and there are several other people present, likely teammates"}, "286711": {"image_id": 286711, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.25807943616605344, "Bleu_3": 0.1435846767449069, "Bleu_4": 1.6105265992271912e-05, "METEOR": 0.28776874670740304, "ROUGE_L": 0.26571250777846916, "CIDEr": 3.349646601147132e-08, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.3125, "f": 0.30303030303030304, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.8333333333333334, "f": 0.6666666666666667, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a baseball game in progress, with a batter standing at home plate, holding a baseball bat and preparing to swing. The catcher and umpire are positioned behind the batter, ready for the pitch.\n\nThere are numerous people in the scene, including players, coaches, and"}, "552744": {"image_id": 552744, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.24414717515239445, "Bleu_3": 0.13449695158773506, "Bleu_4": 0.08437698860111223, "METEOR": 0.23628329239246154, "ROUGE_L": 0.3216168717047452, "CIDEr": 1.842652646422759e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a young woman with blonde hair, posing for a picture in front of a collection of stuffed animals. She is surrounded by various teddy bears, with some placed on her shoulders and others positioned around her. The teddy bears come in different sizes and colors, creating a play"}, "447279": {"image_id": 447279, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.24094636829087762, "Bleu_3": 0.13155283034473333, "Bleu_4": 1.4607727077509403e-05, "METEOR": 0.24593137151787783, "ROUGE_L": 0.2896142433234421, "CIDEr": 1.0642606016961458e-11, "SPICE": {"All": {"pr": 0.32, "re": 0.34782608695652173, "f": 0.3333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features a group of police officers on horseback, standing in a line on a city street. There are five horses in total, with each horse carrying a police officer. The officers are positioned at various points along the street, with some closer to the foreground and others further back.\n\nIn addition"}, "409217": {"image_id": 409217, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.11289809419085711, "Bleu_4": 1.3447816950952107e-05, "METEOR": 0.20497946125290548, "ROUGE_L": 0.2848565710473649, "CIDEr": 9.333636058163807e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.20689655172413793, "f": 0.21818181818181817, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a white plate filled with a delicious assortment of food. The plate is topped with a generous portion of broccoli, which is spread across the plate in various sizes and positions. Alongside the broccoli, there are several pieces of meat, including beef and ste"}, "28114": {"image_id": 28114, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.17831418028047516, "Bleu_3": 0.1069381840568343, "Bleu_4": 1.2443915680934025e-05, "METEOR": 0.20385336981127378, "ROUGE_L": 0.21863799283154117, "CIDEr": 1.1662551316747525e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a city street with a large orange and black bus driving down the road. The bus is prominently displayed in the scene, occupying a significant portion of the image.\n\nThere are several people visible on the street, with some standing closer to the bus and others further away. A few individuals"}, "33994": {"image_id": 33994, "Bleu_1": 0.3999999999927273, "Bleu_2": 0.31031644541139325, "Bleu_3": 0.15374036339868166, "Bleu_4": 1.6258860001944423e-05, "METEOR": 0.23367221819114795, "ROUGE_L": 0.3015655039824224, "CIDEr": 1.7521398179890788e-11, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.19047619047619047, "f": 0.14814814814814814, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features a large, yellow flower with a green stem, sitting in a green pot. The flower is placed on a table, surrounded by other potted plants. The table appears to be a part of a flower show, as there are several other potted plants in the background, some of which are placed on"}, "278509": {"image_id": 278509, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.2997532459416044, "Bleu_3": 0.18583745582527877, "Bleu_4": 1.9890878941153608e-05, "METEOR": 0.33091533567251163, "ROUGE_L": 0.36478405315614615, "CIDEr": 3.6161129817936983e-07, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.037037037037037035, "f": 0.03773584905660377, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features a black motorcycle parked on the side of a street. The motorcycle is positioned next to a metal fence, and its mirrors are visible, reflecting the surroundings. The motorcycle is parked on the sidewalk, and there is a manhole cover nearby."}, "544975": {"image_id": 544975, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.22303564279534369, "Bleu_3": 0.16177207617209954, "Bleu_4": 0.11647848423555034, "METEOR": 0.27318096453012664, "ROUGE_L": 0.3078864353312303, "CIDEr": 4.086993109784187e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.17647058823529413, "f": 0.15, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a zebra and a giraffe standing together in a zoo enclosure. The zebra is positioned on the left side of the scene, while the giraffe is standing on the right side. They are both looking at the ground, possibly searching for food or observing their surr"}, "158806": {"image_id": 158806, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.08423190681730008, "Bleu_4": 1.0455985518811585e-05, "METEOR": 0.20234115789145404, "ROUGE_L": 0.3190005810575247, "CIDEr": 4.08681308413562e-12, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.35294117647058826, "f": 0.31578947368421056, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a brown dog sitting on the grass, looking at a plate of food with a sandwich on it. The dog appears to be eagerly waiting for the food to be served. A person is standing nearby, possibly preparing to feed the dog or simply observing the scene.\n\nThe plate of"}, "267321": {"image_id": 267321, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.16540015368980918, "Bleu_4": 0.12901292604257925, "METEOR": 0.22478572330462376, "ROUGE_L": 0.35777126099706746, "CIDEr": 1.3395119561630812e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a cozy living room with a couch and a chair placed in the room. The couch is situated on the left side of the room, while the chair is located on the right side. A dining table is also present in the room, with a bowl placed on it."}, "137188": {"image_id": 137188, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.14973958333333334, "ROUGE_L": 0.24469914040114613, "CIDEr": 1.1536849807284163e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a gray cat sitting on a table, looking at the camera. The cat is positioned in the center of the scene, occupying a significant portion of the image.\n\nIn the background, there are several books scattered around, with some placed on the table and others on the floor. A ted"}, "132702": {"image_id": 132702, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.07355956748968669, "Bleu_4": 9.644726515398138e-06, "METEOR": 0.17517012896916656, "ROUGE_L": 0.236281471917366, "CIDEr": 2.018191724701693e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15789473684210525, "f": 0.15, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a close-up of two heads of broccoli, one on the left and the other on the right. The broccoli is placed on a table, and the heads are surrounded by a few leaves. The broccoli appears to be fresh and ready to be cooked or eaten."}, "151075": {"image_id": 151075, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.13204641200979725, "Bleu_4": 0.08505146224405902, "METEOR": 0.2639338635735221, "ROUGE_L": 0.317915309446254, "CIDEr": 2.708574460940036e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.12, "f": 0.13636363636363635, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a man skillfully riding a wave on a surfboard in the ocean. He is wearing a wetsuit, which helps him maintain body temperature and stay comfortable in the water. The surfer is positioned in the center of the scene, with the surfboard beneath him,"}, "516372": {"image_id": 516372, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.2543735095295466, "Bleu_3": 0.19935768324788908, "Bleu_4": 0.13479442271323006, "METEOR": 0.3034346370130784, "ROUGE_L": 0.29204069419509276, "CIDEr": 1.0569634166468606e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a red fire hydrant situated in a grassy area next to a parking lot. The fire hydrant is surrounded by a bush, and there is a red car parked nearby. In the parking lot, there are several cars parked, including a truck on the right side of the"}, "397958": {"image_id": 397958, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.2033063824917087, "Bleu_4": 0.1626739259997693, "METEOR": 0.3358141881337148, "ROUGE_L": 0.361711139347734, "CIDEr": 5.155233291898011e-10, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.391304347826087, "f": 0.36734693877551017, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a black and white cow standing in a grassy field, with its head sticking over a barbed wire fence. The cow appears to be looking at the camera, capturing the viewer's attention. The field is filled with tall grass, creating a natural and serene environment for the"}, "154004": {"image_id": 154004, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.18173629401703337, "Bleu_4": 0.12575592044457554, "METEOR": 0.24018024360804477, "ROUGE_L": 0.26704190118824267, "CIDEr": 6.336099197183164e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image depicts a lively beach scene with a group of people sitting and standing on the sand. There are at least 13 people visible in the scene, some of them sitting on the sand, while others are standing or walking around.\n\nA surfboard can be seen lying on the sand"}, "179599": {"image_id": 179599, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.1740776559525035, "Bleu_3": 0.08299846557886469, "Bleu_4": 1.0240041382038528e-05, "METEOR": 0.2397932474517964, "ROUGE_L": 0.21542083578575633, "CIDEr": 4.1087498511165506e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a baseball field with a baseball player in a blue and grey uniform standing on the pitcher's mound. The player is in the process of throwing a baseball, with his arm fully extended and the ball in the air. The player is wearing a baseball glove, ready to catch the ball"}, "282553": {"image_id": 282553, "Bleu_1": 0.41999999999160004, "Bleu_2": 0.20701966779852365, "Bleu_3": 0.0962928392757433, "Bleu_4": 1.174007928420018e-05, "METEOR": 0.2525519377998401, "ROUGE_L": 0.22938079719227877, "CIDEr": 1.0799647587018316e-09, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.17857142857142858, "f": 0.20408163265306123, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a woman walking on a dirt path in a grassy field, possibly a park or a hillside. She is talking on her cell phone while enjoying the outdoor setting. Another person can be seen in the background, standing further away from the woman.\n\nThere are two handbags"}, "53529": {"image_id": 53529, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.1532823268448488, "Bleu_4": 0.0930697942841302, "METEOR": 0.2922063985947877, "ROUGE_L": 0.3687826325913713, "CIDEr": 4.612872028713846e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.2727272727272727, "f": 0.2553191489361702, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man and a dog sitting in the front seat of a truck. The man is wearing a green hat, and the dog is wearing a green hat as well. They seem to be enjoying their time together in the truck.\n\nIn the background, there are several ballo"}, "13168": {"image_id": 13168, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.14229470733464689, "Bleu_4": 1.5652411276385143e-05, "METEOR": 0.35727707882949444, "ROUGE_L": 0.33577981651376143, "CIDEr": 7.295491699486969e-11, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.35294117647058826, "f": 0.3870967741935484, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image captures a train station at night, with a train traveling down the tracks. The train is positioned towards the center of the scene, and it appears to be a passenger train. The station is illuminated by a bright light, which is located on the left side of the image."}, "528738": {"image_id": 528738, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 0.060526698984524764, "Bleu_4": 8.120218167477751e-06, "METEOR": 0.14934844238900244, "ROUGE_L": 0.1783625730994152, "CIDEr": 7.2112802386909095e-12, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2413793103448276, "f": 0.2545454545454545, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a dining table covered with a variety of fresh vegetables and fruits. There are several carrots scattered across the table, with some placed closer to the center and others towards the edges. A few oranges are also present, with one located near the left side of the table and another towards"}, "368193": {"image_id": 368193, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.11215443081631235, "Bleu_3": 6.230790884875896e-07, "Bleu_4": 1.475756952410161e-09, "METEOR": 0.16632467665235967, "ROUGE_L": 0.21403508771929822, "CIDEr": 1.3085121276221188e-12, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.2727272727272727, "f": 0.32727272727272727, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.5, "f": 0.5185185185185186, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image features a group of people riding horses down a street. There are three horses in total, with one horse positioned closer to the left side of the street, another in the middle, and the third horse on the right side. The riders are spread out along the street, with one person riding"}, "538064": {"image_id": 538064, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.14001867164324747, "Bleu_4": 0.10288402441623214, "METEOR": 0.20247353248794553, "ROUGE_L": 0.28773584905660377, "CIDEr": 7.000044697227019e-11, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.4, "f": 0.3137254901960784, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a statue of a man sitting on a bench, accompanied by two children. The statue is located on a sidewalk, and the man appears to be holding a book. The scene is set in a city environment, with a car parked nearby and a truck further away.\n\nThere are"}, "265636": {"image_id": 265636, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.10698389124379477, "Bleu_4": 0.07144376414760542, "METEOR": 0.2930488724063347, "ROUGE_L": 0.317295188556567, "CIDEr": 8.5775090851714e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.16129032258064516, "f": 0.1818181818181818, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a brown teddy bear sitting on a couch, holding a green card with the words \"Happy Birthday\" written on it. The teddy bear appears to be the main focus of the scene, with the card placed in its arms. The couch is situated in the background, providing"}, "577796": {"image_id": 577796, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.21573723181113055, "Bleu_3": 0.1264855137960998, "Bleu_4": 1.4562215827951557e-05, "METEOR": 0.24141591514172867, "ROUGE_L": 0.23680124223602486, "CIDEr": 6.657790543076058e-10, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.4090909090909091, "f": 0.37500000000000006, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a public restroom with four urinals lined up against a white tile wall. The urinals are mounted on the wall, with each one slightly overlapping the other. The urinals are positioned at different heights, catering to the needs of various users. The overall design of"}, "554046": {"image_id": 554046, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.21852940772098994, "Bleu_3": 0.17070628644307023, "Bleu_4": 0.13348823330220064, "METEOR": 0.24759845402370284, "ROUGE_L": 0.27128335451080055, "CIDEr": 1.1559261315325414e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.16, "f": 0.17777777777777778, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a snowy field with a group of sheep standing in the snow. There are three sheep in total, with one of them wearing a jacket. The sheep are standing close to each other, creating a sense of togetherness in the cold weather.\n\nIn the background, there is"}, "316534": {"image_id": 316534, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.10635890745081387, "Bleu_3": 0.060933937607321825, "Bleu_4": 8.243191945354036e-06, "METEOR": 0.1480093639033208, "ROUGE_L": 0.15365239294710328, "CIDEr": 1.4051939896520795e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.19047619047619047, "f": 0.22857142857142854, "fn": 34.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.29411764705882354, "f": 0.3448275862068966, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a group of cows standing in a grassy field near the ocean. There are five cows in total, with one cow standing closer to the left side of the field, two cows in the middle, and two more cows on the right side. The cows are grazing on the"}, "158950": {"image_id": 158950, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.11375929179665137, "Bleu_3": 0.06415924230513619, "Bleu_4": 8.612596688347549e-06, "METEOR": 0.22062577600308825, "ROUGE_L": 0.21903052064631956, "CIDEr": 5.384677482669566e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16129032258064516, "f": 0.18867924528301885, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a long train traveling down the tracks, with a total of 14 cars visible. The train is moving through a rural countryside, with a lush green field surrounding the tracks. The train is positioned in the middle of the scene, with the first car on the left side"}, "524822": {"image_id": 524822, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.21931085605462405, "Bleu_3": 0.15089125644562476, "Bleu_4": 0.09567579772168915, "METEOR": 0.27584071247315645, "ROUGE_L": 0.32620320855614976, "CIDEr": 2.2229915147538974e-07, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.125, "f": 0.11538461538461538, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a spacious, clean, and well-organized living room with white furniture. The room features a large white couch, a chair, and a dining table. A flat-screen TV is mounted on the wall, and a potted plant is placed near the center of"}, "248111": {"image_id": 248111, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.2670982280194135, "Bleu_3": 0.19413885593563246, "Bleu_4": 2.094780152083705e-05, "METEOR": 0.21785858237073707, "ROUGE_L": 0.2588767859668977, "CIDEr": 1.993485064817906e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.14814814814814814, "f": 0.14035087719298248, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image depicts a small, old-fashioned kitchen with wooden cabinets and a white refrigerator. The kitchen is undergoing a remodeling process, as evidenced by the presence of a paint bucket and a roller on the floor. The refrigerator is located on"}, "409964": {"image_id": 409964, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.21550898337204086, "Bleu_3": 0.16574618012457856, "Bleu_4": 0.11617097758561083, "METEOR": 0.32540202535077306, "ROUGE_L": 0.25894481503941785, "CIDEr": 5.132502770731828e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.18518518518518517, "f": 0.1923076923076923, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man standing on a tennis court, holding a tennis racket and preparing to hit a tennis ball. He is wearing a white shirt and blue shorts, and his hair is short. The tennis ball is in the air, close to the man, as he is about to make contact"}, "337987": {"image_id": 337987, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.19342948582067712, "Bleu_3": 0.16840936916301474, "Bleu_4": 0.13285121864454127, "METEOR": 0.25304184768540766, "ROUGE_L": 0.3010487353485503, "CIDEr": 2.646003925146597e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.12, "f": 0.12244897959183673, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a large bird perched on a tree branch, possibly a parrot or a woodpecker. The bird is sitting on the branch, looking upwards, possibly observing its surroundings or searching for food. The bird's position on the branch is quite prominent, taking up a significant portion"}, "544104": {"image_id": 544104, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1211406307163407, "Bleu_3": 6.559319301112625e-07, "Bleu_4": 1.5337392624752068e-09, "METEOR": 0.1608045214387893, "ROUGE_L": 0.20962199312714777, "CIDEr": 4.909954698328598e-12, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a large body of water with numerous boats of various sizes floating on the surface. Some of the boats are docked, while others are floating freely. The boats are scattered throughout the scene, with some closer to the foreground and others further away.\n\nIn addition to the boats, there are several"}, "121210": {"image_id": 121210, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.12059375557298453, "Bleu_4": 1.4050458184787668e-05, "METEOR": 0.23758231245343936, "ROUGE_L": 0.3028368794326241, "CIDEr": 5.497809126170312e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13333333333333333, "f": 0.163265306122449, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a white plate filled with a delicious meal, including meat, potatoes, and a generous amount of greens. The greens are scattered all over the plate, with some pieces placed on top of the meat and potatoes. The dish appears to be a hearty and nutrit"}, "46551": {"image_id": 46551, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.2507849312830716, "Bleu_3": 0.19360515975287376, "Bleu_4": 0.12988310144706322, "METEOR": 0.1814735735589903, "ROUGE_L": 0.24710648148148148, "CIDEr": 7.309229450464045e-10, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.1, "f": 0.10256410256410256, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a group of people gathered in a room, with one man holding a cell phone and taking a picture of another man. The man being photographed is wearing a black shirt, and the cell phone is being used to capture his image.\n\nThere are a few other people in the room,"}, "535588": {"image_id": 535588, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 9.641854808598065e-07, "Bleu_4": 2.07878766516442e-09, "METEOR": 0.21334654415978657, "ROUGE_L": 0.3190932868352223, "CIDEr": 4.4183490331566954e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man standing next to a bus, holding a bicycle. The bus is parked on the side of the road, and the man appears to be preparing to load his bicycle onto the bus. There are several other bicycles in the scene, with one located near the man"}, "173997": {"image_id": 173997, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.10921336092038615, "Bleu_4": 1.2972311576394404e-05, "METEOR": 0.2260166789344153, "ROUGE_L": 0.23091482649842268, "CIDEr": 1.1806161729851463e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two people sitting on a bench near a fence, overlooking a pond. They are enjoying their time together, possibly having a conversation or simply observing the surroundings. One person is sitting on the left side of the bench, while the other is on the right side."}, "320396": {"image_id": 320396, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.10698389124379477, "Bleu_4": 0.07144376414760542, "METEOR": 0.21815066636711974, "ROUGE_L": 0.2901307966706302, "CIDEr": 4.240865348460504e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a man in a white shirt and blue shorts playing with a white frisbee on a sandy beach. He is in the middle of a run, attempting to catch the frisbee, which is flying in the air towards him. The beach is filled with numerous birds scattered"}, "221282": {"image_id": 221282, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.24331962586375616, "Bleu_3": 0.18737166825210916, "Bleu_4": 0.131498946176216, "METEOR": 0.33450779023056487, "ROUGE_L": 0.3724378543392935, "CIDEr": 1.365825059374872e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.18181818181818182, "f": 0.21428571428571427, "fn": 27.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a woman standing in a kitchen, preparing a pizza on a wooden cutting board. She is using a pizza cutter to slice the pizza into pieces. The kitchen is well-equipped with various items such as a knife, a spoon, and a couple of bottles."}, "25143": {"image_id": 25143, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.09838681467861131, "Bleu_4": 1.19310375004674e-05, "METEOR": 0.1979117710908679, "ROUGE_L": 0.22938079719227877, "CIDEr": 4.0184528289569993e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.3125, "f": 0.24390243902439027, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image is a collage of four different pictures featuring people playing with frisbees in a park. In each picture, there are at least two people engaged in the activity. The frisbees can be seen in various positions, with some in the air and others on the ground.\n\nIn the"}, "52835": {"image_id": 52835, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.07830779525362613, "Bleu_4": 1.0001000249872884e-05, "METEOR": 0.17213321153957672, "ROUGE_L": 0.22889305816135083, "CIDEr": 1.164612144104465e-10, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.15151515151515152, "f": 0.15625, "fn": 28.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3076923076923077, "f": 0.29629629629629634, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features a colorful plastic container filled with a variety of food items. Inside the container, there are several carrots, some of which are placed in a separate compartment. The carrots are arranged in different sections of the container, with some closer to the front and others towards the back."}, "300962": {"image_id": 300962, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.09986796846096184, "Bleu_4": 0.06680779845343547, "METEOR": 0.2518630813142024, "ROUGE_L": 0.2959369314736203, "CIDEr": 1.5061686838025013e-12, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.13793103448275862, "f": 0.17391304347826086, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress, with a young man in a white uniform swinging a baseball bat at a ball. He is in the middle of his swing, attempting to hit the ball. The scene takes place on a baseball field, with a baseball glove visible in the background.\n\nThere"}, "332532": {"image_id": 332532, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1978218215826409, "Bleu_3": 0.09095955978984326, "Bleu_4": 1.1021576473731401e-05, "METEOR": 0.20822178062170923, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.1512671482525872e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white sink situated in the middle of the room. The sink is surrounded by a wooden cabinet and a trash can, which is placed next to the sink. The trash can is black and has a bag in it.\n\nIn addition to the sink and trash can"}, "528261": {"image_id": 528261, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1556997888288053, "Bleu_3": 8.261061662208591e-07, "Bleu_4": 1.9140997885086772e-09, "METEOR": 0.24244713941485194, "ROUGE_L": 0.336783988957902, "CIDEr": 8.746629854012522e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a giraffe standing in a grassy field, with its head down, possibly grazing on the grass. The giraffe is positioned near a wooden fence, which is visible in the background. The scene appears to be a close-up of the giraffe, capturing its"}, "297046": {"image_id": 297046, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.16496470132732644, "Bleu_3": 0.10219130767434717, "Bleu_4": 1.208698453218432e-05, "METEOR": 0.21323574067985276, "ROUGE_L": 0.18908865468071917, "CIDEr": 1.3908135957379572e-10, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.25, "f": 0.2692307692307692, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a busy street scene with a red train traveling down the tracks, passing by a traffic light. The train is positioned on the left side of the street, while the traffic light is located on the right side.\n\nThere are several cars on the street, with one car in the"}, "130839": {"image_id": 130839, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.23431167444696221, "Bleu_3": 0.17760448410096263, "Bleu_4": 0.13679192122845404, "METEOR": 0.2739861898080174, "ROUGE_L": 0.3051907442151345, "CIDEr": 5.687145656949327e-11, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.07142857142857142, "f": 0.08, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a man wearing a suit and tie, standing on a sidewalk with a large black suitcase in his hand. He appears to be smiling and is likely preparing for a trip. Another person is visible in the background, standing further away from the man with the suitcase.\n\nThere"}, "451120": {"image_id": 451120, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.17902871850638163, "Bleu_3": 0.08622339795942073, "Bleu_4": 1.0694730137473664e-05, "METEOR": 0.21169947013046111, "ROUGE_L": 0.22048192771084338, "CIDEr": 1.943027138009857e-11, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.22580645161290322, "f": 0.25925925925925924, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a woman standing in a kitchen, smiling and holding a wooden spoon. She is surrounded by various bowls and jars, which are placed on a dining table. There are at least four bowls on the table, with one near the woman and the others spread out across the table."}, "378134": {"image_id": 378134, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.1730297489554192, "Bleu_4": 0.10416634218776664, "METEOR": 0.21417959121795574, "ROUGE_L": 0.2781758957654723, "CIDEr": 4.651565198060414e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09375, "f": 0.11320754716981132, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a group of people playing a game of frisbee in a grassy field. There are at least 13 people in the scene, with some of them actively participating in the game, while others are watching or waiting for their turn. The frisbee is visible"}, "458953": {"image_id": 458953, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1565560727682472, "Bleu_3": 7.884786608036842e-07, "Bleu_4": 1.7784572824150193e-09, "METEOR": 0.17082294173225016, "ROUGE_L": 0.18780788177339902, "CIDEr": 3.015651458176753e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.23529411764705882, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a lively scene at a park where a large group of people is gathered to fly kites. There are numerous kites of various shapes and sizes soaring in the sky, creating a vibrant and colorful atmosphere. The people are spread out across the park, with some standing closer to"}, "159451": {"image_id": 159451, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.14457494718760727, "Bleu_4": 1.618850011273474e-05, "METEOR": 0.27602099250086226, "ROUGE_L": 0.2848565710473649, "CIDEr": 2.0683838954593226e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.37037037037037035, "f": 0.3508771929824561, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 10.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.75, "f": 0.5714285714285714, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features a large yellow dump truck parked in a lot, possibly near a building. The truck is positioned in the center of the scene, with its front facing the viewer. The truck's front tires are prominently visible, and the truck appears to be empty."}, "294258": {"image_id": 294258, "Bleu_1": 0.37037037036351167, "Bleu_2": 0.2507849312830716, "Bleu_3": 1.0654502541910195e-06, "Bleu_4": 2.206771360165277e-09, "METEOR": 0.23175458112819505, "ROUGE_L": 0.2684268426842684, "CIDEr": 4.2331219907962595e-10, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.2962962962962963, "f": 0.2857142857142857, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.46153846153846156, "f": 0.4444444444444445, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image features a man wearing a suit and tie, with the tie being a striking orange color. The man is standing in front of a building, possibly posing for a picture. The suit appears to be gray, and the man's shirt is white. The combination of the orange tie and the gray"}, "544695": {"image_id": 544695, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.0826422446045352, "Bleu_4": 1.0256732621419825e-05, "METEOR": 0.22013927960237495, "ROUGE_L": 0.2445589919816724, "CIDEr": 4.7273504227381845e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image captures a man playing tennis on a court, holding a tennis racket and preparing to hit a tennis ball. He is wearing a white shirt and appears to be focused on the game. Another person is visible in the scene, standing behind the tennis player, possibly watching the game or waiting for"}, "623": {"image_id": 623, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.16094080478419465, "Bleu_3": 0.08318402702711739, "Bleu_4": 1.0694655186909581e-05, "METEOR": 0.25818125584875457, "ROUGE_L": 0.34163036714374606, "CIDEr": 2.2725839777345574e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a woman standing next to a large brown teddy bear, which is wearing a pink apron. The woman is leaning against the teddy bear, giving it a hug. She is also touching the bear's face with her hand.\n\nIn the background, there is"}, "236690": {"image_id": 236690, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.08546457042801381, "Bleu_4": 1.0678967780508542e-05, "METEOR": 0.22015113273308276, "ROUGE_L": 0.23416506717850286, "CIDEr": 8.654009993307518e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.25, "f": 0.23076923076923075, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a bird flying gracefully through the air, with its wings spread wide. The bird is flying over a body of water, possibly the ocean, as it soars through the sky. The bird's wings are spread out, creating a striking silhouette against the blue sky. The scene captures"}, "382088": {"image_id": 382088, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.15193861113228035, "Bleu_4": 0.12365973155756424, "METEOR": 0.2901030245026067, "ROUGE_L": 0.3202099737532808, "CIDEr": 1.0840429572412624e-09, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.23333333333333334, "f": 0.2916666666666667, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.38461538461538464, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a white horse standing in a fenced-in area, possibly a corral or a pasture. The horse is looking directly at the camera, capturing the viewer's attention. The fence surrounding the horse is made of wood, and the horse appears to be calmly observing its"}, "504711": {"image_id": 504711, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.16658955971162087, "Bleu_3": 0.12276317177256985, "Bleu_4": 0.09576248453510561, "METEOR": 0.2697755878670484, "ROUGE_L": 0.34163036714374606, "CIDEr": 3.052650000762673e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.11538461538461539, "f": 0.12244897959183673, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a delicious chocolate cake with a fork stuck in it, placed on a dining table. The cake is cut into slices, and the fork is positioned on the plate, ready to be used to enjoy the dessert. The cake appears to be a chocolate"}, "495348": {"image_id": 495348, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.22281245492303933, "Bleu_3": 0.10257472592290201, "Bleu_4": 1.2444491215242556e-05, "METEOR": 0.18201527104916673, "ROUGE_L": 0.19551282051282048, "CIDEr": 5.804568434479389e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a group of animals in a dry grass field, including zebras and giraffes. There are three zebras in the scene, with one standing closer to the left side, another in the middle, and the third one on the right side of the field. Two gira"}, "326217": {"image_id": 326217, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.10690449676280989, "Bleu_3": 6.197980942284417e-07, "Bleu_4": 1.5002485403888437e-09, "METEOR": 0.19512574273812194, "ROUGE_L": 0.18429003021148035, "CIDEr": 1.6661424668550842e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.15625, "f": 0.19230769230769232, "fn": 27.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a group of people on a boat filled with various fruits and vegetables. There are at least nine people visible in the scene, with some sitting and others standing. They appear to be enjoying their time on the boat, possibly selling or transporting the produce.\n\nThe boat"}, "59752": {"image_id": 59752, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.08867316884239186, "Bleu_4": 1.0866799910298771e-05, "METEOR": 0.20021110127549033, "ROUGE_L": 0.21908296420447745, "CIDEr": 1.0782737518817369e-12, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.11764705882352941, "f": 0.08888888888888889, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a river filled with numerous small boats of various sizes, all docked along the riverbank. The boats are lined up in a row, creating a picturesque scene. Some of the boats are closer to the foreground, while others are further back in the scene. The river appears to be calm"}, "437393": {"image_id": 437393, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1188177051548479, "Bleu_3": 0.06604735246466957, "Bleu_4": 8.801997699586786e-06, "METEOR": 0.18966060738180485, "ROUGE_L": 0.23416506717850286, "CIDEr": 1.5752985411175603e-11, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.3181818181818182, "f": 0.35000000000000003, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5555555555555556, "f": 0.6250000000000001, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a beautifully crafted white horse statue with a blue mane and a pink flower on its head. The horse statue is adorned with a blue ribbon around its neck, adding a touch of elegance to the overall design. The intricate details of the horse's head and man"}, "279209": {"image_id": 279209, "Bleu_1": 0.41509433961480957, "Bleu_2": 0.2680359137985001, "Bleu_3": 0.11209991078678343, "Bleu_4": 1.2955716888713723e-05, "METEOR": 0.24208828417790676, "ROUGE_L": 0.27216954824316786, "CIDEr": 7.089786298593595e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a snowy landscape with a person wearing a blue jacket and a helmet, standing on skis in the snow. The person appears to be looking at a sign, possibly indicating the direction or distance to a specific location. The skier is surrounded by a forest, with trees covered in snow"}, "202228": {"image_id": 202228, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.23431167444696221, "Bleu_3": 0.13086010274554444, "Bleu_4": 1.4699248546847118e-05, "METEOR": 0.29498171683272134, "ROUGE_L": 0.26116207951070336, "CIDEr": 3.5465134682983405e-10, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.25806451612903225, "f": 0.26666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a man standing in a bathroom, taking a selfie with his cell phone. He is wearing a red and white jacket, and the reflection of the man and his surroundings can be seen in the mirror. The man is positioned in the center of the scene, capturing his"}, "193661": {"image_id": 193661, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.16163173752903065, "Bleu_3": 0.100810174751238, "Bleu_4": 0.06727996774735587, "METEOR": 0.21939972507935437, "ROUGE_L": 0.32707774798927614, "CIDEr": 4.5543814716374943e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a cozy living room with a fireplace as the focal point. The fireplace is surrounded by a brick wall, and there is a chair placed in front of it. The room is decorated with various potted plants, with one plant located near the left side of the room, another on"}, "457060": {"image_id": 457060, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1825741858309521, "Bleu_3": 9.186218331858681e-07, "Bleu_4": 2.072718147350536e-09, "METEOR": 0.15885055715639676, "ROUGE_L": 0.26906112161310647, "CIDEr": 2.7615312208885095e-06, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a giraffe standing in a zoo enclosure, looking directly at the camera. The giraffe is positioned in the center of the scene, with its head prominently visible. The enclosure is surrounded by trees, providing a natural environment for the giraffe.\n\nIn the"}, "390215": {"image_id": 390215, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.15118578920063636, "Bleu_3": 0.09838681467861128, "Bleu_4": 0.06709315438908588, "METEOR": 0.23691001061908043, "ROUGE_L": 0.34099378881987574, "CIDEr": 9.98064861532104e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a white plate filled with a delicious meal consisting of two pieces of meat, likely chicken, and a generous portion of broccoli. The broccoli is spread across the plate, with some pieces placed near the meat and others scattered around the plate. The dish appears to be"}, "579635": {"image_id": 579635, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.24743582964759447, "Bleu_3": 0.1733654040140036, "Bleu_4": 0.10316499681152426, "METEOR": 0.2880991551800112, "ROUGE_L": 0.27354260089686094, "CIDEr": 1.8986445760091796e-09, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.08571428571428572, "f": 0.11538461538461539, "fn": 32.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.1875, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a man skillfully riding a wave on a surfboard in the ocean. He is positioned in the center of the scene, with the surfboard beneath him as he skillfully navigates the wave. The ocean is filled with waves, creating a dynamic and exciting atmosphere for the"}, "251920": {"image_id": 251920, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.13644420572458105, "Bleu_3": 0.07396917719335282, "Bleu_4": 9.738340653916805e-06, "METEOR": 0.22088941503797263, "ROUGE_L": 0.29256594724220625, "CIDEr": 5.199279707549243e-07, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1111111111111111, "f": 0.12244897959183673, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a stove top with two pizzas placed on separate pans. One pizza is positioned on the left side of the stove, while the other is on the right side. A wine glass is placed on the stove, close to the right pizza. The pizzas are"}, "271117": {"image_id": 271117, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.19026059765810294, "Bleu_3": 0.11313211375448105, "Bleu_4": 0.07372935016556142, "METEOR": 0.22089761357672225, "ROUGE_L": 0.28514190317195326, "CIDEr": 2.5978625914848754e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a wooden desk with a vase filled with flowers placed on top of it. The vase is positioned towards the center of the desk, and the flowers are arranged in a visually appealing manner. The desk also has a collection of books scattered around, with some placed near the"}, "11051": {"image_id": 11051, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 8.61888809829365e-07, "Bleu_4": 1.9110767207150235e-09, "METEOR": 0.27820638517089935, "ROUGE_L": 0.314974182444062, "CIDEr": 4.335945041905613e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a young man and a young woman standing next to each other, both wearing formal attire. The young man is wearing a suit and tie, while the young woman is dressed in a dress. The woman is fixing the young man's tie, ensuring it is properly placed."}, "170605": {"image_id": 170605, "Bleu_1": 0.3913043478175804, "Bleu_2": 0.2284160962830436, "Bleu_3": 0.10584416257170214, "Bleu_4": 1.2886443367349682e-05, "METEOR": 0.1753318005431489, "ROUGE_L": 0.29249580436346195, "CIDEr": 0.00032021568934254897, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a snowy field with a large airplane flying overhead, likely a propeller plane. The airplane is positioned towards the center of the scene, with its wings visible as it flies through the sky.\n\nBelow the airplane, there is a group of snowmobiles and"}, "84123": {"image_id": 84123, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.26568446565676707, "Bleu_3": 0.17928009705955203, "Bleu_4": 0.1046739829058619, "METEOR": 0.2465391803986196, "ROUGE_L": 0.3216168717047452, "CIDEr": 6.135081910189553e-09, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.20512820512820512, "f": 0.2580645161290323, "fn": 31.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.4375, "f": 0.5384615384615384, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image depicts a busy street with a green street sign on the side of the road. The sign is pointing towards the Capitol Building and the National Mall, indicating directions for visitors. The street is filled with various vehicles, including cars, trucks, and a bus, all moving in different directions."}, "505899": {"image_id": 505899, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.24077170616624616, "Bleu_3": 0.15811017751473136, "Bleu_4": 0.09791579531640565, "METEOR": 0.27453590378436865, "ROUGE_L": 0.2827814569536423, "CIDEr": 2.7047294180799154e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.10526315789473684, "f": 0.13559322033898305, "fn": 34.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a wooden dining table with a white plate holding two delicious donuts. One of the donuts is a glazed donut, while the other is a chocolate-covered donut. A cup of coffee is placed next to the plate, creating a delightful breakfast or snack"}, "256814": {"image_id": 256814, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.13240928541024866, "Bleu_4": 0.08383287626240972, "METEOR": 0.2585009847174134, "ROUGE_L": 0.30118144947980957, "CIDEr": 6.132345701248326e-10, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a man and a woman sitting in a car, both smiling and enjoying their time together. The man is holding a half-eaten doughnut in his hand, and the woman is sitting next to him. They appear to be posing for a picture, capturing a fun and light"}, "419680": {"image_id": 419680, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.19069251784568234, "Bleu_3": 0.13913760149235183, "Bleu_4": 0.10040883216771884, "METEOR": 0.23412541180812574, "ROUGE_L": 0.23461538461538461, "CIDEr": 5.951001499747901e-13, "SPICE": {"All": {"pr": 0.4375, "re": 0.2413793103448276, "f": 0.3111111111111111, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a street sign on a black pole, indicating that no drinks are allowed on the street. The sign is placed near a building, and there is a person standing in the background, possibly observing the sign or walking by. The scene appears to be set in a city, with the street sign being"}, "519555": {"image_id": 519555, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.12196360807045269, "Bleu_4": 0.07722895417973391, "METEOR": 0.22315227408891988, "ROUGE_L": 0.2853801169590643, "CIDEr": 4.3973571492463e-12, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3333333333333333, "f": 0.2926829268292683, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 1.0, "f": 0.6153846153846153, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a stop sign standing on a dirt road, surrounded by a grassy area. The stop sign is positioned in the middle of the scene, with a pole supporting it. The road appears to be empty, and the surrounding environment is characterized by a mix of grass and trees. The stop sign"}, "354929": {"image_id": 354929, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.26052505285439387, "Bleu_3": 0.15969209259965045, "Bleu_4": 0.09548024812134784, "METEOR": 0.2654369118146974, "ROUGE_L": 0.28175519630484985, "CIDEr": 7.685009590892959e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a group of people riding bicycles down a street at night. There are at least nine people visible in the scene, with some of them riding bikes and others standing or walking alongside the road. The cyclists are spread out along the street, with some closer to the foreground"}, "17379": {"image_id": 17379, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.11429089766174176, "Bleu_3": 0.06350643060633274, "Bleu_4": 8.460008059351496e-06, "METEOR": 0.21409376305673689, "ROUGE_L": 0.24707788450410828, "CIDEr": 5.813661538997915e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.26666666666666666, "f": 0.21621621621621623, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a bathroom with a large mirror on the wall, reflecting a television screen. The television is mounted on the wall above the mirror, providing a unique viewing experience for those using the bathroom. The mirror is positioned in such a way that it captures the reflection of the television screen,"}, "13965": {"image_id": 13965, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.11524490328511487, "Bleu_4": 0.07554258316170323, "METEOR": 0.18732143608718646, "ROUGE_L": 0.23797139141742527, "CIDEr": 1.7830100336934507e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a green and white train parked at a station, with its doors open. The train is positioned on the tracks, and there are several benches placed around the station area. A car is parked nearby, with a handicap sign visible in front of it.\n\nThere are multiple"}, "422836": {"image_id": 422836, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.1200160042655936, "Bleu_4": 0.0774674148263478, "METEOR": 0.2581998173093651, "ROUGE_L": 0.26116207951070336, "CIDEr": 1.209680497509978e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.09090909090909091, "f": 0.12000000000000001, "fn": 30.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man walking down a sidewalk with a suitcase in his hand. He is wearing a black jacket and appears to be carrying the suitcase with ease. The scene takes place in a city setting, with a dining table and chairs visible in the background.\n\nThere are several"}, "513292": {"image_id": 513292, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.13644420572458105, "Bleu_3": 0.07396917719335282, "Bleu_4": 9.738340653916805e-06, "METEOR": 0.24806109032984427, "ROUGE_L": 0.270595690747782, "CIDEr": 9.190978749422788e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.16666666666666666, "f": 0.14634146341463414, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a young boy standing on a sidewalk, holding a skateboard in his hands. He appears to be wearing a red shirt and is looking at the camera. The skateboard is positioned in front of him, with its wheels facing upwards. The scene captures the boy"}, "202444": {"image_id": 202444, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.17205295744403565, "Bleu_3": 0.08697022430943882, "Bleu_4": 1.105769924492212e-05, "METEOR": 0.22006973362679658, "ROUGE_L": 0.2621883826599533, "CIDEr": 2.0133313503614695e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a skateboarding scene with a man skillfully riding a skateboard on a ramp. He is in the middle of performing a trick, while two other people watch him from the sidelines. One of the onlookers is sitting on the ground, while the other is"}, "268541": {"image_id": 268541, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.14754891442234067, "Bleu_3": 0.09486600651870754, "Bleu_4": 0.06428216024395343, "METEOR": 0.2616617944697387, "ROUGE_L": 0.24469914040114613, "CIDEr": 2.3402868113048702e-11, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.4375, "f": 0.3255813953488372, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8571428571428571, "f": 0.631578947368421, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a man wearing a suit and tie, sitting in a chair and holding a cup to his face. He appears to be drinking from the cup, possibly enjoying a beverage or snack. The man's attire suggests that he might be dressed for a formal event or a professional setting"}, "377999": {"image_id": 377999, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.09319532338930898, "Bleu_4": 1.1580903993958116e-05, "METEOR": 0.205868780235467, "ROUGE_L": 0.2675438596491228, "CIDEr": 1.482137010184783e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.1111111111111111, "f": 0.11538461538461538, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a white sailboat floating on a large body of water, possibly a lake or a bay. The sailboat is positioned in the middle of the scene, with a person standing nearby, possibly preparing to sail or just enjoying the view.\n\nIn the foreground, there is"}, "272694": {"image_id": 272694, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.08588393224796005, "Bleu_4": 1.0663135316252687e-05, "METEOR": 0.2513964376889472, "ROUGE_L": 0.33622047244094483, "CIDEr": 2.822394536426353e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.1875, "f": 0.22641509433962265, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a dining table with a cup of coffee and a muffin on a napkin. The cup of coffee is placed on the left side of the table, while the muffin is positioned towards the center. A banana is also present on the table, located on the right side of"}, "137844": {"image_id": 137844, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.21070705493664102, "Bleu_3": 0.10186765009058293, "Bleu_4": 1.2671594061541109e-05, "METEOR": 0.16635740488278383, "ROUGE_L": 0.214185393258427, "CIDEr": 4.675399151450203e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a skateboarder in mid-air, performing a trick on a ramp at a skate park. The skateboarder is the main focus of the scene, with their skateboard clearly visible beneath them.\n\nThere are several other people in the background, likely watching the"}, "374829": {"image_id": 374829, "Bleu_1": 0.41666666665798613, "Bleu_2": 0.3122782901393362, "Bleu_3": 0.20392098255990426, "Bleu_4": 0.11716376196838808, "METEOR": 0.340526478552137, "ROUGE_L": 0.40397350993377484, "CIDEr": 7.881082974882996e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.19230769230769232, "f": 0.1851851851851852, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress, with a batter standing at home plate, holding a baseball bat and preparing to swing. The catcher and umpire are positioned behind the batter, ready for the pitch.\n\nThere are several other people in the scene, including teammates and oppon"}, "21465": {"image_id": 21465, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.08588393224796005, "Bleu_4": 1.0663135316252687e-05, "METEOR": 0.1939922217354753, "ROUGE_L": 0.21131639722863746, "CIDEr": 2.1701874024150125e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.10714285714285714, "f": 0.11111111111111112, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a blue table with various items on it, including a vase, a bowl, and a cup. The vase is placed towards the left side of the table, while the bowl is situated in the middle, and the cup is located on the right side. There are also two spoons"}, "281929": {"image_id": 281929, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.14104731216518007, "Bleu_4": 0.10627177653467242, "METEOR": 0.30473884495967535, "ROUGE_L": 0.34163036714374606, "CIDEr": 1.3072081946970181e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.37037037037037035, "f": 0.3508771929824561, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.7272727272727273, "f": 0.64, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 8.0}}, "caption": "The image features a man wearing a suit and tie, standing next to a bicycle. He is posing for the camera, possibly in front of a house. The bicycle is parked on the sidewalk, and the man appears to be the owner of the bike.\n\nIn the"}, "464814": {"image_id": 464814, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.10846522890718008, "Bleu_3": 0.07830779525362613, "Bleu_4": 0.05623975733742531, "METEOR": 0.17281646295150935, "ROUGE_L": 0.25553560742070613, "CIDEr": 5.351104599340644e-11, "SPICE": {"All": {"pr": 0.2903225806451613, "re": 0.28125, "f": 0.28571428571428575, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 9.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.07142857142857142, "f": 0.07407407407407408, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6153846153846154, "re": 0.5333333333333333, "f": 0.5714285714285715, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}}, "caption": "The image depicts a spacious living room with a large couch situated on the left side of the room. The room is well-lit, with natural light coming in through the windows. There are two chairs in the room, one located near the center and the other closer to the right side."}, "213538": {"image_id": 213538, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.121479758333828, "Bleu_4": 1.3901690971832786e-05, "METEOR": 0.2141636354959617, "ROUGE_L": 0.25831820931639443, "CIDEr": 1.6084831623078945e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.15151515151515152, "f": 0.19230769230769232, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5, "f": 0.588235294117647, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a wooden desk with two computer monitors placed on it. The monitors are positioned side by side, with one being larger and occupying a larger portion of the desk. A keyboard and a mouse are also present on the desk, indicating that the setup is ready for use."}, "461573": {"image_id": 461573, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.0560772154081562, "Bleu_3": 3.9251522966741233e-07, "Bleu_4": 1.0435177484324181e-09, "METEOR": 0.17096845977577188, "ROUGE_L": 0.1783625730994152, "CIDEr": 2.995964958165829e-13, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.20689655172413793, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a park with a white metal bench situated in the middle of a grassy area. The bench is positioned near a tree, providing a pleasant spot for visitors to sit and relax. The bench is made of metal and has a rustic appearance, adding a touch of charm to the park"}, "360629": {"image_id": 360629, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.18650096164396338, "Bleu_3": 0.11649657484397867, "Bleu_4": 0.07786956589908328, "METEOR": 0.2239265916795305, "ROUGE_L": 0.2873485868102288, "CIDEr": 3.861616770555731e-07, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.23529411764705882, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a red tray filled with a variety of food items, including meat, vegetables, and rice. The tray is divided into four compartments, each containing different foods.\n\nIn the top compartment, there is a piece of meat, possibly pork, accompanied by a few pieces"}, "114745": {"image_id": 114745, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.14118624159718107, "Bleu_3": 7.863217694465758e-07, "Bleu_4": 1.867175871883868e-09, "METEOR": 0.1896789953050141, "ROUGE_L": 0.17003484320557494, "CIDEr": 1.2936487609926829e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.26666666666666666, "f": 0.21621621621621623, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a black bear wearing a red shirt, standing on a skateboard and riding it on a ramp. The bear appears to be skillfully balancing on the skateboard, showcasing its talent.\n\nIn the background, there are several cars parked, with one"}, "548878": {"image_id": 548878, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.25226248954908703, "Bleu_3": 0.1948658043741257, "Bleu_4": 0.11520979485025054, "METEOR": 0.2806111636158857, "ROUGE_L": 0.28754208754208754, "CIDEr": 5.4244896365797875e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13333333333333333, "f": 0.16666666666666669, "fn": 26.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a thrilling moment of a man performing a high jump on a skateboard, flying through the air with his skateboard in motion. The skateboarder is in the middle of the jump, showcasing his skill and athleticism.\n\nThe scene takes place in front"}, "385985": {"image_id": 385985, "Bleu_1": 0.48076923075998523, "Bleu_2": 0.32201758380487894, "Bleu_3": 0.18392332439162026, "Bleu_4": 1.8876809197962984e-05, "METEOR": 0.24613548839172383, "ROUGE_L": 0.26293103448275856, "CIDEr": 4.120056352955348e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a man and a woman sitting next to each other, both looking at their cell phones. The woman is wearing black pants with a hole in the knee, while the man is wearing a white shirt. They appear to be engaged in their respective activities on their phones, possibly"}, "289714": {"image_id": 289714, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1825741858309521, "Bleu_3": 0.11573909845238914, "Bleu_4": 0.07794670276022728, "METEOR": 0.23230135539079655, "ROUGE_L": 0.21048999309868874, "CIDEr": 5.523241515801895e-08, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.125, "f": 0.13114754098360656, "fn": 28.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a vintage kitchen with green cabinets and a white countertop. The kitchen is equipped with a sink, an oven, and a microwave. There are several bottles placed on the countertop, with one near the sink and two others closer to the oven."}, "230226": {"image_id": 230226, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.20100756304732487, "Bleu_3": 0.09794571638096426, "Bleu_4": 1.2230008607068681e-05, "METEOR": 0.25760151165730816, "ROUGE_L": 0.28754208754208754, "CIDEr": 2.3708641370115062e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.26666666666666666, "f": 0.2285714285714286, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a bathroom scene with a white basket filled with various toiletries and personal care items. The basket is placed on a counter, and it contains a toothbrush, a toothpaste tube, and a toothbrush holder. There are also multiple bottles of different sizes"}, "319534": {"image_id": 319534, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.22117152024581002, "Bleu_3": 0.18743514831946917, "Bleu_4": 0.1593999690407147, "METEOR": 0.2607111263327114, "ROUGE_L": 0.3748603351955307, "CIDEr": 6.919228737343801e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.20689655172413793, "f": 0.2142857142857143, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a man wearing a white shirt and a red scarf, standing in the doorway of a bus. He is holding onto a metal bar, possibly to maintain his balance or support himself. The bus is filled with passengers, with several people visible in the background, some of them standing and others"}, "427476": {"image_id": 427476, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.2581988897420478, "Bleu_3": 0.18947891465794242, "Bleu_4": 0.1297531338421399, "METEOR": 0.23621027242862253, "ROUGE_L": 0.28247746630281984, "CIDEr": 5.353445047415565e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a young girl standing in a bathroom, posing for a picture. She is wearing a white shirt and is positioned in front of a white toilet. The bathroom appears to be under construction, as there is a sink visible in the background. The girl seems to be enjo"}, "101223": {"image_id": 101223, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.09125318612878565, "Bleu_4": 1.1336958836408244e-05, "METEOR": 0.2259219514541536, "ROUGE_L": 0.26940063091482647, "CIDEr": 3.884559171700161e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image features a large airplane wing with a Southwest Airlines logo on it. The wing is positioned in the foreground, and the airplane is flying over a snow-covered mountain range. The wing is angled slightly, giving a sense of depth to the scene. The mountains below the airplane"}, "123570": {"image_id": 123570, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.10090091909748747, "Bleu_3": 0.05883106992209099, "Bleu_4": 8.028899837277661e-06, "METEOR": 0.1493626376428721, "ROUGE_L": 0.2167219327333018, "CIDEr": 1.5519542513852663e-10, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a man and a woman standing outside a store, both holding umbrellas to protect themselves from the rain. The man is on the left side of the woman, and they are both facing the store. The woman is wearing a black dress, and the man is wearing a suit"}, "368581": {"image_id": 368581, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.22037727300834692, "Bleu_3": 0.17540031406503587, "Bleu_4": 0.13849685756424174, "METEOR": 0.20662398008451766, "ROUGE_L": 0.30367143746110764, "CIDEr": 9.818585729380838e-07, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.20833333333333334, "f": 0.2, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a plastic container filled with a variety of food items, including fruits, vegetables, and a sandwich. The container is divided into three sections, each containing different food items.\n\nIn the top section, there are two pieces of bread, a sandwich, and a few slices"}, "446984": {"image_id": 446984, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.14907119849663567, "Bleu_3": 0.11573909845238914, "Bleu_4": 0.0926947735134645, "METEOR": 0.1635189473009027, "ROUGE_L": 0.24646464646464644, "CIDEr": 1.2086958322955922e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15384615384615385, "f": 0.14814814814814817, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a group of people wearing helmets and riding bicycles. They are gathered around a unique bicycle-powered vehicle, which appears to be a small car or a covered wagon. The cyclists are standing around the vehicle, possibly discussing or preparing for their journey"}, "514668": {"image_id": 514668, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.2047650389408227, "Bleu_3": 0.1591571275450723, "Bleu_4": 0.1240958731067451, "METEOR": 0.2891657005262429, "ROUGE_L": 0.31443298969072164, "CIDEr": 4.066696981820653e-12, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.15625, "f": 0.1724137931034483, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two cats sitting in the back seat of a car, looking out the window. They are positioned close to each other, with one cat on the left side and the other on the right side of the car. The cats appear to be enjoying the view outside the car, possibly observing"}, "532129": {"image_id": 532129, "Bleu_1": 0.333333333325926, "Bleu_2": 0.21320071635081886, "Bleu_3": 1.0186765009063686e-06, "Bleu_4": 2.239829154474316e-09, "METEOR": 0.25557529711490934, "ROUGE_L": 0.25258799171842644, "CIDEr": 7.116513211267793e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a large, freshly baked pizza with a generous amount of cheese on top. The pizza is cut into square pieces, making it easy to serve and enjoy. The cheese is spread evenly across the pizza, creating a mouth-watering appearance. The pizza is"}, "200168": {"image_id": 200168, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.11881770515484788, "Bleu_3": 0.06604735246466956, "Bleu_4": 8.801997699586786e-06, "METEOR": 0.2255702610421905, "ROUGE_L": 0.18654434250764526, "CIDEr": 4.2060091643833196e-10, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.28, "f": 0.2916666666666667, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image captures a snowy ski slope with several people skiing down the hill. A young child is prominently featured in the scene, skiing down the slope while wearing a helmet for safety. The child is surrounded by other skiers, some of whom are closer to the top of the slope"}, "470801": {"image_id": 470801, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.27288841144916204, "Bleu_3": 0.22461398772405183, "Bleu_4": 0.14980695244116735, "METEOR": 0.24262555974475267, "ROUGE_L": 0.31282051282051276, "CIDEr": 3.4041584651206096e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a young girl flying a colorful kite in a blue sky. She is holding onto the kite string, which is attached to the kite, and is enjoying the outdoor activity. The kite is soaring high in the sky, adding a vibrant touch to the scene."}, "138713": {"image_id": 138713, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.30292689857244165, "Bleu_3": 0.2357902695778742, "Bleu_4": 0.1691859964483553, "METEOR": 0.31480049082840245, "ROUGE_L": 0.33577981651376143, "CIDEr": 3.5581520601241096e-09, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.26666666666666666, "f": 0.30769230769230765, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.06666666666666667, "f": 0.08333333333333334, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.6363636363636364, "f": 0.6086956521739131, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image features a group of men playing a game of frisbee in a park. There are four men in total, with one man in the foreground and three others in the background. The frisbee is in the air, and the men are actively engaged in the game, trying to catch"}, "195917": {"image_id": 195917, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.22228757208608238, "Bleu_3": 0.1446278221289709, "Bleu_4": 0.08910017878799979, "METEOR": 0.2567719259088953, "ROUGE_L": 0.26704190118824267, "CIDEr": 5.10947192396377e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.15789473684210525, "f": 0.15384615384615385, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man with a beard and a mustache, brushing his teeth with a green toothbrush. He is focused on the task at hand, and his mouth is open as he brushes his teeth. The man is standing in a room, and there is another person visible in the"}, "145391": {"image_id": 145391, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.23763541030969576, "Bleu_3": 0.13209470492933909, "Bleu_4": 1.4803136625307937e-05, "METEOR": 0.27557865116672625, "ROUGE_L": 0.3122200895713372, "CIDEr": 4.057928791576797e-05, "SPICE": {"All": {"pr": 0.28, "re": 0.22580645161290322, "f": 0.25, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5454545454545454, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a table with a pair of blue scissors and a roll of tape placed on top of a Christmas-themed wrapping paper. The scissors are positioned on the left side of the table, while the tape is located on the right side. The table appears to be a part"}, "459303": {"image_id": 459303, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.13643933968471528, "Bleu_4": 0.08442327695098985, "METEOR": 0.2719938680697056, "ROUGE_L": 0.25341246290801184, "CIDEr": 5.2038150494051095e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.24, "f": 0.2608695652173913, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a black and yellow train parked at a train station. The train is positioned on the tracks, and it appears to be a commuter train, as it is waiting for passengers to board.\n\nThere are several people in the scene, some of them standing near the train, while others are"}, "497334": {"image_id": 497334, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.0804252399656011, "Bleu_4": 1.0203142794069551e-05, "METEOR": 0.19430630319552222, "ROUGE_L": 0.2544392801811465, "CIDEr": 1.9378532077308155e-10, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.13513513513513514, "f": 0.15625, "fn": 32.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a book lying on a bed, with its cover open and facing upwards. The book is placed on a white sheet, which covers the entire bed. The book appears to be a diary, as it is a small, thin, and hand-sized book. The open book is the main"}, "173138": {"image_id": 173138, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.24046440328937668, "Bleu_3": 0.1832277488164094, "Bleu_4": 0.14152536710832955, "METEOR": 0.2766208396864649, "ROUGE_L": 0.3463722397476341, "CIDEr": 5.202895333670082e-10, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.28125, "f": 0.3103448275862069, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.46153846153846156, "f": 0.46153846153846156, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features a young boy in a wetsuit, sitting on a surfboard in the ocean. He is smiling and appears to be enjoying his time in the water. The surfboard is positioned in front of him, and the boy is surrounded by waves, which are crashing around him"}, "404984": {"image_id": 404984, "Bleu_1": 0.387755102032903, "Bleu_2": 0.23779743279793192, "Bleu_3": 0.13400329800768257, "Bleu_4": 0.0850446811827131, "METEOR": 0.24920207514850812, "ROUGE_L": 0.26341764342998153, "CIDEr": 7.955041586281491e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a cozy living room with a large flat-screen TV mounted on the wall. The room features a comfortable couch situated near the TV, and a dining table is located in the foreground. A cat is walking across the room, adding a touch of warmth and liveliness"}, "427965": {"image_id": 427965, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.2241462600435509, "Bleu_3": 0.1659167006317322, "Bleu_4": 0.10151973215516544, "METEOR": 0.2422321488589985, "ROUGE_L": 0.31565329883570503, "CIDEr": 1.7952682894422303e-08, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3888888888888889, "f": 0.35000000000000003, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a cozy living room with a television on a wooden stand. The room is furnished with a couch, a chair, and a dining table. There are several decorative items in the room, including a pink flamingo, a couple of potted plants, and a"}, "445834": {"image_id": 445834, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.08401680504001675, "Bleu_3": 5.242181839106549e-07, "Bleu_4": 1.3162056532389086e-09, "METEOR": 0.16620677340425902, "ROUGE_L": 0.14294083186877565, "CIDEr": 5.966172458107515e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2, "f": 0.20408163265306126, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a white and black bus with its door open, allowing passengers to board or disembark. There are several people in the scene, with some standing near the bus and others walking around. One man is standing close to the bus, possibly waiting to board or just having disembarked."}, "386958": {"image_id": 386958, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.10846522890718008, "Bleu_3": 0.06215293828145826, "Bleu_4": 8.409805259069613e-06, "METEOR": 0.18774310051359405, "ROUGE_L": 0.22889305816135083, "CIDEr": 8.801324648832413e-10, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a red and yellow fire hydrant situated on a sidewalk. The fire hydrant is positioned next to a yellow pole, which is connected to a hose. The hose is stretched out, extending from the pole and reaching towards the fire hydrant. The scene appears to be set in"}, "306135": {"image_id": 306135, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.29926959344210463, "Bleu_3": 0.23822084906883004, "Bleu_4": 0.17957628718301308, "METEOR": 0.32397191433991346, "ROUGE_L": 0.30842696629213484, "CIDEr": 3.0215402573896625e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.15625, "f": 0.17857142857142858, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man walking up a set of stairs in front of a statue of a horse and rider. The man is wearing a red shirt and appears to be the main focus of the scene. There are several other people in the background, some of them walking up the stairs as well."}, "335839": {"image_id": 335839, "Bleu_1": 0.387755102032903, "Bleu_2": 0.3113499245321993, "Bleu_3": 0.2176656469528817, "Bleu_4": 2.1759702885994826e-05, "METEOR": 0.27298373632226514, "ROUGE_L": 0.33132166566083276, "CIDEr": 3.4386929540509196e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.11538461538461539, "f": 0.15384615384615388, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a man standing on a sidewalk in front of a building with graffiti on its side. The man is wearing a black jacket and appears to be posing for the camera. He is positioned near a red fire hydrant, which is located on the sidewalk.\n\nThe"}, "190313": {"image_id": 190313, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.13633224439757732, "Bleu_4": 0.11160412118083013, "METEOR": 0.2535697899395891, "ROUGE_L": 0.28175519630484985, "CIDEr": 6.03776373822881e-10, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.35, "f": 0.3043478260869565, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features an older woman sitting on a bench outside a store. She is wearing a black coat and appears to be enjoying her time. The bench is located near a brick wall, and the woman is positioned in the middle of the scene.\n\nIn the background, there are several people"}, "85328": {"image_id": 85328, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1398811515077607, "Bleu_3": 0.07219465044848075, "Bleu_4": 9.268004147205411e-06, "METEOR": 0.1748485431299444, "ROUGE_L": 0.21180555555555555, "CIDEr": 1.4988154020691483e-12, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.4090909090909091, "f": 0.37500000000000006, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.3333333333333333, "f": 0.16666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a train station with a green and yellow train parked on the tracks. The train is positioned near the platform, where several people are waiting to board or disembark. There are at least 11 people visible in the scene, some of them standing closer to the train while others are further"}, "104002": {"image_id": 104002, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 6.880010617668035e-07, "Bleu_4": 1.631181823642126e-09, "METEOR": 0.1586449965915207, "ROUGE_L": 0.16126900198281557, "CIDEr": 1.0955087613594048e-10, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a large herd of cows grazing in a lush green field. There are at least 14 cows scattered throughout the field, with some closer to the foreground and others further in the background. The cows are of various sizes and are spread out across the field,"}, "37389": {"image_id": 37389, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.12148343141342467, "Bleu_4": 0.07738295086492801, "METEOR": 0.2486501904093386, "ROUGE_L": 0.25707405177603854, "CIDEr": 3.320291412382862e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a large clock tower with a green and white color scheme, standing tall in the middle of a city. The clock is prominently displayed on the tower, making it a focal point in the scene. The sky above the clock tower is blue, creating a pleasant atmosphere.\n\nIn the surrounding"}, "383594": {"image_id": 383594, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.22303564279534369, "Bleu_3": 0.1469796854787658, "Bleu_4": 1.6208899419375086e-05, "METEOR": 0.2213808483376468, "ROUGE_L": 0.33443564528761643, "CIDEr": 1.35438975323251e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a delicious meal on a dining table, consisting of a plate with a sandwich cut in half and a side of pickles. The sandwich appears to be a chicken sandwich, and the pickles are placed on the side of the plate.\n\nIn addition to the main"}, "319696": {"image_id": 319696, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.12948675740619273, "Bleu_4": 0.08288569027871298, "METEOR": 0.19948357826707233, "ROUGE_L": 0.20158625247851947, "CIDEr": 9.472761276586558e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.24, "f": 0.2608695652173913, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a red microwave sitting on a countertop, with a clock on the front of it. The microwave is positioned next to a bottle, which is placed on the countertop as well. The bottle appears to be a wine bottle, and it is located to the right"}, "318911": {"image_id": 318911, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 8.61888809829365e-07, "Bleu_4": 1.9110767207150235e-09, "METEOR": 0.20148483928338703, "ROUGE_L": 0.22889305816135083, "CIDEr": 8.017744991010522e-11, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.4444444444444444, "f": 0.3555555555555555, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.8333333333333334, "f": 0.5555555555555556, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a large group of sheep gathered together in a fenced-in area. There are at least 13 sheep visible in the scene, with some standing and others sitting or lying down. The sheep are of various sizes and are spread throughout the enclosure.\n\nThe fence is made of wire"}, "455506": {"image_id": 455506, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.19782182158264086, "Bleu_3": 0.11460186406839476, "Bleu_4": 0.07370572412364096, "METEOR": 0.25459540507307743, "ROUGE_L": 0.2853801169590643, "CIDEr": 7.179962956315826e-12, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.2916666666666667, "f": 0.3333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a dog running through a grassy field, carrying a green frisbee in its mouth. The dog appears to be enjoying the outdoor activity and is likely playing fetch with its owner. The scene is set in a park or a similar open space, with trees in the background providing a natural"}, "444631": {"image_id": 444631, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.10496103543446565, "Bleu_4": 1.2660998324356511e-05, "METEOR": 0.29877283451826614, "ROUGE_L": 0.2401574803149606, "CIDEr": 3.772400178029573e-10, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.1724137931034483, "f": 0.16129032258064518, "fn": 24.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image features a beach scene with a person walking on the wet sand, carrying a surfboard. The person is wearing a wetsuit, indicating that they are likely preparing for a surfing session. Another person can be seen in the background, possibly observing the surfer or enjoying the"}, "497014": {"image_id": 497014, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.31017288007984706, "Bleu_3": 0.2679657039491815, "Bleu_4": 0.21624134910133433, "METEOR": 0.285869269036463, "ROUGE_L": 0.4268221574344023, "CIDEr": 3.2498208607448976e-07, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.09523809523809523, "f": 0.10526315789473684, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a brown dog in a backyard, jumping up in the air to catch a blue frisbee. The dog is focused on the frisbee, which is positioned slightly above its head. The scene is set in a fenced-in area, providing a safe environment for the"}, "502749": {"image_id": 502749, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.2823298512804342, "Bleu_3": 0.2215154679865911, "Bleu_4": 0.16594579152403277, "METEOR": 0.23729396113367138, "ROUGE_L": 0.32317880794701986, "CIDEr": 1.0108290844647274e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a large, well-lit kitchen with a center island. The kitchen is decorated for Christmas, with a bowl of oranges placed on the island, and a potted plant nearby. The countertop is adorned with a red placemat, adding a festive touch to the space"}, "230593": {"image_id": 230593, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.1278888396607359, "Bleu_4": 0.08042331753470428, "METEOR": 0.20413270192097877, "ROUGE_L": 0.25341246290801184, "CIDEr": 9.67651152965967e-12, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.19230769230769232, "f": 0.20833333333333331, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a large group of white birds, likely geese, walking down a path in a park. The birds are spread out along the path, with some closer to the foreground and others further back. There are at least 14 birds visible in the scene, creating a sense of movement and activity."}, "364636": {"image_id": 364636, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.2474358296476976, "Bleu_3": 0.1854462179194681, "Bleu_4": 0.14204283594881859, "METEOR": 0.2858852306511863, "ROUGE_L": 0.34099378881987574, "CIDEr": 1.544328373169837e-09, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2, "f": 0.19607843137254902, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a brown and white dog with a blue collar, standing on a dirt field. The dog appears to be wearing a red collar as well. The dog is looking at the camera, possibly posing for a picture. The dog's tongue is sticking out, adding a playful"}, "288313": {"image_id": 288313, "Bleu_1": 0.3399999999932, "Bleu_2": 0.2634155559173319, "Bleu_3": 0.17948735747185518, "Bleu_4": 1.8728411075322786e-05, "METEOR": 0.24193025294253862, "ROUGE_L": 0.26640878462690293, "CIDEr": 1.767102735325417e-08, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2857142857142857, "f": 0.2727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a dining table with a white tablecloth, set with a variety of food items. There are three plates on the table, each containing different types of food. One plate has a bowl of cereal, another has a plate of vegetables, and the third plate has a sand"}, "384503": {"image_id": 384503, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.15508644003992356, "Bleu_3": 0.11704480209465776, "Bleu_4": 0.07769640590855424, "METEOR": 0.22834099684985776, "ROUGE_L": 0.2501708817498291, "CIDEr": 2.28074943461622e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a green trolley car traveling down a street, passing by a small building. The trolley car is moving along the tracks, and there is a person standing near the tracks, possibly waiting for the trolley to pass.\n\nIn addition to the trolley car, there"}, "190156": {"image_id": 190156, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.23763541030969573, "Bleu_3": 0.15121069009849425, "Bleu_4": 0.10955546868940362, "METEOR": 0.20733122097679002, "ROUGE_L": 0.2799770510613884, "CIDEr": 1.7006796138142147e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09523809523809523, "f": 0.0851063829787234, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image features a black and white cat sitting on a desk, with its head inside a cup. The cup is placed on a saucer, which is positioned on a table. The cat appears to be curiously exploring the contents of the cup.\n\nIn the background, there is a computer monitor"}, "174123": {"image_id": 174123, "Bleu_1": 0.4680851063730195, "Bleu_2": 0.36370994124908435, "Bleu_3": 0.28650306489283267, "Bleu_4": 0.21502986530864976, "METEOR": 0.26903232358504925, "ROUGE_L": 0.36858006042296065, "CIDEr": 6.425268960870098e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13793103448275862, "f": 0.14035087719298248, "fn": 25.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a person holding a fork and a knife, ready to enjoy a delicious pizza. The pizza is placed on a white plate, which is positioned on a dining table. The pizza is topped with cheese and various vegetables, making it a colorful and appet"}, "557239": {"image_id": 557239, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.16658955971162087, "Bleu_3": 8.511922922355495e-07, "Bleu_4": 1.9348958476953622e-09, "METEOR": 0.24886919715385566, "ROUGE_L": 0.2749517063747585, "CIDEr": 9.574559697569004e-09, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2777777777777778, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a cat sitting inside a white toilet bowl, appearing to be relaxed and comfortable. The cat is positioned in the middle of the toilet, with its body occupying a significant portion of the bowl. The cat's fur is visible, giving it a fluffy"}, "184474": {"image_id": 184474, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.12632278815731815, "Bleu_3": 0.08852756586932271, "Bleu_4": 0.0626622181074669, "METEOR": 0.23148232475961916, "ROUGE_L": 0.2459677419354839, "CIDEr": 3.1201177471443056e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.20689655172413793, "f": 0.21052631578947367, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a wooden bench situated in a grassy field, surrounded by a lush green hillside. The bench is positioned on the side of the hill, providing a comfortable spot for visitors to sit and enjoy the scenic view. The grassy area around the bench is well-maint"}, "335099": {"image_id": 335099, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.10167765666209894, "Bleu_3": 0.057283488202355654, "Bleu_4": 7.681104116484306e-06, "METEOR": 0.1472377813477891, "ROUGE_L": 0.13399231191652938, "CIDEr": 2.8670263163795248e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a white dog sitting on a red brick floor, looking through a metal gate. The dog appears to be curious and eager to see what is on the other side of the gate. The gate is decorated with a pattern of circles, adding a unique touch to the scene. The dog's position and"}, "431306": {"image_id": 431306, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.23094010767127685, "Bleu_3": 0.1483569743356351, "Bleu_4": 0.09081773498656424, "METEOR": 0.29787369444872847, "ROUGE_L": 0.3650508677438659, "CIDEr": 9.045393541213241e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.23529411764705882, "f": 0.2162162162162162, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a bathroom with two sinks positioned side by side. A man is standing in front of one of the sinks, taking a picture of himself in the mirror. The reflection of the man and the sinks can be seen clearly in the mirror.\n\nThe bathroom is equipped with"}, "125815": {"image_id": 125815, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.12386606438093092, "Bleu_4": 0.07891603089533021, "METEOR": 0.20611653179522432, "ROUGE_L": 0.2897862232779097, "CIDEr": 1.107318209216339e-09, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.25, "f": 0.2926829268292683, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a red train parked at a train station, with a person standing nearby. The train is positioned on the tracks, occupying a significant portion of the scene. The train station appears to be a busy place, with several people scattered around the area.\n\nIn addition to the train, there"}, "521106": {"image_id": 521106, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 0.10556671919572966, "Bleu_4": 1.2447904522737402e-05, "METEOR": 0.20057147406157436, "ROUGE_L": 0.23669623059866962, "CIDEr": 2.6200137183292775e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.21052631578947367, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a tennis player in action, swinging his racket to hit a tennis ball on a clay court. The player is in the middle of the court, with the ball positioned slightly above and to the right of him. The tennis racket is held in the player's right hand,"}, "508672": {"image_id": 508672, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.25226248954908703, "Bleu_3": 0.1948658043741257, "Bleu_4": 0.1516246170400026, "METEOR": 0.27054704318238454, "ROUGE_L": 0.30219391365888176, "CIDEr": 7.183667537400107e-08, "SPICE": {"All": {"pr": 0.3125, "re": 0.2631578947368421, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8, "f": 0.6153846153846154, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a red bicycle parked next to a flooded road. The bicycle is leaning against a metal fence, which is situated near a gate. The fence appears to be a part of a barrier, possibly to prevent the floodwater from entering the area."}, "221737": {"image_id": 221737, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.1942571724677524, "Bleu_3": 0.13044729210752723, "Bleu_4": 0.081626993367812, "METEOR": 0.23008093436944346, "ROUGE_L": 0.3124644280022766, "CIDEr": 1.8413852554067042e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.391304347826087, "f": 0.3829787234042554, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a rural road with a traffic light hanging above it. The traffic light is currently displaying a red light, indicating that vehicles should stop. The road is surrounded by grass, and there is a bridge visible in the background.\n\nA car is present on the road, waiting for the traffic"}, "345580": {"image_id": 345580, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.11889429373952921, "Bleu_4": 0.07692375025894271, "METEOR": 0.1997800766163387, "ROUGE_L": 0.21997836278398844, "CIDEr": 1.3343801711053105e-10, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.29411764705882354, "f": 0.29411764705882354, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a zebra standing in a grassy field, with its head turned to the side. The zebra is positioned in the center of the scene, and its black and white stripes are clearly visible. The grassy field extends to the edges of the image, creating a natural and ser"}, "46440": {"image_id": 46440, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.26527414191320603, "Bleu_3": 0.1997200836053138, "Bleu_4": 0.15733685553770457, "METEOR": 0.2820439810587313, "ROUGE_L": 0.2872277810476751, "CIDEr": 4.776513589448362e-12, "SPICE": {"All": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image captures a group of young men playing basketball on a court. There are at least six players visible in the scene, with some of them actively engaged in the game. One player is attempting to block a shot, while another player is reaching for the basketball.\n\nThe players are spread out across the"}, "270066": {"image_id": 270066, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.1863906467785316, "Bleu_4": 0.14495567782211874, "METEOR": 0.28143743486290607, "ROUGE_L": 0.32555036691127415, "CIDEr": 3.9106280528514985e-08, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.4117647058823529, "f": 0.39999999999999997, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.8, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a white motorcycle parked on a wet street, with a black leather saddlebag attached to the back. The motorcycle is positioned in front of a van, which is parked further back in the scene. The van has a distinctive green and white color scheme."}, "419867": {"image_id": 419867, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.10767861130247747, "Bleu_4": 1.2699504465465572e-05, "METEOR": 0.2068089443964346, "ROUGE_L": 0.26505276225946617, "CIDEr": 4.003423786621191e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2608695652173913, "f": 0.2727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a grocery store with a large display of bananas. The bananas are arranged in several bunches, with some placed on a shelf and others hanging from a rack. The bananas are displayed in various positions, with some closer to the front and others further back in the store"}, "194724": {"image_id": 194724, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.22861497842409673, "Bleu_3": 0.13773990809586936, "Bleu_4": 1.6088986597188548e-05, "METEOR": 0.22812334941058574, "ROUGE_L": 0.3292847503373819, "CIDEr": 1.733033175345386e-05, "SPICE": {"All": {"pr": 0.28, "re": 0.35, "f": 0.3111111111111111, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a dining table with a delicious pizza placed on a wooden platter. The pizza is topped with olives and cheese, making it a mouth-watering treat. Next to the pizza, there is a bottle of Coca-Cola, adding to the me"}, "236426": {"image_id": 236426, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.29509782884468133, "Bleu_3": 0.18973201303741505, "Bleu_4": 1.9224849995012585e-05, "METEOR": 0.2620958365005901, "ROUGE_L": 0.25707405177603854, "CIDEr": 6.601838372961163e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a tennis match in progress, with a man in a white shirt and white shorts playing tennis on a court. He is in the middle of a swing, holding a tennis racket and preparing to hit the ball. The tennis ball is visible in the air, close to the player."}, "499826": {"image_id": 499826, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.22677868380095453, "Bleu_3": 0.18593942826853238, "Bleu_4": 0.15293931890327764, "METEOR": 0.241925231418399, "ROUGE_L": 0.2692307692307692, "CIDEr": 1.4315077927801604e-07, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.16666666666666666, "f": 0.16216216216216214, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a group of elephants walking down a road, with a woman standing next to them. The elephants are of various sizes, and they are spread out along the road. Some elephants are closer to the woman, while others are further away.\n\nIn addition to the woman and"}, "514904": {"image_id": 514904, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.16026009915056863, "Bleu_4": 0.1375449327243505, "METEOR": 0.334959206746134, "ROUGE_L": 0.3463722397476341, "CIDEr": 6.615730202511747e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.15789473684210525, "f": 0.12244897959183673, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a woman wearing sunglasses and holding two hot dogs in her hands. She is smiling and appears to be enjoying the moment. The hot dogs are wrapped in paper, and she is standing in front of a bus.\n\nIn the background, there are several bicycles park"}, "359864": {"image_id": 359864, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.20604084591910862, "Bleu_3": 0.14932487317800128, "Bleu_4": 1.6064107984430575e-05, "METEOR": 0.29813660150472904, "ROUGE_L": 0.28355607205113303, "CIDEr": 2.8942215012169027e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2857142857142857, "f": 0.24242424242424243, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man wearing a red hat and a red jacket, standing on a boat and looking out over the water. He appears to be enjoying his time on the boat, possibly taking in the view or observing the surroundings. The boat is situated in a body of water, and the"}, "247333": {"image_id": 247333, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.26244532957850014, "Bleu_3": 0.2064003185300409, "Bleu_4": 0.13983014673194485, "METEOR": 0.2791735359145376, "ROUGE_L": 0.3441389809259425, "CIDEr": 5.5662690151393124e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a dining table with a plate of food placed on it. The plate contains a variety of food items, including a salad, meat, and vegetables. There are several carrots scattered across the plate, adding a pop of color to the dish.\n\nIn addition to the plate"}, "54277": {"image_id": 54277, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.19236105428737107, "Bleu_3": 0.0936858341260546, "Bleu_4": 1.1692093421349074e-05, "METEOR": 0.20306147868680155, "ROUGE_L": 0.24416277518345564, "CIDEr": 1.7874105001796688e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11764705882352941, "f": 0.11428571428571428, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a man wearing a blue jacket and green gloves, skiing on a snow-covered slope. He is the main focus of the scene, with his skis visible beneath him. The man appears to be enjoying his time on the snow-covered ground, possibly in a ski"}, "80172": {"image_id": 80172, "Bleu_1": 0.333333333325926, "Bleu_2": 0.24618298195313262, "Bleu_3": 0.1617048149154053, "Bleu_4": 0.100168204947809, "METEOR": 0.2975751145879037, "ROUGE_L": 0.28073635765943455, "CIDEr": 1.7214999862448934e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.20689655172413793, "f": 0.22641509433962265, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a young boy brushing his teeth in a bathroom. He is holding a toothbrush in his mouth, actively cleaning his teeth. The boy is wearing a blue shirt, and there is a toilet visible in the background.\n\nIn addition to the tooth"}, "376959": {"image_id": 376959, "Bleu_1": 0.33928571427965565, "Bleu_2": 0.2356257212561474, "Bleu_3": 0.1455652228495188, "Bleu_4": 0.08734222572913049, "METEOR": 0.2470478582123719, "ROUGE_L": 0.27566171723692706, "CIDEr": 7.590772346831644e-12, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.20689655172413793, "f": 0.23076923076923075, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a young girl sitting at a dining table, holding a cell phone in her hand. She appears to be looking at the phone, possibly engaging in a conversation or playing a game. The table is surrounded by chairs, with one chair visible on the left side of the table and another on the"}, "47055": {"image_id": 47055, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.09125318612878565, "Bleu_4": 1.1336958836408244e-05, "METEOR": 0.17099913994678023, "ROUGE_L": 0.26341764342998153, "CIDEr": 2.5541681402951422e-08, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.1, "f": 0.10714285714285714, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a large bedroom with a bed placed against a wall. The bed is positioned in the center of the room, and it appears to be a king-sized bed. The room is well-lit, with a bright window allowing natural light to enter.\n\nThere are several wine glasses"}, "154816": {"image_id": 154816, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.12166026344082319, "Bleu_4": 0.09306979428413018, "METEOR": 0.2653720344568475, "ROUGE_L": 0.26704190118824267, "CIDEr": 2.7967296355312494e-10, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.3333333333333333, "f": 0.36842105263157887, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.75, "f": 0.75, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image captures a baseball game in progress, with a young boy swinging a baseball bat at a ball. The boy is wearing a red jersey and is in the middle of his swing. There are several other people in the scene, including a catcher and an umpire, who are position"}, "155179": {"image_id": 155179, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.23460952265358181, "Bleu_3": 0.16976425415663207, "Bleu_4": 0.12211781276726974, "METEOR": 0.24417618505933572, "ROUGE_L": 0.3449421057355713, "CIDEr": 7.157052265751669e-09, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.1282051282051282, "f": 0.16666666666666666, "fn": 34.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.3125, "f": 0.39999999999999997, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a large, round, and brown loaf of bread, possibly a brioche, sitting on a white plate. The bread is covered in chocolate, giving it a delicious and appetizing appearance. The plate is placed on a dining table, and the entire scene is set against"}, "328374": {"image_id": 328374, "Bleu_1": 0.3399999999932, "Bleu_2": 0.18626292585916956, "Bleu_3": 0.1130699499343981, "Bleu_4": 1.3242986472209984e-05, "METEOR": 0.24070069274499928, "ROUGE_L": 0.21759809750297268, "CIDEr": 2.0569481430791745e-09, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a group of children gathered on a snow-covered ground, enjoying their time together. There are at least nine children visible in the scene, with some of them sitting on the ground and others standing. They are all wearing skis, which are placed on the ground around them."}, "264919": {"image_id": 264919, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.17807996398101744, "Bleu_3": 9.10598525279523e-07, "Bleu_4": 2.071568233926381e-09, "METEOR": 0.188872175265491, "ROUGE_L": 0.285427807486631, "CIDEr": 1.2042922956676246e-05, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man wearing a unique and eye-catching costume made of balloons. He is standing in a crowd, surrounded by other people. The man's balloon costume is quite elaborate, with a large number of balloons covering his body.\n\nThe man is"}, "48185": {"image_id": 48185, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.14540168172223333, "Bleu_3": 7.954810829018741e-07, "Bleu_4": 1.871873206790386e-09, "METEOR": 0.19339188446362052, "ROUGE_L": 0.31853785900783294, "CIDEr": 9.005511236301532e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts a large, well-lit bathroom with two sinks, each accompanied by a mirror. The sinks are positioned next to each other, creating a spacious and functional layout. The bathroom also features a shower and a toilet, making it a complete and comfortable"}, "43376": {"image_id": 43376, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.12354612406992554, "Bleu_3": 0.08786688777044825, "Bleu_4": 0.06266221810743723, "METEOR": 0.17801828380702353, "ROUGE_L": 0.2781758957654723, "CIDEr": 7.0638738888186125e-09, "SPICE": {"All": {"pr": 0.2903225806451613, "re": 0.3103448275862069, "f": 0.30000000000000004, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a giraffe standing in a lush green forest, with its head and neck prominently visible. The giraffe appears to be looking at the camera, possibly posing for a picture. The scene is set against a backdrop of trees, creating a serene and natural environment."}, "204994": {"image_id": 204994, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.1400280084000279, "Bleu_3": 0.07369045667590099, "Bleu_4": 9.55538360357512e-06, "METEOR": 0.20582924043559414, "ROUGE_L": 0.3216168717047452, "CIDEr": 1.247832348691551e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man standing next to a giraffe, which is leaning over a fence to eat from a man's hand. The man is holding a cup, possibly containing food for the giraffe. The scene takes place in a zoo, as there are other animals in the background, including"}, "309264": {"image_id": 309264, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.21573723181113055, "Bleu_3": 0.1593617613384745, "Bleu_4": 0.11580903993958114, "METEOR": 0.2364274071899593, "ROUGE_L": 0.329136690647482, "CIDEr": 1.0929167880350758e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a large display of bird cages, showcasing a variety of different sizes and styles. The cages are arranged in rows, with some placed on top of each other, creating an organized and visually appealing presentation.\n\nThere are numerous birds visible within the cages, each occupying"}, "356028": {"image_id": 356028, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.24562537538976753, "Bleu_3": 0.1934531933168545, "Bleu_4": 0.15591859227442287, "METEOR": 0.3115806314036881, "ROUGE_L": 0.31452305929533086, "CIDEr": 1.8059380607768666e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.17391304347826086, "f": 0.16326530612244897, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of a large room filled with numerous beds. The room appears to be a dormitory or a hospital ward, as there are at least 14 beds arranged in various positions. Some beds are placed close to each other, while others are more spread out"}, "544794": {"image_id": 544794, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.13204641200979725, "Bleu_4": 0.08505146224405902, "METEOR": 0.30523120178255475, "ROUGE_L": 0.4555071561916615, "CIDEr": 4.837169032432544e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a delicious slice of pizza with various toppings, including mushrooms and sausage, placed on a white plate. The pizza is placed on a dining table, and a person is sitting at the table, likely about to enjoy the meal.\n\nIn addition to the p"}, "264619": {"image_id": 264619, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.06800990296139689, "Bleu_3": 4.684291706302734e-07, "Bleu_4": 1.236288359319698e-09, "METEOR": 0.14270691876220404, "ROUGE_L": 0.22775357809583074, "CIDEr": 1.951595626033422e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a lively scene at the beach, where several people are enjoying themselves by flying kites and surfing. There are at least five kites visible in the sky, with various shapes and sizes, adding a vibrant touch to the atmosphere.\n\nIn addition to the kites"}, "322222": {"image_id": 322222, "Bleu_1": 0.40740740739986286, "Bleu_2": 0.31611725481901065, "Bleu_3": 0.21259564059115535, "Bleu_4": 0.11715834336480174, "METEOR": 0.2723957240150375, "ROUGE_L": 0.29151732377538825, "CIDEr": 1.0695409315712384e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.17857142857142858, "f": 0.1851851851851852, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image captures a tennis match in progress, with a man in a white shirt and shorts swinging a tennis racket at a tennis ball. He is in the middle of a swing, attempting to hit the ball with precision. Another person is visible in the background, likely watching the match or waiting for"}, "359791": {"image_id": 359791, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.22214157542810112, "Bleu_3": 0.15700609186690778, "Bleu_4": 0.11154558241372284, "METEOR": 0.16473287234381137, "ROUGE_L": 0.25341246290801184, "CIDEr": 1.0474838650637576e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a boat with a group of people sitting on it, enjoying the view of the water. There are several chairs placed around the boat, with some of them being orange in color. A few people are sitting on the chairs, while others are standing or walking around the boat.\n\nIn"}, "404635": {"image_id": 404635, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.09672659665842727, "Bleu_4": 1.1657633846364334e-05, "METEOR": 0.16978083650693213, "ROUGE_L": 0.2544696066746126, "CIDEr": 1.4490800608543293e-08, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.1724137931034483, "f": 0.18181818181818185, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.3333333333333333, "f": 0.3703703703703704, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a large herd of elephants in a grassy field, with some of them standing close to each other and others scattered throughout the scene. There are at least 13 elephants visible in the image, with some of them being larger and others smaller, indicating a mix of adult and"}, "364343": {"image_id": 364343, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.16256402218685123, "Bleu_3": 8.569060201339632e-07, "Bleu_4": 1.9792649376644904e-09, "METEOR": 0.17481691075416342, "ROUGE_L": 0.24583557227297154, "CIDEr": 9.153223903494251e-08, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.32, "f": 0.3333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a delicious and colorful fruit salad served on a plate. The fruit salad is topped with a variety of fruits, including bananas, strawberries, kiwi, and apples. The bananas are scattered throughout the plate, with some placed closer to the top and"}, "1573": {"image_id": 1573, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.20520703953870822, "Bleu_3": 0.09709768883661148, "Bleu_4": 1.1942727997804106e-05, "METEOR": 0.26354356161015374, "ROUGE_L": 0.28018372703412076, "CIDEr": 4.397614735930929e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image features a kitchen with an old-fashioned stove top oven, which has a blue pot sitting on top of it. The oven is surrounded by various items, including a teddy bear sitting inside the pot, a cup, and a bowl. There are also several bottles scattered around"}, "174898": {"image_id": 174898, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.07387419460030926, "Bleu_4": 9.42924728285967e-06, "METEOR": 0.23390836558432807, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.720830047805555e-11, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.08823529411764706, "f": 0.09230769230769231, "fn": 31.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a black motorcycle parked on a street, with a tree in the background. The motorcycle is positioned in the middle of the scene, and it appears to be the main focus of the image. The street is empty, and there are no other vehicles or people visible in the scene. The"}, "527580": {"image_id": 527580, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.20520703953870822, "Bleu_3": 0.09709768883661148, "Bleu_4": 1.1942727997804106e-05, "METEOR": 0.17803072456149902, "ROUGE_L": 0.2293233082706767, "CIDEr": 1.280823951318359e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a red and white train traveling down the tracks, passing by a beach area. The train is surrounded by several umbrellas, providing shade for beachgoers. There are at least five umbrellas visible in the scene, with some closer to the train and others further away."}, "522020": {"image_id": 522020, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.0799063530041829, "Bleu_4": 1.0207315006261666e-05, "METEOR": 0.244401075081193, "ROUGE_L": 0.23252858958068615, "CIDEr": 3.2495523032482466e-10, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07407407407407407, "f": 0.08333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a white, fluffy cat sitting on a grassy area, possibly in a backyard. The cat appears to be looking at the camera, possibly with a frown on its face. The cat is positioned in the center of the scene, with its body facing the viewer. The grass"}, "142890": {"image_id": 142890, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.193123630168691, "Bleu_4": 0.1655040988720269, "METEOR": 0.3438641944243816, "ROUGE_L": 0.3433395872420263, "CIDEr": 5.61009802282906e-10, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.10526315789473684, "f": 0.09523809523809525, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image features a black cat sitting in front of a laptop computer. The cat is positioned close to the laptop, with its head and ears visible in the foreground. The laptop screen displays a Google page, capturing the cat's attention.\n\nThe laptop is placed on a desk, and a"}, "503238": {"image_id": 503238, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.12875644765560088, "Bleu_4": 0.10534312981202536, "METEOR": 0.2702056049306694, "ROUGE_L": 0.2872277810476751, "CIDEr": 4.796040596282567e-12, "SPICE": {"All": {"pr": 0.08, "re": 0.07692307692307693, "f": 0.0784313725490196, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a large orange and white bus driving down a city street. The bus is positioned in the middle of the scene, occupying a significant portion of the image. There are several people visible on the street, with some standing closer to the bus and others further away.\n\nIn addition to the bus"}, "522430": {"image_id": 522430, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.12539246564153583, "Bleu_3": 6.711916014355543e-07, "Bleu_4": 1.5604229933011285e-09, "METEOR": 0.1504497411626253, "ROUGE_L": 0.2053872053872054, "CIDEr": 6.192918257552333e-12, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a large white cow with a brown nose standing in a grassy field. The cow appears to be looking directly at the camera, capturing the viewer's attention. Another cow can be seen in the background, partially hidden by the main cow. The scene is set against a sky background, creating"}, "155897": {"image_id": 155897, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.13566654900343936, "Bleu_4": 0.1009954417123122, "METEOR": 0.29292988909959466, "ROUGE_L": 0.27319257837492, "CIDEr": 3.176180967582029e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a person sitting on a bench, holding a sandwich in their hand. The sandwich is cut in half, and the person is in the process of eating it. There are several other people in the scene, some of them sitting on the bench as well.\n\nIn addition to"}, "214494": {"image_id": 214494, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.21438189279304845, "Bleu_3": 0.1288187994554362, "Bleu_4": 0.08446409107172648, "METEOR": 0.22197631653020614, "ROUGE_L": 0.25902335456475584, "CIDEr": 2.1223239165322135e-08, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.23076923076923078, "f": 0.26666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a close-up view of a delicious chocolate cake with a knife stuck in it. The knife is being used to cut the cake, and a person's hand is visible, holding the knife. The cake appears to be a chocolate layer cake"}, "223093": {"image_id": 223093, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.1272154058119733, "Bleu_4": 0.08051110007486427, "METEOR": 0.23362009670960898, "ROUGE_L": 0.22536945812807885, "CIDEr": 4.0781185832683476e-11, "SPICE": {"All": {"pr": 0.1875, "re": 0.24, "f": 0.21052631578947367, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image features a large brick clock tower with a clock on each of its sides. The clocks are positioned at different heights, making the tower visually interesting. The tower is situated in front of a building, and the sky above is filled with clouds, creating a picturesque scene. The clocks on"}, "422706": {"image_id": 422706, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.08788194533129833, "Bleu_4": 1.0848650703059748e-05, "METEOR": 0.21877957443015025, "ROUGE_L": 0.24653579676674361, "CIDEr": 1.6395275556036656e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a boat floating on the water, with a group of people on a cruise ship observing it. The boat is positioned relatively close to the cruise ship, and the people on the ship are watching it with interest.\n\nThere are several people on the cruise ship, with some standing"}, "4011": {"image_id": 4011, "Bleu_1": 0.39999999999200003, "Bleu_2": 0.2996596708997033, "Bleu_3": 0.23570626876212714, "Bleu_4": 0.17003338428901568, "METEOR": 0.37364582824335435, "ROUGE_L": 0.4076549210206561, "CIDEr": 4.791048130689467e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.14285714285714285, "f": 0.13043478260869565, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a woman standing in a kitchen, posing next to a cake that is shaped like a dog. She is wearing an apron and appears to be proud of her creation. The cake is placed on a cake stand, and the woman is standing close to it, showcasing"}, "188824": {"image_id": 188824, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.3407496218415017, "Bleu_3": 0.25165151134840613, "Bleu_4": 0.15889661851698644, "METEOR": 0.31938209341046697, "ROUGE_L": 0.3258160237388724, "CIDEr": 2.9401819173705394e-10, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a gray and white cat sitting on a couch, looking directly at the camera. The cat is positioned near a remote control, which is placed on the couch next to it. The couch occupies most of the background, and the cat appears to be the main focus of the scene."}, "247206": {"image_id": 247206, "Bleu_1": 0.3199999999936, "Bleu_2": 0.21380899352561972, "Bleu_3": 0.12395961884568825, "Bleu_4": 1.418847468492011e-05, "METEOR": 0.26224569193127345, "ROUGE_L": 0.30118144947980957, "CIDEr": 4.4543530993727744e-10, "SPICE": {"All": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a man and a cat playing together on a carpeted floor. The man is lying on the floor, holding a toy in his hand, while the cat is standing nearby, also holding a toy in its mouth. They seem to be enjoying their playtime together.\n\nIn the"}, "430047": {"image_id": 430047, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.17654696589776864, "Bleu_3": 0.1200833155554511, "Bleu_4": 0.0756036974438348, "METEOR": 0.22730053340052148, "ROUGE_L": 0.2576946288473144, "CIDEr": 6.28267682711367e-12, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a living room with a flat screen TV mounted on the wall. The TV is turned on, displaying a picture of a planet. A black coffee table is placed in front of the TV, with a mouse sitting on top of it. The room also contains a bookshelf filled with various books, and"}, "244240": {"image_id": 244240, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.12909944487067912, "Bleu_3": 7.291106321801015e-07, "Bleu_4": 1.7429412599383862e-09, "METEOR": 0.16031294135167196, "ROUGE_L": 0.27941368930768223, "CIDEr": 1.9776169014178583e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.16129032258064516, "f": 0.1818181818181818, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a dirty, old, and broken toilet sitting outside, possibly in a backyard or a similar outdoor area. The toilet is positioned on a concrete slab, and it appears to be in a state of disrepair. The toilet seat is missing, and the"}, "49810": {"image_id": 49810, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.14982983544985165, "Bleu_3": 7.76220525547567e-07, "Bleu_4": 1.7760875805722272e-09, "METEOR": 0.20928311986402512, "ROUGE_L": 0.27128335451080055, "CIDEr": 5.5952352365454e-10, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.0625, "f": 0.05405405405405405, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image features a cat standing on a wooden deck, looking at its reflection in a glass door. The cat appears to be curious about its own image, as it stares intently at the mirror. The deck is situated outside, providing a pleasant outdoor environment for the cat to explore."}, "85914": {"image_id": 85914, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.17205295744403565, "Bleu_3": 8.697022430943884e-07, "Bleu_4": 1.9663678889647942e-09, "METEOR": 0.23208911417282044, "ROUGE_L": 0.31302116741500957, "CIDEr": 4.435582573127489e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.2608695652173913, "f": 0.27906976744186046, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a white plate filled with a delicious meal consisting of meat, potatoes, and broccoli. The plate is topped with a generous amount of broccoli, with some pieces placed on the side and others scattered throughout the dish. The meat appears to be steak, and"}, "442942": {"image_id": 442942, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.17928009705955203, "Bleu_4": 0.12447904522732414, "METEOR": 0.24799146700639724, "ROUGE_L": 0.3042123074182919, "CIDEr": 3.8942862542494366e-11, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.22857142857142856, "f": 0.26229508196721313, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.08333333333333333, "f": 0.08695652173913043, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.4666666666666667, "f": 0.56, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image features a group of people, including both adults and children, riding on a small train in a park. The train is carrying the passengers along a track, providing them with a fun and enjoyable experience. There are several potted plants placed around the park, adding to the pleasant atmosphere."}, "162543": {"image_id": 162543, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.22037727300834692, "Bleu_3": 0.10257472592285453, "Bleu_4": 1.2514603798871615e-05, "METEOR": 0.23015049145642535, "ROUGE_L": 0.26571250777846916, "CIDEr": 1.2185454440589573e-08, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.3684210526315789, "f": 0.3684210526315789, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a group of elephants standing in a dirt field, enclosed by a fence. There are five elephants in total, with one on the left side, two in the middle, and two on the right side of the fence. The elephants are of various sizes,"}, "157352": {"image_id": 157352, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.14544361846700224, "Bleu_3": 0.0822625021119322, "Bleu_4": 1.1075185402506075e-05, "METEOR": 0.17348941868386927, "ROUGE_L": 0.23680124223602486, "CIDEr": 3.4186652630982464e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image captures a skateboarder in action, performing a trick on a ramp at a skate park. The skateboarder is in the middle of the ramp, skillfully balancing on the skateboard. There are several onlookers watching the skateboarder's performance"}, "262810": {"image_id": 262810, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.22522130822577494, "Bleu_3": 0.13210890440524778, "Bleu_4": 1.521710209100825e-05, "METEOR": 0.23015188036370252, "ROUGE_L": 0.3248520710059172, "CIDEr": 2.1039946828731477e-07, "SPICE": {"All": {"pr": 0.35, "re": 0.3333333333333333, "f": 0.3414634146341463, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a beautiful moment of a bride and groom standing together in front of their wedding cake. The couple is embracing each other, and the bride is holding the groom's tie. The cake is placed on a dining table, surrounded by several chairs."}, "498807": {"image_id": 498807, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.2659080117331791, "Bleu_3": 0.17023095994636145, "Bleu_4": 1.851256466469489e-05, "METEOR": 0.3154838574658979, "ROUGE_L": 0.37888198757763975, "CIDEr": 2.8504317128646835e-08, "SPICE": {"All": {"pr": 0.15, "re": 0.14285714285714285, "f": 0.14634146341463414, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a young girl wearing a wetsuit, skillfully riding a pink surfboard on a wave in the ocean. She appears to be enjoying her time in the water, showcasing her surfing abilities. The girl is the main focus of the scene, with the"}, "563605": {"image_id": 563605, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.09672659665842727, "Bleu_4": 0.06555569265748387, "METEOR": 0.1681185557007933, "ROUGE_L": 0.21131639722863746, "CIDEr": 6.915620068739495e-10, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a group of people standing together on a sidewalk, with some of them holding umbrellas. There are three umbrellas in the scene, with one being held by a woman in the center of the group, another by a person on the left side, and the third one by a"}, "162503": {"image_id": 162503, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.35467282364672253, "Bleu_3": 0.28829172306422357, "Bleu_4": 0.2198837646931489, "METEOR": 0.33216681942439696, "ROUGE_L": 0.34269662921348315, "CIDEr": 2.2207256348860374e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.35714285714285715, "f": 0.3225806451612903, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a small owl perched on a tree branch in a forest. The owl is sitting on the branch, surrounded by trees and foliage. The scene is set in a wooded area, with the owl being the main focus of the image."}, "62089": {"image_id": 62089, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.27186953392208474, "Bleu_3": 0.1887018393364794, "Bleu_4": 1.9882225087074857e-05, "METEOR": 0.27854996236381624, "ROUGE_L": 0.3248520710059172, "CIDEr": 1.041853733925734e-06, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.038461538461538464, "f": 0.044444444444444446, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features a young boy wearing a helmet and knee pads, standing on a skateboard in a skate park. He appears to be preparing to ride the skateboard, possibly performing a trick. The skate park is equipped with several benches, one located near the left"}, "340737": {"image_id": 340737, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.1968748077349065, "Bleu_3": 0.09814438977795428, "Bleu_4": 1.239892724075295e-05, "METEOR": 0.2079173631646509, "ROUGE_L": 0.29387474191328283, "CIDEr": 2.524565462846331e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.8333333333333334, "f": 0.5882352941176471, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a small, old-fashioned bathroom with a white bathtub and a sink. The bathtub is situated under a window, allowing natural light to enter the room. The bathroom features a yellow tile design, giving it a warm and cozy atmosphere.\n\nThere"}, "423744": {"image_id": 423744, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1565560727682472, "Bleu_3": 0.11371830097406736, "Bleu_4": 0.08801997699590312, "METEOR": 0.2142585772619865, "ROUGE_L": 0.2544696066746126, "CIDEr": 1.730985422070883e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a workspace with a laptop computer sitting on a wooden stand or a makeshift laptop stand. The laptop is open and appears to be in use. Next to the laptop, there is a monitor, which is also turned on. The workspace is filled with various cables and wires, indicating"}, "343903": {"image_id": 343903, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.13804538956739063, "Bleu_4": 0.10398502497799242, "METEOR": 0.27257326990980757, "ROUGE_L": 0.33363719234275296, "CIDEr": 4.244461487659407e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.11428571428571428, "f": 0.14545454545454545, "fn": 31.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2, "f": 0.26086956521739135, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a dining table with a plate of food and a glass of milk. The plate contains a blueberry pancake, which is the main focus of the meal. The pancake is topped with blueberries, adding a burst of color to the dish. The glass of milk"}, "117786": {"image_id": 117786, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.19402850002522387, "Bleu_3": 0.09158935294477763, "Bleu_4": 1.124795146748506e-05, "METEOR": 0.21246441012177975, "ROUGE_L": 0.27590663112834185, "CIDEr": 4.267488341775923e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07692307692307693, "f": 0.0851063829787234, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features a man standing in front of a large fountain, holding a stick in his hand. He appears to be looking up at the sky, possibly admiring the view or observing something above him. The fountain is located in a courtyard, and there are several other people in the"}, "3693": {"image_id": 3693, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.14679516868082104, "Bleu_3": 0.07408254355300371, "Bleu_4": 9.403425277032118e-06, "METEOR": 0.15698632635827364, "ROUGE_L": 0.17579250720461098, "CIDEr": 1.67350548634023e-12, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.25, "f": 0.2162162162162162, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a group of young people gathered in a room, with some of them standing and others sitting. They are all engaged in using their cell phones, likely texting or browsing the internet. There are at least five cell phones visible in the scene, with some being held by the individuals and others"}, "187852": {"image_id": 187852, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.2018018381949749, "Bleu_3": 0.1346895272889369, "Bleu_4": 0.08403328700354358, "METEOR": 0.2560963590026486, "ROUGE_L": 0.29152506372132536, "CIDEr": 4.7257297636549114e-08, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a group of people gathered in a crowded area, with some of them holding up their cell phones. One man in particular is holding up a cell phone, possibly taking a picture or recording a video. There are several other people in the scene, some of them wearing ties,"}, "414078": {"image_id": 414078, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.12082769166967569, "Bleu_4": 0.07869287296538219, "METEOR": 0.23961279463009164, "ROUGE_L": 0.2663755458515284, "CIDEr": 3.865310440429629e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a large, fluffy cat lying on a blue bedspread, which is placed on a bed. The cat is positioned in the center of the bed, occupying a significant portion of the space. The cat appears to be relaxed and comfortable, enjoying its time on the bed."}, "121716": {"image_id": 121716, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.11805626721734597, "Bleu_3": 7.03675938605906e-07, "Bleu_4": 1.7288741230850778e-09, "METEOR": 0.30062635087628603, "ROUGE_L": 0.25957446808510637, "CIDEr": 5.092793817851474e-07, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.058823529411764705, "f": 0.06451612903225808, "fn": 32.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.125, "f": 0.14814814814814814, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image captures a man skiing down a snow-covered slope, wearing a black jacket and goggles. He is skillfully navigating the snowy terrain, holding onto his ski poles for balance and control. The skier appears to be enjoying the thrill of skiing"}, "327794": {"image_id": 327794, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.18392019594445258, "Bleu_3": 0.09304003187271434, "Bleu_4": 1.1838765649001965e-05, "METEOR": 0.1912627994970485, "ROUGE_L": 0.214185393258427, "CIDEr": 1.4542843212930363e-07, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1, "f": 0.11320754716981132, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a large bowl filled with a delicious stir-fry dish, containing a variety of vegetables such as carrots, peppers, and onions. The carrots are scattered throughout the bowl, with some placed closer to the top and others near the bottom. The pe"}, "143370": {"image_id": 143370, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.16823908657056308, "Bleu_4": 0.1418847468492011, "METEOR": 0.24841986850345668, "ROUGE_L": 0.36715391229578676, "CIDEr": 6.720077833836318e-07, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15789473684210525, "f": 0.18181818181818182, "fn": 32.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.11764705882352941, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a small bathroom with a white toilet situated next to a sink. The sink is positioned under a mirror, which is mounted on the wall above the sink. The bathroom also features a window, allowing natural light to enter the space.\n\nThere are several items scattered around"}, "354202": {"image_id": 354202, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 0.07417848716778727, "Bleu_4": 9.65348251762417e-06, "METEOR": 0.23609451117413136, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.3153231108126407e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.19230769230769232, "f": 0.20833333333333331, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a zoo enclosure with two giraffes standing next to each other. One giraffe is positioned closer to the left side of the enclosure, while the other is on the right side. They are both leaning their heads over a fence, possibly trying to reach for food or"}, "189193": {"image_id": 189193, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.29409860088974943, "Bleu_3": 0.22593051095258676, "Bleu_4": 0.1902656965341923, "METEOR": 0.3643101266943508, "ROUGE_L": 0.3335611756664388, "CIDEr": 4.111049095165149e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10526315789473684, "f": 0.12121212121212122, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a woman riding a skateboard down a street, wearing a hat and a scarf. She is the main focus of the scene, and her skateboard is positioned under her feet.\n\nThe street is lined with parked cars on both sides, with one car closer"}, "561967": {"image_id": 561967, "Bleu_1": 0.33928571427965565, "Bleu_2": 0.20780235364466393, "Bleu_3": 0.09281875130535217, "Bleu_4": 1.1083012517802997e-05, "METEOR": 0.25989223026995345, "ROUGE_L": 0.21682464454976302, "CIDEr": 1.8873750523024028e-13, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a train traveling down the tracks, with a yellow and green engine pulling several cars behind it. The train is moving along the tracks, and the cars are arranged in a line behind the engine. The train appears to be traveling through a rural area, with trees visible in the background. The scene"}, "404071": {"image_id": 404071, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.13284223282838353, "Bleu_3": 0.10261224025520646, "Bleu_4": 0.08191181829040965, "METEOR": 0.24232118106065498, "ROUGE_L": 0.23416506717850286, "CIDEr": 8.26793359191695e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2777777777777778, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a blue and yellow train traveling down the tracks, surrounded by a lush green forest. The train is quite long, stretching across the entire width of the image. The train appears to be moving at a moderate speed, as it travels through the picturesque landscape. The scene captures"}, "251572": {"image_id": 251572, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2455273669893519, "Bleu_3": 0.15782934179488486, "Bleu_4": 0.09668023125951691, "METEOR": 0.2918137360210881, "ROUGE_L": 0.31077147016011636, "CIDEr": 7.149719150664358e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a woman lying on a couch, holding a small brown and white puppy in her arms. The puppy appears to be resting comfortably on the woman's chest, enjoying the warmth and affection. The woman is wearing glasses, and the scene seems to be a"}, "436791": {"image_id": 436791, "Bleu_1": 0.3599999999928, "Bleu_2": 0.3090472521763837, "Bleu_3": 0.21507644363900796, "Bleu_4": 0.12062023507020692, "METEOR": 0.30424819237090794, "ROUGE_L": 0.3317220543806646, "CIDEr": 2.6050253509656306e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a bald man wearing a blue shirt and a black jacket, talking on a cell phone. He is holding the phone to his ear, engaged in a conversation. The man is also wearing a backpack, which is visible on his back.\n\nIn the background, there is a"}, "319257": {"image_id": 319257, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2015901948875348, "Bleu_3": 0.11680628450365417, "Bleu_4": 1.336155969068709e-05, "METEOR": 0.18365098048783124, "ROUGE_L": 0.21721068249258166, "CIDEr": 4.418294993002831e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a cat sitting in a sunlit window, surrounded by a potted plant. The cat is positioned in the center of the scene, with its head partially hidden behind the plant. The plant has a few leaves, and the cat appears to be enjoying the warmth and comfort of the sunlight"}, "279437": {"image_id": 279437, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.17496355305240635, "Bleu_3": 0.08607650943307255, "Bleu_4": 1.0792921564506728e-05, "METEOR": 0.22071508745901175, "ROUGE_L": 0.34777651083238315, "CIDEr": 2.7177999759224216e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a bedroom with a large bed situated in the center of the room. The bed is covered with a floral print quilt, and it is adorned with a vase placed on the footboard. The bedroom also has a window, which allows natural light to enter the space."}, "175718": {"image_id": 175718, "Bleu_1": 0.42222222221283956, "Bleu_2": 0.2938769068160246, "Bleu_3": 0.21574669736327218, "Bleu_4": 0.14787790645525567, "METEOR": 0.28117141375359483, "ROUGE_L": 0.38730158730158726, "CIDEr": 1.7279884702341401e-07, "SPICE": {"All": {"pr": 0.4074074074074074, "re": 0.4230769230769231, "f": 0.4150943396226415, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 11.0}, "Relation": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features a delicious pizza sitting on a wooden cutting board on a dining table. The pizza is topped with cheese and olives, making it a mouth-watering treat. Next to the pizza, there is a bottle of beer, adding to the overall ambiance of"}, "126671": {"image_id": 126671, "Bleu_1": 0.42222222221283956, "Bleu_2": 0.27706980485831745, "Bleu_3": 0.20744038771161455, "Bleu_4": 0.12074180501546639, "METEOR": 0.269222750010709, "ROUGE_L": 0.3696969696969697, "CIDEr": 1.688196429692315e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2, "f": 0.1923076923076923, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a bathroom with a white toilet situated next to a bathtub. A red and white shower curtain is hanging in the bathroom, adding a pop of color to the space. The shower curtain is open, revealing the bathtub beneath it. The bath"}, "281424": {"image_id": 281424, "Bleu_1": 0.1739130434744802, "Bleu_2": 0.06216698721465449, "Bleu_3": 4.44517628108609e-07, "Bleu_4": 1.1955001291193746e-09, "METEOR": 0.14965986394557823, "ROUGE_L": 0.20691994572591585, "CIDEr": 4.747914935140649e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a large, fluffy cat lying down in a suitcase. The cat is curled up and appears to be sleeping or resting comfortably in the open suitcase. The suitcase is placed on a table, and the cat seems to be enjoying its cozy spot."}, "136": {"image_id": 136, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.22760466886504876, "Bleu_3": 0.17921455348377144, "Bleu_4": 0.1407495776897928, "METEOR": 0.2690505135943335, "ROUGE_L": 0.2781758957654723, "CIDEr": 4.326227632372164e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.24, "f": 0.2553191489361702, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two giraffes in a zoo enclosure, standing next to each other and eating hay. One giraffe is positioned on the left side of the enclosure, while the other is on the right side. The giraffes are standing close to a wall, which is part"}, "71929": {"image_id": 71929, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.08435451529716312, "Bleu_4": 1.057477026987749e-05, "METEOR": 0.18849891009698214, "ROUGE_L": 0.29373996789727125, "CIDEr": 9.841260969154545e-08, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.15625, "f": 0.1694915254237288, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a dining table with two plates of food. One plate is filled with a variety of meat, including shrimp, and the other plate contains rice and vegetables. There are several pieces of shrimp spread across both plates, with some on the rice plate and others on the meat"}, "69293": {"image_id": 69293, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.12148343141342467, "Bleu_4": 0.09202435574847834, "METEOR": 0.22978771599603842, "ROUGE_L": 0.25341246290801184, "CIDEr": 3.3591546344306793e-11, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a small bathroom with a white toilet sitting on a tiled floor. The toilet is positioned in the middle of the room, and there is a sink located on the left side of the bathroom. The sink appears to be made of wood and is accompanied by a mirror above"}, "90040": {"image_id": 90040, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.10412270358781489, "Bleu_4": 0.06859090501309911, "METEOR": 0.17503113904381443, "ROUGE_L": 0.23961840628507297, "CIDEr": 4.036581307089315e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.20833333333333334, "f": 0.22727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a group of boats floating on a river, with a large structure, possibly a temple or a monument, in the background. The boats are scattered throughout the scene, with some closer to the shore and others further away.\n\nIn addition to the boats, there are several people visible in the image,"}, "409646": {"image_id": 409646, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.15354390128889114, "Bleu_4": 0.11025109391030485, "METEOR": 0.2438629327166609, "ROUGE_L": 0.25722891566265055, "CIDEr": 3.953094781910405e-11, "SPICE": {"All": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a black bear walking across a grassy field near a road. The bear is positioned in the middle of the scene, with its back facing the camera. The field is lush and green, providing a natural habitat for the bear.\n\nIn the background, there are trees and a building,"}, "296383": {"image_id": 296383, "Bleu_1": 0.339622641503026, "Bleu_2": 0.24244760629354595, "Bleu_3": 0.151215262126857, "Bleu_4": 0.09119147048897473, "METEOR": 0.23003075678852544, "ROUGE_L": 0.35489233094068756, "CIDEr": 1.988877103228971e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08, "f": 0.08695652173913043, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a cell phone lying on a wooden table, with its screen displaying a green glow. The phone appears to be turned on, and the screen is illuminated, creating a unique visual effect. The phone is positioned in the center of the table, and the wooden surface provides a contrasting back"}, "566672": {"image_id": 566672, "Bleu_1": 0.3399999999932, "Bleu_2": 0.23560603574482045, "Bleu_3": 0.10496484340653167, "Bleu_4": 1.2524443334235165e-05, "METEOR": 0.23164050161309213, "ROUGE_L": 0.21759809750297268, "CIDEr": 9.93543499402317e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13793103448275862, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress, with a batter standing at home plate, holding a baseball bat and preparing to swing. The catcher and the umpire are positioned behind the batter, ready to react to the outcome of the swing.\n\nThere are several other people in the scene,"}, "202865": {"image_id": 202865, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2062842492474154, "Bleu_3": 0.12276317177262669, "Bleu_4": 0.08007518431308377, "METEOR": 0.22649582690075964, "ROUGE_L": 0.270595690747782, "CIDEr": 9.031765859122774e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.1724137931034483, "f": 0.18867924528301888, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a person holding a half-eaten doughnut with a bite taken out of it. The doughnut is placed on a piece of paper, and it appears to be a glazed doughnut with a filling. The person holding the doughnut is standing in front of a grass"}, "226805": {"image_id": 226805, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.20851441405249152, "Bleu_3": 0.12549213105688165, "Bleu_4": 1.4641826518869363e-05, "METEOR": 0.19776940284275582, "ROUGE_L": 0.30295505338962003, "CIDEr": 2.489421449277919e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a spacious and well-lit living room with a modern design. The room features a large couch situated in the center, surrounded by several chairs and a dining table. A television is mounted on the wall, providing entertainment for the occupants.\n\nThe living room"}, "235221": {"image_id": 235221, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.13937882544862468, "Bleu_3": 7.557770425284017e-07, "Bleu_4": 1.769832242009009e-09, "METEOR": 0.16515990873478872, "ROUGE_L": 0.24690644154041863, "CIDEr": 3.029911650912711e-07, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.2727272727272727, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a striking scene of a clock tower with a lightning bolt streaking through the sky above it. The clock is prominently displayed on the tower, and the lightning bolt appears to be illuminating the clock face, creating a dramatic and captivating visual effect. The"}, "499402": {"image_id": 499402, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.15613914506966814, "Bleu_3": 0.10196049127995216, "Bleu_4": 0.06966598967664618, "METEOR": 0.20659719042655905, "ROUGE_L": 0.20497311827956988, "CIDEr": 3.342828202257793e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.125, "f": 0.14035087719298245, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.07142857142857142, "f": 0.07692307692307691, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a large airplane wing with a blue and white color scheme. The wing is positioned in the foreground, and the airplane is flying through a cloudy sky. The wing is adorned with the name \"Southwest\" on the tip, indicating that it belongs to the Southwest"}, "539557": {"image_id": 539557, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.06994057575388038, "Bleu_3": 4.5479779894921654e-07, "Bleu_4": 1.1653898241136168e-09, "METEOR": 0.13892267425957405, "ROUGE_L": 0.14896214896214896, "CIDEr": 9.196061514276551e-14, "SPICE": {"All": {"pr": 0.16, "re": 0.23529411764705882, "f": 0.19047619047619052, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a large white boat with a purple awning, docked in a harbor. The boat is surrounded by several birds, with some flying close to the boat and others perched on the dock. The birds are scattered throughout the scene, with some near the top of the boat and others closer to"}, "109976": {"image_id": 109976, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.09267924750141882, "Bleu_4": 1.1469577394366865e-05, "METEOR": 0.16808545892302812, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.4292897074784314e-09, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.19230769230769232, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a white kitchen with a stove top oven and a microwave above it. The oven is located on the left side of the kitchen, while the microwave is positioned above it. The kitchen also has a sink situated on the left side, close to the oven."}, "210448": {"image_id": 210448, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.18625278992847225, "Bleu_3": 9.169191011400123e-07, "Bleu_4": 2.0459032671035465e-09, "METEOR": 0.20567356685226956, "ROUGE_L": 0.2781758957654723, "CIDEr": 2.1606691193241785e-09, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2777777777777778, "f": 0.2777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a group of zebras standing together in a dirt field. There are at least nine zebras in the scene, with some standing closer to the foreground and others further back. They are all gathered around a fence, possibly in a zoo enclosure.\n\nThe zebras"}, "32724": {"image_id": 32724, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.08377724227293193, "Bleu_4": 1.063298221330347e-05, "METEOR": 0.26066175783755746, "ROUGE_L": 0.24190350297422336, "CIDEr": 4.73433321480411e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.18518518518518517, "f": 0.2127659574468085, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a group of four giraffes running together in a grassy field. They are spread out across the field, with one giraffe on the left side, another in the middle, and two more on the right side. The giraffes appear to be enjoying their time in the"}, "277689": {"image_id": 277689, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.11524490328511487, "Bleu_4": 0.07554258316170323, "METEOR": 0.2574779537634616, "ROUGE_L": 0.26725082146768897, "CIDEr": 4.91906582954511e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a beautifully decorated white cake with red roses on top, placed on a dining table. The cake is surrounded by several wine glasses, with some positioned closer to the cake and others further away. The table setting creates an elegant atmosphere for a special occasion or celebration"}, "167818": {"image_id": 167818, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.10219406022809462, "Bleu_4": 1.1969290421672298e-05, "METEOR": 0.21441602298609772, "ROUGE_L": 0.18340348767288037, "CIDEr": 1.8834953355315536e-12, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.35, "f": 0.29787234042553196, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a desk with a laptop and a desktop computer set up. The laptop is placed on the left side of the desk, while the desktop computer is situated on the right side. Both computers have keyboards and mice, with the laptop's keyboard and mouse located closer to the center of the"}, "445135": {"image_id": 445135, "Bleu_1": 0.423076923068787, "Bleu_2": 0.37553380809211284, "Bleu_3": 0.32347181203482006, "Bleu_4": 0.2636955622185484, "METEOR": 0.36999725895543073, "ROUGE_L": 0.3460291734197731, "CIDEr": 2.8386114482234985e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 8.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.8, "f": 0.47058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a man standing on a tennis court, holding a tennis racket and preparing to hit a tennis ball. He is wearing a black shirt and white shorts, and his stance suggests that he is in the middle of a game. The tennis ball is positioned close to the man,"}, "3145": {"image_id": 3145, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.1756183353427233, "Bleu_3": 0.1065450254190632, "Bleu_4": 0.07013057213023403, "METEOR": 0.2308228269828775, "ROUGE_L": 0.27774615822424586, "CIDEr": 5.964331280698028e-11, "SPICE": {"All": {"pr": 0.44, "re": 0.3333333333333333, "f": 0.37931034482758624, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 11.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6363636363636364, "re": 0.5833333333333334, "f": 0.6086956521739131, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image depicts a cozy living room with a large couch and a chair placed in the center of the room. A dining table is located near the couch, and a coffee table is situated in front of the couch. The room is filled with various items, including a TV on the left"}, "319127": {"image_id": 319127, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.11009637651016171, "Bleu_3": 0.06556808986482039, "Bleu_4": 9.051219068884178e-06, "METEOR": 0.24981508573881242, "ROUGE_L": 0.25902335456475584, "CIDEr": 5.538658298712605e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08, "f": 0.08333333333333333, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image depicts a snowy park with a bench situated in the middle of the scene. The bench is surrounded by a snow-covered field, and there are trees nearby, adding to the wintry atmosphere. The snow-covered ground and trees create a serene and peaceful environment,"}, "380906": {"image_id": 380906, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.22037727300834692, "Bleu_3": 0.10257472592285453, "Bleu_4": 1.2514603798871615e-05, "METEOR": 0.24135685615196134, "ROUGE_L": 0.2781758957654723, "CIDEr": 2.5969564496146194e-08, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.25, "f": 0.22641509433962265, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a wooden bench situated on a brick walkway near the ocean. The bench is adorned with a purple bow, adding a touch of color to the scene. The bench is positioned close to the water, providing a picturesque view for anyone who sits there."}, "524850": {"image_id": 524850, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 0.12339926173807332, "Bleu_4": 0.08038616175390124, "METEOR": 0.16235177300562773, "ROUGE_L": 0.1868872549019608, "CIDEr": 6.59349806949883e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a busy airport scene with a large white airplane parked on the tarmac. The airplane has its door open, and a group of people is walking towards it, likely boarding the plane. There are at least 14 people visible in the scene, some of them"}, "85926": {"image_id": 85926, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.23819653366515028, "Bleu_3": 0.13511835401225591, "Bleu_4": 1.530145153727441e-05, "METEOR": 0.19670570826636585, "ROUGE_L": 0.23461538461538461, "CIDEr": 4.0346521566770385e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a group of brown bears in a grassy field, with two adult bears and two baby bears. The adult bears are standing close to each other, while the baby bears are nearby, possibly nursing. The scene is lively, with several birds flying in the sky,"}, "102355": {"image_id": 102355, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.07250583813278431, "Bleu_4": 9.252921909857738e-06, "METEOR": 0.19409216783183664, "ROUGE_L": 0.21095100864553315, "CIDEr": 1.3406069762180206e-12, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2608695652173913, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a group of people riding in a horse-drawn carriage down a street. There are two horses pulling the carriage, one on the left side and the other on the right side of the street. The people in the carriage are enjoying their ride, with some sitting closer to the front and others"}, "47112": {"image_id": 47112, "Bleu_1": 0.3399999999932, "Bleu_2": 0.24989793834546398, "Bleu_3": 0.17329313830999216, "Bleu_4": 0.10257973212183878, "METEOR": 0.30523543604579695, "ROUGE_L": 0.3317220543806646, "CIDEr": 3.863574920807773e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.17857142857142858, "f": 0.1923076923076923, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a dining table with a large pizza placed on a white plate in the center. The pizza is topped with various ingredients, making it an appetizing sight. There are two wine glasses on the table, one positioned closer to the left side and the other near the"}, "215709": {"image_id": 215709, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.12075231718968205, "Bleu_4": 0.10242161260431776, "METEOR": 0.15160029258242755, "ROUGE_L": 0.19513755598208574, "CIDEr": 2.74528357652485e-11, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bathroom with a sink and a mirror. The sink is situated on the right side of the bathroom, while the mirror is placed above it. The bathroom is decorated with several pictures on the walls, adding a touch of personalization to the space.\n\nThere are two tow"}, "512982": {"image_id": 512982, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.1622185893042646, "Bleu_4": 0.11431164199464497, "METEOR": 0.23765091925182094, "ROUGE_L": 0.24811156304474144, "CIDEr": 1.6213466917628928e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.45454545454545453, "f": 0.5555555555555556, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a bathroom sink with a red vase filled with yellow flowers placed on the counter. The vase is positioned in the center of the sink, adding a touch of color and beauty to the space. The sink is surrounded by a marble countertop, which complements the overall design of the"}, "344633": {"image_id": 344633, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.12632278815731815, "Bleu_3": 7.026437559457351e-07, "Bleu_4": 1.6662810872720655e-09, "METEOR": 0.23234213352369584, "ROUGE_L": 0.1639784946236559, "CIDEr": 4.594545153931373e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features two women riding horses in a dirt field. One woman is riding a brown horse, while the other is riding a black horse. Both women are wearing helmets for safety. The horses are positioned close to each other, with one horse slightly behind the other."}, "555942": {"image_id": 555942, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1010152544531381, "Bleu_3": 0.06010242872773111, "Bleu_4": 8.288569027871298e-06, "METEOR": 0.2598433579952958, "ROUGE_L": 0.23091482649842268, "CIDEr": 1.7467280477112612e-10, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a row of motorcycles parked next to each other on a street. The motorcycles are of various sizes and styles, with one of them being a green motorcycle with a sidecar. The sidecar is attached to the main motorcycle, and it appears to be a vintage"}, "471567": {"image_id": 471567, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1520747661648476, "Bleu_3": 0.08010026144994811, "Bleu_4": 1.0395904495718301e-05, "METEOR": 0.18810003276733211, "ROUGE_L": 0.2970176506390748, "CIDEr": 1.6172156766873684e-08, "SPICE": {"All": {"pr": 0.24, "re": 0.35294117647058826, "f": 0.28571428571428564, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.8333333333333334, "f": 0.5555555555555556, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a giraffe standing in a fenced enclosure, possibly at a zoo or a wildlife park. The giraffe is looking up at the sky, possibly enjoying the sunny day. There are several people in the scene, some of them standing near the fence, observing the"}, "24260": {"image_id": 24260, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.17496355305240635, "Bleu_3": 0.10844960613620269, "Bleu_4": 1.2835019116177698e-05, "METEOR": 0.19829065202806995, "ROUGE_L": 0.23854748603351958, "CIDEr": 9.744319725377806e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.15789473684210525, "f": 0.15384615384615385, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a zebra and a horse standing in a grassy field, both appearing to be enjoying their time together. The zebra is positioned on the left side of the field, while the horse is on the right side.\n\nThere are several people in the scene, with some standing"}, "106508": {"image_id": 106508, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.11459194182328535, "Bleu_3": 6.280739235613542e-07, "Bleu_4": 1.4774310979864886e-09, "METEOR": 0.17982354664975736, "ROUGE_L": 0.2127164942461932, "CIDEr": 3.2040438681655797e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.7, "re": 0.875, "f": 0.7777777777777777, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The scene features a man wearing a safety vest standing on a traffic barrier, possibly directing traffic or monitoring the area. He is positioned near a red and yellow bus, which is driving down the street. There are several cars in the scene, with one car located behind the bus and others scattered around the"}, "311082": {"image_id": 311082, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1456862718139933, "Bleu_3": 0.0761842752874376, "Bleu_4": 9.848600952552255e-06, "METEOR": 0.2079540574859182, "ROUGE_L": 0.2594167679222357, "CIDEr": 2.3916686724371046e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.21428571428571427, "f": 0.21428571428571427, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features two elephants standing in a grassy area, surrounded by trees and bushes. One elephant is positioned on the left side of the scene, while the other is on the right side. They appear to be interacting with each other, possibly playing or engaging in a social activity"}, "312167": {"image_id": 312167, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.11651034560483009, "Bleu_3": 6.475197095245912e-07, "Bleu_4": 1.5342308957715506e-09, "METEOR": 0.18797052708196027, "ROUGE_L": 0.25176886792452824, "CIDEr": 2.3509728932040595e-11, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.35, "f": 0.31818181818181823, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a vase filled with pink flowers, which are arranged in a visually appealing manner. The vase is positioned in the center of the scene, and the flowers are spread out around it, creating a sense of depth and dimension. The pink flowers are the main focus of the image"}, "324937": {"image_id": 324937, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.15075567228549366, "Bleu_3": 0.08085240745770268, "Bleu_4": 1.0591498142223814e-05, "METEOR": 0.21610675046810937, "ROUGE_L": 0.27941368930768223, "CIDEr": 2.3448628849180298e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.19230769230769232, "f": 0.20408163265306123, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a dog lying on a couch, resting its head on the couch's arm. The dog appears to be relaxed and comfortable in its position. The couch is covered with a brown fabric, providing a cozy environment for the dog to rest."}, "65415": {"image_id": 65415, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.07132938798910644, "Bleu_3": 4.835501183413489e-07, "Bleu_4": 1.2660998324350519e-09, "METEOR": 0.2449625408931409, "ROUGE_L": 0.16277518345563707, "CIDEr": 2.41371783459306e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.23809523809523808, "f": 0.24390243902439024, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman wearing a red jacket and skiing down a snow-covered slope. She is smiling and appears to be enjoying her time on the snowy hill. The woman is equipped with skis, which are visible beneath her feet as she glides down the slope."}, "201925": {"image_id": 201925, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.2720396118455874, "Bleu_3": 0.1487169916462173, "Bleu_4": 1.65351170890051e-05, "METEOR": 0.2550252968312399, "ROUGE_L": 0.30367143746110764, "CIDEr": 7.048629981144811e-08, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.3333333333333333, "f": 0.35555555555555557, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a cake baking in an oven, with the oven door open to reveal the cake inside. The cake is placed in a pan, and it appears to be a delicious-looking dessert. The oven is located on the left side of the image, and the"}, "273132": {"image_id": 273132, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.26884737596198516, "Bleu_3": 0.19737610911326042, "Bleu_4": 0.13521939191773047, "METEOR": 0.33990281891910185, "ROUGE_L": 0.3386798272671191, "CIDEr": 2.156761174398338e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1111111111111111, "f": 0.12244897959183673, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features an older woman sitting on a bench, wearing a hat and glasses. She appears to be resting her head on her hand, possibly taking a break or enjoying the surroundings. The bench she is sitting on is located near a fence, and there are several bags"}, "475238": {"image_id": 475238, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.15041420939612582, "Bleu_3": 7.677195064444563e-07, "Bleu_4": 1.7432228564084153e-09, "METEOR": 0.18600661195015505, "ROUGE_L": 0.18780788177339902, "CIDEr": 3.567734536531077e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.24, "f": 0.2553191489361702, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a train traveling down the tracks, with a large locomotive engine pulling several cars behind it. The train is moving through a rural countryside, with trees and a sky visible in the background.\n\nThere are multiple traffic lights in the scene, with one located near the left side of"}, "130527": {"image_id": 130527, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.10496103543446565, "Bleu_4": 1.2660998324356511e-05, "METEOR": 0.2077488287424194, "ROUGE_L": 0.27799479166666663, "CIDEr": 2.978400685420589e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.35294117647058826, "f": 0.2926829268292683, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a herd of cows grazing on a lush green hillside. There are at least 13 cows scattered across the field, with some closer to the foreground and others further away. The cows are enjoying the open space and the abundance of grass to graze on"}, "337563": {"image_id": 337563, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.11808065064918527, "Bleu_4": 0.07734719974142869, "METEOR": 0.2981928066685806, "ROUGE_L": 0.27354260089686094, "CIDEr": 1.1551021383951082e-09, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a woman sitting on a bed, holding a banana in her hand. A young child is sitting next to her, also holding a banana. They seem to be enjoying their time together, possibly eating the bananas.\n\nThe room has a cozy atmosphere, with a chair position"}, "135356": {"image_id": 135356, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1824897193978171, "Bleu_3": 0.09045267833662957, "Bleu_4": 1.1388142795948563e-05, "METEOR": 0.2120223548843066, "ROUGE_L": 0.2781758957654723, "CIDEr": 6.156729082080902e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.29411764705882354, "f": 0.24390243902439027, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man standing in a kitchen, holding a large metal bowl or pot. He appears to be in the process of washing the dish, possibly a pan or a bowl. The kitchen is well-equipped with various appliances, including a refrigerator on the left side"}, "290078": {"image_id": 290078, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.11997212723629987, "Bleu_4": 1.4074957768979279e-05, "METEOR": 0.2791201191748892, "ROUGE_L": 0.27948684382772615, "CIDEr": 7.2884663609965674e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2, "f": 0.20408163265306126, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a white toilet sitting on a sidewalk, positioned next to a building. The toilet appears to be old and possibly broken, as it is missing its seat and lid. The toilet is situated in a cement area, and there are a few potholes nearby."}, "578314": {"image_id": 578314, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.27797972456503717, "Bleu_3": 0.15317783496938975, "Bleu_4": 1.7103485451048818e-05, "METEOR": 0.33294871333834825, "ROUGE_L": 0.4411571334648258, "CIDEr": 5.559472970936627e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a white toilet with a closed lid, situated in a bathroom. The toilet is positioned in the center of the scene, and it appears to be clean and well-maintained. Next to the toilet, there is a small trash can, which is also"}, "174893": {"image_id": 174893, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.1397957424660571, "Bleu_4": 0.08597614289216929, "METEOR": 0.25451183835407204, "ROUGE_L": 0.25341246290801184, "CIDEr": 1.138531242145641e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.21052631578947367, "f": 0.17391304347826086, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a young girl sitting at a dining table, cutting yellow paper with a pair of green scissors. She is focused on her task, which appears to be a craft project. The table occupies most of the scene, and the girl is positioned towards the left side of the table. The"}, "539310": {"image_id": 539310, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.12778110819056318, "Bleu_3": 6.841022856919291e-07, "Bleu_4": 1.5907366237766522e-09, "METEOR": 0.18480986269929323, "ROUGE_L": 0.2256871035940803, "CIDEr": 1.2974859798860547e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image captures a busy street scene with multiple cars and traffic lights. There are several cars in various positions on the street, including a car in the foreground, another car further back, and a few more cars in the middle of the scene. A truck is also visible on the street.\n\nThere"}, "49740": {"image_id": 49740, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.170034010199895, "Bleu_3": 8.504678729142536e-07, "Bleu_4": 1.9122909794589726e-09, "METEOR": 0.19349042809901598, "ROUGE_L": 0.19690122659780504, "CIDEr": 1.2667725124299617e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.12, "f": 0.1276595744680851, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress, with a batter swinging a baseball bat and a catcher wearing a baseball glove, ready to catch the ball. The batter is in the middle of his swing, while the catcher is positioned behind him, prepared to catch the ball.\n\nThere"}, "274549": {"image_id": 274549, "Bleu_1": 0.4347826086862004, "Bleu_2": 0.26006316586278166, "Bleu_3": 0.1664467895387212, "Bleu_4": 1.8096286076349795e-05, "METEOR": 0.27494161876643985, "ROUGE_L": 0.32317880794701986, "CIDEr": 1.3719875929663868e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.18518518518518517, "f": 0.22222222222222224, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image captures a person skiing down a snow-covered slope, surrounded by trees. The skier is wearing an orange jacket and is skiing down the hill with determination. The skis are clearly visible, as they glide through the snow. The scene is set in a forest,"}, "537211": {"image_id": 537211, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.16367090728932468, "Bleu_4": 0.13075424659374268, "METEOR": 0.3512011864085976, "ROUGE_L": 0.35192307692307695, "CIDEr": 3.2187463572639345e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man sitting on a dock, enjoying a hot dog. He is wearing sunglasses and appears to be eating the hot dog with relish. The man is positioned near the center of the scene, with the hot dog in his hand.\n\nIn the background, there"}, "533743": {"image_id": 533743, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.10386373237947197, "Bleu_4": 0.06950845485916396, "METEOR": 0.26391762125538015, "ROUGE_L": 0.26116207951070336, "CIDEr": 5.4447571967736e-11, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features two men playing a video game together in a living room. One man is standing and holding a Wii remote, while the other man is sitting on a couch, also holding a Wii remote. They appear to be enjoying their time together, possibly playing a boxing game.\n\nThe"}, "81812": {"image_id": 81812, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 0.09345903743205189, "Bleu_4": 0.06455672842920546, "METEOR": 0.27019409442084025, "ROUGE_L": 0.27128335451080055, "CIDEr": 3.4873674691058995e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a group of people gathered around a dining table, enjoying a meal together. There are five people in the scene, with one person on the left side, two on the right side, and two more in the background. They are seated on chairs placed around the table."}, "59743": {"image_id": 59743, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.07355956748968669, "Bleu_4": 9.644726515398138e-06, "METEOR": 0.19633737390013267, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.0310363853377373e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.24, "f": 0.2264150943396226, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image captures a group of people enjoying a day at the beach, with three of them holding surfboards. They are standing in the water, preparing to surf the waves. The surfboards are of various sizes and colors, with one being blue, another yellow, and the third one white"}, "356131": {"image_id": 356131, "Bleu_1": 0.38888888888168727, "Bleu_2": 0.2708786851189368, "Bleu_3": 0.17804731863811085, "Bleu_4": 0.12197379410072966, "METEOR": 0.1847690990904969, "ROUGE_L": 0.2738496071829405, "CIDEr": 4.867944692278211e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a small boat with two people on board, sailing across a large body of water. The boat is positioned in the middle of the scene, and the two people are sitting close to each other, enjoying their time together. The boat appears to be a canoe, and the people are likely"}, "311310": {"image_id": 311310, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.23094010767127685, "Bleu_3": 0.12960175458699527, "Bleu_4": 1.4593109846477936e-05, "METEOR": 0.24771444817921048, "ROUGE_L": 0.25831820931639443, "CIDEr": 2.2921531900825325e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a lively scene in a park, where a group of people is enjoying a day outdoors. There are several individuals scattered throughout the park, with some standing closer to the foreground and others further in the background. A young boy is flying a kite, which can be seen"}, "165257": {"image_id": 165257, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 8.845670453991436e-07, "Bleu_4": 2.026992316987076e-09, "METEOR": 0.1737151154419812, "ROUGE_L": 0.32620320855614976, "CIDEr": 8.61128011850576e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1111111111111111, "f": 0.12, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a large kitchen with wooden cabinets and a black countertop. The countertop is cluttered with various items, including a sink, a microwave, and a toaster. There are also several cups and bowls placed on the countertop, as well as a bottle."}, "202658": {"image_id": 202658, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.20603150145092247, "Bleu_3": 0.16413404551419425, "Bleu_4": 0.09848600952552256, "METEOR": 0.2765092110114764, "ROUGE_L": 0.29647630619684084, "CIDEr": 5.325611118027678e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2, "f": 0.17647058823529413, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a Hello Kitty toilet with a pink seat and lid, placed in a room. The toilet is positioned next to a blue suitcase, which is located on the right side of the scene. There is also a chair situated in the background, close to the right edge"}, "50926": {"image_id": 50926, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.17407765595250352, "Bleu_3": 0.11970450131729178, "Bleu_4": 0.07578478544136132, "METEOR": 0.23436851662664288, "ROUGE_L": 0.24610951008645532, "CIDEr": 1.4631042202220808e-13, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2692307692307692, "f": 0.2692307692307692, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a group of people gathered in a field, enjoying a day of flying kites. There are at least five people visible in the scene, with some standing closer to the foreground and others further back. One of the kites is flying high in the sky, while another one is closer to the"}, "514797": {"image_id": 514797, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.128337789581408, "Bleu_3": 0.06952980477333488, "Bleu_4": 9.147827112062708e-06, "METEOR": 0.1908151971183013, "ROUGE_L": 0.18654434250764526, "CIDEr": 3.2172117397652886e-11, "SPICE": {"All": {"pr": 0.28, "re": 0.21875, "f": 0.2456140350877193, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features two men standing on a beach, flying a large blue and black kite together. One man is holding the kite, while the other man is holding the string, helping to control the kite's flight. The kite is soaring high in the sky, creating a lively atmosphere on"}, "258021": {"image_id": 258021, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.09267924750141882, "Bleu_4": 1.1469577394366865e-05, "METEOR": 0.2148622022565229, "ROUGE_L": 0.24190350297422336, "CIDEr": 2.164452592456764e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.21052631578947367, "f": 0.17777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman standing on a sidewalk next to a motorcycle. She is wearing a white shirt and appears to be looking at the motorcycle. The motorcycle is parked on the side of the road, and the woman is positioned close to it.\n\nIn the background, there"}, "203085": {"image_id": 203085, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2526455763146363, "Bleu_3": 0.16086526297444997, "Bleu_4": 0.09807167131318557, "METEOR": 0.2838273146575671, "ROUGE_L": 0.3505747126436782, "CIDEr": 6.334203048742309e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man sitting on a toilet in a room, using a computer. He is focused on the screen, which is located on a desk in front of him. The desk is cluttered with various items, including a keyboard, a mouse, and several books.\n\nIn addition"}, "441442": {"image_id": 441442, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.10386373237947197, "Bleu_4": 0.06950845485916396, "METEOR": 0.20114381788018879, "ROUGE_L": 0.25831820931639443, "CIDEr": 1.1541758860266409e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.125, "f": 0.14035087719298245, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a woman riding a brown horse in a grassy field. She is wearing a black jacket and white pants, and she appears to be enjoying her time on the horse. The horse and rider are positioned in the center of the scene, with the woman sitting comfortably on"}, "494759": {"image_id": 494759, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.1647705109111272, "Bleu_3": 0.12950394190491815, "Bleu_4": 0.10738497851612415, "METEOR": 0.28548385874981563, "ROUGE_L": 0.29397590361445786, "CIDEr": 2.112792688187192e-11, "SPICE": {"All": {"pr": 0.04, "re": 0.041666666666666664, "f": 0.04081632653061224, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image captures a group of people standing on a sandy beach, enjoying a day of kite flying. There are three people in the scene, with one person standing closer to the left side of the image, another person in the middle, and the third person on the right side.\n\nA color"}, "336937": {"image_id": 336937, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.12121830534381622, "Bleu_3": 6.739562828886045e-07, "Bleu_4": 1.59753113202508e-09, "METEOR": 0.131359469216911, "ROUGE_L": 0.18944099378881987, "CIDEr": 4.159277469652144e-11, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.125, "f": 0.1276595744680851, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a large number of white toilets arranged in rows. There are at least 14 toilets visible in the scene, with some placed closer to the foreground and others further back. The toilets are of various sizes and are positioned in a way that creates a visually striking"}, "157155": {"image_id": 157155, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.1887840379814224, "Bleu_3": 0.11108422721947973, "Bleu_4": 1.2804032108828842e-05, "METEOR": 0.1983263411813274, "ROUGE_L": 0.2738496071829405, "CIDEr": 1.9870417107517938e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.23809523809523808, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image captures a night scene with a police officer riding a horse down a street. The horse is positioned in the center of the scene, and the officer is wearing a helmet for safety. There are several people around the horse and the officer, some of them standing closer to the horse, while"}, "243600": {"image_id": 243600, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.2201927530212316, "Bleu_3": 0.15409790041514113, "Bleu_4": 0.10891914013328477, "METEOR": 0.2410762518514036, "ROUGE_L": 0.28126801152737757, "CIDEr": 5.5429710838669274e-12, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.18518518518518517, "f": 0.19999999999999998, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of a library scene, featuring a woman standing in the middle of the room, surrounded by numerous books. She appears to be looking at a book, possibly checking it out or browsing through the collection.\n\nThere are several people in the library, with some sitting at tables"}, "542147": {"image_id": 542147, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.20203050890627616, "Bleu_3": 0.0954066585882441, "Bleu_4": 1.172180673188117e-05, "METEOR": 0.20123209599592945, "ROUGE_L": 0.26341764342998153, "CIDEr": 8.183795333809437e-10, "SPICE": {"All": {"pr": 0.28, "re": 0.3684210526315789, "f": 0.3181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a large, grassy field with a herd of cows grazing on the lush green grass. There are at least 13 cows scattered throughout the field, with some closer to the foreground and others further in the background. The cows are of various sizes, indicating a diverse"}, "277227": {"image_id": 277227, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.10484363678213088, "Bleu_4": 0.06999971125156287, "METEOR": 0.18255875143271785, "ROUGE_L": 0.22889305816135083, "CIDEr": 1.7797120171149773e-11, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a harbor with several boats docked in the water. There is a large white boat, possibly a ferry, parked in the middle of the scene. Another boat is located towards the left side of the harbor, and a third boat can be seen on the right side.\n\nIn"}, "323552": {"image_id": 323552, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.2570050525511465, "ROUGE_L": 0.26940063091482647, "CIDEr": 6.299741325532499e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.3125, "f": 0.2631578947368421, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a woman sitting on a luggage carousel at an airport, waiting for her luggage. She is holding a brown purse in her hand. There are two suitcases in the scene, one located near the woman and the other further away. A backpack is also present, placed"}, "319607": {"image_id": 319607, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.19425717246782156, "Bleu_3": 8.986355476387577e-07, "Bleu_4": 1.9422053745009808e-09, "METEOR": 0.19987089886189574, "ROUGE_L": 0.27072436202250755, "CIDEr": 3.1255368689720724e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15789473684210525, "f": 0.15789473684210525, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image depicts a busy city street with a red traffic light hanging above the road. The traffic light is currently displaying a red light, indicating that vehicles must stop. There are several cars and a truck on the street, with one car positioned closer to the left side of the image, another car"}, "581702": {"image_id": 581702, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.21550898337204086, "Bleu_3": 0.17613159861866798, "Bleu_4": 0.14459406071073252, "METEOR": 0.25954199877812584, "ROUGE_L": 0.26472411655300687, "CIDEr": 1.9744480616720502e-11, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.3181818181818182, "f": 0.3414634146341463, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a small red and white bird perched on a rock. The bird is standing on a rocky surface, surrounded by a few other rocks. The bird appears to be looking at the camera, capturing the viewer's attention. The scene is set in a natural environment, with the bird being"}, "328818": {"image_id": 328818, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.09496360514530064, "Bleu_4": 1.1879571650374926e-05, "METEOR": 0.2872445119633935, "ROUGE_L": 0.3084702907711757, "CIDEr": 1.3621315650471966e-07, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.21428571428571427, "f": 0.18181818181818182, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a woman in a pink shirt and blue jeans, standing next to a bench and tying her shoes. She is wearing a helmet, indicating that she might be preparing for a bike ride. The bench is located near a bicycle, which is park"}, "55981": {"image_id": 55981, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.1400280084000279, "Bleu_3": 0.07369045667590099, "Bleu_4": 9.55538360357512e-06, "METEOR": 0.17374075367564143, "ROUGE_L": 0.24497991967871488, "CIDEr": 2.0341040604249388e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.16, "f": 0.16, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.06666666666666667, "f": 0.09090909090909091, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a young girl standing on a staircase, holding a purple scarf around her neck. She is wearing a brown shirt and appears to be smiling. The girl is also holding a suitcase, which is placed on the ground next to her. The scene suggests that she might be"}, "385918": {"image_id": 385918, "Bleu_1": 0.3599999999928, "Bleu_2": 0.24243661068763242, "Bleu_3": 0.18293988070876474, "Bleu_4": 0.14060058991881091, "METEOR": 0.2681472456758774, "ROUGE_L": 0.27128335451080055, "CIDEr": 9.545847037226083e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2777777777777778, "f": 0.24390243902439024, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image captures a group of people playing a game of frisbee on a grassy field. There are at least six people in the scene, with one man wearing a yellow hat and a black shirt, and another man wearing a white shirt. They are all actively engaged in the"}, "86625": {"image_id": 86625, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.20304239863369572, "Bleu_3": 0.12521356825154964, "Bleu_4": 0.08318453241921067, "METEOR": 0.2357164715689548, "ROUGE_L": 0.29985955056179775, "CIDEr": 7.177560268736363e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a man standing in a kitchen, leaning over a refrigerator filled with various food items. He appears to be looking at the contents of the refrigerator, possibly deciding what to eat or preparing a meal.\n\nThe refrigerator is stocked with several"}, "87429": {"image_id": 87429, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.18070977621815823, "Bleu_3": 0.10859446879612175, "Bleu_4": 0.07113990450126208, "METEOR": 0.1676033901832721, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.6565243682719186e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15789473684210525, "f": 0.15, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a busy city street with multiple vehicles, including cars and buses, driving down the road. There are two buses in the scene, one located towards the center of the street and the other towards the right side. A car is driving in front of the buses, and another car is"}, "330091": {"image_id": 330091, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 8.411954328528159e-07, "Bleu_4": 1.8864626675179613e-09, "METEOR": 0.20788095936569384, "ROUGE_L": 0.2901307966706302, "CIDEr": 2.090068526525256e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21428571428571427, "f": 0.21818181818181817, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image captures a snowboarder in action, making a sharp turn on a snow-covered slope. The snowboarder is wearing a black jacket and is surrounded by a cloud of snow as they navigate the slope. There are several other people in the scene, some of them standing or walking in"}, "491851": {"image_id": 491851, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.23644230070621639, "Bleu_3": 0.16261814409393693, "Bleu_4": 0.09582618669737837, "METEOR": 0.293999937577978, "ROUGE_L": 0.34936998854524626, "CIDEr": 1.3782896773327802e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a computer desk with a desktop computer setup. The computer monitor is placed on the desk, and a keyboard and mouse are positioned in front of it. There are also several books scattered around the desk, with some placed near the monitor and others on the right side of the desk."}, "203661": {"image_id": 203661, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.2201927530203234, "Bleu_3": 0.17797917821554632, "Bleu_4": 0.1416592339557592, "METEOR": 0.28778237884314095, "ROUGE_L": 0.30091613812544044, "CIDEr": 1.069004508665927e-08, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.27586206896551724, "f": 0.2711864406779661, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a small, cozy kitchen with a wooden dining table in the center. The table is surrounded by chairs, with one on the left side and another on the right side. The kitchen is well-equipped with a sink, an oven, and a refrigerator."}, "150875": {"image_id": 150875, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.09476070829395405, "Bleu_3": 5.719241732016864e-07, "Bleu_4": 1.412470464555783e-09, "METEOR": 0.15614047681548235, "ROUGE_L": 0.1586475942782835, "CIDEr": 1.4995169760801934e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.2222222222222222, "f": 0.23076923076923075, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a stone bench situated in a park, surrounded by trees and bushes. The bench is adorned with a beautiful stone sculpture, which adds a touch of artistic charm to the scene. The bench is positioned in the middle of the park, providing a comfortable spot for visitors"}, "99707": {"image_id": 99707, "Bleu_1": 0.41666666665798613, "Bleu_2": 0.2824663414270688, "Bleu_3": 0.17328685148662828, "Bleu_4": 0.10369816700415076, "METEOR": 0.2214157503538645, "ROUGE_L": 0.23461538461538461, "CIDEr": 6.406262774701292e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16129032258064516, "f": 0.1923076923076923, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a woman standing on a snow-covered slope, wearing skis and holding ski poles. She is posing for a picture in front of a sign that reads \"Superstar.\" The woman appears to be enjoying her time on the snowy hill, possibly preparing to ski down the"}, "124647": {"image_id": 124647, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.15802842456444308, "Bleu_4": 0.09845529669817563, "METEOR": 0.2502177967234, "ROUGE_L": 0.2922655715263518, "CIDEr": 1.5942706793012174e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a young boy wearing a helmet and a grey shirt, standing in a skate park. He is holding a skateboard, likely preparing to ride it. There are several other people in the skate park, some of them also holding skateboards.\n\nIn total,"}, "62167": {"image_id": 62167, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.17396263050956592, "ROUGE_L": 0.21266705403834982, "CIDEr": 5.994548720751851e-12, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man standing in a grassy field, holding a sword and engaging in a game of swordplay with a group of sheep. There are three sheep in the scene, with one sheep located closer to the man, another in the middle of the field, and the third one further away."}, "300221": {"image_id": 300221, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.10767638040926633, "Bleu_3": 6.411053581337095e-07, "Bleu_4": 1.573366652415358e-09, "METEOR": 0.17128905507615586, "ROUGE_L": 0.2378476735118274, "CIDEr": 5.4794620484574734e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09523809523809523, "f": 0.0909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a large display of fresh vegetables, including a variety of carrots and cauliflower. The carrots are arranged in several bunches, with some placed closer to the front and others further back. The cauliflower is also displayed in multiple bunches, with some located near"}, "109537": {"image_id": 109537, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.27450794146236435, "Bleu_3": 0.11788286024426504, "Bleu_4": 1.3812900077678664e-05, "METEOR": 0.3050700108420483, "ROUGE_L": 0.34398496240601506, "CIDEr": 3.1595815992303486e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.11538461538461539, "f": 0.14634146341463417, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a man skillfully riding a wave on a surfboard in the ocean. He is positioned in the middle of the wave, displaying his balance and control as he navigates the water. The surfer is wearing a blue shirt, which stands out against the ocean backdrop."}, "382715": {"image_id": 382715, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.23782574707262866, "Bleu_3": 0.18933591164923458, "Bleu_4": 0.15342308957715506, "METEOR": 0.3767548011955884, "ROUGE_L": 0.29397590361445786, "CIDEr": 6.301588738825069e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a busy city street with a man riding a skateboard down the middle of the road. He is wearing a green hat and appears to be the main focus of the scene. There are several other people in the image, some walking and others standing, scattered throughout the street."}, "52596": {"image_id": 52596, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.20995626366288764, "Bleu_3": 0.1766265128453326, "Bleu_4": 0.13694550133052863, "METEOR": 0.2732476825578611, "ROUGE_L": 0.30310559006211185, "CIDEr": 2.2297195245491955e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a young girl wearing a purple shirt, standing in a park and holding a slice of pizza in her hand. She appears to be enjoying her meal while surrounded by a lively outdoor setting.\n\nThere are several other people in the background, some of them sitting on"}, "500718": {"image_id": 500718, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.17583479290167828, "Bleu_3": 0.08890352562172174, "Bleu_4": 1.1306342156768618e-05, "METEOR": 0.2514386431421698, "ROUGE_L": 0.26991150442477874, "CIDEr": 5.104145473479934e-08, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.09090909090909091, "f": 0.09302325581395349, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a large airport tarmac with several airplanes parked on the runway. There are three prominent airplanes in the scene, with one on the left side, another in the middle, and the third on the right side of the tarmac.\n\nIn addition to the"}, "182240": {"image_id": 182240, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.23819653366515028, "Bleu_3": 0.15467190426819247, "Bleu_4": 0.0952259789202735, "METEOR": 0.18401399500057483, "ROUGE_L": 0.23680124223602486, "CIDEr": 2.9151525053942782e-09, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2222222222222222, "f": 0.22857142857142856, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a group of four zebras standing together in a grassy field. They are positioned in a line, with one zebra slightly ahead of the others. The zebras are facing the camera, showcasing their unique black and white stripes. The field appears to be a mix"}, "525083": {"image_id": 525083, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 0.09105491676695633, "Bleu_4": 1.1795365411101286e-05, "METEOR": 0.19469443755292934, "ROUGE_L": 0.27354260089686094, "CIDEr": 1.3340994021469879e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image depicts a spacious kitchen and living room area with hardwood floors. The kitchen features a refrigerator, microwave, and oven, while the living room has a couch and a chair. There is also a dining table in the room.\n\nIn the"}, "56821": {"image_id": 56821, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.13937882544862468, "Bleu_3": 0.09522194049088255, "Bleu_4": 1.1835581532782094e-05, "METEOR": 0.21923359751613694, "ROUGE_L": 0.26571250777846916, "CIDEr": 6.355649620191537e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.18518518518518517, "f": 0.1923076923076923, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a city street with a white flag hanging from a pole, advertising a business called \"Homestyle.\" The street is lined with trees, providing a pleasant atmosphere. There are several cars parked along the street, with some closer to the foreground and others further back."}, "256367": {"image_id": 256367, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.12281268769488378, "Bleu_3": 0.06706647632268699, "Bleu_4": 8.857886206727456e-06, "METEOR": 0.20960369613968385, "ROUGE_L": 0.22241127856101123, "CIDEr": 6.565845735154327e-12, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.1724137931034483, "f": 0.19999999999999998, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.35714285714285715, "f": 0.41666666666666663, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a blue and yellow train traveling down the tracks, with a total of 11 cars visible in the scene. The train is moving along the tracks, which are surrounded by trees and bushes, creating a serene and natural environment. The train appears to be traveling at a moderate speed"}, "42667": {"image_id": 42667, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.07205793047605258, "Bleu_4": 9.44575929237223e-06, "METEOR": 0.1483911514987427, "ROUGE_L": 0.1937738246505718, "CIDEr": 6.321168016530887e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a young child sitting in a suitcase, likely enjoying a playful moment. The child is positioned in the middle of the suitcase, with their legs and arms visible. The suitcase is placed on a floor, and the child appears to be the main focus of the scene."}, "388453": {"image_id": 388453, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 0.07777190244898266, "Bleu_4": 1.0056053706911773e-05, "METEOR": 0.19443131164931565, "ROUGE_L": 0.2663755458515284, "CIDEr": 5.301206686404594e-10, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.25, "f": 0.25641025641025644, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a large group of people gathered in a spacious room, possibly a ballroom or a banquet hall. The room is filled with people standing and mingling, with some of them holding wine glasses. There are several wine glasses scattered throughout the room, indicating that the event"}, "38118": {"image_id": 38118, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.15508644003992356, "Bleu_3": 0.10224805260881925, "Bleu_4": 1.2484700111358323e-05, "METEOR": 0.18570766351114978, "ROUGE_L": 0.20847573479152426, "CIDEr": 8.021014800436257e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a person wearing a red jacket and skiing down a snow-covered slope. The skier is making their way through the snow, likely enjoying the thrill of skiing down the mountain. The skier is also wearing a backpack, which can be seen on their back"}, "305319": {"image_id": 305319, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.18650096164396338, "Bleu_3": 0.14677648688658226, "Bleu_4": 0.1218724568456559, "METEOR": 0.2354286878800954, "ROUGE_L": 0.28968792401628224, "CIDEr": 1.7353704684171993e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.11428571428571428, "f": 0.13793103448275862, "fn": 31.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a person wearing a wetsuit, skillfully riding a wave on a surfboard in the ocean. The surfer is positioned in the middle of the scene, with the surfboard visible beneath them. The wave is quite large, providing an exciting ride for the surfer"}, "410484": {"image_id": 410484, "Bleu_1": 0.3199999999936, "Bleu_2": 0.24243661068763242, "Bleu_3": 0.18293988070876474, "Bleu_4": 0.14060058991881091, "METEOR": 0.22870210473936425, "ROUGE_L": 0.30118144947980957, "CIDEr": 4.1548356380060926e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.18518518518518517, "f": 0.18518518518518517, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a person, likely a woman, cutting a blue and white cake with a knife. The cake is placed on a dining table, and the person is using a plate to hold the cake while cutting it. The cake is decorated with stars, adding a festive touch to"}, "454252": {"image_id": 454252, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.23763541030969573, "Bleu_3": 0.179280097059552, "Bleu_4": 0.12447904522732414, "METEOR": 0.24494378032376177, "ROUGE_L": 0.3042123074182919, "CIDEr": 3.939917823162263e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.18181818181818182, "f": 0.12903225806451613, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a group of six people standing together in a room, posing for a picture. They are all holding wine glasses, with some of them holding them in the air. The group appears to be enjoying a social gathering or a wine tasting event.\n\nThe room is filled with"}, "245153": {"image_id": 245153, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.15755219780890306, "Bleu_3": 8.141361391768222e-07, "Bleu_4": 1.8608854771631139e-09, "METEOR": 0.2109848849130346, "ROUGE_L": 0.2635802469135803, "CIDEr": 7.783628996247655e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.26666666666666666, "f": 0.23529411764705882, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two penguins standing on a grassy hillside, overlooking a steep cliff. The penguins are positioned close to each other, with one on the left side and the other on the right side of the hill. The grassy hillside provides a natural habitat for these birds"}, "528980": {"image_id": 528980, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 8.491317075202567e-07, "Bleu_4": 1.8997953886425763e-09, "METEOR": 0.16912315286887009, "ROUGE_L": 0.27128335451080055, "CIDEr": 3.608255433832857e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.0967741935483871, "f": 0.10526315789473684, "fn": 28.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a large red umbrella, which is attached to a pole and stands out in the scene. The umbrella is positioned in front of a tall building, possibly a brick building, and is located near a street corner. The umbrella is open, providing shade and protection from the"}, "402118": {"image_id": 402118, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.08845670453991433, "Bleu_4": 1.1398615456851686e-05, "METEOR": 0.22998909652926783, "ROUGE_L": 0.25318206972883234, "CIDEr": 6.185662904879509e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.21052631578947367, "f": 0.22857142857142856, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a snowboarder in mid-air, performing a jump on a snow-covered slope. The snowboarder is wearing a white suit and is surrounded by a cloudy sky. The snowboarder's body is positioned in the air, with their legs slightly bent and arms"}, "303893": {"image_id": 303893, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.22214157542810112, "Bleu_3": 0.16912968543219944, "Bleu_4": 0.11794509340801168, "METEOR": 0.29482655408475766, "ROUGE_L": 0.3620178041543027, "CIDEr": 8.625169679553811e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.29411764705882354, "f": 0.24390243902439027, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a young boy and a young girl sitting on a sidewalk, enjoying their lunch together. They are both eating hot dogs, with one hot dog in the boy's hand and another in the girl's hand. The children are sitting close to each other, creating a sense of companion"}, "491836": {"image_id": 491836, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.2669809468728851, "Bleu_3": 0.2018534368193611, "Bleu_4": 0.16851053919438938, "METEOR": 0.3260378087269515, "ROUGE_L": 0.3567251461988304, "CIDEr": 2.7713486120643585e-12, "SPICE": {"All": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07142857142857142, "f": 0.09523809523809523, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a large body of water with a boat floating on it. The boat is situated in the middle of the scene, surrounded by a vast expanse of water. The sky above the water is a beautiful shade of blue, indicating a clear and sunny day.\n\nThere are several people on the"}, "456816": {"image_id": 456816, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 0.1161912088962168, "Bleu_4": 0.07560832959746702, "METEOR": 0.20996468660321999, "ROUGE_L": 0.25831820931639443, "CIDEr": 1.3017103149103412e-10, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.3333333333333333, "f": 0.2978723404255319, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a white plate with a delicious pastry, possibly a donut or a cake, sitting on top of it. The plate is placed on a wooden dining table. A fork is positioned next to the plate, ready to be used to enjoy the dessert. The table also has a"}, "495825": {"image_id": 495825, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.19410642689759766, "Bleu_3": 0.09356368818038328, "Bleu_4": 1.1615218159577744e-05, "METEOR": 0.17510875317079252, "ROUGE_L": 0.18484848484848485, "CIDEr": 1.6231646910145378e-07, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2413793103448276, "f": 0.27450980392156865, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a picturesque scene of a herd of cows grazing in a lush green field. There are at least nine cows visible in the field, with some closer to the foreground and others further away. The cows are scattered throughout the field, enjoying the abundant grass."}, "174740": {"image_id": 174740, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.24902912254001588, "Bleu_3": 0.16555636850966743, "Bleu_4": 1.835246569006447e-05, "METEOR": 0.24771242113164424, "ROUGE_L": 0.3138263665594855, "CIDEr": 5.8201521295841885e-06, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.06666666666666667, "f": 0.07547169811320756, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features a dining table with a plastic container filled with a variety of doughnuts. There are six doughnuts in total, with some of them being covered in sugar. A bottle of Coca-Cola is placed next to the doughnuts, adding a refres"}, "507037": {"image_id": 507037, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.21797089763394864, "Bleu_3": 0.1681121136269389, "Bleu_4": 0.11800699061814819, "METEOR": 0.2665978733261029, "ROUGE_L": 0.319823568575233, "CIDEr": 2.1323693587259117e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.38095238095238093, "f": 0.3137254901960784, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image depicts a group of people gathered outside a building, with some of them standing in front of a flag. There are several bicycles parked in the area, with some of them placed close to the people. A few people are standing near a red wagon, possibly preparing for a ride"}, "57323": {"image_id": 57323, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.18871982178961313, "Bleu_3": 0.1165424577061418, "Bleu_4": 1.3772093427771898e-05, "METEOR": 0.2901516673643951, "ROUGE_L": 0.2848565710473649, "CIDEr": 7.435025095420614e-10, "SPICE": {"All": {"pr": 0.32, "re": 0.36363636363636365, "f": 0.3404255319148936, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a group of people riding motorcycles down a street. There are several motorcycles visible in the scene, with some riders wearing helmets for safety. The motorcycles are positioned in various locations along the street, with some closer to the foreground and others further back"}, "516038": {"image_id": 516038, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.2084219669570065, "Bleu_3": 0.0981091958911253, "Bleu_4": 1.2035916294672372e-05, "METEOR": 0.20765531785141678, "ROUGE_L": 0.23036253776435048, "CIDEr": 1.3943012750407664e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13333333333333333, "f": 0.163265306122449, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress, with a pitcher in the middle of throwing a pitch. The pitcher is wearing a baseball glove and is in the process of releasing the ball. The scene also includes a catcher and an umpire, both positioned behind the pitcher"}, "433915": {"image_id": 433915, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.06475239082260723, "Bleu_3": 4.3201891081498714e-07, "Bleu_4": 1.1213327957896796e-09, "METEOR": 0.1536570800805827, "ROUGE_L": 0.23487348734873487, "CIDEr": 4.4248678427764885e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a split-screen display of two people, one on the left side and the other on the right side of the screen. The two individuals are both wearing ties, with one of them having a red tie. The man on the left side of the screen is wearing a suit and tie,"}, "17899": {"image_id": 17899, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.2235033479141667, "Bleu_3": 0.1304553364641582, "Bleu_4": 1.4987638789540041e-05, "METEOR": 0.26522528384634037, "ROUGE_L": 0.317915309446254, "CIDEr": 8.552002148569053e-09, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.25806451612903225, "f": 0.31999999999999995, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features an older woman standing in a kitchen, preparing food on a dining table. She is focused on making bread and decorating cookies, with several loaves of bread and a variety of cookies spread across the table.\n\nThe kitchen is well-equipped with a refrigerator, an"}, "298252": {"image_id": 298252, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.15698856690934238, "Bleu_4": 0.1347074304621809, "METEOR": 0.3016461315752946, "ROUGE_L": 0.34879288437102923, "CIDEr": 3.46597819190116e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.3076923076923077, "f": 0.23529411764705882, "fn": 9.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.5, "f": 0.2, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image showcases a bakery display case filled with a variety of delicious pastries. There are several donuts in different shapes and sizes, with some placed closer to the front of the display and others further back. The donuts are arranged in a visually appealing manner, making them look tempting"}, "222370": {"image_id": 222370, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.17030176766040664, "Bleu_4": 0.15221849019243577, "METEOR": 0.317972435141122, "ROUGE_L": 0.31504196255648803, "CIDEr": 1.8525017835671238e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.30434782608695654, "f": 0.31818181818181823, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a man riding a motorcycle down a city street, with another man walking beside him. The man on the motorcycle is wearing a turban, and both men appear to be engaged in conversation.\n\nThere are several potted plants placed along the street, adding a touch of"}, "374448": {"image_id": 374448, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1458649914948234, "Bleu_3": 0.07733595213409626, "Bleu_4": 1.0068921364329411e-05, "METEOR": 0.17836328018881042, "ROUGE_L": 0.2635802469135803, "CIDEr": 2.4834298342486948e-08, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.12121212121212122, "f": 0.13333333333333333, "fn": 29.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a large, open dining area with a high ceiling and a large clock hanging from the ceiling. The dining area is filled with numerous people sitting at various tables, enjoying their meals and conversations. The tables are surrounded by chairs, and some people are standing"}, "181278": {"image_id": 181278, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 0.07925015807505881, "Bleu_4": 1.0039245690493996e-05, "METEOR": 0.2342249259941707, "ROUGE_L": 0.22048192771084338, "CIDEr": 9.00475343619258e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.19230769230769232, "f": 0.20833333333333331, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a group of young boys playing baseball on a field. One boy is in the process of throwing a baseball, while another boy is preparing to catch it. The third boy is standing nearby, possibly waiting for his turn to play.\n\nThere are two bicycles in the background, one"}, "373789": {"image_id": 373789, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.13160986848342301, "Bleu_4": 1.4920276910509015e-05, "METEOR": 0.2630902835316962, "ROUGE_L": 0.28222075346992725, "CIDEr": 2.307429623502958e-07, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.25, "f": 0.2592592592592593, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a white plate placed on a dining table, topped with a delicious sandwich and two pieces of breaded meat, likely fish sticks. The sandwich is cut in half, revealing the bread and filling inside. The plate is positioned in the center of the table, making it"}, "251124": {"image_id": 251124, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.13093073413895012, "Bleu_3": 7.094917059707092e-07, "Bleu_4": 1.660297934705131e-09, "METEOR": 0.2291779910451201, "ROUGE_L": 0.25386444708680145, "CIDEr": 7.217553634936203e-10, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.25, "f": 0.27906976744186046, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a black bicycle parked on a sidewalk near a body of water, possibly a river or a lake. The bicycle is positioned close to the water's edge, with a beautiful city skyline visible in the background. The scene appears to be captured at night, as the"}, "162249": {"image_id": 162249, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.1390096093683277, "Bleu_3": 0.09576841983278785, "Bleu_4": 0.06722791268742227, "METEOR": 0.13832812411748055, "ROUGE_L": 0.2367399741267788, "CIDEr": 1.987430994875764e-08, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.15, "f": 0.11320754716981132, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image depicts a bathroom with a large, round, stone-like sink in the center of the room. The sink is surrounded by a stone-like countertop, giving it a unique and luxurious appearance. The bathroom also features a toilet situated towards the right side of the room"}, "551908": {"image_id": 551908, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.210720977237338, "Bleu_3": 0.1435846767449069, "Bleu_4": 0.1077024049139832, "METEOR": 0.21229230474246322, "ROUGE_L": 0.3552741055745586, "CIDEr": 4.946624870852513e-07, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.23809523809523808, "f": 0.1923076923076923, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a white plate with a delicious meal consisting of a piece of fish, broccoli, and potatoes. The fish is placed in the center of the plate, surrounded by a generous portion of broccoli and potatoes. The broccoli is scattered around the plate, with some"}, "366367": {"image_id": 366367, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.31067135505649107, "Bleu_3": 0.25729119193859795, "Bleu_4": 0.19212823182749383, "METEOR": 0.2858852306511863, "ROUGE_L": 0.3258160237388724, "CIDEr": 2.5900424208988146e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.20689655172413793, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a young girl standing in a store, holding a cell phone in her hand. She appears to be looking at the screen of the phone, possibly browsing or playing a game. The girl is wearing a red handbag, which is placed in front of her.\n\nThe store has a variety"}, "231343": {"image_id": 231343, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2126329371370835, "Bleu_3": 0.09942625500921409, "Bleu_4": 1.2156895477519368e-05, "METEOR": 0.24619700895600316, "ROUGE_L": 0.2839851024208566, "CIDEr": 9.888900062849592e-06, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.4166666666666667, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress, with a baseball player standing at home plate, holding a bat and preparing to swing. The player is wearing a baseball glove, ready to catch the ball.\n\nThere are several other people in the scene, including teammates and opponents, some"}, "236290": {"image_id": 236290, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.1184508853673932, "Bleu_3": 6.683330244266766e-07, "Bleu_4": 1.5960821227040779e-09, "METEOR": 0.15281282096875098, "ROUGE_L": 0.15394321766561514, "CIDEr": 1.1209845747702521e-10, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.20689655172413793, "f": 0.23076923076923075, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a person standing on a staircase, holding a blue suitcase. The suitcase is positioned in the middle of the scene, with the person standing on the left side of the staircase. Another person can be seen in the background, standing further away from the main subject."}, "189095": {"image_id": 189095, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.11524490328511487, "Bleu_4": 1.3433582021760985e-05, "METEOR": 0.21662944329034592, "ROUGE_L": 0.26521739130434785, "CIDEr": 2.559107360707387e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.25, "f": 0.24489795918367346, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features two brown bears in a zoo enclosure, standing close to each other and engaging in a playful fight. They are both growling and biting at each other, displaying their strength and agility. The bears are positioned near a rock wall, which adds to the natural setting of"}, "426546": {"image_id": 426546, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.19410642689759766, "Bleu_3": 0.09356368818038328, "Bleu_4": 1.1615218159577744e-05, "METEOR": 0.24556276478145644, "ROUGE_L": 0.270595690747782, "CIDEr": 8.890399926557645e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.19230769230769232, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a white plate filled with a delicious meal. On the plate, there are two sandwiches, each cut in half, accompanied by a generous portion of french fries. The sandwiches are placed on the left side of the plate, while the fries are spread out on"}, "114119": {"image_id": 114119, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.09073607102736221, "Bleu_4": 1.1055858618542048e-05, "METEOR": 0.2253566719537358, "ROUGE_L": 0.2544999403981404, "CIDEr": 1.162583937731459e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a cat lying down on a glass table, with a clock positioned above it. The cat appears to be sleeping or resting, and it is located near the center of the scene. The clock is prominently displayed, covering a significant portion of the upper part of the image. The glass"}, "290828": {"image_id": 290828, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.10339796947386827, "Bleu_4": 0.06964012518749992, "METEOR": 0.21111877930861994, "ROUGE_L": 0.22732919254658387, "CIDEr": 7.113505259272323e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.23529411764705882, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a giraffe standing in an enclosure at a zoo, surrounded by a fence. The giraffe is eating leaves from a tree, with a few people observing it from a nearby platform. There are at least five people in the scene, with some standing closer to the gira"}, "64103": {"image_id": 64103, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.1344109151128908, "Bleu_4": 0.10192489527760022, "METEOR": 0.2163640309659149, "ROUGE_L": 0.2401574803149606, "CIDEr": 2.58828793037768e-10, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.20833333333333334, "f": 0.19607843137254902, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two birds, possibly ducks, swimming together in a body of water. They are positioned close to each other, with their heads touching as they interact with each other. The birds are surrounded by a serene environment, with the water providing a calm and peaceful atmosphere."}, "194756": {"image_id": 194756, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 8.378836055206644e-07, "Bleu_4": 1.861395885683349e-09, "METEOR": 0.2461907702590573, "ROUGE_L": 0.25176886792452824, "CIDEr": 6.851466412912275e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man sitting in a small boat on a river, possibly a canal. He is steering the boat with a steering wheel, and there is a bench nearby. The boat is surrounded by several people, some of whom are sitting on a bench and others standing nearby.\n\nIn the"}, "412879": {"image_id": 412879, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.20550493309104514, "Bleu_3": 0.11909718541937828, "Bleu_4": 1.3626273559929098e-05, "METEOR": 0.27415301246376517, "ROUGE_L": 0.25722891566265055, "CIDEr": 6.622662916510341e-11, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.375, "f": 0.3913043478260869, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a woman standing in a fenced-in area, holding a tennis racket and preparing to hit a tennis ball. She is wearing a black shirt and appears to be focused on the game. The tennis ball is in the air, close to the woman, as she is about to make"}, "51741": {"image_id": 51741, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.08939035350783202, "Bleu_4": 1.1103081472064331e-05, "METEOR": 0.22115606589651648, "ROUGE_L": 0.26521739130434785, "CIDEr": 3.094775251820666e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.38461538461538464, "f": 0.30303030303030304, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet situated next to a white sink. The toilet is positioned on the left side of the bathroom, while the sink is located on the right side. Above the sink, there is a mirror, and a bottle can be seen placed on"}, "111448": {"image_id": 111448, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.10353608435894587, "Bleu_4": 1.220608250473103e-05, "METEOR": 0.1932418354578308, "ROUGE_L": 0.27774615822424586, "CIDEr": 5.557781821242893e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.23076923076923078, "f": 0.23529411764705882, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a man riding a horse on a grassy field, surrounded by a crowd of people. The man on the horse is wearing a red and yellow jacket, and the horse is wearing a blanket. The crowd consists of various individuals, some of whom are standing close to the horse and"}, "255279": {"image_id": 255279, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1577557537051747, "Bleu_3": 0.12580178429699443, "Bleu_4": 0.10507427312661778, "METEOR": 0.3052268469962708, "ROUGE_L": 0.32370283018867924, "CIDEr": 1.6288365635886717e-10, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.16666666666666666, "f": 0.17543859649122806, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a black motorcycle parked in a parking lot, occupying a significant portion of the scene. The motorcycle is positioned in the middle of the parking lot, with a car parked behind it on the left side. Another car can be seen further back on the right side of the"}, "243626": {"image_id": 243626, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2474358296475945, "Bleu_3": 0.15751292285925483, "Bleu_4": 1.7072522153615456e-05, "METEOR": 0.2639097712839942, "ROUGE_L": 0.28824571766095686, "CIDEr": 3.58314921208447e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a white plate filled with a delicious meal, including a generous portion of meat, likely steak, and a side of green beans. The plate is placed on a dining table, and a fork is positioned nearby, ready for use. The meal is accompanied by a glass"}, "171255": {"image_id": 171255, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.13609999140195853, "Bleu_4": 1.5138514598460069e-05, "METEOR": 0.22365803572951692, "ROUGE_L": 0.29847094801223245, "CIDEr": 1.295352120998157e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a group of people riding horses on a sandy beach. There are several horses and riders scattered across the scene, with some closer to the water and others further back on the beach. The riders are enjoying their time on the beach, creating a picturesque scene.\n\nIn addition"}, "41119": {"image_id": 41119, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.25900956329042873, "Bleu_3": 0.20824540717562975, "Bleu_4": 0.15181662886775785, "METEOR": 0.2975086328814902, "ROUGE_L": 0.3210526315789473, "CIDEr": 9.641026162307478e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.3333333333333333, "f": 0.25641025641025644, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a traffic light hanging from a pole in front of a tall building. The traffic light is currently displaying a green light, signaling that vehicles can proceed. The building is situated in the background, and the traffic light is positioned in the foreground, making it the focal point of the scene"}}}