{"overall": {"Bleu_1": 0.2851263533553679, "Bleu_2": 0.19113628803928165, "Bleu_3": 0.12227768081156457, "Bleu_4": 0.07751742743598986, "METEOR": 0.23076161020290337, "ROUGE_L": 0.26996964731960665, "CIDEr": 3.268019998095701e-05, "SPICE": 0.21250321012440088}, "imgToEval": {"504142": {"image_id": 504142, "Bleu_1": 0.3399999999932, "Bleu_2": 0.276272565791757, "Bleu_3": 0.1995881547631518, "Bleu_4": 0.13562323730550369, "METEOR": 0.2767647413766746, "ROUGE_L": 0.34099378881987574, "CIDEr": 9.052272699555301e-10, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.20689655172413793, "f": 0.1875, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.0625, "re": 0.1111111111111111, "f": 0.08, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image features a black and white dog lying on a couch, covered by a blanket. The dog appears to be sleeping or resting comfortably under the blanket. The couch is situated in a room with a chair nearby, and a pillow can be seen on the couch as well."}, "49115": {"image_id": 49115, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.12632278815731815, "Bleu_3": 0.07026437559457349, "Bleu_4": 9.370187147561893e-06, "METEOR": 0.22366191855357848, "ROUGE_L": 0.2582244799225931, "CIDEr": 1.0206825212505932e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.26666666666666666, "f": 0.2962962962962963, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a giraffe standing in a lush green forest, surrounded by trees and bushes. The giraffe is positioned in the center of the scene, with its long neck stretched upwards, possibly reaching for leaves on a tree. The giraffe appears to be the main focus of"}, "328284": {"image_id": 328284, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.16163173752903065, "Bleu_3": 0.100810174751238, "Bleu_4": 0.06727996774735587, "METEOR": 0.22286113353540107, "ROUGE_L": 0.25341246290801184, "CIDEr": 1.4590128922862105e-12, "SPICE": {"All": {"pr": 0.36, "re": 0.2903225806451613, "f": 0.3214285714285714, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a person wearing skis and standing in the snow, possibly in a wooded area. The person is holding ski poles and appears to be enjoying their time skiing. The skis are visible on the snow, with one set placed closer to the person and the other set slightly further away"}, "434662": {"image_id": 434662, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2014440620697061, "Bleu_3": 0.12263904310164322, "Bleu_4": 1.4391446615915733e-05, "METEOR": 0.20903182708968904, "ROUGE_L": 0.20691994572591585, "CIDEr": 3.8694838462029445e-08, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.2962962962962963, "f": 0.31999999999999995, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image captures a person skiing down a snow-covered slope, wearing a white jacket and a yellow helmet. The skier is leaning forward, maintaining balance and control as they glide down the hill. The scene is set against a backdrop of trees, adding to the pictures"}, "307166": {"image_id": 307166, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1543033499589101, "Bleu_3": 7.971700074705258e-07, "Bleu_4": 1.8216869827152143e-09, "METEOR": 0.20325099871326766, "ROUGE_L": 0.30329397141081416, "CIDEr": 5.4366289020228025e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a table covered with a variety of pizzas and other food items. There are several pizzas placed on the table, with some of them being homemade. In addition to the pizzas, there are also a few bottles and a cup on the table, possibly containing bever"}, "386352": {"image_id": 386352, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.14982983544985165, "Bleu_3": 0.11195037194347686, "Bleu_4": 0.07391706107787872, "METEOR": 0.22807663679561768, "ROUGE_L": 0.23252858958068615, "CIDEr": 1.230348065350719e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.21739130434782608, "f": 0.20833333333333331, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image captures a woman playing tennis on a court, holding a tennis racket and preparing to hit the ball. She is focused and determined, displaying her athleticism.\n\nThere are several people in the scene, including a group of spectators watching the game from the stands. Some of them are"}, "74059": {"image_id": 74059, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.1593617613384745, "Bleu_4": 0.11580903993958114, "METEOR": 0.2513238156791218, "ROUGE_L": 0.33639705882352944, "CIDEr": 7.441599237507125e-09, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a tall brick clock tower with a clock on each of its sides. The clocks are positioned at different heights, making the tower visually interesting. The tower is adorned with intricate carvings and decorations, giving it a unique and historical appearance. The clocks are visible"}, "466882": {"image_id": 466882, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.1475489144223407, "Bleu_3": 7.529519927190925e-07, "Bleu_4": 1.7093577453608883e-09, "METEOR": 0.19001942085679469, "ROUGE_L": 0.18100890207715134, "CIDEr": 2.6773446016819e-12, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a doubles tennis match in progress on a blue tennis court. Two tennis players are actively engaged in the game, each holding a tennis racket. One player is positioned on the left side of the court, while the other is on the right side.\n\nThere are several other people in"}, "264124": {"image_id": 264124, "Bleu_1": 0.3199999999936, "Bleu_2": 0.24243661068763242, "Bleu_3": 0.16982634150405124, "Bleu_4": 0.12015361032790647, "METEOR": 0.2822750303642245, "ROUGE_L": 0.30310559006211185, "CIDEr": 9.85612192599681e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.3125, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man with a beard and mustache, wearing a black shirt, talking on a cell phone. He is smiling while engaged in the conversation, giving the impression that he is enjoying the call. The man is standing in a room with a car visible in the background."}, "92205": {"image_id": 92205, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.23924685418403427, "Bleu_3": 0.18643292680607412, "Bleu_4": 0.14941910307668207, "METEOR": 0.2769827104679439, "ROUGE_L": 0.3038184836745988, "CIDEr": 6.052224626852042e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.3333333333333333, "f": 0.27906976744186046, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a man standing on the side of a road, holding a stop sign. He is wearing a safety vest and appears to be directing traffic or ensuring the safety of the area. The stop sign is positioned in the middle of the scene, with the man standing to the right of it."}, "34071": {"image_id": 34071, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.17368336856959593, "Bleu_3": 0.10646139506643364, "Bleu_4": 1.2526942807511535e-05, "METEOR": 0.2365789195346667, "ROUGE_L": 0.26293103448275856, "CIDEr": 2.2621278651833454e-10, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09523809523809523, "f": 0.1, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a city street with two parking meters prominently placed on the sidewalk. The parking meters are positioned close to each other, with one on the left side and the other on the right side of the street. The sun is shining brightly in the background, creating a warm and"}, "555066": {"image_id": 555066, "Bleu_1": 0.4038461538383876, "Bleu_2": 0.30825739963656773, "Bleu_3": 0.22507957633966116, "Bleu_4": 0.1846909213573168, "METEOR": 0.2867368147393873, "ROUGE_L": 0.34502262443438914, "CIDEr": 2.5150869861864937e-10, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.11538461538461539, "f": 0.11111111111111112, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a busy street scene with multiple cars and traffic lights. There are two cars parked on the side of the road, and another car is driving down the street. A truck is also visible in the scene, parked near the center of the image.\n\nThere are several traffic lights"}, "448786": {"image_id": 448786, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 8.378836055206644e-07, "Bleu_4": 1.861395885683349e-09, "METEOR": 0.18075992900443605, "ROUGE_L": 0.23047858942065497, "CIDEr": 7.421472881686757e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 30.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.26666666666666666, "f": 0.30769230769230765, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a white bullet train parked at a train station. The train is positioned on the tracks, occupying a significant portion of the scene. The train appears to be waiting for passengers to board or disembark.\n\nThere are several people visible in the image, some of them standing near the"}, "324308": {"image_id": 324308, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.1287696884067729, "Bleu_3": 0.08902660440381878, "Bleu_4": 0.06258213843195243, "METEOR": 0.1796876471557337, "ROUGE_L": 0.236281471917366, "CIDEr": 3.4660578456208334e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2, "f": 0.23076923076923075, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a large bunch of green bananas hanging from a tree. The bananas are in various stages of ripeness, with some appearing ripe and ready to eat, while others are still unripe. The bananas are spread across the tree, with some bunches hanging higher up and others"}, "42837": {"image_id": 42837, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.23632829671335462, "Bleu_3": 0.13441091511289083, "Bleu_4": 1.5241326792946003e-05, "METEOR": 0.2734594456475013, "ROUGE_L": 0.29901960784313725, "CIDEr": 7.82907418005015e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image is a computer-generated (CGI) scene featuring a man surfing on a wave in a large body of water. The man is skillfully riding a surfboard, which is positioned in the middle of the scene. The wave appears to be a large, curling one, providing"}, "314690": {"image_id": 314690, "Bleu_1": 0.42592592591803846, "Bleu_2": 0.34719601577603876, "Bleu_3": 0.2531714451630168, "Bleu_4": 0.1757716421514516, "METEOR": 0.3504777950606482, "ROUGE_L": 0.3364854215918045, "CIDEr": 3.45708199737205e-10, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.3076923076923077, "f": 0.3404255319148936, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image is a black and white photo of a living room with a person sitting on a couch. The person is wearing red shoes and has their feet up on a coffee table. A television is placed on the table, and a laptop is situated nearby.\n\nIn the room, there are two ch"}, "263780": {"image_id": 263780, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.18535150310271878, "Bleu_3": 0.09352211318264238, "Bleu_4": 1.188474230301215e-05, "METEOR": 0.20790624445223035, "ROUGE_L": 0.24465240641711228, "CIDEr": 2.221719633453627e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.2, "f": 0.2181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a mother elephant and her baby walking together on a dirt road. The baby elephant is following closely behind the adult elephant, showcasing a strong bond between the two. The mother elephant appears to be protective and attentive to her young."}, "256035": {"image_id": 256035, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.21573723181113055, "Bleu_3": 0.1593617613384745, "Bleu_4": 0.11580903993958114, "METEOR": 0.2869298241211536, "ROUGE_L": 0.28018372703412076, "CIDEr": 3.1611896344246424e-08, "SPICE": {"All": {"pr": 0.3125, "re": 0.1724137931034483, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a woman wearing a black and white ski suit, skiing down a snow-covered slope. She is holding ski poles in her hands, and her skis are visible beneath her feet. The woman appears to be enjoying her time on the snowy terrain.\n\nIn the background"}, "413900": {"image_id": 413900, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.22404481344004462, "Bleu_3": 0.16002133902079144, "Bleu_4": 0.1143090498056583, "METEOR": 0.2792894043387131, "ROUGE_L": 0.26704190118824267, "CIDEr": 3.730447148960392e-10, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.2962962962962963, "f": 0.32653061224489793, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image depicts a group of people gathered in a room, playing a tennis video game on a large screen. There are at least five people in the scene, with some standing closer to the screen and others further away. They are all holding Wii remotes, actively engaged in the game."}, "357978": {"image_id": 357978, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1258455564244646, "Bleu_3": 0.06816612219878869, "Bleu_4": 8.966592262802168e-06, "METEOR": 0.2061081923594874, "ROUGE_L": 0.18373493975903615, "CIDEr": 7.601262695435297e-11, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.17857142857142858, "f": 0.2127659574468085, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features two women standing in front of a large screen, playing a video game together. They are both holding Wii remotes, fully engaged in the game. The women are positioned close to each other, with one woman on the left and the other on the right.\n\nIn the background, there"}, "521874": {"image_id": 521874, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.1584236068731305, "Bleu_3": 8.001066951039577e-07, "Bleu_4": 1.8073847727775389e-09, "METEOR": 0.24464272630075798, "ROUGE_L": 0.26116207951070336, "CIDEr": 1.7361137950789053e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a blue and red train traveling down the tracks, passing by a small building. The train is positioned in the middle of the scene, with the tracks running horizontally across the image. The train appears to be a small passenger train, possibly a trolley or a commuter train."}, "49517": {"image_id": 49517, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.20550493309104514, "Bleu_3": 0.11909718541937828, "Bleu_4": 1.3626273559929098e-05, "METEOR": 0.19893680155060445, "ROUGE_L": 0.22048192771084338, "CIDEr": 3.321301070459502e-11, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2631578947368421, "f": 0.27027027027027023, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a kitchen with a stove top oven and a countertop. On the stove, there are two large pots filled with food, one on the left side and the other on the right side. A third pot is placed on the countertop, closer to the right side of the kitchen."}, "67616": {"image_id": 67616, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.17583479290167828, "Bleu_3": 0.08890352562172174, "Bleu_4": 1.1306342156768618e-05, "METEOR": 0.1810564336484953, "ROUGE_L": 0.2378476735118274, "CIDEr": 2.008480294672471e-07, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.125, "f": 0.10256410256410256, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image depicts a busy city street with a row of tables and chairs set up on the sidewalk, likely for outdoor dining. There are several people sitting at the tables, enjoying their meals and the atmosphere. The tables are adorned with white tablecloths, and there"}, "154071": {"image_id": 154071, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 0.10556671919572966, "Bleu_4": 1.2447904522737402e-05, "METEOR": 0.2384622337708957, "ROUGE_L": 0.30049261083743845, "CIDEr": 8.94505713181893e-11, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.03571428571428571, "f": 0.04, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image captures a baseball game in progress, with a batter swinging a baseball bat at a pitch. The batter is in the middle of the scene, holding the bat and preparing to hit the ball. The catcher is positioned behind the batter, ready to catch the ball if the batter misses."}, "351133": {"image_id": 351133, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1889822365007167, "Bleu_3": 0.11497181007363186, "Bleu_4": 1.3481992110749651e-05, "METEOR": 0.24014239081128705, "ROUGE_L": 0.30329397141081416, "CIDEr": 1.4187124944421022e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a woman standing in a bathroom, holding a blue toothbrush in her hand. She is smiling and appears to be enjoying her time in the bathroom. The bathroom has a sink and a mirror, which is visible in the background.\n\nThere are several objects placed around"}, "270165": {"image_id": 270165, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.2729648400776508, "Bleu_3": 0.19663573608904716, "Bleu_4": 1.994970724061462e-05, "METEOR": 0.2617368011081236, "ROUGE_L": 0.34091816367265465, "CIDEr": 3.4629187691816797e-09, "SPICE": {"All": {"pr": 0.3, "re": 0.2608695652173913, "f": 0.27906976744186046, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a red cow statue hanging from a rope in front of a building. The cow statue is wearing a pink hat, adding a whimsical touch to the scene. The building has a window with blinds, and the cow statue is positioned in front of it. The cow statue"}, "200250": {"image_id": 200250, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.15534712747310678, "Bleu_3": 7.8441426562788e-07, "Bleu_4": 1.7715772413454909e-09, "METEOR": 0.1957522262716606, "ROUGE_L": 0.2652173913043478, "CIDEr": 8.939258389011746e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a woman walking down a city street, passing by a large truck with a political advertisement on its side. She is wearing boots and a white sweater, and she appears to be enjoying her walk. There are several other people in the scene, some of whom are walking or"}, "302990": {"image_id": 302990, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.1609148974309868, "Bleu_4": 0.12770357013671624, "METEOR": 0.28275427489794985, "ROUGE_L": 0.3335358444714459, "CIDEr": 4.078048284049124e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.17647058823529413, "f": 0.1935483870967742, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image captures a man skillfully riding a wave on a surfboard in the ocean. He is wearing a black wetsuit and appears to be enjoying the thrill of the ride. Another person can be seen in the background, possibly watching the surfer or waiting for their turn to catch"}, "147425": {"image_id": 147425, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.08668270200700183, "Bleu_4": 1.0908370302144318e-05, "METEOR": 0.1882442017821972, "ROUGE_L": 0.24190350297422336, "CIDEr": 2.0171008648261362e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a large, fluffy, and striped cat sitting on a couch. The cat is positioned in the center of the couch, occupying a significant portion of the space. The couch appears to be a blue fabric, providing a comfortable and cozy environment for the cat to relax"}, "152245": {"image_id": 152245, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.17583479290167828, "Bleu_3": 8.890352562172177e-07, "Bleu_4": 2.0105835460236694e-09, "METEOR": 0.17972495154305881, "ROUGE_L": 0.190625, "CIDEr": 4.3305847183037585e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.22727272727272727, "f": 0.24390243902439024, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a busy airport baggage claim area with a large number of suitcases and backpacks waiting to be picked up by their owners. There are at least 13 suitcases and 5 backpacks visible in the scene, with some of them placed on a lugg"}, "191689": {"image_id": 191689, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.18389242811841477, "Bleu_3": 9.159919831148882e-07, "Bleu_4": 2.056135070108479e-09, "METEOR": 0.1908001392984904, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.3744860524407617e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a large brown bear standing in a grassy area, surrounded by a fence. The bear is positioned near a rock, possibly investigating it or exploring its surroundings. The fence encloses the bear, keeping it within a designated area.\n\nIn addition to the bear"}, "51484": {"image_id": 51484, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.17614871215260033, "Bleu_3": 0.11049527392440639, "Bleu_4": 1.315844739913602e-05, "METEOR": 0.23713725535839716, "ROUGE_L": 0.23461538461538461, "CIDEr": 8.894591797265097e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features a beach scene with two people walking along the shore, each carrying a surfboard. They are likely preparing to go surfing or have just finished a surfing session. The surfboards are positioned horizontally, with one closer to the left side of the image and the"}, "66181": {"image_id": 66181, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.0560772154081562, "Bleu_3": 3.9251522966741233e-07, "Bleu_4": 1.0435177484324181e-09, "METEOR": 0.14947479110914674, "ROUGE_L": 0.20962199312714777, "CIDEr": 5.338114507793112e-13, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a black frame with three pictures of children, each with a different pose and expression. The pictures are placed in a row, with the first child on the left, the second child in the middle, and the third child on the right.\n\nIn the background, there is a vase with a"}, "289263": {"image_id": 289263, "Bleu_1": 0.4347826086862004, "Bleu_2": 0.29488391230331257, "Bleu_3": 0.18099097209374854, "Bleu_4": 0.10836164032974355, "METEOR": 0.27472281316987524, "ROUGE_L": 0.2827814569536423, "CIDEr": 3.466601956968807e-08, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.3684210526315789, "f": 0.32558139534883723, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a beautiful young woman standing on a beach, posing with her surfboard. She is wearing a bikini and appears to be enjoying her time at the beach. The surfboard is placed horizontally on the sand, with the woman standing next to it.\n\nIn"}, "536426": {"image_id": 536426, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.23045544793969702, "Bleu_3": 0.10070635369456069, "Bleu_4": 1.1895976831560022e-05, "METEOR": 0.26084265212299806, "ROUGE_L": 0.31077147016011636, "CIDEr": 6.074797101256446e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a white fire hydrant situated on the side of a street, with a pink and orange traffic cone placed next to it. The fire hydrant is located near the curb, and the cone is positioned in front of it. The scene appears to be a street corner, with a car park"}, "377814": {"image_id": 377814, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.0914699403543824, "Bleu_4": 1.129625096611556e-05, "METEOR": 0.20636708585163516, "ROUGE_L": 0.2776332899869961, "CIDEr": 1.1026768114740353e-06, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2608695652173913, "f": 0.2608695652173913, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a box filled with a variety of delicious donuts. There are six donuts in total, each with different flavors and toppings. The donuts are arranged in a visually appealing manner, with some placed closer to the front of the box and others towards the back. The assort"}, "411754": {"image_id": 411754, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.11072431282861321, "Bleu_4": 0.08627614350761502, "METEOR": 0.254202388745293, "ROUGE_L": 0.29397590361445786, "CIDEr": 1.1786663530684409e-11, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.10714285714285714, "f": 0.13333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man wearing a red shirt, sitting on a bench and looking at his cell phone. He appears to be engaged in a conversation or browsing the internet. There are several other people in the scene, some of them sitting on benches and others standing or walking around.\n\nIn"}, "340034": {"image_id": 340034, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.2277316449803929, "Bleu_3": 0.1652150636465604, "Bleu_4": 0.10005391875419714, "METEOR": 0.2990627449183255, "ROUGE_L": 0.29901960784313725, "CIDEr": 7.42050311850259e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a young boy sitting on a toilet, engrossed in playing a game on his cell phone. He is wearing a black shirt and appears to be focused on the screen. The toilet is located in a bathroom, and the boy is seated on the toilet"}, "193050": {"image_id": 193050, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.11605177063500235, "Bleu_3": 0.07980300087819453, "Bleu_4": 0.05591310122421515, "METEOR": 0.24604324526505586, "ROUGE_L": 0.2513243084167157, "CIDEr": 4.917776359303459e-13, "SPICE": {"All": {"pr": 0.3125, "re": 0.22727272727272727, "f": 0.2631578947368421, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a group of sheep grazing in a lush green field. There are at least six sheep visible in the scene, with some standing closer to the foreground and others further in the background. The sheep are scattered throughout the field, with some closer to the fence and others more towards the center."}, "217269": {"image_id": 217269, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.12186787521464361, "Bleu_4": 1.3863341114193003e-05, "METEOR": 0.24002629382591492, "ROUGE_L": 0.2897862232779097, "CIDEr": 9.258637004592369e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.0967741935483871, "f": 0.10526315789473684, "fn": 28.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a computer desk with a desktop computer setup. The computer monitor is placed on a stand, and a keyboard is positioned in front of it. A mouse can be seen on the desk as well. The desk is surrounded by various cords, indicating that it is a busy workspace."}, "437290": {"image_id": 437290, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.1390596095466697, "Bleu_4": 0.0865148073184506, "METEOR": 0.2141539326638609, "ROUGE_L": 0.26704190118824267, "CIDEr": 1.115064104053025e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a lively scene at a convention, with a group of people gathered in a room. Among the crowd, there are several individuals dressed in costumes, including a man dressed as a demon and a woman dressed as a fairy. They are interacting with each other, possibly discussing their"}, "282928": {"image_id": 282928, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.10079509744376741, "Bleu_3": 5.840314225182713e-07, "Bleu_4": 1.4128129251678322e-09, "METEOR": 0.16923153740219532, "ROUGE_L": 0.20331074325074994, "CIDEr": 3.464630842283318e-11, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.25925925925925924, "f": 0.2641509433962264, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a person holding a hot dog bun in their hand, with a hot dog sticking out of it. The person is wearing a ring on their finger, and their hand is positioned in the foreground of the scene. The hot dog appears to be partially eaten, as the person is"}, "188084": {"image_id": 188084, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.11497181007363187, "Bleu_4": 0.07581481309764793, "METEOR": 0.1860689962528826, "ROUGE_L": 0.27354260089686094, "CIDEr": 3.4728971015448568e-09, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.17391304347826086, "f": 0.15384615384615385, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a dining table with a sandwich and a cup of coffee placed on it. The sandwich is cut in half, revealing its contents, and is accompanied by a side of carrots. The cup of coffee is positioned next to the sandwich, creating a pleasant meal setup."}, "552320": {"image_id": 552320, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.06317667074948415, "Bleu_3": 4.277412148886299e-07, "Bleu_4": 1.1185188895571612e-09, "METEOR": 0.1611399847204965, "ROUGE_L": 0.20209828823854226, "CIDEr": 1.5431880742423776e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.26666666666666666, "f": 0.26666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5454545454545454, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image features two men standing in a kitchen, both pointing at a large pizza placed on a cutting board. The pizza is placed on a dining table, which is located in the background. The men seem to be excited about the pizza, possibly discussing its size or preparing to enjoy it together"}, "530313": {"image_id": 530313, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.15569978882944752, "Bleu_3": 0.11112381532950555, "Bleu_4": 0.08523383334872277, "METEOR": 0.21895315398782905, "ROUGE_L": 0.2127164942461932, "CIDEr": 2.097872629831353e-12, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image features a group of people sitting together in a room, with some of them wearing wigs. There are at least six people in the scene, with some sitting closer to the front and others further back. A man in the center of the group is wearing a wig, and another person nearby is"}, "242060": {"image_id": 242060, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.11429089766174176, "Bleu_3": 0.06350643060633274, "Bleu_4": 8.460008059351496e-06, "METEOR": 0.1679821932678827, "ROUGE_L": 0.24707788450410828, "CIDEr": 2.6249033732715033e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.23076923076923078, "f": 0.16216216216216217, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a wooden dining table with a plate of delicious cakes placed on it. The cakes are arranged in a visually appealing manner, with some of them having a hole in the center. There are a total of six cakes on the plate, with some of them being closer to the"}, "391214": {"image_id": 391214, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 0.08556026937263805, "Bleu_4": 1.0861779420621467e-05, "METEOR": 0.20826961049811488, "ROUGE_L": 0.2675438596491228, "CIDEr": 1.6692706402629391e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.1724137931034483, "f": 0.19230769230769232, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a surfer riding a wave in the ocean. The surfer is skillfully balancing on their surfboard, which is positioned in the middle of the wave. The wave is large and powerful, providing an exciting ride for the surfer. The scene is set against a back"}, "482367": {"image_id": 482367, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.1426954482435772, "Bleu_3": 0.07412250338267956, "Bleu_4": 9.548024812134783e-06, "METEOR": 0.22191228605355662, "ROUGE_L": 0.2167219327333018, "CIDEr": 2.894226883690959e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a tennis court with two men sitting on chairs, both holding tennis rackets. They appear to be taking a break from playing tennis. There are several other people in the scene, some of whom are also holding tennis rackets.\n\nIn addition to the people and tennis rackets, there are"}, "402334": {"image_id": 402334, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.14002800840008178, "Bleu_3": 7.319587495056677e-07, "Bleu_4": 1.681961051814596e-09, "METEOR": 0.1930226955427627, "ROUGE_L": 0.22536945812807885, "CIDEr": 2.2950116360526998e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1, "f": 0.11320754716981132, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a large brick church with a tall steeple and a cross on top. The church has a clock on its side, making it a prominent landmark in the area. The clock is positioned near the top of the building, and the steeple is visible above it. The church's"}, "469398": {"image_id": 469398, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.2799246944109327, "ROUGE_L": 0.27774615822424586, "CIDEr": 4.126477658843036e-11, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2, "f": 0.19607843137254902, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a person holding a cell phone in their hand, with a baby lying in front of them. The baby is positioned towards the left side of the scene, while the person is on the right side. The cell phone is prominently displayed in the person's hand, capturing the viewer"}, "316648": {"image_id": 316648, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 7.41784871677873e-07, "Bleu_4": 1.7166589196261759e-09, "METEOR": 0.21108080495717207, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.8151262044516117e-10, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a busy city street with a group of people walking down the sidewalk. Among them, there is a woman wearing a black dress and a man wearing a backpack. The group appears to be walking together, possibly as a family.\n\nThere are several cars parked along the"}, "254004": {"image_id": 254004, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1010152544531381, "Bleu_3": 6.010242872773113e-07, "Bleu_4": 1.4739391640949855e-09, "METEOR": 0.16323051082649878, "ROUGE_L": 0.20158625247851947, "CIDEr": 1.4223106133283199e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14285714285714285, "f": 0.14545454545454545, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a group of men wearing orange vests, standing around a luggage cart. They appear to be airport workers, possibly loading or unloading luggage from a plane. There are several suitcases and a backpack on the cart, indicating that they are handling a considerable amount of lug"}, "399369": {"image_id": 399369, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.25425669045977695, "Bleu_3": 0.1818494973816351, "Bleu_4": 0.10938852244325235, "METEOR": 0.2743694693820304, "ROUGE_L": 0.3286195286195286, "CIDEr": 3.370428603382206e-08, "SPICE": {"All": {"pr": 0.24, "re": 0.1935483870967742, "f": 0.21428571428571427, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a man running on a sandy beach, holding a white frisbee in his hand. He appears to be enjoying a game of frisbee on the beach. The man is wearing shorts, which are visible as he runs. The frisbee is positioned in"}, "206838": {"image_id": 206838, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.1505903985438184, "Bleu_4": 0.1196425813532057, "METEOR": 0.23617917654474044, "ROUGE_L": 0.25341246290801184, "CIDEr": 6.366065436362317e-12, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.11428571428571428, "f": 0.14285714285714285, "fn": 31.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two women riding horses in a body of water, possibly a lake or a river. They are both wearing bikinis and appear to be enjoying their time together. The horses are positioned close to each other, with one horse on the left side of the image and the other on"}, "146672": {"image_id": 146672, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.07126876576918603, "Bleu_4": 9.270974964697601e-06, "METEOR": 0.26897809084504837, "ROUGE_L": 0.2167219327333018, "CIDEr": 4.4038761088933625e-11, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a table with three clocks and a wine glass. The clocks are placed at different positions on the table, with one on the left side, another in the middle, and the third on the right side. The wine glass is positioned between the middle and right clocks.\n\nThe clock"}, "431256": {"image_id": 431256, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.14907119849663567, "Bleu_3": 8.024900879514216e-07, "Bleu_4": 1.87291227086443e-09, "METEOR": 0.17785449731129846, "ROUGE_L": 0.25902335456475584, "CIDEr": 4.271139948025738e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a snowboarder in mid-air, performing a trick on a snow-covered slope. The snowboarder is the main focus of the scene, with their snowboard clearly visible as they jump over a ramp.\n\nThere are several other people in the background, likely watching the"}, "506454": {"image_id": 506454, "Bleu_1": 0.38461538460798816, "Bleu_2": 0.26052505285439387, "Bleu_3": 0.15969209259965045, "Bleu_4": 0.09548024812134784, "METEOR": 0.25983788310202033, "ROUGE_L": 0.39019189765458434, "CIDEr": 9.21154922882944e-08, "SPICE": {"All": {"pr": 0.5217391304347826, "re": 0.42857142857142855, "f": 0.47058823529411764, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 12.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.8181818181818182, "re": 0.8181818181818182, "f": 0.8181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 9.0}}, "caption": "The image features a park with a wooden bench situated in the middle of a grassy field. The bench is positioned under a large tree, providing shade and a pleasant spot for visitors to sit and relax. The park is surrounded by a lush green field, creating a serene and inviting atmosphere"}, "212384": {"image_id": 212384, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1556997888288053, "Bleu_3": 0.0826106166220859, "Bleu_4": 1.0763774116165367e-05, "METEOR": 0.2047924471260335, "ROUGE_L": 0.28073635765943455, "CIDEr": 3.551147773690227e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a beautifully crafted cake that is designed to resemble a zebra and a giraffe. The cake is placed on a dining table, and it is surrounded by a few decorative elements. There are two giraffes on the left side of the cake,"}, "181969": {"image_id": 181969, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.16751484856166823, "Bleu_3": 0.14398798523187573, "Bleu_4": 0.12693173928949333, "METEOR": 0.2651630224225361, "ROUGE_L": 0.28222075346992725, "CIDEr": 1.1441652985795517e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a small brown dog curled up and sleeping on a couch. The dog is positioned in the center of the couch, with its body wrapped around and resting comfortably. The couch appears to be a sofa, providing a cozy and inviting space for the dog to"}, "450889": {"image_id": 450889, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.26042109924757323, "Bleu_3": 0.18066949544542255, "Bleu_4": 0.1272383399268874, "METEOR": 0.27739223002163843, "ROUGE_L": 0.33639705882352944, "CIDEr": 1.2233571551376164e-08, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13043478260869565, "f": 0.15, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man standing in a living room, holding a Wii remote and actively playing a video game. He appears to be enjoying the game, possibly a boxing game, as he is swinging the remote with enthusiasm.\n\nThe living room is furnished with a couch located"}, "84073": {"image_id": 84073, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.12121830534381622, "Bleu_3": 6.739562828886045e-07, "Bleu_4": 1.59753113202508e-09, "METEOR": 0.1828944750096426, "ROUGE_L": 0.22235722964763066, "CIDEr": 3.5314076886761166e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a refrigerator with a beer tap attached to it. The tap is connected to a small computer, which is likely used to control the beer dispensing system. The refrigerator is located in a room with a few other items, including a TV on the left side of"}, "293207": {"image_id": 293207, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.09522194049088256, "Bleu_4": 1.1835581532782098e-05, "METEOR": 0.21914606284485727, "ROUGE_L": 0.28817763080193687, "CIDEr": 3.939868409304613e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image captures a lively scene of two young men playing a game of frisbee in a grassy field. One of the men is in the process of catching the frisbee, while the other is running towards him, possibly trying to block the catch. The frisbee is"}, "431691": {"image_id": 431691, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.22404481344004462, "Bleu_3": 0.14538903521362667, "Bleu_4": 0.08945166560683261, "METEOR": 0.2819896878794216, "ROUGE_L": 0.25553560742070613, "CIDEr": 1.795892503199225e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.21428571428571427, "f": 0.15384615384615383, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man and a woman standing on a sidewalk, with the man eating a piece of food. The woman is looking at the man as he enjoys his snack. They are both positioned near a car, which is parked in the background.\n\nThere are a few other people"}, "218470": {"image_id": 218470, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.11895773785545558, "Bleu_3": 0.06522364605376364, "Bleu_4": 8.631003710817792e-06, "METEOR": 0.20294876393766184, "ROUGE_L": 0.2083096186681844, "CIDEr": 4.4730006239244376e-11, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.04, "f": 0.041666666666666664, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image features a city street with a large crane or cherry picker positioned above the street. The crane is being used to repair or maintain a traffic light, as it is suspended above the traffic light. The traffic light is located near the center of the scene, with the crane extending from"}, "9050": {"image_id": 9050, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.15943400149410503, "Bleu_4": 0.09688270405692424, "METEOR": 0.28744359449498985, "ROUGE_L": 0.32864411852738695, "CIDEr": 6.473320032569641e-09, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.23333333333333334, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a dining table with a white plate filled with a variety of food items. The plate contains a piece of meat, asparagus, and carrots, all arranged neatly. There are several wine glasses placed around the table, with some closer to the plate and others further away."}, "390769": {"image_id": 390769, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.2084219669570065, "Bleu_3": 0.0981091958911253, "Bleu_4": 1.2035916294672372e-05, "METEOR": 0.2561858522422018, "ROUGE_L": 0.29901960784313725, "CIDEr": 4.082179586966591e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.12903225806451613, "f": 0.14285714285714285, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a woman standing on a sidewalk, talking on her cell phone. She is wearing sunglasses and appears to be engaged in a conversation. The woman is positioned near the center of the scene, with her back facing the viewer.\n\nThe sidewalk is lined with several"}, "175718": {"image_id": 175718, "Bleu_1": 0.42222222221283956, "Bleu_2": 0.2938769068160246, "Bleu_3": 0.21574669736327218, "Bleu_4": 0.14787790645525567, "METEOR": 0.28117141375359483, "ROUGE_L": 0.38730158730158726, "CIDEr": 1.8040240086152475e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.12903225806451613, "f": 0.14285714285714285, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.0625, "f": 0.1, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a delicious pizza sitting on a wooden cutting board on a dining table. The pizza is topped with cheese and olives, making it a mouth-watering treat. Next to the pizza, there is a bottle of beer, adding to the overall ambiance of"}, "288430": {"image_id": 288430, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.0958411776672495, "Bleu_4": 0.06544158309931196, "METEOR": 0.2227696453555544, "ROUGE_L": 0.23416506717850286, "CIDEr": 1.5505458442533774e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a sandy beach with several people enjoying their time. A woman is prominently flying a large kite in the sky, while another person is holding a smaller kite. There are also a few other people scattered across the beach, some of them closer to the water.\n\nIn the"}, "568150": {"image_id": 568150, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.29020657841007313, "Bleu_3": 0.15413297340291793, "Bleu_4": 1.6889567906227443e-05, "METEOR": 0.2403566703867949, "ROUGE_L": 0.3388888888888889, "CIDEr": 4.306148495051344e-06, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a small bathroom with a white toilet situated next to a bathtub. The toilet is positioned in the corner of the room, and the bathtub is located towards the right side of the bathroom. The bathroom appears to be in need of repair, as there"}, "200109": {"image_id": 200109, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.08760206462900565, "Bleu_4": 1.0878661088479764e-05, "METEOR": 0.2648533168144168, "ROUGE_L": 0.22889305816135083, "CIDEr": 4.3228550732622935e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a cell phone with a message displayed on the screen. The message is written in a heartfelt manner, possibly expressing love or affection. The cell phone is being held by a person, who is partially visible in the scene.\n\nIn the background, there is a piece of pizza,"}, "292617": {"image_id": 292617, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.12386606438093092, "Bleu_4": 0.07891603089533021, "METEOR": 0.2225416062666408, "ROUGE_L": 0.30049261083743845, "CIDEr": 4.201807472652567e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2, "f": 0.2162162162162162, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a cozy living room with a fireplace as the focal point. The room features a couch situated near the left side of the room, and a chair placed in the middle. A coffee table is located in the center of the room, with a bowl placed on it. A"}, "467990": {"image_id": 467990, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.1518578172003014, "Bleu_3": 0.10998431114093206, "Bleu_4": 0.0714669931452011, "METEOR": 0.24749315355773485, "ROUGE_L": 0.25507765830346474, "CIDEr": 2.650654431846825e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a silver and yellow train traveling down the tracks, with a yellow front and a silver body. The train is positioned on the left side of the image, occupying a significant portion of the scene.\n\nThere are several people visible in the image, with one person standing near the middle of"}, "443713": {"image_id": 443713, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.2142857142812956, "Bleu_3": 0.1250180897226835, "Bleu_4": 1.4356222678314862e-05, "METEOR": 0.21021978432511637, "ROUGE_L": 0.30329397141081416, "CIDEr": 1.52518559285692e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.29411764705882354, "f": 0.22727272727272727, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a lively scene of a young man performing a skateboard trick on a ramp. He is in the middle of the trick, with his skateboard positioned on a rail. The skateboarder is surrounded by a crowd of people, some of whom are watching the performance int"}, "365129": {"image_id": 365129, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.17496355305240635, "Bleu_3": 0.08607650943307255, "Bleu_4": 1.0792921564506728e-05, "METEOR": 0.1899316039689331, "ROUGE_L": 0.25386444708680145, "CIDEr": 1.9924920275008646e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image captures a serene scene of a harbor filled with numerous boats of various sizes. The boats are docked in the water, with some closer to the shore and others further out. The sun is setting, casting a warm glow over the scene, creating a picturesque atmosphere.\n\nThe boats"}, "462904": {"image_id": 462904, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.22404481344004462, "Bleu_3": 1.0080712673232955e-06, "Bleu_4": 2.1493548313346258e-09, "METEOR": 0.1835066864791948, "ROUGE_L": 0.28113837999769564, "CIDEr": 2.0310990931979366e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.27586206896551724, "f": 0.3018867924528302, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a small horse standing in a dirt area near a restaurant. The horse is positioned close to a wooden deck with several chairs and dining tables arranged around it. There are at least 13 chairs and 10 dining tables in the scene, indicating that the area is likely"}, "3466": {"image_id": 3466, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.17857142856774635, "Bleu_3": 0.08787028385478016, "Bleu_4": 1.1020265663118309e-05, "METEOR": 0.24964617085612661, "ROUGE_L": 0.22578655151141266, "CIDEr": 1.3736601138281392e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a person wearing orange shoes and khaki pants standing on a red brick floor. The person is positioned in the center of the scene, with their feet standing on a white toilet. The toilet is located towards the bottom of the image, and the person's"}, "134760": {"image_id": 134760, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.07289725414308927, "Bleu_3": 4.942991774103207e-07, "Bleu_4": 1.2945692944860819e-09, "METEOR": 0.1218750354501466, "ROUGE_L": 0.16158940397350993, "CIDEr": 3.266740364180636e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a snowy ski slope with several skiers and snowboarders enjoying the winter sports. There are at least 13 people visible on the slope, some of them skiing and others snowboarding. The skiers and snowboarders are scattered across the slope, with some closer to"}, "364705": {"image_id": 364705, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.14979742339481708, "Bleu_4": 0.10878661088479764, "METEOR": 0.20786140721779048, "ROUGE_L": 0.22889305816135083, "CIDEr": 1.50468473663294e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2777777777777778, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a large group of white teddy bears arranged on a blue surface. There are at least 14 teddy bears in the scene, varying in size and position. Some of the teddy bears are sitting on the floor, while others are standing or lying down. The arrangement creates a"}, "191296": {"image_id": 191296, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2474358296475945, "Bleu_3": 0.15751292285925483, "Bleu_4": 0.11417083671725523, "METEOR": 0.2767915091575876, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.3414329618308614e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.16, "f": 0.17777777777777778, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a fire hydrant sitting in a grassy field, surrounded by tall grass and weeds. The hydrant is rusted and appears to be old, giving it a vintage appearance. The hydrant is positioned in the middle of the grass, with the surrounding vegetation reaching up to its"}, "457817": {"image_id": 457817, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.10987673829748816, "Bleu_4": 1.2961487777593183e-05, "METEOR": 0.27186842582232923, "ROUGE_L": 0.2692307692307692, "CIDEr": 7.190609759204885e-11, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.38095238095238093, "f": 0.3333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.875, "f": 0.6666666666666667, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image captures a man in the middle of a tennis court, swinging a tennis racket with great force. He is wearing a white shirt and appears to be in the middle of a powerful serve. The tennis ball is visible in the air, close to the man's racket."}, "531995": {"image_id": 531995, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.12674769789184412, "Bleu_4": 0.09548024812134782, "METEOR": 0.24592893490258344, "ROUGE_L": 0.2771467514766015, "CIDEr": 6.108340868139143e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.23809523809523808, "f": 0.21276595744680848, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a black and white cat standing on a carpeted floor, wearing a pair of black boots. The cat appears to be playing with a toy mouse, which is located on the floor near the cat's feet. The scene is set in a room with a fireplace, and there"}, "276673": {"image_id": 276673, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.1756183353427233, "Bleu_3": 0.1065450254190632, "Bleu_4": 0.07013057213023403, "METEOR": 0.17862838915470491, "ROUGE_L": 0.21721068249258166, "CIDEr": 4.991153306799102e-08, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3333333333333333, "f": 0.3255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress, with a batter holding a baseball bat and preparing to swing at an incoming pitch. The batter is positioned near the center of the scene, while the pitcher is located on the left side of the image.\n\nThere are several other players on the field,"}, "112800": {"image_id": 112800, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.08217664461402949, "Bleu_4": 1.0264051022519406e-05, "METEOR": 0.18826539543350115, "ROUGE_L": 0.24811156304474144, "CIDEr": 1.1366361275371218e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a small airplane flying low over a lake, with a boat nearby. The airplane is positioned towards the center of the scene, while the boat is located on the left side of the lake. The boat appears to be a small watercraft, possibly a speedboat or a similar type of"}, "390685": {"image_id": 390685, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.22562131409418867, "Bleu_3": 0.15969209259965045, "Bleu_4": 0.11354579040813202, "METEOR": 0.23001032230001553, "ROUGE_L": 0.2760180995475113, "CIDEr": 2.6051325633958104e-10, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.36363636363636365, "f": 0.32653061224489793, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a stop sign on a pole, positioned on the side of a street. The stop sign is red and white, and it is clearly visible for drivers and pedestrians. The pole holding the stop sign is located near a tree, which adds a touch of nature to the scene."}, "195002": {"image_id": 195002, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.11764652669092619, "Bleu_4": 0.09172809483333236, "METEOR": 0.23958615120582916, "ROUGE_L": 0.26940063091482647, "CIDEr": 4.514604436525199e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.13793103448275862, "f": 0.14814814814814817, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a little girl wearing a yellow dress and a crown, sitting in a chair and holding a donut with frosting and sprinkles. She appears to be enjoying her treat. Another person is present in the scene, sitting next to the girl and smiling.\n\nThe room has"}, "104626": {"image_id": 104626, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.2363282967133546, "Bleu_3": 0.16934714128636405, "Bleu_4": 0.12120981066002942, "METEOR": 0.2639338635735221, "ROUGE_L": 0.27371794871794874, "CIDEr": 2.3359564114677255e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.27586206896551724, "f": 0.3018867924528302, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a blue truck with a white tarp covering its back, parked in a parking lot. The truck is positioned in the middle of the scene, and the tarp is covering the majority of the truck's back. The truck appears to be a delivery truck,"}, "291370": {"image_id": 291370, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.0804252399656011, "Bleu_4": 1.0203142794069551e-05, "METEOR": 0.146967675628051, "ROUGE_L": 0.20408163265306123, "CIDEr": 7.58818536931606e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.16666666666666666, "f": 0.13636363636363638, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image depicts a lively street scene with a group of people gathered around a woman wearing a large hat. The woman is holding a bouquet of flowers, and a man is shaking her hand. The group consists of various individuals, some of whom are holding cell phones, possibly capturing the"}, "434804": {"image_id": 434804, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 0.07901769277795581, "Bleu_4": 1.0290348647814142e-05, "METEOR": 0.17018485832798605, "ROUGE_L": 0.24416277518345564, "CIDEr": 7.729285850070064e-09, "SPICE": {"All": {"pr": 0.35, "re": 0.5, "f": 0.4117647058823529, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 1.0, "f": 0.7692307692307693, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a group of four giraffes standing in a fenced enclosure, likely in a zoo. They are positioned close to each other, with one giraffe on the left side, another in the middle, and two more on the right side of the enclosure. The giraff"}, "143": {"image_id": 143, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.1905193970494735, "Bleu_3": 0.10903688982210127, "Bleu_4": 1.2390516745962157e-05, "METEOR": 0.2192582055184445, "ROUGE_L": 0.259298618490967, "CIDEr": 7.279518134067965e-14, "SPICE": {"All": {"pr": 0.3, "re": 0.2857142857142857, "f": 0.2926829268292683, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a group of birds perched on a tree branch in a snowy environment. There are nine birds in total, with some of them sitting closer to the top of the branch and others near the bottom. The birds are of various sizes, and their positions on the branch create a sense of depth and balance"}, "249219": {"image_id": 249219, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1348399724902187, "Bleu_3": 0.08765119647604921, "Bleu_4": 0.059703448811482686, "METEOR": 0.20741960346863472, "ROUGE_L": 0.21229698375870068, "CIDEr": 3.494561010132273e-14, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.3157894736842105, "f": 0.36363636363636365, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a large red and white bus driving down a street in a residential area. The bus is positioned in the middle of the street, and it appears to be a public transit bus. There are several people visible in the scene, some of them walking or standing near the bus, while others are"}, "19716": {"image_id": 19716, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.26042109924757323, "Bleu_3": 0.19462031420908787, "Bleu_4": 0.1345381642465729, "METEOR": 0.3384894301717855, "ROUGE_L": 0.38220551378446116, "CIDEr": 1.2231512816216282e-07, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.3888888888888889, "f": 0.3111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man wearing a suit and tie, standing in a large, open building with a glass ceiling. He is smiling and appears to be posing for a picture. The man is positioned near the center of the scene, and his suit is well-fitted and well-dress"}, "517973": {"image_id": 517973, "Bleu_1": 0.3399999999932, "Bleu_2": 0.24989793834546398, "Bleu_3": 0.18667437435977016, "Bleu_4": 0.1289871843779205, "METEOR": 0.28504450655521535, "ROUGE_L": 0.3294188239327962, "CIDEr": 1.8714651388884258e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a white Volkswagen Beetle with a surfboard strapped to its roof. The car is parked in a parking lot, and it appears to be the main focus of the scene. The surfboard is placed on top of the car, adding a unique and fun element to the"}, "23019": {"image_id": 23019, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.0714005547281277, "Bleu_3": 4.703296565188882e-07, "Bleu_4": 1.2133650006096253e-09, "METEOR": 0.1971150006589859, "ROUGE_L": 0.15259537210756724, "CIDEr": 2.211450619740066e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.20689655172413793, "f": 0.23529411764705882, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image captures a busy city street at dusk, with a large skyscraper towering over the surrounding buildings. The street is filled with traffic, including multiple cars and a truck, as well as a bus. The traffic appears to be moving in both directions, with some vehicles closer to the for"}, "177213": {"image_id": 177213, "Bleu_1": 0.3199999999936, "Bleu_2": 0.18070158057739935, "Bleu_3": 0.08794832144810152, "Bleu_4": 1.0968473790380014e-05, "METEOR": 0.2480794277041066, "ROUGE_L": 0.3550640279394645, "CIDEr": 2.710693595717463e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.2, "f": 0.24, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a delicious pizza with a generous amount of cheese and a green herb on top, placed on a white plate. The pizza is served on a dining table, and a fork is positioned nearby, ready to be used to enjoy the meal. The table is surrounded by"}, "514773": {"image_id": 514773, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.221323371633511, "Bleu_3": 0.15662032595896783, "Bleu_4": 1.664920847962604e-05, "METEOR": 0.23206623256145367, "ROUGE_L": 0.24811156304474144, "CIDEr": 2.742779042055848e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a wooden desk with a desktop computer setup, including a monitor, keyboard, and mouse. The monitor is positioned towards the center of the desk, while the keyboard and mouse are placed closer to the front. A chair is situated in front of the desk, ready for someone to sit and"}, "259253": {"image_id": 259253, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.194191754997615, "Bleu_3": 0.08927473462734822, "Bleu_4": 1.0815474806811216e-05, "METEOR": 0.24768418143191404, "ROUGE_L": 0.2731707317073171, "CIDEr": 8.398106174783538e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a group of sheep grazing in a grassy field under a tree. There are a total of nine sheep in the scene, with some standing closer to the tree and others scattered throughout the field. The sheep are of various sizes, indicating a mix of adults and younger members of the flock."}, "85340": {"image_id": 85340, "Bleu_1": 0.38461538460798816, "Bleu_2": 0.26052505285439387, "Bleu_3": 0.18933591164923458, "Bleu_4": 0.12901292604257922, "METEOR": 0.205868780235467, "ROUGE_L": 0.28175519630484985, "CIDEr": 5.520924431965424e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a group of three people, two women and a man, standing together and smiling. They are all holding a hot dog, which is placed on a tray. The hot dog is positioned in the center of the group, with the two women on either side of the man.\n\nThe"}, "94025": {"image_id": 94025, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.20159019488753482, "Bleu_3": 0.15853051819285777, "Bleu_4": 0.12434332373336153, "METEOR": 0.2256603347002726, "ROUGE_L": 0.3124644280022766, "CIDEr": 3.333500434680493e-11, "SPICE": {"All": {"pr": 0.1875, "re": 0.1111111111111111, "f": 0.13953488372093023, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a red stop sign with bullet holes in it, located near a train track. The stop sign is positioned in the middle of the scene, with the train tracks running horizontally across the image. The bullet holes are scattered across the sign, indicating that it has been vandalized or damaged"}, "21746": {"image_id": 21746, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.23644230070621639, "Bleu_3": 0.16261814409393693, "Bleu_4": 0.11395718302410143, "METEOR": 0.32164243340916104, "ROUGE_L": 0.2770478507704785, "CIDEr": 1.0360891241700812e-11, "SPICE": {"All": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6, "f": 0.631578947368421, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a woman playing tennis on a court, holding a tennis racket and preparing to hit a tennis ball. She is wearing a white shirt and appears to be focused on the game. There are several other people in the background, possibly watching the game or waiting for their turn to play."}, "338291": {"image_id": 338291, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.2399704669849505, "Bleu_3": 0.17777222549589156, "Bleu_4": 0.1294614399070719, "METEOR": 0.21308683807687384, "ROUGE_L": 0.29756097560975614, "CIDEr": 2.00917300201734e-07, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a snowboarder standing on a sidewalk, holding a snowboard in his hand. He is wearing a blue jacket and a helmet, which indicates that he is prepared for snowboarding. The snowboarder is smiling, possibly posing for a picture.\n\nIn the"}, "10142": {"image_id": 10142, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.10536048861866901, "Bleu_3": 6.271638431991356e-07, "Bleu_4": 1.538766030885031e-09, "METEOR": 0.18887817633955126, "ROUGE_L": 0.23297262889879056, "CIDEr": 3.965130915064892e-09, "SPICE": {"All": {"pr": 0.28, "re": 0.28, "f": 0.28, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a man skiing down a snow-covered path in a wooded area. He is wearing a blue jacket and appears to be enjoying his time on the snow-covered slope. Another person can be seen in the background, possibly skiing or walking along the same path."}, "327433": {"image_id": 327433, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.09829463743443755, "Bleu_3": 6.033032403124956e-07, "Bleu_4": 1.5032618275449672e-09, "METEOR": 0.1758800209098281, "ROUGE_L": 0.25452016689847007, "CIDEr": 4.169970354274279e-09, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.05263157894736842, "f": 0.04878048780487805, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features a lush green field with a giraffe standing prominently in the middle of the scene. The giraffe is surrounded by a herd of zebras, with some of them grazing in the grass. In total, there are five zebras visible in the field, with"}, "177935": {"image_id": 177935, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1889822365007167, "Bleu_3": 0.09125318612878565, "Bleu_4": 1.1336958836408244e-05, "METEOR": 0.2218917848597551, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.7613736296701026e-10, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.24242424242424243, "f": 0.2909090909090909, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a white stove top oven with a chrome finish, situated in a kitchen. The stove is equipped with four burners, and it is surrounded by various utensils and cooking tools. There are multiple knives placed around the stove, with some on the left side and others"}, "100354": {"image_id": 100354, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.10314212462370773, "Bleu_3": 0.06138158588631337, "Bleu_4": 8.466919880736143e-06, "METEOR": 0.13213213213213212, "ROUGE_L": 0.19551282051282048, "CIDEr": 3.048585238920089e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.17857142857142858, "f": 0.1886792452830189, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a group of goats in a fenced-in area, with one adult goat and two baby goats standing close together. The adult goat is positioned towards the left side of the image, while the two baby goats are located on the right side.\n\nIn the background,"}, "377326": {"image_id": 377326, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.221323371633511, "Bleu_3": 0.16871413170505073, "Bleu_4": 0.13028709730944066, "METEOR": 0.25304184768540766, "ROUGE_L": 0.2959369314736203, "CIDEr": 5.224367576775268e-12, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.32, "f": 0.3404255319148936, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a group of cows standing in a body of water, likely a river or a lake. There are five cows in total, with some of them drinking water from the river. The cows are spread out along the water's edge, with some closer to the foreground and others further"}, "300471": {"image_id": 300471, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.20597146021399534, "Bleu_3": 0.14738933945193888, "Bleu_4": 0.10534312981202536, "METEOR": 0.25392480529830885, "ROUGE_L": 0.32620320855614976, "CIDEr": 2.5332420181753638e-09, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.29411764705882354, "f": 0.23255813953488372, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a cat sitting on a yellow woven chair, which is placed on a sidewalk. The cat appears to be relaxed and comfortable on the chair. In the background, there is a black cat standing on a step, possibly observing the scene or waiting for its turn to join the cat on the"}, "512729": {"image_id": 512729, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.17204158993311794, "Bleu_3": 0.08898958910772611, "Bleu_4": 1.1450077782939158e-05, "METEOR": 0.18273268949847346, "ROUGE_L": 0.20890410958904113, "CIDEr": 1.8210652178378987e-06, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.35294117647058826, "f": 0.33333333333333337, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8333333333333334, "f": 0.625, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a white plate filled with a delicious meal consisting of broccoli and cauliflower. The broccoli is placed on the left side of the plate, while the cauliflower is on the right side. The dish appears to be a stir-fry, with the"}, "14151": {"image_id": 14151, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.23460952265358181, "Bleu_3": 0.13474197781741729, "Bleu_4": 1.5355502013332655e-05, "METEOR": 0.24491509987484184, "ROUGE_L": 0.30367143746110764, "CIDEr": 2.7316094991368014e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2631578947368421, "f": 0.24390243902439024, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a person skiing down a snow-covered slope, performing a jump in the air. The skier is wearing a red and white outfit, and their skis are visible as they glide through the air. The scene is set against a backdrop of a snowy hill,"}, "323726": {"image_id": 323726, "Bleu_1": 0.3399999999932, "Bleu_2": 0.22038926600328315, "Bleu_3": 0.10039526102358762, "Bleu_4": 1.2113243442494859e-05, "METEOR": 0.23088368284498617, "ROUGE_L": 0.22333414693678305, "CIDEr": 1.2930311798692007e-09, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.25, "f": 0.2631578947368421, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress, with a batter swinging a baseball bat and a catcher wearing a baseball glove, ready to catch the ball. The batter is in the middle of the swing, while the catcher is positioned behind him.\n\nThere are several other players on the"}, "270351": {"image_id": 270351, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.08932370012443137, "Bleu_3": 5.576887186735733e-07, "Bleu_4": 1.4011697930921417e-09, "METEOR": 0.16195839991938246, "ROUGE_L": 0.19551282051282048, "CIDEr": 5.886225348247281e-10, "SPICE": {"All": {"pr": 0.28, "re": 0.2, "f": 0.23333333333333334, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features three pigeons perched on a ledge or window sill, possibly on a building. They are standing close to each other, with one pigeon on the left side, another in the middle, and the third on the right side of the ledge. The pigeons seem to"}, "290113": {"image_id": 290113, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.11375929179665137, "Bleu_3": 6.415924230513621e-07, "Bleu_4": 1.5315603357857856e-09, "METEOR": 0.1738371648792819, "ROUGE_L": 0.18654434250764526, "CIDEr": 1.0124871268542984e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image captures a snowy scene with a woman wearing skis and standing on a snow-covered slope. She is the main focus of the scene, and she appears to be enjoying her time skiing. There are also two other people in the background, one of them closer to the right side"}, "535312": {"image_id": 535312, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.2526455763146363, "Bleu_3": 0.11153774373471463, "Bleu_4": 1.3251445746056094e-05, "METEOR": 0.17374809637874988, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.0034694078611042234, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image is a collage of four pictures showcasing a living room and kitchen area. The living room features a couch, a chair, and a TV. There is also a bicycle parked in the room, adding a unique touch to the space.\n\nThe kitchen area includes a dining"}, "478282": {"image_id": 478282, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.13093073413895012, "Bleu_3": 7.094917059707092e-07, "Bleu_4": 1.660297934705131e-09, "METEOR": 0.19091487306065144, "ROUGE_L": 0.2852466682253917, "CIDEr": 1.2010495320678196e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15384615384615385, "f": 0.14814814814814817, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a vase filled with a variety of colorful flowers, placed on a table. The vase is positioned in the center of the scene, and the flowers are arranged in a visually appealing manner. The flowers are of different sizes and colors, creating a vibrant and lively atmosphere"}, "64796": {"image_id": 64796, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.10067569617030046, "Bleu_4": 1.2138611630520416e-05, "METEOR": 0.19502310594777045, "ROUGE_L": 0.22732919254658387, "CIDEr": 2.1980260784287995e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.17647058823529413, "f": 0.14634146341463414, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a large blue vase filled with a variety of red and green flowers. The vase is placed on a small round table, which is positioned on a pedestal. The flowers in the vase are arranged in a visually appealing manner, creating a beautiful centerpiece for the table"}, "525297": {"image_id": 525297, "Bleu_1": 0.39215686273740874, "Bleu_2": 0.30678599553287267, "Bleu_3": 0.24861175312583292, "Bleu_4": 0.21757322176959526, "METEOR": 0.3387561832447939, "ROUGE_L": 0.3954619124797406, "CIDEr": 2.4378256064115984e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.09090909090909091, "f": 0.11940298507462685, "fn": 40.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.2222222222222222, "f": 0.27586206896551724, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a person holding a cell phone with a picture of a UFO on the screen. The UFO is hovering above a field where several cows are grazing. The person is holding the cell phone up to the camera, showcasing the image of the UFO and the cows. The"}, "158414": {"image_id": 158414, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.06475239082260723, "Bleu_3": 4.3201891081498714e-07, "Bleu_4": 1.1213327957896796e-09, "METEOR": 0.11631306989824397, "ROUGE_L": 0.22592592592592595, "CIDEr": 2.8652541787235617e-11, "SPICE": {"All": {"pr": 0.2903225806451613, "re": 0.32142857142857145, "f": 0.3050847457627119, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a display of Metro tickets on a wall. There are several rows of tickets, with each row containing a different number of tickets. The tickets are arranged in a way that makes it easy for people to find and select the ticket they need. The tickets are displayed in a visually"}, "170346": {"image_id": 170346, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.10698389124379477, "Bleu_4": 0.07144376414760542, "METEOR": 0.16983810205238242, "ROUGE_L": 0.22333414693678305, "CIDEr": 3.044338059900825e-10, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.28, "f": 0.2692307692307692, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a group of four horned animals, likely mountain goats, standing on a rocky hillside. They are positioned at various locations on the hill, with one goat standing closer to the left side, another in the middle, and two more towards the right side. The goats appear to"}, "328315": {"image_id": 328315, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.29014422873101564, "Bleu_3": 0.22067870246906, "Bleu_4": 0.17484203644715038, "METEOR": 0.26981327176732656, "ROUGE_L": 0.35777126099706746, "CIDEr": 1.4806547638933206e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.14285714285714285, "f": 0.15094339622641512, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a wooden desk with a computer setup, including a monitor, keyboard, and mouse. The desk is cluttered with various items, such as books, a cup, and a bottle. There are several books scattered around the desk, with some placed on the left side and others on"}, "113246": {"image_id": 113246, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.26052505285439387, "Bleu_3": 0.18933591164923458, "Bleu_4": 0.12901292604257922, "METEOR": 0.2916635142329874, "ROUGE_L": 0.30049261083743845, "CIDEr": 7.754400337138939e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a group of people gathered in a living room, enjoying a video game session. A woman is standing in the center of the room, holding a Wii remote, while a man sits on a couch nearby, smiling and watching her play. Another person is also present in the room,"}, "1290": {"image_id": 1290, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.16816819849581244, "Bleu_3": 0.08270007684490462, "Bleu_4": 1.0365265119381272e-05, "METEOR": 0.25768928888439985, "ROUGE_L": 0.26293103448275856, "CIDEr": 3.631924400135594e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3157894736842105, "f": 0.2926829268292683, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.8333333333333334, "f": 0.6666666666666667, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a young child sitting in a high chair, surrounded by a group of people. The child is wearing a bib and appears to be enjoying the moment. A birthday cake is placed in front of the child, with a candle on top, indicating that it is a special occasion."}, "292365": {"image_id": 292365, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.29738085706045825, "Bleu_3": 0.23616130129837049, "Bleu_4": 0.15469439948285735, "METEOR": 0.2999495522903142, "ROUGE_L": 0.27566171723692706, "CIDEr": 5.001768026184334e-10, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.03333333333333333, "f": 0.0392156862745098, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features a small, curious cat standing on a rug in front of a toilet. The cat appears to be looking at the toilet seat, possibly intrigued by the water inside. The cat is positioned close to the toilet, with its front paws on the edge of the"}, "246746": {"image_id": 246746, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.12326123997631012, "Bleu_4": 0.07903320424081517, "METEOR": 0.26794887606255274, "ROUGE_L": 0.3051907442151345, "CIDEr": 1.8974842983885747e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a woman riding a brown horse in a grassy field. She is wearing a white shirt and black pants, and she appears to be enjoying her time on the horse. The horse and rider are the main focus of the scene, with the woman skillfully guiding the horse"}, "328464": {"image_id": 328464, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.13026252642719696, "Bleu_3": 6.97519462339574e-07, "Bleu_4": 1.6222516606715129e-09, "METEOR": 0.1671327451474423, "ROUGE_L": 0.21131639722863746, "CIDEr": 1.285901040625931e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.21052631578947367, "f": 0.1702127659574468, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a small sailboat floating on a frozen lake. The boat is positioned in the middle of the lake, and it appears to be the only boat on the water. The frozen lake provides a serene and peaceful atmosphere, with no signs of other boats or people around. The boat"}, "420852": {"image_id": 420852, "Bleu_1": 0.3199999999936, "Bleu_2": 0.24243661068763242, "Bleu_3": 0.18293988070876474, "Bleu_4": 0.14060058991881091, "METEOR": 0.33237668927529984, "ROUGE_L": 0.33882913066478576, "CIDEr": 3.2607899573679743e-09, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.2962962962962963, "f": 0.3333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image captures a beautiful scene of two hot air balloons flying high in the sky, with power lines running above them. The balloons are positioned close to each other, creating a sense of harmony and balance in the scene.\n\nThe image also features a traffic light, which is located"}, "97646": {"image_id": 97646, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.15118578920063636, "Bleu_3": 0.07808966656031394, "Bleu_4": 1.0032766664400675e-05, "METEOR": 0.1737706008859501, "ROUGE_L": 0.23252858958068615, "CIDEr": 5.7029085885366375e-11, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two men walking down a dirt path in a wooded area. One of the men is carrying a skateboard, while the other is holding a bottle. They appear to be enjoying their time together in the forest.\n\nThe path is surrounded by trees, creating a serene and"}, "545796": {"image_id": 545796, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.20203050890627616, "Bleu_3": 0.0954066585882441, "Bleu_4": 1.172180673188117e-05, "METEOR": 0.2801919259156008, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.8216264734155133e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.23529411764705882, "f": 0.21052631578947367, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a young child, possibly a baby or toddler, brushing their teeth with a red toothbrush. The child is focused on the task, holding the toothbrush in their mouth. The scene takes place in a room with a chair visible in the background. The child appears to"}, "332407": {"image_id": 332407, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.1906925178456823, "Bleu_3": 0.13913760149235183, "Bleu_4": 0.08443342702964665, "METEOR": 0.2395469888688088, "ROUGE_L": 0.2663755458515284, "CIDEr": 1.0835554297879907e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.5, "f": 0.2, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a group of people, including a man and a young boy, playing baseball on a field. The man is holding a baseball bat, while the boy is holding a baseball glove, ready to catch the ball. There are several other people in the scene, some of them standing and others possibly waiting for"}, "204448": {"image_id": 204448, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.26937144541723856, "Bleu_3": 0.12299274718747141, "Bleu_4": 1.4875231298957957e-05, "METEOR": 0.224313697757796, "ROUGE_L": 0.3165307635285397, "CIDEr": 0.00043064387979861946, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a small, old-fashioned kitchen with wooden cabinets and a white stove. The kitchen is equipped with a sink, a microwave, and an oven. There is a window above the sink, providing natural light to the space.\n\nVarious utens"}, "480842": {"image_id": 480842, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.10767638040926633, "Bleu_3": 6.411053581337095e-07, "Bleu_4": 1.573366652415358e-09, "METEOR": 0.13675568972784594, "ROUGE_L": 0.16553595658073267, "CIDEr": 1.3612760726138007e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a group of three giraffes standing in a lush green field. The giraffes are positioned in a line, with one giraffe standing in the foreground, another in the middle, and the third one further back. They are surrounded by tall, green bushes and"}, "224155": {"image_id": 224155, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.3008284187922516, "Bleu_3": 0.22144862565722637, "Bleu_4": 0.145098599594937, "METEOR": 0.3190110106462735, "ROUGE_L": 0.3380541871921182, "CIDEr": 3.040194639792907e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2608695652173913, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man standing in a bathroom, holding up a cell phone in front of a mirror. He is taking a selfie, capturing his reflection in the mirror. The man is wearing a green shirt, and the cell phone is positioned at a slightly higher angle than the mirror. The"}, "303647": {"image_id": 303647, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.1968748077349065, "Bleu_3": 0.14154870398533734, "Bleu_4": 0.10912441388233995, "METEOR": 0.2371087214185818, "ROUGE_L": 0.3642999336429994, "CIDEr": 1.0890040797303056e-06, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.2857142857142857, "f": 0.1951219512195122, "fn": 10.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a delicious homemade pizza with a variety of toppings, including mushrooms, spinach, and cheese. The pizza is placed on a metal pan, which is sitting on top of a stove. The stove is equipped with a burner, and the p"}, "448868": {"image_id": 448868, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.12038585308312308, "Bleu_3": 0.06906098117642889, "Bleu_4": 9.355294087801786e-06, "METEOR": 0.17348698817926458, "ROUGE_L": 0.20691994572591585, "CIDEr": 2.612562870015165e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a snowy street with a line of trucks parked on the side of the road. There are several trucks in the scene, including a large tanker truck and a smaller truck. The tanker truck is positioned towards the left side of the image,"}, "360705": {"image_id": 360705, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.2084219669570065, "Bleu_3": 0.1414979456171808, "Bleu_4": 0.08907574685995524, "METEOR": 0.25963282349851, "ROUGE_L": 0.27371794871794874, "CIDEr": 3.569132886260102e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14285714285714285, "f": 0.1568627450980392, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a peaceful scene of a herd of cows resting in a lush green field. There are at least 14 cows scattered throughout the field, with some lying down and others standing. The cows are spread out, with some closer to the foreground and others further"}, "122678": {"image_id": 122678, "Bleu_1": 0.41509433961480957, "Bleu_2": 0.25270668299793647, "Bleu_3": 0.13579937089687322, "Bleu_4": 1.4959973266486896e-05, "METEOR": 0.2218099559845873, "ROUGE_L": 0.2993223771321754, "CIDEr": 0.00869711378758052, "SPICE": {"All": {"pr": 0.28, "re": 0.2413793103448276, "f": 0.25925925925925924, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a woman wearing a white shirt and headphones, standing in a room and drawing on a wall with a pencil. She appears to be focused on her task, possibly working on a project or creating a piece of art. The room has a few other items in it, such as"}, "253843": {"image_id": 253843, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.21312620972123467, "Bleu_3": 0.16346074019310983, "Bleu_4": 0.1266041277700147, "METEOR": 0.31305599855772, "ROUGE_L": 0.2738496071829405, "CIDEr": 2.7735390093950696e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a woman standing next to a brown and white horse in a dirt field. The woman is wearing a red jacket and appears to be leading the horse. Another person is also present in the scene, standing further back and observing the interaction between the woman and the horse.\n\nThe horse"}, "301421": {"image_id": 301421, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.0855482429777259, "Bleu_4": 0.059486144209873165, "METEOR": 0.1809076154153968, "ROUGE_L": 0.22195269860521533, "CIDEr": 4.104835693902687e-12, "SPICE": {"All": {"pr": 0.32, "re": 0.42105263157894735, "f": 0.3636363636363636, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6363636363636364, "re": 0.7, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image features a desk with a computer setup, including a monitor, keyboard, and mouse. The monitor is positioned towards the left side of the desk, while the keyboard and mouse are placed closer to the center. A cell phone is also visible on the desk, slightly to the right of the keyboard"}, "248965": {"image_id": 248965, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.31608146585600694, "Bleu_3": 0.23705307833386735, "Bleu_4": 0.1568658941364877, "METEOR": 0.37055358690616796, "ROUGE_L": 0.34945894334818584, "CIDEr": 6.108436755236947e-08, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2916666666666667, "f": 0.2916666666666667, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a young girl standing on a sandy beach, holding a colorful kite. The kite is large and has a rainbow pattern, making it a vibrant and eye-catching sight. The girl appears to be enjoying her time on the beach, possibly preparing to fly the"}, "274134": {"image_id": 274134, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.16823908657056308, "Bleu_4": 0.1418847468492011, "METEOR": 0.27769419141166524, "ROUGE_L": 0.40893854748603353, "CIDEr": 1.6327084946666612e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a cozy reading nook with a bench and a mirror on the wall. The bench is situated in front of a bookshelf filled with numerous books, creating a comfortable and inviting atmosphere for reading. The mirror on the wall adds a touch of elegance to the space."}, "527193": {"image_id": 527193, "Bleu_1": 0.340909090901343, "Bleu_2": 0.23557764908855597, "Bleu_3": 0.1876418158130923, "Bleu_4": 0.14827965596724016, "METEOR": 0.2724019159213724, "ROUGE_L": 0.2840606705694519, "CIDEr": 1.2958334295287188e-06, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.21052631578947367, "f": 0.17391304347826086, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a group of elephants in a dirt field, with two adult elephants and a baby elephant standing close together. The adult elephants are positioned on the left side of the baby elephant, creating a sense of family bonding.\n\nIn the background,"}, "277383": {"image_id": 277383, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.16329931618231128, "Bleu_3": 0.0816439893537324, "Bleu_4": 1.0318886931044728e-05, "METEOR": 0.21555123133225343, "ROUGE_L": 0.18654434250764526, "CIDEr": 2.91285913373746e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image captures a group of people playing a game of frisbee on a grassy field. There are at least 12 people in the scene, with some of them actively participating in the game, while others are watching or waiting for their turn. One man is in the middle of throwing"}, "417015": {"image_id": 417015, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.20195126571496114, "Bleu_3": 0.14932035830598486, "Bleu_4": 0.10852666491528783, "METEOR": 0.3038711397941366, "ROUGE_L": 0.3650508677438659, "CIDEr": 9.93012216221209e-10, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2608695652173913, "f": 0.28571428571428575, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a pink flower placed in a vase, which is sitting on a table. The vase is positioned in front of a mirror, reflecting the flower and the table. The table appears to be made of wood, and the vase is filled with chips, adding a unique touch to"}, "349525": {"image_id": 349525, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.18650096164396338, "Bleu_3": 0.13335528843258257, "Bleu_4": 0.08617684067542819, "METEOR": 0.2537659685121857, "ROUGE_L": 0.30451060795150653, "CIDEr": 5.122344135142072e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a silver toaster oven sitting on a table, with its door open. The toaster oven is placed next to a microwave, which is also open. A person can be seen in the background, possibly observing the appliances or preparing to use them.\n\nThere"}, "567254": {"image_id": 567254, "Bleu_1": 0.41176470587427916, "Bleu_2": 0.30097879541676964, "Bleu_3": 0.19482524762767495, "Bleu_4": 0.13248939509702828, "METEOR": 0.2406121466042318, "ROUGE_L": 0.3042123074182919, "CIDEr": 2.921189387810645e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1935483870967742, "f": 0.21052631578947367, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a young child with blonde hair, standing in front of a television. The child is holding a pink toothbrush, possibly getting ready to brush their teeth. The television is located on the left side of the room, and the child is positioned in the center of the scene."}, "19783": {"image_id": 19783, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.1448554036562842, "Bleu_4": 0.09015951515832439, "METEOR": 0.27740011312202645, "ROUGE_L": 0.3078864353312303, "CIDEr": 7.034290542643571e-09, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2631578947368421, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a beautiful scene of a person feeding a flock of seagulls on a beach. The person is standing near the water, holding food in their hand, and the birds are eagerly approaching to eat. There are at least nine seagulls in the scene, with some flying"}, "562292": {"image_id": 562292, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.2179708976339486, "Bleu_3": 0.15606146188116843, "Bleu_4": 0.09384750542850123, "METEOR": 0.2708863294312328, "ROUGE_L": 0.28773584905660377, "CIDEr": 3.064497085998939e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2, "f": 0.20689655172413796, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.35714285714285715, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a woman sitting on a concrete wall, holding a cell phone in her hand. She is wearing tight black pants and appears to be looking at her phone. Another person is sitting next to her, also holding a cell phone.\n\nThere are several handbags in the scene, with one"}, "538819": {"image_id": 538819, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.18625278992847225, "Bleu_3": 0.11552456765769871, "Bleu_4": 0.07693830154425157, "METEOR": 0.23687896669746558, "ROUGE_L": 0.2501708817498291, "CIDEr": 7.030178777528679e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.17647058823529413, "f": 0.16216216216216214, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two slices of pizza with various toppings, including peppers and cheese. The pizza slices are placed on a metal surface, possibly a cutting board or a pan. The pizza slices are cut in half, making them easier to eat. The toppings are spread evenly"}, "521259": {"image_id": 521259, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.2451550735724403, "Bleu_3": 0.11180754334250519, "Bleu_4": 1.3506443502756254e-05, "METEOR": 0.18248850505369588, "ROUGE_L": 0.27941368930768223, "CIDEr": 2.785732151666119e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a group of people gathered in a courtyard, with a man in a yellow shirt holding a frisbee. The man is preparing to throw the frisbee, while others watch and participate in the activity. There are at least 13 people in the"}, "470779": {"image_id": 470779, "Bleu_1": 0.3599999999928, "Bleu_2": 0.27105237086609907, "Bleu_3": 0.18293988070876474, "Bleu_4": 0.1068333456439781, "METEOR": 0.2164463465116009, "ROUGE_L": 0.30118144947980957, "CIDEr": 1.0196742158165518e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.11764705882352941, "f": 0.14035087719298242, "fn": 30.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a group of five people standing on a snow-covered slope, all wearing skis and posing for a picture. They are all smiling and enjoying their time together on the snowy hill. The group consists of three men and two women, all of whom are wearing ski g"}, "92053": {"image_id": 92053, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.15508644003992356, "Bleu_3": 0.08115433313646976, "Bleu_4": 1.0498339569158865e-05, "METEOR": 0.2593318509098148, "ROUGE_L": 0.23404527433175598, "CIDEr": 5.95005009968706e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 1.0, "f": 0.625, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a dining table with a variety of food and drinks. There are three plates of food, including a plate with a sausage, potatoes, and greens. A sandwich is also present on the table. In addition to the food, there are two glasses of beer,"}, "361687": {"image_id": 361687, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.12047318414543881, "Bleu_3": 6.577641517236671e-07, "Bleu_4": 1.5445790835941056e-09, "METEOR": 0.19241428346697806, "ROUGE_L": 0.24302788844621512, "CIDEr": 1.8157872194651022e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a baby lying in a crib, with one hand visible and the other hand holding a teddy bear. The baby's hand is positioned near the top of the crib, while the teddy bear is placed on the bed, close to the baby. The scene appears to be a co"}, "386879": {"image_id": 386879, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.2862879395127905, "Bleu_3": 0.23741054457209523, "Bleu_4": 0.2022332244523942, "METEOR": 0.29757561249446696, "ROUGE_L": 0.3285457809694794, "CIDEr": 2.2972570041285475e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a woman wearing a red dress and a red shirt, holding a tennis racket in her hand. She appears to be smiling and enjoying herself as she poses for the camera. The woman is standing in a grassy area, surrounded by trees, which adds a natural and serene"}, "461855": {"image_id": 461855, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.23431167444696221, "Bleu_3": 0.17760448410096263, "Bleu_4": 0.12360545409967114, "METEOR": 0.2817646427818922, "ROUGE_L": 0.3267857142857143, "CIDEr": 9.4796879405352e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.15151515151515152, "f": 0.18867924528301888, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is a black and white photograph of a young child sitting on a couch, smiling and holding a teddy bear. The child appears to be enjoying the company of the stuffed animal, which is placed on their lap. The couch is covered with a blanket, providing a cozy and"}, "315610": {"image_id": 315610, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.1390096093683277, "Bleu_3": 7.601144519394984e-07, "Bleu_4": 1.7876896610284684e-09, "METEOR": 0.16360282763134298, "ROUGE_L": 0.1927939317319848, "CIDEr": 1.2486208443901473e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a carnival ride with a large, colorful wheel in the center. The wheel is adorned with many small containers, each containing a different color. The ride is surrounded by a cloudy sky, creating a somewhat gloomy atmosphere.\n\nIn the background, two airplanes can"}, "419560": {"image_id": 419560, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.15971914124669148, "Bleu_3": 8.157154566934659e-07, "Bleu_4": 1.8533803782519565e-09, "METEOR": 0.25145613387884813, "ROUGE_L": 0.24190350297422336, "CIDEr": 5.966429677797174e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features two giraffes standing in a grassy field with trees in the background. The giraffes are positioned close to each other, with one giraffe on the left side and the other on the right side of the frame. They appear to be interacting with each other, possibly"}, "136271": {"image_id": 136271, "Bleu_1": 0.339622641503026, "Bleu_2": 0.16163173752903065, "Bleu_3": 8.001308872460666e-07, "Bleu_4": 1.7890738820867685e-09, "METEOR": 0.2317477430243898, "ROUGE_L": 0.27036011080332406, "CIDEr": 1.6744520293115693e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a grocery store with a fruit display filled with a variety of fruits. There are several oranges and apples arranged in the display, with some oranges placed in the middle and others towards the top and bottom of the display. The apples are spread across the display, with some located"}, "174633": {"image_id": 174633, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 8.587253589737383e-07, "Bleu_4": 1.926199466506815e-09, "METEOR": 0.2274863120518781, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.065362806364389e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1875, "f": 0.19999999999999998, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a man and a young child walking together on a snow-covered path. The man is holding the child's hand, providing support and guidance as they walk. They are both wearing skis, which are visible on their feet.\n\nIn the background, there are several cars parked"}, "122120": {"image_id": 122120, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2175844552512906, "Bleu_3": 0.1626625894743699, "Bleu_4": 0.10002271697505068, "METEOR": 0.2743414114126337, "ROUGE_L": 0.32317880794701986, "CIDEr": 9.087539030966246e-09, "SPICE": {"All": {"pr": 0.08, "re": 0.06896551724137931, "f": 0.07407407407407408, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a young man skillfully performing a trick on his skateboard, jumping into the air while riding it. He is wearing a red shirt and jeans, and his feet are firmly planted on the skateboard. The scene takes place in a park, with a"}, "34015": {"image_id": 34015, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.25392841118422627, "Bleu_3": 0.19778861023374, "Bleu_4": 0.13330899000704285, "METEOR": 0.3016861023298898, "ROUGE_L": 0.3670678336980307, "CIDEr": 2.9649292879786563e-09, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.19230769230769232, "f": 0.18181818181818185, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a man wearing a red shirt and white shorts, holding a tennis racket and walking across a tennis court. He appears to be a tennis player, possibly preparing for a match or taking a break. The tennis court is surrounded by a white fence, and there are several potted"}, "369460": {"image_id": 369460, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.23957871187003724, "Bleu_3": 0.18277755597330705, "Bleu_4": 0.1073378004247929, "METEOR": 0.24071313162872832, "ROUGE_L": 0.2982103884766477, "CIDEr": 1.2624789758853196e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10714285714285714, "f": 0.1276595744680851, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a woman standing on a sidewalk, talking on her cell phone. She is wearing a black shirt and appears to be engaged in a conversation. The woman is positioned near a row of payphones, with one of them being particularly noticeable in the foreground.\n\nThere are"}, "240049": {"image_id": 240049, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.15604075333783501, "Bleu_4": 0.13481992110749652, "METEOR": 0.2744014989913334, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.804313683913181e-06, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.25, "f": 0.17777777777777778, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a woman holding a young child in a pink jacket, both of them standing near a fence. They are observing a giraffe that is leaning over the fence, reaching for some leaves. The giraffe is located on the left side of the image, with its long"}, "168686": {"image_id": 168686, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.13026252642719696, "Bleu_3": 0.06975194623395738, "Bleu_4": 9.122591486542633e-06, "METEOR": 0.12655389606542872, "ROUGE_L": 0.21580188679245285, "CIDEr": 3.408034938006519e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a table with a variety of fresh fruits and vegetables. There are several apples, with one placed towards the top right corner of the table, another in the middle-right, and a third one in the bottom left corner. A cluster of blueberries can be seen in the middle of"}, "195172": {"image_id": 195172, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 7.606919312543152e-07, "Bleu_4": 1.7401885144332757e-09, "METEOR": 0.2670560066221466, "ROUGE_L": 0.3042123074182919, "CIDEr": 2.3162680930067744e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.20833333333333334, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a giraffe standing in a grassy field, with its head and neck raised, possibly looking for food. The giraffe is the main focus of the scene, and it appears to be walking through the tall grass. The field is surrounded by a lush green hillside, creating a pictures"}, "124798": {"image_id": 124798, "Bleu_1": 0.4313725490111496, "Bleu_2": 0.26271583096647133, "Bleu_3": 0.11209652142009935, "Bleu_4": 1.3088316619862389e-05, "METEOR": 0.24246166187608556, "ROUGE_L": 0.24497991967871488, "CIDEr": 5.537102437765845e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a busy city street with a blue and yellow bus driving down the road. The bus is surrounded by various vehicles, including cars and a truck, as it navigates through the traffic. There are multiple traffic lights in the scene, ensuring the safe flow of traffic.\n\nIn addition"}, "279809": {"image_id": 279809, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1922322627296484, "Bleu_3": 0.11391235988457692, "Bleu_4": 0.07411039308756416, "METEOR": 0.23408007939838305, "ROUGE_L": 0.22536945812807885, "CIDEr": 2.9199850055944025e-12, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.1724137931034483, "f": 0.19999999999999998, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two cats sitting next to each other on a window sill. One cat is positioned on the left side of the window, while the other cat is on the right side. Both cats are looking out the window, possibly observing the surroundings or watching birds outside. The scene capt"}, "170898": {"image_id": 170898, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.11741874968995038, "Bleu_4": 1.3772093427778417e-05, "METEOR": 0.27324230290408474, "ROUGE_L": 0.27799479166666663, "CIDEr": 1.4941243594692393e-09, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a large black dog lying on a couch, taking up a significant portion of the couch's surface. The dog appears to be sleeping or resting comfortably on the couch.\n\nIn the background, there are two pillows, one on the left side of the couch"}, "274411": {"image_id": 274411, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.24019223070296639, "Bleu_3": 0.17935189526395756, "Bleu_4": 0.13709157673970118, "METEOR": 0.3189151515695665, "ROUGE_L": 0.38741339491916865, "CIDEr": 1.526117027894658e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features a young girl standing on a tennis court, holding a tennis racket and a tennis ball. She appears to be preparing to serve the ball or practice her swing. The tennis court is surrounded by a chain-link fence, which provides a secure boundary for the game.\n\nIn the background"}, "449379": {"image_id": 449379, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 0.08411954328528157, "Bleu_4": 1.0608359163741716e-05, "METEOR": 0.19545721873836142, "ROUGE_L": 0.19830949284785435, "CIDEr": 1.9028764063401564e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.21052631578947367, "f": 0.17777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a cozy scene of three cats lying on a bed, enjoying each other's company. The cats are positioned in various ways, with one cat lying on its side, another on its back, and the third one curled up. The bed is covered with a red blanket"}, "475660": {"image_id": 475660, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.0855482429777259, "Bleu_4": 0.059486144209873165, "METEOR": 0.1574272486929333, "ROUGE_L": 0.30314743235781333, "CIDEr": 1.4875200570851992e-07, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a lively scene with a group of people gathered around a stage, possibly for a concert or a public event. There are several individuals standing on the stage, with some of them holding musical instruments, such as a trombone and a guitar. The crowd is watching and enjoying the performance."}, "125535": {"image_id": 125535, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.0804252399656011, "Bleu_4": 1.0203142794069551e-05, "METEOR": 0.2665667464707053, "ROUGE_L": 0.2966050186680559, "CIDEr": 5.5900487735655713e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a large bird perched on a tree branch, possibly a pelican, with its wings spread out. The bird is positioned in the center of the scene, taking up a significant portion of the frame. The tree is filled with green leaves, providing a lush backdrop for the bird."}, "353898": {"image_id": 353898, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.2243088616326247, "Bleu_3": 0.1570060918669648, "Bleu_4": 0.11099472319754804, "METEOR": 0.3016461315752946, "ROUGE_L": 0.3279569892473118, "CIDEr": 2.4764574307050456e-12, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.21428571428571427, "f": 0.26666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a man sitting on a stone bench in a park, surrounded by a large flock of birds. The birds are scattered around the bench, with some standing close to the man and others further away. The man appears to be enjoying the company of the birds, as he sits and watch"}, "177539": {"image_id": 177539, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.1096274741694192, "Bleu_4": 1.3230383778958117e-05, "METEOR": 0.23790877309474986, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.628529832096604e-08, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.3333333333333333, "f": 0.3243243243243243, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man standing on a beach, holding a surfboard. He is wearing a striped shirt and appears to be preparing to go surfing. The surfboard is positioned behind him, extending from the left side of the image to the right.\n\nIn addition to"}, "467791": {"image_id": 467791, "Bleu_1": 0.387755102032903, "Bleu_2": 0.20097551209269068, "Bleu_3": 0.09507422851111282, "Bleu_4": 1.1691161223351998e-05, "METEOR": 0.22991568794435585, "ROUGE_L": 0.2663755458515284, "CIDEr": 3.7358949506499085e-08, "SPICE": {"All": {"pr": 0.32, "re": 0.36363636363636365, "f": 0.3404255319148936, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress, with a batter standing at home plate, holding a baseball bat and preparing to swing. The catcher is positioned behind the batter, wearing a baseball glove, ready to catch the ball.\n\nThere are several other players on the field, including a"}, "197918": {"image_id": 197918, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.10942520359115704, "Bleu_3": 0.06169095833758949, "Bleu_4": 8.277965966610606e-06, "METEOR": 0.15892533380750098, "ROUGE_L": 0.21266705403834982, "CIDEr": 1.9387119465119387e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.23076923076923078, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a young girl and a young boy standing together in a room, surrounded by various stuffed animals. The girl is holding a stuffed panda bear, while the boy is holding a stuffed teddy bear. There are several other stuffed animals scattered around the room, including a few near the girl"}, "153524": {"image_id": 153524, "Bleu_1": 0.3599999999928, "Bleu_2": 0.19166296949610961, "Bleu_3": 0.11524490328511486, "Bleu_4": 1.3433582021760983e-05, "METEOR": 0.2493406063875144, "ROUGE_L": 0.27128335451080055, "CIDEr": 9.031063510085232e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2916666666666667, "f": 0.2692307692307692, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a wooden desk with two computer monitors placed on it. The monitors are positioned side by side, with one slightly larger than the other. A keyboard and a mouse are also placed on the desk, positioned in front of the monitors.\n\nIn addition to the computer setup"}, "449428": {"image_id": 449428, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.1892670629421493, "Bleu_3": 8.948014799671464e-07, "Bleu_4": 1.9554467787545266e-09, "METEOR": 0.18741371016287178, "ROUGE_L": 0.21131639722863746, "CIDEr": 2.1941237928543643e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3, "f": 0.2926829268292683, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a black and white cow grazing on grass in a field. The cow is positioned in the center of the scene, with its head down, eating the grass. Another cow is visible in the background, standing further away from the main cow.\n\nThere are also two other cows in"}, "231140": {"image_id": 231140, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.2474358296476976, "Bleu_3": 0.17215301886614504, "Bleu_4": 0.12138611630520416, "METEOR": 0.25288393871770176, "ROUGE_L": 0.27128335451080055, "CIDEr": 2.5229621795951884e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.16666666666666666, "f": 0.15, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a group of zebras grazing in a grassy field in front of a large, old building. There are five zebras in total, with some standing closer to the building and others further away. The zebras are spread out across the field, with some closer to the foreground"}, "540449": {"image_id": 540449, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.20604084591910862, "Bleu_3": 0.16085534342964874, "Bleu_4": 0.11359039689503823, "METEOR": 0.2987869107814186, "ROUGE_L": 0.3258160237388724, "CIDEr": 3.8621066978166174e-11, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.21212121212121213, "f": 0.25, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a black dog sitting in the back seat of a car. The dog appears to be relaxed and comfortable, occupying a significant portion of the seat. The car's interior is visible through the rear window, providing a clear view of the dog.\n\nIn addition to the dog, there are"}, "182755": {"image_id": 182755, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.26271583096647133, "Bleu_3": 0.20369289745731148, "Bleu_4": 0.11519181072008923, "METEOR": 0.28776874670740304, "ROUGE_L": 0.3730886850152905, "CIDEr": 1.3811904021338502e-10, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.30434782608695654, "f": 0.2978723404255319, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a wooden desk with a variety of electronic devices and accessories. There are three computer monitors placed on the desk, with one on the left side, one in the middle, and another on the right side. A laptop is also present on the left side of the desk."}, "159170": {"image_id": 159170, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.08491317075202565, "Bleu_4": 1.068333456439781e-05, "METEOR": 0.20740066736383198, "ROUGE_L": 0.19830949284785435, "CIDEr": 4.76998206678851e-10, "SPICE": {"All": {"pr": 0.28, "re": 0.25925925925925924, "f": 0.2692307692307692, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a large orange cat lying on a couch, resting its head on its paws. The cat appears to be sleepy and relaxed, occupying a significant portion of the couch. The couch is covered with a grey fabric, providing a comfortable surface for the cat to rest on."}, "408480": {"image_id": 408480, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1457945082861785, "Bleu_3": 0.07846510342081583, "Bleu_4": 1.029533066265393e-05, "METEOR": 0.19445727858753462, "ROUGE_L": 0.24238410596026488, "CIDEr": 1.4271817341841426e-08, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3181818181818182, "f": 0.3181818181818182, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a large boat docked next to a red lighthouse, creating a picturesque scene. The boat is positioned towards the right side of the image, while the lighthouse stands prominently in the middle.\n\nIn the background, there are several cars parked along the street,"}, "538242": {"image_id": 538242, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.14285714285419707, "Bleu_3": 0.07572431510387477, "Bleu_4": 9.856825261135735e-06, "METEOR": 0.2231022990563027, "ROUGE_L": 0.26341764342998153, "CIDEr": 1.7088289185017087e-09, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.13333333333333333, "f": 0.13114754098360656, "fn": 26.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.21428571428571427, "f": 0.21428571428571427, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image features a man sitting on a motorcycle, which is parked on a tarmac. The man appears to be wearing a military uniform, and he is surrounded by several bags, including a backpack and a handbag. Another person is standing nearby, possibly observing the scene or waiting for"}, "552153": {"image_id": 552153, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.10942520359115704, "Bleu_3": 6.16909583375895e-07, "Bleu_4": 1.4720536435426584e-09, "METEOR": 0.2238134811500847, "ROUGE_L": 0.226906385616863, "CIDEr": 7.105434392650932e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14814814814814814, "f": 0.16326530612244897, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a small airplane flying low over a mountainous area, with the mountain range visible in the background. The airplane is positioned towards the right side of the scene, and it appears to be flying close to the mountain range. The sky above the airplane is cloudy, adding to the dram"}, "63617": {"image_id": 63617, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.16870903059432618, "Bleu_4": 0.10001000249872885, "METEOR": 0.3194599165931219, "ROUGE_L": 0.27319257837492, "CIDEr": 1.4552476392869307e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a young boy wearing glasses, standing on a porch and attempting to catch a baseball with his catcher's mitt. He is focused on the ball, which is in the air, and appears to be making a funny face as he tries to catch it.\n\nThere are two"}, "366529": {"image_id": 366529, "Bleu_1": 0.43999999999120004, "Bleu_2": 0.2507132682061381, "Bleu_3": 0.1378418621736858, "Bleu_4": 1.536425067241173e-05, "METEOR": 0.26204894999728745, "ROUGE_L": 0.3090346186321419, "CIDEr": 9.231308653273878e-09, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.10526315789473684, "f": 0.0816326530612245, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a newly married couple, a man and a woman, standing together and smiling for a picture. The man is wearing a white suit with a red tie, while the woman is dressed in a white gown. They are both posing for the camera, capturing their special moment."}, "282841": {"image_id": 282841, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1577557537051747, "Bleu_3": 0.09984894236626275, "Bleu_4": 1.1938742404395867e-05, "METEOR": 0.15143567902066554, "ROUGE_L": 0.18373493975903615, "CIDEr": 1.8026275530711714e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a wooden table with a mirror placed on it. The mirror is positioned towards the left side of the table, and it appears to be a small, round mirror. A rope is hanging from the table, extending towards the right side. The rope is tied in a knot, adding"}, "169679": {"image_id": 169679, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.27355060221045585, "Bleu_3": 0.19967138586310745, "Bleu_4": 0.13639703043455445, "METEOR": 0.3034087708075686, "ROUGE_L": 0.3078864353312303, "CIDEr": 1.5171615589203025e-09, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a group of three people standing on a snow-covered slope, posing for a picture. They are all wearing ski gear and are positioned close to each other, with one person on the left, another in the middle, and the third person on the right.\n\nEach person"}, "427034": {"image_id": 427034, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.23763541030969576, "Bleu_3": 0.16642889932012636, "Bleu_4": 0.11772501252046863, "METEOR": 0.2778802284668627, "ROUGE_L": 0.26704190118824267, "CIDEr": 4.889904410449077e-09, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.19230769230769232, "f": 0.21276595744680848, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a small black and brown dog lying on a laptop computer, resting its head on the keyboard. The dog appears to be looking at the camera, capturing a cute and playful moment.\n\nIn the background, there is a person partially visible, likely the owner of the dog. The"}, "381527": {"image_id": 381527, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.19720265943222184, "Bleu_3": 0.15351083131080304, "Bleu_4": 0.1145643364316842, "METEOR": 0.27773942528483964, "ROUGE_L": 0.336783988957902, "CIDEr": 1.155480407415454e-07, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.14285714285714285, "f": 0.1395348837209302, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a skateboarder in action, performing a trick on a ramp at a skate park. The skateboarder is in the air, showcasing their skill and balance. There are several other people in the scene, watching the skateboarder and possibly waiting for their turn"}, "81661": {"image_id": 81661, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.10767861130247747, "Bleu_4": 1.2699504465465572e-05, "METEOR": 0.2549126625273795, "ROUGE_L": 0.3061224489795918, "CIDEr": 3.1691809970816935e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.20833333333333334, "f": 0.20408163265306126, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a wooden desk with a variety of items on it. A can of Coca-Cola is prominently placed on the desk, along with a remote control and a laptop. The remote control is located towards the left side of the desk, while the laptop is situated on the right"}, "501368": {"image_id": 501368, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.24866794885861784, "Bleu_3": 0.16154842718261028, "Bleu_4": 0.09950844432373991, "METEOR": 0.24186303512377, "ROUGE_L": 0.28968792401628224, "CIDEr": 6.507980647712845e-08, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.1935483870967742, "f": 0.24000000000000002, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a woman with long, wet hair, standing in a bathroom and brushing her hair with a black hairbrush. She is wearing a yellow towel, which is wrapped around her body. The bathroom appears to be dimly lit, creating a cozy atmosphere.\n\nIn the"}, "51119": {"image_id": 51119, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.20982172726164103, "Bleu_3": 0.17190279610259213, "Bleu_4": 0.14128129251683555, "METEOR": 0.2334635642849171, "ROUGE_L": 0.27949599083619703, "CIDEr": 1.5692238058090267e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.13793103448275862, "f": 0.16326530612244897, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image depicts a black bus that has been involved in a fire, with its roof and windows destroyed. The bus is parked on the side of a road, and the fire appears to have caused significant damage to the vehicle.\n\nThere are a few people in the scene, with one person standing close"}, "502006": {"image_id": 502006, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 0.12084372700297995, "Bleu_4": 0.09212480089239698, "METEOR": 0.2570359558960274, "ROUGE_L": 0.22241127856101123, "CIDEr": 8.202305207765447e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.15384615384615385, "f": 0.1846153846153846, "fn": 33.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.3125, "f": 0.3703703703703703, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a lush green field with two brown bears walking through it. One bear is larger and appears to be an adult, while the other is smaller and likely a younger bear. They are walking together, exploring the grassy area.\n\nIn the background, there are trees that provide a natural"}, "213457": {"image_id": 213457, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.192868005722087, "Bleu_3": 0.09455603100869434, "Bleu_4": 1.1841311663495051e-05, "METEOR": 0.19190824544164797, "ROUGE_L": 0.24238410596026488, "CIDEr": 5.6158461044845955e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a thrilling moment of a man performing a jump on a snowboard, flying through the air. He is skillfully riding the snowboard, showcasing his talent and athleticism.\n\nIn the background, there are several other people scattered around the scene, possibly watching the snow"}, "138549": {"image_id": 138549, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.08588393224796005, "Bleu_4": 1.0663135316252687e-05, "METEOR": 0.1888924255147482, "ROUGE_L": 0.25722891566265055, "CIDEr": 1.7452835299977605e-11, "SPICE": {"All": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a dining table with a plate of food and a glass of beer. The plate contains a sandwich cut in half, an orange slice, and a pickle. The sandwich is placed on the left side of the plate, while the orange slice is on the right side. The pickle"}, "579303": {"image_id": 579303, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.0799063530041829, "Bleu_4": 1.0207315006261666e-05, "METEOR": 0.1804990921660458, "ROUGE_L": 0.19830949284785435, "CIDEr": 4.0418418863627514e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a dining table with two sandwiches placed on it. One sandwich is located on the left side of the table, while the other is on the right side. Both sandwiches are served on wooden boards and are accompanied by a side of lettuce.\n\nIn addition to the"}, "351744": {"image_id": 351744, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.14754891442234067, "Bleu_3": 0.09486600651870754, "Bleu_4": 0.06428216024395343, "METEOR": 0.23505385014629682, "ROUGE_L": 0.25707405177603854, "CIDEr": 7.958248371496879e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a blue and yellow train traveling down the tracks, with a yellow front car. The train is quite long, occupying a significant portion of the scene. The train is moving through a train station, with a building visible in the background.\n\nThere are several people in the scene, with one"}, "521605": {"image_id": 521605, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.09319532338930898, "Bleu_4": 1.1580903993958116e-05, "METEOR": 0.23509646949264904, "ROUGE_L": 0.2675438596491228, "CIDEr": 7.611246631912027e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.13333333333333333, "f": 0.1142857142857143, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features a delicious and colorful meal served on a plate. The dish consists of a variety of food items, including a fried egg, broccoli, and potatoes. The broccoli is scattered throughout the plate, with some pieces placed near the center and others closer to the edges"}, "494439": {"image_id": 494439, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.10090091909748747, "Bleu_3": 5.8831069922091e-07, "Bleu_4": 1.4277627265895718e-09, "METEOR": 0.18527962141471996, "ROUGE_L": 0.15365239294710328, "CIDEr": 7.660602291883279e-12, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.23333333333333334, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07142857142857142, "f": 0.08695652173913043, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a train traveling down the tracks, with a blue and white train car leading the way. The train is surrounded by a lush green field, giving the scene a serene atmosphere. There are several people visible in the image, likely passengers or train staff, scattered along the train tracks."}, "209753": {"image_id": 209753, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.2556147957905549, "Bleu_3": 0.18452117548297922, "Bleu_4": 0.12528515491792497, "METEOR": 0.27773942528483964, "ROUGE_L": 0.3202099737532808, "CIDEr": 1.4746564428783315e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.16666666666666666, "f": 0.18867924528301885, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman wearing a black dress and a headband, standing in a room and looking at her cell phone. She is holding the cell phone in her hand, possibly texting or browsing. The room has a TV in the background, and there are two other people in the scene, one on"}, "435709": {"image_id": 435709, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.20935894733588342, "Bleu_3": 0.0932816953791531, "Bleu_4": 1.1124445062735476e-05, "METEOR": 0.2378097888179818, "ROUGE_L": 0.23775055679287305, "CIDEr": 1.6996955796305175e-13, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a city street with a large clock mounted on a pole near the center of the scene. The clock is positioned in front of a tall building, which is part of a row of buildings lining the street. The clock is visible from various angles, making it a prominent feature in the scene."}, "38029": {"image_id": 38029, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.13794014695833945, "Bleu_3": 7.680285411963504e-07, "Bleu_4": 1.82321151624697e-09, "METEOR": 0.253296297052028, "ROUGE_L": 0.306312769010043, "CIDEr": 3.3028621329523874e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.1724137931034483, "f": 0.19230769230769232, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a large, red fire hydrant-shaped vehicle, possibly a truck or a trailer, driving down a street. The fire hydrant is prominently displayed on the front of the vehicle, making it a unique and eye-catching sight.\n\nThere are several people in the"}, "434494": {"image_id": 434494, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.13736056394612134, "Bleu_3": 0.07132475068288914, "Bleu_4": 9.184122179475869e-06, "METEOR": 0.14151451063336667, "ROUGE_L": 0.21403508771929822, "CIDEr": 9.936790651051384e-12, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.3333333333333333, "f": 0.26315789473684204, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.8, "f": 0.5333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a group of construction workers standing on a road, working on a paved surface. There are five people in the scene, with some of them standing closer to the center of the road and others near the edges.\n\nA large yellow construction vehicle, possibly a road roller or a cement mix"}, "171062": {"image_id": 171062, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.20921530481644351, "Bleu_3": 0.14893279556267885, "Bleu_4": 0.10616941372973597, "METEOR": 0.2634042502941453, "ROUGE_L": 0.3444381705251271, "CIDEr": 3.695289592405898e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1875, "f": 0.19999999999999998, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a cat sitting on a wooden table in front of a television. The cat appears to be watching the TV screen, which is displaying a video game. The television is positioned on the left side of the table, while the cat is situated on the right side.\n\nIn the background, there is"}, "238866": {"image_id": 238866, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.10281451514171928, "Bleu_3": 6.313737539096188e-07, "Bleu_4": 1.5740514693995106e-09, "METEOR": 0.11682701037803668, "ROUGE_L": 0.17579250720461098, "CIDEr": 1.2550078797256393e-08, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.25, "f": 0.2592592592592593, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a large tray filled with a variety of doughnuts. There are at least 14 doughnuts on the tray, each with different shapes and sizes. Some doughnuts are placed closer to the front of the tray, while others are positioned further back."}, "428454": {"image_id": 428454, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.11113289333084049, "Bleu_4": 0.07274999134048009, "METEOR": 0.17712242065347059, "ROUGE_L": 0.26293103448275856, "CIDEr": 7.50760977784888e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a snowy field with a man standing on a snowboard, holding onto a kite. The kite is flying high in the sky, adding a sense of excitement to the scene. The man appears to be enjoying his time on the snowboard, possibly preparing to ride or having just finished"}, "200945": {"image_id": 200945, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.16205747826449043, "Bleu_3": 0.0848444097298203, "Bleu_4": 1.0981334023238417e-05, "METEOR": 0.2310779338478515, "ROUGE_L": 0.30091613812544044, "CIDEr": 1.6969245611841914e-07, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.17391304347826086, "f": 0.19999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07692307692307693, "f": 0.125, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a delicious hot dog with various toppings, including tomatoes, onions, and pickles. The hot dog is placed on a bun, and it appears to be a foot-long hot dog. The toppings are generously spread across the hot dog, making it a mouth-water"}, "391139": {"image_id": 391139, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.24308621739673564, "Bleu_3": 0.1901110702410287, "Bleu_4": 0.14884133138560784, "METEOR": 0.3521664558045391, "ROUGE_L": 0.36715391229578676, "CIDEr": 1.3145407030636488e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.20833333333333334, "f": 0.20408163265306126, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a small dog sitting on a wooden bench, looking at the camera. The dog is wearing a red collar and appears to be a shaggy breed. The bench is located outdoors, with a pumpkin nearby, possibly indicating a fall or autumn setting."}, "440093": {"image_id": 440093, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 0.09105491676695633, "Bleu_4": 1.1795365411101286e-05, "METEOR": 0.2184806265061084, "ROUGE_L": 0.3028368794326241, "CIDEr": 4.2065267666989243e-07, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.24, "f": 0.2727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image captures a skateboarder in mid-air, performing a trick on a skateboard ramp. The skateboarder is wearing a blue hat and appears to be in the middle of a jump. The skateboard is clearly visible beneath the skateboarder, as they skill"}, "555356": {"image_id": 555356, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.24046440328937668, "Bleu_3": 0.13500335961292423, "Bleu_4": 1.5207890408489945e-05, "METEOR": 0.2543573780651858, "ROUGE_L": 0.27062999112688557, "CIDEr": 4.2597032466647005e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.14285714285714285, "f": 0.15094339622641512, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a kitchen counter with a silver tray or pan sitting on top of it. The tray is covered in aluminum foil, which is commonly used for cooking or baking purposes. The foil is placed on the counter, possibly after being removed from the oven or stove."}, "561270": {"image_id": 561270, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.23354968324417125, "Bleu_3": 0.17264376558872666, "Bleu_4": 0.13126309882514392, "METEOR": 0.28240411606570975, "ROUGE_L": 0.34269662921348315, "CIDEr": 9.338502692843859e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a red boat sitting on the shore of a lake, surrounded by a grassy area. The boat is tied to a pole, ensuring it stays in place. There are several other boats in the scene, both near the shore and further out on the water. Some of these boats are larger, while"}, "351557": {"image_id": 351557, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.1923802475574326, "Bleu_3": 0.11322098426534662, "Bleu_4": 0.0734011211371756, "METEOR": 0.23772051609198155, "ROUGE_L": 0.21721068249258166, "CIDEr": 1.0414521073512687e-11, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2916666666666667, "f": 0.32558139534883723, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a man standing in a public area, holding a colorful kite that is shaped like a diamond. He is surrounded by a group of people who are watching him and the kite. There are at least 11 people in the scene, with some standing closer to the man and others"}, "123131": {"image_id": 123131, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.19234834502379758, "Bleu_3": 0.15217005687885418, "Bleu_4": 0.11450077782939155, "METEOR": 0.36882462095809593, "ROUGE_L": 0.34269662921348315, "CIDEr": 3.549945877902427e-08, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.034482758620689655, "f": 0.03508771929824562, "fn": 28.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image features a large black semi-truck parked in a parking lot. The truck is prominently displayed, taking up a significant portion of the scene. The truck's hood is open, revealing its engine and other components.\n\nIn the background, there are two people"}, "326248": {"image_id": 326248, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.18375590810914594, "Bleu_3": 0.10773900313322693, "Bleu_4": 1.2393978751529657e-05, "METEOR": 0.2035876212749948, "ROUGE_L": 0.2426136363636364, "CIDEr": 4.550101544297967e-13, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image captures a tennis match in progress, with a tennis player standing on the court holding a racket. The player appears to be engaged in a conversation with a referee, who is sitting on a chair nearby. There are several other people in the scene, including a man sitting on a chair in the background"}, "531852": {"image_id": 531852, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.21718612137747484, "Bleu_3": 0.17590196133275157, "Bleu_4": 0.14373928004606754, "METEOR": 0.3137983670248316, "ROUGE_L": 0.3210526315789473, "CIDEr": 1.8559609232440598e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features two men standing in a living room, playing a video game together. Both men are holding Wii remotes, fully engaged in the game. They are standing close to each other, with one man on the left side and the other on the right side of the room.\n\nThe living room is"}, "205720": {"image_id": 205720, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.24094636829087762, "Bleu_3": 0.1505903985438184, "Bleu_4": 1.6166107444596474e-05, "METEOR": 0.30107663545649604, "ROUGE_L": 0.3924932975871315, "CIDEr": 1.6498716081893138e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.3125, "f": 0.2777777777777778, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man standing on a boat, talking on his cell phone. He is wearing a red shirt and appears to be engaged in a conversation. The boat is situated in a body of water, possibly a lake or a river.\n\nIn the background, there are several cars parked along the"}, "69223": {"image_id": 69223, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.18677184190511298, "Bleu_3": 0.11843166534940335, "Bleu_4": 0.079781998871299, "METEOR": 0.16597317003875747, "ROUGE_L": 0.2197406340057637, "CIDEr": 1.0525888277865512e-08, "SPICE": {"All": {"pr": 0.1, "re": 0.13636363636363635, "f": 0.11538461538461538, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image features a woman standing in a bathroom, holding a handbag. She is positioned near a bathtub, which is the main focus of the scene. The bathroom has a marble-tiled design, giving it a luxurious and elegant appearance.\n\nIn addition to the bat"}, "233311": {"image_id": 233311, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.26048408657499267, "Bleu_3": 0.17458921120504992, "Bleu_4": 0.10157119243203651, "METEOR": 0.3322294550616659, "ROUGE_L": 0.3351648351648352, "CIDEr": 4.232954418849466e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a wooden table with a stuffed monkey sitting on top of it. The monkey is wearing a red bow tie and appears to be the center of attention. The table is surrounded by a variety of oranges, with some placed in a bowl and others scattered around. The oranges are"}, "460294": {"image_id": 460294, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.20824828195446654, "Bleu_3": 0.1226586924270837, "Bleu_4": 1.4152536710832955e-05, "METEOR": 0.23244537034621193, "ROUGE_L": 0.26341764342998153, "CIDEr": 3.774701230329769e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13333333333333333, "f": 0.15384615384615383, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a group of three women walking down a street, each holding an umbrella to protect themselves from the sun. They are walking in a line, with one woman slightly ahead of the others. The women are carrying handbags as they stroll along the sidewalk.\n\nIn the"}, "107907": {"image_id": 107907, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 0.06880010617668034, "Bleu_4": 9.172809483333237e-06, "METEOR": 0.21229352609332613, "ROUGE_L": 0.19690122659780504, "CIDEr": 2.5118208927535103e-09, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.3181818181818182, "f": 0.35000000000000003, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.5454545454545454, "f": 0.631578947368421, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a unique art installation in a museum setting. The centerpiece of the display is a toilet with a guitar-like seat, which is placed on a wooden stand. The toilet is surrounded by several chairs, some of which are positioned around the display, while others are placed"}, "463084": {"image_id": 463084, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.21182963642996727, "Bleu_3": 0.12152840862275044, "Bleu_4": 1.3834368456136866e-05, "METEOR": 0.216558514005943, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.1778902109581703e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a city street with a blue and white bus driving down the road. The bus is positioned in the middle of the scene, and it appears to be a public transit bus. There are several people walking along the sidewalk, with some of them carrying handbags.\n\nIn addition to"}, "279621": {"image_id": 279621, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.07830779525362613, "Bleu_4": 1.0001000249872884e-05, "METEOR": 0.22451985454803022, "ROUGE_L": 0.21903052064631956, "CIDEr": 8.810193165395854e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks, surrounded by a lush green hillside. The train is positioned in the middle of the scene, with a few cars visible in the background. The train appears to be a cargo train, as it is carrying several cars and a truck.\n\nThere"}, "199438": {"image_id": 199438, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1543033499589101, "Bleu_3": 0.10043712727569681, "Bleu_4": 0.06850641701834057, "METEOR": 0.16950545448291834, "ROUGE_L": 0.21618428824571767, "CIDEr": 7.590239500760896e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.19230769230769232, "f": 0.20408163265306123, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a family of four, consisting of two adults and two children, enjoying a leisurely boat ride on a lake. They are all wearing life jackets, ensuring their safety during the activity. The family is sitting in a small canoe, which is filled with supplies and p"}, "160341": {"image_id": 160341, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.1390596095466697, "Bleu_4": 0.10288402441619092, "METEOR": 0.27252631904081964, "ROUGE_L": 0.26116207951070336, "CIDEr": 2.6052305513052384e-10, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.07692307692307693, "f": 0.08163265306122448, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a snowy scene with a person standing in front of a house, holding a pair of skis. The person is wearing a white jacket and appears to be posing for a picture. The skis are placed on the ground, with some of them leaning against a nearby bench."}, "571196": {"image_id": 571196, "Bleu_1": 0.3199999999936, "Bleu_2": 0.26802375769878084, "Bleu_3": 0.20785103853265577, "Bleu_4": 0.13981288055315805, "METEOR": 0.22656268554418602, "ROUGE_L": 0.29865361077111385, "CIDEr": 1.6962586710093826e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a bed with a book lying on top of a colorful comforter. The book is open and appears to be a paperback, possibly a novel or a travel guide. The bed is covered with a multicolored blanket, adding a vibrant touch to the scene. The book is"}, "370266": {"image_id": 370266, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.2247332874836235, "Bleu_3": 0.15620909290310706, "Bleu_4": 0.11003640569767388, "METEOR": 0.22758355040033176, "ROUGE_L": 0.24358243011979464, "CIDEr": 2.1406417016268634e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.14285714285714285, "f": 0.13043478260869565, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a group of sheep grazing on a lush green field. There are four sheep in total, with one on the left side, one in the middle, and two on the right side of the field. The sheep are spread out, with one closer to the foreground and the other two further back"}, "458487": {"image_id": 458487, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.2363282967133546, "Bleu_3": 0.1344109151128908, "Bleu_4": 1.5241326792946003e-05, "METEOR": 0.2717112106826633, "ROUGE_L": 0.3420560747663552, "CIDEr": 7.149007551195068e-09, "SPICE": {"All": {"pr": 0.24, "re": 0.1875, "f": 0.21052631578947367, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.3333333333333333, "f": 0.3703703703703704, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image captures a baseball game in progress, with a batter standing at home plate, holding a baseball bat and preparing to swing. The catcher is positioned behind the batter, wearing a baseball glove, ready to catch the ball. The umpire is also present, closely observing the game"}, "521879": {"image_id": 521879, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.09288407280072536, "Bleu_3": 0.05604826071004969, "Bleu_4": 7.78235962387436e-06, "METEOR": 0.1633346904015399, "ROUGE_L": 0.20783645655877342, "CIDEr": 3.7846205233445956e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a lively scene with a horse-drawn carriage moving down a street, surrounded by several people. There are two horses visible in the scene, one on the left side and another on the right side of the street.\n\nA group of people can be seen walking alongside the carriage,"}, "307784": {"image_id": 307784, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.23791547571099586, "Bleu_3": 0.129605673244496, "Bleu_4": 0.08083053722301232, "METEOR": 0.2185444460448997, "ROUGE_L": 0.31282051282051276, "CIDEr": 0.002996627355445451, "SPICE": {"All": {"pr": 0.25, "re": 0.21739130434782608, "f": 0.23255813953488372, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a kitchen with a sink and a wooden cutting board placed on the counter. The sink is positioned on the left side of the counter, while the cutting board is located on the right side. A knife is resting on the cutting board, ready for use.\n\nIn addition to the sink"}, "154095": {"image_id": 154095, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.1518578172003014, "Bleu_3": 0.0762588621312534, "Bleu_4": 9.656621220138898e-06, "METEOR": 0.23050832929396878, "ROUGE_L": 0.2853801169590643, "CIDEr": 4.619185673755127e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a bed with a backpack and a sleeping bag placed on it. The backpack is positioned on the left side of the bed, while the sleeping bag is on the right side. There are also two suitcases, one located near the left side of the bed and the other near the"}, "222322": {"image_id": 222322, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.18625278992847225, "Bleu_3": 9.169191011400123e-07, "Bleu_4": 2.0459032671035465e-09, "METEOR": 0.1743198105865752, "ROUGE_L": 0.23843648208469054, "CIDEr": 3.714391264428039e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.10344827586206896, "f": 0.11320754716981132, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a lively beach scene with a large crowd of people enjoying their time by the ocean. There are numerous umbrellas scattered across the beach, providing shade for the beachgoers. Some of the umbrellas are blue, while others are yellow, and they are placed in"}, "227042": {"image_id": 227042, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.13643933968471528, "Bleu_4": 1.5012817512995878e-05, "METEOR": 0.2555401498338852, "ROUGE_L": 0.3710086163203244, "CIDEr": 9.832772398404272e-07, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.2857142857142857, "f": 0.32653061224489793, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a group of young men playing soccer on a field. There are at least 11 players visible in the scene, with some of them actively engaged in the game, while others are watching or waiting for their turn. The soccer ball is in the air, and the players are trying"}, "155897": {"image_id": 155897, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.13566654900343936, "Bleu_4": 0.1009954417123122, "METEOR": 0.29292988909959466, "ROUGE_L": 0.27319257837492, "CIDEr": 2.8190614397583406e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a person sitting on a bench, holding a sandwich in their hand. The sandwich is cut in half, and the person is in the process of eating it. There are several other people in the scene, some of them sitting on the bench as well.\n\nIn addition to"}, "33798": {"image_id": 33798, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1258455564244646, "Bleu_3": 0.06816612219878869, "Bleu_4": 8.966592262802168e-06, "METEOR": 0.23002379926589742, "ROUGE_L": 0.22241127856101123, "CIDEr": 1.9533214150468118e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.09090909090909091, "f": 0.1016949152542373, "fn": 30.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image depicts a cozy living room with a couch and a chair placed in the center of the room. The couch is positioned against the wall, while the chair is situated in the middle of the room. A dining table is located near the couch, with a laptop placed on it"}, "490794": {"image_id": 490794, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.20402970888419056, "Bleu_3": 0.12276317177256986, "Bleu_4": 0.0805263299613596, "METEOR": 0.2636502309920305, "ROUGE_L": 0.23297262889879056, "CIDEr": 5.979863632379824e-08, "SPICE": {"All": {"pr": 0.47058823529411764, "re": 0.2962962962962963, "f": 0.3636363636363636, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.7142857142857143, "re": 0.35714285714285715, "f": 0.4761904761904762, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts a busy city street with a traffic light and a large electronic sign hanging above it. The sign displays information about parking spaces and farmers' markets. The street is filled with various vehicles, including cars and trucks, driving and parked along the road.\n\nThere"}, "381925": {"image_id": 381925, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.13633224439757732, "Bleu_4": 0.10084570751011404, "METEOR": 0.21859814604628885, "ROUGE_L": 0.2507045561296383, "CIDEr": 1.3947565908106819e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a young girl sitting on a wooden bench, holding a dog in her arms. The girl is wearing a hat and a scarf, and she appears to be enjoying her time outdoors. The dog is positioned close to her, and they seem to be sharing a moment of bond"}, "145312": {"image_id": 145312, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.2852987010721684, "Bleu_3": 0.2493523286987107, "Bleu_4": 0.2182488277648039, "METEOR": 0.29786762202309136, "ROUGE_L": 0.3669786096256685, "CIDEr": 2.1487345750728775e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2608695652173913, "f": 0.2727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a black and white dog jumping in the air to catch a frisbee. The dog is positioned in the middle of the scene, with the frisbee in its mouth. The dog's jump is captured mid-air, showcasing its athleticism and excitement."}, "65798": {"image_id": 65798, "Bleu_1": 0.43749999999088546, "Bleu_2": 0.28944186936439076, "Bleu_3": 0.153862088884353, "Bleu_4": 0.09485180280880742, "METEOR": 0.229192989932992, "ROUGE_L": 0.3078734858681023, "CIDEr": 2.42532351364045e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress, with a batter standing at home plate, holding a baseball bat and preparing to swing. The catcher and the umpire are also present, positioned behind the batter. The scene is filled with excitement as the crowd watches the game intently."}, "358817": {"image_id": 358817, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 6.880010617668035e-07, "Bleu_4": 1.631181823642126e-09, "METEOR": 0.2118704260529319, "ROUGE_L": 0.19690122659780504, "CIDEr": 3.842100389564325e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16666666666666666, "f": 0.15686274509803924, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a residential street with a row of houses on one side and a street corner on the other. There are multiple traffic lights hanging above the street, ensuring the safety of pedestrians and drivers.\n\nA few people can be seen walking along the sidewalk, with one"}, "188465": {"image_id": 188465, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.2760387427794136, "Bleu_3": 0.23779577728928664, "Bleu_4": 0.1914930884861308, "METEOR": 0.31270826095878457, "ROUGE_L": 0.4002186987424823, "CIDEr": 3.1055079495631954e-10, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2692307692307692, "f": 0.2692307692307692, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image captures a thrilling moment during a baseball game, with a batter swinging a baseball bat at a pitch. The batter is in the middle of the scene, holding the bat and preparing to hit the ball. The catcher is positioned behind the batter, ready to catch the ball if the batter"}, "14285": {"image_id": 14285, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.28284271246901765, "Bleu_3": 0.20135139234068317, "Bleu_4": 0.1141972559801914, "METEOR": 0.30893572258185253, "ROUGE_L": 0.41146711635750427, "CIDEr": 2.2182230383024315e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.20833333333333334, "f": 0.19607843137254902, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a gray and black cat sitting on a bed in a bedroom. The cat is looking directly at the camera, capturing attention. The bedroom is furnished with a television on the left side of the room, a dresser in the background, and a bookshelf filled with various books."}, "499631": {"image_id": 499631, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.1344109151128908, "Bleu_4": 0.0857082790640443, "METEOR": 0.22260646874889756, "ROUGE_L": 0.2459677419354839, "CIDEr": 6.725113493307098e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a large group of teddy bears sitting on a bench, creating a festive atmosphere. The teddy bears are arranged in various positions, with some sitting closer to the front and others further back. They are all dressed in winter clothing, adding to the holiday theme."}, "67342": {"image_id": 67342, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.13736056394612134, "Bleu_3": 0.10286809102467985, "Bleu_4": 0.08083053722301232, "METEOR": 0.21568423666606643, "ROUGE_L": 0.21863799283154117, "CIDEr": 3.1322841174813863e-13, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two small birds perched on a metal wire, possibly a fence or a branch. One bird is positioned closer to the left side of the wire, while the other bird is on the right side. Both birds appear to be looking at each other, possibly engaging in a conversation or observing"}, "295728": {"image_id": 295728, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.10859446879612174, "Bleu_4": 0.08460008059351494, "METEOR": 0.20274978045793293, "ROUGE_L": 0.28554710356933877, "CIDEr": 1.5468622672001302e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a large, ornate clock mounted on a pole in the middle of a room. The clock is prominently displayed, with its face facing the viewer. The room appears to be a restaurant or a dining area, as there are several people present in the scene. Some of them are se"}, "267951": {"image_id": 267951, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.14457494718760727, "Bleu_4": 0.10825902502501075, "METEOR": 0.21037070117520165, "ROUGE_L": 0.20847573479152426, "CIDEr": 7.399922178532643e-09, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.17857142857142858, "f": 0.2, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a zebra standing in a stall, eating hay from a feeder. The zebra is positioned near the center of the scene, with its head down as it enjoys its meal. The stall is made of wood and has a fence, providing a secure environment"}, "2302": {"image_id": 2302, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.121479758333828, "Bleu_4": 1.3901690971832786e-05, "METEOR": 0.2114235216606857, "ROUGE_L": 0.2799770510613884, "CIDEr": 1.4440869548939427e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.21739130434782608, "f": 0.20833333333333331, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a man and a woman riding horses on a rocky trail. The man is riding a brown horse, while the woman is riding a brown and white horse. Both horses are carrying backpacks, with the man's horse having a red backpack and the woman's horse having"}, "146397": {"image_id": 146397, "Bleu_1": 0.1555555555520988, "Bleu_2": 0.05945883899972003, "Bleu_3": 4.348319676410201e-07, "Bleu_4": 1.1828475534420008e-09, "METEOR": 0.12011621417160613, "ROUGE_L": 0.1616964877402253, "CIDEr": 6.722850862560576e-09, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.09090909090909091, "f": 0.0967741935483871, "fn": 30.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image captures a group of young men performing skateboard tricks on a brick road. There are five skateboarders in total, each showcasing their skills as they ride their skateboards. The skateboarders are spread out along the road, with some closer to the foreground and"}, "122981": {"image_id": 122981, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.2690691175932999, "Bleu_3": 0.23532427968836384, "Bleu_4": 0.1998659656033594, "METEOR": 0.24304490888845243, "ROUGE_L": 0.26293103448275856, "CIDEr": 1.2530265551124904e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.1875, "f": 0.15, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a young boy wearing a hat and a green shirt, standing next to a man. The boy appears to be looking at the camera, possibly posing for a picture. The man is standing behind the boy, and they are both positioned in front of a bus.\n\nThere are two"}, "227878": {"image_id": 227878, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.14819171472405493, "Bleu_3": 7.652745233046606e-07, "Bleu_4": 1.7480450957103998e-09, "METEOR": 0.20315628481933168, "ROUGE_L": 0.22584228063680117, "CIDEr": 7.2152832303255634e-09, "SPICE": {"All": {"pr": 0.35, "re": 0.2692307692307692, "f": 0.3043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image is a collage of four pictures featuring a variety of aquatic and avian elements. In the first picture, a blue bird is hanging from the ceiling, while in the second picture, a fish is swimming in a tank. The third picture showcases a cat sitting on a chair, and"}, "286858": {"image_id": 286858, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2879063578987017, "Bleu_3": 0.19316786967473912, "Bleu_4": 0.11249883867866671, "METEOR": 0.23883483101116276, "ROUGE_L": 0.27371794871794874, "CIDEr": 1.901286101519443e-09, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.17857142857142858, "f": 0.2, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a stuffed teddy bear wearing a red shirt, sitting on a surface. The teddy bear is positioned in the center of the scene, with a blue blanket placed in front of it. The teddy bear appears to be a Winnie the Pooh character, adding a"}, "459680": {"image_id": 459680, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 8.077421359130519e-07, "Bleu_4": 1.8710588175603566e-09, "METEOR": 0.23210955660125523, "ROUGE_L": 0.33936022253129344, "CIDEr": 2.9816006162602204e-08, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.19230769230769232, "f": 0.17543859649122806, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman dressed in a pink dress, standing outdoors and holding a pink umbrella. She is wearing a white glove and appears to be posing for the picture. The umbrella is open, providing shade and protection from the elements. The woman's out"}, "462677": {"image_id": 462677, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.14189834119414174, "Bleu_4": 0.11620875224195953, "METEOR": 0.2583913466458293, "ROUGE_L": 0.2765544041450777, "CIDEr": 1.467568426917563e-07, "SPICE": {"All": {"pr": 0.3, "re": 0.17142857142857143, "f": 0.21818181818181817, "fn": 29.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a blue parking meter on a sidewalk, with a rope tied around it. The parking meter is located near the center of the scene, and it appears to be old and possibly broken. The rope is wrapped around the meter, possibly to prevent unauthorized use or tamper"}, "90520": {"image_id": 90520, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.15115540850568024, "Bleu_4": 0.11193401922301613, "METEOR": 0.2904231545095739, "ROUGE_L": 0.31063017186505404, "CIDEr": 4.496302338772949e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.24, "f": 0.2264150943396226, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5454545454545454, "f": 0.4799999999999999, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image features two white teddy bears dressed in traditional Asian clothing, standing next to each other. The bears are wearing red and gold outfits, with one bear appearing to be a geisha and the other dressed as a samurai. The bears are positioned in a way"}, "552866": {"image_id": 552866, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.21182963642996727, "Bleu_3": 9.645716184588767e-07, "Bleu_4": 2.068720600984956e-09, "METEOR": 0.1635931912800711, "ROUGE_L": 0.22241127856101123, "CIDEr": 3.654682850378205e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.16129032258064516, "f": 0.1694915254237288, "fn": 26.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a beautiful cityscape with a large clock tower towering over the city. The clock tower is located near a bridge, and the city is bathed in a warm, golden light. The scene is set against a backdrop of a cloudy sky, adding a dramatic touch to the overall atmosphere"}, "337083": {"image_id": 337083, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.13572088082697478, "Bleu_4": 0.08540052443980553, "METEOR": 0.27849877577741217, "ROUGE_L": 0.3100381194409149, "CIDEr": 2.1046401814924194e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a large, old-fashioned building with a clock tower on top. The building has a distinctive yellow and brown color scheme, and it appears to be a commercial building, possibly a hotel or a cleaning establishment.\n\nThere are several windows on the building, with some located on the"}, "304828": {"image_id": 304828, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 7.502652544655378e-07, "Bleu_4": 1.7134131896259546e-09, "METEOR": 0.17377205023380857, "ROUGE_L": 0.22048192771084338, "CIDEr": 2.3958397574188284e-11, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.19047619047619047, "f": 0.16, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.3333333333333333, "f": 0.11764705882352941, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a giraffe walking through a grassy field with its front legs spread apart. The giraffe is the main focus of the scene, and its long neck and legs are clearly visible. The field appears to be a mix of grass and dirt, providing a natural habitat for the giraffe"}, "506115": {"image_id": 506115, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 0.060526698984524764, "Bleu_4": 8.120218167477751e-06, "METEOR": 0.25199357096949043, "ROUGE_L": 0.3028368794326241, "CIDEr": 5.339791889712334e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.16, "f": 0.16, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features two young girls sitting on a bus, each holding a soccer ball. They are surrounded by several other soccer balls, indicating that they might be on their way to a soccer game or practice. The girls are seated on a bench, with one girl on the left side and the other"}, "147179": {"image_id": 147179, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.0903507902886997, "Bleu_3": 5.540397074769196e-07, "Bleu_4": 1.3792125616624927e-09, "METEOR": 0.16159150067671194, "ROUGE_L": 0.1852976913730255, "CIDEr": 3.802263680539088e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.23809523809523808, "f": 0.23255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a group of four people, two women and two men, sitting on a bed together. They are all wearing shorts, and the women are wearing tops. The group appears to be enjoying each other's company and having a good time.\n\nThere are several books scattered around"}, "549718": {"image_id": 549718, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.19069251784568234, "Bleu_3": 0.13913760149235183, "Bleu_4": 0.08443342702964665, "METEOR": 0.23668398033531682, "ROUGE_L": 0.21682464454976302, "CIDEr": 7.617969435018712e-14, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a yellow and blue bus driving down a street. The bus is quite large and occupies a significant portion of the scene. The bus is heading towards a bus stop, possibly to pick up passengers.\n\nThere are two people visible in the scene, one standing closer to the bus and another further away"}, "160820": {"image_id": 160820, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.1942571724677524, "Bleu_3": 0.1546623666287077, "Bleu_4": 0.1311628924494135, "METEOR": 0.27860668163885066, "ROUGE_L": 0.3258160237388724, "CIDEr": 3.632473349311885e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.19230769230769232, "f": 0.20833333333333331, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a group of sheep grazing on a lush green hillside. There are at least nine sheep visible in the scene, scattered across the grassy field. Some of the sheep are closer to the foreground, while others are further away, creating a sense of depth in the image. The sheep are"}, "517629": {"image_id": 517629, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.20402970888419056, "Bleu_3": 0.14052875118908187, "Bleu_4": 0.08911703342805896, "METEOR": 0.2911006250551568, "ROUGE_L": 0.34945894334818584, "CIDEr": 1.9352399522870813e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a white cat sitting inside a bathroom sink, licking its nose. The cat appears to be enjoying its time in the sink, possibly seeking a cool and comfortable spot.\n\nThe bathroom is equipped with a toothbrush and a cup, both placed on the sink'"}, "433277": {"image_id": 433277, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.14254579382569355, "Bleu_3": 0.07358334830308164, "Bleu_4": 9.448049464513672e-06, "METEOR": 0.2775723174875694, "ROUGE_L": 0.2959369314736203, "CIDEr": 6.958319527420772e-12, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.2857142857142857, "f": 0.2758620689655172, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a wooden desk with a computer setup on it. There are three computer monitors placed on the desk, with one on the left side, one in the middle, and the third on the right side. A keyboard and a mouse are also present on the desk, positioned in front of"}, "487498": {"image_id": 487498, "Bleu_1": 0.17647058823183395, "Bleu_2": 1.8786728732182436e-09, "Bleu_3": 4.160722483003165e-12, "Bleu_4": 1.968186519407282e-13, "METEOR": 0.12558869701726844, "ROUGE_L": 0.1561100447856686, "CIDEr": 2.839047457930252e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.18518518518518517, "f": 0.18181818181818182, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a woman holding a blue umbrella, which is open and providing shelter from the rain. She is also holding a flag, possibly a British flag, and is wearing a red jacket. The woman is standing next to a tree, which is visible in the background.\n\nThere are other"}, "90640": {"image_id": 90640, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.17039568890752202, "Bleu_3": 0.12032507801506327, "Bleu_4": 0.0918280988077437, "METEOR": 0.25704197059497336, "ROUGE_L": 0.26293103448275856, "CIDEr": 6.922567401230712e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a group of elephants walking down a street in a city. There are a total of nine elephants in the scene, with some of them walking in pairs or small groups. The elephants are of various sizes, indicating that they might be of different ages or stages of development"}, "470173": {"image_id": 470173, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.17869060919900012, "Bleu_3": 0.10778403210915813, "Bleu_4": 0.07074134593845909, "METEOR": 0.21698569436818219, "ROUGE_L": 0.24811156304474144, "CIDEr": 7.139357356755398e-12, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.27586206896551724, "f": 0.3076923076923077, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a statue of a woman holding a large bag on her shoulder. The statue is positioned in a grassy area, possibly a park or a garden. The woman statue is the main focus of the scene, and it appears to be a bronze sculpture.\n\nIn the background, there are several"}, "536183": {"image_id": 536183, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.11805626721734597, "Bleu_3": 7.03675938605906e-07, "Bleu_4": 1.7288741230850778e-09, "METEOR": 0.1835064778847583, "ROUGE_L": 0.2543786488740617, "CIDEr": 1.7204800145768775e-07, "SPICE": {"All": {"pr": 0.3, "re": 0.35294117647058826, "f": 0.3243243243243243, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a large pot filled with a delicious stir-fry dish, containing a variety of vegetables and meat. The dish consists of numerous pieces of broccoli, carrots, and red peppers, all mixed together in a savory sauce. The broccoli pieces are"}, "523597": {"image_id": 523597, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.23063280200236536, "Bleu_3": 0.15138000825437875, "Bleu_4": 0.11143093224787654, "METEOR": 0.2993721733590716, "ROUGE_L": 0.28696236559139787, "CIDEr": 1.320585102857219e-08, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.14285714285714285, "f": 0.12000000000000001, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a man and a woman riding a motorcycle down a road. The man is driving the motorcycle, while the woman is sitting behind him. They are both wearing traditional Indian clothing, with the man wearing a turban.\n\nThe motorcycle is positioned in the center of"}, "366178": {"image_id": 366178, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.18233123936852927, "Bleu_3": 0.11306584792083928, "Bleu_4": 0.07528274645181147, "METEOR": 0.267650478754213, "ROUGE_L": 0.2184813753581662, "CIDEr": 7.341395588729428e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a snowy road with a yellow sign on a pole, indicating a pedestrian crossing. The road is surrounded by snow-covered ground, and there are several cars parked or driving along the road. In addition to the cars, there are two trucks visible in the scene."}, "11260": {"image_id": 11260, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.11172119198541168, "Bleu_4": 1.2922875770638225e-05, "METEOR": 0.23098009614361964, "ROUGE_L": 0.2507339988256019, "CIDEr": 9.624702830402717e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2608695652173913, "f": 0.2553191489361702, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a train traveling on tracks over a bridge, with a body of water visible below. The train is positioned in the middle of the scene, and it appears to be a passenger train. The tracks are situated above the water, providing a unique perspective of the train's journey.\n\nThere"}, "92765": {"image_id": 92765, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.11375929179665137, "Bleu_3": 6.415924230513621e-07, "Bleu_4": 1.5315603357857856e-09, "METEOR": 0.2150140180815744, "ROUGE_L": 0.25553560742070613, "CIDEr": 5.014264690357352e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3157894736842105, "f": 0.2608695652173913, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a large display of bananas at a market, with several bunches of bananas arranged in various positions. The bananas are placed on a table, and some are even piled up on the floor. The bananas are of different sizes and are spread across the entire scene.\n\nIn addition"}, "171936": {"image_id": 171936, "Bleu_1": 0.333333333325926, "Bleu_2": 0.19462473603600663, "Bleu_3": 0.13825567198357513, "Bleu_4": 0.08906352819962383, "METEOR": 0.26880917808969146, "ROUGE_L": 0.28894302341318173, "CIDEr": 3.102422533035919e-08, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.14285714285714285, "f": 0.13559322033898305, "fn": 24.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.25, "f": 0.23076923076923075, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image depicts a small, cluttered kitchen and living room area. The kitchen features a refrigerator, a sink, and a microwave. There is a dining table with a chair positioned in front of it. The living room area has a couch and a chair, with"}, "244401": {"image_id": 244401, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.12354612406992554, "Bleu_3": 6.973999503999067e-07, "Bleu_4": 1.6662810872712766e-09, "METEOR": 0.23260372214649955, "ROUGE_L": 0.19869706840390877, "CIDEr": 1.6698047005964595e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.0625, "f": 0.08, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a wooden table filled with a variety of fresh vegetables, including several carrots, broccoli, and lettuce. The vegetables are arranged in different sections of the table, with some placed closer to the front and others towards the back.\n\nIn addition to the vegetables, there"}, "534122": {"image_id": 534122, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.18070977621815823, "Bleu_3": 0.08619148700244576, "Bleu_4": 1.0637896949215625e-05, "METEOR": 0.2307116716345241, "ROUGE_L": 0.3124644280022766, "CIDEr": 1.885646634228841e-11, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.125, "f": 0.11428571428571428, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a man running on a beach, with the ocean in the background. He is wearing swim trunks and appears to be enjoying his time in the water. The man is running towards the ocean, possibly to cool off or engage in some water activities. The beach is a sandy area"}, "366099": {"image_id": 366099, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.2705008903935497, "Bleu_3": 0.19578417892468591, "Bleu_4": 0.14097587386591498, "METEOR": 0.24936124905778553, "ROUGE_L": 0.34634492547906315, "CIDEr": 2.9792396014243565e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.1935483870967742, "f": 0.23076923076923075, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a close-up view of a delicious pizza with a generous amount of toppings. The pizza is topped with a variety of ingredients, including tomatoes, olives, onions, and cheese. The tomatoes are scattered across the pizza, with some placed"}, "503135": {"image_id": 503135, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1889822365007167, "Bleu_3": 0.15604075333783501, "Bleu_4": 0.11336958836408242, "METEOR": 0.2568202292670898, "ROUGE_L": 0.2663755458515284, "CIDEr": 4.156120686411195e-09, "SPICE": {"All": {"pr": 0.35, "re": 0.3181818181818182, "f": 0.3333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a police officer riding a motorcycle down a street, surrounded by a crowd of people. The officer is wearing a helmet and a yellow jacket, making them easily noticeable. The crowd consists of various individuals, some standing closer to the motorcycle and others further away.\n\nThere"}, "200807": {"image_id": 200807, "Bleu_1": 0.41666666665798613, "Bleu_2": 0.29774566708143785, "Bleu_3": 0.21279807305898574, "Bleu_4": 0.14385671494946425, "METEOR": 0.2404147594362841, "ROUGE_L": 0.38463743192891947, "CIDEr": 1.2461676915433757e-06, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.19047619047619047, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a wooden floor with a pair of black shoes and a red polka dot umbrella lying on it. The umbrella is open and positioned horizontally across the floor, while the shoes are placed next to it. The scene appears to be indoors, possibly in a"}, "328805": {"image_id": 328805, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.27735009810722866, "Bleu_3": 0.19740230337098555, "Bleu_4": 0.111934803681957, "METEOR": 0.2507558487979434, "ROUGE_L": 0.38181818181818183, "CIDEr": 6.910512559351055e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.24, "f": 0.2553191489361702, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a bathroom with a white toilet situated next to a black cabinet. The cabinet has a vase with yellow flowers on top, adding a touch of color to the space. There are two bowls placed on the floor, one near the toilet and the other closer to the cabinet."}, "445055": {"image_id": 445055, "Bleu_1": 0.3913043478175804, "Bleu_2": 0.29488391230331257, "Bleu_3": 0.15811017751473136, "Bleu_4": 1.7412164272874968e-05, "METEOR": 0.32661173471612, "ROUGE_L": 0.3084702907711757, "CIDEr": 1.0197326823686289e-05, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man and a young boy in the ocean, both wearing wetsuits and enjoying a surfing session. The man is standing on a surfboard, while the boy is riding a wave on his own surfboard. They are both skillfully navigating the waves, show"}, "387223": {"image_id": 387223, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.11741874968995038, "Bleu_4": 0.07744617268822214, "METEOR": 0.2911135554067887, "ROUGE_L": 0.27371794871794874, "CIDEr": 7.843003238121034e-09, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a group of sheep grazing in a snow-covered field. There are nine sheep in total, scattered across the field, with some closer to the foreground and others further away. The sheep are peacefully eating the grass, despite the cold and snowy conditions.\n\nThe field is"}, "436349": {"image_id": 436349, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.17339191115885713, "Bleu_3": 0.12608269096032357, "Bleu_4": 0.09769805815563083, "METEOR": 0.1947188431173811, "ROUGE_L": 0.22775357809583074, "CIDEr": 9.184256275539413e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a parking lot with several colorful buses parked next to each other. The buses are painted with various designs, making them visually appealing. There are at least five buses in the scene, with some parked closer to the foreground and others further back.\n\nIn"}, "51335": {"image_id": 51335, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.23045544793969702, "Bleu_3": 0.17220544249521463, "Bleu_4": 0.13165062476661393, "METEOR": 0.23900344173511098, "ROUGE_L": 0.28367380833748546, "CIDEr": 1.3571081252155898e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.11538461538461539, "f": 0.11538461538461539, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a man sitting at a wooden dining table, enjoying a hot dog with mustard. He is smiling and appears to be having a good time. The table is surrounded by chairs, and there are a few other people in the scene, one of whom is standing near the left side of"}, "515531": {"image_id": 515531, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.22696949467552002, "Bleu_3": 0.1428653103202315, "Bleu_4": 1.5388427959471035e-05, "METEOR": 0.22365293297290056, "ROUGE_L": 0.26307277628032344, "CIDEr": 1.2403237938158164e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image captures a beautiful scene of a moon rising in the sky, with a jet airplane flying in the background. The airplane is positioned towards the right side of the image, while the moon is located more towards the center. The combination of the moon and the airplane creates a striking contrast against the"}, "20371": {"image_id": 20371, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1360198059227937, "Bleu_3": 0.10724350864958367, "Bleu_4": 0.072763753096432, "METEOR": 0.15014042266766284, "ROUGE_L": 0.20847573479152426, "CIDEr": 4.1603846065929894e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.36363636363636365, "f": 0.30769230769230765, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a black bird perched on a metal surface, possibly a roof or a ledge. The bird is looking upwards, possibly observing its surroundings or the sky. The bird's position on the metal surface suggests that it is comfortable and relaxed in its environment."}, "180653": {"image_id": 180653, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.0804252399656011, "Bleu_4": 1.0203142794069551e-05, "METEOR": 0.25920779576817643, "ROUGE_L": 0.25553560742070613, "CIDEr": 5.790951051239546e-10, "SPICE": {"All": {"pr": 0.35, "re": 0.2413793103448276, "f": 0.2857142857142857, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a man and a woman standing on skis in a snowy area, possibly a forest or a ski slope. The man is on the left side of the woman, both of them wearing backpacks. The woman is wearing a green hat, and the man is wearing a backpack"}, "373382": {"image_id": 373382, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.24836183164306555, "Bleu_3": 0.13423832028706206, "Bleu_4": 1.4830810331831031e-05, "METEOR": 0.2905469176050106, "ROUGE_L": 0.3190005810575247, "CIDEr": 8.870146441697627e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.13793103448275862, "f": 0.16326530612244897, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a tennis match in progress, with a man in a white shirt and white shorts playing the game. He is holding a tennis racket and appears to be in the middle of a serve. The tennis ball is in the air, and the player is reaching up to hit it."}, "515642": {"image_id": 515642, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.14021847959482642, "Bleu_3": 0.07054628688135094, "Bleu_4": 8.938506241154746e-06, "METEOR": 0.211219353700441, "ROUGE_L": 0.2973997833152763, "CIDEr": 2.783594146419859e-14, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.22727272727272727, "f": 0.20833333333333331, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a book and a remote control placed on a counter or table. The book is open, and the remote control is positioned next to it. The book appears to be a novel, and the remote control is a TV remote. The scene suggests that someone might be reading the book while watching television or taking"}, "276254": {"image_id": 276254, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.08788194533129833, "Bleu_4": 1.0848650703059748e-05, "METEOR": 0.20612294362389003, "ROUGE_L": 0.2167219327333018, "CIDEr": 3.729174891621106e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a serene scene of a large body of water with numerous boats of various sizes docked in the harbor. The boats are scattered throughout the water, with some closer to the shore and others further out. The harbor is surrounded by a lush green hillside, providing a picturesque backdrop"}, "332377": {"image_id": 332377, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.21535276081853263, "Bleu_3": 0.16154842718261025, "Bleu_4": 0.0995084443237399, "METEOR": 0.2752912822389106, "ROUGE_L": 0.28968792401628224, "CIDEr": 3.448539682741705e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a dining table with two donuts placed on it. One of the donuts is a red frosted donut, while the other is a sprinkled donut. The red frosted donut is sitting on a napkin, and the sprinkled donut is on a paper wrapper"}, "66675": {"image_id": 66675, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 0.13300573168298876, "Bleu_4": 0.08367437134425945, "METEOR": 0.20048063703632632, "ROUGE_L": 0.2858816637375513, "CIDEr": 9.622504396002101e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man and a woman standing in a room, both holding Wii remotes and smiling. They appear to be enjoying a gaming session together. The room has a bed in the background, and there are several books scattered around the area.\n\nIn addition to the main subjects, there"}, "578752": {"image_id": 578752, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.22758963106159172, "Bleu_3": 0.15466509142797644, "Bleu_4": 0.09746490477140814, "METEOR": 0.2763947661440846, "ROUGE_L": 0.25702247191011235, "CIDEr": 5.59538933573549e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a serene beach scene with a person walking along the shoreline. The person is carrying a surfboard, likely preparing to go surfing or having just finished a surfing session. The surfboard is visible in the person's hand as they walk."}, "411177": {"image_id": 411177, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.126168012373563, "Bleu_3": 6.921800773739778e-07, "Bleu_4": 1.6298208029972444e-09, "METEOR": 0.19256494487320963, "ROUGE_L": 0.23252858958068615, "CIDEr": 3.703091034039456e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.12903225806451613, "f": 0.14814814814814814, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a large, well-furnished living room with a red wall and a brown carpet. The room is filled with various pieces of furniture, including a couch and a chair. The couch is positioned in the center of the room, while the chair is located towards the right side"}, "12192": {"image_id": 12192, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.2753807233863433, "Bleu_3": 0.195174151667895, "Bleu_4": 0.11042673313489705, "METEOR": 0.2563242158726627, "ROUGE_L": 0.38777506112469434, "CIDEr": 4.911597743821098e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.24, "f": 0.2666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a young child standing on a beach, holding a tennis racket and ball. The child appears to be enjoying their time at the beach, possibly playing a game of tennis or simply having fun with the racket and ball.\n\nIn the background, there are two other people, one of whom"}, "403657": {"image_id": 403657, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.10158210507506187, "Bleu_4": 1.1973479150365735e-05, "METEOR": 0.21588551720260607, "ROUGE_L": 0.23961840628507297, "CIDEr": 4.228577808398616e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2916666666666667, "f": 0.3111111111111111, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a busy city street with a red double-decker bus driving down the road, surrounded by tall buildings. The bus is positioned in the middle of the scene, and there are several cars in front of it, including one on the left side and two on the right side of the bus."}, "191672": {"image_id": 191672, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.26375218935251743, "Bleu_3": 0.1992063408534251, "Bleu_4": 0.15324650139531865, "METEOR": 0.3300885793790969, "ROUGE_L": 0.35510996119016824, "CIDEr": 5.3569567940062715e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a man skillfully riding a wave on a surfboard in the ocean. He is wearing a wetsuit and appears to be enjoying the thrill of the ride. The surfer is positioned in the center of the scene, with the surfboard beneath him, as"}, "461945": {"image_id": 461945, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.08423190681730008, "Bleu_4": 1.0455985518811585e-05, "METEOR": 0.23604065250370543, "ROUGE_L": 0.24811156304474144, "CIDEr": 9.341363460497607e-12, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.1111111111111111, "f": 0.0851063829787234, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image captures a man in the middle of a tennis match, swinging his tennis racket to hit the ball. He is in the process of serving the ball, and his racket is positioned above his head, ready to make contact with the ball. The man is focused and determined, displaying his athlet"}, "502979": {"image_id": 502979, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.13093073413895012, "Bleu_3": 7.094917059707092e-07, "Bleu_4": 1.660297934705131e-09, "METEOR": 0.20725360830063794, "ROUGE_L": 0.21759809750297268, "CIDEr": 1.3080699996640256e-07, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.35714285714285715, "f": 0.30303030303030304, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image depicts a family gathered around a dining table, enjoying a meal together. There are three people in the scene, with two children and an adult. The children are sitting on either side of the table, while the adult is seated on the opposite side.\n\nThe table is set"}, "43448": {"image_id": 43448, "Bleu_1": 0.4347826086862004, "Bleu_2": 0.3108349360732723, "Bleu_3": 0.18746034392462774, "Bleu_4": 0.11125382292156775, "METEOR": 0.2353463944184796, "ROUGE_L": 0.32317880794701986, "CIDEr": 0.0004888513970590664, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.23333333333333334, "f": 0.2692307692307693, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features two elephants in a zoo enclosure, with one being a baby elephant and the other being a larger adult elephant. The baby elephant is standing next to the adult elephant, which is grazing on some grass. The elephants are surrounded by a l"}, "55022": {"image_id": 55022, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.13148092653242613, "Bleu_3": 7.216432604089977e-07, "Bleu_4": 1.6999603483372018e-09, "METEOR": 0.2335161331449484, "ROUGE_L": 0.20013123359580048, "CIDEr": 1.760240461829801e-10, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2857142857142857, "f": 0.34285714285714286, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a room with a large number of bicycles parked in a row. The bicycles are of various sizes and styles, with some being more prominent than others. The room appears to be a showroom or a storage area for bicycles.\n\nIn addition to the bicycles"}, "204661": {"image_id": 204661, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.12641490045451217, "Bleu_4": 0.07857415746443173, "METEOR": 0.26628823448480654, "ROUGE_L": 0.2772727272727273, "CIDEr": 2.821147163213557e-13, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a person holding a Motorola cell phone in their hand. The phone is open and displaying a map on its screen. The person is standing in front of a desk, with a keyboard and a mouse placed nearby. Another cell phone can be seen on the desk, closer to the right side of"}, "259983": {"image_id": 259983, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.16314309133869306, "Bleu_4": 0.11721806731881168, "METEOR": 0.2947486648902057, "ROUGE_L": 0.31504196255648803, "CIDEr": 9.544601971550173e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.3076923076923077, "f": 0.2285714285714286, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a white stove top oven with four burners, located in a kitchen. The oven is positioned under a counter, and it appears to be old and dirty. The stove is surrounded by various bottles, with some placed on the counter and others scattered around the kitchen."}, "343561": {"image_id": 343561, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.13805054457255134, "Bleu_4": 1.5820356672588363e-05, "METEOR": 0.19811729548255572, "ROUGE_L": 0.24887800897592818, "CIDEr": 2.3528078418703727e-07, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image captures a group of cyclists riding down a road, with a large crowd of people watching them from the sidelines. The cyclists are wearing helmets and are positioned closely together, creating an impressive line of riders.\n\nThere are numerous spectators in the scene"}, "559665": {"image_id": 559665, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.07715167497945508, "Bleu_3": 5.021856363784845e-07, "Bleu_4": 1.2881272186771893e-09, "METEOR": 0.18888472818309257, "ROUGE_L": 0.15752098127824402, "CIDEr": 8.542290123853754e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man sitting on a motorcycle, wearing a helmet and a backpack. He is positioned in the middle of the scene, with another person standing nearby. The motorcycle is parked on the side of the road, and there are two other motorcycles visible in the background."}, "137003": {"image_id": 137003, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.12592155012443357, "Bleu_3": 0.07227425284747027, "Bleu_4": 9.795841373567018e-06, "METEOR": 0.2609287351420064, "ROUGE_L": 0.2636887608069164, "CIDEr": 4.0306238871614327e-08, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.36, "f": 0.3333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a young girl standing in a grassy field, holding a colorful umbrella. She is smiling and appears to be enjoying her time outdoors. The umbrella is open, providing shade and protection from the sun.\n\nIn the background, there is a carousel"}, "338203": {"image_id": 338203, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.11432028587212996, "Bleu_4": 0.08792400740713412, "METEOR": 0.24561311502984354, "ROUGE_L": 0.25341246290801184, "CIDEr": 3.929578920324297e-11, "SPICE": {"All": {"pr": 0.375, "re": 0.4, "f": 0.38709677419354843, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.8333333333333334, "f": 0.7142857142857143, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a large bird perched on a tree branch, possibly a parrot or a vulture. The bird is sitting on the branch, looking around and observing its surroundings. The tree branch is located near the center of the image, and the bird appears to be the main focus of the scene"}, "238691": {"image_id": 238691, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.13483997248961796, "Bleu_3": 0.10825053129131099, "Bleu_4": 0.08815921282809275, "METEOR": 0.19471493587908775, "ROUGE_L": 0.28754208754208754, "CIDEr": 5.8593398704608104e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09375, "f": 0.11320754716981132, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a busy airport scene with several people walking around and carrying luggage. One person is lying on the floor, possibly sleeping or resting, with their luggage nearby. Another person is sitting on the floor, also with their luggage.\n\nThere are multiple suit"}, "454610": {"image_id": 454610, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.16447838792810768, "Bleu_3": 0.08503316321009778, "Bleu_4": 1.0935134706922625e-05, "METEOR": 0.2220450052552576, "ROUGE_L": 0.20691994572591585, "CIDEr": 1.7545611311068197e-08, "SPICE": {"All": {"pr": 0.15, "re": 0.14285714285714285, "f": 0.14634146341463414, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a woman sitting in a boat filled with various fruits and vegetables. The boat is filled with bananas, apples, and oranges, creating a colorful and abundant display. The woman appears to be selling these fresh produce items to passersby.\n\nThere are several other"}, "163057": {"image_id": 163057, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.09838681467861131, "Bleu_4": 1.19310375004674e-05, "METEOR": 0.2173346352113749, "ROUGE_L": 0.23252858958068615, "CIDEr": 1.8796083819483777e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07407407407407407, "f": 0.08333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image depicts a lively scene at a park, where a large group of people is gathered to fly kites. There are numerous kites of various shapes and sizes soaring in the sky, creating a vibrant and colorful atmosphere. The people are spread out across the park, with some standing"}, "493623": {"image_id": 493623, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.15943400149410505, "Bleu_4": 0.09688270405692424, "METEOR": 0.2189712333520799, "ROUGE_L": 0.236281471917366, "CIDEr": 1.3555965793904705e-09, "SPICE": {"All": {"pr": 0.47619047619047616, "re": 0.35714285714285715, "f": 0.40816326530612246, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.8333333333333334, "re": 0.5555555555555556, "f": 0.6666666666666667, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a woman in a white dress standing in a room, possibly a bedroom or a living area. She is wearing a white shawl and appears to be getting dressed. Another woman is standing nearby, possibly assisting her in the process.\n\nThere are two chairs in the"}, "564940": {"image_id": 564940, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.15613914506966814, "Bleu_3": 0.10196049127995216, "Bleu_4": 1.2388559502196402e-05, "METEOR": 0.23913374819640829, "ROUGE_L": 0.27371794871794874, "CIDEr": 6.420804849400033e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features two teddy bears sitting next to each other on a table. Both teddy bears are wearing black shirts, with one of them having a gold circle on its shirt. The bears are positioned close to each other, creating a sense of companionship. The table they"}, "423229": {"image_id": 423229, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.10966267342231086, "Bleu_3": 0.06441223689630492, "Bleu_4": 8.828016109821917e-06, "METEOR": 0.28660179721339524, "ROUGE_L": 0.19869706840390877, "CIDEr": 7.227702058651538e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a large, old-fashioned steam train traveling down the tracks, with smoke billowing from its engine. The train is moving along a scenic route, surrounded by trees and a lush green landscape.\n\nThere are several people visible in the scene, likely passengers or train staff"}, "412571": {"image_id": 412571, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.2102800206225174, "Bleu_3": 0.14132092548377867, "Bleu_4": 0.08850450893277763, "METEOR": 0.21069646527509603, "ROUGE_L": 0.27566171723692706, "CIDEr": 3.2910071438869596e-10, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.16666666666666666, "f": 0.16393442622950818, "fn": 25.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.35714285714285715, "f": 0.3703703703703704, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a table with a tray filled with a variety of donuts. There are at least 13 donuts on the tray, each with different toppings and flavors. The donuts are arranged in a visually appealing manner, with some placed closer to the front and others further back"}, "217760": {"image_id": 217760, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.12121830534381622, "Bleu_3": 0.06739562828886043, "Bleu_4": 8.983577738158223e-06, "METEOR": 0.20561910509030623, "ROUGE_L": 0.23252858958068615, "CIDEr": 2.986015207070334e-10, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.27586206896551724, "f": 0.3076923076923077, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a black case containing a variety of scissors. There are six pairs of scissors in total, with some placed horizontally and others vertically. The scissors are of different sizes and are neatly arranged within the case. The case itself is black and appears to be a p"}, "579893": {"image_id": 579893, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.2529289702084681, "Bleu_3": 0.19347469801548806, "Bleu_4": 0.12918877974107223, "METEOR": 0.23962217448692116, "ROUGE_L": 0.33098209441128595, "CIDEr": 1.1099934868179218e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a stop sign with two street signs attached to it. The stop sign is located on the left side of the image, while the street signs are positioned above it. The street signs are green and white, indicating the names of the streets at the intersection.\n\nIn the background, there are trees"}, "5965": {"image_id": 5965, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.16087993330478273, "Bleu_3": 0.12831848461027234, "Bleu_4": 0.09686438070110744, "METEOR": 0.2431236102279514, "ROUGE_L": 0.3051907442151345, "CIDEr": 2.901088881047572e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a teddy bear sitting on the seat of a motorcycle, giving the impression of a person riding the bike. The motorcycle is parked on the side of a street, and there are several potted plants placed around the area. Some of these plants are located near the motorcycle,"}, "107375": {"image_id": 107375, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.08206702275709715, "Bleu_4": 1.041362763232212e-05, "METEOR": 0.1782340192233656, "ROUGE_L": 0.26521739130434785, "CIDEr": 1.2570296988325802e-10, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.07407407407407407, "f": 0.07843137254901962, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a white dog running through a wooded area, carrying a blue Frisbee in its mouth. The dog appears to be enjoying its time outdoors, possibly playing fetch with its owner. The scene is set in a dirt field, with a few rocks scattered around the area. The"}, "115721": {"image_id": 115721, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.10846522890718008, "Bleu_3": 0.06215293828145826, "Bleu_4": 8.409805259069613e-06, "METEOR": 0.24841002395637754, "ROUGE_L": 0.25553560742070613, "CIDEr": 8.317895293383842e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a brown and white dog lying on a couch, appearing to be sleeping or resting. The dog is positioned in the center of the couch, taking up a significant portion of the space.\n\nIn the background, there are two people present, one on the left side of the"}, "493509": {"image_id": 493509, "Bleu_1": 0.42592592591803846, "Bleu_2": 0.36961838403979497, "Bleu_3": 0.2870221618700676, "Bleu_4": 0.20751955490115945, "METEOR": 0.32953374312926376, "ROUGE_L": 0.3567251461988304, "CIDEr": 2.1739085948174678e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3157894736842105, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features two people, a man and a woman, standing next to each other and looking at a cell phone. The man is wearing a yellow safety vest, while the woman is dressed in a suit. They appear to be engaged in a conversation or discussing something on the cell phone.\n\nIn the"}, "507797": {"image_id": 507797, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.09267924750141882, "Bleu_4": 0.06449817351321535, "METEOR": 0.18720007562168528, "ROUGE_L": 0.27566171723692706, "CIDEr": 2.7500569398268967e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.3125, "f": 0.27027027027027023, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a group of people standing outside a bus, waiting to board. There are at least nine people visible in the scene, with some of them carrying handbags. The bus is parked in the background, occupying a significant portion of the image.\n\nIn addition to the bus,"}, "512830": {"image_id": 512830, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.14819171472405493, "Bleu_3": 0.07652745233046604, "Bleu_4": 9.829979956142771e-06, "METEOR": 0.21864973786640016, "ROUGE_L": 0.22889305816135083, "CIDEr": 6.701709750849971e-11, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.3333333333333333, "f": 0.2978723404255319, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.7, "f": 0.608695652173913, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image depicts a group of men in military uniforms sitting in an airplane. They are all wearing sunglasses and appear to be engaged in conversation or waiting for their flight. The men are seated in rows of chairs, with some of them sitting closer to the front of the plane"}, "69969": {"image_id": 69969, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.14132092548377867, "Bleu_4": 0.10525019173268102, "METEOR": 0.22027493040181856, "ROUGE_L": 0.24190350297422336, "CIDEr": 4.994945908314684e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.25, "f": 0.24489795918367346, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a large restaurant with a group of people sitting at various dining tables. There are at least 12 people in the scene, some of them sitting and others standing. The restaurant has a cozy atmosphere, with a wooden dining table and benches placed throughout the space."}, "420466": {"image_id": 420466, "Bleu_1": 0.17777777777382722, "Bleu_2": 0.11009637651016171, "Bleu_3": 6.55680898648204e-07, "Bleu_4": 1.60955965059484e-09, "METEOR": 0.1343779641357778, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.2602994806181582e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.38461538461538464, "f": 0.4545454545454546, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a giraffe standing on a grassy hillside at dusk. The giraffe is the main focus of the scene, with its long neck and legs prominently visible. The sky above the giraffe is dark, creating a dramatic backdrop for the scene. The gira"}, "529850": {"image_id": 529850, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.17039568890752202, "Bleu_3": 0.1051136375718304, "Bleu_4": 1.2407814132465894e-05, "METEOR": 0.2301310081605109, "ROUGE_L": 0.25722891566265055, "CIDEr": 7.479945106533339e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a man sitting on the floor next to a suitcase, with a black cat sitting on top of the suitcase. The man appears to be looking at the cat, possibly admiring or interacting with it. The scene takes place in a kitchen, with a refrigerator visible in the background"}, "397842": {"image_id": 397842, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.12632278815731815, "Bleu_3": 0.07026437559457349, "Bleu_4": 9.370187147561893e-06, "METEOR": 0.20206553682948208, "ROUGE_L": 0.27799479166666663, "CIDEr": 2.095500478255461e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.21428571428571427, "f": 0.17142857142857143, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a brown and white dog running across a lush green field, with a frisbee in its mouth. The dog appears to be enjoying a game of fetch, as it chases the frisbee across the grassy area. The scene captures the dog's energy and excitement"}, "48555": {"image_id": 48555, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.16496470132732644, "Bleu_3": 0.10219130767434717, "Bleu_4": 0.06797010899383783, "METEOR": 0.19924224832301568, "ROUGE_L": 0.226906385616863, "CIDEr": 1.3230931093761398e-12, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a group of people riding horses on a beach. There are five horses in total, with each horse carrying a rider. The riders are positioned in various locations on the beach, with some closer to the water and others further back. The scene is set against a backdrop of a"}, "51938": {"image_id": 51938, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 6.47433787030964e-07, "Bleu_4": 1.558500916173644e-09, "METEOR": 0.1306881261033663, "ROUGE_L": 0.19242902208201892, "CIDEr": 1.8028867582745093e-09, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image captures a snowy ski slope with several skiers and snowboarders enjoying the winter sports. A man is prominently featured in the scene, skiing down the slope while holding a ski pole. He is wearing a white jacket and appears to be in the middle of the slope."}, "380516": {"image_id": 380516, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.12674769789184412, "Bleu_4": 0.08028899837277662, "METEOR": 0.2662126519042839, "ROUGE_L": 0.25722891566265055, "CIDEr": 1.6234550700845115e-11, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.23809523809523808, "f": 0.25641025641025644, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a young boy wearing a white headband and a white shirt, holding a tennis racket and preparing to hit a tennis ball. He is in a crouched position, focused on the game. There are several other people in the background, possibly watching the boy play or waiting for their"}, "461009": {"image_id": 461009, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.08217664461402949, "Bleu_4": 1.0264051022519406e-05, "METEOR": 0.2605470883758139, "ROUGE_L": 0.3190005810575247, "CIDEr": 5.027499545745153e-12, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14814814814814814, "f": 0.14814814814814814, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man sitting in a chair, holding a small, round fruit in his hand. He is smiling and appears to be enjoying the moment. The man is surrounded by other people in the room, with some sitting at a dining table and others standing or sitting nearby.\n\nThere are a"}, "262323": {"image_id": 262323, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.17696643646840995, "ROUGE_L": 0.2569193742478941, "CIDEr": 6.679713061367083e-08, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}}, "caption": "The image features a giraffe standing in a grassy field, looking directly at the camera. The giraffe is positioned in the center of the scene, with its head turned to the side. Another giraffe can be seen in the background, slightly to the left of the main giraffe."}, "236049": {"image_id": 236049, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1543033499589101, "Bleu_3": 7.971700074705258e-07, "Bleu_4": 1.8216869827152143e-09, "METEOR": 0.1908499396989539, "ROUGE_L": 0.26341764342998153, "CIDEr": 3.1883894682525663e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13333333333333333, "f": 0.14814814814814814, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a bird perched on a window ledge, possibly a pigeon, as it looks out of the window. The bird is positioned near the center of the scene, with its wings spread out. The window is adorned with an ornate design, adding a touch of elegance to"}, "373374": {"image_id": 373374, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.22247460415230486, "Bleu_3": 0.10480069030260979, "Bleu_4": 1.2866510680665704e-05, "METEOR": 0.21273107290998255, "ROUGE_L": 0.28073635765943455, "CIDEr": 3.6234771378778764e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.20833333333333334, "f": 0.23255813953488372, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a dining table with a white plate containing a delicious meal. The plate is topped with a large seafood sandwich, which appears to be a lobster sandwich, and a side of coleslaw. There are also two lemon wedges placed on the plate,"}, "225603": {"image_id": 225603, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.14882336590863374, "Bleu_3": 0.08144281873878519, "Bleu_4": 1.0780144922565258e-05, "METEOR": 0.16256478487809584, "ROUGE_L": 0.19999999999999998, "CIDEr": 1.0620664967294703e-06, "SPICE": {"All": {"pr": 0.28, "re": 0.25925925925925924, "f": 0.2692307692307692, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a dining table with a delicious-looking barbecue sandwich cut into four pieces, placed on a cutting board. The sandwich is accompanied by a side of french fries, making for a hearty meal.\n\nThere are several utensils on the table, including"}, "528729": {"image_id": 528729, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.19402850002522387, "Bleu_3": 9.158935294477766e-07, "Bleu_4": 2.0002000499745764e-09, "METEOR": 0.2614181342393461, "ROUGE_L": 0.30860033726812813, "CIDEr": 2.3611785720001806e-09, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.21052631578947367, "f": 0.17391304347826086, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features a man standing on a busy street, talking on his cell phone while holding a bicycle. He is positioned near the center of the scene. The street is filled with various vehicles, including cars and trucks, which are scattered throughout the image.\n\nThere are multiple traffic lights in"}, "317070": {"image_id": 317070, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.11144846405416943, "Bleu_4": 1.3555314602468014e-05, "METEOR": 0.1900675094957944, "ROUGE_L": 0.20890410958904113, "CIDEr": 6.191581762172219e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image captures a person parasailing over the ocean, with their parachute-like sail visible in the sky. The person is suspended in the air, enjoying the thrill of the activity. The parasailer is positioned in the middle of the scene, with the sail extending"}, "102331": {"image_id": 102331, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1740776559517855, "Bleu_3": 0.0889895891077732, "Bleu_4": 1.1381305436598616e-05, "METEOR": 0.2308957406377035, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.7010616071015245e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image captures a young person riding a green dirt bike on a dirt track. The rider is skillfully navigating the track, with the dirt bike in the air, showcasing their talent. The scene is set in a desert-like environment, with a mountain visible in"}, "450452": {"image_id": 450452, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.08606629658080774, "Bleu_3": 5.189555018762679e-07, "Bleu_4": 1.2804032108833407e-09, "METEOR": 0.13827557768217358, "ROUGE_L": 0.17579250720461098, "CIDEr": 8.909683671001161e-13, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2222222222222222, "f": 0.1951219512195122, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a white clock with black numbers and hands, placed on a red wall. The clock is positioned near the center of the wall, and it appears to be a small, round clock. The red wall has a few chipped paint areas, giving it a worn and aged appearance. The clock is the"}, "503292": {"image_id": 503292, "Bleu_1": 0.3399999999932, "Bleu_2": 0.16659862556364263, "Bleu_3": 8.331065142160288e-07, "Bleu_4": 1.872841107532279e-09, "METEOR": 0.1815144715684837, "ROUGE_L": 0.19830949284785435, "CIDEr": 1.1213301291385421e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.12, "f": 0.1276595744680851, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a large Delta airplane flying low over a runway at an airport. The airplane is in the process of landing, as it is close to the ground. The scene also includes several other airplanes parked on the tarmac, with one located near the left side of the"}, "542248": {"image_id": 542248, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.12366938847771936, "Bleu_3": 0.0678332745017197, "Bleu_4": 8.979905725239549e-06, "METEOR": 0.17653729762472525, "ROUGE_L": 0.2501464557703574, "CIDEr": 4.657469540037869e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09375, "f": 0.11320754716981132, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a giraffe walking through a lush green forest, surrounded by trees and bushes. The giraffe is the main focus of the scene, standing tall and walking gracefully through the vegetation. The forest appears to be a mix of grass and trees, providing a natural habitat for the g"}, "251019": {"image_id": 251019, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.23210354127000468, "Bleu_3": 0.15960600175638903, "Bleu_4": 0.0940342527703212, "METEOR": 0.24905345437985263, "ROUGE_L": 0.2872277810476751, "CIDEr": 5.382087413910993e-13, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13636363636363635, "f": 0.14634146341463414, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a young man playing tennis on a court. He is holding a tennis racket and appears to be in the middle of a swing, attempting to hit a tennis ball that is in the air. The man is wearing a red shirt and black shorts, which are typical attire for playing tennis"}, "48738": {"image_id": 48738, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 0.06474337870309639, "Bleu_4": 8.764094705114603e-06, "METEOR": 0.2406121466042318, "ROUGE_L": 0.24190350297422336, "CIDEr": 5.078297428839119e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a large ram with curved horns standing on a rocky hillside. The ram is looking directly at the camera, capturing the viewer's attention. The ram's horns are quite prominent, with one horn being larger than the other. The scene is set against a backdrop"}, "22759": {"image_id": 22759, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.20628424924741542, "Bleu_3": 0.15467190426819247, "Bleu_4": 0.0952259789202735, "METEOR": 0.2626849651654455, "ROUGE_L": 0.31282051282051276, "CIDEr": 1.853254917077247e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a large, fluffy cat sitting on a bed, comfortably laying on a pillow. The cat is positioned in the center of the bed, occupying a significant portion of the space. The bed appears to be a cozy and inviting place for the cat to rest."}, "577065": {"image_id": 577065, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.11396057645758446, "Bleu_3": 0.062187796919435406, "Bleu_4": 8.207481478419242e-06, "METEOR": 0.14416503932597308, "ROUGE_L": 0.20795454545454545, "CIDEr": 2.2087225704690265e-14, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10714285714285714, "f": 0.12244897959183672, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a group of animals in a grassy field, including a herd of horses and a cow. The horses are scattered throughout the field, with some closer to the foreground and others further in the background. The cow is located near the right side of the field, standing out from the rest of the"}, "116461": {"image_id": 116461, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.20851441405249152, "Bleu_3": 0.09960317042671257, "Bleu_4": 1.2312259432484023e-05, "METEOR": 0.2387065711038275, "ROUGE_L": 0.3084702907711757, "CIDEr": 1.7892223586845424e-08, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.04, "f": 0.0425531914893617, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a large, freshly baked pizza with a generous amount of cheese and herbs on top. The pizza is placed on a metal tray, which is resting on a dining table. The pizza is cut into slices, making it easy to serve and enjoy."}, "7214": {"image_id": 7214, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.27801921873665536, "Bleu_3": 0.15202289038789957, "Bleu_4": 1.6906924964194055e-05, "METEOR": 0.2831927107563666, "ROUGE_L": 0.35510996119016824, "CIDEr": 1.4658377573839057e-08, "SPICE": {"All": {"pr": 0.4375, "re": 0.25, "f": 0.3181818181818182, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.5454545454545454, "f": 0.631578947368421, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image depicts a bathroom with a white toilet situated next to a sink. The toilet is positioned under a window, allowing natural light to enter the room. A mirror is mounted above the sink, and a picture is hanging on the wall above the toilet."}, "264336": {"image_id": 264336, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2439750182321024, "Bleu_3": 0.20696502809816514, "Bleu_4": 0.16662810872728212, "METEOR": 0.3334113284916711, "ROUGE_L": 0.37631091918568776, "CIDEr": 1.6786043502341985e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.1388888888888889, "f": 0.15873015873015875, "fn": 31.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.3125, "f": 0.3703703703703703, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a man riding a bicycle down a path in a park, surrounded by a lush green forest. The man is wearing a red jacket, making him stand out against the natural backdrop. The path is wide enough to accommodate the bicycle, and the man appears to"}, "91994": {"image_id": 91994, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.24174688920325796, "Bleu_3": 0.1629781336014208, "Bleu_4": 0.09506661657351217, "METEOR": 0.2811566847313208, "ROUGE_L": 0.27566171723692706, "CIDEr": 2.837600720447373e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2631578947368421, "f": 0.21739130434782608, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a man sitting in a chair in front of a computer, with a laptop placed on a desk in front of him. He appears to be engaged in a video call or a presentation. The man is wearing glasses and a black shirt, and he seems to be the main focus of the"}, "222831": {"image_id": 222831, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.06440351676097583, "Bleu_3": 4.3613042737873907e-07, "Bleu_4": 1.1406785378264665e-09, "METEOR": 0.10631230885096805, "ROUGE_L": 0.18373493975903615, "CIDEr": 6.194995555010616e-11, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.35, "f": 0.3333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a white table with a collection of white horse figurines on it. There are a total of 11 white horse statues, each varying in size and positioned on the table. The table is placed in a corner, and the horses are arranged in a visually appealing manner. The scene"}, "167122": {"image_id": 167122, "Bleu_1": 0.39215686273740874, "Bleu_2": 0.29372522840318716, "Bleu_3": 0.23099087294416515, "Bleu_4": 0.18929027702829326, "METEOR": 0.33638821535320396, "ROUGE_L": 0.3650508677438659, "CIDEr": 2.221934746948016e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a cat sitting on top of a car, possibly a silver sedan, in a parking lot. The cat is positioned near the center of the car, with its body facing the front. The car appears to be parked in a dark area, possibly at night.\n\nIn the background,"}, "561699": {"image_id": 561699, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 0.07417848716778727, "Bleu_4": 9.65348251762417e-06, "METEOR": 0.18979272147614948, "ROUGE_L": 0.27128335451080055, "CIDEr": 7.442812725959451e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a large, partially eaten pizza sitting on a dining table. The pizza is cut into several slices, with one slice missing, indicating that someone has already enjoyed a portion of it. The pizza is placed on a white plate, which is resting on the table. The table"}, "144932": {"image_id": 144932, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.12993504870706918, "Bleu_3": 0.08551250345584478, "Bleu_4": 1.0422052302891997e-05, "METEOR": 0.14945612015471893, "ROUGE_L": 0.20795454545454545, "CIDEr": 1.0482343522862254e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 40.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.25, "f": 0.34782608695652173, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a large boat traveling across a large body of water, possibly a lake or a bay. The boat is moving through the water, and it appears to be a ferry boat, as it is carrying a car on its deck. The boat is surrounded by a beautiful landscape, with a mountain visible in"}, "267321": {"image_id": 267321, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.16540015368980918, "Bleu_4": 0.12901292604257925, "METEOR": 0.22478572330462376, "ROUGE_L": 0.35777126099706746, "CIDEr": 1.1624304235033258e-06, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2608695652173913, "f": 0.2608695652173913, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a cozy living room with a couch and a chair placed in the room. The couch is situated on the left side of the room, while the chair is located on the right side. A dining table is also present in the room, with a bowl placed on it."}, "47837": {"image_id": 47837, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.27373457909672566, "Bleu_3": 0.20267753101829, "Bleu_4": 0.1543552297172121, "METEOR": 0.27650661349862926, "ROUGE_L": 0.34945894334818584, "CIDEr": 3.081098318654622e-07, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a group of three people sitting around a wooden dining table, enjoying a meal together. They are seated on chairs placed around the table. The table is set with various items, including a bowl, a wine glass, a fork, a knife, and a sp"}, "119802": {"image_id": 119802, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.10910894511574631, "Bleu_3": 6.32714254228105e-07, "Bleu_4": 1.5318500534795794e-09, "METEOR": 0.2216653120520145, "ROUGE_L": 0.26341764342998153, "CIDEr": 7.844418740716087e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a large pink teddy bear sitting on a sidewalk, surrounded by several other stuffed animals. The teddy bear is positioned in the center of the scene, with a few other stuffed animals placed around it.\n\nIn the background, there are multiple cars parked along the street"}, "186624": {"image_id": 186624, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.15755219780890306, "Bleu_3": 0.08141361391768222, "Bleu_4": 1.0464528052553808e-05, "METEOR": 0.2263837260769315, "ROUGE_L": 0.22426470588235295, "CIDEr": 4.779328454624018e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a large, old-fashioned green train engine sitting on a track. The train is positioned in a train station, with a woman standing nearby, possibly admiring the vintage locomotive. The train occupies a significant portion of the scene, extending from the left side to the right"}, "43345": {"image_id": 43345, "Bleu_1": 0.15789473683933522, "Bleu_2": 0.0530994244044193, "Bleu_3": 3.714830298881312e-07, "Bleu_4": 9.870878229862096e-10, "METEOR": 0.18030862577647294, "ROUGE_L": 0.14244016345592528, "CIDEr": 9.396811989121966e-15, "SPICE": {"All": {"pr": 0.3, "re": 0.3157894736842105, "f": 0.3076923076923077, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a brown and white dog with a black collar, standing next to a laptop computer. The dog appears to be looking at the camera with a curious expression. The laptop is placed on a table, and the dog is positioned close to it, possibly seeking attention or wanting to be involved in the activity"}, "260802": {"image_id": 260802, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.11172119198541168, "Bleu_4": 0.07267067086130956, "METEOR": 0.23919917919194333, "ROUGE_L": 0.24811156304474144, "CIDEr": 1.673082105777153e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13043478260869565, "f": 0.13636363636363635, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a man in a blue shirt and white shorts playing tennis on a clay court. He is in the middle of a swing, holding a tennis racket and preparing to hit the ball. The tennis ball is positioned close to the man, and he is focused on making a successful"}, "225537": {"image_id": 225537, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.07457725404314713, "Bleu_4": 9.591924934151242e-06, "METEOR": 0.18597123658917933, "ROUGE_L": 0.25176886792452824, "CIDEr": 1.0578523561050785e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2, "f": 0.20408163265306126, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a black laptop computer with a keyboard and a screen. The laptop is placed on a table, and the keyboard is prominently visible in the foreground. The screen is positioned above the keyboard, and it appears to be turned off.\n\nThere are several keys on the keyboard, including the"}, "533548": {"image_id": 533548, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.22893427324353557, "Bleu_3": 0.1714468183744664, "Bleu_4": 0.09970215112770837, "METEOR": 0.30700227630598176, "ROUGE_L": 0.2853801169590643, "CIDEr": 1.4381592786717172e-11, "SPICE": {"All": {"pr": 0.3125, "re": 0.23809523809523808, "f": 0.27027027027027023, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a man sitting at a table in a room, working on a laptop computer. He is wearing a red jacket and a baseball cap, giving him a casual and comfortable appearance. The table is surrounded by several chairs, with one chair placed in front of the man and others positioned around"}, "120783": {"image_id": 120783, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.08330762903217113, "Bleu_4": 1.0646588104484678e-05, "METEOR": 0.28463358624468205, "ROUGE_L": 0.3028368794326241, "CIDEr": 2.6318916788336064e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13333333333333333, "f": 0.15384615384615383, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a woman wearing a striped shirt and holding a yellow bowl or hat on her head. She is smiling and appears to be enjoying herself. The bowl or hat is filled with bananas, which are scattered around the woman's head.\n\nIn the background, there"}, "574823": {"image_id": 574823, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.13552618543304953, "Bleu_3": 0.07259973977100755, "Bleu_4": 9.498976943212884e-06, "METEOR": 0.2481352902389526, "ROUGE_L": 0.23252858958068615, "CIDEr": 1.0805568568682707e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a baseball field with a baseball player wearing a red and white uniform, standing in the outfield. The player is holding a baseball glove, ready to catch the ball. There are several other people in the background, some of them possibly teammates or opponents.\n\nIn addition to"}, "455301": {"image_id": 455301, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.19069251784568234, "Bleu_3": 0.1264149004545122, "Bleu_4": 0.09344094711204637, "METEOR": 0.2652584688073968, "ROUGE_L": 0.2772727272727273, "CIDEr": 2.5314113573508682e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman and a baby lying in bed together, with the baby looking at a book. The woman is positioned on the left side of the bed, while the baby is on the right side. The baby is holding the book in its hands, seemingly engaged in reading or looking at the pictures."}, "463498": {"image_id": 463498, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.07387419460030926, "Bleu_4": 9.42924728285967e-06, "METEOR": 0.2231904727017034, "ROUGE_L": 0.2445589919816724, "CIDEr": 2.7504009330126964e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15789473684210525, "f": 0.13043478260869565, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a cozy living room with a variety of furniture and decorations. There is a large couch situated in the center of the room, accompanied by two chairs, one on the left side and another on the right side. A coffee table is placed in the middle of the room, surrounded by"}, "132362": {"image_id": 132362, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.18392019594445258, "Bleu_3": 0.09304003187271434, "Bleu_4": 1.1838765649001965e-05, "METEOR": 0.25877956735086294, "ROUGE_L": 0.3342465753424657, "CIDEr": 6.30569085813025e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.35294117647058826, "f": 0.34285714285714286, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a dining table filled with a variety of foods, including a white plate with a bowl of guacamole, a bowl of salsa, and a bowl of beans. There are also several bowls containing different types of food, such as salad, sals"}, "496198": {"image_id": 496198, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.2589571847366968, "Bleu_3": 0.18984971582808918, "Bleu_4": 0.1545297678092279, "METEOR": 0.3241619614751134, "ROUGE_L": 0.3216168717047452, "CIDEr": 5.516815509170189e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2222222222222222, "f": 0.1951219512195122, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a busy street scene with a red fire truck parked in front of a large building. Several people are standing around the fire truck, observing the situation. Some of the individuals are carrying handbags, with one person holding a handbag near the center of the scene and another"}, "227830": {"image_id": 227830, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.07269451760681338, "Bleu_4": 9.458362067955946e-06, "METEOR": 0.19941225791040104, "ROUGE_L": 0.2238532110091743, "CIDEr": 1.180767794941474e-10, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.13333333333333333, "f": 0.09523809523809523, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a large blue and white truck driving down a street, passing by a gas station. The truck is prominently visible in the scene, occupying a significant portion of the image.\n\nThere are several people in the scene, with one person standing near the gas station, another person closer"}, "440528": {"image_id": 440528, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.08330762903217113, "Bleu_4": 1.0646588104484678e-05, "METEOR": 0.16632467665235962, "ROUGE_L": 0.23680124223602486, "CIDEr": 6.632144664056392e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.24324324324324326, "f": 0.2950819672131148, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.17647058823529413, "f": 0.23076923076923078, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a delicious chocolate cake with a white plate underneath it, placed on a dining table. The cake is adorned with a white plate and a white bowl, adding to its presentation. A fork is also visible on the table, ready to be used to enjoy"}, "163412": {"image_id": 163412, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 9.337611011479059e-07, "Bleu_4": 2.0511025549387832e-09, "METEOR": 0.2540539139097492, "ROUGE_L": 0.30329397141081416, "CIDEr": 8.349816443966276e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a large group of people gathered on a street, with many of them riding bicycles. The crowd is diverse, with individuals of various ages and genders participating in the event. Some people are walking alongside the bicyclists, while others are standing or sitting on the side"}, "389174": {"image_id": 389174, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.26967994497923586, "Bleu_3": 0.18913109886682938, "Bleu_4": 0.14826553207746493, "METEOR": 0.289829812882083, "ROUGE_L": 0.32084155161078237, "CIDEr": 2.0576789164877922e-07, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.26666666666666666, "f": 0.33333333333333337, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a couple sitting on a bench in a park, enjoying the serene surroundings. They are positioned close to each other, facing the water, which appears to be a lake or a pond. The park is adorned with trees, creating a peaceful atmosphere."}, "250427": {"image_id": 250427, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.11202240672002234, "Bleu_3": 6.350451047474111e-07, "Bleu_4": 1.5198233764127822e-09, "METEOR": 0.18742857142857142, "ROUGE_L": 0.18252543387193296, "CIDEr": 5.525672069127799e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12903225806451613, "f": 0.14545454545454548, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.26666666666666666, "f": 0.32, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a city street with a large movie theater in the background. There are two men standing in front of the theater, one of them holding a white sign. The street appears to be wet, possibly due to recent rain.\n\nThere are several people walking on the sidewalk, with"}, "399741": {"image_id": 399741, "Bleu_1": 0.387755102032903, "Bleu_2": 0.2980948577450177, "Bleu_3": 0.22469191916740558, "Bleu_4": 0.12531444423275337, "METEOR": 0.3117536123153298, "ROUGE_L": 0.3727629855958097, "CIDEr": 6.60771699581904e-06, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09523809523809523, "f": 0.08333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a young girl sitting on the floor, holding a stuffed animal, which appears to be a teddy bear. She is surrounded by various toys, including a toy car and a toy train. The girl seems to be enjoying her time playing with her toys.\n\nIn the"}, "555461": {"image_id": 555461, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.12326123997631012, "Bleu_4": 0.07903320424081517, "METEOR": 0.26059305774775304, "ROUGE_L": 0.3336806460015629, "CIDEr": 4.766852501960254e-10, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13043478260869565, "f": 0.11538461538461538, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man wearing a yellow jacket and a black hat, sitting at a dining table with a laptop computer. He is smiling and appears to be enjoying his time. The table is surrounded by chairs, with one on the left side and another on the right side.\n\nThere"}, "6593": {"image_id": 6593, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.26302545491742896, "Bleu_3": 0.1745892112051133, "Bleu_4": 0.12019267668952276, "METEOR": 0.2322816858265506, "ROUGE_L": 0.33333333333333337, "CIDEr": 3.553501507071383e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.25, "f": 0.22857142857142856, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image captures a tennis match in progress, with a man in the center of the scene leaping into the air to hit a tennis ball with his racket. He is wearing a white shirt and appears to be in the middle of a powerful swing.\n\nThere are several other people in the scene"}, "536088": {"image_id": 536088, "Bleu_1": 0.340909090901343, "Bleu_2": 0.15422177271257892, "Bleu_3": 8.273336660439995e-07, "Bleu_4": 1.9278114644534454e-09, "METEOR": 0.23762848896936012, "ROUGE_L": 0.285427807486631, "CIDEr": 7.341810829829245e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a large, three-tiered wedding cake adorned with white flowers. The cake is placed on a dining table, and it appears to be the centerpiece of the event. A man is standing nearby, possibly admiring the cake or preparing to cut it"}, "106849": {"image_id": 106849, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.161880977056518, "Bleu_3": 0.07957856377253618, "Bleu_4": 9.970215112770837e-06, "METEOR": 0.2619437492623099, "ROUGE_L": 0.24970760233918127, "CIDEr": 5.138148377716377e-13, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.10526315789473684, "f": 0.0851063829787234, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a man standing in front of a table filled with various bottles of wine. He appears to be engaged in a conversation with another man, who is also standing near the table. The table is covered with numerous bottles of wine, some of which are placed closer to the foreground, while"}, "38259": {"image_id": 38259, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.1271283452298885, "Bleu_3": 7.216702086087403e-07, "Bleu_4": 1.729584404005621e-09, "METEOR": 0.20297311795618572, "ROUGE_L": 0.2053872053872054, "CIDEr": 3.119224205004616e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.16129032258064516, "f": 0.19607843137254902, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a large airplane parked on the tarmac at an airport. The airplane is positioned in the middle of the scene, with its nose facing the viewer. The airplane is connected to a jetway, allowing passengers to board or disembark.\n\nIn the for"}, "535602": {"image_id": 535602, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 0.10556671919572966, "Bleu_4": 1.2447904522737402e-05, "METEOR": 0.236259566261966, "ROUGE_L": 0.2897862232779097, "CIDEr": 6.799271100806076e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a cat standing on a carpeted floor, looking at a pizza box that is open and placed on the floor. The pizza box is filled with pizza slices, and there are a few more slices scattered around the floor. A laptop is also present in the scene, placed on"}, "448600": {"image_id": 448600, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.13398285197459078, "Bleu_4": 0.08598520764469421, "METEOR": 0.22665706125777113, "ROUGE_L": 0.26771159874608147, "CIDEr": 6.126979158111772e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a delicious slice of cake with white frosting and strawberries on top, placed on a white plate. The cake is accompanied by a fork, which is resting on the plate, ready for someone to enjoy the dessert. The plate is positioned on a dining"}, "499226": {"image_id": 499226, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.19402850002522387, "Bleu_3": 0.11539535372137631, "Bleu_4": 1.337614391433853e-05, "METEOR": 0.268424617345675, "ROUGE_L": 0.29847094801223245, "CIDEr": 2.210832297232046e-09, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.2916666666666667, "f": 0.2978723404255319, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a gray and white cat lying on a couch, appearing to be sleeping or resting. The couch is covered with a floral print, adding a touch of color to the scene. A remote control is placed on the couch, close to the cat, suggesting that the cat's"}, "286303": {"image_id": 286303, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.2862879395127905, "Bleu_3": 0.21570179474872342, "Bleu_4": 0.14300048439150906, "METEOR": 0.27487780565728037, "ROUGE_L": 0.3790960451977401, "CIDEr": 5.03358847121008e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.19230769230769232, "f": 0.2173913043478261, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a man wearing a green shirt and a patterned tie. The tie is a combination of blue and white, with a checkered pattern. The man is standing in front of a wall, and the tie is neatly tied around his neck. The shirt is tucked into the man"}, "363072": {"image_id": 363072, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 0.07733118331435387, "Bleu_4": 9.806713568284028e-06, "METEOR": 0.19646398881280477, "ROUGE_L": 0.14796846573681016, "CIDEr": 1.1009670957742073e-11, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.2222222222222222, "f": 0.2711864406779661, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.46153846153846156, "f": 0.4999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a train station with two trains parked on the tracks. One train is positioned on the left side of the image, while the other is on the right side. The trains are parked next to each other, with one train being longer than the other.\n\nIn the background, there is"}, "416193": {"image_id": 416193, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.1047873663970416, "Bleu_3": 6.073987916691404e-07, "Bleu_4": 1.4699248546847117e-09, "METEOR": 0.1799213816994328, "ROUGE_L": 0.24497991967871488, "CIDEr": 2.7597063760236435e-10, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.26666666666666666, "f": 0.326530612244898, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a lush green field with a herd of zebras grazing on the grass. There are three zebras in the scene, with one on the left side, another in the middle, and the third on the right side of the field. They are all focused on eating the grass"}, "390048": {"image_id": 390048, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1234482786556696, "Bleu_3": 0.06685490874553476, "Bleu_4": 8.792400740713413e-06, "METEOR": 0.18429190413619306, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.0201544234154285e-12, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.0625, "f": 0.07407407407407407, "fn": 30.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a man sitting at a dining table, enjoying a large sandwich with a smile on his face. He is wearing a red shirt and appears to be in a restaurant setting. The man is taking a bite of the sandwich, which is placed in front of him on the table"}, "46924": {"image_id": 46924, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.22117152024581002, "Bleu_3": 0.17804731863811085, "Bleu_4": 0.12197379410072967, "METEOR": 0.23778165036392407, "ROUGE_L": 0.24970760233918127, "CIDEr": 3.96025611865817e-12, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.4444444444444444, "f": 0.3555555555555555, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.8, "f": 0.5000000000000001, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a person holding an Apple iPhone in their hand, showcasing the back of the device. The person is standing in front of a wooden desk, which has a few items on it. There are two cups placed on the desk, one near the top left corner and the other near the"}, "26026": {"image_id": 26026, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.0922138891935132, "Bleu_3": 5.655855085604915e-07, "Bleu_4": 1.4082645504822834e-09, "METEOR": 0.14632654035369422, "ROUGE_L": 0.184067592033796, "CIDEr": 7.54178636885778e-10, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.3684210526315789, "f": 0.3684210526315789, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8571428571428571, "f": 0.75, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a group of people, including children, riding on the back of an elephant. The elephant is positioned in the center of the scene, with the riders sitting on its back, enjoying the experience. There are at least five people visible in the image, with some of"}, "382333": {"image_id": 382333, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 0.12339926173807332, "Bleu_4": 0.08038616175390124, "METEOR": 0.21069646527509603, "ROUGE_L": 0.23680124223602486, "CIDEr": 1.2966194449141001e-09, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a garden with a variety of plants, including tomatoes, peppers, and beans. The plants are growing in a dirt field, with some of them in pots. There are several tomato plants, with some of them placed in wire cages to protect them from potential pests."}, "508899": {"image_id": 508899, "Bleu_1": 0.3636363636297521, "Bleu_2": 0.23210354127000468, "Bleu_3": 0.1450116762655686, "Bleu_4": 0.08750873255009596, "METEOR": 0.19886166971175157, "ROUGE_L": 0.27006087437742116, "CIDEr": 2.476873577561816e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23529411764705882, "f": 0.20512820512820512, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a living room with a white carpet and a television on the left side of the room. A small white bunny is sitting on the floor, positioned in the center of the room. The room also contains a couch located on the right side of the room, and a chair placed near"}, "20553": {"image_id": 20553, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.14601036983997978, "ROUGE_L": 0.24192634560906517, "CIDEr": 2.738431558757918e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.23333333333333334, "f": 0.2413793103448276, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a teddy bear sitting on a chair in a desert-like setting. The chair is placed on a dirt ground, and the teddy bear is positioned in the middle of the scene. The chair is surrounded by various items, including a bottle, a cup, and a vase."}, "65465": {"image_id": 65465, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.17720317768650332, "Bleu_3": 8.936417387415975e-07, "Bleu_4": 2.0183917843818546e-09, "METEOR": 0.25389132256904945, "ROUGE_L": 0.2969401947148818, "CIDEr": 1.4695826198371653e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a group of elephants, including both adult and baby elephants, standing together in a grassy field. The elephants are of various sizes, with some being larger and others smaller, indicating a family or a herd.\n\nThe elephants are spread out across the field"}, "320823": {"image_id": 320823, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.10514001031125872, "Bleu_3": 6.172759988054166e-07, "Bleu_4": 1.5037307654525653e-09, "METEOR": 0.15701105905087098, "ROUGE_L": 0.18711656441717792, "CIDEr": 4.673608457495072e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a joyful wedding celebration with a bride and groom sitting together at a table. The bride is wearing a beautiful red dress, and the groom is dressed in a suit. They are surrounded by a group of people, some of whom are standing and others sitting,"}, "477087": {"image_id": 477087, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.10087498788996685, "Bleu_3": 6.092349727774223e-07, "Bleu_4": 1.5056549290355162e-09, "METEOR": 0.19407063146961223, "ROUGE_L": 0.22775357809583074, "CIDEr": 2.286874728783236e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image showcases a baseball-themed display featuring various baseball items and memorabilia. There are multiple baseballs scattered throughout the scene, with some placed closer to the foreground and others further back. A baseball glove is also present, positioned towards the left side of the image.\n\nIn addition"}, "71357": {"image_id": 71357, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 0.08378836055206641, "Bleu_4": 1.0467398290590384e-05, "METEOR": 0.2004581263959451, "ROUGE_L": 0.23047858942065497, "CIDEr": 3.883469645377865e-12, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.3181818181818182, "f": 0.2857142857142857, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a yellow and black train parked at a train station. The train is positioned on the tracks, occupying a significant portion of the scene. The train appears to be a passenger train, as it is designed for public transportation.\n\nThere are several people visible in the image, likely waiting"}, "343453": {"image_id": 343453, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 8.077421359130519e-07, "Bleu_4": 1.8710588175603566e-09, "METEOR": 0.2771364344177333, "ROUGE_L": 0.26991150442477874, "CIDEr": 1.5866942681879638e-08, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a woman standing on a snow-covered slope, wearing a blue hoodie and a black hat. She is posing for a picture, possibly enjoying her time skiing or snowboarding. The woman is positioned in the center of the scene, with her skis visible on"}, "34580": {"image_id": 34580, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.2862879395127905, "Bleu_3": 0.22707501691546758, "Bleu_4": 0.1767387198086519, "METEOR": 0.3041250086105119, "ROUGE_L": 0.3641791044776119, "CIDEr": 8.168879397712432e-09, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.17857142857142858, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a red and white fire hydrant situated in a grassy area, surrounded by a parking lot filled with various cars. The fire hydrant is located near the center of the scene, with the parking lot stretching out in the background.\n\nThere are several cars parked in the lot"}, "151393": {"image_id": 151393, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.21128856367777224, "Bleu_3": 0.16808980602487011, "Bleu_4": 0.13266210611018667, "METEOR": 0.30246357214461667, "ROUGE_L": 0.3386798272671191, "CIDEr": 3.500805484959434e-06, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.12, "f": 0.1276595744680851, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a stop sign with a sticker underneath it, which reads \"driving.\" The stop sign is positioned on a pole, and there is a no parking sign above it. The scene is set in a snowy environment, with trees visible in the background. The combination of the"}, "239351": {"image_id": 239351, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.27186953392208474, "Bleu_3": 0.21600968308447857, "Bleu_4": 0.162842632521902, "METEOR": 0.28957283367103237, "ROUGE_L": 0.40568319226118504, "CIDEr": 1.3285074951253843e-05, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.34782608695652173, "f": 0.3636363636363636, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a man and a woman standing on a dirt road, each holding a sign. The woman is holding a sign that reads \"September 2011,\" while the man is holding a sign that reads \"August 2011.\" They are both dressed in business attire, with"}, "357109": {"image_id": 357109, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1314021767661405, "Bleu_4": 0.08678345215448577, "METEOR": 0.2846960864115188, "ROUGE_L": 0.26852531181217903, "CIDEr": 6.366278562118834e-07, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a skateboarder performing a trick on a ramp, surrounded by a large crowd of people watching the impressive display. The skateboarder is in the middle of the scene, skillfully riding the skateboard up the ramp.\n\nThere are numerous spectators in"}, "174888": {"image_id": 174888, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.24462302738989036, "Bleu_3": 0.17328685148662828, "Bleu_4": 0.12331859801407646, "METEOR": 0.3066663508477195, "ROUGE_L": 0.35192307692307695, "CIDEr": 2.580912602500502e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.11538461538461539, "f": 0.13043478260869565, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man wearing glasses, standing outside a deli and eating a slice of pizza. He is holding the pizza slice in a paper plate, taking a bite. Another person is visible in the background, standing further away from the man eating pizza.\n\nThere are a"}, "542934": {"image_id": 542934, "Bleu_1": 0.4473684210408588, "Bleu_2": 0.34772170490469695, "Bleu_3": 0.27212646708903987, "Bleu_4": 0.21906655280246518, "METEOR": 0.2831443898805643, "ROUGE_L": 0.362555720653789, "CIDEr": 2.596360684404927e-05, "SPICE": {"All": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image depicts a small, old-fashioned kitchen with wooden cabinets and a wooden countertop. The kitchen is equipped with various appliances, including a refrigerator, a microwave, and an oven. There are also several pots and pans hanging on"}, "467848": {"image_id": 467848, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.22404481344004462, "Bleu_3": 0.16002133902079144, "Bleu_4": 0.1143090498056583, "METEOR": 0.24622787096263551, "ROUGE_L": 0.272108843537415, "CIDEr": 1.0382634888622685e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.17857142857142858, "f": 0.20833333333333331, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a red trailer with a large tank on the back, parked in front of a building. The tank appears to be a large water tank, possibly for a construction project or a similar purpose. The trailer is connected to a truck, which is parked next to the building."}, "413124": {"image_id": 413124, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.2807284211697214, "Bleu_3": 0.18473715501020269, "Bleu_4": 0.1266555331066003, "METEOR": 0.22692963585099932, "ROUGE_L": 0.30432372505543237, "CIDEr": 5.723867193453524e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.18518518518518517, "f": 0.17857142857142858, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a young boy wearing a baseball uniform, standing on a field and holding a baseball glove. He appears to be a baseball player, possibly a catcher, as he is wearing a baseball glove and is positioned to catch a ball. The boy is looking at the camera, possibly pos"}, "300773": {"image_id": 300773, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.15604694598027796, "Bleu_3": 0.09661597203086345, "Bleu_4": 1.1421357570300361e-05, "METEOR": 0.23481799438656747, "ROUGE_L": 0.2096700274977085, "CIDEr": 1.133153447503706e-13, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image features a man and a woman standing next to each other, both looking at a cell phone. The woman is holding the cell phone, while the man is standing close to her. They appear to be engaged in a conversation or sharing information on the screen of the phone.\n\nIn the scene, there are"}, "373440": {"image_id": 373440, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.1313579154832357, "Bleu_3": 0.08897106801212075, "Bleu_4": 0.06189082809605832, "METEOR": 0.19610177654551883, "ROUGE_L": 0.21997836278398844, "CIDEr": 1.5920655326325843e-10, "SPICE": {"All": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a display case filled with a variety of teddy bears. There are at least nine teddy bears in the display, each with different colors and sizes. They are arranged in a way that showcases their unique features and makes the display visually appealing. The teddy bears are placed"}, "334321": {"image_id": 334321, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.17878070701566398, "Bleu_4": 0.1381962749917267, "METEOR": 0.24879212581744395, "ROUGE_L": 0.3129988597491448, "CIDEr": 4.905780630972226e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.10344827586206896, "f": 0.12244897959183673, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a large white dog sitting on a park bench, seemingly enjoying the outdoor environment. The bench is located in the middle of the scene, with the dog occupying a significant portion of it.\n\nThere are several people in the background, some of them sitting on other benches"}, "535668": {"image_id": 535668, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.11262478804206155, "Bleu_4": 1.3203863485033786e-05, "METEOR": 0.21262946036936298, "ROUGE_L": 0.27128335451080055, "CIDEr": 6.149680349252817e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress, with a batter swinging a baseball bat at a ball. The batter is wearing a red jersey and is in the middle of the swing. The catcher is positioned behind the batter, ready to catch the ball if it's not hit."}, "157184": {"image_id": 157184, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.17251638983203116, "Bleu_3": 0.1363141538186681, "Bleu_4": 0.10244098719420823, "METEOR": 0.2842286641933639, "ROUGE_L": 0.31504196255648803, "CIDEr": 3.620621552168474e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man wearing glasses and a plaid shirt, holding a pair of black scissors in his hands. He appears to be smiling and posing for the camera. The man is standing in front of a window, which can be seen in the background. The scissors are"}, "64390": {"image_id": 64390, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.20982172726164103, "Bleu_3": 0.11919074177013061, "Bleu_4": 1.3498619260852726e-05, "METEOR": 0.17402233650707588, "ROUGE_L": 0.25326215895610915, "CIDEr": 1.670060992353633e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13636363636363635, "f": 0.16666666666666663, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a busy street with a traffic light hanging above the road. The traffic light is displaying a red light, indicating that vehicles must stop. There are several cars on the street, with one car positioned in the foreground and another car further back on the right side of the image.\n\nIn"}, "91857": {"image_id": 91857, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 7.355956748968672e-07, "Bleu_4": 1.7151018577788952e-09, "METEOR": 0.17434185153612008, "ROUGE_L": 0.2543786488740617, "CIDEr": 2.111229002968758e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a giraffe standing in a forest, reaching up to eat from a hanging basket. The giraffe's long neck allows it to easily access the food provided in the basket. The scene is set in a lush green environment, with trees surrounding the giraffe. The gira"}, "275202": {"image_id": 275202, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.09337611011479056, "Bleu_4": 1.1534197288455865e-05, "METEOR": 0.1998468183785956, "ROUGE_L": 0.22679390259015986, "CIDEr": 1.6075196669504157e-09, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a delicious pizza with a generous amount of cheese and spinach on top, placed on a wooden dining table. The pizza is cut into slices, making it easy to serve and enjoy. A knife is also visible on the table, likely used for cutting the pizza"}, "508811": {"image_id": 508811, "Bleu_1": 0.41509433961480957, "Bleu_2": 0.33429951892828713, "Bleu_3": 0.24846570667022772, "Bleu_4": 0.18716400876315178, "METEOR": 0.2930488724063347, "ROUGE_L": 0.36868131868131865, "CIDEr": 5.174278620204961e-08, "SPICE": {"All": {"pr": 0.45, "re": 0.45, "f": 0.45, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 9.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.8333333333333334, "f": 0.6666666666666667, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a man in the middle of a tennis court, holding a tennis racket and preparing to serve the ball. He is in the process of throwing the ball up in the air, getting ready to hit it with his racket. The tennis player is focused and determined, showcasing his skill"}, "511111": {"image_id": 511111, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.192868005722087, "Bleu_3": 0.13637339509226334, "Bleu_4": 0.10421677374070494, "METEOR": 0.3011478495900899, "ROUGE_L": 0.28968792401628224, "CIDEr": 9.043985186713044e-09, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2857142857142857, "f": 0.3, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a kitchen scene with a glass of orange juice being squeezed by a juicer. The juicer is located on the left side of the glass, and the juice is being poured into the glass. The juicer is a modern and sleek appliance, and"}, "70471": {"image_id": 70471, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2285817953234835, "Bleu_3": 0.1600261774492132, "Bleu_4": 0.12522212981184377, "METEOR": 0.2932457926803876, "ROUGE_L": 0.3249482095294466, "CIDEr": 4.603555566577171e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.14285714285714285, "f": 0.15094339622641512, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a baby girl sitting on a couch, holding a remote control in her mouth. She appears to be enjoying her playtime with the remote. The couch is situated in the background, and there is a person sitting on the left side of the couch, possibly the baby's parent or"}, "95516": {"image_id": 95516, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.22131333406452386, "Bleu_3": 0.15981270600836578, "Bleu_4": 0.11479990094513041, "METEOR": 0.2446767530789129, "ROUGE_L": 0.326397146254459, "CIDEr": 7.294510559910547e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a pickup truck parked in a driveway, with a bed full of firewood. The truck is a silver GMC, and the bed is packed with numerous logs and branches, indicating that the owner is likely preparing for a fire or has recently used the firewood for he"}, "299946": {"image_id": 299946, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.13204641200979725, "Bleu_4": 1.5124526410231296e-05, "METEOR": 0.2526517220613953, "ROUGE_L": 0.2848565710473649, "CIDEr": 6.346016649860364e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a man standing in a kitchen, preparing a meal. He is using a blender to mix ingredients, and there is a bowl on the counter nearby. The man is focused on his task, and the kitchen appears to be well-equipped with various items.\n\nIn"}, "356456": {"image_id": 356456, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.1475489144223407, "Bleu_3": 7.529519927190925e-07, "Bleu_4": 1.7093577453608883e-09, "METEOR": 0.2682375215370712, "ROUGE_L": 0.25707405177603854, "CIDEr": 6.421825536126318e-10, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.4375, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a train yard with a train car sitting on the tracks. The train car is an old, rusty orange train car with graffiti on it, giving it a worn and aged appearance. The train car is positioned next to a silver train car, which is also sitting on the tracks."}, "420181": {"image_id": 420181, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.17037481092075088, "Bleu_3": 0.10441355063931189, "Bleu_4": 0.06907567655081503, "METEOR": 0.229959418729583, "ROUGE_L": 0.2083096186681844, "CIDEr": 3.132601746015116e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.2222222222222222, "f": 0.18604651162790697, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a group of people gathered around a food stand, with one man wearing a leather jacket and a black and gold lion emblem on the back. The man appears to be ordering food from the stand, while the others are waiting in line.\n\nThere are several people in the scene"}, "324785": {"image_id": 324785, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.11895773785545558, "Bleu_3": 6.522364605376366e-07, "Bleu_4": 1.5348336186916813e-09, "METEOR": 0.10798194102691377, "ROUGE_L": 0.20010934937124114, "CIDEr": 6.081763765199888e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.0967741935483871, "f": 0.10714285714285714, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a harbor filled with various boats, including a large boat with a crab trap on the back. The crab trap is filled with crabs, and the boat is surrounded by other boats of different sizes. Some boats are docked close to the shore, while others are further out in the"}, "100329": {"image_id": 100329, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.10755901259843535, "Bleu_4": 0.08441965712987705, "METEOR": 0.21568038626195568, "ROUGE_L": 0.2544696066746126, "CIDEr": 9.835406280536143e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.21428571428571427, "f": 0.24489795918367344, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a large brown bear standing near a waterfall, with its mouth open and its tongue sticking out. The bear appears to be enjoying the water and possibly trying to catch fish. The waterfall is located in the background, creating a picturesque scene.\n\nThere are several rocks scattered around the"}, "191425": {"image_id": 191425, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.09108032686789493, "Bleu_3": 5.494899059541206e-07, "Bleu_4": 1.356503033114134e-09, "METEOR": 0.1429552809955083, "ROUGE_L": 0.18780788177339902, "CIDEr": 8.918558644388613e-12, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.375, "f": 0.35999999999999993, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.7, "f": 0.6363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image features a beautiful sunset with a silhouette of a hill in the foreground. The sky is filled with a warm glow, creating a serene atmosphere. The sun is setting behind the hill, casting a warm light on the landscape. The scene is further enhanced by the presence of a few"}, "494620": {"image_id": 494620, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 6.789968544843665e-07, "Bleu_4": 1.581824583382231e-09, "METEOR": 0.20496257808677962, "ROUGE_L": 0.24302788844621512, "CIDEr": 3.199822581851302e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of a young boy riding a horse. The boy is wearing a suit and a hat, giving the impression of a formal or special occasion. The horse is positioned in the center of the scene, with the boy sitting comfortably on its back.\n\nThe setting"}, "359260": {"image_id": 359260, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.11455372707190037, "Bleu_4": 1.351928705097216e-05, "METEOR": 0.2090297820781363, "ROUGE_L": 0.2616421568627451, "CIDEr": 9.88681666436024e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man standing on a beach, guiding a horse-drawn cart along the shoreline. The horse is pulling the cart, and the man appears to be steering it. The scene is set against a backdrop of the ocean, creating a serene and picturesque atmosphere. The man"}, "286342": {"image_id": 286342, "Bleu_1": 0.17543859648815024, "Bleu_2": 0.12515654357822442, "Bleu_3": 0.0657932708360904, "Bleu_4": 8.521924221914256e-06, "METEOR": 0.19979837224362554, "ROUGE_L": 0.17438536306460833, "CIDEr": 2.1203262813221113e-14, "SPICE": {"All": {"pr": 0.24, "re": 0.2727272727272727, "f": 0.2553191489361702, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a black computer keyboard sitting on a pink surface, likely a bed. The keyboard is placed in the center of the scene, with a mouse located to the left of it. The mouse is positioned closer to the bottom left corner of the keyboard. The keyboard and mouse are the main focus of the"}, "576191": {"image_id": 576191, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.23645189633360697, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.2018068901956255e-09, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.34615384615384615, "f": 0.34615384615384615, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a gray and black cat lying on a stone step, possibly a staircase or a sidewalk. The cat appears to be resting or sleeping, with its head tucked under its paws. The scene is set against a backdrop of a green bench, which is located to"}, "580908": {"image_id": 580908, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.15305490466093202, "Bleu_4": 0.1105560791026379, "METEOR": 0.27763192512755175, "ROUGE_L": 0.2966050186680559, "CIDEr": 2.439308981490552e-10, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2916666666666667, "f": 0.27999999999999997, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts a group of baseball players gathered on a field, with some of them holding baseball bats. There are at least 12 people in the scene, with some standing closer to the foreground and others further back. The players are engaged in conversation and enjoying each other's company."}, "556420": {"image_id": 556420, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.18289322463964397, "ROUGE_L": 0.2559952038369305, "CIDEr": 1.1503088215861971e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15789473684210525, "f": 0.14634146341463414, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a beautiful beach scene with a straw umbrella providing shade for a wooden bench. The bench is situated under the umbrella, offering a comfortable spot to relax and enjoy the view. The umbrella is positioned near the center of the scene, while the bench is"}, "81251": {"image_id": 81251, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.2526455763146363, "Bleu_3": 0.1770551317386454, "Bleu_4": 0.10538486915683062, "METEOR": 0.2968783556792143, "ROUGE_L": 0.3657074340527578, "CIDEr": 1.503420762187868e-08, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2608695652173913, "f": 0.2608695652173913, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a delicious pizza topped with a generous amount of cheese and tomatoes. The pizza is placed on a white plate, which is resting on a wooden table. The cheese is spread all over the pizza, with some pieces of tomato scattered around, adding a burst"}, "130437": {"image_id": 130437, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.06317667074948415, "Bleu_3": 4.277412148886299e-07, "Bleu_4": 1.1185188895571612e-09, "METEOR": 0.17782207020045873, "ROUGE_L": 0.18100890207715134, "CIDEr": 5.967068680664785e-12, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a red and white train traveling down the tracks, passing by a tall building. The train is positioned in the middle of the scene, with the tracks running horizontally across the image.\n\nThere are several cars visible in the image, with one car located near the right edge of the"}, "359546": {"image_id": 359546, "Bleu_1": 0.255813953482423, "Bleu_2": 0.13517553494737666, "Bleu_3": 0.07638430164587322, "Bleu_4": 1.0273965107862501e-05, "METEOR": 0.16986142158853765, "ROUGE_L": 0.25505226480836235, "CIDEr": 8.126479708525118e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a beautiful beach scene with a row of large, open umbrellas providing shade for beachgoers. The umbrellas are positioned close to the water, creating a relaxing atmosphere for those enjoying the beach.\n\nThere are several chairs placed under the umbrell"}, "298979": {"image_id": 298979, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.3414070032975731, "Bleu_3": 0.21800382296695808, "Bleu_4": 0.12387535527350022, "METEOR": 0.3194194092010877, "ROUGE_L": 0.37958929682638454, "CIDEr": 3.251340248578543e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14814814814814814, "f": 0.15999999999999998, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a large herd of zebras grazing in a grassy field near a body of water. There are at least 14 zebras visible in the scene, scattered across the field. Some zebras are closer to the water, while others are further away, enjoying the grass"}, "413079": {"image_id": 413079, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.14540168172223333, "Bleu_3": 0.07954810829018738, "Bleu_4": 1.0526316596948142e-05, "METEOR": 0.23943654981449577, "ROUGE_L": 0.2636887608069164, "CIDEr": 1.0466344713343648e-07, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.125, "f": 0.14545454545454545, "fn": 28.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a man riding a brown horse, skillfully jumping over a hurdle in a field. The horse and rider are in the middle of the jump, showcasing their athleticism and coordination.\n\nIn the background, there are several other horses, some of which"}, "403584": {"image_id": 403584, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.14285714285419707, "Bleu_3": 0.09540665858824407, "Bleu_4": 0.06591656331231212, "METEOR": 0.19202800483309568, "ROUGE_L": 0.26940063091482647, "CIDEr": 1.331931865538657e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3157894736842105, "f": 0.3, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a beach scene with two people standing on the sand, each holding a surfboard. They appear to be enjoying their time together, possibly discussing their surfing plans or sharing their experiences.\n\nIn the background, there are several other people scattered across the beach, some closer to"}, "401004": {"image_id": 401004, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.1883108942847125, "Bleu_3": 0.1155245676577522, "Bleu_4": 0.07650725768637208, "METEOR": 0.23403695848648315, "ROUGE_L": 0.31282051282051276, "CIDEr": 4.5589543145032856e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a lively bar scene with several people sitting at various tables and chairs. There are at least nine people in the scene, some of them engaged in conversation, while others are focused on their drinks.\n\nThe bar is well-equipped with numerous bottles and cups placed"}, "489829": {"image_id": 489829, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 0.060526698984524764, "Bleu_4": 8.120218167477751e-06, "METEOR": 0.22722167823784867, "ROUGE_L": 0.22344322344322343, "CIDEr": 2.334984742739502e-12, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2777777777777778, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a woman standing in a room with a variety of clocks displayed around her. There are four clocks in total, with one on the left side, one on the right side, and two in the middle of the room. The woman appears to be examining the clocks, possibly considering which one"}, "177810": {"image_id": 177810, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.13663794162380996, "Bleu_4": 0.10207315006261665, "METEOR": 0.2582050665347169, "ROUGE_L": 0.2594167679222357, "CIDEr": 1.3842076278302394e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08695652173913043, "f": 0.0909090909090909, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a cozy scene with three teddy bears sitting on a table. The teddy bears are positioned in a way that they appear to be a family, with one teddy bear on the left, another in the middle, and the third on the right.\n\nIn addition to the"}, "130225": {"image_id": 130225, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.22281245492303933, "Bleu_3": 0.14793835438670558, "Bleu_4": 0.10952542776957251, "METEOR": 0.2866017972133953, "ROUGE_L": 0.28696236559139787, "CIDEr": 6.829174086743614e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.35714285714285715, "f": 0.25641025641025644, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image captures a lively scene at a beach, where a large group of people is enjoying a day of kite flying. There are numerous kites of various sizes and colors soaring in the sky, creating a vibrant and colorful atmosphere.\n\nTwo people, a man and a child"}, "364010": {"image_id": 364010, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.22893427324353557, "Bleu_3": 0.1917956598705532, "Bleu_4": 0.1533739262475207, "METEOR": 0.2510243258923706, "ROUGE_L": 0.33062330623306235, "CIDEr": 3.8944517529157674e-11, "SPICE": {"All": {"pr": 0.24242424242424243, "re": 0.25, "f": 0.24615384615384617, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.6363636363636364, "f": 0.6086956521739131, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image features a small black and brown dog sitting on a green blanket in the back of a car. The dog appears to be looking at the camera, possibly posing for a picture. Another dog can be seen in the background, partially hidden by the first dog.\n\nThe car's interior is furn"}, "527728": {"image_id": 527728, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.08668270200700183, "Bleu_4": 1.0908370302144318e-05, "METEOR": 0.19295810938995311, "ROUGE_L": 0.26940063091482647, "CIDEr": 2.2134723162226805e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a large elephant with a long trunk, standing in a body of water. The elephant appears to be enjoying the water, possibly in a zoo or a water park. The water is calm, and the elephant seems to be playing with a toy, which is located"}, "8787": {"image_id": 8787, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.20982172726164103, "Bleu_3": 0.15017092450877165, "Bleu_4": 0.09027070761263258, "METEOR": 0.27123705851182117, "ROUGE_L": 0.3210526315789473, "CIDEr": 2.447238453104821e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.2777777777777778, "f": 0.2631578947368421, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man holding a small brown dog in his arms while standing on a sidewalk. The man is wearing a striped shirt and appears to be holding a camera in his other hand. The dog is comfortably resting in the man's arms, and the scene seems to be a cas"}, "198717": {"image_id": 198717, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.12354612406992554, "Bleu_3": 6.973999503999067e-07, "Bleu_4": 1.6662810872712766e-09, "METEOR": 0.17780507586506006, "ROUGE_L": 0.20847573479152426, "CIDEr": 2.3760807173808077e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a man lying in bed, holding a frisbee in his hand. Another man is standing next to the bed, making a funny face and pointing at the frisbee. The scene appears to be a playful and lighthearted moment between the two men.\n\nThe bed"}, "465223": {"image_id": 465223, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.23329531792993197, "Bleu_3": 0.17474467808257138, "Bleu_4": 0.12086984532184321, "METEOR": 0.22876160836893225, "ROUGE_L": 0.24707788450410828, "CIDEr": 3.403630125863147e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a tennis match in progress, with a crowd of people watching the game. There are several players on the court, including a man and a woman who are the main focus of the scene. They are standing near the net, possibly discussing a point or preparing for the next play."}, "377595": {"image_id": 377595, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.18824832212957474, "Bleu_3": 0.09525609865690522, "Bleu_4": 1.212424196299872e-05, "METEOR": 0.1506710050254899, "ROUGE_L": 0.33993808049535607, "CIDEr": 1.8785144547859483e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.24, "f": 0.2264150943396226, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image features a dining table with a large, uncooked turkey placed on a foil-covered tray. The turkey is wrapped in plastic, and it appears to be a homemade creation. The table is surrounded by various kitchen utensils and items, including a knife"}, "386968": {"image_id": 386968, "Bleu_1": 0.40740740739986286, "Bleu_2": 0.3719741655935811, "Bleu_3": 0.26507783667695894, "Bleu_4": 0.13824120768778234, "METEOR": 0.3049698298645375, "ROUGE_L": 0.32901833872707653, "CIDEr": 1.2824512704982683e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a woman riding a bicycle with her dog in a basket attached to the front of the bike. The dog appears to be a small white and brown dog, and it is sitting in the basket next to the woman. The woman is wearing a coat, and she is riding the"}, "405994": {"image_id": 405994, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.12903971808302675, "Bleu_3": 7.17923383724535e-07, "Bleu_4": 1.7029245450294905e-09, "METEOR": 0.16664598440998343, "ROUGE_L": 0.27180140038192235, "CIDEr": 2.446059091498279e-09, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.0625, "f": 0.05714285714285714, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features a display of colorful wooden baseball bats, each with a unique design. The bats are arranged in a row, with some of them having a rainbow-colored design. The bats are positioned in front of a window, possibly in a store or a museum.\n\nThere"}, "134815": {"image_id": 134815, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.16408253082431878, "Bleu_3": 0.08914842985218376, "Bleu_4": 1.1763453574139755e-05, "METEOR": 0.15606471724400467, "ROUGE_L": 0.2691176470588235, "CIDEr": 6.465132169850383e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a large, well-equipped kitchen with wooden cabinets and a center island. The kitchen is filled with various cooking utensils and appliances, including a refrigerator, oven, and sink. There are multiple bottles, cups, and bowls scattered throughout the"}, "201934": {"image_id": 201934, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.2807284211697214, "Bleu_3": 0.21147125246896165, "Bleu_4": 0.1551207146056763, "METEOR": 0.24851198385164192, "ROUGE_L": 0.28773584905660377, "CIDEr": 6.454950964927068e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a white bus parked on the side of a road, next to a fence. The bus is positioned in front of a parking lot filled with various cars. There are at least 13 cars visible in the parking lot, with some parked closer to the bus and others further"}, "320899": {"image_id": 320899, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.14887283354071895, "Bleu_3": 7.839548039992823e-07, "Bleu_4": 1.8089024246182524e-09, "METEOR": 0.16383781194663394, "ROUGE_L": 0.20013123359580048, "CIDEr": 3.169509950832359e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.24, "f": 0.2264150943396226, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a bed with a large, patterned comforter on it. The bed is positioned in a room with a window, and the comforter has a unique design that resembles a diamond pattern. The bed is situated on a hardwood floor, which adds a contrasting element to"}, "406217": {"image_id": 406217, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.20982172726164103, "Bleu_3": 0.16176672459792843, "Bleu_4": 0.09544965216004306, "METEOR": 0.3073711962871904, "ROUGE_L": 0.2853801169590643, "CIDEr": 2.721653679307156e-12, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.27586206896551724, "f": 0.3137254901960784, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a large sign that reads \"Factory Training Technicians\" in yellow and black. The sign is positioned in front of a building, possibly a factory or a training facility. The building has a glass facade, allowing the sign to be clearly visible from the outside. The sign is placed in the for"}, "130076": {"image_id": 130076, "Bleu_1": 0.3399999999932, "Bleu_2": 0.276272565791757, "Bleu_3": 0.18528123009400493, "Bleu_4": 0.10785719076969459, "METEOR": 0.2791930484438715, "ROUGE_L": 0.3100381194409149, "CIDEr": 6.820957044701012e-11, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3125, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man standing in a living room, holding a Wii remote in his hand. He appears to be playing a video game, possibly on a Nintendo Wii console. The living room is furnished with a couch and a chair, and there is a potted plant placed nearby."}, "407042": {"image_id": 407042, "Bleu_1": 0.3199999999936, "Bleu_2": 0.21380899352561972, "Bleu_3": 0.14189834119414174, "Bleu_4": 0.08829955693848539, "METEOR": 0.2874224716056014, "ROUGE_L": 0.3335358444714459, "CIDEr": 7.166662271346446e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a young boy and a young girl standing next to each other, both holding stuffed animals. The boy is holding a stuffed monkey, while the girl is holding a stuffed dog. They are both smiling and seem to be enjoying their time together.\n\nIn the background, there"}, "170784": {"image_id": 170784, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.15613914506966814, "Bleu_3": 0.10196049127995216, "Bleu_4": 1.2388559502196402e-05, "METEOR": 0.31322600788349214, "ROUGE_L": 0.3057644110275689, "CIDEr": 1.1786774406905979e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a large red double-decker bus parked on a city street. The bus is prominently displayed in the scene, occupying a significant portion of the image. The bus is parked near a tree, which can be seen in the foreground.\n\nThere are several people in the"}, "189744": {"image_id": 189744, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.11656242933815306, "Bleu_4": 1.3408182811888846e-05, "METEOR": 0.22293889790566312, "ROUGE_L": 0.28175519630484985, "CIDEr": 2.1642838750098487e-11, "SPICE": {"All": {"pr": 0.3, "re": 0.35294117647058826, "f": 0.3243243243243243, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a brick building with a sign on the side that reads \"The Peal Aldergate.\" The building appears to be a restaurant or a pizza shop, as there is a pizza advertisement on the side of the building. The building is situated next to a brick wall, and a car"}, "222440": {"image_id": 222440, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.2142857142812956, "Bleu_3": 0.1250180897226835, "Bleu_4": 0.08073097285651325, "METEOR": 0.18743138124005432, "ROUGE_L": 0.2208811104405552, "CIDEr": 1.9955705796107702e-09, "SPICE": {"All": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a zoo enclosure with a group of people gathered around, observing the animals. There are several people standing near the fence, watching the animals in their habitat. The enclosure features a dirt area and a log, providing a natural environment for the animals.\n\nIn the en"}, "78060": {"image_id": 78060, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.16843038420975753, "Bleu_3": 0.08511922922359433, "Bleu_4": 1.081976014400406e-05, "METEOR": 0.23035091873461275, "ROUGE_L": 0.2616421568627451, "CIDEr": 9.32830972961278e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a woman and a young girl standing on a snow-covered slope, both wearing skis. The woman is giving the thumbs up, indicating that they are enjoying their time skiing together. The girl is wearing a pink hat, adding a touch of color to the scene."}, "224647": {"image_id": 224647, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.293211273104214, "Bleu_3": 0.22917282640918032, "Bleu_4": 0.1647607022667407, "METEOR": 0.32209603935679, "ROUGE_L": 0.3932101418134938, "CIDEr": 3.844412044722898e-07, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a young girl wearing an orange dress, holding a tennis racket and preparing to hit a tennis ball. She is standing on a grassy field, possibly a tennis court. Another person is visible in the background, standing further away from the girl.\n\nThere are two tennis balls in the"}, "301326": {"image_id": 301326, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.0939614522123186, "Bleu_4": 1.1406785378264661e-05, "METEOR": 0.2070313816801005, "ROUGE_L": 0.22048192771084338, "CIDEr": 1.7706555255973136e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.23529411764705882, "f": 0.19047619047619052, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a black and brown cat standing on a tiled floor, looking at a brown and black dog through a fence. The dog is on the other side of the fence, seemingly curious about the cat. The cat appears to be looking at the dog, possibly intrigued by its presence."}, "128058": {"image_id": 128058, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.11432028587212996, "Bleu_4": 1.3147705731634356e-05, "METEOR": 0.20840889603366355, "ROUGE_L": 0.25894481503941785, "CIDEr": 3.219616321453157e-12, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.26666666666666666, "f": 0.30769230769230765, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.7, "f": 0.7, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image features a man in a white shirt and hat, holding a tennis racket and preparing to hit a tennis ball. He is in the middle of a swing, demonstrating his skill and focus on the game. The tennis ball is positioned close to the racket, indicating that he is about to"}, "123867": {"image_id": 123867, "Bleu_1": 0.423076923068787, "Bleu_2": 0.25761406704390316, "Bleu_3": 0.15850031615011761, "Bleu_4": 0.09494532372505993, "METEOR": 0.24867437758475394, "ROUGE_L": 0.2610024449877751, "CIDEr": 6.86439673897481e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a small dog wearing a red shirt, walking across a grassy field. The dog is carrying a frisbee in its mouth, indicating that it has been playing fetch. There are two people in the scene, one standing near the dog and the other further away. The dog appears to"}, "331753": {"image_id": 331753, "Bleu_1": 0.41176470587427916, "Bleu_2": 0.24009801919475754, "Bleu_3": 0.13300573168298876, "Bleu_4": 0.08367437134425945, "METEOR": 0.2306826837821457, "ROUGE_L": 0.2893689114781872, "CIDEr": 2.92740313024413e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.18518518518518517, "f": 0.20408163265306123, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a display of five white toilets lined up next to each other. Each toilet has a green sticker on the back, indicating that they are for sale. The toilets are arranged in a row, with the first one on the left side, the second one in the middle"}, "425690": {"image_id": 425690, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.1601281538019776, "Bleu_3": 0.08004271223291963, "Bleu_4": 1.0114451288069099e-05, "METEOR": 0.22168674698795182, "ROUGE_L": 0.22048192771084338, "CIDEr": 5.42282381300217e-12, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image captures a busy city street at night, with a blur of lights and motion. The street is filled with traffic, including cars and a truck, as they move through the intersection. There are multiple traffic lights visible in the scene, with some closer to the foreground and others further away."}, "225658": {"image_id": 225658, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.18173629401703337, "Bleu_4": 0.12575592044457554, "METEOR": 0.30682900586811535, "ROUGE_L": 0.3051907442151345, "CIDEr": 4.026808737194378e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.25, "f": 0.24489795918367346, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a man wearing a suit and tie, with the tie being designed to resemble the American flag. The tie is predominantly red, white, and blue, and it is placed in the center of the man's chest. The man is standing in a room, possibly at a formal"}, "331236": {"image_id": 331236, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.24077170616624616, "Bleu_3": 0.13812196235285776, "Bleu_4": 1.573366652415358e-05, "METEOR": 0.29792892292467343, "ROUGE_L": 0.28968792401628224, "CIDEr": 6.50460780478259e-07, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.08, "f": 0.09302325581395349, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a blue shirt with a logo on it, placed on a bed. The shirt is accompanied by various items, including a frisbee, a cup, and a package of beads. The frisbee is positioned to the left of the shirt, while the cup is"}, "47225": {"image_id": 47225, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.14912567704434504, "Bleu_4": 0.12062023507020692, "METEOR": 0.2496235327115453, "ROUGE_L": 0.26228501228501233, "CIDEr": 6.457784138814492e-10, "SPICE": {"All": {"pr": 0.3125, "re": 0.2, "f": 0.24390243902439027, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a wooden table with a variety of stuffed animals and snacks. There are three stuffed animals on the table, including a teddy bear, a tiger, and a bear. The teddy bear is positioned on the left side of the table, while the tiger is in the middle"}, "64300": {"image_id": 64300, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.20565318641151553, "Bleu_3": 0.1566604610064578, "Bleu_4": 0.10923922468551896, "METEOR": 0.20718955667234018, "ROUGE_L": 0.20504201680672268, "CIDEr": 9.076292230793861e-14, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09090909090909091, "f": 0.08888888888888888, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features two large birds standing on a sandy beach near a body of water. The birds are facing opposite directions, with one bird on the left side of the image and the other on the right side. They appear to be walking or standing on the beach, possibly searching for food or exploring the area."}, "59547": {"image_id": 59547, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.14189834119414174, "Bleu_4": 0.08829955693848539, "METEOR": 0.29785534865720864, "ROUGE_L": 0.3941097499580466, "CIDEr": 1.9274828457415015e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.17857142857142858, "f": 0.18181818181818182, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a woman standing outside, holding a plate with two slices of rainbow cake on it. She is smiling and appears to be enjoying the moment. The cake is placed on a green plate, and the woman is holding the plate with both hands.\n\nIn the background, there"}, "501538": {"image_id": 501538, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.22131333406452386, "Bleu_3": 0.18293988070876474, "Bleu_4": 0.1510851663234064, "METEOR": 0.22660691892510043, "ROUGE_L": 0.30902840600687537, "CIDEr": 9.070776873077889e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.19230769230769232, "f": 0.21276595744680848, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a young woman wearing glasses and a gray shirt, standing in front of a blue wall. She is holding a bunch of bananas in her hands, showcasing them proudly. The bananas are placed in various positions, with some closer to her and others further away. The woman"}, "318471": {"image_id": 318471, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.14285714285419707, "Bleu_3": 0.07572431510387477, "Bleu_4": 9.856825261135735e-06, "METEOR": 0.2575864561200965, "ROUGE_L": 0.2663755458515284, "CIDEr": 7.176057155625e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a street sign at an intersection, displaying the names of the streets: Cedar Street and Roberts Street. The sign is positioned on a pole, and the street names are clearly visible. The sky in the background is cloudy, adding a sense of depth to the scene."}, "6091": {"image_id": 6091, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.15061880827957486, "Bleu_3": 0.09322522944811516, "Bleu_4": 1.1016900404543489e-05, "METEOR": 0.1954998729893907, "ROUGE_L": 0.26961325966850824, "CIDEr": 1.9510686209540267e-12, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a person standing in front of a stop sign, which is located on the side of a road. The person is holding a piece of paper, possibly a note or a sign, and placing it on the stop sign. The scene appears to be taking place at night, as the person is standing in the"}, "73": {"image_id": 73, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.14695129936263138, "Bleu_3": 8.075839294554588e-07, "Bleu_4": 1.904915665082057e-09, "METEOR": 0.16622707092500963, "ROUGE_L": 0.2576376179079263, "CIDEr": 8.912532980425201e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.19230769230769232, "f": 0.20833333333333331, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features an old-fashioned motorcycle parked on a street. The motorcycle is positioned in the center of the scene, with its front wheel prominently visible. The motorcycle has a vintage appearance, and it appears to be a classic model.\n\nIn the background,"}, "196715": {"image_id": 196715, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.23819653366515028, "Bleu_3": 0.1702384584471886, "Bleu_4": 0.1346698708793052, "METEOR": 0.2469080458930322, "ROUGE_L": 0.27799479166666663, "CIDEr": 5.669785049817502e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a beach scene with a white truck parked on the sand, likely serving as a lifeguard vehicle. The truck is positioned near the water, and a surfboard can be seen placed on the back of it.\n\nThere are several people scattered around the beach, enjoying"}, "461467": {"image_id": 461467, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.15354390128889114, "Bleu_4": 0.09270974964697601, "METEOR": 0.25812798906723766, "ROUGE_L": 0.28773584905660377, "CIDEr": 1.4047125918450174e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.125, "f": 0.1276595744680851, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a group of people gathered around a dining table, enjoying a meal together. There are two women sitting at the table, with one of them holding her nose, possibly due to the strong smell of the pizza. The table is covered with a pizza, and there are several wine"}, "398066": {"image_id": 398066, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.1103716852403353, "Bleu_4": 1.293698116812338e-05, "METEOR": 0.20297848610809685, "ROUGE_L": 0.22889305816135083, "CIDEr": 6.747504463428298e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.20689655172413793, "f": 0.22641509433962265, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image captures a baseball game in progress, with a man in a red shirt and white shorts swinging a baseball bat at a ball. The ball is in the air, close to the batter. Another person is standing nearby, possibly waiting for their turn to bat or observing the game."}, "431140": {"image_id": 431140, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2474358296475945, "Bleu_3": 0.21842672184077228, "Bleu_4": 0.19955581062932934, "METEOR": 0.32956787530305964, "ROUGE_L": 0.39633786178381575, "CIDEr": 1.2691227208838141e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.18518518518518517, "f": 0.19999999999999998, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet and a white sink. The toilet is located on the left side of the bathroom, while the sink is situated on the right side. A metal handrail is installed next to the toilet, providing support and accessibility for individuals with"}, "67315": {"image_id": 67315, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.11656242933815306, "Bleu_4": 0.07539975290832036, "METEOR": 0.24638519039501605, "ROUGE_L": 0.26293103448275856, "CIDEr": 1.9362157077856614e-11, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.0625, "f": 0.07272727272727272, "fn": 30.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a man wearing a striped tie and a dress shirt, sitting in a room with his arms crossed. He appears to be relaxed and comfortable in his attire. The room has a dining table in the background, and a chair is placed nearby. The man's tie is visible"}, "261777": {"image_id": 261777, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.17857142856774635, "Bleu_3": 0.11070962028887511, "Bleu_4": 1.310537833580047e-05, "METEOR": 0.21188312109035343, "ROUGE_L": 0.23091482649842268, "CIDEr": 9.268682029576058e-10, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.34615384615384615, "f": 0.37500000000000006, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.7142857142857143, "re": 0.625, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image captures a thrilling moment of a skier performing a high jump in the air. The skier is in the middle of the jump, with their skis visible as they soar through the air. The skis are positioned at an angle, indicating the skier's impressive height and"}, "62296": {"image_id": 62296, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.06317667074948415, "Bleu_3": 4.277412148886299e-07, "Bleu_4": 1.1185188895571612e-09, "METEOR": 0.15261538461538462, "ROUGE_L": 0.14796846573681016, "CIDEr": 5.730486193499609e-13, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21428571428571427, "f": 0.21818181818181817, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a large body of water with several boats docked in the harbor. The boats are of various sizes and are scattered throughout the scene. Some boats are closer to the foreground, while others are further away, creating a sense of depth in the water.\n\nIn addition to the boats, there"}, "329088": {"image_id": 329088, "Bleu_1": 0.24999999999479172, "Bleu_2": 2.3063280200236533e-09, "Bleu_3": 4.8718597003705156e-12, "Bleu_4": 2.2514792630740484e-13, "METEOR": 0.19340659340659339, "ROUGE_L": 0.19551282051282048, "CIDEr": 7.747363473980348e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man standing on a snow-covered slope, wearing a white jacket and a backpack. He is holding ski poles and appears to be enjoying his time on the mountain. The man is positioned in the center of the scene, surrounded by a beautiful snowy landscape."}, "337120": {"image_id": 337120, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.12186787521464361, "Bleu_4": 0.07795929613721146, "METEOR": 0.22281619779899295, "ROUGE_L": 0.28514190317195326, "CIDEr": 9.50963681673274e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13333333333333333, "f": 0.14814814814814814, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a street scene with a clock mounted on the side of a brick building. The clock is positioned above a doorway, making it easily visible to passersby. There are two bicycles parked on the sidewalk, one closer to the left side of the scene and the other further to"}, "60240": {"image_id": 60240, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.19425717246782156, "Bleu_3": 0.16329291590653727, "Bleu_4": 0.1437392800460675, "METEOR": 0.33439117672413243, "ROUGE_L": 0.29151732377538825, "CIDEr": 9.187100136805261e-13, "SPICE": {"All": {"pr": 0.15, "re": 0.13043478260869565, "f": 0.13953488372093023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a person holding a cell phone in their hand, likely using it for texting or browsing. The person's hand is visible, with the cell phone placed in the center of the scene. The focus of the image is on the person's hand and the cell phone, capturing the interaction"}, "134657": {"image_id": 134657, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.10433283794475068, "Bleu_3": 0.07529519927190921, "Bleu_4": 0.05405463811390528, "METEOR": 0.12653500980723853, "ROUGE_L": 0.21356050881082975, "CIDEr": 4.084935026155889e-12, "SPICE": {"All": {"pr": 0.35, "re": 0.25, "f": 0.2916666666666667, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts a highway with a green sign above it, indicating the name of the street. The highway is surrounded by a bridge, and there are several cars driving on it. In total, there are nine cars visible in the scene, with some positioned closer to the foreground and others further back."}, "166979": {"image_id": 166979, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.2520504151200502, "Bleu_3": 0.18645881484437468, "Bleu_4": 0.14187543101933917, "METEOR": 0.3070594568379814, "ROUGE_L": 0.31590628853267566, "CIDEr": 8.426761160268823e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a red and white boat speeding across a large body of water, likely a lake. The boat is moving quickly, leaving a trail of water behind it. In the background, there is a city skyline visible, with several buildings and a large airport nearby.\n\nThere are multiple airplan"}, "160437": {"image_id": 160437, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.08701138391057635, "Bleu_4": 1.1125382292156774e-05, "METEOR": 0.18587748356434866, "ROUGE_L": 0.1927939317319848, "CIDEr": 2.3752709618953667e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a zebra lying down on a dirt ground, possibly in a zoo enclosure. The zebra is positioned in the center of the scene, with its body facing the camera. The zebra appears to be relaxed and comfortable in its environment.\n\nIn the background,"}, "426815": {"image_id": 426815, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.19794866371815809, "Bleu_3": 0.16982634150405124, "Bleu_4": 0.1510851663234064, "METEOR": 0.24567183243758245, "ROUGE_L": 0.29647630619684084, "CIDEr": 4.5206440605939887e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a person riding a horse in the ocean, with the horse standing in shallow water. The person is wearing a black jacket and a helmet, ensuring safety while enjoying the unique experience of horseback riding in the ocean. The horse appears to be calmly walking through the"}, "31749": {"image_id": 31749, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.12262786789482262, "Bleu_3": 0.06490406357826438, "Bleu_4": 8.435396018679067e-06, "METEOR": 0.20391234294513816, "ROUGE_L": 0.23682750970604544, "CIDEr": 1.7952869984543254e-13, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.34782608695652173, "f": 0.32653061224489793, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a doll sitting at a table, with a clock placed in front of it. The doll appears to be a Barbie doll, and it is positioned in a way that it seems to be looking at the clock. The clock is placed on the table, and it is quite large compared to the doll"}, "54337": {"image_id": 54337, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 0.1017691319923899, "Bleu_4": 0.0703630957666405, "METEOR": 0.2237094126466892, "ROUGE_L": 0.24830393487109906, "CIDEr": 5.4389762936244564e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6363636363636364, "f": 0.56, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The image depicts a group of people gathered around a dining table, enjoying a wine tasting event. There are several wine bottles and wine glasses placed on the table, with some of the bottles being unopened. The people are seated on chairs surrounding the table, engaged"}, "161044": {"image_id": 161044, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.22493385270597108, "Bleu_3": 0.1024874282416925, "Bleu_4": 1.2368399045659156e-05, "METEOR": 0.22211538329388764, "ROUGE_L": 0.27566171723692706, "CIDEr": 4.0621690049052236e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a group of three small airplanes flying in formation through a cloudy sky. The planes are positioned close to each other, creating an impressive sight as they soar through the air. The sky is filled with clouds, adding a dramatic backdrop to the scene. The airplan"}, "161978": {"image_id": 161978, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.15927956195690762, "Bleu_3": 0.08453247893683392, "Bleu_4": 1.1017212838732253e-05, "METEOR": 0.1864311075385383, "ROUGE_L": 0.214185393258427, "CIDEr": 3.44790724363573e-06, "SPICE": {"All": {"pr": 0.35, "re": 0.3684210526315789, "f": 0.358974358974359, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is a collage of various people riding skateboards at a skate park. There are multiple instances of the same person in different positions, showcasing different stages of their skateboarding experience. The collage captures the essence of skateboarding, with people of different ages"}, "106046": {"image_id": 106046, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.20603150145092247, "Bleu_3": 0.13843601547479548, "Bleu_4": 0.08667869289335833, "METEOR": 0.22821320574383022, "ROUGE_L": 0.3205170975813178, "CIDEr": 1.7022301933540516e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.23809523809523808, "f": 0.24390243902439024, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a young girl sitting at a dining table, enjoying a delicious piece of cake. She is surrounded by various desserts, including a cake on her plate and another cake on the table. There are also two donuts on the table, one closer to the girl and the"}, "138970": {"image_id": 138970, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.12632278815731815, "Bleu_3": 7.026437559457351e-07, "Bleu_4": 1.6662810872720655e-09, "METEOR": 0.20306147868680155, "ROUGE_L": 0.2459677419354839, "CIDEr": 2.1974865337039236e-10, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.28, "f": 0.3181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a group of people, including two men and a woman, working together to move a large white refrigerator. They are holding onto the refrigerator, which is placed on the back of a car. The people are positioned around the refrigerator, with one person on the"}, "450037": {"image_id": 450037, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.2498843395674313, "Bleu_3": 0.1608652629743755, "Bleu_4": 0.09862420963216202, "METEOR": 0.2543378938734566, "ROUGE_L": 0.27056139906222276, "CIDEr": 3.0612289159051095e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a man riding a horse in a fenced-in area, possibly a corral or a field. The man is wearing a cowboy hat and appears to be guiding the horse. Another horse can be seen in the background, standing near the fence.\n\nIn the scene,"}, "237869": {"image_id": 237869, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.07606919312543149, "Bleu_4": 9.785799152874335e-06, "METEOR": 0.2392514336290249, "ROUGE_L": 0.24702071040148096, "CIDEr": 6.279710193545957e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.1935483870967742, "f": 0.21818181818181817, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.06666666666666667, "f": 0.08695652173913045, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a unique and creative display of a clock built into a stack of suitcases. The clock is positioned on top of the suitcases, making it a functional and decorative piece. The suitcases are arranged in a colorful stack, with each suitcase having a different color, adding a v"}, "323598": {"image_id": 323598, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.20173664619184403, "Bleu_3": 0.14271858103762705, "Bleu_4": 0.0917623284503745, "METEOR": 0.19149969198667696, "ROUGE_L": 0.214185393258427, "CIDEr": 5.0907775808661064e-08, "SPICE": {"All": {"pr": 0.3793103448275862, "re": 0.3548387096774194, "f": 0.36666666666666664, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 11.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5333333333333333, "re": 0.7272727272727273, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 8.0}}, "caption": "The image features a bathroom with a large bathtub and a toilet. The bathtub is situated next to a shower, creating a combined bathing area. The toilet is positioned on the right side of the bathroom, while the bathtub is located towards the center."}, "261948": {"image_id": 261948, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.1331559103200233, "Bleu_3": 0.07277591728600324, "Bleu_4": 9.620278342821096e-06, "METEOR": 0.1883099658396171, "ROUGE_L": 0.20132013201320131, "CIDEr": 4.119823613568068e-09, "SPICE": {"All": {"pr": 0.12, "re": 0.13043478260869565, "f": 0.12499999999999997, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a vintage orange suitcase with a green floral pattern, sitting on a carpeted floor. The suitcase is open, revealing its interior. The suitcase is placed on a metal stand, which adds a unique touch to the overall presentation. The combination of the suitcase and the"}, "438539": {"image_id": 438539, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.09983569293155374, "Bleu_4": 0.06819851521727724, "METEOR": 0.24578408336830226, "ROUGE_L": 0.26940063091482647, "CIDEr": 2.35187366203647e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image is a collage of four different pictures featuring a group of people playing frisbee in a park. In each picture, there are at least two people engaged in the game, with one person jumping in the air to catch the frisbee. The frisbee can be seen in"}, "204044": {"image_id": 204044, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.24330354977564592, "Bleu_3": 0.16170481491531974, "Bleu_4": 0.11984053756396974, "METEOR": 0.2570949824081955, "ROUGE_L": 0.3076368876080692, "CIDEr": 3.4507468729161387e-07, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.1, "f": 0.0851063829787234, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a kitchen with a sink, a stove, and a refrigerator. The kitchen is well-equipped with various appliances, including a microwave and an oven. The sink is located on the left side of the kitchen, while the stove is positioned on the"}, "142454": {"image_id": 142454, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.21602468994265056, "Bleu_3": 0.1418983411941997, "Bleu_4": 0.08783602619536428, "METEOR": 0.2842018223803625, "ROUGE_L": 0.3900029061319384, "CIDEr": 8.380174735844034e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.25, "f": 0.22727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a bathroom scene with two cats sitting on the edge of a sink. One cat is on the left side of the sink, while the other cat is on the right side. The sink is located near a mirror, which is positioned above the cats.\n\nIn the bathroom,"}, "239455": {"image_id": 239455, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.14679516868082104, "Bleu_3": 0.07408254355300371, "Bleu_4": 9.403425277032118e-06, "METEOR": 0.1876280178156434, "ROUGE_L": 0.22008418520745643, "CIDEr": 1.0745579136217171e-12, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.6363636363636364, "f": 0.6666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image features a harbor with several boats docked in the water. There are two prominent boats, one red and one blue, sitting next to each other. The red boat is larger and occupies a significant portion of the scene, while the blue boat is smaller and positioned closer to the right side of the"}, "409725": {"image_id": 409725, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.1878672873218244, "Bleu_3": 0.08964004852977604, "Bleu_4": 1.106792615545272e-05, "METEOR": 0.2361737375856205, "ROUGE_L": 0.29847094801223245, "CIDEr": 3.1996374200462116e-11, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.3076923076923077, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image captures a lively scene of a large group of people gathered in a city park, flying kites. There are at least 13 people visible in the scene, with some standing closer to the foreground and others further back. The kites can be seen soaring in the sky, with at"}, "299493": {"image_id": 299493, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 7.926525909642893e-07, "Bleu_4": 1.7765182019941675e-09, "METEOR": 0.21762076225596774, "ROUGE_L": 0.26472411655300687, "CIDEr": 7.477485662735469e-12, "SPICE": {"All": {"pr": 0.3, "re": 0.2, "f": 0.24, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.38461538461538464, "f": 0.4761904761904762, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a yellow bus driving down a street, with a large sign on the front advertising Walmart. The bus is positioned in the middle of the street, and there are several people visible around it. Some of them are standing near the bus, while others are walking or standing further away."}, "460390": {"image_id": 460390, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.06982754846489585, "Bleu_3": 4.732586777946994e-07, "Bleu_4": 1.2388559502196402e-09, "METEOR": 0.11669367909238249, "ROUGE_L": 0.1639784946236559, "CIDEr": 1.9857105193157534e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13043478260869565, "f": 0.14634146341463414, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a snowy slope with several skiers and snowboarders enjoying the winter sports. There are at least 12 people visible in the scene, some of them skiing and others snowboarding. They are scattered across the slope, with some closer to the foreground and others further in"}, "473002": {"image_id": 473002, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 8.491317075202567e-07, "Bleu_4": 1.8997953886425763e-09, "METEOR": 0.19476629736848639, "ROUGE_L": 0.2582869586256957, "CIDEr": 3.549551131827435e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a young man wearing a black shirt and jeans, standing on a skateboard in the middle of a street. He appears to be posing for a picture. There are several other people in the scene, some of them walking or standing nearby.\n\nIn addition to the people,"}, "523470": {"image_id": 523470, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.24462302738989036, "Bleu_3": 0.17328685148662828, "Bleu_4": 0.12331859801407646, "METEOR": 0.17881065005542277, "ROUGE_L": 0.3028368794326241, "CIDEr": 2.604962704193659e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.125, "f": 0.16, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a white plate with a delicious meal consisting of two meatballs, a salad, and a side of vegetables. The meatballs are placed on the left side of the plate, while the salad and vegetables are spread across the right side. The salad includes a variety"}, "85944": {"image_id": 85944, "Bleu_1": 0.4313725490111496, "Bleu_2": 0.3475403771084825, "Bleu_3": 0.24546443053708886, "Bleu_4": 0.1743658498789943, "METEOR": 0.24074510833830923, "ROUGE_L": 0.27319257837492, "CIDEr": 7.097017233139184e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image depicts a lively scene at a bar with a group of people gathered around a counter. A woman is standing behind the counter, pouring wine into wine glasses for the patrons. There are several people in the scene, with some standing closer to the bar and others further away."}, "258523": {"image_id": 258523, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.2571817658421884, "Bleu_3": 0.18048562115893838, "Bleu_4": 0.10751493265432491, "METEOR": 0.3028016874943426, "ROUGE_L": 0.317915309446254, "CIDEr": 8.324831480204495e-09, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.4117647058823529, "f": 0.3255813953488372, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a black cat lying on top of a white toilet seat. The cat is stretched out and appears to be sleeping or relaxing on the toilet lid. The scene takes place in a bathroom, with the toilet being the main focus of the image."}}}