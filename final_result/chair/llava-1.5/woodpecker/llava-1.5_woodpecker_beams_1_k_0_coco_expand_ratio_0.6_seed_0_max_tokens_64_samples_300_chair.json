{"overall": {"Bleu_1": 0.2748911362515373, "Bleu_2": 0.18339915595041123, "Bleu_3": 0.11681992587752117, "Bleu_4": 0.07206855098020748, "METEOR": 0.22621990592932448, "ROUGE_L": 0.2872722945777055, "CIDEr": 0.010528146540355998, "SPICE": 0.21531941997578988}, "imgToEval": {"472621": {"image_id": 472621, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.12626174790809142, "Bleu_3": 7.129027762233403e-07, "Bleu_4": 1.7037490064393743e-09, "METEOR": 0.21220192674146293, "ROUGE_L": 0.2662758792716388, "CIDEr": 3.543806830026884e-08, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.35294117647058826, "f": 0.35294117647058826, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a black bathtub situated in a bathroom. The bathtub is placed on a pedestal. The bathroom also contains a sink, which is located in the corner. The bathtub is the main focus of the room, and it is surrounded by a tile floor."}, "196053": {"image_id": 196053, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.15160238526733089, "Bleu_4": 0.09722173654629655, "METEOR": 0.2645439605886136, "ROUGE_L": 0.2663755458515284, "CIDEr": 8.722523215685767e-07, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a woman standing on a tennis court. She is holding a tennis racket. The woman is wearing a white shirt and blue shorts. Her hair is styled in a ponytail. She appears to be focused and ready to play."}, "42276": {"image_id": 42276, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 0.11472200633111387, "Bleu_4": 0.07888036262328214, "METEOR": 0.1877735912777418, "ROUGE_L": 0.2824074074074074, "CIDEr": 5.261317611062011e-06, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.25, "f": 0.27906976744186046, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.75, "f": 0.631578947368421, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image depicts a bathroom with a white toilet positioned in the middle of the room. The floor is cluttered with various items, including a helmet. There are no skis or snowboard in the scene. There are no gloves in the scene."}, "530226": {"image_id": 530226, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.3994297929951073, "Bleu_3": 0.3171784229273114, "Bleu_4": 0.19095230982023845, "METEOR": 0.38994933172538193, "ROUGE_L": 0.5336832895888014, "CIDEr": 0.052292284609801815, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a polar bear standing on a snow-covered ice floe, with its reflection visible in the water. The polar bear is eating a dead animal."}, "487421": {"image_id": 487421, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 0.0858725358973738, "Bleu_4": 1.0831815605763862e-05, "METEOR": 0.20203663784669204, "ROUGE_L": 0.23303196230739842, "CIDEr": 5.7501542325218526e-08, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.125, "f": 0.12903225806451615, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a pasta dish filled with vegetables. The dish is primarily composed of noodles, which are scattered throughout the bowl. There are three pieces of broccoli, adding a green touch to the dish. The pasta is topped with a sauce made of tomatoes, spinach, and feta cheese."}, "536990": {"image_id": 536990, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.12539246564153583, "Bleu_3": 0.08456484271613045, "Bleu_4": 1.043517748432418e-05, "METEOR": 0.1836073535344935, "ROUGE_L": 0.2367487247726769, "CIDEr": 1.7836786412090768e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.2, "f": 0.19354838709677422, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a vase with a pink flower arrangement placed on a table. The vase is positioned in the center of the scene. The flower arrangement is quite large, occupying a significant portion of the vase.\n\nThere is also a candle placed on the table.\n\nThere are no other objects in the scene."}, "101762": {"image_id": 101762, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.17879377258086276, "Bleu_3": 0.13940368573118822, "Bleu_4": 0.10880002810376022, "METEOR": 0.3023457279594597, "ROUGE_L": 0.2857886517438834, "CIDEr": 6.473117579195245e-16, "SPICE": {"All": {"pr": 0.5, "re": 0.25925925925925924, "f": 0.3414634146341463, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.25, "f": 0.375, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a cat standing next to a bicycle wheel, which is propped up against a wall. The cat is curiously observing the bicycle wheel. The bicycle wheel is intriguing the cat. The cat is observing the movement and sound of the bicycle wheel. The cat is the main focus of the scene, with a bicycle standing next to it."}, "100329": {"image_id": 100329, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.12121830534381621, "Bleu_3": 6.739562828886045e-07, "Bleu_4": 1.5975311320250798e-09, "METEOR": 0.15777494562507835, "ROUGE_L": 0.22333414693678305, "CIDEr": 3.9528522482745164e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 9.0}, "Relation": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a bear standing near a waterfall. The bear is brown. The bear is not standing near a waterfall. The bear is not trying to catch fish. The waterfall is located in the background. There are rocks scattered around the water. \n\nThe bear is not enjoying the water."}, "105234": {"image_id": 105234, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2738612787456488, "Bleu_3": 0.2279342766232552, "Bleu_4": 0.1891567293219883, "METEOR": 0.3206938530969062, "ROUGE_L": 0.32250755287009064, "CIDEr": 2.261059945524279e-06, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.1875, "f": 0.21818181818181817, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image captures a joyful moment at a wedding reception, where a bride and groom are celebrating their special day. The bride is standing at the table, holding up a cake. The groom is standing in front of the cake."}, "577355": {"image_id": 577355, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.14433756729513328, "Bleu_3": 0.08759225147093093, "Bleu_4": 1.024511431064054e-05, "METEOR": 0.18438394673961903, "ROUGE_L": 0.2139278557114228, "CIDEr": 1.1726805753039069e-18, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.18181818181818182, "f": 0.21621621621621623, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a city street with 5 traffic lights hanging above the road. The traffic light 1 is displaying a yellow light. The traffic light 2 is displaying a black light. The traffic light 3 is displaying a black light. The traffic light 4 is displaying a light. The traffic light 5 is displaying a light.\n\nThere are 2 buildings in the background."}, "526645": {"image_id": 526645, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.21733262130578967, "Bleu_3": 0.15645512323417216, "Bleu_4": 0.12077421280261787, "METEOR": 0.28685153311301326, "ROUGE_L": 0.32570556826849734, "CIDEr": 7.6099821755345974e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a giraffe walking through a forest. The giraffe is the main focus of the scene, with its long neck and legs prominently visible. The forest is surrounded by trees, providing a natural habitat for the giraffe."}, "476939": {"image_id": 476939, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.2243088616326247, "Bleu_3": 0.1570060918669648, "Bleu_4": 0.11099472319754804, "METEOR": 0.3065578548290853, "ROUGE_L": 0.2814302191464821, "CIDEr": 8.988335307539875e-12, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.21739130434782608, "f": 0.29411764705882354, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features two people standing in a hospital room. The woman is wearing a hat and appears to be reading a paper. The man is standing next to her. They are both dressed in medical attire, with the woman wearing a scrub suit.\n\nThere is no other woman or man in the scene."}, "546444": {"image_id": 546444, "Bleu_1": 0.27777777777391977, "Bleu_2": 0.15321285325683096, "Bleu_3": 6.947535697953364e-07, "Bleu_4": 1.4847755848126421e-09, "METEOR": 0.20089869370670543, "ROUGE_L": 0.21863799283154117, "CIDEr": 2.049105496227641e-23, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a group of men gathered in a living room, watching a TV. They are playing on a Nintendo Wii. Two of the men are sitting on a couch, while the third man is lying on the floor. They are all holding Wii remotes.\n\nThere is no video game session in the scene. There is no Nintendo Wii console in the scene. There is no Wii remote in the scene."}, "285734": {"image_id": 285734, "Bleu_1": 0.2187499999931641, "Bleu_2": 0.16800537625272693, "Bleu_3": 0.12345775254393485, "Bleu_4": 0.08975099573971049, "METEOR": 0.2472437485255926, "ROUGE_L": 0.33639705882352944, "CIDEr": 0.0003404593947989352, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2, "f": 0.2380952380952381, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a boy flying a kite in a grassy field. The boy is enjoying the outdoor activity. He is wearing a striped shirt. The kite is soaring in the sky."}, "191013": {"image_id": 191013, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.20083857809555095, "Bleu_3": 0.1542057366280892, "Bleu_4": 0.12303973923372491, "METEOR": 0.25797172481014985, "ROUGE_L": 0.3981145757795504, "CIDEr": 0.000854603124057632, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.29411764705882354, "f": 0.3225806451612903, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a clock prominently displayed on the side of a store, likely a telecommunications company. The clock is a focal point of the scene. There is no building or mural in the image."}, "50350": {"image_id": 50350, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.1532823268448488, "Bleu_4": 0.0930697942841302, "METEOR": 0.23056066079801046, "ROUGE_L": 0.25553560742070613, "CIDEr": 1.0575147179539369e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.12, "f": 0.11538461538461538, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet situated next to a bathtub. The bathtub is filled with water. A towel is hanging on the side of the bathtub. The bathroom also contains a sink, which is located near the bathtub.\n\nThere is no water or towel in the scene."}, "412676": {"image_id": 412676, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1556997888288053, "Bleu_3": 0.0826106166220859, "Bleu_4": 1.0763774116165367e-05, "METEOR": 0.17808502234140197, "ROUGE_L": 0.2053872053872054, "CIDEr": 7.341182630144223e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a building, which appears to be a commercial building. There are three cars parked in front of the building. One car is parked on the sidewalk, another car is parked on the street, and a third car is parked on the sidewalk."}, "151742": {"image_id": 151742, "Bleu_1": 0.14999999999812502, "Bleu_2": 0.10673521004338038, "Bleu_3": 0.08359756011225314, "Bleu_4": 0.06241371296100169, "METEOR": 0.207840077094793, "ROUGE_L": 0.15508474576271186, "CIDEr": 2.1815071780142478e-29, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.19047619047619047, "f": 0.15384615384615383, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features three men. Two of the men are wearing suits and holding a baby in their arms. The baby is wearing a white hat. The men are not smiling. They are also wearing glasses. The third man is wearing a blue and white striped shirt. He is holding a cake. The man is cutting the cake. He is not smiling. He is not wearing glasses. He is not wearing a hat.\n\nIn the background, there are two chairs."}, "433924": {"image_id": 433924, "Bleu_1": 0.5714285714013606, "Bleu_2": 0.41403933558520356, "Bleu_3": 0.26229289922503723, "Bleu_4": 0.1779392574442387, "METEOR": 0.32055301258171215, "ROUGE_L": 0.48248587570621465, "CIDEr": 0.3223689481328369, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.27586206896551724, "f": 0.28070175438596495, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.5833333333333334, "f": 0.6086956521739131, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image features a woman cutting her hair with a pair of scissors. The woman's hair appears to be cut."}, "160104": {"image_id": 160104, "Bleu_1": 0.26315789473337947, "Bleu_2": 0.2051956704143129, "Bleu_3": 0.14169620653233575, "Bleu_4": 0.09396052864094993, "METEOR": 0.23669904641102593, "ROUGE_L": 0.24243762419960257, "CIDEr": 2.1441730305540034e-25, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a wooden dining table with a variety of food and drinks. On the table, there is a bowl filled with bread. There are also three plates with different items. One plate has a slice of pizza, another has bread and cheese, and the third has a slice of bread. There are two glasses with a red drink. \n\nThere is no cup or water in the scene. There is no beverage in the scene."}, "174198": {"image_id": 174198, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 0.09955605444507261, "Bleu_4": 0.06881570893052942, "METEOR": 0.26483525145423725, "ROUGE_L": 0.23843648208469054, "CIDEr": 2.632691209014728e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2962962962962963, "f": 0.25396825396825395, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4375, "re": 0.6363636363636364, "f": 0.5185185185185185, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}}, "caption": "The image features a train parked in a train station. The train is green and orange. It is positioned in the middle of the station. On top of the train is one of the traffic lights. On the other side of the train is another traffic light."}, "313341": {"image_id": 313341, "Bleu_1": 0.30508474575754096, "Bleu_2": 0.20513569798190054, "Bleu_3": 0.15454651343685405, "Bleu_4": 0.11858444239827323, "METEOR": 0.3085536634405993, "ROUGE_L": 0.33242506811989103, "CIDEr": 4.2033002506274665e-15, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two women sitting at a dining table. One woman is on the left side of the table, while the other is on the right side. The women are engaged in their respective activities. One woman is looking at a laptop and using a laptop computer. The other woman is eating a cake and using a laptop."}, "92355": {"image_id": 92355, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.1671899541887144, "Bleu_3": 8.130907204696851e-07, "Bleu_4": 1.801821270464176e-09, "METEOR": 0.1720787412862445, "ROUGE_L": 0.2694941462337088, "CIDEr": 7.301167144189545e-11, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.18518518518518517, "f": 0.22727272727272727, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a silver oven with a digital display showing the current temperature inside. The oven is set to 450 degrees. A rock is placed on top of the oven, adding a unique decorative touch to the scene.\n\nIn addition to the oven, there is a clock placed on top of the oven."}, "196681": {"image_id": 196681, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.1507453267063429, "Bleu_4": 0.12433577130208663, "METEOR": 0.254202388745293, "ROUGE_L": 0.28968792401628224, "CIDEr": 2.9506093954010306e-08, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.21739130434782608, "f": 0.1694915254237288, "fn": 18.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image features a helicopter flying high in the sky above a mountain range. The helicopter is positioned towards the top left of the scene, with its blades visible as it soars through the air. The mountain range stretches across the background, creating a picturesque landscape."}, "53457": {"image_id": 53457, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.11796693107080776, "Bleu_4": 1.4416980526283728e-05, "METEOR": 0.23132126321949126, "ROUGE_L": 0.34634492547906315, "CIDEr": 1.9261917898396306e-05, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a gray and white cat sitting on a television. The cat is perched on the TV, occupying a significant portion of the screen. The TV is placed on a wall, and the cat is enjoying a TV show."}, "245301": {"image_id": 245301, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.20140768086634514, "Bleu_4": 0.14596169407878418, "METEOR": 0.31361689068696774, "ROUGE_L": 0.3559445660102115, "CIDEr": 8.288642341460847e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a woman wearing a red jacket, riding a grey horse in a grassy field. The woman is riding a horse. The horse is grey. The horse is calm and well-trained. The woman is guiding the horse."}, "297574": {"image_id": 297574, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.1643989873008524, "Bleu_3": 0.09174380408476636, "Bleu_4": 1.2276168154895987e-05, "METEOR": 0.26671936373393507, "ROUGE_L": 0.3418734987990392, "CIDEr": 4.0775600203425265e-05, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.1875, "f": 0.26666666666666666, "fn": 26.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.3333333333333333, "f": 0.47058823529411764, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image features a plate of pizza placed on the table. The plate is blue. A slice of pizza is on the plate. The pizza is cut into several slices, and some of the slices are missing."}, "392048": {"image_id": 392048, "Bleu_1": 0.13761467889782006, "Bleu_2": 0.09444294536110055, "Bleu_3": 0.05503788729245713, "Bleu_4": 0.0354135814085102, "METEOR": 0.19318994951857293, "ROUGE_L": 0.13681512335789808, "CIDEr": 1.1211969019240317e-58, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.2, "f": 0.1702127659574468, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.25, "f": 0.11764705882352941, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a dining table with a tray filled with various food items and drinks. On the tray, there is a plate with waffles, eggs, bacon, and coffee. Another plate holds waffles and a cup of coffee. A third plate contains waffles with whipped cream. The tray also includes a fork and a knife. \n\nThere is no tray in the image.\n\nThere are no waffles or cups in the image.\n\nThere is a pie on the tray.\n\nThere are three plates on the tray.\n\nThere is a fork and a knife on the tray.\n\nThere is a coffee on the tray.\n\nThere are no cups in the image."}, "434511": {"image_id": 434511, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.1886616557167528, "Bleu_3": 0.14531254128144008, "Bleu_4": 0.10186291694218536, "METEOR": 0.2857819134141599, "ROUGE_L": 0.29516129032258065, "CIDEr": 4.830515368793365e-16, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man sitting at a dining table, working on a laptop computer. The man is wearing a blue shirt and appears to be focused on his task. The laptop computer is on the dining table. The table is surrounded by chairs, with one chair located in front of the table and another chair located behind the man."}, "454348": {"image_id": 454348, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.0932504808219817, "Bleu_3": 0.058248287421989356, "Bleu_4": 8.233704127828195e-06, "METEOR": 0.21301861084345566, "ROUGE_L": 0.20691994572591585, "CIDEr": 7.049833573182226e-09, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.22580645161290322, "f": 0.2456140350877193, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5454545454545454, "re": 0.46153846153846156, "f": 0.4999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a unique bench located in a park. The bench has been created by transforming a large tree stump into a stone bench. It provides a shady spot for a dog to rest. The bench is situated in a grassy area, surrounded by trees."}, "554459": {"image_id": 554459, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.2577696311071676, "Bleu_3": 0.1864575091279535, "Bleu_4": 0.13417679370522617, "METEOR": 0.2568979694909986, "ROUGE_L": 0.25505226480836235, "CIDEr": 1.0617924298811638e-06, "SPICE": {"All": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a group of three people standing in front of a small airplane, posing for a picture. The group consists of a man and two women, with the man standing between the women. They are all smiling and enjoying the moment."}, "455981": {"image_id": 455981, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.214984853867146, "Bleu_3": 0.1118838140362068, "Bleu_4": 1.4463984657639369e-05, "METEOR": 0.18156572553618477, "ROUGE_L": 0.28960278525083083, "CIDEr": 0.0001294021620419112, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.3181818181818182, "f": 0.358974358974359, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a toilet with a white seat, situated in a bathroom. The toilet is positioned under a sink. Above the toilet, there is a mirror. There are two towels hanging on the right."}, "498363": {"image_id": 498363, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.1663895814060149, "Bleu_3": 0.1105349109648521, "Bleu_4": 0.07622713576919625, "METEOR": 0.20908439513701976, "ROUGE_L": 0.2616154395997141, "CIDEr": 1.0779398881914047e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1111111111111111, "f": 0.15789473684210525, "fn": 24.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a pair of scissors with a chain hanging from them. The scissors are positioned in the center of the scene. The chain extends from the top left corner to the bottom right corner. There is no fabric in the scene."}, "122572": {"image_id": 122572, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.22214157542810112, "Bleu_3": 0.15700609186690778, "Bleu_4": 0.09379828038908734, "METEOR": 0.2378438151148509, "ROUGE_L": 0.26472411655300687, "CIDEr": 2.732161891057809e-12, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two deer walking on the road in a wooded area. The deer are walking side by side, with one deer slightly ahead of the other. They appear to be looking at something in the distance, possibly a source of food or an interesting sight. The road is surrounded by trees."}, "516143": {"image_id": 516143, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.14887283354071895, "Bleu_3": 0.07839548039992822, "Bleu_4": 1.017220586599864e-05, "METEOR": 0.28075351261775433, "ROUGE_L": 0.28018372703412076, "CIDEr": 2.739846273323312e-10, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.22727272727272727, "f": 0.30303030303030304, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a bus parked on the side of a street. The bus is green and white. It is positioned near a bus stop. There is a passenger waiting for the bus. There are also people standing close to a train and further away from the camera."}, "478621": {"image_id": 478621, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.22404481344004462, "Bleu_3": 0.14538903521362667, "Bleu_4": 1.5907005514231726e-05, "METEOR": 0.2919032379132632, "ROUGE_L": 0.2893689114781872, "CIDEr": 1.567062307381022e-08, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.10714285714285714, "f": 0.10714285714285714, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.07142857142857142, "f": 0.08, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features two men walking down a sidewalk in the rain. They are both holding an umbrella to protect themselves from the rain. Both men are wearing a suit and tie, suggesting that they might be businessmen or attending a formal event. The men are walking confidently in the rain."}, "353935": {"image_id": 353935, "Bleu_1": 0.305555555547068, "Bleu_2": 0.18687063685519775, "Bleu_3": 0.10089455706733778, "Bleu_4": 1.3282270438373226e-05, "METEOR": 0.25751790200289515, "ROUGE_L": 0.35942760942760943, "CIDEr": 6.385302231458257e-05, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.15384615384615385, "f": 0.1951219512195122, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a dining table with a white plate filled with a delicious dessert. The plate is topped with three waffles, each topped with blueberries and apples. The waffles are accompanied by a syrup sauce."}, "443952": {"image_id": 443952, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.12147975833382801, "Bleu_4": 1.3901690971832788e-05, "METEOR": 0.2269329757655879, "ROUGE_L": 0.3051907442151345, "CIDEr": 4.607528732363281e-11, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.3125, "f": 0.30303030303030304, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a clean and well-organized bathroom with a white toilet situated next to a walk-in shower. The shower has a glass door. There is a wooden cabinet above the toilet. The bathroom also includes a sink with a mirror above it and a towel rack next to the sink."}, "364399": {"image_id": 364399, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.12214340376073665, "Bleu_3": 0.08741691908645972, "Bleu_4": 0.05640409537213844, "METEOR": 0.28754368058837665, "ROUGE_L": 0.21212121212121215, "CIDEr": 2.627005098034948e-22, "SPICE": {"All": {"pr": 0.4, "re": 0.23529411764705882, "f": 0.29629629629629634, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a dining table with four bowls filled with various types of food. The bowls are arranged in a semi-circle shape. \n\nThe first bowl contains a salad with carrots. The second bowl contains pasta, green beans, and cheese. The third bowl has bananas, raspberries, and a salad. The fourth bowl holds a salad.\n\nIn addition to the bowls, there are no other items on the dining table."}, "281733": {"image_id": 281733, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.12725695259184966, "Bleu_3": 0.0759254028064691, "Bleu_4": 1.0500614219604798e-05, "METEOR": 0.19282482771095052, "ROUGE_L": 0.24148851939825808, "CIDEr": 1.8241283437485514e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2, "f": 0.2162162162162162, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a young boy with blond hair, enjoying a chocolate doughnut. He is biting into the doughnut, which is placed in the center of the scene. The boy appears to be the main focus of the image."}, "250167": {"image_id": 250167, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.2545139051836993, "Bleu_3": 0.17382577992832773, "Bleu_4": 1.954384523264165e-05, "METEOR": 0.32037087074850223, "ROUGE_L": 0.3198501872659176, "CIDEr": 4.979800614768442e-06, "SPICE": {"All": {"pr": 0.1875, "re": 0.2, "f": 0.19354838709677422, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man standing on a sandy beach. He is holding a surfboard. He is wearing a black swimsuit and appears to be enjoying his time at the beach. There are no other people in the scene."}, "460346": {"image_id": 460346, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.24494897426831577, "Bleu_3": 1.376600125372212e-06, "Bleu_4": 3.2998954723870518e-09, "METEOR": 0.19469100127814462, "ROUGE_L": 0.2571127502634352, "CIDEr": 0.029831053171243873, "SPICE": {"All": {"pr": 0.5, "re": 0.3181818181818182, "f": 0.3888888888888889, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}, "Relation": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image captures a man riding a skateboard on a sidewalk. The man is wearing a red shirt. He appears to be enjoying the activity."}, "246263": {"image_id": 246263, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.24814583348402305, "Bleu_3": 0.20894728579470018, "Bleu_4": 0.18012107374706401, "METEOR": 0.2344741040914, "ROUGE_L": 0.3729257641921398, "CIDEr": 0.007534155914681741, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet situated under a cabinet. The cabinet above the toilet is open. A sink is situated under one of the cabinets."}, "402588": {"image_id": 402588, "Bleu_1": 0.25714285713918367, "Bleu_2": 0.17266633891820174, "Bleu_3": 0.13804453971306602, "Bleu_4": 0.11194655206030497, "METEOR": 0.22460437419072543, "ROUGE_L": 0.2663755458515284, "CIDEr": 1.0524701318854682e-18, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a large crowd of people gathered on a street. Some of the people are wearing suits and ties. A man in a suit and tie stands out among the crowd. The crowd is diverse, with people of various ages and backgrounds. Some of the people are wearing green hoodies, while others are wearing black shirts. The crowd is lively and bustling, with people engaged in different activities."}, "470779": {"image_id": 470779, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.22934123614279892, "Bleu_3": 0.14296528607741424, "Bleu_4": 0.08616958092754766, "METEOR": 0.2228941807840875, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.9676673896520658e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.10526315789473684, "f": 0.10256410256410256, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a group of six people standing on a snow-covered slope, all wearing skis. They are posing for a picture and enjoying their time together on the snowy hill. The group consists of three men and three women, all of whom are wearing ski gear. One of the women is also wearing a helmet."}, "306281": {"image_id": 306281, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.07229440390503974, "Bleu_3": 5.074381600450152e-07, "Bleu_4": 1.3529171154640911e-09, "METEOR": 0.20612585648399906, "ROUGE_L": 0.2469635627530364, "CIDEr": 1.3108236846253248e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a close-up view of a delicious stir-fry dish, primarily consisting of broccoli and mushrooms. The broccoli pieces are scattered throughout the dish, with some pieces being larger and others smaller. The mushrooms are also mixed in with the broccoli."}, "307790": {"image_id": 307790, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.22086305214437035, "Bleu_3": 0.13460836455258657, "Bleu_4": 1.5813859795376296e-05, "METEOR": 0.2535732444002475, "ROUGE_L": 0.35384296664594983, "CIDEr": 5.479353551921261e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.16129032258064516, "f": 0.17857142857142855, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a brown chicken standing in a forest, surrounded by leaves. The chicken is looking at the camera. The scene is set in a wooded area with a mix of greenery and brown leaves, creating a natural and serene atmosphere."}, "353231": {"image_id": 353231, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.11919584838724184, "Bleu_3": 0.07838508147276235, "Bleu_4": 0.05368068661858022, "METEOR": 0.1337112183476571, "ROUGE_L": 0.23093564088696594, "CIDEr": 4.418147676260072e-16, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.35, "f": 0.36842105263157887, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a large body of water with several boats floating on it. There is a ferry boat in the middle of the water, surrounded by smaller boats. Some of the smaller boats are located closer to the shore, while others are further away.\n\nIn addition to the boats, there is a car visible.\n\nBoats are floating on the water."}, "199688": {"image_id": 199688, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.24445060351331568, "Bleu_3": 0.14524991003982507, "Bleu_4": 1.685159468450619e-05, "METEOR": 0.25006264605417033, "ROUGE_L": 0.32685867381111855, "CIDEr": 1.2417600493987072e-05, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.30434782608695654, "f": 0.34146341463414637, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a spacious living room with a large couch and a dining table. The couch is situated in the living room. The dining table is located in the living room. There are four chairs placed around the dining table."}, "13992": {"image_id": 13992, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.16791512356189472, "Bleu_3": 0.10083600805943947, "Bleu_4": 1.1738518622277468e-05, "METEOR": 0.2127808790413089, "ROUGE_L": 0.2392156862745098, "CIDEr": 5.901996229522118e-14, "SPICE": {"All": {"pr": 0.21621621621621623, "re": 0.21052631578947367, "f": 0.21333333333333335, "fn": 30.0, "numImages": 1.0, "fp": 29.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.5384615384615384, "f": 0.5384615384615384, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image features a street sign with a blue arrow pointing to the left, indicating the direction to the restroom. The sign is mounted on a pole in the middle of the road. There is a rusty metal fence situated near the pole. There are two trees in the scene. There is no bench in the scene."}, "567315": {"image_id": 567315, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4577377081947216, "Bleu_3": 0.2804378262594809, "Bleu_4": 3.327049924768659e-05, "METEOR": 0.2931478969578134, "ROUGE_L": 0.43109540636042404, "CIDEr": 0.13601382710384122, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks, surrounded by a lush green field. The train is red and yellow."}, "437351": {"image_id": 437351, "Bleu_1": 0.34615384614053263, "Bleu_2": 0.1664100588610404, "Bleu_3": 1.0488562462463889e-06, "Bleu_4": 2.661368533136455e-09, "METEOR": 0.21386105586389356, "ROUGE_L": 0.2505133470225872, "CIDEr": 0.030145603388457974, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12903225806451613, "f": 0.14545454545454548, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a woman sitting on a suitcase. The woman is positioned in the center of the scene. The luggage is stacked on the floor."}, "531602": {"image_id": 531602, "Bleu_1": 0.3199999999936, "Bleu_2": 0.2555506259948128, "Bleu_3": 0.2013513923406009, "Bleu_4": 0.1623515768756913, "METEOR": 0.3144935338859403, "ROUGE_L": 0.30310559006211185, "CIDEr": 7.960164538458902e-10, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.1724137931034483, "f": 0.20833333333333334, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a boy standing in a bathroom. The boy is brushing his teeth with a toothbrush. He is using an electric brush to brush his teeth and appears to be focused on the task. The boy is wearing a yellow shirt. There are two toothbrushes in the scene."}, "430546": {"image_id": 430546, "Bleu_1": 0.2916666666545139, "Bleu_2": 0.19504737439306988, "Bleu_3": 0.12002890534307711, "Bleu_4": 1.693984999796846e-05, "METEOR": 0.1606239112309082, "ROUGE_L": 0.3177083333333333, "CIDEr": 0.028947864808305437, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.30434782608695654, "f": 0.31111111111111117, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a thrilling moment of a motorcycle rider skillfully navigating a curve on a race track. The rider is leaning his motorcycle."}, "309366": {"image_id": 309366, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.10390486669052698, "Bleu_3": 6.6326948668966e-07, "Bleu_4": 1.6872983760809617e-09, "METEOR": 0.1848184818481848, "ROUGE_L": 0.2741573033707865, "CIDEr": 1.8647362681482945e-06, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.21739130434782608, "f": 0.16129032258064516, "fn": 18.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image features a train yard with several yellow and white trains parked on the tracks. The trains are arranged in a row. The trains are of various sizes, indicating a diverse range of train types in the yard."}, "560111": {"image_id": 560111, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.25112360116008, "Bleu_3": 0.12168461497444133, "Bleu_4": 1.5172495765202357e-05, "METEOR": 0.24367367137355167, "ROUGE_L": 0.32323996971990915, "CIDEr": 4.573441803109882e-05, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a train moving along the tracks. The train is red. There is a red train car in the foreground. A building is behind the train. The southeastern railroad logo is on the train car."}, "152946": {"image_id": 152946, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.12577443714450187, "Bleu_3": 0.06485133546264767, "Bleu_4": 8.317072340661929e-06, "METEOR": 0.15452098401258027, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.238235292977776e-15, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.35714285714285715, "f": 0.27027027027027023, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a snowy ski slope with two people standing on the snow. The first person is on the left side of the scene, holding a snowboard, and wearing snow gear. The second person is on the right side, also holding a snowboard, and wearing a black jacket. They both appear to be enjoying their time on the mountain."}, "364016": {"image_id": 364016, "Bleu_1": 0.333333333325926, "Bleu_2": 0.21320071635081886, "Bleu_3": 0.14691857457144636, "Bleu_4": 0.09321701825196603, "METEOR": 0.2808596961345335, "ROUGE_L": 0.3609467455621302, "CIDEr": 1.2921731102368319e-06, "SPICE": {"All": {"pr": 0.11363636363636363, "re": 0.22727272727272727, "f": 0.15151515151515152, "fn": 17.0, "numImages": 1.0, "fp": 39.0, "tp": 5.0}, "Relation": {"pr": 0.047619047619047616, "re": 0.09090909090909091, "f": 0.0625, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image depicts a group of six people sitting around a dining table. The people are engaged in various activities, such as eating, using cell phones, and writing on paper. The table is the focal point of the scene, with the people sitting around it."}, "449603": {"image_id": 449603, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.2705008903937107, "Bleu_3": 0.2339511309046898, "Bleu_4": 0.21067622240307926, "METEOR": 0.36561013100411827, "ROUGE_L": 0.4218533886583678, "CIDEr": 1.073553592007348e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.25, "f": 0.24242424242424243, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 8.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.11764705882352941, "f": 0.14285714285714285, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image captures a person skillfully riding a wave on a surfboard in the ocean. The person is doing parasailing. The water is visible beneath the person. The person is enjoying water sports. The person is riding the wave in the ocean."}, "350289": {"image_id": 350289, "Bleu_1": 0.2957746478831581, "Bleu_2": 0.19500812550508156, "Bleu_3": 0.10329883893031021, "Bleu_4": 1.1283513475680752e-05, "METEOR": 0.17500803701845338, "ROUGE_L": 0.22067690328804565, "CIDEr": 2.997864819380425e-17, "SPICE": {"All": {"pr": 0.35, "re": 0.2413793103448276, "f": 0.2857142857142857, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures two men walking on the beach. One of the men is carrying a surfboard, likely preparing to go surfing in the ocean. The other man is walking behind him. \n\nThe beach scene is peaceful and serene, with the sound of crashing waves and the warm sand beneath their feet. The men are enjoying their time at the beach, taking in the beautiful scenery and the refreshing ocean breeze."}, "460621": {"image_id": 460621, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 0.1272232018279771, "Bleu_4": 0.08821755394408795, "METEOR": 0.290778462427548, "ROUGE_L": 0.27858121479677267, "CIDEr": 2.4005067676617292e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.12, "f": 0.16216216216216217, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a white bathtub in a bathroom. A toilet is situated next to the bathtub. The bathtub looks dirty and rusty, indicating that it has not been well-maintained. There are two faucets on the bathtub."}, "473199": {"image_id": 473199, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.152498570329016, "Bleu_3": 8.277818425483375e-07, "Bleu_4": 1.940536983395307e-09, "METEOR": 0.21025636398361755, "ROUGE_L": 0.30521801286633315, "CIDEr": 2.3880669882215823e-07, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15789473684210525, "f": 0.16666666666666669, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a lively outdoor dining area with two tables and two chairs arranged under a row of yellow umbrellas. The umbrellas provide shade and protection from the sun. The patrons benefit from the umbrellas. The tables are adorned with potted plants."}, "322944": {"image_id": 322944, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.13950389246791473, "Bleu_4": 1.5342308957715507e-05, "METEOR": 0.18889171302755434, "ROUGE_L": 0.2784479947831757, "CIDEr": 7.831633148204197e-09, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.05555555555555555, "f": 0.0606060606060606, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image features a woman holding a stuffed teddy bear in her arms. The woman is wearing a white dress and appears to be in a vulnerable state. The woman's eye is brown. The woman is positioned in the center of the scene, with the teddy bear on her left side."}, "110027": {"image_id": 110027, "Bleu_1": 0.305555555547068, "Bleu_2": 0.18687063685519775, "Bleu_3": 0.10089455706733778, "Bleu_4": 1.3282270438373226e-05, "METEOR": 0.27747039566275766, "ROUGE_L": 0.29901960784313725, "CIDEr": 2.2687875948322216e-05, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.23809523809523808, "f": 0.30303030303030304, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5, "f": 0.6153846153846154, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image depicts a kitchen with a dining table surrounded by chairs. The chairs are placed around the table. There is a black refrigerator on the left side and another black refrigerator on the right side."}, "74492": {"image_id": 74492, "Bleu_1": 0.16176470587997407, "Bleu_2": 0.09827306030011396, "Bleu_3": 0.05269567943735181, "Bleu_4": 6.888155095077198e-06, "METEOR": 0.15479278679587344, "ROUGE_L": 0.21785714285714283, "CIDEr": 1.1504571751199742e-18, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.4, "f": 0.3243243243243243, "fn": 9.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image is a collage of four different pictures of a remote control. Each picture shows a different angle or perspective of the remote control, allowing for a comprehensive view of the device. The remote control is black in color and features a button on the bottom left side. The images are arranged in a way that highlights the button on the top located on the remote control."}, "280211": {"image_id": 280211, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4281744192679387, "Bleu_3": 0.26822913134033327, "Bleu_4": 3.2178169207644135e-05, "METEOR": 0.33573297421328835, "ROUGE_L": 0.5252152521525214, "CIDEr": 0.12154209766792866, "SPICE": {"All": {"pr": 0.3, "re": 0.13043478260869565, "f": 0.18181818181818182, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a train station with a silver train parked on the tracks. The train is positioned behind a fence."}, "41247": {"image_id": 41247, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.16087993330478273, "Bleu_3": 0.10184644872865577, "Bleu_4": 1.2180051043910706e-05, "METEOR": 0.18541288944208453, "ROUGE_L": 0.2544392801811465, "CIDEr": 4.645907622666605e-09, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.043478260869565216, "f": 0.04878048780487805, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image captures a scene at the beach, with an ocean in the background and a beach in the foreground. There are no people or surfers in the image. However, there is a wave visible in the ocean. There is also a person present. There is no camera in the scene."}, "419379": {"image_id": 419379, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.0973123680171955, "Bleu_3": 6.734801438348329e-07, "Bleu_4": 1.7863365456276687e-09, "METEOR": 0.14664695332209263, "ROUGE_L": 0.21922731356693623, "CIDEr": 7.635986844917705e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.34782608695652173, "f": 0.3404255319148936, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.8571428571428571, "f": 0.7999999999999999, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a table with a tray of donuts displayed on it. The tray contains a dozen donuts, including cranberry oat type donuts. The donuts are arranged in a visually appealing manner."}, "581731": {"image_id": 581731, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 0.06912848008424652, "Bleu_4": 8.92774794149235e-06, "METEOR": 0.14424677912555373, "ROUGE_L": 0.20666290231507625, "CIDEr": 4.819852542776615e-13, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.1724137931034483, "f": 0.20833333333333334, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a forest with a large, rusty metal sculpture sitting in the middle. The sculpture is positioned on a wooden platform. Trees surround the sculpture. The scene appears to be a mix of natural elements and human-made art, creating a unique atmosphere. The forest floor adds to the overall ambiance of the image."}, "103584": {"image_id": 103584, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.3028759993164135, "Bleu_3": 0.23040371938290988, "Bleu_4": 0.18860270984176705, "METEOR": 0.2902657954622177, "ROUGE_L": 0.42068965517241375, "CIDEr": 0.005246293341759355, "SPICE": {"All": {"pr": 0.15, "re": 0.1875, "f": 0.16666666666666663, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a dog sitting on a bed. The dog is brown and is wearing a collar. The dog is staring at a person. The bed is covered with a blanket."}, "350132": {"image_id": 350132, "Bleu_1": 0.4374999999863282, "Bleu_2": 0.39400753225542773, "Bleu_3": 0.34593347830242555, "Bleu_4": 0.290661457416434, "METEOR": 0.33087582917584285, "ROUGE_L": 0.36810344827586206, "CIDEr": 0.003732819250638072, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image is a collage of four different shots of men playing with a frisbee in a park. In each shot, a man is catching a frisbee, showcasing their athleticism and skill."}, "210448": {"image_id": 210448, "Bleu_1": 0.23809523809145886, "Bleu_2": 0.1752768273470684, "Bleu_3": 0.11474844499183373, "Bleu_4": 0.0708389791644021, "METEOR": 0.19026563689423712, "ROUGE_L": 0.22067183462532297, "CIDEr": 4.185029128506764e-18, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07407407407407407, "f": 0.10256410256410256, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a group of six zebras standing together in a dirt field. They are all gathered around a fence, possibly in a zoo enclosure.\n\nThere are six zebras in the scene. Some zebras are standing closer to the foreground and others further back. They are all gathered around a fence, possibly in a zoo enclosure.\n\nThe field is made of sand."}, "267300": {"image_id": 267300, "Bleu_1": 0.382352941165225, "Bleu_2": 0.2636640221444497, "Bleu_3": 0.16317761743821596, "Bleu_4": 1.934884374047744e-05, "METEOR": 0.2953427888905817, "ROUGE_L": 0.4109281437125748, "CIDEr": 0.004215995121710033, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.14285714285714285, "f": 0.18749999999999997, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a dog eating a piece of food on a plate placed on the floor. The dog is eating a piece of pizza. The plate is filled with a mix of food."}, "107939": {"image_id": 107939, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.23008949664965453, "Bleu_3": 0.14799245941635208, "Bleu_4": 1.6120161235009696e-05, "METEOR": 0.2341976033842251, "ROUGE_L": 0.29847094801223245, "CIDEr": 2.9213845688242333e-10, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.3181818181818182, "f": 0.2916666666666667, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a stop sign on a pole, located at the corner of North and Northwest Avenues. The stop sign is positioned in front of a house. There are trees in the background, providing a pleasant and natural setting. The scene appears to be captured in a fisheye lens, giving"}, "352760": {"image_id": 352760, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.24280424359293504, "Bleu_3": 0.13685528388493665, "Bleu_4": 0.08687464620677844, "METEOR": 0.2683537427091716, "ROUGE_L": 0.29901960784313725, "CIDEr": 1.0993775558664697e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a man in a yellow ski suit flying through the air while skiing. He is performing a jump, showcasing his skill and athleticism. The skier is in mid-air, with his skis clearly visible beneath him. The scene is set against a backdrop of a cloud."}, "58210": {"image_id": 58210, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.3646984043000982, "Bleu_3": 0.29095421656751347, "Bleu_4": 0.17543860063978756, "METEOR": 0.24339552093995448, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.009172393424491967, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2222222222222222, "f": 0.21818181818181817, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a bird standing on a grassy field. The bird is gray and white. It is standing on the ground. The bird's wings are spread wide."}, "529592": {"image_id": 529592, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.21931085605462405, "Bleu_3": 0.15089125644562476, "Bleu_4": 0.09567579772168915, "METEOR": 0.2284424930317632, "ROUGE_L": 0.214185393258427, "CIDEr": 1.274735387245186e-06, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2608695652173913, "f": 0.2608695652173913, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a group of people playing frisbee on a red gym floor. Two men are the main focus of the scene. One of the men is holding a yellow frisbee, preparing to throw it. The other man is also holding a frisbee."}, "191112": {"image_id": 191112, "Bleu_1": 0.18292682926606188, "Bleu_2": 0.09504432475086728, "Bleu_3": 0.06089721934782905, "Bleu_4": 7.312086563612999e-06, "METEOR": 0.197927428643376, "ROUGE_L": 0.15186721991701246, "CIDEr": 2.1918624407460678e-30, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.25, "f": 0.25641025641025644, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features three men standing on a soccer field. The first man is holding a robotic arm and interacting with a sports ball. The second man is holding a tennis racket and standing on a tennis court. The third man is holding a cell phone and playing badminton. \n\nThe men are possibly playing a game or practicing with the ball. Another person can be seen in the background, possibly observing the men. The men are standing in front of the goal."}, "549338": {"image_id": 549338, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.15430334995456055, "Bleu_3": 1.078116525133221e-06, "Bleu_4": 2.888558389780397e-09, "METEOR": 0.17119493034749975, "ROUGE_L": 0.2549634273772205, "CIDEr": 0.10379118427779747, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2222222222222222, "f": 0.22857142857142856, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features three fields, all of which are green. There are two cows grazing on the grass in the pasture."}, "369849": {"image_id": 369849, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.12246598403054855, "Bleu_4": 0.07906552205748897, "METEOR": 0.22667849080636682, "ROUGE_L": 0.26228501228501233, "CIDEr": 1.3485332112298345e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 33.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.06666666666666667, "f": 0.1, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.35714285714285715, "f": 0.3846153846153846, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features three horses grazing on grass in a field. They are spread out across the scene, with one horse on the left side, another in the middle, and two more on the right side. The horses are peacefully eating the grass, enjoying their time in the open field."}, "206271": {"image_id": 206271, "Bleu_1": 0.2077922077895092, "Bleu_2": 0.1478947733273738, "Bleu_3": 0.10526923333823952, "Bleu_4": 0.07493343889927806, "METEOR": 0.14976006049734822, "ROUGE_L": 0.16017505470459517, "CIDEr": 2.988505970080088e-28, "SPICE": {"All": {"pr": 0.25, "re": 0.20689655172413793, "f": 0.22641509433962265, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a bathroom with two urinals mounted on the wall. One urinal is located on the left side of the wall, and the other urinal is located on the right side. The urinals are connected to a pipe system. A sink is positioned next to the urinals. A toilet paper dispenser is also positioned next to one of the urinals. The bathroom has a tiled floor, and a TV screen is visible beneath the urinals."}, "442301": {"image_id": 442301, "Bleu_1": 0.12499999999687503, "Bleu_2": 1.7902871850532516e-09, "Bleu_3": 4.385515023467518e-12, "Bleu_4": 2.1850683240976132e-13, "METEOR": 0.07799113737075333, "ROUGE_L": 0.1382175226586103, "CIDEr": 9.452156443899252e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.19047619047619047, "f": 0.1951219512195122, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features five carrots cut into various shapes, including a slanted triangle, a heart, a hand, and a finger. One of the carrots resembles a hand. The carrots are placed on a countertop. A knife is also seen nearby.\n\n"}, "578788": {"image_id": 578788, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.30760958357595436, "Bleu_3": 0.21391487908731557, "Bleu_4": 2.4315949751658318e-05, "METEOR": 0.19225589590655512, "ROUGE_L": 0.3266107442441549, "CIDEr": 0.0016797093882536464, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3333333333333333, "f": 0.34285714285714286, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a man performing a trick on his skateboard. The man is skateboarding and performing the trick on a skateboard. A green fence is clearly visible beneath the skateboarder."}, "5352": {"image_id": 5352, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.3351111237096373, "Bleu_3": 0.25985589372428086, "Bleu_4": 0.18342836881371094, "METEOR": 0.3205227974426264, "ROUGE_L": 0.4282371294851794, "CIDEr": 0.0011373387770758998, "SPICE": {"All": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a dining table with a green plate containing a slice of pizza on it. The pizza is topped with cheese and pepperoni. A glass of beer is next to the plate."}, "236023": {"image_id": 236023, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.09460175443535335, "Bleu_4": 1.1407274488549462e-05, "METEOR": 0.18662569320562442, "ROUGE_L": 0.2616621983914209, "CIDEr": 2.7657725207823534e-10, "SPICE": {"All": {"pr": 0.4375, "re": 0.25925925925925924, "f": 0.3255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image depicts a group of five people gathered in a kitchen, enjoying each other's company. They are standing around a kitchen counter, which is filled with various items such as bottles, cups, and a clock. The people are holding red cups. \n\nThere is a bottle of wine on the kitchen counter."}, "339943": {"image_id": 339943, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.13240928541024866, "Bleu_4": 0.08383287626240972, "METEOR": 0.22238560579965022, "ROUGE_L": 0.2692307692307692, "CIDEr": 1.2658447079229941e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white sink and two white bathtubs. The sink is positioned on the right side of the room, while the bathtubs are located on the left side. A mirror is mounted above the sink, and a towel rack is placed next to the bathtubs."}, "491755": {"image_id": 491755, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.12757664411350078, "Bleu_4": 0.08435919294635907, "METEOR": 0.2217652125382655, "ROUGE_L": 0.285427807486631, "CIDEr": 2.8240724914785333e-07, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.26666666666666666, "f": 0.30188679245283023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a cozy living room with a fireplace as the focal point. The room features a comfortable couch situated in the center, with a chair placed nearby. A television is mounted on the wall. \n\nThere is no remote control in the scene."}, "375405": {"image_id": 375405, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.22794037622152502, "Bleu_3": 0.1615055126759114, "Bleu_4": 0.10400755516777732, "METEOR": 0.2944628039056893, "ROUGE_L": 0.33808392715756136, "CIDEr": 6.589602220349739e-06, "SPICE": {"All": {"pr": 0.3125, "re": 0.23809523809523808, "f": 0.27027027027027023, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features two white birds perched on a tree branch. One bird is resting its head on the other, creating a sense of companionship and affection. The birds are surrounded by greenery, with leaves visible in the background."}, "253624": {"image_id": 253624, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.37959013414553383, "Bleu_3": 0.2988216257482, "Bleu_4": 0.21284976747696133, "METEOR": 0.3130692120482718, "ROUGE_L": 0.42178046672428693, "CIDEr": 0.027583942703131276, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8333333333333334, "f": 0.625, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a gray and white cat sitting on a chair. The cat is relaxed and comfortable, occupying the chair. The chair is positioned in the dining room."}, "510122": {"image_id": 510122, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.3246172270214718, "Bleu_3": 0.1936979576834366, "Bleu_4": 2.2571180478063343e-05, "METEOR": 0.2595507842098334, "ROUGE_L": 0.4299559471365638, "CIDEr": 0.0022777846360145138, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a lively scene of a group of 18 people gathered on a rooftop. The people are flying kites. A kite is in the sky, soaring above the crowd."}, "484225": {"image_id": 484225, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.18946618668147105, "Bleu_3": 0.09812054324169892, "Bleu_4": 1.2640653505172758e-05, "METEOR": 0.2824169839184068, "ROUGE_L": 0.28416149068322977, "CIDEr": 1.2498755847330139e-06, "SPICE": {"All": {"pr": 0.15625, "re": 0.20833333333333334, "f": 0.17857142857142858, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a yellow and black train traveling down the tracks in a snowy environment. The train is quite large, occupying a significant portion of the scene. The tracks are covered in snow. The train is moving through snow."}, "271772": {"image_id": 271772, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.2670982280194135, "Bleu_3": 0.19413885593563246, "Bleu_4": 0.11779814467051922, "METEOR": 0.32785099651716487, "ROUGE_L": 0.3951061532925513, "CIDEr": 2.7305932955645217e-06, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.35294117647058826, "f": 0.35294117647058826, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.8, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man flying a colorful kite in a blue sky. The kite is soaring in the sky. The man is holding onto the string and enjoying the activity. The tail of the kite is visible in the sky."}, "264013": {"image_id": 264013, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.1301889109786357, "Bleu_3": 0.06636004394087884, "Bleu_4": 8.461771328963095e-06, "METEOR": 0.23253515780824738, "ROUGE_L": 0.1967741935483871, "CIDEr": 3.635350308517409e-15, "SPICE": {"All": {"pr": 0.4, "re": 0.13793103448275862, "f": 0.20512820512820515, "fn": 25.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features two trains traveling down the tracks. The trains are blue and yellow. They are moving along the tracks and passing through a train station. \n\nThere are four traffic lights visible in the scene, indicating that the train is passing through an area with traffic control. \n\nThere is no specific mention of an area in the supplementary information."}, "138644": {"image_id": 138644, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.1996674976872179, "Bleu_3": 0.1428841479853578, "Bleu_4": 0.10989565913581457, "METEOR": 0.28501479950229813, "ROUGE_L": 0.3132795304475422, "CIDEr": 9.067632981015799e-08, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.23529411764705882, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a woman with short hair, wearing a black shirt, and holding a banana in her mouth. She appears to be playfully posing for the camera. The woman is standing in a kitchen, with a refrigerator not visible in the background."}, "525208": {"image_id": 525208, "Bleu_1": 0.5151515151359045, "Bleu_2": 0.38063941418019953, "Bleu_3": 0.26540469628740676, "Bleu_4": 0.15799783603861695, "METEOR": 0.38600908942627987, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.001811232657415506, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.36363636363636365, "f": 0.3555555555555555, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Attribute": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts a busy city street at night. There are 13 cars driving through an intersection. Some of the cars are waiting at the traffic light. The street is filled with traffic."}, "548713": {"image_id": 548713, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.2084219669570065, "Bleu_3": 0.0981091958911253, "Bleu_4": 1.2035916294672372e-05, "METEOR": 0.2971481780472015, "ROUGE_L": 0.3194832402234637, "CIDEr": 4.9395057764947045e-08, "SPICE": {"All": {"pr": 0.47058823529411764, "re": 0.27586206896551724, "f": 0.34782608695652173, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.7142857142857143, "re": 0.4166666666666667, "f": 0.5263157894736842, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features two horses standing on a city street, pulling a carriage. The horses are positioned close to each other, with one horse on the left side and the other on the right side of the carriage. The carriage is located in the middle of the scene."}, "552186": {"image_id": 552186, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 0.14563421111572247, "Bleu_4": 1.7361123498626597e-05, "METEOR": 0.35158921466693566, "ROUGE_L": 0.40230832646331416, "CIDEr": 3.2110135948088496e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.12, "f": 0.1764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image captures a man skateboarding in a park. The man is riding a skateboard. He is performing a trick, possibly a kickflip, as he moves across the park. There are several other people in the background."}, "245513": {"image_id": 245513, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.3038218101131809, "Bleu_3": 0.24871131730975723, "Bleu_4": 0.191248131481018, "METEOR": 0.32801350181790595, "ROUGE_L": 0.5010266940451744, "CIDEr": 0.04486286109318561, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2, "f": 0.22727272727272727, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a giraffe standing in a grassy field. The giraffe's neck is visible. A white bird is standing nearby. Trees surround the giraffe."}, "156999": {"image_id": 156999, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.14564381624866016, "Bleu_3": 0.08719228127993563, "Bleu_4": 1.0127993013405751e-05, "METEOR": 0.15856830713417916, "ROUGE_L": 0.2079680498733684, "CIDEr": 5.020010710597624e-18, "SPICE": {"All": {"pr": 0.3, "re": 0.1111111111111111, "f": 0.16216216216216217, "fn": 24.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a giraffe bending down to eat grass in a grassy area. The giraffe is eating from a tree branch. The giraffe's head is close to the ground as it feeds on the leaves. The grassy area is brown in color. The tree branch is brown and white in color.\n\nIn the background, there is a scene with a ground covered in grass."}, "406211": {"image_id": 406211, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.2452557357896452, "Bleu_3": 0.1970869636916744, "Bleu_4": 0.1631689373831181, "METEOR": 0.3048632824595579, "ROUGE_L": 0.3342465753424657, "CIDEr": 1.2839880651048527e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.15, "f": 0.12, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a cat sitting on a blue stool in a living room. The cat is attentively watching a television. The television is located on the right side of the room. The cat is positioned on a blue stool. \n\nThe living room is filled with various books scattered around. The floor is visible in the scene."}, "403065": {"image_id": 403065, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.12964074470667444, "Bleu_3": 7.985884624255978e-07, "Bleu_4": 1.9973527828806605e-09, "METEOR": 0.14545454545454548, "ROUGE_L": 0.2250922509225092, "CIDEr": 0.00046305930058363224, "SPICE": {"All": {"pr": 0.125, "re": 0.05555555555555555, "f": 0.07692307692307691, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image depicts a beach scene with a group of people enjoying their time near the ocean. The people are putting up flags. Flags are near the people. There is no truck in the scene."}, "142697": {"image_id": 142697, "Bleu_1": 0.49999999998076927, "Bleu_2": 0.37416573866271535, "Bleu_3": 0.22680307052269716, "Bleu_4": 2.6687306187655183e-05, "METEOR": 0.303489452288653, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.033514235237086916, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.18181818181818182, "f": 0.20512820512820512, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image captures a man riding a surfboard in the water. The man is skillfully riding the wave. He is surfing and wearing a blue shirt."}, "546424": {"image_id": 546424, "Bleu_1": 0.49999999998750005, "Bleu_2": 0.25318484176450595, "Bleu_3": 1.1904119237541848e-06, "Bleu_4": 2.5984987977839535e-09, "METEOR": 0.20846449998115268, "ROUGE_L": 0.3359559402045633, "CIDEr": 8.854535313493518e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08, "f": 0.10256410256410256, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a bride and a groom standing together, dressed in their wedding attire. The bride is wearing a white dress, and the groom is wearing a suit. They are both holding hands, creating a romantic and intimate atmosphere."}, "219798": {"image_id": 219798, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.2419433515576788, "Bleu_3": 0.18174993173897372, "Bleu_4": 0.11211398594791805, "METEOR": 0.2716945973749843, "ROUGE_L": 0.3434201266713582, "CIDEr": 3.7195849244884546e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a dog wearing a colorful rainbow-colored scarf. The dog is walking on a sidewalk, possibly on a leash, as it appears to be a pet. The dog's tail is wagging, indicating that it is enjoying its walk."}, "198223": {"image_id": 198223, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.16351748503705, "Bleu_3": 0.09418739954830285, "Bleu_4": 1.2813098990443002e-05, "METEOR": 0.2154669516134947, "ROUGE_L": 0.3024793388429752, "CIDEr": 9.17410140836691e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures three families on the beach. They are playing with a frisbee. They are standing on the beach. They are playing in the water. The woman is holding the child's hand."}, "288799": {"image_id": 288799, "Bleu_1": 0.06666666666592594, "Bleu_2": 0.027369027574892877, "Bleu_3": 2.041794458126517e-07, "Bleu_4": 5.592798882929977e-10, "METEOR": 0.08966144984451888, "ROUGE_L": 0.09479409479409479, "CIDEr": 4.5170631055313027e-41, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.07692307692307693, "f": 0.08888888888888889, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a busy city street with three traffic lights hanging above the road. The first traffic light is displaying a red light, indicating that vehicles should stop. The second traffic light is displaying a blue light, which may indicate a faulty battery. The third traffic light has a red and yellow light, also indicating a stop sign. \n\nThere is a building in the scene, and it has a clock on it. \n\nThere is also a sign with red and yellow colors. \n\nThere is a vehicle on the street."}, "492366": {"image_id": 492366, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.15115540850568024, "Bleu_4": 0.11193401922301613, "METEOR": 0.25137064381362484, "ROUGE_L": 0.31063017186505404, "CIDEr": 3.863503898518051e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.08695652173913043, "f": 0.11428571428571427, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image depicts a busy street scene with two men standing next to two horse-drawn carriages. The man is standing next to a horse drawn cart, while the other man is standing next to a rickshaw. The horse is positioned on the left side of the carriage."}, "313240": {"image_id": 313240, "Bleu_1": 0.14666666666471112, "Bleu_2": 0.06296001877269054, "Bleu_3": 0.03786770157073074, "Bleu_4": 5.24045004364293e-06, "METEOR": 0.14167817887120776, "ROUGE_L": 0.20307948397836043, "CIDEr": 1.4199142756064763e-23, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features two desks. On the first desk, there is a computer monitor located on the left side. A computer keyboard is on the desk. The desk is surrounded by a shelf. On the second desk, there is a computer, books, and a mouse. Books are surrounding the desk. \n\nThere is a workspace where books are scattered around.\n\nThere is no TV in the scene.\n\nOverall, a keyboard is a part of the computer."}, "103705": {"image_id": 103705, "Bleu_1": 0.4634146341350387, "Bleu_2": 0.3403728228441033, "Bleu_3": 0.20732681062829109, "Bleu_4": 0.12375014058584424, "METEOR": 0.3282393963180038, "ROUGE_L": 0.416382252559727, "CIDEr": 0.0033561488672169326, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.20833333333333334, "f": 0.2631578947368421, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a man lying on a bed on a cruise ship. The man is enjoying a cruise. The bed is positioned next to a window, providing a clear view of the scenery. There are four beds in the room."}, "148588": {"image_id": 148588, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.09525009524711837, "Bleu_3": 6.712276850566138e-07, "Bleu_4": 1.797019940085349e-09, "METEOR": 0.20211174440351237, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.001157557819969167, "SPICE": {"All": {"pr": 0.09259259259259259, "re": 0.15625, "f": 0.11627906976744184, "fn": 27.0, "numImages": 1.0, "fp": 49.0, "tp": 5.0}, "Relation": {"pr": 0.043478260869565216, "re": 0.08333333333333333, "f": 0.057142857142857134, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.3333333333333333, "f": 0.27586206896551724, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image features two ovens, with one pizza inside one of the ovens. The oven is filled with fire, creating a warm glow. The pizzas are placed on trays inside the oven."}, "240739": {"image_id": 240739, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.25951288748882756, "Bleu_3": 0.2239007438869537, "Bleu_4": 0.18589156724648007, "METEOR": 0.320428031829567, "ROUGE_L": 0.3335358444714459, "CIDEr": 6.592057945420455e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.28125, "f": 0.18367346938775508, "fn": 23.0, "numImages": 1.0, "fp": 57.0, "tp": 9.0}, "Relation": {"pr": 0.05, "re": 0.08333333333333333, "f": 0.0625, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.09523809523809523, "re": 0.2857142857142857, "f": 0.14285714285714285, "fn": 5.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.24, "re": 0.46153846153846156, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}}, "caption": "The image features a man playing tennis on a tennis court. He is holding a tennis racket and preparing to hit a tennis ball. The man is wearing a white shirt and blue shorts. He appears to be focused on the game as he prepares to hit the tennis ball."}, "213224": {"image_id": 213224, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.10033557298297395, "Bleu_4": 1.1749577059992224e-05, "METEOR": 0.2135371214240794, "ROUGE_L": 0.2330786026200873, "CIDEr": 1.599467921438297e-11, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.2413793103448276, "f": 0.2978723404255319, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a table with a vase of flowers placed on it. The table is made of wood and is positioned towards the center of the image. The vase contains ferns and is located near the left side of the table. There are also five flowers arranged in a visually appealing manner in the vase."}, "440895": {"image_id": 440895, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.13867504905279598, "Bleu_3": 0.07969009659317544, "Bleu_4": 1.0814410080200432e-05, "METEOR": 0.23480453014324806, "ROUGE_L": 0.263536866359447, "CIDEr": 6.737668255616936e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2857142857142857, "f": 0.25531914893617025, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features two buildings. A horse is looking out of one of the windows. The horse is standing in the window, possibly observing its surroundings or waiting for someone. A cat is also looking out of several other windows."}, "142934": {"image_id": 142934, "Bleu_1": 0.17460317460040317, "Bleu_2": 0.10613538967648731, "Bleu_3": 5.694604069888632e-07, "Bleu_4": 1.324524018391331e-09, "METEOR": 0.23294637556633743, "ROUGE_L": 0.19056544829740704, "CIDEr": 2.874669904787309e-17, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two men standing on a snow-covered slope, each holding a snowboard. They are preparing to snowboard down the mountain. The slope is surrounded by a mountain range, creating a picturesque winter scene.\n\nThe men are positioned close to each other, with one man holding a snowboard and the other carrying snowboards. They are both doing snowboarding on the snow-covered slope."}, "164983": {"image_id": 164983, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.19674775072873343, "Bleu_3": 0.11010503638215555, "Bleu_4": 1.4776306152176402e-05, "METEOR": 0.21784828114663868, "ROUGE_L": 0.3266107442441549, "CIDEr": 0.005849659724788255, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2777777777777778, "f": 0.2777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a dog lying on a bed. The dog is brown. The dog is occupying the bed. \n\nThe room also contains a dining table and several books scattered around."}, "316672": {"image_id": 316672, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.09897433185907906, "Bleu_3": 5.887550428177757e-07, "Bleu_4": 1.4435323317269659e-09, "METEOR": 0.18827314483264454, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.0830732627084182e-09, "SPICE": {"All": {"pr": 0.4375, "re": 0.2, "f": 0.27450980392156865, "fn": 28.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.45454545454545453, "f": 0.5555555555555556, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a small, colorful train traveling along a track in a park-like setting. The train is surrounded by lush greenery, including ten trees and grass, creating a serene and picturesque environment. The train appears to be a miniature or toy train, as it is not a typical train."}, "386012": {"image_id": 386012, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1295047816452144, "Bleu_3": 6.857872734978661e-07, "Bleu_4": 1.5858040477395045e-09, "METEOR": 0.13647957791516027, "ROUGE_L": 0.1821983273596177, "CIDEr": 4.424329734815085e-13, "SPICE": {"All": {"pr": 0.12195121951219512, "re": 0.25, "f": 0.16393442622950818, "fn": 15.0, "numImages": 1.0, "fp": 36.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.3333333333333333, "f": 0.125, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.1875, "re": 0.42857142857142855, "f": 0.26086956521739124, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image captures a lively scene at a beach, where a group of people are playing frisbee and enjoying a game of beach volleyball. The people are also flying kites in the sky. The kites flying in the air create a vibrant and colorful atmosphere.\n\nThe beach is surrounded by a clear blue sky."}, "283290": {"image_id": 283290, "Bleu_1": 0.14285714285594237, "Bleu_2": 0.06958890006333485, "Bleu_3": 3.4591125587001116e-07, "Bleu_4": 7.728745795635799e-10, "METEOR": 0.09840372713944764, "ROUGE_L": 0.1280359820089955, "CIDEr": 3.136161468597055e-73, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a thrilling scene of two men engaging in various water activities on a lake. One man is water skiing on a jet ski, being towed by a boat. The other man is jumping off a jet ski and being towed by a jet ski. The man is riding a jet ski. The jet ski is shooting water into the air.\n\nThere are several boats in the scene, including speed boats, white boat kind of boats, jet skis, a small boat with a police officer on it, and a red inflatable boat. There is also a large boat in the scene.\n\nPlease note that the refined passage is incomplete due to insufficient information in the original passage."}, "527038": {"image_id": 527038, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.20966962740242623, "Bleu_3": 0.1441827180568874, "Bleu_4": 0.10866139876796073, "METEOR": 0.28707933516167494, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.2282547012321986e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a snowy city street scene with two people standing on the street. One person is holding a snowboard and protecting themselves from a snowstorm. The other person is holding an umbrella and protecting themselves from the rain. The umbrella is shielding the person."}, "209544": {"image_id": 209544, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.29080336344446667, "Bleu_3": 0.20044867222824783, "Bleu_4": 2.1052633193896276e-05, "METEOR": 0.2717102381060461, "ROUGE_L": 0.43675417661097854, "CIDEr": 0.0005815143983614928, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.05, "f": 0.05128205128205128, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image features a man standing on a grassy field, holding a frisbee in his hand. He appears to be preparing to throw the frisbee, possibly enjoying a game of frisbee with his friends or family.\n\nIn the background, there are several cars parked."}, "442223": {"image_id": 442223, "Bleu_1": 0.16666666666481483, "Bleu_2": 0.1223980122710533, "Bleu_3": 0.07993355054037407, "Bleu_4": 0.04922287938391653, "METEOR": 0.21980612885580172, "ROUGE_L": 0.1819537658463833, "CIDEr": 2.3606644103339105e-38, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.041666666666666664, "f": 0.05405405405405406, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image features a man standing in front of a motorcycle. A motorcycle is located near the man. The man is looking at a motorcycle. The man is standing close to a cow statue. A cow statue is located near the man. A cow statue is located further away. \n\nThere are two motorcycles in the scene. \n\nThere is one man and one cow in the scene. \n\nThere are two cow statues in the scene. \n\nThere are two churches in the scene. \n\nThe cow is standing in front of the church."}, "301684": {"image_id": 301684, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.0956600132176177, "Bleu_4": 1.248740514185277e-05, "METEOR": 0.2434478124857385, "ROUGE_L": 0.2897862232779097, "CIDEr": 4.843282583063006e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man standing next to a baby elephant. The man is holding a stick. The elephant is sitting on its back. The elephant is playing with a broom. The elephant is spraying water from its trunk."}, "523529": {"image_id": 523529, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.08423190681730008, "Bleu_4": 1.0455985518811585e-05, "METEOR": 0.21483111909688798, "ROUGE_L": 0.2896142433234421, "CIDEr": 2.4070318983622034e-12, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.21739130434782608, "f": 0.17857142857142858, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a large brown bear standing near a rock wall, possibly in a zoo enclosure. The bear appears to be looking up, possibly observing something in the distance. The bear's fur is wet, indicating that it might have been in the water recently.\n\nThere are several rocks in the scene."}, "140289": {"image_id": 140289, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2383656473040621, "Bleu_3": 1.2237946382258258e-06, "Bleu_4": 2.7957677823832457e-09, "METEOR": 0.2568017840716703, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.00023248775296185175, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16, "f": 0.15094339622641512, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features two brown bears walking together in a wooded area. They are walking on a dirt path, surrounded by rocks and trees. The bears are exploring their environment in a zoo."}, "71933": {"image_id": 71933, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2559769394774182, "Bleu_3": 0.12974585030066288, "Bleu_4": 1.6566112562512974e-05, "METEOR": 0.2508594568207899, "ROUGE_L": 0.4080267558528428, "CIDEr": 0.013204388896746435, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.14705882352941177, "f": 0.20408163265306123, "fn": 29.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.2857142857142857, "f": 0.38095238095238093, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a delicious chili cheese dog in a bun, placed in a white container. The chili cheese dog is generously topped with chili and cheese, making it a mouth-watering meal."}, "115412": {"image_id": 115412, "Bleu_1": 0.38095238093424044, "Bleu_2": 0.19518001458018006, "Bleu_3": 1.260972737339982e-06, "Bleu_4": 3.2487115055976186e-09, "METEOR": 0.11359322966543024, "ROUGE_L": 0.3279569892473118, "CIDEr": 0.04722027428250673, "SPICE": {"All": {"pr": 0.25, "re": 0.3125, "f": 0.2777777777777778, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features an orange object made of plastic, sitting on a white surface. The object is a piece of art."}, "71549": {"image_id": 71549, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.23204774044025303, "Bleu_3": 0.14151431132866968, "Bleu_4": 1.6636035584894695e-05, "METEOR": 0.22823806376493366, "ROUGE_L": 0.28416149068322977, "CIDEr": 8.88527385484051e-05, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.14285714285714285, "f": 0.17647058823529413, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a brown teddy bear lying on the floor, positioned in front of a Christmas tree. The teddy bear is wearing a Santa hat. The floor is covered with a carpet. There are no presents in the scene."}, "297022": {"image_id": 297022, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.10033557298297395, "Bleu_4": 0.06607272734342155, "METEOR": 0.22324922290782612, "ROUGE_L": 0.26124197002141325, "CIDEr": 4.7086123299627016e-11, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1111111111111111, "f": 0.12, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of three men standing around a truck. One man is standing on the left side of the truck, another on the right side, and two more standing closer to the front of the truck. The men are standing around a large machine gun, a truck, and a tractor."}, "272694": {"image_id": 272694, "Bleu_1": 0.5416666666440973, "Bleu_2": 0.3431524780303644, "Bleu_3": 0.1749244562861414, "Bleu_4": 2.2468965418037152e-05, "METEOR": 0.2939305038800399, "ROUGE_L": 0.5165322580645161, "CIDEr": 0.23415703912277427, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.22727272727272727, "f": 0.25641025641025644, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a dining table with a cup of coffee and a muffin on it. A banana is also present on the table."}, "469067": {"image_id": 469067, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.23186944787247984, "Bleu_3": 0.12284656554035166, "Bleu_4": 1.6041048674046e-05, "METEOR": 0.26486279828713244, "ROUGE_L": 0.3266107442441549, "CIDEr": 0.0013200706905953001, "SPICE": {"All": {"pr": 0.2, "re": 0.1875, "f": 0.19354838709677422, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a woman lying on a bed. The woman is sleeping and holding a cat. The cat is resting on the bed. The bed is covered with a sheet."}, "269311": {"image_id": 269311, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.27327631272580527, "Bleu_3": 0.16068567361899208, "Bleu_4": 0.10434360980499202, "METEOR": 0.27937516195940576, "ROUGE_L": 0.38231197771587744, "CIDEr": 0.00012288599925034337, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.19230769230769232, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features three men standing outside a house. They are all wearing blue shirts. One of the men is holding a baseball bat, adding a playful element to the scene.\n\nIn the background, there is a house."}, "410724": {"image_id": 410724, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2530600894303559, "Bleu_3": 0.1333606949819784, "Bleu_4": 1.7379110739620047e-05, "METEOR": 0.20682226211849192, "ROUGE_L": 0.31633535004321517, "CIDEr": 0.004321830059173023, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.15625, "f": 0.15873015873015875, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two cat statues sitting on a wooden table, which is positioned in front of a window. The cat statues are painted with yellow and black colors."}, "102056": {"image_id": 102056, "Bleu_1": 0.19318181817962293, "Bleu_2": 0.11542479808184485, "Bleu_3": 0.05370729324637142, "Bleu_4": 6.533865909961939e-06, "METEOR": 0.1598331772250908, "ROUGE_L": 0.19062500000000002, "CIDEr": 2.272973725701834e-37, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.17647058823529413, "f": 0.1935483870967742, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a blue bus parked on a street, with a group of seven people standing around it. Some of the people are getting on the bus, while others are boarding the bus. One person is wearing a red hoodie, another is wearing a red jacket, and another is wearing a black and white hat. Some of the people are carrying bags, skis, snowboards, or a cell phone. There are also two backpacks visible in the scene. The overall scene shows the bus parked on the snow."}, "449406": {"image_id": 449406, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.19026059765810296, "Bleu_3": 0.15354390128889117, "Bleu_4": 0.12201289225771661, "METEOR": 0.23856220064551026, "ROUGE_L": 0.29397590361445786, "CIDEr": 1.0265420043066722e-11, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.375, "f": 0.3913043478260869, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features two zebras standing in a rocky, grassy field. The zebras are positioned in the center of the field. They are surrounded by rocks and bushes in one case, and rocks and trees in the other. The zebras appear to be looking at the camera, possibly curious about their surroundings."}, "225786": {"image_id": 225786, "Bleu_1": 0.6086956521474481, "Bleu_2": 0.576208131014439, "Bleu_3": 0.5581840019742412, "Bleu_4": 0.5289153452547961, "METEOR": 0.502230251880694, "ROUGE_L": 0.7269116186693149, "CIDEr": 0.4319042000011307, "SPICE": {"All": {"pr": 0.25, "re": 0.4375, "f": 0.3181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 1.0, "f": 0.2222222222222222, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.8571428571428571, "f": 0.6, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features a man standing on a beach, flying a kite high in the sky. The kite is soaring above the man."}, "252280": {"image_id": 252280, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.11322770341159263, "Bleu_3": 0.06961571161674676, "Bleu_4": 9.771922616327614e-06, "METEOR": 0.19243323345171437, "ROUGE_L": 0.25558659217877094, "CIDEr": 8.300600324865235e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.08, "f": 0.09756097560975609, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a white bus driving down the road. The bus is surrounded by tall buildings. There are several bicycles parked along the sidewalk. Some of the bicycles are located closer to the foreground, while others are further away."}, "126046": {"image_id": 126046, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 0.07178791139239354, "Bleu_4": 9.274617069102212e-06, "METEOR": 0.23348205226607122, "ROUGE_L": 0.24469914040114613, "CIDEr": 4.461747112238645e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a street scene with a traffic light positioned in the middle of the road. There is also a road sign placed on the side of the road. Multiple cones of orange and white or red and white colors are scattered throughout the scene, indicating a construction or road work area."}, "8188": {"image_id": 8188, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.12262786789482262, "Bleu_3": 0.06490406357826438, "Bleu_4": 8.435396018679067e-06, "METEOR": 0.15813637278264192, "ROUGE_L": 0.17805020431990656, "CIDEr": 2.1087027403689724e-14, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.28, "f": 0.32558139534883723, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5, "f": 0.588235294117647, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a man walking on the beach. The man is carrying a towel. \n\nThere are three people scattered around the beach. Some of the people are playing beach volleyball, while others are walking on the beach or doing surfing.\n\nThere is an umbrella set up on the beach.\n\nThere is no surfboard in the image."}, "53145": {"image_id": 53145, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.2571514254230454, "Bleu_3": 0.15289808564244914, "Bleu_4": 1.7751126164185924e-05, "METEOR": 0.2139269477202176, "ROUGE_L": 0.3559445660102115, "CIDEr": 6.159212377416242e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15, "f": 0.14634146341463414, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a group of three people riding surfboards on a lake. One person is riding a surfboard, while the others are standing on surfboards nearby. They are skillfully riding the waves, enjoying their time on the lake."}, "574825": {"image_id": 574825, "Bleu_1": 0.2207792207763535, "Bleu_2": 0.10779591359637081, "Bleu_3": 5.370908791624418e-07, "Bleu_4": 1.2028955078190365e-09, "METEOR": 0.16574046296138048, "ROUGE_L": 0.16538635336647084, "CIDEr": 1.776232000932819e-24, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two women standing next to each other. They are dressed in costumes, possibly for a parade. One of the women is holding a pair of scissors, while the other is holding a piece of paper. The women are smiling and appear to be enjoying themselves.\n\nIn the background, there is an event taking place, possibly a costume contest. There are no other performances happening at the moment.\n\nThere is no knife in the scene."}, "16064": {"image_id": 16064, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.26261286571054043, "Bleu_3": 0.19477433953587744, "Bleu_4": 0.12861981015776489, "METEOR": 0.31780920889255115, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.002343878141415327, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.3125, "f": 0.2564102564102564, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a man in a green shirt playing with a frisbee in a park. The man is catching the frisbee. The frisbee is positioned slightly above the ground."}, "503926": {"image_id": 503926, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.10861276726025744, "Bleu_3": 5.950104277147966e-07, "Bleu_4": 1.3989518286920131e-09, "METEOR": 0.17795467350307864, "ROUGE_L": 0.23591160220994478, "CIDEr": 2.212908657778778e-15, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image depicts a cluttered office space with two wooden desks. Each desk is filled with items such as a laptop, a printer, and a computer monitor. The TV is positioned on the left side of the desk, while the laptop is placed on the right. A potted plant is positioned on the left side of the desk."}, "30828": {"image_id": 30828, "Bleu_1": 0.27941176470177337, "Bleu_2": 0.17085746668972407, "Bleu_3": 0.10988753082953231, "Bleu_4": 0.06721759536651178, "METEOR": 0.23352070048982176, "ROUGE_L": 0.24049563503238522, "CIDEr": 3.6626671315572083e-14, "SPICE": {"All": {"pr": 0.5833333333333334, "re": 0.3181818181818182, "f": 0.4117647058823529, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.5555555555555556, "f": 0.6666666666666667, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image features two people sleeping on a wooden bench in a park. Both people are lying down and possibly homeless. Each person has a backpack placed next to them on the bench.\n\nThe bench is located near four parking meters. The parking meters are positioned behind the bench.\n\nThe overall scene depicts the people sleeping on the bench in a park, with the parking meters situated nearby."}, "381792": {"image_id": 381792, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.2506031371798624, "Bleu_3": 0.1925292762405306, "Bleu_4": 2.0183917843818547e-05, "METEOR": 0.21305565549128375, "ROUGE_L": 0.24830393487109906, "CIDEr": 4.367337467946802e-09, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.5, "f": 0.41025641025641024, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a bathroom with a white toilet situated next to a bathtub. The toilet is positioned in the corner of the bathroom. The bathtub is located in the bathroom. The bathtub is not filled with water. There is a towel placed in the bathroom."}, "254571": {"image_id": 254571, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.21223817998318864, "Bleu_3": 0.10877430749251785, "Bleu_4": 1.3948420003604408e-05, "METEOR": 0.21738260068081877, "ROUGE_L": 0.2880528883991815, "CIDEr": 5.048095514827922e-05, "SPICE": {"All": {"pr": 0.1875, "re": 0.2, "f": 0.19354838709677422, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "There is no man in this image. There is a bicycle on a road. The road is made of gravel and appears to be a dirt road. There is no forest, cyclist, or tree in the image."}, "14781": {"image_id": 14781, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.16001422411453176, "Bleu_3": 0.0892630166489473, "Bleu_4": 1.193951426417031e-05, "METEOR": 0.20454879344569776, "ROUGE_L": 0.28249459709786967, "CIDEr": 4.333402760216132e-05, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.23809523809523808, "f": 0.2941176470588235, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet situated in the middle of the room. The toilet seat is not up. There is a large, colorful comic book lying on the floor in front of the toilet."}, "320972": {"image_id": 320972, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.269724531227751, "Bleu_3": 0.17754121209966744, "Bleu_4": 2.175150859631799e-05, "METEOR": 0.25708323484976225, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.0031797929424529294, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21875, "f": 0.2641509433962264, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a white table with a variety of fruits on it. There are four fruits on the table. The fruits include bananas, oranges, and a paper."}, "145025": {"image_id": 145025, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.2232350488629506, "Bleu_3": 0.10672028316489315, "Bleu_4": 1.3202927206769878e-05, "METEOR": 0.28434942787718104, "ROUGE_L": 0.21801286633309508, "CIDEr": 8.156605218666072e-07, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.12903225806451613, "f": 0.17391304347826086, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man wearing a wetsuit, sitting on the beach near the ocean. The man is sitting on the ground. He is looking out at the water, possibly enjoying the view or contemplating his next move. A bicycle is parked nearby."}, "564816": {"image_id": 564816, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.18233123936852927, "Bleu_3": 0.14245404181967788, "Bleu_4": 0.10646588104484676, "METEOR": 0.22843023483264155, "ROUGE_L": 0.2459677419354839, "CIDEr": 2.2958808646457406e-09, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.2631578947368421, "f": 0.3225806451612903, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.7142857142857143, "f": 0.7692307692307692, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image depicts a small, clean bathroom with green tiles on the walls and floor. The bathroom features a toilet, sink, and two bathtubs. The sink is situated in the corner. The toilet is located in the bathroom. The bathtubs are positioned in the middle of the room."}, "430533": {"image_id": 430533, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.23611253443469188, "Bleu_3": 0.16110157381285278, "Bleu_4": 0.10175568578207565, "METEOR": 0.25571060627636444, "ROUGE_L": 0.35328185328185324, "CIDEr": 6.807497856836907e-06, "SPICE": {"All": {"pr": 0.1875, "re": 0.12, "f": 0.14634146341463414, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a hot dog with ketchup and mustard, placed in a bun. The hot dog is sitting on a paper plate. It is accompanied by a slice of watermelon and a piece of cake, creating a delightful and colorful meal."}, "364557": {"image_id": 364557, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.15508644003992356, "Bleu_3": 0.08115433313646976, "Bleu_4": 1.0498339569158865e-05, "METEOR": 0.23729396113367138, "ROUGE_L": 0.20346897931954633, "CIDEr": 4.643164051180621e-09, "SPICE": {"All": {"pr": 0.07547169811320754, "re": 0.17391304347826086, "f": 0.10526315789473685, "fn": 19.0, "numImages": 1.0, "fp": 49.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 22.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3076923076923077, "f": 0.29629629629629634, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image captures a beautiful beach scene with two people walking along the shoreline. Both individuals are carrying surfboards, likely preparing to go surfing in the ocean. The first person is on the left side of the image, while the second person is on the right side."}, "354424": {"image_id": 354424, "Bleu_1": 0.2162162162103726, "Bleu_2": 0.13423121103912666, "Bleu_3": 0.08014559500904617, "Bleu_4": 1.1092770141415386e-05, "METEOR": 0.21178767824301542, "ROUGE_L": 0.36941710825132484, "CIDEr": 1.954011175306139e-05, "SPICE": {"All": {"pr": 0.02702702702702703, "re": 0.058823529411764705, "f": 0.03703703703703704, "fn": 16.0, "numImages": 1.0, "fp": 36.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image features a black cat resting under the bed. The cat is partially hidden under the sheets. The bed occupies most of the scene, and the cat is positioned towards the left side of the bed."}, "508489": {"image_id": 508489, "Bleu_1": 0.305555555547068, "Bleu_2": 2.9546842013431482e-09, "Bleu_3": 6.355958813447927e-12, "Bleu_4": 2.9700059595738456e-13, "METEOR": 0.19917012448132781, "ROUGE_L": 0.25673400673400676, "CIDEr": 3.6856714608381354e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image showcases a vibrant display of fresh vegetables at a market. The vegetables are arranged in baskets. Carrots are placed in the foreground, and there is also a basket of carrots placed in the background."}, "203063": {"image_id": 203063, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.2361125344346919, "Bleu_3": 0.1407351877211811, "Bleu_4": 1.635068194930436e-05, "METEOR": 0.23811586829034823, "ROUGE_L": 0.3292847503373819, "CIDEr": 1.0556798914859016e-06, "SPICE": {"All": {"pr": 0.24, "re": 0.1875, "f": 0.21052631578947367, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a snow-covered field with a group of five sheep scattered throughout. The sheep are eating grass in the field. A fence is on the left side of the field. A fence is on the right side of the field."}, "125129": {"image_id": 125129, "Bleu_1": 0.14285714285557302, "Bleu_2": 0.0796819072880791, "Bleu_3": 0.04147405300779158, "Bleu_4": 5.33594925484446e-06, "METEOR": 0.18798265601203906, "ROUGE_L": 0.14082339361292806, "CIDEr": 2.4085313908168243e-40, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features two men sitting at a dining table. One of the men is wearing a white robe and the other is wearing a white shirt and a black tie. The man in the white robe is holding a piece of paper and is not waiting for his turn to use the phone. The man in the white shirt and black tie is also holding a piece of paper and is not waiting for his turn to use the phone. There is no cell phone or conversation in the scene."}, "197859": {"image_id": 197859, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.1584236068731305, "Bleu_3": 8.001066951039577e-07, "Bleu_4": 1.8073847727775389e-09, "METEOR": 0.20832801622406724, "ROUGE_L": 0.26704190118824267, "CIDEr": 3.2288648123316603e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a small, cozy bedroom with two twin beds placed side by side. The beds are covered with floral bedspreads, adding a sense of comfort to the room. A nightstand is situated between the beds, providing a convenient place for personal items.\n\nThere is no lamp in the scene."}, "427094": {"image_id": 427094, "Bleu_1": 0.17021276595563603, "Bleu_2": 0.09566202995970274, "Bleu_3": 4.633371459225643e-07, "Bleu_4": 1.022498056706465e-09, "METEOR": 0.15613308666715442, "ROUGE_L": 0.15549890750182083, "CIDEr": 1.9174581287154476e-41, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features 6 street signs attached to a pole. One street sign indicates the name of the street as Fell. Another street sign indicates a one-way street. The third street sign indicates Stanley Road. The fourth street sign indicates \"Tow Away\". The fifth street sign indicates a stop sign. The sixth street sign also indicates a stop sign.\n\nThere is a building painted in green and white colors. The building has many windows, some of which are open, allowing natural light to enter the space.\n\nThere are no other streets in the scene."}, "118743": {"image_id": 118743, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.22631728213415836, "Bleu_3": 0.1379749595894305, "Bleu_4": 1.6214527868787693e-05, "METEOR": 0.21952403715545898, "ROUGE_L": 0.33493479752916955, "CIDEr": 1.8830396596436692e-06, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.25925925925925924, "f": 0.2857142857142857, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a woman standing in a room. The woman is holding an umbrella over her head. She is wearing a black and white shirt, which has a plaid pattern. The umbrella is open. The woman appears to be smiling."}, "472109": {"image_id": 472109, "Bleu_1": 0.1028571428565551, "Bleu_2": 0.04862645390810781, "Bleu_3": 2.3909272699934503e-07, "Bleu_4": 5.309365975359741e-10, "METEOR": 0.11204927388311568, "ROUGE_L": 0.10195493209968662, "CIDEr": 1.704256764534746e-162, "SPICE": {"All": {"pr": 0.15625, "re": 0.19230769230769232, "f": 0.1724137931034483, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features three desks, each with different items on them. On the first desk, there is a computer, a laptop, a printer, a telephone, and a water bottle. On the second desk, there is a computer, a laptop, a mouse, a keyboard, and a mouse pad. On the third desk, there is a computer, a keyboard, a mouse, a monitor, and a printer.\n\nThere are three computers in the image. The first computer has a monitor, the second computer has a picture of a cat, and the third computer has a picture of a fruit.\n\nThere are two keyboards in the image. The first keyboard has a mouse on it, and the second keyboard has a mouse and a mouse pad.\n\nThere are two mice in the image. The first mouse has a spooky mouse pad on it.\n\nThere is one monitor in the image.\n\nThere is one telephone in the image.\n\nThere are no books in the image.\n\nOverall, the image shows a clean and organized computer desk with various items on it."}, "173545": {"image_id": 173545, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.24445060351331568, "Bleu_3": 0.16626964075217796, "Bleu_4": 0.10487303092067435, "METEOR": 0.20668823887079887, "ROUGE_L": 0.23229246001523232, "CIDEr": 3.642660519758486e-06, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features two people riding on the backs of two elephants. The elephants are carrying people. Each rider is holding a red umbrella to provide shade. The elephants are walking through a grassy area, with a tree in the background."}, "6527": {"image_id": 6527, "Bleu_1": 0.22499999999437506, "Bleu_2": 0.15191090505870358, "Bleu_3": 0.08468336402372789, "Bleu_4": 1.131874160173397e-05, "METEOR": 0.21456566498064839, "ROUGE_L": 0.2621776504297994, "CIDEr": 1.9527374907179267e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a clock mounted on a green pole. The clock is prominently displayed, with its face facing east. The clock's hands are positioned at around 10:30, indicating the time. \n\nIn the background, there is a street lamp."}, "219164": {"image_id": 219164, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.12539246564153583, "Bleu_3": 0.08456484271613045, "Bleu_4": 1.043517748432418e-05, "METEOR": 0.2244636807210928, "ROUGE_L": 0.21585279547062985, "CIDEr": 1.9869379564317033e-12, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.25, "f": 0.27027027027027023, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5555555555555556, "f": 0.6250000000000001, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features two women playing tennis on a court. They are both holding a tennis racket and preparing to hit a tennis ball. One of the women is wearing a blue and white dress, and the other is wearing a pink hat. The tennis ball is in the air, close to their rackets."}, "270222": {"image_id": 270222, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.14227759830242195, "Bleu_3": 0.08178816083045058, "Bleu_4": 1.1103047724285478e-05, "METEOR": 0.13314318409921191, "ROUGE_L": 0.18277153558052436, "CIDEr": 5.780455855228741e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features 5 clocks mounted on a wall. A clock is positioned in the center of the scene. The image also includes 1 statue and 1 statues. The statues of the four kings is arranged around the clock."}, "548843": {"image_id": 548843, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.21733262130578967, "Bleu_3": 1.0847992362433127e-06, "Bleu_4": 2.4402616953280328e-09, "METEOR": 0.19937240584398225, "ROUGE_L": 0.25363825363825365, "CIDEr": 9.469965728009809e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a boy wearing a blue jacket, standing in a room. The boy is holding a donut and appears to be enjoying it. His mouth is covered in frosting.\n\nThere is no other person in the scene."}, "146126": {"image_id": 146126, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.23940600197905648, "Bleu_3": 0.15094095943292793, "Bleu_4": 1.6276323370626888e-05, "METEOR": 0.2431149756665992, "ROUGE_L": 0.3298287774106338, "CIDEr": 4.372783917489005e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.19230769230769232, "f": 0.20833333333333331, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a dining table with a variety of food items and drinks. There is a bowl of noodles, possibly instant ramen, placed on the table. A glass of black liquid is also present. The table is set with a remote control, a packet of noodles, and a can of soda."}, "398066": {"image_id": 398066, "Bleu_1": 0.14432989690572856, "Bleu_2": 0.07754834430432873, "Bleu_3": 0.03985417451104967, "Bleu_4": 5.094169604457348e-06, "METEOR": 0.14010102967443783, "ROUGE_L": 0.13313932339032375, "CIDEr": 3.1639051629229976e-46, "SPICE": {"All": {"pr": 0.05, "re": 0.038461538461538464, "f": 0.043478260869565216, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image captures a baseball game in progress, with two men in the scene. The first man is wearing a white shirt and blue shorts, and he is swinging a baseball bat at a baseball. The second man is wearing a red shirt and red shorts, and he is also swinging a baseball bat at a baseball. \n\nThere is another person in the scene who is throwing a baseball and waiting for a ball. It seems like this person is observing the baseball game. \n\nThere is no information about the ball, batter, turn, or the game itself."}, "429323": {"image_id": 429323, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1642880193591135, "Bleu_3": 0.11341748684039174, "Bleu_4": 1.4188431559098948e-05, "METEOR": 0.2307726311665922, "ROUGE_L": 0.31145149525893506, "CIDEr": 0.00015299241408361415, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15, "f": 0.15789473684210525, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a small, white bathroom with a toilet and a sink. The toilet is positioned in the corner. A fan is above the toilet. The sink is located in the bathroom. The bathroom also features two windows."}, "69293": {"image_id": 69293, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.12641490045451217, "Bleu_4": 0.10340940672857568, "METEOR": 0.2383835003554196, "ROUGE_L": 0.2717149220489977, "CIDEr": 9.528670418031115e-13, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.3333333333333333, "f": 0.3846153846153846, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet sitting on a tiled floor. The toilet is positioned in the corner. There are two sinks in the bathroom. The first sink is made of a shell and has a mirror above it. The second sink is made of wood and also has a mirror above it."}, "527573": {"image_id": 527573, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1565560727682472, "Bleu_3": 0.11371830097406736, "Bleu_4": 0.07401568312656936, "METEOR": 0.2686102936207043, "ROUGE_L": 0.25176886792452824, "CIDEr": 3.6320095820497614e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.16666666666666666, "f": 0.20689655172413793, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a yellow fire hydrant situated on a city street, with a man standing nearby. The man appears to be looking at the fire hydrant, possibly admiring its color or considering its purpose.\n\nIn the background, there are four people walking around. Some of them are carrying bags, including backpacks."}, "10966": {"image_id": 10966, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.22019275302032337, "Bleu_3": 0.15011345265055326, "Bleu_4": 0.09473323931830074, "METEOR": 0.18646258476334573, "ROUGE_L": 0.3134232498394348, "CIDEr": 1.7313613970644216e-06, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.11538461538461539, "f": 0.11111111111111112, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a group of four people gathered in a living room. Two men and two women are sitting on a couch, with one woman sitting on the floor next to them. They are all holding wine glasses, suggesting a casual and relaxed atmosphere."}, "487698": {"image_id": 487698, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.25503068521918915, "Bleu_3": 0.18666445436887247, "Bleu_4": 0.11363969700972805, "METEOR": 0.31534158634830706, "ROUGE_L": 0.3551673944687045, "CIDEr": 1.9857772665944117e-06, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.2903225806451613, "f": 0.33333333333333337, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a woman walking on the sidewalk. The woman is talking on the phone. She is wearing a black jacket. The woman is carrying a handbag. She is walking past a red fire hydrant, which is located on the sidewalk."}, "301746": {"image_id": 301746, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.2162249910430379, "Bleu_3": 0.13746108160935094, "Bleu_4": 1.4878729567894347e-05, "METEOR": 0.2488443574927657, "ROUGE_L": 0.21229698375870068, "CIDEr": 2.5660315936939505e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21428571428571427, "f": 0.1875, "fn": 22.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image depicts three people riding bicycles on a street at night. A man on a bike is on the street. There is a tree located on the left side of the street. There is a tree located in the middle of the street. There is a tree located on the right side of the street."}, "39053": {"image_id": 39053, "Bleu_1": 0.09160305343441527, "Bleu_2": 0.045977348963386476, "Bleu_3": 2.539994137083574e-07, "Bleu_4": 5.981664397674096e-10, "METEOR": 0.12953661614369943, "ROUGE_L": 0.13164283787429187, "CIDEr": 8.602405076669047e-85, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.06451612903225806, "f": 0.08163265306122448, "fn": 29.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two tables with a variety of food items and utensils. On the first table, there is a bowl containing eggs and bread, and another bowl containing a plate of eggs. There is also a plate with cucumbers, tomatoes, and a slice of bread. On the second table, there is a bowl containing a bowl of soup, a plate of food, and a cup of coffee. There is also a plate with a bowl of whipped cream.\n\nThere are two tables in the image. On the first table, there is a bowl of soup, a plate of food, and a bowl of yogurt. On the second table, there is a bowl of soup, a plate of food, and a cup of coffee.\n\nThere are four pizzas in the image."}, "5033": {"image_id": 5033, "Bleu_1": 0.4374999999726563, "Bleu_2": 0.2415229457542257, "Bleu_3": 1.609148974235122e-06, "Bleu_4": 4.231178541317022e-09, "METEOR": 0.20217870402862034, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.09259133202373303, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.14814814814814814, "f": 0.2, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a lighthouse model made of wood, which is placed in a garden setting."}, "379048": {"image_id": 379048, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2014440620697061, "Bleu_3": 9.733867301596096e-07, "Bleu_4": 2.1520232157119847e-09, "METEOR": 0.16911113682433943, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.2664845262631312e-08, "SPICE": {"All": {"pr": 0.10256410256410256, "re": 0.19047619047619047, "f": 0.13333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 35.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.05555555555555555, "re": 0.2, "f": 0.08695652173913045, "fn": 4.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a baseball uniform and a bat on display in a glass case. The baseball uniform is gray. The bat is placed in the case. The display case is designed to protect and showcase the items, making them easily visible and accessible to visitors."}, "374342": {"image_id": 374342, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 9.166878867586852e-07, "Bleu_4": 2.1980503399202124e-09, "METEOR": 0.1956399524314782, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.00031775187997310265, "SPICE": {"All": {"pr": 0.5, "re": 0.1891891891891892, "f": 0.2745098039215686, "fn": 30.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}, "Relation": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image captures a tennis match in progress, with two men playing tennis. One man is in a white shirt and green shorts, and he is playing tennis. The other man is sitting in a chair."}, "441841": {"image_id": 441841, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.1996674976872179, "Bleu_3": 0.1428841479853578, "Bleu_4": 0.09241086581925062, "METEOR": 0.24398702394090233, "ROUGE_L": 0.2616154395997141, "CIDEr": 1.447239910515281e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.12903225806451613, "f": 0.1509433962264151, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07142857142857142, "f": 0.11111111111111112, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man riding a red and white motorcycle on a race track. The man is wearing a helmet and a red and white racing suit, which is typical attire for a professional racer.\n\nThe motorcycle is positioned on a curve."}, "201993": {"image_id": 201993, "Bleu_1": 0.2162162162103726, "Bleu_2": 0.13423121103912666, "Bleu_3": 8.014559500904618e-07, "Bleu_4": 1.9726044742773524e-09, "METEOR": 0.22293439815054258, "ROUGE_L": 0.2627422828427854, "CIDEr": 0.0001224411025004945, "SPICE": {"All": {"pr": 0.1875, "re": 0.15789473684210525, "f": 0.17142857142857143, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a bench situated on the sand, overlooking the ocean. You can watch the waves roll in while sitting on the bench. The beach is relatively empty, with no other notable elements in the scene."}, "478433": {"image_id": 478433, "Bleu_1": 0.5714285714013606, "Bleu_2": 0.507092552812359, "Bleu_3": 0.3782918212019942, "Bleu_4": 0.23418123260642584, "METEOR": 0.3458418429986062, "ROUGE_L": 0.5514124293785311, "CIDEr": 0.27010318152458285, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a man skillfully riding a wave on a surfboard in the ocean. The man is riding the wave."}, "351930": {"image_id": 351930, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.12725695259184966, "Bleu_3": 0.09566001321761768, "Bleu_4": 0.07022183955658268, "METEOR": 0.1984735960030748, "ROUGE_L": 0.22846441947565538, "CIDEr": 1.2053585975018099e-05, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a fighter jet parked on a runway. The fighter jet is gray. The jet is on the ground. A canopy is covering the jet. The tarp is covering the nose, wings, and tail of the jet."}, "519361": {"image_id": 519361, "Bleu_1": 0.3199999999936, "Bleu_2": 0.22857142856681054, "Bleu_3": 0.1483569743355745, "Bleu_4": 1.623515768756913e-05, "METEOR": 0.2348662886016018, "ROUGE_L": 0.3603651987110633, "CIDEr": 6.81107635914272e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a street scene with a horse pulling a carriage down the street. The horse is positioned in the middle of the street. The carriage is being pulled by two white horses. A car is following closely behind the horse. A fire truck is driving down the street."}, "113001": {"image_id": 113001, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.12626174790809142, "Bleu_3": 7.129027762233403e-07, "Bleu_4": 1.7037490064393743e-09, "METEOR": 0.13943998720053677, "ROUGE_L": 0.23135271807838179, "CIDEr": 1.2939995646457627e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a red and white bus positioned on the left side and a blue bus positioned on the right side. The bus is a double decker bus, while the other bus is a train bus. There is no train or tracks in the image."}, "545155": {"image_id": 545155, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.25440640194528097, "Bleu_3": 0.17537120059764763, "Bleu_4": 0.11141706023091318, "METEOR": 0.2774945374848135, "ROUGE_L": 0.24636510500807754, "CIDEr": 1.2055047346928223e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21739130434782608, "f": 0.26315789473684204, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a boy riding a horse. The boy is sitting on the horse and enjoying the ride. However, the boy is not smiling. The horse is positioned behind the child.\n\nIn the background, there are trees."}, "60677": {"image_id": 60677, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.22893427324353557, "Bleu_3": 0.1591571275450723, "Bleu_4": 0.11213327957896793, "METEOR": 0.23277717756942753, "ROUGE_L": 0.2606837606837607, "CIDEr": 3.810602976803022e-11, "SPICE": {"All": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a blue pickup truck parked in a parking lot, with a tree in the background. The truck is positioned in the middle of the scene, and it appears to be the main focus of the image. The parking lot is surrounded by trees, giving the area a natural and serene atmosphere."}, "526368": {"image_id": 526368, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.26261286571054043, "Bleu_3": 0.17015105805045752, "Bleu_4": 0.11622111816247423, "METEOR": 0.3170184304004672, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.0025972457859822764, "SPICE": {"All": {"pr": 0.04838709677419355, "re": 0.15, "f": 0.07317073170731707, "fn": 17.0, "numImages": 1.0, "fp": 59.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 23.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 24.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image features a computer sitting on a desk. The computer is open and its screen is displaying a spreadsheet. \n\nThere is no laptop, keyboard, or mouse in the image."}, "300737": {"image_id": 300737, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.19920476821515276, "Bleu_3": 1.1513535483002172e-06, "Bleu_4": 2.795255596253083e-09, "METEOR": 0.18346702703414658, "ROUGE_L": 0.28773584905660377, "CIDEr": 0.006248477596922783, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a green field with a sheep standing in the grass. Tall grass is surrounding the sheep. The sheep is the main focus of the image."}, "292324": {"image_id": 292324, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.13760021235336062, "Bleu_4": 0.10316499681152426, "METEOR": 0.30703958432214795, "ROUGE_L": 0.35442220787604906, "CIDEr": 5.278051651441558e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.3157894736842105, "f": 0.34285714285714286, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image showcases a cozy living room with a large couch and a chair placed in the center of the room. The couch is situated in the middle of the room. The chair is positioned in front of the window. A dining table is not present in the room."}, "40839": {"image_id": 40839, "Bleu_1": 0.14084507042154334, "Bleu_2": 0.09481619523007183, "Bleu_3": 0.04004475775384023, "Bleu_4": 4.6361294414521495e-06, "METEOR": 0.14140590537947706, "ROUGE_L": 0.13787041687594173, "CIDEr": 5.913008898865935e-103, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image depicts a busy scene with a large group of ten people walking down the street. Some of the people are playing a game of soccer, while others are riding a skateboard or riding a bike. One person is putting on a pair of shoes. There is also a woman riding a skateboard. In the street, some people are playing baseball. There is a blurry image of people walking in a crowd. \n\nIn front of the large building, there is a large statue of a Buddhist monk. \n\nThere are five umbrellas in the scene. The umbrellas come in various colors and designs, including blue and white umbrellas with white handles, purple umbrellas, and the Sassy Sailor umbrella. \n\nThere is no courtyard in the scene. There is one building and no other people. There is no sun or rain in the scene."}, "6437": {"image_id": 6437, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.19778287446532944, "Bleu_3": 0.12952938033879158, "Bleu_4": 1.5785531341013118e-05, "METEOR": 0.28517591762526895, "ROUGE_L": 0.3351648351648352, "CIDEr": 6.636143348843942e-05, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a polar bear lying down in a zoo enclosure. The polar bear is white. It is resting its head on a rock. The polar bear is enjoying the water. Its mouth is open, possibly drinking."}, "320823": {"image_id": 320823, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.15041420939612582, "Bleu_3": 7.677195064444563e-07, "Bleu_4": 1.7432228564084153e-09, "METEOR": 0.17632379589891126, "ROUGE_L": 0.2167219327333018, "CIDEr": 2.60847847086838e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image depicts a joyful wedding celebration with two brides and a groom sitting together at a table. The brides are wearing red dresses. The groom is wearing a suit. A cake is on the table. They are surrounded by a group of people, some of whom are standing and others sitting."}, "300753": {"image_id": 300753, "Bleu_1": 0.26865671641390065, "Bleu_2": 0.1562796783188368, "Bleu_3": 0.0721601155871601, "Bleu_4": 8.753423117851344e-06, "METEOR": 0.2490607223540975, "ROUGE_L": 0.2398034398034398, "CIDEr": 1.7414807801479297e-19, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image captures a baseball game in progress. The batter is standing at home plate, holding a baseball bat and preparing to swing. The pitcher is in the process of throwing a ball. The catcher is squatting down, ready to catch the ball.\n\nThere is no ball in the scene.\n\nThere are no other players in the scene.\n\nThe batter is standing on the pitcher's mound."}, "35770": {"image_id": 35770, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.23371317621462567, "Bleu_3": 0.11829075901056599, "Bleu_4": 1.5080843018301503e-05, "METEOR": 0.20711641616969462, "ROUGE_L": 0.305254378648874, "CIDEr": 8.13323082337445e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet and two white sinks. The sinks are placed on a glass countertop. A toilet is positioned next to each sink. The bathroom has a checkered floor."}, "447558": {"image_id": 447558, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.14458880781007946, "Bleu_3": 0.08055078690642642, "Bleu_4": 1.075935380376544e-05, "METEOR": 0.22631284663748583, "ROUGE_L": 0.35742187499999994, "CIDEr": 3.4250233457301997e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.17391304347826086, "f": 0.2162162162162162, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress. There is a batter swinging a baseball bat at a ball. The batter is wearing a white uniform. The catcher is positioned behind home plate. The catcher is wearing a black and yellow uniform."}, "160185": {"image_id": 160185, "Bleu_1": 0.3220338982996266, "Bleu_2": 0.1825208249698178, "Bleu_3": 0.10534000356037619, "Bleu_4": 0.06759241907827901, "METEOR": 0.2561430547642949, "ROUGE_L": 0.29918256130790194, "CIDEr": 4.554156747910313e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image captures a soccer game in progress, with two men on the field. One man is kicking a soccer ball, while the other man is talking to the referee. The man playing soccer is wearing a green shirt with the number ten on it. He is also wearing green shorts. The soccer ball is located on the field."}, "134537": {"image_id": 134537, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.09087495946522164, "Bleu_3": 6.179312211857994e-07, "Bleu_4": 1.6230629895740087e-09, "METEOR": 0.19501521530673332, "ROUGE_L": 0.24419535628502803, "CIDEr": 2.3606945314012568e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image captures a city street during the night. People are walking down the street. There is a traffic light in the scene.\n\nThere are no lights or vehicles in the scene. There is no festive atmosphere."}, "277329": {"image_id": 277329, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.16265001215217242, "Bleu_3": 1.0057999677998904e-06, "Bleu_4": 2.5257985573759175e-09, "METEOR": 0.14634878388834155, "ROUGE_L": 0.2978515625, "CIDEr": 0.015577791164812282, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.23809523809523808, "f": 0.2941176470588235, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a picturesque landscape with two fields, a mountain in the background, and several houses scattered throughout the area. The cows are not in the image."}, "380634": {"image_id": 380634, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.2836543144559696, "Bleu_3": 0.24310669551482578, "Bleu_4": 0.21479380273480794, "METEOR": 0.3458140270652315, "ROUGE_L": 0.42582897033158806, "CIDEr": 0.00518984422538111, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.125, "f": 0.1509433962264151, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.26666666666666666, "f": 0.36363636363636365, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a boy sitting on the back of a brown horse, enjoying the ride. The horse is positioned on the ground. The boy is sitting on the horse."}, "388215": {"image_id": 388215, "Bleu_1": 0.42857142856122454, "Bleu_2": 0.3541688016520378, "Bleu_3": 0.27999668155330865, "Bleu_4": 0.1831707022022871, "METEOR": 0.27944111855053777, "ROUGE_L": 0.40815085158150854, "CIDEr": 0.00019374499188455987, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.07692307692307693, "f": 0.08888888888888889, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures a man playing tennis on a tennis court. The man is holding a tennis racket and preparing to hit a tennis ball. The man is in the middle of a swing, showcasing his skill and focus on the game."}, "102947": {"image_id": 102947, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.152498570329016, "Bleu_3": 0.08277818425483373, "Bleu_4": 1.0912441388233997e-05, "METEOR": 0.2564768213585141, "ROUGE_L": 0.3132795304475422, "CIDEr": 3.3518307593200824e-07, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a cozy living room with a television placed in the corner. The room features seven chairs in brown and red colors. A dining table is situated in the middle of the room. A cup is placed on the dining table."}, "458401": {"image_id": 458401, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.33476703169424327, "Bleu_3": 0.25510983198722365, "Bleu_4": 0.189042546777147, "METEOR": 0.34986698983514863, "ROUGE_L": 0.5113160100586757, "CIDEr": 0.021110528830103115, "SPICE": {"All": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 33.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.23076923076923078, "f": 0.20000000000000004, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image is a black and white photograph featuring two dogs. One dog is standing on the back of a donkey. The other dog is standing on a rock."}, "554625": {"image_id": 554625, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.17393131069069204, "Bleu_3": 0.09714352679613725, "Bleu_4": 1.3009868452696128e-05, "METEOR": 0.2185886662667036, "ROUGE_L": 0.23828124999999997, "CIDEr": 0.0002653346569131552, "SPICE": {"All": {"pr": 0.24, "re": 0.2727272727272727, "f": 0.2553191489361702, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "There are no people in this image. However, there is a boy wearing a white shirt. The boy is focused on a computer. There are three keyboards and one pair of headphones in the image."}, "138246": {"image_id": 138246, "Bleu_1": 0.5789473683905818, "Bleu_2": 0.4392976850832163, "Bleu_3": 0.283160693887166, "Bleu_4": 3.451395513737833e-05, "METEOR": 0.25040764694539047, "ROUGE_L": 0.40352811466372657, "CIDEr": 0.4687458895860322, "SPICE": {"All": {"pr": 0.47368421052631576, "re": 0.391304347826087, "f": 0.42857142857142855, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6, "f": 0.631578947368421, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features three horses grazing in a lush green field. The horses are peacefully grazing and eating grass."}, "339974": {"image_id": 339974, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.23570226038887507, "Bleu_3": 0.11778306710176518, "Bleu_4": 1.4917074526131141e-05, "METEOR": 0.23082023936649285, "ROUGE_L": 0.19365079365079363, "CIDEr": 4.725566035168966e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.3125, "f": 0.2777777777777778, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a busy street at night with two cars driving down the road. A traffic light is present on the left side of the image, and another one is located on the right side."}, "176649": {"image_id": 176649, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.11303027047441294, "Bleu_3": 6.83559800121601e-07, "Bleu_4": 1.6916722834125866e-09, "METEOR": 0.17232756290225154, "ROUGE_L": 0.2279521674140508, "CIDEr": 1.930333832791801e-07, "SPICE": {"All": {"pr": 0.35, "re": 0.4375, "f": 0.38888888888888884, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a sign with a black triangle shape. The sign is square and is written in both Chinese and English. The sign is placed on a pole. The surrounding area is filled with trees, creating a natural and serene atmosphere."}, "23899": {"image_id": 23899, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.15585730003579046, "Bleu_3": 0.0869128899641639, "Bleu_4": 1.1620839902584731e-05, "METEOR": 0.1920048322755515, "ROUGE_L": 0.22846441947565538, "CIDEr": 5.665058119334829e-06, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.1724137931034483, "f": 0.23255813953488377, "fn": 24.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features two men playing a video game together. The men are positioned in different ways, with one man sitting on a couch and the other lying down. They are fully engaged in the game, using Wii remotes."}, "335532": {"image_id": 335532, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.18563715382699006, "Bleu_3": 0.16368983753609684, "Bleu_4": 0.14195815601044184, "METEOR": 0.3048450857550152, "ROUGE_L": 0.307563025210084, "CIDEr": 2.7086685415470416e-14, "SPICE": {"All": {"pr": 0.4375, "re": 0.23333333333333334, "f": 0.3043478260869565, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.4166666666666667, "f": 0.5263157894736842, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a girl eating a sandwich. The girl is focused on the sandwich. The girl's expression shows that she is enjoying the sandwich. The girl is taking a bite out of the sandwich. \n\nThere are three eyes in the image. \n\nThere is no camera in the scene.\n\nThere is one mouth in the image."}, "503772": {"image_id": 503772, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.15569978882944752, "Bleu_3": 0.11112381532950555, "Bleu_4": 0.0716728249212735, "METEOR": 0.19228382816536554, "ROUGE_L": 0.2513243084167157, "CIDEr": 2.1069274054748004e-13, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a kitchen with a large stainless steel refrigerator standing in the corner. The refrigerator is open, revealing a TV. The kitchen counter is cluttered with various items, including three cups, and a bottle. There is no bowl or spoon in the scene.\n\nA coffee maker is also seen on the kitchen counter."}, "446861": {"image_id": 446861, "Bleu_1": 0.13333333333222222, "Bleu_2": 0.06694619269989763, "Bleu_3": 0.04235128431410241, "Bleu_4": 5.047815504927728e-06, "METEOR": 0.12052512800895628, "ROUGE_L": 0.10892857142857144, "CIDEr": 1.0668771168131724e-73, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image depicts a busy street with multiple cars driving under a cloudy sky. The cars include a new era of flying cars, a Saturn SLR, a spooky sighting in a San Diego neighborhood, and a 2020 Nissan Titan XD. \n\nThere are five cars in total. \n\nThere are several traffic lights hanging above the street. The traffic lights display various color lights, including green, red, yellow, orange, amber, and white. Some of the traffic lights also have arrows pointing to the left and right.\n\nThere is one driver in the image. \n\nOverall, the image depicts a busy street scene with cars driving under the sky. The traffic lights are positioned above the road, ensuring that drivers can see them clearly."}, "90476": {"image_id": 90476, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.2626128657105405, "Bleu_3": 0.19477433953587747, "Bleu_4": 0.15295559336991324, "METEOR": 0.24631216457873134, "ROUGE_L": 0.37854609929078015, "CIDEr": 0.004456184312899032, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a beach with a group of boats on it. The boats are of various sizes and colors. They are tightly packed together, creating a visually dense scene."}, "508481": {"image_id": 508481, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.23782574707262866, "Bleu_3": 0.16540015368980918, "Bleu_4": 0.09802862511748141, "METEOR": 0.29175145971943, "ROUGE_L": 0.39563679245283023, "CIDEr": 6.885453843846726e-11, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.11538461538461539, "f": 0.12499999999999997, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a kitchen with a white countertop and a stove top oven. The stove is equipped with three burners, and a kettle is placed on one of the burners. The kitchen also has a sink located towards the left side of the countertop.\n\nUnder the stove is the sink located."}, "339470": {"image_id": 339470, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.3356243110283886, "Bleu_3": 0.252466016516249, "Bleu_4": 0.18580985893921348, "METEOR": 0.28075351261775433, "ROUGE_L": 0.4790575916230366, "CIDEr": 0.006316763903971248, "SPICE": {"All": {"pr": 0.1875, "re": 0.16666666666666666, "f": 0.17647058823529413, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a brown dog standing on a bed. The dog is looking at a blanket and appears to be enjoying it. The bed is covered with a blanket."}, "102848": {"image_id": 102848, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.12632278815731815, "Bleu_3": 0.07026437559457349, "Bleu_4": 9.370187147561893e-06, "METEOR": 0.1732298632455991, "ROUGE_L": 0.20497311827956988, "CIDEr": 3.417357985947895e-10, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a group of eight men gathered on a sidewalk. The men are wearing helmets and riding skateboards. Some of the men are doing skateboarding and riding skateboards. \n\nThere are also nine skateboards in the scene. \n\nThere are no other people or objects in the scene."}, "511066": {"image_id": 511066, "Bleu_1": 0.3199999999936, "Bleu_2": 0.21380899352561972, "Bleu_3": 0.14189834119414174, "Bleu_4": 1.5702128401926803e-05, "METEOR": 0.27295409258418596, "ROUGE_L": 0.3359559402045633, "CIDEr": 7.16435377618443e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a woman standing next to a doorway. She is holding a surfboard in her hand. The woman is wearing a blue shirt and is looking at her feet. The surfboard is positioned on the floor next to her, and there is another surfboard located in the garage."}, "130171": {"image_id": 130171, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.2823298512746205, "Bleu_3": 0.15359024716828806, "Bleu_4": 2.0380644131029715e-05, "METEOR": 0.19556855843361454, "ROUGE_L": 0.34346846846846846, "CIDEr": 0.024815259205001466, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.2916666666666667, "f": 0.3333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a pot filled with a delicious-looking stew. The stew contains carrots, onions, and potatoes. The carrots are placed in the pot."}, "55772": {"image_id": 55772, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.18227065413983304, "Bleu_3": 0.11746087033063704, "Bleu_4": 1.4187468588449892e-05, "METEOR": 0.14864485481933445, "ROUGE_L": 0.24881033310673015, "CIDEr": 1.81155745026626e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a delicious breakfast meal consisting of a bacon sandwich and a pancake. The sandwich is placed on a plate, with the bacon visible on top. The pancake is positioned next to the sandwich, creating a visually appealing and appetizing meal."}, "22969": {"image_id": 22969, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.19050019049423664, "Bleu_3": 0.10655075333690472, "Bleu_4": 1.4291173573605971e-05, "METEOR": 0.18603466275340302, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.0008048798917554177, "SPICE": {"All": {"pr": 0.6153846153846154, "re": 0.36363636363636365, "f": 0.4571428571428572, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}, "Relation": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features two giraffes standing next to each other in a zoo enclosure. The giraffes are positioned closer to the fence. They are possibly observing their surroundings or waiting for something."}, "59532": {"image_id": 59532, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.10314212462370773, "Bleu_3": 6.138158588631339e-07, "Bleu_4": 1.505654929036229e-09, "METEOR": 0.17405514742584385, "ROUGE_L": 0.2293233082706767, "CIDEr": 1.4701179707094543e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a parking lot filled with numerous motor scooters and motorcycles parked in rows. The scooters are of various sizes and colors, creating a diverse and vibrant scene. Some of the scooters and motorcycles are parked closer to the foreground, while others are situated further away."}, "448151": {"image_id": 448151, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.14270041527824082, "Bleu_3": 0.09047027838968494, "Bleu_4": 0.06085286151132168, "METEOR": 0.23630892575381926, "ROUGE_L": 0.23682750970604544, "CIDEr": 1.9949211497454054e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.3076923076923077, "f": 0.163265306122449, "fn": 9.0, "numImages": 1.0, "fp": 32.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.75, "f": 0.31578947368421056, "fn": 1.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image features a young boy standing in front of a pink birthday cake with a race car theme. The cake is decorated with a race car and a driver. The boy is wearing a black sweater. The cake is a special occasion for the boy. A sense of maturity does the tie add to the boy."}, "327383": {"image_id": 327383, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.06726727939832501, "Bleu_3": 4.4896509096312353e-07, "Bleu_4": 1.1657633846364334e-09, "METEOR": 0.1722173935182459, "ROUGE_L": 0.16906873614190687, "CIDEr": 6.817404449672224e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16129032258064516, "f": 0.1923076923076923, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two buses parked on the street. The buses are silver in color. One bus is covered in mirrors and the other is covered in glitter.\n\nThere is a building next to the buses. It appears to be a restaurant, as there is a dining table visible in the background.\n\n"}, "164420": {"image_id": 164420, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 0.10349919939527817, "Bleu_4": 0.0812021816747775, "METEOR": 0.2551614988745808, "ROUGE_L": 0.22344322344322343, "CIDEr": 2.3567518082562846e-12, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a red fire hydrant sitting in a grassy area, surrounded by a few trees. The fire hydrant is positioned near a sidewalk, and it appears to be in a park-like setting. The hydrant is located close to a building, which could be a part of the park or a college campus."}, "398884": {"image_id": 398884, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.15075567228616532, "Bleu_3": 0.09441938915540041, "Bleu_4": 0.06312871110155649, "METEOR": 0.21125611522990537, "ROUGE_L": 0.20795454545454545, "CIDEr": 1.0916032434340007e-13, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.16666666666666666, "f": 0.1935483870967742, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features two green trucks parked on a grassy field. The trucks are old-fashioned models, possibly classic Fords. The trucks are the main focus of the scene. There are other vehicles surrounding the trucks.\n\nIn addition to the green trucks, there are no other vehicles in the scene. The grass surrounds the vintage green trucks."}, "20273": {"image_id": 20273, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.3100868364669995, "Bleu_3": 0.2679161449133076, "Bleu_4": 0.23671328958432472, "METEOR": 0.34356444966168054, "ROUGE_L": 0.3380541871921182, "CIDEr": 2.8263930211452844e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a bus parked on the side of a road. The bus is white. There is a person standing near the bus, possibly waiting to board or disembark. The bus has a large windshield, and the driver is visible through the windshield. The bus is parked next to a curb."}, "207611": {"image_id": 207611, "Bleu_1": 0.25974025973688647, "Bleu_2": 0.18486846665921722, "Bleu_3": 0.07695227639227041, "Bleu_4": 8.858458884093051e-06, "METEOR": 0.265268421619762, "ROUGE_L": 0.20704285108188372, "CIDEr": 1.5682613048651382e-24, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09523809523809523, "f": 0.12121212121212123, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image captures a scene of a busy city street. There is a man wearing a black bow tie and a gray suit walking across the street. He is carrying a red bag. \n\nThere are several other people in the scene, some walking and others standing. The people are walking across the street and walking down the stairs, walking down the street, standing on a street, walking on the escalator, playing a game, and riding a bike."}, "522020": {"image_id": 522020, "Bleu_1": 0.33333333331944454, "Bleu_2": 0.20851441404819784, "Bleu_3": 0.15811017751136303, "Bleu_4": 2.0828838183045013e-05, "METEOR": 0.21147230916495305, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.0362736128544675, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.21428571428571427, "f": 0.21052631578947367, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.26666666666666666, "f": 0.2962962962962963, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a white cat sitting on a grassy area, possibly in a backyard. The cat is sitting and looking at the camera."}, "252549": {"image_id": 252549, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.1200160042655936, "Bleu_4": 0.0774674148263478, "METEOR": 0.22989236902758145, "ROUGE_L": 0.2966050186680559, "CIDEr": 1.1941091257196046e-10, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.2608695652173913, "f": 0.33333333333333337, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5, "f": 0.6153846153846154, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image features a store with a large display of shirts and ties hanging on a wall. The shirts are arranged in various sections, with one shirt hanging higher up and another shirt hanging lower down. The ties are also displayed in different sections, with twelve ties hanging higher and lower."}, "122239": {"image_id": 122239, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.33282011772208075, "Bleu_3": 0.26429521259190897, "Bleu_4": 0.200167014751115, "METEOR": 0.29014245982149633, "ROUGE_L": 0.40822179732313574, "CIDEr": 0.039351945131671354, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a boy wearing a blue jacket, standing in a grassy field. The boy is holding an apple and appears to be enjoying it."}, "257940": {"image_id": 257940, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.25819888973988653, "Bleu_3": 0.15769573215932156, "Bleu_4": 1.8566774804562616e-05, "METEOR": 0.2724841491528291, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.0013329303553677885, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.23076923076923078, "f": 0.3243243243243243, "fn": 20.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image captures two trains traveling down the tracks in a city. The trains are passing through a city street. A tall building is visible in the background.\n\nThere is no person standing near the train.\n\n"}, "82263": {"image_id": 82263, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.12909944487067912, "Bleu_3": 7.291106321801015e-07, "Bleu_4": 1.7429412599383862e-09, "METEOR": 0.17927364968085363, "ROUGE_L": 0.24887800897592818, "CIDEr": 1.7983780276020225e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2608695652173913, "f": 0.2727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a boat sailing on the water. The boat is white. The boat is positioned in the middle of the scene. A bridge is visible in the background. The water appears to be calm, providing a serene atmosphere for the boat's journey."}, "53893": {"image_id": 53893, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.3027650353973863, "Bleu_3": 0.15854815808014064, "Bleu_4": 2.0630760173659833e-05, "METEOR": 0.19629985756815987, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.024934835410822476, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features four zebras in a zoo enclosure. They are all standing close to a tree. The zebras are standing near a wooden bench."}, "550815": {"image_id": 550815, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.06998542122096257, "Bleu_3": 4.672951871602598e-07, "Bleu_4": 1.2138611630520417e-09, "METEOR": 0.18495281786752799, "ROUGE_L": 0.2130384167636787, "CIDEr": 6.379036154465728e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.14285714285714285, "f": 0.15625, "fn": 30.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.0625, "f": 0.09090909090909091, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a bustling farmers market with a variety of fresh produce on display. Artichokes, carrots, onions, and potatoes are on display at the market. Some people are shopping and browsing the market. Some people are standing in front of the produce. Some people are walking in the market."}, "442487": {"image_id": 442487, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.19445555936085132, "Bleu_4": 0.14529286474157088, "METEOR": 0.29895198416664936, "ROUGE_L": 0.32348484848484854, "CIDEr": 0.00017984059687310643, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.07142857142857142, "f": 0.0851063829787234, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features two boys standing in a living room. The boys are holding a Wii remote and playing with a Wii. A couch is located in the background.\n\nThere is no chair in the scene."}, "412247": {"image_id": 412247, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.35269001105261744, "Bleu_3": 0.26747979862672605, "Bleu_4": 0.21185432734816126, "METEOR": 0.3147740771152063, "ROUGE_L": 0.4280701754385965, "CIDEr": 3.221007253975462e-05, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.42857142857142855, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.8333333333333334, "f": 0.5555555555555556, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a woman wearing a pink shirt and white pants, standing in a batting cage and holding a baseball bat. She is playing baseball. The batting cage is filled with baseballs, with some of them scattered around the area."}, "19817": {"image_id": 19817, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.21928846684766465, "Bleu_3": 0.148279070183802, "Bleu_4": 0.08658703974053754, "METEOR": 0.24996817756176062, "ROUGE_L": 0.25563122053431114, "CIDEr": 6.475847415135693e-16, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image depicts a bathroom with a white toilet situated next to a sink. A small bench is situated next to one of the sinks. The toilet is positioned under a shower curtain, which is not open. The sink is located on the right side of the bathroom. There are two towels nearby, and a mirror is located nearby as well."}, "82696": {"image_id": 82696, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.26208179769640866, "Bleu_3": 0.1855617321922141, "Bleu_4": 1.9749403858487766e-05, "METEOR": 0.2718922094464779, "ROUGE_L": 0.28754208754208754, "CIDEr": 2.064132110035583e-07, "SPICE": {"All": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.45454545454545453, "f": 0.5882352941176471, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image features a bird walking across a shiny floor in a restaurant setting. The bird is white and black. It is positioned in the center of the scene, surrounded by chairs and dining tables.\n\nThe bird is walking in the middle of the room."}, "167003": {"image_id": 167003, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.18442777838702637, "Bleu_3": 0.0897811031266893, "Bleu_4": 1.1199515753588489e-05, "METEOR": 0.18190803911457015, "ROUGE_L": 0.2576946288473144, "CIDEr": 4.5046547670736344e-09, "SPICE": {"All": {"pr": 0.23684210526315788, "re": 0.2727272727272727, "f": 0.2535211267605634, "fn": 24.0, "numImages": 1.0, "fp": 29.0, "tp": 9.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.08333333333333333, "f": 0.07692307692307691, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image features a woman standing on a Ferris wheel. She is holding an apple in her hand and wearing a blue shirt. The woman is enjoying her time on the ride. The Ferris wheel is surrounded by a lively beach scene, with several people scattered around the area."}, "87681": {"image_id": 87681, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2477973138852387, "Bleu_3": 0.11839421659860744, "Bleu_4": 1.465285462748969e-05, "METEOR": 0.2930367920681062, "ROUGE_L": 0.32570556826849734, "CIDEr": 6.621932452579854e-06, "SPICE": {"All": {"pr": 0.375, "re": 0.1935483870967742, "f": 0.25531914893617014, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image captures a skateboarder performing a trick in mid-air at a skate park. The skateboarder is in the center of the scene, with his skateboard clearly visible beneath him. The skateboarder is surrounded by a crowd of people."}, "353317": {"image_id": 353317, "Bleu_1": 0.4444444444320988, "Bleu_2": 0.22537446792125462, "Bleu_3": 0.11431682937091153, "Bleu_4": 1.4586602326405412e-05, "METEOR": 0.18944316452681892, "ROUGE_L": 0.3765432098765432, "CIDEr": 0.020099412813607914, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.23809523809523808, "f": 0.2941176470588235, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image is a split-screen view of a kitchen and dining area. The kitchen features two refrigerators, a sink, two microwaves, and an oven. The dining area is equipped with chairs placed around the dining table."}, "432553": {"image_id": 432553, "Bleu_1": 0.15238095237950114, "Bleu_2": 0.09376144618680182, "Bleu_3": 0.0554728469638493, "Bleu_4": 6.3960271482568315e-06, "METEOR": 0.19242948966281256, "ROUGE_L": 0.1410078594544614, "CIDEr": 1.1556907801538496e-52, "SPICE": {"All": {"pr": 0.1875, "re": 0.2, "f": 0.19354838709677422, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features three dogs standing on a subway train. The dogs are positioned near the center of the train, and they appear to be the main focus of the scene. One dog is brown and looking at a person. Another dog is white and looking at the brown dog. The third dog is brown and looking at a person.\n\nThere are two people in the image. One person is sitting on a bus, and the other person is holding a dog.\n\nThe overall scene shows the dogs standing on the floor of the subway train. The person is not standing close to the dog."}, "523245": {"image_id": 523245, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.32235637146490637, "Bleu_3": 0.2563740207204051, "Bleu_4": 0.1935798724449265, "METEOR": 0.3192462300140476, "ROUGE_L": 0.3519835136527563, "CIDEr": 0.0001606751665057256, "SPICE": {"All": {"pr": 0.3125, "re": 0.15625, "f": 0.20833333333333334, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man riding a cart being pulled by two oxen. The man is sitting on the cart, guiding the oxen as they walk down the road. The oxen are positioned on either side of the cart."}, "356586": {"image_id": 356586, "Bleu_1": 0.17721518987117452, "Bleu_2": 0.11675588928282493, "Bleu_3": 0.05615075786517585, "Bleu_4": 6.947256258017946e-06, "METEOR": 0.21476620463019283, "ROUGE_L": 0.15919965202261854, "CIDEr": 5.087499340688195e-28, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.2692307692307692, "f": 0.3181818181818182, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features two plates with a variety of donuts and pastries. On the first plate, there are four donuts. On the second plate, there is a piece of cake. The plates are placed on a dining table. \n\nThe donuts on the first plate include a chocolate frosted, a glazed, and a plain donut. There is also a plate of donuts on the dining table. \n\nThere is no chocolate donut, chocolate-covered donut, churro, or dining table in the scene."}, "371155": {"image_id": 371155, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.08451542547132876, "Bleu_3": 5.095178478788676e-07, "Bleu_4": 1.2568995875390724e-09, "METEOR": 0.16794292733658547, "ROUGE_L": 0.18068720379146921, "CIDEr": 2.7571134642943367e-14, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.19230769230769232, "f": 0.2564102564102564, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a bench situated in the middle of a grassy area. Rocks are surrounding the bench. \n\nThere are a total of six flowers in the scene. The flowers are of white, yellow, orange, pink, purple, and red colors. Some of the flowers are closer to the bench, while others are scattered in the grass."}, "180983": {"image_id": 180983, "Bleu_1": 0.2916666666545139, "Bleu_2": 0.19504737439306988, "Bleu_3": 0.12002890534307711, "Bleu_4": 1.693984999796846e-05, "METEOR": 0.2349195059126191, "ROUGE_L": 0.33008658008658004, "CIDEr": 0.021563154598382768, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a person wearing black pants. The person is standing on a snowboard. The snowboard is positioned horizontally on the snow-covered slope."}, "127659": {"image_id": 127659, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.22430886163262467, "Bleu_3": 0.16912968543226087, "Bleu_4": 0.11736263070262705, "METEOR": 0.24781824229433233, "ROUGE_L": 0.28944246737841045, "CIDEr": 3.794900316549529e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2608695652173913, "f": 0.2727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a train station with a train on the tracks, pulling into the station. A man is sitting on a bench, waiting for the train to come to a stop. There are several other people in the scene, some standing and others sitting on benches, likely waiting for their train as well."}, "69827": {"image_id": 69827, "Bleu_1": 0.21212121211799817, "Bleu_2": 0.057126204698926174, "Bleu_3": 3.7082037591362484e-07, "Bleu_4": 9.485004800057392e-10, "METEOR": 0.19038968426926792, "ROUGE_L": 0.17951736315479697, "CIDEr": 3.38636432978098e-19, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3157894736842105, "f": 0.2926829268292683, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features two men standing on the sidewalk. One man is wearing a red shirt and a blue hat, and he appears to be looking at a frisbee. The other man is wearing a blue hat and he appears to be looking at a car. \n\nThere is a white truck parked on the side of the road. There is no traffic light in the scene."}, "541887": {"image_id": 541887, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 0.08794832144810151, "Bleu_4": 0.06168026086597909, "METEOR": 0.21292999670910762, "ROUGE_L": 0.2776332899869961, "CIDEr": 1.2255114101978522e-10, "SPICE": {"All": {"pr": 0.35, "re": 0.2413793103448276, "f": 0.2857142857142857, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a stop sign with the word \"capitalism\" written underneath it. The stop sign is located on a pole, and it is positioned in front of a tree. The tree is visible in the background, and its leaves are changing colors, indicating that it is the fall season."}, "267725": {"image_id": 267725, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.3563483225369369, "Bleu_3": 0.30830160097047504, "Bleu_4": 0.2766873691177593, "METEOR": 0.4116648627608218, "ROUGE_L": 0.4603773584905661, "CIDEr": 0.02052725116217447, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.25, "f": 0.32432432432432434, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features a dog sitting on a pile of blankets and clothes, which are spread out on the ground. The dog appears to be relaxed and comfortable."}, "147140": {"image_id": 147140, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.0645198590415134, "Bleu_3": 4.522633916831482e-07, "Bleu_4": 1.2041494936393691e-09, "METEOR": 0.22002004470548364, "ROUGE_L": 0.23843648208469054, "CIDEr": 6.618825900697737e-10, "SPICE": {"All": {"pr": 0.4375, "re": 0.30434782608695654, "f": 0.358974358974359, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a woman wearing a green and gray outfit, skiing down a snow-covered slope. She is holding a pair of ski poles in her hands, maintaining her balance and control as she glides down the hill. The woman appears to be enjoying her skiing experience."}, "24567": {"image_id": 24567, "Bleu_1": 0.20987654320728547, "Bleu_2": 0.1619708859659129, "Bleu_3": 0.09987482383911962, "Bleu_4": 0.05978171489864259, "METEOR": 0.1884763154712012, "ROUGE_L": 0.24022503516174398, "CIDEr": 1.889793442661272e-26, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man wearing a green shirt and a hat, standing next to a tray filled with a variety of hot dogs. The hot dogs are arranged on the tray. The tray of hot dogs is placed on the table. \n\nThere are a total of nine hot dogs on the tray. The hot dogs are arranged in various ways, some on a bun, some in a tray, and some in a row. \n\nThere is no table in the scene."}, "322145": {"image_id": 322145, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.07441168295431691, "Bleu_3": 5.130576084588407e-07, "Bleu_4": 1.3555314602460315e-09, "METEOR": 0.18586310679207987, "ROUGE_L": 0.17441029306647607, "CIDEr": 1.1907570705142376e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man wearing a black jacket and skiing down a snow-covered slope. The man is holding ski poles in his hands, and his skis are visible beneath him. The man appears to be enjoying his time on the snowy hill."}, "11567": {"image_id": 11567, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2738612787456488, "Bleu_3": 0.239952475964027, "Bleu_4": 0.2078672146785203, "METEOR": 0.34927464387626395, "ROUGE_L": 0.464199239017641, "CIDEr": 6.574096732047969e-05, "SPICE": {"All": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a man standing on a tennis court. The man is holding a tennis racket and a tennis ball. He appears to be playing tennis. The man is wearing a blue shirt and is focused on the game."}, "482487": {"image_id": 482487, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.1923131632828435, "Bleu_3": 0.12713013434655676, "Bleu_4": 0.08753250723793518, "METEOR": 0.2167596729089117, "ROUGE_L": 0.23282442748091606, "CIDEr": 0.036112174990488244, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2222222222222222, "f": 0.24489795918367346, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.35714285714285715, "f": 0.45454545454545453, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features two clocks mounted on a wall. One clock is visible in the glass. The clock is positioned on the floor. A street is visible in the background. There is no fire hydrant in the scene."}, "132992": {"image_id": 132992, "Bleu_1": 0.1948051948026649, "Bleu_2": 0.13394992994245392, "Bleu_3": 6.207850355404369e-07, "Bleu_4": 1.3409049673646936e-09, "METEOR": 0.2375096004801334, "ROUGE_L": 0.2329232074671192, "CIDEr": 6.2131002413220944e-27, "SPICE": {"All": {"pr": 0.2, "re": 0.23529411764705882, "f": 0.2162162162162162, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features three brown teddy bears sitting on a stone surface. One teddy bear is sitting on a table, with a small teddy bear lying next to it. Another teddy bear is also sitting on a table, with a stuffed dog next to it. The third teddy bear is sitting on a wooden table, with a small dog next to it.\n\nThe scene is set against a backdrop of trees, creating a peaceful and cozy atmosphere."}, "411953": {"image_id": 411953, "Bleu_1": 0.2615384615344379, "Bleu_2": 0.1917781169808111, "Bleu_3": 0.12053863481783907, "Bleu_4": 0.08669704155707406, "METEOR": 0.2325890537082569, "ROUGE_L": 0.27164769915883225, "CIDEr": 6.594589394694497e-19, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.19047619047619047, "f": 0.25, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a man standing on stage, holding a guitar and singing into a microphone. He is wearing a yellow shirt and a red tie, which adds a touch of style to his performance.\n\nThe stage is illuminated by red and orange lights. The man is playing a guitar and singing into a microphone. The lights are creating a dramatic atmosphere for the performance."}, "359314": {"image_id": 359314, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.07001400420004092, "Bleu_3": 4.611051180784598e-07, "Bleu_4": 1.189326065429759e-09, "METEOR": 0.09688581314878891, "ROUGE_L": 0.15365239294710328, "CIDEr": 4.4349888350478483e-13, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a scene where a large truck is being towed by a white tractor. The truck is positioned in the middle of the scene, with the tractor on the right side of it. There are several people around the truck and tractor, some of them standing closer to the truck."}, "502220": {"image_id": 502220, "Bleu_1": 0.17241379310047567, "Bleu_2": 0.09525969852473676, "Bleu_3": 5.451844491105067e-07, "Bleu_4": 1.3101376346359472e-09, "METEOR": 0.16207382924226493, "ROUGE_L": 0.20220994475138118, "CIDEr": 6.668214861807367e-15, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10344827586206896, "f": 0.12000000000000001, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features four people gathered on a rooftop, enjoying a sunny day. The people are playing with a frisbee, playing with a kite, walking, and playing a game. \n\nThere are no women in the scene.\n\nThe kite is flying in the sky, adding a lively atmosphere to the scene.\n\nThere is no specific information about the scene."}, "488723": {"image_id": 488723, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.2419433515576788, "Bleu_3": 0.16513077185436242, "Bleu_4": 0.1240745211940968, "METEOR": 0.29699649795562055, "ROUGE_L": 0.35234657039711187, "CIDEr": 4.079576744618988e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.24, "f": 0.2666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a table with a vase of red roses positioned towards the center of the table. The roses are arranged in a bouquet. \n\nThere is a bottle located on the table.\n\nThere are no other items in the scene."}, "400367": {"image_id": 400367, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.24331962586375616, "Bleu_3": 0.17394044861887759, "Bleu_4": 0.10457726275765848, "METEOR": 0.23434999633678855, "ROUGE_L": 0.34945894334818584, "CIDEr": 2.400386325404209e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image captures a busy city street at night, with a row of 10 cars parked on the side of the road. The street is illuminated by streetlights, creating a vibrant atmosphere. There are several traffic lights visible along the street, ensuring the smooth flow of traffic."}, "453330": {"image_id": 453330, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1740776559517855, "Bleu_3": 0.0889895891077732, "Bleu_4": 1.1381305436598616e-05, "METEOR": 0.23104110353783502, "ROUGE_L": 0.25258799171842644, "CIDEr": 9.298259859259699e-09, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.2857142857142857, "f": 0.21818181818181817, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.06666666666666667, "re": 0.125, "f": 0.08695652173913045, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.8, "f": 0.47058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a bird standing in a wooded area. The bird is black and white. It is perched on a branch, surrounded by leaves and twigs. The scene captures the bird's natural habitat, showcasing its beauty and the lush greenery of the forest."}, "272129": {"image_id": 272129, "Bleu_1": 0.2162162162103726, "Bleu_2": 0.07749842582708927, "Bleu_3": 5.556985188906214e-07, "Bleu_4": 1.4988552732319317e-09, "METEOR": 0.19215053591962064, "ROUGE_L": 0.1898832684824903, "CIDEr": 1.0202995361288463e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2, "f": 0.20408163265306126, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features two objects with green covers. One of the objects is possibly a kite, as a kite is flying above it. The other object could be a person, as an alien is flying above it."}, "100543": {"image_id": 100543, "Bleu_1": 0.1940298507433727, "Bleu_2": 0.14345355890802863, "Bleu_3": 0.08587098231867618, "Bleu_4": 9.973321743171706e-06, "METEOR": 0.2616947037213367, "ROUGE_L": 0.2356349589570256, "CIDEr": 2.7837695784043843e-20, "SPICE": {"All": {"pr": 0.05, "re": 0.045454545454545456, "f": 0.04761904761904762, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features a group of twelve people gathered together, with some of them holding umbrellas. The umbrellas vary in size and color. Some of the people are also holding bags, a paper airplane, a hat, a microphone, and a pink umbrella. \n\nThe overall atmosphere of the scene is lively and vibrant, with the people standing close to each other, creating a sense of unity and camaraderie."}, "532919": {"image_id": 532919, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.1797866299868988, "Bleu_3": 0.10684551660659944, "Bleu_4": 1.237560363984256e-05, "METEOR": 0.251169024161974, "ROUGE_L": 0.24013046901360924, "CIDEr": 7.309765306266432e-11, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a horse pulling a wagon down a street. The horse is positioned behind the cart. The wagon is being pulled by the horse. The man is standing in front of the horse and wagon in relation to the horse and wagon. The man is possibly guiding or controlling the horse's movements."}, "498274": {"image_id": 498274, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.09267924750141882, "Bleu_4": 1.1469577394366865e-05, "METEOR": 0.21915524958759172, "ROUGE_L": 0.15394321766561514, "CIDEr": 5.629007876401725e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features four buses parked on the street. The buses are green and white, orange and white, orange and white, and blue and green respectively. A building can be seen in the background.\n\nThere is a parking lot in the scene.\n\nThere is one person in the image."}, "536933": {"image_id": 536933, "Bleu_1": 0.18556701030736528, "Bleu_2": 0.08793155726317115, "Bleu_3": 0.043336647145547545, "Bleu_4": 5.424497552137075e-06, "METEOR": 0.14733040368021474, "ROUGE_L": 0.17298830202056012, "CIDEr": 4.118316988288462e-46, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1875, "f": 0.17647058823529413, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a snowy ski slope with a large group of people skiing and snowboarding. There are at least 14 people visible in the scene. Some of the people are skiing, some are snowboarding, and some are carrying skis or a snowboard. The skiers and snowboarders are wearing jackets of various colors, including black, blue, green, red, and yellow. \n\nThere is no ski slope in the scene.\n\nThere is no snowboarder in the scene.\n\nThere is no backpack in the scene.\n\nThere is no slope in the scene.\n\nSkis and snowboards are scattered across the slope."}, "273637": {"image_id": 273637, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.2399704669849505, "Bleu_3": 0.19149932476625964, "Bleu_4": 0.16278914239404066, "METEOR": 0.2932457926803876, "ROUGE_L": 0.37094594594594593, "CIDEr": 8.079901356050779e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.1724137931034483, "f": 0.17543859649122806, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a woman wearing a red shirt and holding two wine glasses in her hands. She is smiling and appears to be enjoying herself. The glasses are filled with red wine.\n\nIn the background, there is no bottle, glasses, or camera."}, "257887": {"image_id": 257887, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.28767798088147595, "Bleu_3": 0.1435109603954101, "Bleu_4": 1.8189587991496385e-05, "METEOR": 0.20347490174747768, "ROUGE_L": 0.36802413273001505, "CIDEr": 0.025184768558809058, "SPICE": {"All": {"pr": 0.2, "re": 0.24, "f": 0.2181818181818182, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a city skyline with a river in the foreground. A train is traveling through the city. A red and white fire hydrant is also in the foreground."}, "316123": {"image_id": 316123, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.31280898701791376, "Bleu_3": 0.18897171906057175, "Bleu_4": 2.2156854334632592e-05, "METEOR": 0.25837313796744954, "ROUGE_L": 0.31448702526207256, "CIDEr": 0.010191638306948855, "SPICE": {"All": {"pr": 0.2, "re": 0.13636363636363635, "f": 0.16216216216216214, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features three boys playing soccer on a grassy field. The boys are wearing green shirts. They are actively engaged in the game. A soccer ball is on the field."}, "155488": {"image_id": 155488, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.24194335155767877, "Bleu_3": 0.14425501641879765, "Bleu_4": 0.0942762488834096, "METEOR": 0.21684844851469193, "ROUGE_L": 0.33493479752916955, "CIDEr": 5.099851594440439e-06, "SPICE": {"All": {"pr": 0.21875, "re": 0.3333333333333333, "f": 0.2641509433962264, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features a building with a red door, situated in a parking lot. A white truck is parked in front of the building. A large American flag is flying on the flagpole.\n\nThere are no other vehicles in the scene."}, "495513": {"image_id": 495513, "Bleu_1": 0.17499999999781252, "Bleu_2": 0.1052423363804223, "Bleu_3": 0.05217095496362434, "Bleu_4": 6.553131885417986e-06, "METEOR": 0.21066026338082963, "ROUGE_L": 0.16716254306295023, "CIDEr": 1.7414023193216379e-25, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a man and a woman standing next to each other. The man is on the left side of the woman. They are both holding hot dogs on sticks. \n\nThere are three other people in the scene. One person is holding a hot dog, another person is holding a skateboard, and the third person is holding a hat and a hat.\n\nOverall, the man and the woman are enjoying a fun moment together, holding hot dogs on sticks."}, "356337": {"image_id": 356337, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.26010243549896195, "Bleu_3": 0.14769184446990152, "Bleu_4": 1.6742542942575295e-05, "METEOR": 0.22522596019845792, "ROUGE_L": 0.3392239248640633, "CIDEr": 8.850863167926051e-05, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.19230769230769232, "f": 0.16666666666666669, "fn": 21.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.2, "f": 0.10526315789473682, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a man and a woman standing together, both holding a knife and preparing to cut a cake. The cake is placed on a dining table. There is a bottle of beer nearby the cake, suggesting a celebration or a special occasion."}, "488": {"image_id": 488, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.15360164850632854, "Bleu_3": 0.10812057011504156, "Bleu_4": 0.06923737162392678, "METEOR": 0.19080695671967962, "ROUGE_L": 0.21852610030706246, "CIDEr": 3.662666946595035e-13, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.19047619047619047, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress. The batter is standing on home plate, holding a baseball bat, and preparing to hit the ball. The batter is wearing a baseball uniform. The catcher is positioned behind home plate, wearing a maroon shirt. There is no ball in the image. There are no other players in the scene."}, "179599": {"image_id": 179599, "Bleu_1": 0.26865671641390065, "Bleu_2": 0.18045622869249706, "Bleu_3": 0.10006605940160482, "Bleu_4": 1.1185878679402043e-05, "METEOR": 0.2248954488985424, "ROUGE_L": 0.231608922638823, "CIDEr": 4.59534278152336e-19, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.28, "f": 0.3333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a baseball field with a baseball player in a blue uniform standing on the pitcher's mound. The player is in the process of throwing a ball. The player is wearing a blue baseball uniform. The player is ready to throw a ball. The player is wearing a baseball glove, ready to catch the ball.\n\nThere is no baseball or arm in the scene."}, "516601": {"image_id": 516601, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.3478041718090821, "Bleu_3": 0.25265977408827234, "Bleu_4": 0.18262493612884187, "METEOR": 0.3101651395781914, "ROUGE_L": 0.42068965517241375, "CIDEr": 0.0011108946651622875, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.13636363636363635, "f": 0.0759493670886076, "fn": 19.0, "numImages": 1.0, "fp": 54.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08695652173913043, "re": 0.18181818181818182, "f": 0.1176470588235294, "fn": 9.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.058823529411764705, "re": 0.2, "f": 0.0909090909090909, "fn": 4.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}}, "caption": "The image captures a group of people skiing on a snow-covered slope, enjoying the winter sport. Some of the people are standing on the snow, while others are skiing down the slope."}, "574376": {"image_id": 574376, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.2705008903937107, "Bleu_3": 0.17638685649486258, "Bleu_4": 0.10891395115950224, "METEOR": 0.23051082885795868, "ROUGE_L": 0.3339198435972629, "CIDEr": 1.1652877836291218e-06, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.3333333333333333, "f": 0.2692307692307692, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a woman sitting on the beach. She is wearing a blue shirt and blue shorts. She is holding a surfboard, likely preparing to go surfing or having just finished a surfing session. The surfboard is placed on the sand."}, "469755": {"image_id": 469755, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.24909123653704068, "Bleu_3": 0.15396523123679995, "Bleu_4": 1.6437073337356213e-05, "METEOR": 0.2499663977081124, "ROUGE_L": 0.24811156304474144, "CIDEr": 6.448165880122052e-12, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.4375, "f": 0.3255813953488372, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image captures two people surfing in the ocean. The people are enjoying surfing. One of the surfers is riding a wave on a surfboard, while the other surfer is standing in the water, likely preparing to catch a wave. The scene is set on a beach, with waves crashing in the background."}, "575957": {"image_id": 575957, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.2562353715895104, "Bleu_3": 0.166077317092673, "Bleu_4": 1.817274019118142e-05, "METEOR": 0.20738569520858124, "ROUGE_L": 0.32084155161078237, "CIDEr": 9.056064210757065e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16666666666666666, "f": 0.1923076923076923, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a brown and black dog lying on a bed. The dog is rolling on its back, with its head resting on the left side of the bed and its tail resting on the right side. The bed is like a dog bed."}, "112378": {"image_id": 112378, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.06868028197303624, "Bleu_3": 4.522355034563233e-07, "Bleu_4": 1.1662213550197089e-09, "METEOR": 0.1613295526544357, "ROUGE_L": 0.20412716118237598, "CIDEr": 1.5628067155925365e-11, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.2, "f": 0.17241379310344826, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image features four benches situated in a lush green field near a body of water. The benches are surrounded by a variety of fruits, including coconuts and bananas. Two bananas are placed on each bench. Some bananas are placed closer to the water, while others are placed further away on the ground."}, "293811": {"image_id": 293811, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.16003048489677246, "Bleu_3": 0.08691877797255902, "Bleu_4": 1.1465402609758039e-05, "METEOR": 0.18653471977328248, "ROUGE_L": 0.23229246001523232, "CIDEr": 3.444347528161795e-06, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.20833333333333334, "f": 0.23255813953488372, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a baseball game in progress. There are two pitchers in the scene, both wearing red and white uniforms. They are each throwing a ball. The batter is holding a baseball bat and is ready to hit the ball."}, "285534": {"image_id": 285534, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.17787191480959694, "Bleu_3": 0.11784269714184226, "Bleu_4": 1.3016921671724025e-05, "METEOR": 0.24217377257982994, "ROUGE_L": 0.2609227008860372, "CIDEr": 1.0488382022959281e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.12121212121212122, "f": 0.163265306122449, "fn": 29.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two women. One woman is holding a baby and the other woman is holding a teddy bear. Both women are sitting on a chair. The baby is also holding a teddy bear. The women are not smiling. A stuffed animal is placed in front of each woman.\n\nThere is no other person or man in the scene."}, "192714": {"image_id": 192714, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.23722785728454912, "Bleu_3": 1.4117803263685948e-06, "Bleu_4": 3.488485674852371e-09, "METEOR": 0.290183099439877, "ROUGE_L": 0.2579281183932347, "CIDEr": 0.11333066641033288, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3157894736842105, "f": 0.3243243243243243, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a residential area with a green traffic light hanging above the road. The cars are parked on the street."}, "510798": {"image_id": 510798, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.14414999402869194, "Bleu_3": 0.09164072107290062, "Bleu_4": 1.0977347333932835e-05, "METEOR": 0.1812594904678507, "ROUGE_L": 0.20795454545454545, "CIDEr": 1.3421114654626102e-11, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.1724137931034483, "f": 0.15873015873015872, "fn": 24.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress. At home plate, the batter is standing, holding a baseball bat, and preparing to swing. The batter is wearing a black helmet. The catcher is positioned behind the batter, wearing a white shirt and holding a baseball glove. The umpire is also present, preparing to throw the ball."}, "303358": {"image_id": 303358, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.23186944787247984, "Bleu_3": 1.228465655403517e-06, "Bleu_4": 2.852546657248816e-09, "METEOR": 0.21887577300500585, "ROUGE_L": 0.2869238005644403, "CIDEr": 0.0007761764432406661, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features three elephants walking in a grassy field. The elephants are spread out across the field. The largest elephant is leading the way, followed closely by two smaller elephants."}, "66191": {"image_id": 66191, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.23124864502453574, "Bleu_3": 0.14951317712512502, "Bleu_4": 1.8120458368313502e-05, "METEOR": 0.32504974822915095, "ROUGE_L": 0.41567291311754684, "CIDEr": 0.00041526812307055613, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1875, "f": 0.13636363636363635, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image captures a baseball player standing on the field holding a bat. The player appears to be preparing to hit the ball. The home plate is positioned in the middle of the field."}, "89697": {"image_id": 89697, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.4465760846878646, "Bleu_3": 0.3416700986421019, "Bleu_4": 0.20190748509151957, "METEOR": 0.35469001831639413, "ROUGE_L": 0.48031496062992124, "CIDEr": 0.030163976189768977, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.1, "f": 0.0851063829787234, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image is a black and white photograph of a man and a woman sitting on a park bench. They appear to be engaged in a conversation."}, "503799": {"image_id": 503799, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.25043516133286925, "Bleu_3": 0.21110278158177162, "Bleu_4": 0.17624601773356902, "METEOR": 0.3280770303517103, "ROUGE_L": 0.31077147016011636, "CIDEr": 1.3495262750748145e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image captures a man riding a skateboard down a street. The man is wearing a helmet for safety. He is the main focus of the scene, with his skateboard positioned under his feet. The man appears to be enjoying his ride."}, "256838": {"image_id": 256838, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.14907119849663567, "Bleu_3": 0.08024900879514213, "Bleu_4": 1.0532159683631698e-05, "METEOR": 0.23569435098570066, "ROUGE_L": 0.25258799171842644, "CIDEr": 3.47420401300922e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a train parked at a subway station. The train is silver. It is positioned under a bridge. The train appears to be an older model. It is stopped at the station, waiting for passengers. \n\nThere is one person visible in the scene."}, "461839": {"image_id": 461839, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.22758963106159172, "Bleu_3": 0.1351124024481338, "Bleu_4": 0.08806948323308712, "METEOR": 0.21343876589442898, "ROUGE_L": 0.29985955056179775, "CIDEr": 7.629835336184597e-08, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.27586206896551724, "f": 0.2857142857142857, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image depicts a cozy living room with a desk area featuring a computer monitor, keyboard, and mouse. A chair is positioned in front of the desk. The room also has a TV mounted on the wall, and a potted plant is placed nearby."}, "515612": {"image_id": 515612, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.22131333406452386, "Bleu_3": 0.17215301886614504, "Bleu_4": 0.12138611630520416, "METEOR": 0.3192462300140476, "ROUGE_L": 0.3100381194409149, "CIDEr": 5.0856641097310764e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.10810810810810811, "f": 0.14035087719298245, "fn": 33.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man sitting on a stool, playing a keyboard. The man is wearing a hat and appears to be enjoying his time playing music. The man is positioned on a chair. The keyboard is in front of the man.\n\nThe setting appears to be an outdoor area."}, "408534": {"image_id": 408534, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.29777500018082764, "Bleu_3": 0.18727547166812117, "Bleu_4": 2.2419056819481584e-05, "METEOR": 0.28090101178446203, "ROUGE_L": 0.3489037178265014, "CIDEr": 0.0031348760578421833, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.34782608695652173, "f": 0.3636363636363636, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a person riding a wave in the ocean. The person is riding a surfboard and skillfully navigating the waves. The ocean water is a vibrant blue."}, "321742": {"image_id": 321742, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.09087496586948689, "Bleu_4": 1.1854610697110774e-05, "METEOR": 0.21358589739665398, "ROUGE_L": 0.23229246001523232, "CIDEr": 2.7809747625594e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a parking lot with six motorcycles parked in a row. The motorcycles are of various sizes and colors. The prominent motorcycle is black, green, or blue. Some of the motorcycles are small, while one of them is 125cc."}, "149469": {"image_id": 149469, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.24450482345050376, "Bleu_3": 0.13954600049383722, "Bleu_4": 1.896632645996694e-05, "METEOR": 0.2728975773265416, "ROUGE_L": 0.38125000000000003, "CIDEr": 0.05594046890557336, "SPICE": {"All": {"pr": 0.3125, "re": 0.25, "f": 0.2777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a delicious pizza with tomatoes and cheese. The pizza is placed on a blue plate, which is positioned on a table."}, "355919": {"image_id": 355919, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.17368336856959593, "Bleu_3": 8.449846526122947e-07, "Bleu_4": 1.8732148659640307e-09, "METEOR": 0.223074195763555, "ROUGE_L": 0.23669623059866962, "CIDEr": 5.855308238071832e-10, "SPICE": {"All": {"pr": 0.21875, "re": 0.23333333333333334, "f": 0.22580645161290322, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.46153846153846156, "f": 0.4444444444444445, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image features a large pepperoni pizza sitting on a dining table. The pizza is cut into slices, and it appears to be a freshly baked pizza from North End Pizza Bakery. The table is made of wood. There is a cup in the image, but there is no drink in it."}, "369045": {"image_id": 369045, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2006088294094673, "Bleu_3": 0.12731761426913407, "Bleu_4": 1.5265831690423254e-05, "METEOR": 0.18486234707828125, "ROUGE_L": 0.23229246001523232, "CIDEr": 1.3131822965077566e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image features a clock tower with a gold dome, towering over the city. The clock is prominently displayed in the tower. The scene is bustling with activity, as people are walking down the street, admiring the architecture of the tower."}, "439589": {"image_id": 439589, "Bleu_1": 0.30769230768047345, "Bleu_2": 3.5082320770904867e-09, "Bleu_3": 8.004271223128443e-12, "Bleu_4": 3.8641981489783027e-13, "METEOR": 0.20109814274126628, "ROUGE_L": 0.270509977827051, "CIDEr": 0.012844440850076492, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.13636363636363635, "f": 0.1714285714285714, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a train yard with six trains parked on the tracks. The trains vary in length and are arranged in a somewhat organized manner."}, "467696": {"image_id": 467696, "Bleu_1": 0.2535211267569926, "Bleu_2": 0.13456839120296812, "Bleu_3": 0.06402442350632395, "Bleu_4": 7.881920122766104e-06, "METEOR": 0.21529121263042755, "ROUGE_L": 0.2075712462781795, "CIDEr": 3.373463017079616e-16, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features four boats floating in the water. The boats are filled with luggage, including suitcases and backpacks. Some of the luggage contains a laptop, and one of the suitcases is red with a black handle. \n\nThere are seven people on the boat, some standing and some sitting. One man is standing near the front of one of the boats, possibly guiding it or ensuring the safety of the passengers."}, "519916": {"image_id": 519916, "Bleu_1": 0.18749999999765626, "Bleu_2": 0.12889501173519066, "Bleu_3": 0.07524353737881434, "Bleu_4": 8.62440657784898e-06, "METEOR": 0.18004234775826802, "ROUGE_L": 0.15275459098497496, "CIDEr": 2.9411648770506445e-30, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.15384615384615385, "f": 0.13559322033898305, "fn": 22.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a lively scene on a sandy beach, where four men are playing a game of volleyball. One man is actively hitting a volleyball, while the others are positioned nearby, ready to return the ball. A volleyball net is set up in the middle of the scene. \n\nThere is no tennis or tennis ball in the image.\n\nThere is no mention of players or a game of tennis.\n\nThere is no mention of a frisbee or a net."}, "359136": {"image_id": 359136, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.16816819849581244, "Bleu_3": 0.08270007684490462, "Bleu_4": 1.0365265119381272e-05, "METEOR": 0.24049245260547264, "ROUGE_L": 0.31697459584295606, "CIDEr": 1.1868748120395122e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a woman wearing a black tank top and boots, lying on the floor next to a bathtub. She appears to be relaxing or possibly taking a break from a bath. The bathroom has a sink and a toilet, with the sink located on the left side of the room."}, "514904": {"image_id": 514904, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.23555849565513073, "Bleu_3": 0.1923243679466874, "Bleu_4": 0.16542259679051985, "METEOR": 0.35884424355995, "ROUGE_L": 0.39638989169675093, "CIDEr": 1.4854136686477213e-06, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a woman wearing sunglasses and holding two hot dogs in her hands. She is smiling. The hot dogs are wrapped in paper. She is standing in front of a bus.\n\nIn the background, there are several bicycles parked."}, "333998": {"image_id": 333998, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.18946618668147105, "Bleu_3": 9.812054324169895e-07, "Bleu_4": 2.2478613857685046e-09, "METEOR": 0.19383812032779552, "ROUGE_L": 0.22426470588235295, "CIDEr": 4.1077804601289495e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.14814814814814814, "f": 0.1951219512195122, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image depicts a small, clean kitchen with white appliances and wooden cabinets. The kitchen features a microwave on the left side and an oven on the right side. A sink is located towards the right side of the kitchen."}, "395290": {"image_id": 395290, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.21821789022984422, "Bleu_3": 0.11188381403630097, "Bleu_4": 1.4353141358611075e-05, "METEOR": 0.21946909662488645, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.00021888330256434197, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.3181818181818182, "f": 0.35000000000000003, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.5454545454545454, "f": 0.631578947368421, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a white and black cat sitting on a window sill. The cat is enjoying a sunny day. There is a white car parked on the street. A building is visible in the background."}, "254892": {"image_id": 254892, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.344350221559779, "Bleu_3": 0.256823187111443, "Bleu_4": 3.033668865621181e-05, "METEOR": 0.31303474840871415, "ROUGE_L": 0.4241019698725377, "CIDEr": 0.06518457026550037, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a giraffe standing in a grassy field. The giraffe is holding its head high and is positioned under an umbrella."}}}