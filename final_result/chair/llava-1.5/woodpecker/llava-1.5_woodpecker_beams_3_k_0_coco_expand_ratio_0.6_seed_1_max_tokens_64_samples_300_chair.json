{"overall": {"Bleu_1": 0.2852940271760069, "Bleu_2": 0.19480904254606687, "Bleu_3": 0.12446989539456554, "Bleu_4": 0.07757968242769418, "METEOR": 0.23299685690167407, "ROUGE_L": 0.29432179231546757, "CIDEr": 0.017541652493878703, "SPICE": 0.21489216315371226}, "imgToEval": {"281533": {"image_id": 281533, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.24046440328937668, "Bleu_3": 0.15454026854146363, "Bleu_4": 0.09464371716192442, "METEOR": 0.27990297128553343, "ROUGE_L": 0.3059013163786155, "CIDEr": 7.539406511343617e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13636363636363635, "f": 0.13636363636363635, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a dog sitting on the floor in front of a TV. The dog is watching TV. The dog is captivated by the content displayed on the screen. \n\nIn the room, there are two potted plants, one on the left side and another on the right side."}, "397773": {"image_id": 397773, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.17996850826166375, "Bleu_3": 9.566001321761773e-07, "Bleu_4": 2.2206095448570952e-09, "METEOR": 0.2806132642220446, "ROUGE_L": 0.2741573033707865, "CIDEr": 1.325182220148574e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image showcases a delicious pasta dish served on a white plate. The dish is topped with a generous amount of shredded cheese. The pasta is accompanied by a variety of vegetables, including five pieces of broccoli scattered throughout."}, "371250": {"image_id": 371250, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.10390486669052698, "Bleu_3": 6.6326948668966e-07, "Bleu_4": 1.6872983760809617e-09, "METEOR": 0.16438744420038265, "ROUGE_L": 0.28870858688302903, "CIDEr": 1.4322776171843702e-05, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a living room with a brown leather couch as the main focal point. The couch is adorned with four pillows, with two pillows on each side. A remote control can be seen on a wooden table."}, "573877": {"image_id": 573877, "Bleu_1": 0.4374999999863282, "Bleu_2": 0.2909938476144488, "Bleu_3": 0.2038242586060542, "Bleu_4": 0.13072010980250545, "METEOR": 0.28198200444724214, "ROUGE_L": 0.4552238805970149, "CIDEr": 0.00803533046103915, "SPICE": {"All": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a white cat sitting in front of a laptop computer. The cat is staring at the screen, seemingly intrigued by its content. The laptop is placed on a desk."}, "181859": {"image_id": 181859, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.2734059812097495, "Bleu_3": 0.1939236242118044, "Bleu_4": 0.13818647557441413, "METEOR": 0.29152523998943114, "ROUGE_L": 0.34882058613295214, "CIDEr": 5.763332140854518e-07, "SPICE": {"All": {"pr": 0.4375, "re": 0.3684210526315789, "f": 0.39999999999999997, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.6666666666666666, "f": 0.6153846153846153, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a cat comfortably laying in a sink. The cat is gray and white. The sink is made of stone. A mirror is above the sink. \n\nIn the bathroom, there is a bottle nearby, which appears to be a soap dispenser."}, "119939": {"image_id": 119939, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.33333333332075027, "Bleu_3": 0.26099117606787625, "Bleu_4": 0.21711852080234603, "METEOR": 0.38706029466743885, "ROUGE_L": 0.37446286065070594, "CIDEr": 0.011054478458394218, "SPICE": {"All": {"pr": 0.35, "re": 0.5384615384615384, "f": 0.4242424242424242, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts two men riding skateboards down a sidewalk near a building. The skateboarders are wearing backpacks. \n\nOn the street are the men riding the skateboards."}, "385320": {"image_id": 385320, "Bleu_1": 0.388888888867284, "Bleu_2": 0.21389631596101674, "Bleu_3": 0.1419369740087647, "Bleu_4": 2.0895311115411017e-05, "METEOR": 0.19679967097399267, "ROUGE_L": 0.3765432098765432, "CIDEr": 0.32101435804657547, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.3333333333333333, "f": 0.2916666666666667, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 1.0, "f": 0.5882352941176471, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a child brushing her teeth with a toothbrush. The child is wearing a striped shirt."}, "490415": {"image_id": 490415, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.2114602732248218, "Bleu_3": 0.14968316139452448, "Bleu_4": 0.09629717763049693, "METEOR": 0.2855255836759479, "ROUGE_L": 0.29901960784313725, "CIDEr": 9.682049908313486e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10344827586206896, "f": 0.1276595744680851, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "In the image, there are two men engaging in different activities. One man is standing in a grassy field, flying a green kite high in the sky. The other man is riding a bike. \n\nThere are no other people in the scene."}, "432293": {"image_id": 432293, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.19847906537508855, "Bleu_3": 0.12236681347581897, "Bleu_4": 1.4452248335535119e-05, "METEOR": 0.22814739046147303, "ROUGE_L": 0.2840984697272122, "CIDEr": 2.431080098829433e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.24, "f": 0.2666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a cutting board made of wood, with a pizza placed on top of it. The pizza is topped with shrimp, tomatoes, and cheese. The pizza appears to be a pizza with shrimp and tomatoes. The pizza is not ready to be served."}, "256301": {"image_id": 256301, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.14524007059304897, "Bleu_4": 0.09604819623180479, "METEOR": 0.23698339821262662, "ROUGE_L": 0.2741573033707865, "CIDEr": 8.89702302543524e-05, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.13793103448275862, "f": 0.1904761904761905, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image captures four people standing on a platform under a large neon sign that reads \"Public Market.\" One of the individuals is taking a picture of the clock, which is prominently displayed on the side of the sign."}, "361103": {"image_id": 361103, "Bleu_1": 0.11274509803866302, "Bleu_2": 0.08817893173898238, "Bleu_3": 0.04869673575800092, "Bleu_4": 4.895824863362731e-06, "METEOR": 0.13393362942146728, "ROUGE_L": 0.15069701782248104, "CIDEr": 7.616371107401545e-204, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.043478260869565216, "f": 0.043478260869565216, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image depicts a busy city street with two men standing on the sidewalk. One man is talking on the phone and looking at a woman, while the other man is reading a paper and looking at a newspaper. \n\nThere are several other people on the street. Some are walking down the street, others are walking on the sidewalk, and some are standing on the sidewalk. There is also a blurry image of a person in a yellow shirt, a painting of a woman in a black dress, and people looking at a phone. Additionally, there are people riding bikes and playing a game of soccer.\n\nThere is a street and a sidewalk in the scene. \n\nThere are four traffic lights in the scene. One traffic light indicates a stop sign, another indicates a red light, another indicates a green light, and the last one indicates the direction of traffic.\n\nThere is also a cell phone store in the scene.\n\nOverall, the image depicts a bustling city street with people engaged in various activities, such as talking on the phone, reading, and playing sports. The presence of the street, sidewalk, traffic lights, and cell phone store adds to the urban atmosphere of the scene."}, "567562": {"image_id": 567562, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1504928025607928, "Bleu_3": 8.272888216792643e-07, "Bleu_4": 1.9519860758481695e-09, "METEOR": 0.25885711360110625, "ROUGE_L": 0.2824074074074074, "CIDEr": 6.283834431468956e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image depicts two women and a group of children sitting around a dining table, enjoying a meal together. The table is filled with various food items, including four pizzas, a bowl, six bottles, and two cups. The people are enjoying pizza."}, "448320": {"image_id": 448320, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.23431167444696221, "Bleu_3": 0.16487339804051732, "Bleu_4": 0.09829979956142772, "METEOR": 0.2617780195019988, "ROUGE_L": 0.32455029136052693, "CIDEr": 7.302572000910009e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.10714285714285714, "f": 0.11999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image depicts a bathroom with a white toilet situated on the left side of the room. Next to the toilet, there is a sink with a round-shaped sink basin. Above the sink, there are two mirrors mounted on the wall. A roll of toilet paper is placed on the sink."}, "14874": {"image_id": 14874, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.18389242811841477, "Bleu_3": 9.159919831148882e-07, "Bleu_4": 2.056135070108479e-09, "METEOR": 0.23161134863335364, "ROUGE_L": 0.2873485868102288, "CIDEr": 1.8046433680115692e-08, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.21052631578947367, "f": 0.2857142857142857, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "In the image, a man is standing on a snowy slope, wearing a blue jacket and black pants. He is posing in front of two snow skis, which are placed upright next to him. The man appears to be enjoying his time in the snowy environment."}, "373713": {"image_id": 373713, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.14261480656006148, "Bleu_3": 0.07051806934510951, "Bleu_4": 8.856387214393412e-06, "METEOR": 0.17843081410744532, "ROUGE_L": 0.16721491228070173, "CIDEr": 4.772593627080402e-16, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a group of three men sitting in a room. They are engaged in a conversation and playing a game. Two of the men are wearing black shirts. They are sitting at a table, while the third man is sitting on the floor. The men are wearing lanyards, suggesting that they might be attending a convention or conference."}, "539326": {"image_id": 539326, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.18299102222839972, "Bleu_4": 0.1358326617524907, "METEOR": 0.3132289501092905, "ROUGE_L": 0.3756735950731332, "CIDEr": 3.851083946240355e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.21428571428571427, "f": 0.1764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a large herd of cows grazing on a lush green field. The cows are scattered across the field, with some closer to the foreground and others further in the background. The cows are grazing on grass."}, "20059": {"image_id": 20059, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.21070705493664102, "Bleu_3": 0.174191231399375, "Bleu_4": 0.15069149816410912, "METEOR": 0.2581998173093651, "ROUGE_L": 0.2506849315068493, "CIDEr": 1.0057701286369147e-07, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.12903225806451613, "f": 0.19047619047619047, "fn": 27.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features two zebras grazing on grass in a lush green field. The zebras are positioned close to each other, with one zebra in the foreground and the other in the background. They appear to be enjoying their meal in a peaceful environment."}, "530520": {"image_id": 530520, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2209045015297887, "Bleu_3": 0.1611217291451592, "Bleu_4": 0.10531636385451841, "METEOR": 0.2902138266719191, "ROUGE_L": 0.2930344275420336, "CIDEr": 4.847168933957744e-05, "SPICE": {"All": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image depicts three men sitting on the grass, each using a laptop. They are positioned close to each other, with one man on the left side and the other on the right side of the scene."}, "117337": {"image_id": 117337, "Bleu_1": 0.2608695652060492, "Bleu_2": 0.2177862025825042, "Bleu_3": 0.13120402049391547, "Bleu_4": 1.8331704948630108e-05, "METEOR": 0.1337694123056589, "ROUGE_L": 0.19572192513368983, "CIDEr": 0.04370204818375364, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a collage featuring four oranges placed on the table. There is also a cake and a typewriter in the image."}, "256504": {"image_id": 256504, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.16968474448956103, "Bleu_3": 0.0888861127479458, "Bleu_4": 1.1510930649036865e-05, "METEOR": 0.23356803796639133, "ROUGE_L": 0.29756097560975614, "CIDEr": 1.2366893172949348e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.1724137931034483, "f": 0.1851851851851852, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image depicts two people lying on a bed. One person is on the left side of the bed, while the other is on the right side. Both individuals have their laptops open and are likely working, studying, or enjoying some leisure time."}, "265472": {"image_id": 265472, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.1732917482985969, "Bleu_3": 0.09502311009068282, "Bleu_4": 1.2603820262448582e-05, "METEOR": 0.2492871778722619, "ROUGE_L": 0.33862014274385416, "CIDEr": 2.6119179329512494e-05, "SPICE": {"All": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a plate with a delicious breakfast meal consisting of bacon, bananas, and powdered sugar. The bacon is placed on the left side of the plate. Some of the banana slices are on the plate."}, "441083": {"image_id": 441083, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.20935894733588342, "Bleu_3": 0.11752757157807629, "Bleu_4": 0.07439364783947176, "METEOR": 0.24349960532959408, "ROUGE_L": 0.23461538461538461, "CIDEr": 2.1697968578261186e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "In the image, a dog is sticking its head out of a car window, enjoying the breeze and the view outside. The dog is sticking its tongue out as it takes in the surroundings. The dog appears to be wearing a collar.\n\nThe car is driving down the road, with three cars visible in the scene."}, "126958": {"image_id": 126958, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.28419928002220657, "Bleu_3": 0.16199344770305454, "Bleu_4": 1.8410799797294126e-05, "METEOR": 0.18468561443289094, "ROUGE_L": 0.2937534397358283, "CIDEr": 7.11403810091694e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2608695652173913, "f": 0.2926829268292683, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a room with a blue wall. The clock is mounted on the wall. The clock is positioned near the top left corner of the wall. The doorway is not open.\n\nThere is no bed in the room."}, "484075": {"image_id": 484075, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.13572088082697478, "Bleu_4": 0.10155891128878049, "METEOR": 0.23724571358322977, "ROUGE_L": 0.3129988597491448, "CIDEr": 5.164359329764782e-09, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3157894736842105, "f": 0.33333333333333337, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features two desks. On the first desk, there is a computer setup, including a monitor, keyboard, and mouse. On the second desk, there is a computer, keyboard, mouse, monitor, and printer. \n\nThe computer setup includes a keyboard and mouse. \n\nA cell phone is also placed on the desk."}, "274528": {"image_id": 274528, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.10899451514727879, "Bleu_3": 0.06113200612973375, "Bleu_4": 8.181048022484049e-06, "METEOR": 0.1917470016951887, "ROUGE_L": 0.17468499427262313, "CIDEr": 1.7747859214010632e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.07142857142857142, "f": 0.11111111111111112, "fn": 26.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features two trucks parked next to two cars. The trucks are white and one of them is displaying a poster for a cycling event. The cars are white and blue. There are several bicycles in the scene, with one bicycle positioned in front of the truck. A cycling event is being advertised."}, "286820": {"image_id": 286820, "Bleu_1": 0.222222222217284, "Bleu_2": 0.07106690545027299, "Bleu_3": 4.897285819048216e-07, "Bleu_4": 1.2931659652745186e-09, "METEOR": 0.14450897060517381, "ROUGE_L": 0.1643097643097643, "CIDEr": 6.318956625550987e-09, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.4, "f": 0.4137931034482759, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two smartphones placed side by side on a green cloth. Both phones have their screens turned on. The home screen of one of the smartphones showcases an iPhone. The smartphones are likely used to make calls, send texts, and access the internet."}, "69236": {"image_id": 69236, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.06741998624480901, "Bleu_3": 4.72827747167074e-07, "Bleu_4": 1.2595484949270663e-09, "METEOR": 0.16311617091579445, "ROUGE_L": 0.12629399585921322, "CIDEr": 7.776930286971987e-08, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.17857142857142858, "f": 0.21739130434782608, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features three benches situated on the sidewalk. One of the benches is near a grassy area. Another bench is positioned under a tree, providing shade and a comfortable spot for people to sit and relax.\n\nThere is no city skyline in the scene."}, "333237": {"image_id": 333237, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.22522130822577494, "Bleu_3": 0.1664467895387212, "Bleu_4": 0.10176289493198208, "METEOR": 0.21581413193766344, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.3260341651450956e-07, "SPICE": {"All": {"pr": 0.12, "re": 0.15, "f": 0.1333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image is a photograph of a bedroom with a large bed and two white bedspreads. The bed is positioned towards the left side of the room. There are two chairs in the room, one located near the center and the other towards the right side."}, "285258": {"image_id": 285258, "Bleu_1": 0.5483870967565037, "Bleu_2": 0.35771076198364365, "Bleu_3": 0.16401692733273615, "Bleu_4": 1.9924021232863833e-05, "METEOR": 0.2842331873190697, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.001662421799650342, "SPICE": {"All": {"pr": 0.32, "re": 0.2857142857142857, "f": 0.30188679245283023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.46153846153846156, "f": 0.46153846153846156, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image depicts a scene with four dogs playing on a grassy field. The dogs are wrestling with each other. There is a large black dog and a small brown dog."}, "574454": {"image_id": 574454, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.10496165562800558, "Bleu_3": 5.748366509372991e-07, "Bleu_4": 1.3511066263448826e-09, "METEOR": 0.18705035971223025, "ROUGE_L": 0.2046979865771812, "CIDEr": 8.866922057158382e-17, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3157894736842105, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image captures a scene at the beach. There are no people in the scene. The beach is surrounded by water. There are no water sports or parasailing in the scene. There are no windsurfers or parasailers in the scene. However, there is one person riding a bike on the beach. There are no waves or air in the scene."}, "57703": {"image_id": 57703, "Bleu_1": 0.3214285714170919, "Bleu_2": 0.2439750182282586, "Bleu_3": 0.13179708049535738, "Bleu_4": 1.7395797374984622e-05, "METEOR": 0.2342057550847383, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.010499889510134136, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts three people walking their dogs on a dirt trail in a forest. The people are walking their dogs. The dogs are walking on a leash."}, "70294": {"image_id": 70294, "Bleu_1": 0.423076923060651, "Bleu_2": 0.3186510027137757, "Bleu_3": 0.23326354095212345, "Bleu_4": 0.15326859947301405, "METEOR": 0.26148611469300653, "ROUGE_L": 0.439323010442924, "CIDEr": 0.054469797829465746, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16, "f": 0.14545454545454545, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a blue bus parked next to a building. The bus is prominently displayed in the foreground, occupying a significant portion of the scene."}, "279769": {"image_id": 279769, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.36115755924124826, "Bleu_3": 0.26511346924327256, "Bleu_4": 0.17470942956955962, "METEOR": 0.25658275001677794, "ROUGE_L": 0.3769309989701339, "CIDEr": 0.16537155578445792, "SPICE": {"All": {"pr": 0.2, "re": 0.1875, "f": 0.19354838709677422, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a dining table with a banana placed on top of a paper towel. The size of the banana is small."}, "541474": {"image_id": 541474, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.08681823924888467, "Bleu_4": 1.1239895308238822e-05, "METEOR": 0.19948357826707233, "ROUGE_L": 0.2924657534246575, "CIDEr": 3.696763520703087e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "In the image, a person is doing snowboarding on a snow-covered slope. The person is wearing a blue and white jacket and appears to be enjoying the thrill of snowboarding. The skis can be seen beneath the person as they glide down the slope."}, "217561": {"image_id": 217561, "Bleu_1": 0.1891891891866326, "Bleu_2": 0.10181616234269503, "Bleu_3": 0.05241235214072348, "Bleu_4": 6.71058915259362e-06, "METEOR": 0.15523636487553566, "ROUGE_L": 0.19321266968325795, "CIDEr": 3.2714440588723824e-24, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.21428571428571427, "f": 0.2553191489361702, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts two tables set for a meal. On the first table, there is a plate with a toothbrush arranged, along with silverware, napkins, and a toothbrush spread across the table. On the second table, there is a plate with a toothbrush arranged, along with a fork, knife, napkin, and a toothbrush spread across the table. Besides the tables, there are cups and wine glasses. There are also four bottles on the tables."}, "303778": {"image_id": 303778, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.22228757208608238, "Bleu_3": 0.1446278221289709, "Bleu_4": 1.5844501336948676e-05, "METEOR": 0.3040606505828232, "ROUGE_L": 0.26116207951070336, "CIDEr": 8.329963250395506e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a baseball game in progress, with two baseball players standing on the field. Both players are holding a bat and wearing a white baseball uniform. They appear to be preparing for a game. In the background, a person can be seen, possibly a baseball player throwing a ball."}, "40426": {"image_id": 40426, "Bleu_1": 0.17777777777382722, "Bleu_2": 0.11009637651016171, "Bleu_3": 0.06556808986482039, "Bleu_4": 9.051219068884178e-06, "METEOR": 0.1699892035666639, "ROUGE_L": 0.2350674373795761, "CIDEr": 1.7429992823497567e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.17857142857142858, "f": 0.20833333333333331, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a blender on the kitchen counter. The blender is placed on the left side of the counter. There is a bowl of ice cream on the right side. A spoon is resting inside the bowl of ice cream, ready to be used."}, "324291": {"image_id": 324291, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.17425375883480393, "Bleu_3": 9.362407257485935e-07, "Bleu_4": 2.1850683240960956e-09, "METEOR": 0.22265565386990374, "ROUGE_L": 0.3468372423596305, "CIDEr": 6.647569489495262e-05, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.18181818181818182, "f": 0.24242424242424246, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "In the image, a man and a young girl are riding on the back of two ponies in a grassy field. The man is holding a rope. The girl is wearing a helmet for safety while riding the pony."}, "96241": {"image_id": 96241, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.06317667074948415, "Bleu_3": 4.277412148886299e-07, "Bleu_4": 1.1185188895571612e-09, "METEOR": 0.1278062669808357, "ROUGE_L": 0.14796846573681016, "CIDEr": 1.7670919915541218e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2, "f": 0.23076923076923075, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a woman standing next to a black and red train on the tracks. The train appears to be a steam engine, capturing the attention of the onlookers. The woman is wearing a white dress. The children are standing close to the woman. The children are standing on the train tracks."}, "326911": {"image_id": 326911, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.22447181760045806, "Bleu_3": 0.18316251491261745, "Bleu_4": 0.15744448347846624, "METEOR": 0.29373453566818825, "ROUGE_L": 0.33764950084017, "CIDEr": 3.804634273194137e-07, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.22727272727272727, "f": 0.2857142857142857, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "In the image, there are two dogs standing on a sidewalk next to a bicycle. One dog is positioned closer to the left side of the bicycle, while the other dog is on the right side. The bicycle is parked on the sidewalk."}, "209222": {"image_id": 209222, "Bleu_1": 0.1799999999982, "Bleu_2": 0.11281521496241939, "Bleu_3": 0.08659505513116916, "Bleu_4": 0.06694331273358549, "METEOR": 0.16800412196314315, "ROUGE_L": 0.1728045325779037, "CIDEr": 1.8367079026948975e-49, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a man sitting on a bench. He appears to be relaxing and enjoying the surroundings. There are several other people in the scene, some sitting on benches and others standing or walking around. \n\nThere are a total of nine people in the scene. Some of them are sitting on benches, some are walking, and one person is playing a guitar. \n\nThe man is sitting on a bench. The person is also sitting on a bench. The person is sitting on a bench as well. The person is sitting on a chair. The person is playing a guitar."}, "362293": {"image_id": 362293, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 8.435451529716314e-07, "Bleu_4": 1.8804896236814876e-09, "METEOR": 0.21190128253075838, "ROUGE_L": 0.24582613701784684, "CIDEr": 5.5887425505477965e-09, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.4, "f": 0.4137931034482759, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image depicts two horse-drawn carriages traveling down a city street. Each carriage is being pulled by a horse. Two people are riding in each carriage. The horse is pulling the carriage. \n\nThere are several cars parked or driving along the street. One car is parked in front of a sign."}, "144481": {"image_id": 144481, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.14227759830242195, "Bleu_3": 8.178816083045061e-07, "Bleu_4": 1.974432115677638e-09, "METEOR": 0.1877463322326605, "ROUGE_L": 0.17954378219278885, "CIDEr": 2.508147243978225e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image showcases a museum display featuring five vases. The vases are brown. A lion is adorned on the vases. They are positioned on a blue table.\n\nIn addition to the vases, there are twelve people in the scene."}, "433804": {"image_id": 433804, "Bleu_1": 0.12745098039090735, "Bleu_2": 0.06152782041354102, "Bleu_3": 3.3577448151113446e-07, "Bleu_4": 7.863700541441346e-10, "METEOR": 0.11811239815374143, "ROUGE_L": 0.08597603946441155, "CIDEr": 6.937815745628582e-50, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts two boats speeding through the water. The boats are white. One boat is surrounded by green trees, while the other is surrounded by palm trees. Both boats are speedboats, moving swiftly through the water. \n\nThere are four people on the boats. Some of the people are eating a sandwich, while others are sitting in a chair. One person is holding a red bag, and another person is putting on a helmet. The people are enjoying the boat ride and the beautiful scenery around them.\n\nThe scene also includes palm trees and water. The overall scenery is picturesque and serene."}, "142815": {"image_id": 142815, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.21602468994265056, "Bleu_3": 0.12395961884573889, "Bleu_4": 1.4113991930504503e-05, "METEOR": 0.26509910413639265, "ROUGE_L": 0.3042123074182919, "CIDEr": 1.2003273937491888e-09, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.20833333333333334, "f": 0.2631578947368421, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "In the image, there are two men sitting on a bed. One of the men is holding a camera, possibly filming the other man who is sitting next to him. The man holding the camera is wearing a gray shirt, while the man being filmed is also wearing a gray shirt."}, "85292": {"image_id": 85292, "Bleu_1": 0.5499999999725, "Bleu_2": 0.24061325158054672, "Bleu_3": 1.476121796196066e-06, "Bleu_4": 3.708765841904931e-09, "METEOR": 0.26603325415676954, "ROUGE_L": 0.34040178571428575, "CIDEr": 0.2976871569239045, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.35, "f": 0.3333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a train traveling down the tracks. The train is red and yellow. The train is carrying cargo."}, "500423": {"image_id": 500423, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.2708012801434743, "Bleu_3": 1.4718307202693096e-06, "Bleu_4": 3.46966645479793e-09, "METEOR": 0.24915953114685543, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.03053260207253848, "SPICE": {"All": {"pr": 0.3, "re": 0.24, "f": 0.2666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a train station with a red and white train parked on the platform. The train is the main focus of the scene."}, "196280": {"image_id": 196280, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.19069251784483274, "Bleu_3": 0.11914512632603338, "Bleu_4": 1.416592339557592e-05, "METEOR": 0.2015831219997219, "ROUGE_L": 0.25258799171842644, "CIDEr": 1.0905060676278247e-07, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.23076923076923078, "f": 0.21052631578947367, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a boy standing in a kitchen, preparing a meal. The boy is putting food in a pot. He is reaching for a pot filled with a sourdough loaf. The kitchen is well-equipped with three pots filled with different types of sourdough bread."}, "84752": {"image_id": 84752, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.11875421719606402, "Bleu_3": 7.186291482531253e-07, "Bleu_4": 1.7796237394908679e-09, "METEOR": 0.12273361227336121, "ROUGE_L": 0.25558659217877094, "CIDEr": 8.617767238305896e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a US Air Force fighter jet on display in a parking lot. The fighter jet is red and white. It is prominently positioned in the center of the scene, drawing attention to its impressive size and design."}, "222317": {"image_id": 222317, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.1662583773973145, "Bleu_4": 0.10629480218956691, "METEOR": 0.3112201895630149, "ROUGE_L": 0.3655430711610487, "CIDEr": 7.473379961550166e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a cozy living room scene with a brown dog comfortably laying on a couch. The dog is positioned on the couch. The couch is situated in front of a window, allowing natural light to come in."}, "544421": {"image_id": 544421, "Bleu_1": 0.18604651162358038, "Bleu_2": 0.06655583256240599, "Bleu_3": 4.7628049328452643e-07, "Bleu_4": 1.2819825042675062e-09, "METEOR": 0.1477728416393448, "ROUGE_L": 0.24286662242866625, "CIDEr": 5.272358617843915e-06, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a cake that resembles a mountain. The cake is adorned with frosting. The cake is placed on a white plate. There is no mountain or waterfall in the image. There is no dining table, frosting, or dessert in the image."}, "526827": {"image_id": 526827, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2065984676302324, "Bleu_3": 0.12983940805705807, "Bleu_4": 0.08711822053257058, "METEOR": 0.2207685407322518, "ROUGE_L": 0.29306794783802337, "CIDEr": 3.6619496012115375e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23529411764705882, "f": 0.2580645161290323, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a pair of scissors with a red handle. The scissors are positioned in the center of the scene, and they appear to be the main focus of the image. They are placed on top of a blue surface."}, "527529": {"image_id": 527529, "Bleu_1": 0.49999999997222233, "Bleu_2": 0.29704426287601454, "Bleu_3": 0.17667460064728172, "Bleu_4": 2.4623953023773364e-05, "METEOR": 0.255188681331776, "ROUGE_L": 0.3765432098765432, "CIDEr": 0.21048920378656727, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1875, "f": 0.17142857142857143, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "In the image, a white cat is exploring a black purse. The cat is positioned on the floor."}, "152785": {"image_id": 152785, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.26874192493571336, "Bleu_3": 0.18539772256586728, "Bleu_4": 2.0962825117217268e-05, "METEOR": 0.28283072093427175, "ROUGE_L": 0.35942760942760943, "CIDEr": 9.498341952678683e-05, "SPICE": {"All": {"pr": 0.28, "re": 0.30434782608695654, "f": 0.2916666666666667, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a herd of seven elephants walking across a field during a beautiful sunset. The elephants are moving in a line. Some elephants are closer to trees, while others are further in the scene."}, "516212": {"image_id": 516212, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.3429971702750737, "Bleu_3": 0.30552895439523625, "Bleu_4": 0.2704204918425052, "METEOR": 0.4348473219872874, "ROUGE_L": 0.5279307631785994, "CIDEr": 0.0012727483972211227, "SPICE": {"All": {"pr": 0.3, "re": 0.17647058823529413, "f": 0.22222222222222224, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a cat sitting on top of a microwave oven in a kitchen. The cat is enjoying its elevated position on the microwave. The microwave oven is placed on top of a cabinet."}, "403378": {"image_id": 403378, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.2225972810858974, "Bleu_3": 0.11228555469706271, "Bleu_4": 1.4284767866790581e-05, "METEOR": 0.2665978733261029, "ROUGE_L": 0.2848249027237354, "CIDEr": 2.7634434136446668e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "In the image, a woman is standing in front of a mirror, holding it up to her face. She is looking at her reflection. There are several lit candles around her, creating a cozy and intimate atmosphere."}, "216051": {"image_id": 216051, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.17806548534627567, "Bleu_3": 0.11759123766316994, "Bleu_4": 0.08087891600185095, "METEOR": 0.29342564952799993, "ROUGE_L": 0.3165307635285397, "CIDEr": 1.4822471239606077e-06, "SPICE": {"All": {"pr": 0.07058823529411765, "re": 0.20689655172413793, "f": 0.10526315789473684, "fn": 23.0, "numImages": 1.0, "fp": 79.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 31.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.038461538461538464, "re": 0.14285714285714285, "f": 0.060606060606060615, "fn": 6.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.17857142857142858, "re": 0.4166666666666667, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}}, "caption": "In the image, a woman is sitting on a bench. She is wearing purple pants. The woman's shirt is purple. She is accompanied by her dog, which appears to be a pit bull. They are enjoying each other's company."}, "543043": {"image_id": 543043, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.16402518938356242, "Bleu_3": 0.13727641178842917, "Bleu_4": 0.11106691492559417, "METEOR": 0.24350145098710893, "ROUGE_L": 0.21403508771929822, "CIDEr": 9.28475208548955e-12, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features two cars parked in front of a junkyard. The sports car is red and a red mustang is prominently positioned in the foreground. The other car is orange. \n\nThe junkyard is filled with various items, including a boat and a truck. The boat is situated in the back of the scene."}, "392493": {"image_id": 392493, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.1516196087106396, "Bleu_3": 9.363773583417624e-07, "Bleu_4": 2.34826571218133e-09, "METEOR": 0.15693739407775006, "ROUGE_L": 0.31937172774869105, "CIDEr": 0.0011633647805390005, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.10344827586206896, "f": 0.14285714285714288, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts a scene in a city park. A group of people is flying kites, creating a vibrant and colorful atmosphere. There are three kites soaring in the sky."}, "524681": {"image_id": 524681, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.29554023163570037, "Bleu_3": 0.20155867668733007, "Bleu_4": 0.12748547320294246, "METEOR": 0.2921284247311809, "ROUGE_L": 0.36371379897785344, "CIDEr": 0.00036495456929253804, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "In the image, there are five people standing on a sandy beach. Some of the people are playing frisbee and others are walking on the beach. A kite is flying high in the sky."}, "265816": {"image_id": 265816, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.19802950858942228, "Bleu_3": 0.10701301835858801, "Bleu_4": 1.4100581946635955e-05, "METEOR": 0.27745726111529023, "ROUGE_L": 0.3604135893648449, "CIDEr": 0.000600066452787444, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.17857142857142858, "f": 0.1923076923076923, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image depicts a man driving a horse-drawn carriage down a street. The horse is positioned in front of the carriage. The man is seated in the horse-drawn carriage. He is holding a hat."}, "528984": {"image_id": 528984, "Bleu_1": 0.49999999997222233, "Bleu_2": 0.29704426287601454, "Bleu_3": 0.17667460064728172, "Bleu_4": 2.4623953023773364e-05, "METEOR": 0.1868714808026607, "ROUGE_L": 0.35672514619883033, "CIDEr": 0.5245814530973618, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.038461538461538464, "f": 0.038461538461538464, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image features a ski slope covered in snow. There are no people or snowboarders in the scene."}, "565776": {"image_id": 565776, "Bleu_1": 0.3399999999932, "Bleu_2": 0.204040812239959, "Bleu_3": 0.12015475121483696, "Bleu_4": 0.07794374109075407, "METEOR": 0.17588982946200102, "ROUGE_L": 0.31955762514551805, "CIDEr": 1.4106001019946682e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.09090909090909091, "f": 0.12121212121212123, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image depicts a large kitchen with a center island that has a sink. The kitchen is well-equipped with various appliances and utensils. There is a refrigerator on the right side of the kitchen, and an oven on the left side. The sink provides a place to wash your hands."}, "208132": {"image_id": 208132, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.2963188789875593, "Bleu_3": 0.2507171403651364, "Bleu_4": 0.201816708078193, "METEOR": 0.3857526049814784, "ROUGE_L": 0.5024021962937543, "CIDEr": 9.573136591090243e-06, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.07407407407407407, "f": 0.0909090909090909, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a person sitting at a dining table with a plate of food in front of them. The meal consists of a sandwich, a side of fries, and a pickle. There is a bottle of ketchup on the table."}, "37017": {"image_id": 37017, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.3746343246229452, "Bleu_3": 0.3244033314624714, "Bleu_4": 0.29512829626658804, "METEOR": 0.45823118524763645, "ROUGE_L": 0.4894237782640408, "CIDEr": 2.143965937035232e-05, "SPICE": {"All": {"pr": 0.43478260869565216, "re": 0.35714285714285715, "f": 0.39215686274509803, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 10.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.7, "f": 0.7, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image features a black dog with a red collar standing in a kitchen. The dog is looking at the camera. The kitchen is well-equipped with a refrigerator on the left side and a white oven in the background."}, "20536": {"image_id": 20536, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.308606699915489, "Bleu_3": 0.20330638248996402, "Bleu_4": 0.1263236816956828, "METEOR": 0.3129748005588276, "ROUGE_L": 0.34885620915032683, "CIDEr": 0.0002700098848567257, "SPICE": {"All": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image depicts a bathroom with a white toilet positioned in the center of the room. The toilet is surrounded by several rolls of toilet paper. Some rolls of toilet paper are placed on the floor."}, "289264": {"image_id": 289264, "Bleu_1": 0.17948717948257728, "Bleu_2": 0.1536773702983718, "Bleu_3": 0.08610057243934667, "Bleu_4": 1.1539285110641761e-05, "METEOR": 0.24394894057855288, "ROUGE_L": 0.3287143956889915, "CIDEr": 8.215405831956652e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.23529411764705882, "f": 0.23529411764705882, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a dog sitting on a window sill. The dog is looking out of the window, enjoying the view of a forest. The dog is wearing a red collar. The window provides a view of the outdoors."}, "18014": {"image_id": 18014, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2530600894303559, "Bleu_3": 0.1333606949819784, "Bleu_4": 1.7379110739620047e-05, "METEOR": 0.20394491193797482, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.003451857155838427, "SPICE": {"All": {"pr": 0.03333333333333333, "re": 0.043478260869565216, "f": 0.03773584905660378, "fn": 22.0, "numImages": 1.0, "fp": 29.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image features a pizza with various toppings, including peppers. The toppings on the pizza include pepperoni, mushrooms, onions, and olives. The pizza is placed on a cardboard box."}, "381123": {"image_id": 381123, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.15191090505870355, "Bleu_3": 0.08468336402372788, "Bleu_4": 1.1318741601733969e-05, "METEOR": 0.2665978733261029, "ROUGE_L": 0.28416149068322977, "CIDEr": 8.703518337931724e-06, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.20833333333333334, "f": 0.21739130434782608, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts a beautiful beach scene with a row of colorful kayaks and a canoe lined up on the sandy shore. There are a total of nine kayaks and canoes in various sizes and colors, creating an eye-catching display."}, "19608": {"image_id": 19608, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.214984853867146, "Bleu_3": 0.1118838140362068, "Bleu_4": 1.4463984657639369e-05, "METEOR": 0.2742042640006021, "ROUGE_L": 0.32670237184391737, "CIDEr": 0.0014233592440112803, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a bird swimming in the water. The bird is possibly a heron. In the background, a person is riding a bicycle, enjoying the peaceful surroundings. The bicycle is positioned in the water."}, "497348": {"image_id": 497348, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.21879748724223508, "Bleu_3": 0.10133876550919195, "Bleu_4": 1.2331859801407647e-05, "METEOR": 0.2742542918168505, "ROUGE_L": 0.2635802469135803, "CIDEr": 1.3468922112821336e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a car parked on the side of the road. The car is red. The car is positioned close to a \"No Through Road\" sign, which is mounted on a wooden pole. The street is empty, with no other vehicles or pedestrians visible in the scene."}, "437594": {"image_id": 437594, "Bleu_1": 0.333333333325926, "Bleu_2": 0.24618298195313262, "Bleu_3": 0.17797917821554635, "Bleu_4": 0.10763774116165369, "METEOR": 0.22498605521139764, "ROUGE_L": 0.34078212290502796, "CIDEr": 8.269976025836589e-07, "SPICE": {"All": {"pr": 0.07894736842105263, "re": 0.15789473684210525, "f": 0.10526315789473684, "fn": 16.0, "numImages": 1.0, "fp": 35.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a woman sitting at a desk, working on a laptop computer. The woman is working on her laptop. The laptop is placed on the desk in front of her.\n\nIn addition to the laptop, there are no other items in the scene."}, "413404": {"image_id": 413404, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.06262242910727484, "Bleu_3": 4.309444049146827e-07, "Bleu_4": 1.1363330167951873e-09, "METEOR": 0.15773377827575707, "ROUGE_L": 0.18654434250764526, "CIDEr": 3.082185522491508e-11, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts an outdoor area with four benches arranged in a circular formation. There are four benches in total, with one on the left side, one in the middle, and two on the right side of the scene. The benches are positioned close to each other, creating a welcoming atmosphere."}, "332775": {"image_id": 332775, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.09897882079639587, "Bleu_3": 0.057699421416016236, "Bleu_4": 7.872924608075425e-06, "METEOR": 0.24044012667135148, "ROUGE_L": 0.25894481503941785, "CIDEr": 1.5371048722795746e-12, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.1724137931034483, "f": 0.18181818181818185, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "In the image, a cat is sitting inside an open suitcase, which is placed on a bed. The cat appears to be looking out of the suitcase, possibly curious about its surroundings or seeking attention. The bed occupies the majority of the scene, with the suitcase and the cat being the main entities."}, "530624": {"image_id": 530624, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.21110016545407168, "Bleu_3": 0.14069728646721347, "Bleu_4": 1.7313061339444437e-05, "METEOR": 0.2197211348361624, "ROUGE_L": 0.3528925619834711, "CIDEr": 0.0001933215214985611, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.14285714285714285, "f": 0.17142857142857143, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a brown dog lying on a bed. The dog is partially covered by a blanket and appears to be sleeping or resting comfortably. The bed is adorned with a floral comforter."}, "139113": {"image_id": 139113, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.1426954482435772, "Bleu_3": 0.0933885022827419, "Bleu_4": 0.0638514902478946, "METEOR": 0.2566017054934232, "ROUGE_L": 0.3073908174692049, "CIDEr": 1.5902663958978594e-09, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.034482758620689655, "f": 0.045454545454545456, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "In the image, there are two men playing soccer on two different soccer fields. The first man is wearing a blue shirt and black shorts, while the second man is wearing a red shirt and blue shorts. Both men are holding a soccer ball and appear to be preparing to kick it."}, "192858": {"image_id": 192858, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.2613286875248416, "Bleu_3": 0.12053222932010679, "Bleu_4": 1.4651479869824228e-05, "METEOR": 0.24193399343361255, "ROUGE_L": 0.35905820797907134, "CIDEr": 9.921520763893285e-06, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a group of six girls gathered around a dining table, enjoying a meal together. They are sharing a large pizza, which is placed in the center of the table. The girls are seated on chairs surrounding the table."}, "482742": {"image_id": 482742, "Bleu_1": 0.3015873015825145, "Bleu_2": 0.184526906467268, "Bleu_3": 0.08233728119138711, "Bleu_4": 9.8210874725219e-06, "METEOR": 0.20670354763019375, "ROUGE_L": 0.21403508771929822, "CIDEr": 6.020436127251627e-12, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.21212121212121213, "f": 0.21875, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.46153846153846156, "f": 0.4444444444444445, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image depicts two men on a city street. \n\nThe first man is riding a bicycle and carrying a box on the back of his bike. He is wearing a blue shirt. \n\nThe second man is riding a motorcycle and carrying a laptop. He is wearing a suit.\n\nThere is no bottle or backpack in the scene.\n\nThe street is lined with buildings."}, "398818": {"image_id": 398818, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.10223972648618562, "Bleu_3": 6.39332019360638e-07, "Bleu_4": 1.6088986597188547e-09, "METEOR": 0.1499540220963398, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.3636007722356797e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a countertop with three ripe bananas displayed. The bananas are placed next to each other. One of the bananas has a Chiquita sticker on it, indicating that it is a Chiquita brand banana. The bananas appear to be ripe."}, "305871": {"image_id": 305871, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.17614871215260033, "Bleu_3": 8.770015703255858e-07, "Bleu_4": 1.967646828106159e-09, "METEOR": 0.19235811104175835, "ROUGE_L": 0.2663423153692615, "CIDEr": 1.9500395516237004e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a street corner in San Carlos district, California, with three street signs mounted on a pole. One of the signs indicates \"San Carlos.\" The other sign indicates \"End San Carlos,\" indicating the end of the San Carlos district.\n\nThere is no street in the image."}, "443818": {"image_id": 443818, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.12666009927244304, "Bleu_3": 7.944072943886587e-07, "Bleu_4": 2.0053583652894944e-09, "METEOR": 0.19233517180961934, "ROUGE_L": 0.25206611570247933, "CIDEr": 9.414082223476227e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a dog lying in a bed. The dog is brown and appears to be relaxed. The bed is positioned on the floor, providing a comfortable spot for the dog to rest."}, "421109": {"image_id": 421109, "Bleu_1": 0.17460317460040317, "Bleu_2": 0.05306769483824368, "Bleu_3": 3.587375769234853e-07, "Bleu_4": 9.365799152489659e-10, "METEOR": 0.17623806797601024, "ROUGE_L": 0.15762273901808782, "CIDEr": 8.209951959193619e-18, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.21052631578947367, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts four horses standing in a grassy field. The horses are brown and black. They are enjoying their time in the open field, possibly grazing on the grass. In the background, there are mountains, trees, and a fence. Some of the horses and trees are closer to the foreground, while the mountains, trees, and the saratoga horse races are further away."}, "416660": {"image_id": 416660, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2474358296475945, "Bleu_3": 0.15751292285925483, "Bleu_4": 0.0960058473220571, "METEOR": 0.21423129204192884, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.2336487875674417e-09, "SPICE": {"All": {"pr": 0.375, "re": 0.46153846153846156, "f": 0.41379310344827586, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image is a photograph of a city street. There are five people standing in front of a store. The people are standing closer to the left side of the store. The store has a window with a woman in front of it. The photograph is black and white."}, "322845": {"image_id": 322845, "Bleu_1": 0.19736842105003463, "Bleu_2": 0.15389675281073467, "Bleu_3": 0.11696764135353005, "Bleu_4": 0.08137220475607798, "METEOR": 0.27378662951406496, "ROUGE_L": 0.23542024013722126, "CIDEr": 2.8836400274831007e-25, "SPICE": {"All": {"pr": 0.125, "re": 0.29411764705882354, "f": 0.17543859649122806, "fn": 12.0, "numImages": 1.0, "fp": 35.0, "tp": 5.0}, "Relation": {"pr": 0.0625, "re": 0.14285714285714285, "f": 0.08695652173913043, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a stop sign prominently displayed in front of a building. The stop sign is red. A railroad crossing sign is combined with the stop sign. The building is in the background. The stop sign is combined with the building.\n\nThe stop sign is positioned on the right side of the scene, with the building in the background. The building appears to be old and rusted, adding a sense of history to the scene."}, "304361": {"image_id": 304361, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.18314741859482847, "Bleu_3": 0.12461581769751784, "Bleu_4": 1.3956847546700087e-05, "METEOR": 0.21250168845213005, "ROUGE_L": 0.2738496071829405, "CIDEr": 8.200287104124032e-12, "SPICE": {"All": {"pr": 0.24, "re": 0.2727272727272727, "f": 0.2553191489361702, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a child standing in a room. The child is holding a remote control and appears to be focused on it. The remote can be used for controlling a television. The child is possibly playing a video game or adjusting the television settings.\n\nThere is no chair or backpack in the room."}, "446917": {"image_id": 446917, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.13801311186458243, "Bleu_3": 0.08243669901955125, "Bleu_4": 1.1414633188359127e-05, "METEOR": 0.1669245535043262, "ROUGE_L": 0.29652777777777783, "CIDEr": 0.0004524854868273718, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.21052631578947367, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a blue and yellow backpack with a banana sticking out of it. A ripe banana is clearly visible. The backpack is placed on the ground. A bottle of lotion is inside the backpack."}, "234676": {"image_id": 234676, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.21931085605462405, "Bleu_3": 0.15089125644562476, "Bleu_4": 0.11377833938419385, "METEOR": 0.20768246174883714, "ROUGE_L": 0.3342465753424657, "CIDEr": 2.3268296977784646e-07, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.17391304347826086, "f": 0.19999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a lively beach scene with seven people sitting on a beach. Some of the people are playing in the water, while others are sitting on the beach. There are surfboards near the people. A boat is also present in the scene."}, "343692": {"image_id": 343692, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.26052505285439387, "Bleu_3": 0.20119942896806087, "Bleu_4": 0.16057799674555318, "METEOR": 0.25538374804225045, "ROUGE_L": 0.28175519630484985, "CIDEr": 5.0674971205775154e-11, "SPICE": {"All": {"pr": 0.375, "re": 0.14285714285714285, "f": 0.20689655172413796, "fn": 18.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a motor scooter parked in front of a yellow building. The scooter is positioned close to the building, and it appears to be the main focus of the scene. The scooter is parked on the side of the road, and there are no other vehicles visible in the image."}, "293011": {"image_id": 293011, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.2235033479141667, "Bleu_3": 0.10354246916903509, "Bleu_4": 1.2603051731241745e-05, "METEOR": 0.28155493538351734, "ROUGE_L": 0.3244372684965333, "CIDEr": 1.1063985971006519e-06, "SPICE": {"All": {"pr": 0.11904761904761904, "re": 0.18518518518518517, "f": 0.14492753623188406, "fn": 22.0, "numImages": 1.0, "fp": 37.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image features a birthday cake designed to look like an airplane. The cake is decorated with blue and white frosting, and it is shaped to resemble a large plane. The cake is placed on a red tray, and there are lit candles on top of it."}, "104625": {"image_id": 104625, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.12521758066643465, "Bleu_3": 0.07318524682825046, "Bleu_4": 1.0012706930582776e-05, "METEOR": 0.2544604001720048, "ROUGE_L": 0.2952973720608575, "CIDEr": 4.995464085938122e-07, "SPICE": {"All": {"pr": 0.6, "re": 0.1935483870967742, "f": 0.2926829268292683, "fn": 25.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.4166666666666667, "f": 0.5555555555555556, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "In the image, there are two cats sitting on top of a television. They are attentively watching a tv show on the screen. The cats are captivated by the show.\n\nThere is no soccer game or people playing soccer in the scene."}, "175612": {"image_id": 175612, "Bleu_1": 0.3124999999804688, "Bleu_2": 0.20412414521874855, "Bleu_3": 0.14384239565657908, "Bleu_4": 2.1874057154605617e-05, "METEOR": 0.18732143608718646, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.24468175018882954, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man holding a skateboard. The man appears to be a cartoon character."}, "43448": {"image_id": 43448, "Bleu_1": 0.45283018867070135, "Bleu_2": 0.36141955243631635, "Bleu_3": 0.2486192701868678, "Bleu_4": 0.1742564663784162, "METEOR": 0.2722918333817609, "ROUGE_L": 0.3801699716713881, "CIDEr": 3.5842664586261443e-06, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.2857142857142857, "f": 0.32, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image depicts two elephants in a zoo enclosure. The elephants are standing next to each other, with one of them being larger, possibly an adult, and the other being smaller, likely a baby elephant. They are standing next to a tree and a rock respectively. The elephants are walking and eating leaves."}, "528705": {"image_id": 528705, "Bleu_1": 0.11320754716874334, "Bleu_2": 0.07342230982073929, "Bleu_3": 3.728558106318585e-07, "Bleu_4": 8.4226039664854e-10, "METEOR": 0.12720910000155367, "ROUGE_L": 0.137582162649826, "CIDEr": 5.402366989382774e-54, "SPICE": {"All": {"pr": 0.3, "re": 0.2857142857142857, "f": 0.2926829268292683, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features three people in different positions. Person 1 is wearing a black coat and holding a cell phone, talking on it and enjoying their time with it. Person 2 is also wearing a black coat and holding a cell phone, taking a selfie. There is a dog with person 2, and they are enjoying their time together. Person 3 is wearing a red coat and holding a teddy bear, riding a horse and enjoying their time with the teddy bear. The teddy bear is wearing a red and white shirt. The scene is vibrant, with a touch of color added by the red jacket."}, "319221": {"image_id": 319221, "Bleu_1": 0.378378378368152, "Bleu_2": 0.10252078086873168, "Bleu_3": 6.696562432589322e-07, "Bleu_4": 1.7239283526069041e-09, "METEOR": 0.21776467478470385, "ROUGE_L": 0.2293233082706767, "CIDEr": 4.7489509131132285e-05, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2, "f": 0.21428571428571427, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a dining table with four plates filled with various types of food. There are bowls containing a variety of vegetables. The plates are filled with broccoli, carrots, ham, asparagus, and other types of food."}, "338903": {"image_id": 338903, "Bleu_1": 0.30434782607372407, "Bleu_2": 0.23523598443802232, "Bleu_3": 0.13812196234964122, "Bleu_4": 1.905195539272694e-05, "METEOR": 0.23682781562451435, "ROUGE_L": 0.28273464658169173, "CIDEr": 0.051114770082196025, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a yellow and white plate filled with sliced bananas and cereal. The bananas and cereal are spread across the plate."}, "364993": {"image_id": 364993, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.13334123550086785, "Bleu_4": 1.6132673522067715e-05, "METEOR": 0.27088305151353925, "ROUGE_L": 0.32153614457831325, "CIDEr": 6.910582232634971e-05, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.06896551724137931, "f": 0.09523809523809525, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a person's hand holding a delicious-looking sandwich. The sandwich looks like a half sandwich and is filled with meat, lettuce, and pickles. The person's hand is positioned on the top of the sandwich."}, "37616": {"image_id": 37616, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.21718612137747484, "Bleu_3": 0.16553008316495676, "Bleu_4": 0.13733465907666018, "METEOR": 0.29792825013520174, "ROUGE_L": 0.31443298969072164, "CIDEr": 3.649201724906229e-11, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2413793103448276, "f": 0.2545454545454545, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a man standing in a living room. The man is playing a video game and holding a wii remote. He is also holding a box in his hand. The living room is furnished with two couches, a chair, and a dining table. There is also a plant placed in the room."}, "157756": {"image_id": 157756, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.25819888973988653, "Bleu_3": 0.18051655059265087, "Bleu_4": 0.11554716242768162, "METEOR": 0.26259640430807507, "ROUGE_L": 0.37654320987654316, "CIDEr": 0.00026602933373102674, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image does not depict a city street. There is a clock tower towering over the surrounding buildings. The clock is prominently displayed on the side of the tower. \n\nThere are six people in the scene."}, "516508": {"image_id": 516508, "Bleu_1": 0.1538461538441815, "Bleu_2": 0.08939803125238129, "Bleu_3": 0.04720059128142643, "Bleu_4": 6.119208672953316e-06, "METEOR": 0.15526539729920877, "ROUGE_L": 0.1362823949955317, "CIDEr": 1.0611494255171645e-28, "SPICE": {"All": {"pr": 0.3125, "re": 0.25, "f": 0.2777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features two clocks mounted on the wall of a building. The clocks have Roman numerals on their faces. The first clock has an ornate frame, giving it a classic and elegant appearance. The second clock has gold Roman numerals and a black dial, also giving it a classic and elegant appearance. The clocks are positioned near a window, allowing natural light to come in. The combination of the clocks and the window creates a beautiful scene."}, "520528": {"image_id": 520528, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.22696949467552002, "Bleu_3": 0.1428653103202315, "Bleu_4": 0.08653548971325163, "METEOR": 0.27033836440830733, "ROUGE_L": 0.21542083578575633, "CIDEr": 2.3194961628969144e-13, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.25, "f": 0.20512820512820512, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "In the image, there is a boy standing on a baseball field. The boy is wearing a blue shirt and a baseball glove on his hand. He is in the process of throwing a baseball, which is captured in mid-air.\n\nThe boy appears to be focused and determined as he prepares to throw the ball."}, "37675": {"image_id": 37675, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.14540168172223333, "Bleu_3": 0.11472822500028991, "Bleu_4": 0.07790345908043068, "METEOR": 0.21990925028916614, "ROUGE_L": 0.25702247191011235, "CIDEr": 4.1989906728847854e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image depicts two horses grazing in a grassy field in front of two churches. The horses are standing in different positions. The brown horse is closer to the foreground and the other brown horse is further back.\n\nThe church features a clock tower."}, "232383": {"image_id": 232383, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.15839698776796265, "Bleu_3": 0.10725768492380099, "Bleu_4": 1.1975220022289e-05, "METEOR": 0.2921244639295976, "ROUGE_L": 0.22149600580973125, "CIDEr": 5.692097156228586e-18, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a cat sitting on a shelf. The cat is gray and white. The cat is looking at the camera. The cat is resting on a shelf.\n\nThere is a laptop computer on a desk. The cat is sitting on top of the laptop.\n\nIn the background, there is no camera or additional laptop. There is no keyboard on the desk."}, "137658": {"image_id": 137658, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.26726124189937955, "Bleu_3": 1.5549130951147036e-06, "Bleu_4": 3.801556631685876e-09, "METEOR": 0.21535704256853766, "ROUGE_L": 0.33116178067318125, "CIDEr": 0.15235980585849776, "SPICE": {"All": {"pr": 0.4, "re": 0.375, "f": 0.38709677419354843, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a person holding a flashlight in their hand. There is no cell phone or pocket in the scene."}, "209322": {"image_id": 209322, "Bleu_1": 0.2424242424168963, "Bleu_2": 0.19462473603439093, "Bleu_3": 0.13469602876696646, "Bleu_4": 1.6894127988830862e-05, "METEOR": 0.20312505908357764, "ROUGE_L": 0.2997542997542998, "CIDEr": 0.0008477690366036341, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.3181818181818182, "f": 0.31111111111111117, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a bathroom with a toilet sitting on a tiled floor. The toilet is white. A towel is hanging above the toilet. A toilet paper holder is hanging on the toilet."}, "128644": {"image_id": 128644, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.24445060351331568, "Bleu_3": 0.11528492999775236, "Bleu_4": 1.4170445561509808e-05, "METEOR": 0.19575207296483027, "ROUGE_L": 0.34957020057306587, "CIDEr": 0.00015495061222917084, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a small airplane parked on a wet runway. The airplane appears to be in a state of disrepair, possibly due to its age and exposure to the elements. The runway is wet, possibly from recent rain or dew."}, "342675": {"image_id": 342675, "Bleu_1": 0.2238805970115839, "Bleu_2": 0.20175619715983573, "Bleu_3": 0.16366135785095984, "Bleu_4": 0.1286558732429286, "METEOR": 0.25273527091128334, "ROUGE_L": 0.26508932882665376, "CIDEr": 4.067598543627304e-20, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.3125, "f": 0.2631578947368421, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a man standing next to a red train at a train station. The man is wearing a hat and appears to be waiting for the train to come to a stop. The train occupies a significant portion of the scene, stretching from the left to the right side of the image. The man is waiting for the train to go to the next station."}, "200234": {"image_id": 200234, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.20759971843926334, "Bleu_3": 0.1481650871060074, "Bleu_4": 0.08893210551641491, "METEOR": 0.22939999412248913, "ROUGE_L": 0.26307277628032344, "CIDEr": 1.41083902264188e-10, "SPICE": {"All": {"pr": 0.28, "re": 0.3684210526315789, "f": 0.3181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image depicts a young boy playing with a frisbee in a park setting. The boy is playing in the woods. He is bending down to pick up the frisbee, which is placed on the ground in front of him.\n\nThe park is equipped with four picnic tables and ten benches scattered throughout the area."}, "545390": {"image_id": 545390, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.14580296087694455, "Bleu_3": 0.0967137615427347, "Bleu_4": 1.184204612229436e-05, "METEOR": 0.22832231805038936, "ROUGE_L": 0.27566171723692706, "CIDEr": 4.1393362746822046e-10, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2608695652173913, "f": 0.2608695652173913, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "In the image, a woman is sitting at a dining table, holding a pizza with a smile on her face. She appears to be enjoying her meal at a restaurant. The dining table is surrounded by several chairs, and there are other people in the scene, including a man."}, "43073": {"image_id": 43073, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.1714985851373884, "Bleu_3": 0.09722777968025705, "Bleu_4": 1.3122070075706762e-05, "METEOR": 0.2810975408639633, "ROUGE_L": 0.24478330658105937, "CIDEr": 0.00036738421463486197, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.14285714285714285, "f": 0.17777777777777778, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "In the image, a young boy with blond hair is sitting in front of a hairdryer, getting his hair blow-dried. The boy is not smiling. The hairdryer is positioned on the child's head."}, "188651": {"image_id": 188651, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.33282011772208075, "Bleu_3": 0.1664955508654934, "Bleu_4": 2.1165084928651254e-05, "METEOR": 0.31333785579948414, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.013579131347810998, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.16666666666666666, "f": 0.2051282051282051, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a brown and white cat sitting underneath a car. The cat is resting comfortably on the ground, undisturbed by the car's surroundings."}, "484551": {"image_id": 484551, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.20701966779852365, "Bleu_3": 0.12132137515765275, "Bleu_4": 0.07851064200963404, "METEOR": 0.23537464053691623, "ROUGE_L": 0.22938079719227877, "CIDEr": 8.08829128219676e-10, "SPICE": {"All": {"pr": 0.4, "re": 0.17142857142857143, "f": 0.24000000000000002, "fn": 29.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.38461538461538464, "f": 0.5263157894736842, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image features a woman wearing an orange shirt and sunglasses, sitting on a boat in the ocean. She is smiling and appears to be enjoying her time on the boat. The woman is positioned in the center of the scene, with the boat occupying the majority of the image."}, "396224": {"image_id": 396224, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.14695129936263138, "Bleu_3": 8.075839294554588e-07, "Bleu_4": 1.904915665082057e-09, "METEOR": 0.15534189409762636, "ROUGE_L": 0.20608108108108109, "CIDEr": 1.0946021549321264e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a dining table with a white tablecloth. A white plate is set for a meal. On the plate, there are various foods, including meat, bread, and vegetables. Silverware, including a fork, knife, and spoon, is placed neatly around the plate."}, "255067": {"image_id": 255067, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.28509785718527286, "Bleu_3": 0.20824846022093968, "Bleu_4": 0.1623493339058779, "METEOR": 0.2794407387628478, "ROUGE_L": 0.3871260199456029, "CIDEr": 0.013903194574193055, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.12903225806451613, "f": 0.19999999999999998, "fn": 27.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.3076923076923077, "f": 0.4444444444444444, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image features a large white polar bear playing in a pool of water. The polar bear is swimming and appears to be enjoying its time in the water."}, "479129": {"image_id": 479129, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.28846974492426525, "Bleu_3": 0.16658760276667972, "Bleu_4": 1.906404251606798e-05, "METEOR": 0.2667409491078521, "ROUGE_L": 0.3320373250388802, "CIDEr": 5.6270161386302544e-05, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.18518518518518517, "f": 0.18867924528301885, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a dessert served on a plate. The dessert consists of a banana cut in half and topped with banana slices. The dessert is served with ice cream, and sauce is also drizzled on the plate."}, "363887": {"image_id": 363887, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.15007505629280368, "Bleu_3": 0.08633422507036763, "Bleu_4": 1.1729176379484152e-05, "METEOR": 0.19629431560823762, "ROUGE_L": 0.23735408560311286, "CIDEr": 9.386024316796057e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11538461538461539, "f": 0.12765957446808512, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a fire truck parked on a dirt road. The fire truck is red. The truck's hood is not open.\n\nThere is no engine in the scene.\n\nThere is no person in the scene."}, "441969": {"image_id": 441969, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.20121090914115633, "Bleu_3": 0.10304662546247204, "Bleu_4": 1.3203823351935061e-05, "METEOR": 0.22621245337885004, "ROUGE_L": 0.2741573033707865, "CIDEr": 1.0769649636304326e-05, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.21739130434782608, "f": 0.27027027027027023, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image depicts an outdoor balcony with a dining table placed on it. A vase of flowers is placed on the dining table. There are five potted plants surrounding the table. A potted plant is placed on the balcony."}, "410225": {"image_id": 410225, "Bleu_1": 0.15476190476006238, "Bleu_2": 0.1057714875232535, "Bleu_3": 0.05148030650445688, "Bleu_4": 6.406334162111562e-06, "METEOR": 0.18661851132827204, "ROUGE_L": 0.19431171786120588, "CIDEr": 1.7542281016912754e-31, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.14285714285714285, "f": 0.17857142857142855, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a table with a cup of food placed on it. A bowl is also on the table, with a spoon placed inside. The cup of food contains a burger, while the other cup has a piece of paper inside. \n\nThere are also three laptops on the table, positioned as follows: laptop 1, laptop 2, and laptop 3.\n\nOverall, the image shows a table with a cup of food, a bowl, and two cups. Additionally, there are three laptops on the table."}, "277073": {"image_id": 277073, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.12712834523041283, "Bleu_3": 0.08480334272970086, "Bleu_4": 0.05852061649365133, "METEOR": 0.16544600511824908, "ROUGE_L": 0.21095100864553315, "CIDEr": 1.2938457753852285e-13, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1111111111111111, "f": 0.12244897959183673, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image depicts a street with various vehicles and pedestrians. A man is riding a motorcycle, and a woman is sitting on the back of the motorcycle. The man is driving the motorcycle. The woman is sitting on the back of the motorcycle. The motorcycle is surrounded by other vehicles, including cars and a truck."}, "41011": {"image_id": 41011, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.21438189279304845, "Bleu_3": 0.10224354888442, "Bleu_4": 1.2630327564106435e-05, "METEOR": 0.23730683291514662, "ROUGE_L": 0.32635903315181036, "CIDEr": 1.306365551711897e-07, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.2222222222222222, "f": 0.2580645161290323, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a man wearing a black suit and riding a horse in a field. The man is wearing a top hat and a suit. The man is riding a horse. The horse is carrying the man. \n\nThere is no house in the scene."}, "343821": {"image_id": 343821, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.12521356825154964, "Bleu_4": 0.09892363781109982, "METEOR": 0.24168626876940147, "ROUGE_L": 0.2506849315068493, "CIDEr": 3.623449739617317e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a family of swans swimming together in a body of water. There are two adult swans and two baby swans. The adult swans are positioned on the left side of the image, while the baby swans are on the right side."}, "530620": {"image_id": 530620, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 0.09798645698584388, "Bleu_4": 0.06724888422819458, "METEOR": 0.21875853750444635, "ROUGE_L": 0.19242902208201892, "CIDEr": 1.782406468725058e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.27586206896551724, "f": 0.3018867924528302, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "In the image, there are three people working together to repair a hot air balloon, a bike, and standing next to a horse. There is a person standing closer to a car. They are also loading a large box onto the truck. The kite is placed on the ground."}, "22113": {"image_id": 22113, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.30181636371173454, "Bleu_3": 0.19474591881120223, "Bleu_4": 2.1282647338648418e-05, "METEOR": 0.26348489269880665, "ROUGE_L": 0.3287143956889915, "CIDEr": 6.027082559134788e-06, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.20833333333333334, "f": 0.2702702702702703, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a fire hydrant sitting on a sidewalk. The fire hydrant is red and green. The top of the fire hydrant is green, while the body is red and green. The hydrant is positioned near the curb."}, "82836": {"image_id": 82836, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1825741858309521, "Bleu_3": 0.14582212643602022, "Bleu_4": 1.648372071572152e-05, "METEOR": 0.2009178405528335, "ROUGE_L": 0.27941368930768223, "CIDEr": 4.6374866251998635e-08, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5555555555555556, "f": 0.6250000000000001, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image depicts a beach scene with three seagulls standing on the sandy shore. The seagulls are spread out along the beach, with some closer to the water's edge and others further inland. The seagulls appear to be enjoying their time on the beach."}, "538925": {"image_id": 538925, "Bleu_1": 0.4848484848337925, "Bleu_2": 0.3256694736294419, "Bleu_3": 0.15068295792388314, "Bleu_4": 1.837671114729021e-05, "METEOR": 0.25564445111616785, "ROUGE_L": 0.370057415231286, "CIDEr": 0.007246260993651623, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.3125, "f": 0.2325581395348837, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image depicts a bed situated in a room. The bed is covered with a white sheet. A blanket is placed on top of the bed. There are no pillows in the scene."}, "440189": {"image_id": 440189, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.358248860405223, "Bleu_3": 0.25220859496075343, "Bleu_4": 0.15082713742508697, "METEOR": 0.32572019431012567, "ROUGE_L": 0.5479041916167665, "CIDEr": 0.03738731441732788, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2, "f": 0.17647058823529413, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a boy standing on a beach. The boy is holding a tennis racket. He is also holding a red frisbee. \n\nThere are two people in the background, scattered across the beach."}, "32777": {"image_id": 32777, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.19026059765810294, "Bleu_3": 0.11313211375448105, "Bleu_4": 1.311113853149677e-05, "METEOR": 0.25399367587658794, "ROUGE_L": 0.22536945812807885, "CIDEr": 6.4144713524175305e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13636363636363635, "f": 0.16666666666666663, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image depicts a train station with two trains parked on the tracks. The trains are blue and yellow. A man is standing next to the train, looking at his cell phone. The man is possibly checking the train schedule or communicating with someone. Another person can be seen in the background."}, "50679": {"image_id": 50679, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.08588393224796005, "Bleu_4": 1.0663135316252687e-05, "METEOR": 0.2130041088552134, "ROUGE_L": 0.22536945812807885, "CIDEr": 7.141476785903692e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "In the image, there is an orange sitting on the ground in a parking lot. The parking lot is filled with several cars parked in various positions. The orange is located near the center of the parking lot, drawing attention to itself.\n\nThere are no other objects or elements in the scene."}, "86250": {"image_id": 86250, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.23371317621462567, "Bleu_3": 0.14903701728545368, "Bleu_4": 0.10085167559360493, "METEOR": 0.19900540672533848, "ROUGE_L": 0.3359559402045633, "CIDEr": 0.0002000618066486978, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.3157894736842105, "f": 0.22641509433962262, "fn": 13.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.3333333333333333, "f": 0.14285714285714288, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image depicts a man meditating in a living room. He is wearing a white shirt. The living room is furnished with a couch on the left side and another couch on the right side."}, "482432": {"image_id": 482432, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.21693045781236706, "Bleu_3": 1.1255782917387133e-06, "Bleu_4": 2.5837130979528137e-09, "METEOR": 0.20222467384388038, "ROUGE_L": 0.28796223446105423, "CIDEr": 0.001249702018880033, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a toothbrush and two tubes in a bathroom scene. The toothbrush is placed next to the tube of Aveeno Active Brightening Skin Daily Exfoliating Scrub. The toothbrush is positioned towards the tube."}, "330880": {"image_id": 330880, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.27080128014916915, "Bleu_3": 0.21881031701985373, "Bleu_4": 0.1599634826606484, "METEOR": 0.3612665573807716, "ROUGE_L": 0.4549627079747562, "CIDEr": 8.35145451340254e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.11764705882352941, "f": 0.125, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a man sitting at a dining table with a large pizza placed in front of him. He is wearing glasses and appears to be staring at the pizza, possibly contemplating whether to eat it or not.\n\nThe table is surrounded by five chairs, some of which are unoccupied."}, "201934": {"image_id": 201934, "Bleu_1": 0.1911764705854239, "Bleu_2": 0.13084449146866245, "Bleu_3": 0.0803524239552018, "Bleu_4": 0.05315215750163827, "METEOR": 0.2401757364957936, "ROUGE_L": 0.23282442748091603, "CIDEr": 2.0485909742132228e-20, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.14285714285714285, "f": 0.1081081081081081, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image depicts a white bus parked in the lot. A fence is next to the bus. There are several cars parked in the lot. The san diego zoo's newest exhibit 0 are in the parking lot. The san francisco ferry or the san francisco bay bridge is farther away.\n\nThere is no street or truck in the scene. A garbage can is next to the fence.\n\n"}, "579462": {"image_id": 579462, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 7.41784871677873e-07, "Bleu_4": 1.7166589196261759e-09, "METEOR": 0.22404420018356389, "ROUGE_L": 0.27128335451080055, "CIDEr": 3.610886446329116e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.16666666666666666, "f": 0.2051282051282051, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "In the image, a woman is standing in a bedroom, holding a blue suitcase. She appears to be in the process of opening the suitcase. The bedroom features a bed in the background and a dresser nearby. There is also a window in the room, allowing natural light to enter."}, "183657": {"image_id": 183657, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2771809306010938, "Bleu_3": 0.15794190135774153, "Bleu_4": 1.7944324828864327e-05, "METEOR": 0.24411762465079964, "ROUGE_L": 0.33493479752916955, "CIDEr": 3.7204769732169603e-06, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.3333333333333333, "f": 0.3846153846153846, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.8, "re": 0.5714285714285714, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image features a bowl filled with an orange floating on a body of water, possibly a lake or a pond. The bowl is placed in the water. The orange is inside the bowl. The color of the oranges is orange."}, "352652": {"image_id": 352652, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.20026720118197788, "Bleu_3": 0.15549997053553327, "Bleu_4": 1.8661962389794467e-05, "METEOR": 0.25784632454790146, "ROUGE_L": 0.3426966292134831, "CIDEr": 0.00075496419021505, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2692307692307692, "f": 0.2978723404255319, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image depicts a snow-covered parking lot with two cars and a parking meter. One of the cars is covered in snow. The parking meter is situated in the middle of the parking lot."}, "339823": {"image_id": 339823, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.29217435488817356, "Bleu_3": 0.23593386214161544, "Bleu_4": 0.17944324828864328, "METEOR": 0.35373934637123106, "ROUGE_L": 0.42927515833919777, "CIDEr": 3.35669394505144e-06, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.16666666666666666, "f": 0.13793103448275862, "fn": 20.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.25, "f": 0.11111111111111112, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a woman wearing an orange dress and holding a black umbrella. She appears to be smiling and enjoying her time outdoors. The umbrella is open. The woman's outfit and the umbrella create a vibrant and colorful scene."}, "203690": {"image_id": 203690, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.2235033479141667, "Bleu_3": 0.16436342448231112, "Bleu_4": 0.13190796805494118, "METEOR": 0.32656970672683594, "ROUGE_L": 0.28259430840502975, "CIDEr": 4.095344432152266e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.25, "f": 0.1764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of a beach scene with a man carrying a surfboard. The man is walking along the beach, likely heading towards the water to surf. There are several other people in the scene. Some of the people are carrying surfboards."}, "344614": {"image_id": 344614, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.24308621739673564, "Bleu_3": 0.1901110702410287, "Bleu_4": 0.14884133138560784, "METEOR": 0.2705139515526457, "ROUGE_L": 0.3286195286195286, "CIDEr": 3.505292112289988e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.06666666666666667, "f": 0.09090909090909091, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image features a clock tower standing tall in the middle of a city. The clock tower is adorned with a large, ornate clock, prominently displaying the words \"London England\". The tower is situated in front of a building, where another clock is also present."}, "573549": {"image_id": 573549, "Bleu_1": 0.1911764705854239, "Bleu_2": 0.14132820350390682, "Bleu_3": 0.09683038650167902, "Bleu_4": 1.0871273198986113e-05, "METEOR": 0.14509002398452495, "ROUGE_L": 0.21096837944664032, "CIDEr": 7.546080732199552e-22, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2857142857142857, "f": 0.2790697674418604, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a group of ten people walking on the sidewalk. Some of the people are walking, some are riding bikes, and one person is riding a skateboard. Some people are talking on the phone, while others are engaged in other activities such as kissing. \n\nThere is a bicycle parked on the sidewalk. The scene also includes a theater, but it is not visible in the image."}, "522941": {"image_id": 522941, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.183339699400327, "Bleu_3": 0.10061584140131913, "Bleu_4": 1.3357103091691184e-05, "METEOR": 0.21662978780338835, "ROUGE_L": 0.2469635627530364, "CIDEr": 9.995186821808554e-05, "SPICE": {"All": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a large elephant standing on a dirt ground, surrounded by a crowd of people. The elephant is adorned with intricate paintings on its face. It is an eye-catching centerpiece of the scene."}, "511662": {"image_id": 511662, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.16300321563702572, "Bleu_3": 0.10649352950670186, "Bleu_4": 0.07279898126120386, "METEOR": 0.2171117443569609, "ROUGE_L": 0.23135271807838179, "CIDEr": 8.339306348320166e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.8333333333333334, "f": 0.7142857142857143, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a beach scene with a large cruise ship docked in the background. There are eight sailboats scattered across the water. The sailboats have sails and are positioned at different angles. Some sailboats are closer to the cruise ship while others are further away."}, "377371": {"image_id": 377371, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.21438189279304845, "Bleu_3": 0.1288187994554362, "Bleu_4": 1.5020075404050356e-05, "METEOR": 0.25273527091128334, "ROUGE_L": 0.3446327683615819, "CIDEr": 2.753624336507437e-07, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.04, "f": 0.041666666666666664, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image features a cutting board on a table, topped with chopped almonds. The almonds are spread across the cutting board in various sizes and shapes, creating a visually appealing presentation. A knife is also present on the table, likely used for cutting up food."}, "170813": {"image_id": 170813, "Bleu_1": 0.1562499999983724, "Bleu_2": 0.09068453126280186, "Bleu_3": 4.4392832595186036e-07, "Bleu_4": 9.848359777189442e-10, "METEOR": 0.183284739035029, "ROUGE_L": 0.15271816881258943, "CIDEr": 1.1885197893059893e-43, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "In the image, there are five people sitting on a wooden bench in a park. One person is squatting down to use a laptop. Another person is walking on the grass and using a golf club. The other three people are also walking on the grass and using a golf club. \n\nThe park features two trees, providing shade and a peaceful atmosphere. The person is sitting under one of the trees and using the laptop computer to study. The bench is positioned under the tree, providing a comfortable spot for the person to work or relax."}, "347210": {"image_id": 347210, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.2449489742734669, "Bleu_3": 0.15429747117624054, "Bleu_4": 0.09353169330469448, "METEOR": 0.2823663026732959, "ROUGE_L": 0.29847094801223245, "CIDEr": 6.041046107539881e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a park setting with a long row of trees in the background. In the foreground, there is a wooden park bench situated on a dirt path. The bench is not empty. The overall atmosphere of the scene is peaceful and inviting, with the park bench in the background."}, "175494": {"image_id": 175494, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.2839809171145149, "Bleu_3": 0.22071864286820123, "Bleu_4": 0.13876494356053687, "METEOR": 0.2572067410889445, "ROUGE_L": 0.36810344827586206, "CIDEr": 0.0018087912353412419, "SPICE": {"All": {"pr": 0.1, "re": 0.13043478260869565, "f": 0.11320754716981132, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a dog laying on a bed. The bed has a cartoon comforter. The dog is sleeping. \n\nIn the room, there is a bedside table with a radio on it."}, "265879": {"image_id": 265879, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.12393943320197576, "Bleu_3": 0.063148502881137, "Bleu_4": 8.048862002738133e-06, "METEOR": 0.20468712467413674, "ROUGE_L": 0.20900636319138516, "CIDEr": 8.987700782479816e-17, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.08888888888888889, "f": 0.12121212121212122, "fn": 41.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts three men sitting at a dining table. Each man has a plate of food in front of him. The first man is wearing a black shirt. The dining table is surrounded by two tables. The chairs around the tables are occupied by various people, including a man and a woman. There is also a dog occupying one of the chairs."}, "433998": {"image_id": 433998, "Bleu_1": 0.42857142856268227, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.10445882183999107, "Bleu_4": 1.2546407368639799e-05, "METEOR": 0.21459825166907928, "ROUGE_L": 0.2945081472540736, "CIDEr": 0.07068037580795682, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress, with a pitcher in the middle of throwing a pitch from the mound. The pitcher is wearing a white and red uniform. The pitcher is throwing a ball. There are several other people in the scene, including baseball players and opponents."}, "286711": {"image_id": 286711, "Bleu_1": 0.28124999999560546, "Bleu_2": 0.17677669529385284, "Bleu_3": 0.1147783196209119, "Bleu_4": 0.07056062808770269, "METEOR": 0.258526269275868, "ROUGE_L": 0.26547388781431336, "CIDEr": 4.8596467717435936e-17, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.25, "f": 0.22857142857142856, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a thrilling moment during a baseball game. A baseball player is in the middle of swinging his bat, attempting to hit the ball. The catcher and umpire are positioned behind him, ready to react to the outcome of the swing.\n\nThere is no ball in the scene.\n\nThe overall atmosphere is filled with excitement as the baseball player swings his bat."}, "552744": {"image_id": 552744, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.14555562743244904, "Bleu_3": 0.0900644361555668, "Bleu_4": 0.0598337588755971, "METEOR": 0.17492681750188172, "ROUGE_L": 0.25258799171842644, "CIDEr": 6.745468792922472e-14, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two women. The women have brown hair and are wearing white shirts. They are posing for a photo in front of a large collection of stuffed animals. The stuffed animals include teddy bears, lions, giraffes, tigers, and other plush toys. The stuffed animals are made of cotton. A necklace is also worn by one of the women."}, "447279": {"image_id": 447279, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.25300470311328, "Bleu_3": 0.12114855245115348, "Bleu_4": 1.5013144369944e-05, "METEOR": 0.22367274357236536, "ROUGE_L": 0.2793893129770992, "CIDEr": 1.9827561284301516e-05, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.30434782608695654, "f": 0.28571428571428575, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image depicts a police officer standing on a horse on a street. There are four horses in total, each with a police officer riding on their backs. The officers are positioned at various points along the street."}, "409217": {"image_id": 409217, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.3741657386621157, "Bleu_3": 0.2300435521933498, "Bleu_4": 2.7274191068218678e-05, "METEOR": 0.23115031263886024, "ROUGE_L": 0.38566912539515275, "CIDEr": 0.11119573117570944, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.20689655172413793, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a plate filled with a piece of meat, broccoli, and black beans. The plate is filled with meat, beans, broccoli, and cauliflower."}, "28114": {"image_id": 28114, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.174582229926461, "Bleu_3": 0.08423190681730008, "Bleu_4": 1.0455985518811585e-05, "METEOR": 0.21796186062940967, "ROUGE_L": 0.22195269860521533, "CIDEr": 3.912826807280063e-12, "SPICE": {"All": {"pr": 0.375, "re": 0.14285714285714285, "f": 0.20689655172413796, "fn": 18.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image depicts a city street with a bus parked on the side of the road. The bus is a city bus. There are several people standing near the bus. Some of the people are standing near a store, while others are standing near a mirror, a bench, a bookcase, and a bus."}, "33994": {"image_id": 33994, "Bleu_1": 0.3999999999938461, "Bleu_2": 0.2622022120384725, "Bleu_3": 0.12971415859411217, "Bleu_4": 1.3697541181080388e-05, "METEOR": 0.28111202428367205, "ROUGE_L": 0.24146462147451755, "CIDEr": 5.67896272370201e-17, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.23809523809523808, "f": 0.18181818181818185, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5, "f": 0.38461538461538464, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image features a flower show with a variety of flowers on display. There are three flowers, including a large yellow flower that stands out among the others. The yellow flower is placed in a green vase, which is positioned on a green table. There are three other vases in the scene, all of them are green. There is no potted plant in the scene."}, "278509": {"image_id": 278509, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.34419020751467316, "Bleu_3": 0.26095327986424666, "Bleu_4": 0.19228093785932168, "METEOR": 0.33858006536346774, "ROUGE_L": 0.34359283846308586, "CIDEr": 2.7577077898244727e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.14814814814814814, "f": 0.13559322033898305, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image is a black and white photo of a motorcycle parked on the side of a street. The motorcycle is prominently featured in the foreground, occupying the sidewalk. \n\nIn addition to the motorcycle, there is one car parked along the street."}, "544975": {"image_id": 544975, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.31108550840892535, "Bleu_3": 0.2372141099289385, "Bleu_4": 0.17572088409626654, "METEOR": 0.3358611093553948, "ROUGE_L": 0.4299559471365638, "CIDEr": 0.011961563551198316, "SPICE": {"All": {"pr": 0.1, "re": 0.11764705882352941, "f": 0.1081081081081081, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a zebra and a giraffe standing next to each other in a zoo enclosure. The zebra is standing on the ground. The giraffe is positioned in the middle."}, "158806": {"image_id": 158806, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.20159019488753482, "Bleu_3": 0.11680628450365418, "Bleu_4": 1.3361559690687091e-05, "METEOR": 0.1985260857753716, "ROUGE_L": 0.2896142433234421, "CIDEr": 3.980430630352871e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "In the image, a brown and black dog is sitting on the ground, looking up at a person holding a blue plate with a sandwich on it. The dog appears to be begging for a bite of the sandwich. The person holding the plate is positioned on the left side of the scene."}, "267321": {"image_id": 267321, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.16408253082431878, "Bleu_3": 0.08914842985218376, "Bleu_4": 1.1763453574139755e-05, "METEOR": 0.1763136936527781, "ROUGE_L": 0.36706783369803064, "CIDEr": 0.002312046237972198, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a cozy living room filled with various pieces of furniture. There is a furniture in the room, accompanied by a red chair and two dining tables. A potted plant is placed on one of the dining tables."}, "137188": {"image_id": 137188, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.17821457732346996, "Bleu_3": 0.08277505429035362, "Bleu_4": 1.0077062063152982e-05, "METEOR": 0.23516823072322376, "ROUGE_L": 0.2544316996871741, "CIDEr": 1.067445269394005e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features two gray cats sitting on a table. One cat is staring at a teddy bear, while the other cat is interested in a stuffed animal. There are several books placed on a wooden shelf, and a book is in front of the teddy bear. A stuffed tiger is also in front of the teddy bear."}, "132702": {"image_id": 132702, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.20304239863369572, "Bleu_3": 0.14333375493847259, "Bleu_4": 1.637063006100509e-05, "METEOR": 0.23096415293823674, "ROUGE_L": 0.29985955056179775, "CIDEr": 9.257117913673689e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a close-up view of three pieces of broccoli, one on the left side and the other on the right side of the frame. The pieces are placed on top of a piece of wax paper, which is resting on a table."}, "151075": {"image_id": 151075, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2289527349375426, "Bleu_3": 0.1517516670954597, "Bleu_4": 0.10477329534453905, "METEOR": 0.24631489058354208, "ROUGE_L": 0.2713523131672598, "CIDEr": 0.000639506236701637, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16, "f": 0.1568627450980392, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures two men skillfully riding a wave on surfboards. They are wearing black wetsuits and appear to be enjoying the thrill of surfing. The wave is located in the ocean."}, "516372": {"image_id": 516372, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1520747661648476, "Bleu_3": 0.12715123928857544, "Bleu_4": 0.09831839444823974, "METEOR": 0.2911747575795766, "ROUGE_L": 0.19869706840390877, "CIDEr": 5.4472812348097795e-09, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16666666666666666, "f": 0.19512195121951217, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a red fire hydrant situated on the side of the road. The fire hydrant is close to the curb, making it easily accessible in case of emergencies. \n\nThere are no bushes or trees in the scene.\n\nThere are three cars parked along the street."}, "397958": {"image_id": 397958, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.20604084591910862, "Bleu_3": 0.13567065103689688, "Bleu_4": 1.494933694745193e-05, "METEOR": 0.24620909137594504, "ROUGE_L": 0.28355607205113303, "CIDEr": 1.847026111492482e-11, "SPICE": {"All": {"pr": 0.35, "re": 0.30434782608695654, "f": 0.3255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a cow standing in a grassy field. The cow is black and white. It is positioned close to a fence. The cow is looking at the sky. Another cow can be seen in the background, a few feet away from the main cow. The field is filled with tall grass."}, "154004": {"image_id": 154004, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.20942695414214083, "Bleu_3": 0.17739178391688393, "Bleu_4": 0.13270338457225678, "METEOR": 0.2438571242621186, "ROUGE_L": 0.24413950829045164, "CIDEr": 5.3618943544953946e-14, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.4090909090909091, "f": 0.4, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.75, "f": 0.5454545454545454, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a lively beach scene with a group of 16 people enjoying their time on the sand. Some people are sitting on the beach, while others are playing frisbee, sitting on beach chairs, or laying down. A group of people is playing in the sand. \n\nThere is a surfboard in the middle of the scene."}, "179599": {"image_id": 179599, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.19611613513437562, "Bleu_3": 9.162603270562093e-07, "Bleu_4": 1.990513566543731e-09, "METEOR": 0.24184788102531324, "ROUGE_L": 0.2507045561296383, "CIDEr": 1.458065738065566e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress. The pitcher is standing on the mound. He is wearing a blue uniform and is in the process of throwing a pitch. The pitcher is holding a baseball glove in his hand, ready to catch the ball.\n\nThere is no ball in the image."}, "282553": {"image_id": 282553, "Bleu_1": 0.41999999999160004, "Bleu_2": 0.20701966779852365, "Bleu_3": 9.629283927574332e-07, "Bleu_4": 2.087714126331767e-09, "METEOR": 0.22631344036645254, "ROUGE_L": 0.22938079719227877, "CIDEr": 8.834491032538738e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.10714285714285714, "f": 0.13636363636363635, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "In the image, there are two women walking on a dirt path in a grassy field. One of the women is talking on her cell phone, while the other woman is walking beside her. They appear to be enjoying their time outdoors.\n\nThere are no standing stones in the scene."}, "53529": {"image_id": 53529, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.26010243549896195, "Bleu_3": 0.1172230946393227, "Bleu_4": 1.4078744342642945e-05, "METEOR": 0.3144180336231078, "ROUGE_L": 0.2809210526315789, "CIDEr": 7.153893098283036e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.22727272727272727, "f": 0.2631578947368421, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "In the image, a person is sitting in the driver's seat of a truck. The person is wearing a green hat on their head. \n\nThere is no shamrocks or St. Patrick's Day celebration in the scene.\n\nThere is also a dog present."}, "13168": {"image_id": 13168, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.1448554036562842, "Bleu_4": 1.6032880942514037e-05, "METEOR": 0.3096469482885732, "ROUGE_L": 0.3078864353312303, "CIDEr": 2.621777268895003e-09, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.23529411764705882, "f": 0.23529411764705882, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a train station at night. A train is traveling down the tracks. The train occupies a significant portion of the scene, stretching from the left side to the right side of the image. The train appears to be a commuter train, possibly heading to New York."}, "528738": {"image_id": 528738, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.17541160385452437, "Bleu_3": 0.10863467408031745, "Bleu_4": 1.536541839019132e-05, "METEOR": 0.19119418934838334, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.015900897686116043, "SPICE": {"All": {"pr": 0.5, "re": 0.2413793103448276, "f": 0.32558139534883723, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.4166666666666667, "f": 0.5555555555555556, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image features a dining table covered with a variety of fresh vegetables. There are no fruits, carrots, apples, or any other produce on the table."}, "368193": {"image_id": 368193, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.13773990809586936, "Bleu_4": 0.10759353803765437, "METEOR": 0.2305991471831916, "ROUGE_L": 0.25957446808510637, "CIDEr": 3.630807913076039e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.35714285714285715, "f": 0.41666666666666663, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts two people riding horses on a city street. The people are riding a horse. The horses are standing still. The horses are positioned closer to the left side of the street. \n\nThere is no other horse in the scene."}, "538064": {"image_id": 538064, "Bleu_1": 0.2916666666545139, "Bleu_2": 0.15925551431087165, "Bleu_3": 1.0485490691139458e-06, "Bleu_4": 2.7219913802054716e-09, "METEOR": 0.1779487405092151, "ROUGE_L": 0.24497991967871482, "CIDEr": 0.00747075713747666, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.25, "f": 0.25641025641025644, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two men sitting on a bench. On the sidewalk are the children statues placed. A car is parked along the street."}, "265636": {"image_id": 265636, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.0958411776672495, "Bleu_4": 0.06544158309931196, "METEOR": 0.23842807265623572, "ROUGE_L": 0.27319257837492, "CIDEr": 2.430975607323086e-11, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.16129032258064516, "f": 0.22727272727272727, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a brown teddy bear sitting on top of a green card, which reads \"Happy Birthday.\" The teddy bear appears to be the main focus of the scene, occupying a significant portion of the image. The card is placed on a couch, with the teddy bear resting on it."}, "577796": {"image_id": 577796, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.19847906537508855, "Bleu_3": 0.12236681347581897, "Bleu_4": 1.4452248335535119e-05, "METEOR": 0.26847894481888246, "ROUGE_L": 0.21585279547062985, "CIDEr": 1.044018978516973e-08, "SPICE": {"All": {"pr": 0.36, "re": 0.4090909090909091, "f": 0.3829787234042554, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a public restroom with five urinals lined up against a white tiled wall. The urinals are positioned at different heights, catering to the needs of various users. There is no trash can in the scene. There are two toilet paper rolls available."}, "554046": {"image_id": 554046, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.12246598403054855, "Bleu_4": 1.406005899188109e-05, "METEOR": 0.2165074955341985, "ROUGE_L": 0.22732919254658387, "CIDEr": 4.654826421363844e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2, "f": 0.1886792452830189, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a group of four sheep standing in a snow-covered field. Two of the sheep are wearing jackets, which are blankets. One of the sheep is wearing a coat, and another sheep is wearing a hat. The sheep are standing close to each other, forming a small herd."}, "316534": {"image_id": 316534, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.12803687993077956, "Bleu_3": 0.0822146823185309, "Bleu_4": 9.893615743279745e-06, "METEOR": 0.16195839991938246, "ROUGE_L": 0.19565914679781887, "CIDEr": 2.1977005646580775e-16, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 35.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.29411764705882354, "f": 0.35714285714285715, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a group of seven cows grazing in a lush green field near the ocean. The cows are grazing on grass. Some of the cows are grazing in the grass, while others are drinking water. The cows of St John's Farm 0 and Santa Fe Ranch are also present in the scene. The field is brown in color."}, "158950": {"image_id": 158950, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2067245576408771, "Bleu_3": 0.11956793017371352, "Bleu_4": 1.6336470130381284e-05, "METEOR": 0.21776457874752925, "ROUGE_L": 0.30530530530530536, "CIDEr": 0.010182268825813492, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1935483870967742, "f": 0.24489795918367346, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a long train traveling through a lush green field. The train is blue and yellow. The train showcases the Sydney to Melbourne freight train."}, "524822": {"image_id": 524822, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.2148344622063902, "Bleu_3": 0.1344264611354716, "Bleu_4": 0.09001463882336909, "METEOR": 0.28520447074664407, "ROUGE_L": 0.34957020057306587, "CIDEr": 6.236780181290104e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.16666666666666666, "f": 0.2051282051282051, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image depicts a spacious and well-lit living room with white furniture, including a leather couch and a white chair. The room also features a flat-screen TV mounted on the wall and a fireplace, creating a cozy and inviting atmosphere."}, "248111": {"image_id": 248111, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.19577417125493551, "Bleu_3": 0.09858638280047965, "Bleu_4": 1.2519775677898552e-05, "METEOR": 0.1425544429341585, "ROUGE_L": 0.2109266943291839, "CIDEr": 5.554770397565299e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.18518518518518517, "f": 0.20833333333333334, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a kitchen in the middle of a remodeling process. The kitchen is equipped with a refrigerator on the right side, a sink in the middle, and an oven on the left side. There is no microwave in the scene."}, "409964": {"image_id": 409964, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.19738550848437394, "Bleu_3": 0.15336829563872276, "Bleu_4": 0.10801653085536465, "METEOR": 0.31718710745972967, "ROUGE_L": 0.2476798143851508, "CIDEr": 1.1650748673255586e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.25925925925925924, "f": 0.2545454545454545, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a man playing tennis on a tennis court. The man is holding a tennis racket and is preparing to hit a tennis ball. He is wearing a white and blue shirt.\n\nThere are two tennis courts in the image. One is surrounded by a chain-link fence and the other is surrounded by grass."}, "337987": {"image_id": 337987, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.3597384670818214, "Bleu_3": 0.3016610834374349, "Bleu_4": 0.22523313614243626, "METEOR": 0.35117144040184356, "ROUGE_L": 0.3839496459480724, "CIDEr": 0.0006106595537367223, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.12, "f": 0.11538461538461538, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a bird perched on a tree branch. The bird is a woodpecker, with black and white feathers. It is sitting on the branch, possibly observing its surroundings or preparing to take flight."}, "544104": {"image_id": 544104, "Bleu_1": 0.2089552238774783, "Bleu_2": 0.09745750213072185, "Bleu_3": 0.05267110122508168, "Bleu_4": 6.912486646967604e-06, "METEOR": 0.1636892530482919, "ROUGE_L": 0.2356349589570256, "CIDEr": 1.2610992056621446e-19, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.2608695652173913, "f": 0.33333333333333337, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image depicts a harbor filled with 25 boats of various sizes and colors. The boats are docked in the water, creating a lively scene. Some of the boats are closer to the shore, while others are further out in the harbor. The sizes of the boats range from small skiffs to larger ships. The colors of the boats include white, gray, yellow, blue, brown, and green."}, "121210": {"image_id": 121210, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.2560199571978607, "Bleu_3": 0.1257026887176931, "Bleu_4": 1.5784140234610454e-05, "METEOR": 0.2528748665518645, "ROUGE_L": 0.32972972972972975, "CIDEr": 0.0009947892621457034, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.16666666666666666, "f": 0.21276595744680848, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a white plate topped with a delicious meal consisting of meat, potatoes, and an abundance of cooked carrots. The carrots are orange in color. The dish appears to be a hearty stew."}, "46551": {"image_id": 46551, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.28402864099045616, "Bleu_3": 0.21384057212126054, "Bleu_4": 0.13221480419997017, "METEOR": 0.2047722791790731, "ROUGE_L": 0.28796223446105423, "CIDEr": 0.000584560568383393, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a man holding a cell phone in a room. The man is taking a picture. The man is holding a cell phone. The other people in the room are playing video games."}, "535588": {"image_id": 535588, "Bleu_1": 0.3599999999928, "Bleu_2": 0.29692299557723706, "Bleu_3": 0.19440263188041348, "Bleu_4": 0.13297182813661193, "METEOR": 0.3196911505296513, "ROUGE_L": 0.3969631236442517, "CIDEr": 2.204850888381589e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "In the image, a man is standing next to a blue and yellow bus, holding a bicycle. The bus is parked on the side of the road, and the man is preparing to put his bike on the back of the bus. The man is preparing to board the bus."}, "173997": {"image_id": 173997, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.11148712271224703, "Bleu_3": 5.984214337036917e-07, "Bleu_4": 1.39247254575044e-09, "METEOR": 0.1998242422830075, "ROUGE_L": 0.1608649789029536, "CIDEr": 1.627238816034422e-15, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.25, "f": 0.20512820512820512, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image depicts two people sitting on a wooden bench near a fence. The people are eating lunch and riding a bike. One person is on the left side of the bench, while the other is on the right side. Both individuals have backpacks with them, with one backpack placed on the ground. \n\nThere is no fence in the scene."}, "320396": {"image_id": 320396, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.09618052714368557, "Bleu_3": 5.901837724618786e-07, "Bleu_4": 1.470202913098025e-09, "METEOR": 0.19999999999999996, "ROUGE_L": 0.23297262889879056, "CIDEr": 2.764168682030957e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14285714285714285, "f": 0.16, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "In the image, a man wearing a white shirt and blue shorts is playing with a white frisbee on a sandy beach. He appears to be in the middle of throwing the frisbee, which is captured in mid-air.\n\nThe beach is filled with numerous birds scattered around."}, "221282": {"image_id": 221282, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.22760466886504876, "Bleu_3": 0.16636805405423474, "Bleu_4": 0.12028093140521147, "METEOR": 0.3237023257532188, "ROUGE_L": 0.399642644431209, "CIDEr": 1.26975891491273e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.15151515151515152, "f": 0.17857142857142858, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "In the image, there are two women standing in a kitchen. One woman is putting a pizza on a wooden table and preparing a pizza. The other woman is preparing food. The pizza is on paper. The woman is using a pizza cutter to slice the pizza."}, "25143": {"image_id": 25143, "Bleu_1": 0.3199999999936, "Bleu_2": 0.19794866371815806, "Bleu_3": 0.0934590374320519, "Bleu_4": 1.1479990094513042e-05, "METEOR": 0.253063274805971, "ROUGE_L": 0.29865361077111385, "CIDEr": 2.769875160749497e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image is a collage of four photographs showcasing people playing with frisbees in a park. In each photograph, a person is captured in various stages of catching or throwing a frisbee. The frisbees can be seen in different positions within the photographs, with some people holding a white disc."}, "52835": {"image_id": 52835, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.28171808489925787, "Bleu_3": 0.14506145713745966, "Bleu_4": 1.8693000799253376e-05, "METEOR": 0.22942470222669248, "ROUGE_L": 0.3655821917808219, "CIDEr": 0.012102892108631132, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15151515151515152, "f": 0.20833333333333331, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a container filled with carrots, an orange, and peas. The container is filled with carrots, oranges, and peas. Some carrots are placed in the container."}, "300962": {"image_id": 300962, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.12577443714450187, "Bleu_3": 0.06485133546264767, "Bleu_4": 8.317072340661929e-06, "METEOR": 0.2208877049814222, "ROUGE_L": 0.2675438596491228, "CIDEr": 1.234946817182631e-16, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13793103448275862, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress, with a man in a white uniform swinging a baseball bat at a baseball. The man is in the middle of his swing, attempting to make contact with the ball. The scene takes place on a baseball field, with a baseball glove visible in the background. The man's uniform is white."}, "332532": {"image_id": 332532, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.15861031714066393, "Bleu_3": 0.0989076400524586, "Bleu_4": 1.1736263070262705e-05, "METEOR": 0.2527287621592805, "ROUGE_L": 0.25507765830346474, "CIDEr": 1.5929591776165508e-12, "SPICE": {"All": {"pr": 0.3125, "re": 0.2777777777777778, "f": 0.29411764705882354, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a bathroom with a white toilet positioned on the right side of the room. A sink is located in the center of the bathroom. There is a trash can on the left side and another trash can on the right side. Additionally, there is a potted plant placed in the bathroom."}, "528261": {"image_id": 528261, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.21060588478687045, "Bleu_3": 0.11392173307167976, "Bleu_4": 1.5026417037436177e-05, "METEOR": 0.3283509347802822, "ROUGE_L": 0.34790874524714827, "CIDEr": 0.0004154271991208105, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1111111111111111, "f": 0.14634146341463417, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a giraffe standing in a grassy field. The giraffe is grazing on grass. Its long neck, legs, and head are visible as it bends down to eat the grass."}, "297046": {"image_id": 297046, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.18609684207103389, "Bleu_3": 1.2008331555190807e-06, "Bleu_4": 3.089751861772178e-09, "METEOR": 0.23476485176430983, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.047047377169499124, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.17857142857142858, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image depicts a train traveling on a street. The train is orange. A car is positioned in front of the train."}, "130839": {"image_id": 130839, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.21110016545407168, "Bleu_3": 0.16105818770762542, "Bleu_4": 0.12813098990443, "METEOR": 0.22539366381736964, "ROUGE_L": 0.3117546848381601, "CIDEr": 0.0001880469336885749, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.07142857142857142, "f": 0.0625, "fn": 26.0, "numImages": 1.0, "fp": 34.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image depicts a man wearing a suit and standing on a sidewalk. The man is pulling two pieces of luggage behind him. One of the suitcases is larger and closer to the man."}, "451120": {"image_id": 451120, "Bleu_1": 0.27848101265470276, "Bleu_2": 0.20698606889247123, "Bleu_3": 0.14064377153098026, "Bleu_4": 0.07778341024650083, "METEOR": 0.22656268554418602, "ROUGE_L": 0.21564295183384888, "CIDEr": 1.684303511457326e-28, "SPICE": {"All": {"pr": 0.36, "re": 0.2903225806451613, "f": 0.3214285714285714, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "In the image, a woman is standing in a kitchen, smiling as she prepares food. She is wearing a blue sweater. She is holding a wooden spoon. The woman is preparing food.\n\nThere are two bowls in the scene. One bowl is placed on a counter and the other bowl is placed on a wooden table.\n\nThere are two dining tables in the scene. The dining tables occupy the entire room.\n\nThe woman is not standing in the kitchen."}, "378134": {"image_id": 378134, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.3469443332317352, "Bleu_3": 0.24037492837565722, "Bleu_4": 2.73012086260586e-05, "METEOR": 0.23221267463844883, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.010690335688065692, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.0625, "f": 0.09302325581395349, "fn": 30.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image depicts a group of four people playing frisbee in a grassy field. The people are actively participating in the game. A frisbee is in the field."}, "458953": {"image_id": 458953, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 8.157154566934659e-07, "Bleu_4": 1.8533803782519565e-09, "METEOR": 0.1606443001477133, "ROUGE_L": 0.19690122659780504, "CIDEr": 5.641125652223222e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.11764705882352941, "f": 0.0930232558139535, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image depicts a lively scene at a park where a large group of people is gathered to fly kites. There are numerous kites of various shapes and sizes soaring in the sky, creating a vibrant and colorful atmosphere. \n\nIn total, there are 14 people gathered in the park."}, "159451": {"image_id": 159451, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.3478041718090821, "Bleu_3": 0.22955663923805797, "Bleu_4": 0.14291173573605973, "METEOR": 0.29376635243662735, "ROUGE_L": 0.39246323529411764, "CIDEr": 0.0006603480238247768, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.18518518518518517, "f": 0.1639344262295082, "fn": 22.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a dump truck parked on a dirt road. The dump truck is yellow. The truck is parked in front of a building, which appears to be a construction site."}, "294258": {"image_id": 294258, "Bleu_1": 0.43902439023319456, "Bleu_2": 0.2963188789875593, "Bleu_3": 1.310643804769679e-06, "Bleu_4": 2.7743906366573875e-09, "METEOR": 0.26249068076575593, "ROUGE_L": 0.36771600803750837, "CIDEr": 4.0608565597344155e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.18518518518518517, "f": 0.2127659574468085, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a man dressed in a black suit and brown tie, wearing a white and gray shirt underneath. The man is talking on the phone. He is standing in front of a building. The suit appears to be well-fitted."}, "544695": {"image_id": 544695, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.22934123614279892, "Bleu_3": 0.15735365791500988, "Bleu_4": 0.09259524070257806, "METEOR": 0.2790134593457792, "ROUGE_L": 0.31011943189154295, "CIDEr": 6.499913854669395e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image depicts two men playing tennis on a tennis court. They are both holding tennis rackets and preparing to hit a tennis ball. The men are focused on the game. One of the men is wearing a white shirt. There are two tennis balls in the scene, one near the man and another further away."}, "623": {"image_id": 623, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1666666666629209, "Bleu_3": 0.08644562419446397, "Bleu_4": 1.1136402991439421e-05, "METEOR": 0.2568181901485823, "ROUGE_L": 0.2922655715263518, "CIDEr": 9.16788294548119e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2727272727272727, "f": 0.24489795918367346, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "In the image, a woman is hugging a large brown teddy bear. The teddy bear is positioned in front of her, occupying a significant portion of the scene. The woman's arms are wrapped around the teddy bear, showcasing her affection for the stuffed toy."}, "236690": {"image_id": 236690, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.11964664509646934, "Bleu_4": 0.07944348368460985, "METEOR": 0.2642166401451884, "ROUGE_L": 0.28968792401628224, "CIDEr": 1.3562422584324656e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.3333333333333333, "f": 0.22857142857142854, "fn": 8.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.8, "f": 0.5000000000000001, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image captures a bird flying over a body of water. The bird is in the middle of the scene, with its wings spread wide as it soars through the air. The water beneath the bird appears to be blue, creating a serene and picturesque scene."}, "382088": {"image_id": 382088, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.392232270247274, "Bleu_3": 0.2948798730856944, "Bleu_4": 0.21972813873225094, "METEOR": 0.27557865116672625, "ROUGE_L": 0.45252225519287836, "CIDEr": 0.7191194611033398, "SPICE": {"All": {"pr": 0.3, "re": 0.2, "f": 0.24, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.46153846153846156, "f": 0.5714285714285714, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a horse standing in a fenced-in area. The horse is white."}, "504711": {"image_id": 504711, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.3086066999129581, "Bleu_3": 0.22232392576237683, "Bleu_4": 0.17219167420117132, "METEOR": 0.35982648739911527, "ROUGE_L": 0.5388692579505301, "CIDEr": 0.03819573695799717, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a piece of chocolate cake on a white plate. The cake appears to be a chocolate cake. The fork is placed next to the cake."}, "495348": {"image_id": 495348, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.11451966686088066, "Bleu_3": 6.057629586243617e-07, "Bleu_4": 1.3991685565054186e-09, "METEOR": 0.19645851697899838, "ROUGE_L": 0.19416445623342174, "CIDEr": 7.450200612342659e-16, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a lush green field with a diverse group of animals. There are five zebras scattered throughout the field. Some zebras are closer to the foreground, while others are further in the background. There are also two giraffes and two antelopes in the scene. The overall atmosphere of the image is serene and natural, with trees surrounding the field."}, "326217": {"image_id": 326217, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.13397282540802452, "Bleu_3": 7.787832678078205e-07, "Bleu_4": 1.8902185812799826e-09, "METEOR": 0.17609901417747775, "ROUGE_L": 0.25558659217877094, "CIDEr": 9.761773771050107e-06, "SPICE": {"All": {"pr": 0.1951219512195122, "re": 0.25, "f": 0.21917808219178084, "fn": 24.0, "numImages": 1.0, "fp": 33.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5454545454545454, "f": 0.4799999999999999, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image depicts a group of four people on a boat. The boat is filled with a variety of fruits and vegetables. Two people are on the boat. The people are sitting and standing, possibly selling or transporting the produce."}, "59752": {"image_id": 59752, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 0.11558994996382839, "Bleu_4": 1.4598906514772134e-05, "METEOR": 0.23770883261805706, "ROUGE_L": 0.332295719844358, "CIDEr": 1.3359499576850869e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.23529411764705882, "f": 0.21052631578947367, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image depicts boats docked along the shore of a large body of water. The boats are lined up in a row, creating a picturesque scene. Some of the boats are closer to the water's edge."}, "437393": {"image_id": 437393, "Bleu_1": 0.24999999997916675, "Bleu_2": 4.767312945812628e-09, "Bleu_3": 1.3147679470444613e-11, "Bleu_4": 7.08885680157797e-13, "METEOR": 0.0898876404494382, "ROUGE_L": 0.2074829931972789, "CIDEr": 0.08682840912852446, "SPICE": {"All": {"pr": 0.3, "re": 0.13636363636363635, "f": 0.18749999999999997, "fn": 19.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a beautifully crafted white statue. The statue is white."}, "279209": {"image_id": 279209, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.08696565534534605, "Bleu_3": 6.119658713574004e-07, "Bleu_4": 1.6359043508197515e-09, "METEOR": 0.2795323157165988, "ROUGE_L": 0.28003060443764344, "CIDEr": 9.166912704555746e-05, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image depicts a person wearing a black and blue jacket and carrying skis and a backpack. The person is positioned towards the left side of the image, making their way through the snow-covered slope."}, "202228": {"image_id": 202228, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.34050261229601503, "Bleu_3": 0.2762439247057154, "Bleu_4": 0.22250764584313545, "METEOR": 0.3314358116283948, "ROUGE_L": 0.3935483870967742, "CIDEr": 1.1506506695948727e-07, "SPICE": {"All": {"pr": 0.5384615384615384, "re": 0.22580645161290322, "f": 0.3181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "In the image, a man wearing a red and white jacket is standing in front of a mirror. He is taking a picture of himself using a cell phone. The man appears to be in a bathroom, as there is a toilet visible in the background."}, "193661": {"image_id": 193661, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.21442250696028836, "Bleu_3": 0.14864064036709165, "Bleu_4": 0.10501763523338824, "METEOR": 0.23364276946744186, "ROUGE_L": 0.4128595600676818, "CIDEr": 0.01401796423715125, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.2, "f": 0.1639344262295082, "fn": 20.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image depicts a cozy living room with a fireplace as the focal point. The fireplace is adorned with several potted plants, adding a touch of greenery to the room."}, "457060": {"image_id": 457060, "Bleu_1": 0.24590163934023115, "Bleu_2": 0.12803687993077953, "Bleu_3": 6.525383659983367e-07, "Bleu_4": 1.4794406243584445e-09, "METEOR": 0.16280517074617223, "ROUGE_L": 0.2148968293910418, "CIDEr": 3.2486119230548494e-13, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15789473684210525, "f": 0.15789473684210525, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features two giraffes. The head of one giraffe is shown in the image, and it is looking at a tree. The other giraffe's neck is shown in the image, and it is looking at a water bottle. The giraffes are prominently displayed, showcasing their unique features of long necks and legs.\n\nThe giraffes are in a zoo enclosure."}, "390215": {"image_id": 390215, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.21938172723158908, "Bleu_3": 0.1818738688549909, "Bleu_4": 0.14036046697224605, "METEOR": 0.3104825793861241, "ROUGE_L": 0.4033057851239669, "CIDEr": 0.00039751518643590196, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15, "f": 0.15789473684210525, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a plate topped with a delicious meal consisting of meat and broccoli. The meat includes pound and ham. The broccoli is a vegetable. Meth and broccoli is spread across the plate."}, "579635": {"image_id": 579635, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.2791452631065508, "Bleu_3": 0.15735365791036715, "Bleu_4": 2.127988281940048e-05, "METEOR": 0.2172326202506343, "ROUGE_L": 0.2612419700214133, "CIDEr": 0.10450881193206407, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.11428571428571428, "f": 0.1818181818181818, "fn": 31.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.1875, "f": 0.3, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image captures two men skillfully riding surfboards on a wave in the ocean. The men are surfing and enjoying the experience."}, "251920": {"image_id": 251920, "Bleu_1": 0.17142857142612247, "Bleu_2": 0.12209353913171513, "Bleu_3": 0.07596883787328153, "Bleu_4": 8.994104132811597e-06, "METEOR": 0.17398623832500296, "ROUGE_L": 0.2006578947368421, "CIDEr": 4.424399923931264e-18, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.18518518518518517, "f": 0.18181818181818182, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a stove with two pizzas placed on top of it. One pizza is positioned on the left side of the stove, while the other is on the right side. Both pizzas appear to be freshly baked and ready to be enjoyed. The pizzas on the stove include a pizza with sausage, a pizza with cheese and tomatoes, a pizza with mushrooms and cheese, and a cheese pizza."}, "271117": {"image_id": 271117, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.13187609467625871, "Bleu_3": 7.338824344329119e-07, "Bleu_4": 1.741216427287497e-09, "METEOR": 0.21429141952385136, "ROUGE_L": 0.3125343092406221, "CIDEr": 5.8008399993275254e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a wooden desk filled with various items. On the desk, there is a blue vase with a bouquet of yellow and orange flowers, adding a touch of color to the scene. A bottle can be seen on the left side of the desk."}, "11051": {"image_id": 11051, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.1814970425910117, "Bleu_3": 8.760206462900567e-07, "Bleu_4": 1.9345299022435176e-09, "METEOR": 0.17363604234215124, "ROUGE_L": 0.21441124780316342, "CIDEr": 3.308759802108759e-10, "SPICE": {"All": {"pr": 0.09375, "re": 0.15, "f": 0.11538461538461538, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image depicts a man and a woman standing next to each other. The woman is adjusting a tie on the man's lapel. The man is wearing a black suit and the woman is wearing a black dress. They are both smiling and seem to be enjoying their time together."}, "170605": {"image_id": 170605, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.19050019049423667, "Bleu_3": 1.0655075333690477e-06, "Bleu_4": 2.5413699711235867e-09, "METEOR": 0.3310850701437838, "ROUGE_L": 0.2659883720930233, "CIDEr": 0.01868459586051414, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image depicts a snow-covered field with a large airplane flying overhead. The airplane is a float plane. \n\nThere are two seaplanes in the image. \n\nOn the ground, there are two snowmobiles."}, "84123": {"image_id": 84123, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.3351111237096373, "Bleu_3": 0.21917094903823833, "Bleu_4": 0.13575218161509645, "METEOR": 0.19279887098760495, "ROUGE_L": 0.3330733229329173, "CIDEr": 0.0021795881438365287, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.15384615384615385, "f": 0.20689655172413793, "fn": 33.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.3125, "f": 0.4166666666666667, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a busy city street with four cars and one truck driving down the road. Some cars are positioned on the street. Some trucks are positioned on the side of the road."}, "505899": {"image_id": 505899, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.18893226103154032, "Bleu_3": 0.12129998563457307, "Bleu_4": 0.07416219225006379, "METEOR": 0.2581998173093651, "ROUGE_L": 0.25549738219895285, "CIDEr": 1.5718574976988067e-16, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.05263157894736842, "f": 0.07142857142857142, "fn": 36.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a table with a plate holding two donuts. One of the donuts is a chocolate frosted donut, while the other is a glazed donut. Beside the plate, there is a cup of coffee with a spoon.\n\nThe overall scene shows two donuts on the plate. There is coffee in the cup, and a donut is placed beside the coffee."}, "256814": {"image_id": 256814, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.11293938405626278, "Bleu_4": 0.08801997699586785, "METEOR": 0.19441991324896796, "ROUGE_L": 0.25831820931639443, "CIDEr": 1.272101356417718e-10, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.4166666666666667, "f": 0.5263157894736842, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features two men and two women taking a selfie. The man is holding a doughnut and eating a donut. The man is holding a cell phone and eating a sandwich. The woman is taking a selfie. The woman is taking a selfie.\n\nThere is no car in the scene."}, "419680": {"image_id": 419680, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.2047650389408227, "Bleu_3": 0.14774838920061847, "Bleu_4": 0.08917631496980528, "METEOR": 0.2669036909467038, "ROUGE_L": 0.2738496071829405, "CIDEr": 7.880619527256322e-12, "SPICE": {"All": {"pr": 0.35, "re": 0.2413793103448276, "f": 0.2857142857142857, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image depicts a city street with a green sign posted on a black pole. The sign reads \"No drinks allowed on street. All drinks may be beer containers.\" There is a black and white sign as well. The street is not located in a historic district. There is a balcony in the background."}, "519555": {"image_id": 519555, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.23210354127000468, "Bleu_3": 0.1923365852245496, "Bleu_4": 0.16927132846311346, "METEOR": 0.31265958605443017, "ROUGE_L": 0.34269662921348315, "CIDEr": 3.5706553783792402e-12, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.05555555555555555, "f": 0.06666666666666667, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image is a black and white photo of a stop sign located on a dirt road. The stop sign is positioned on the side of the road, and it appears to be the main focus of the scene. The dirt road is surrounded by a grassy area, and there are trees in the background."}, "354929": {"image_id": 354929, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.1906925178456823, "Bleu_3": 0.11043358748864571, "Bleu_4": 1.2625742220311294e-05, "METEOR": 0.2287762285395809, "ROUGE_L": 0.2717149220489977, "CIDEr": 1.114946477712061e-10, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.4, "f": 0.41025641025641024, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts a group of eight people riding bicycles on a street. Some riders are wearing backpacks. \n\nThere are twelve bicycles visible in the scene. \n\nThe image is taken at night, and the street is illuminated by streetlights. The overall atmosphere of the scene is lively and energetic as the riders navigate the city streets."}, "17379": {"image_id": 17379, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.14185186364132965, "Bleu_3": 0.08020507112003895, "Bleu_4": 1.0794573108750781e-05, "METEOR": 0.3037704765979484, "ROUGE_L": 0.29550173010380626, "CIDEr": 1.4254618485598114e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.26666666666666666, "f": 0.2105263157894737, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a bathroom with a television mounted on the wall. A football game is being displayed on the television. The bathroom is equipped with a sink, which includes a mirror and a soap dish. The mirror reflects the television."}, "13965": {"image_id": 13965, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.19802950858942228, "Bleu_3": 0.10701301835858801, "Bleu_4": 1.4100581946635955e-05, "METEOR": 0.178545745388674, "ROUGE_L": 0.3239757207890743, "CIDEr": 0.000597779477305596, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.25, "f": 0.2631578947368421, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a green and white train parked at a train station. The train occupies a significant portion of the scene. A parking lot is close to the left side of the train."}, "422836": {"image_id": 422836, "Bleu_1": 0.2058823529381488, "Bleu_2": 0.1752960621157672, "Bleu_3": 0.14826300843778753, "Bleu_4": 0.11900391932114061, "METEOR": 0.2587782187356819, "ROUGE_L": 0.24110671936758896, "CIDEr": 3.8733813070207453e-20, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.12121212121212122, "f": 0.13333333333333333, "fn": 29.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts two men walking down a city street. One of the men is riding a skateboard and carrying a suitcase, while the other man is walking down the street and carrying a bag of ice cream. The man riding the skateboard is wearing a black jacket. The street is lined with several chairs and dining tables, suggesting that there might be an outdoor seating area nearby."}, "513292": {"image_id": 513292, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.20195126571496114, "Bleu_3": 0.13566654900343936, "Bleu_4": 1.5102341067340486e-05, "METEOR": 0.2593937332555629, "ROUGE_L": 0.26704190118824267, "CIDEr": 5.659300637388647e-10, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.1111111111111111, "f": 0.11428571428571428, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a boy wearing a red shirt. He is holding a skateboard in his hands while standing on a sidewalk. The skateboard is positioned on the sidewalk in front of the boy, and he appears to be admiring it or preparing to use it. The scene takes place outdoors."}, "202444": {"image_id": 202444, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.11945967146768073, "Bleu_3": 6.978002390453578e-07, "Bleu_4": 1.6966894961903369e-09, "METEOR": 0.1538264589775269, "ROUGE_L": 0.25318206972883234, "CIDEr": 9.559219742683809e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20833333333333334, "f": 0.25641025641025644, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image captures a lively scene at a skate park, where four men are skillfully riding skateboards on the side of a ramp. One of the men is riding a skateboard up the ramp. Another skateboard can be seen lying on the ground nearby."}, "268541": {"image_id": 268541, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.28171808489925787, "Bleu_3": 0.18276598337590827, "Bleu_4": 0.12500763055417202, "METEOR": 0.2922049024335942, "ROUGE_L": 0.38959854014598544, "CIDEr": 0.0193096691370574, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.3125, "f": 0.29411764705882354, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a man wearing a suit and tie. The man is holding a cup and drinking from it. The man is possibly enjoying a hot beverage."}, "377999": {"image_id": 377999, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.18535150310271878, "Bleu_3": 0.09352211318264238, "Bleu_4": 1.188474230301215e-05, "METEOR": 0.20705201498505527, "ROUGE_L": 0.266209476309227, "CIDEr": 6.127282051942021e-07, "SPICE": {"All": {"pr": 0.15, "re": 0.1111111111111111, "f": 0.12765957446808512, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a sailboat floating on the water. The sailboat is white and red. The sailboat is positioned on the water. \n\nThere are two people in the scene, with one person standing close to the sailboat. \n\nThere is no dock in the scene."}, "272694": {"image_id": 272694, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.20701966779852365, "Bleu_3": 0.13887830606912108, "Bleu_4": 0.10332581568909559, "METEOR": 0.2772593621833057, "ROUGE_L": 0.4040627069993376, "CIDEr": 3.285148564409977e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a table with a cup of coffee, a muffin, and a banana placed on it. The cup of coffee is not present in the image. A banana is positioned towards the left side of the table. The muffin and banana are placed closer to the right side."}, "137844": {"image_id": 137844, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.12898224153816748, "Bleu_3": 0.08406862345268944, "Bleu_4": 0.05733037464733334, "METEOR": 0.1901064200627897, "ROUGE_L": 0.20220994475138118, "CIDEr": 2.5806991674263765e-15, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2777777777777778, "f": 0.25641025641025644, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image captures an exciting moment at a skate park, where two skateboarders are in mid-air, performing tricks on their skateboards. The skateboarders are the main focus of the scene, showcasing their skills and athleticism. One skateboarder is doing a trick, while the other skateboarder is also performing a trick. Both skateboarders are in mid-air on their skateboards."}, "374829": {"image_id": 374829, "Bleu_1": 0.18749999999804687, "Bleu_2": 0.12565617248619285, "Bleu_3": 0.06951682553068804, "Bleu_4": 0.04359600681647779, "METEOR": 0.22784961672939408, "ROUGE_L": 0.19491783323189288, "CIDEr": 6.632696372606452e-39, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.11538461538461539, "f": 0.11538461538461539, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image depicts a baseball game in progress, with two batters standing at home plate, each holding a bat and preparing to swing. The catcher is positioned behind the batters, wearing a black and white uniform and crouching down to catch the ball. \n\nThere are a total of 34 people in the scene, including men, women, and children. Some are wearing baseball uniforms, while others are dressed in casual attire. \n\nOverall, the image captures the excitement and action of a baseball game, with the batters preparing to swing and the catcher ready to catch the ball."}, "21465": {"image_id": 21465, "Bleu_1": 0.15652173912907372, "Bleu_2": 0.104804492714635, "Bleu_3": 0.057930034106497524, "Bleu_4": 6.454659432029522e-06, "METEOR": 0.12374937759306463, "ROUGE_L": 0.1302544079067781, "CIDEr": 6.783283322574845e-66, "SPICE": {"All": {"pr": 0.375, "re": 0.10714285714285714, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.25, "f": 0.375, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features three tables with various items placed on top of them. The first table is blue and has a blue shelf arranged on it. The second table is white and has a picture, a box, a hat, and a tin box arranged on it. The third table is green and has a lamp, a chair, a table, a stool, and a box arranged on it.\n\nThere are seven cups arranged on the tables. There is one bowl and one vase on the tables as well.\n\nThere are four cups, one bowl, and one vase on the tables.\n\nA blue shelf, a white table, and a green table are creating a visually appealing display."}, "281929": {"image_id": 281929, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.210720977237338, "Bleu_3": 0.17023845844710978, "Bleu_4": 0.14552750619286398, "METEOR": 0.30867413470315597, "ROUGE_L": 0.34163036714374606, "CIDEr": 1.663439530646249e-08, "SPICE": {"All": {"pr": 0.1875, "re": 0.1111111111111111, "f": 0.13953488372093023, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a man wearing a brown suit, standing next to a bicycle in front of a house. The man appears to be posing for a picture, possibly for a special occasion. The bicycle is located on the sidewalk. The house is located in a city."}, "464814": {"image_id": 464814, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1825741858309521, "Bleu_3": 0.13248819441873214, "Bleu_4": 1.5339830594132386e-05, "METEOR": 0.2930488724063347, "ROUGE_L": 0.3609467455621302, "CIDEr": 4.428776093452889e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.125, "f": 0.17391304347826086, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.26666666666666666, "f": 0.36363636363636365, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image depicts a spacious living room with hardwood floors. The living room is furnished with a couch, a rug, a television, and a window. There is a couch in the room, but its position is not specified. There is a chair facing the wall."}, "213538": {"image_id": 213538, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 0.08618888098293648, "Bleu_4": 1.0746774156673132e-05, "METEOR": 0.23068389722651034, "ROUGE_L": 0.2858816637375513, "CIDEr": 1.1281995927050689e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.09090909090909091, "f": 0.11538461538461539, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features two desks, each with a computer monitor sitting on top. One of the monitors is positioned towards the left side of the desk, while the other is on the right side. A keyboard is placed in front of the monitors. There are two mice located on the desk."}, "461573": {"image_id": 461573, "Bleu_1": 0.27999999998880004, "Bleu_2": 3.4156502551803943e-09, "Bleu_3": 7.975164525246399e-12, "Bleu_4": 3.8967188122828966e-13, "METEOR": 0.13267894365680502, "ROUGE_L": 0.24771573604060915, "CIDEr": 0.008466782548897205, "SPICE": {"All": {"pr": 0.25, "re": 0.1724137931034483, "f": 0.20408163265306123, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a white bench placed in a park. The bench is surrounded by a brown field, giving it a serene and inviting atmosphere."}, "360629": {"image_id": 360629, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2804086879058332, "Bleu_3": 0.17371229465538454, "Bleu_4": 0.11595071162522325, "METEOR": 0.24081526315315888, "ROUGE_L": 0.3758802816901408, "CIDEr": 0.005097051315266771, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.23529411764705882, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a red tray filled with a variety of food items, including meat, vegetables, and a piece of fish. There are no pieces of broccoli or carrots on the tray."}, "114745": {"image_id": 114745, "Bleu_1": 0.3181818181673554, "Bleu_2": 0.1740776559475969, "Bleu_3": 1.1485555942497076e-06, "Bleu_4": 2.98830977790788e-09, "METEOR": 0.12381953472051899, "ROUGE_L": 0.23689320388349516, "CIDEr": 0.08458382490207272, "SPICE": {"All": {"pr": 0.3125, "re": 0.3333333333333333, "f": 0.3225806451612903, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "There is no bear in this image. There is a skateboard in the image. There are two skate parks in the image."}, "548878": {"image_id": 548878, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.192868005722087, "Bleu_3": 0.13637339509226334, "Bleu_4": 1.5584042559597084e-05, "METEOR": 0.23969086983199128, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.365258613261622e-08, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.1, "f": 0.10714285714285714, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a thrilling moment of two skateboarders in mid-air, performing impressive tricks. The skateboarders are the main focus of the scene, with a person on a snowboard also being present. The skateboarders are soaring through the air with their skateboards clearly visible beneath them."}, "385985": {"image_id": 385985, "Bleu_1": 0.5999999999828572, "Bleu_2": 0.47896948200546186, "Bleu_3": 0.3468041869393537, "Bleu_4": 0.1900096922045934, "METEOR": 0.2905475039529034, "ROUGE_L": 0.4033798677443056, "CIDEr": 0.005727098143569966, "SPICE": {"All": {"pr": 0.375, "re": 0.3157894736842105, "f": 0.34285714285714286, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.7142857142857143, "f": 0.7142857142857143, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a man and a woman sitting next to each other. They are engrossed in their cell phones. The man is playing a video game. The woman is looking at her cell phone."}, "289714": {"image_id": 289714, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.23555849565513073, "Bleu_3": 0.16221265425974885, "Bleu_4": 0.12242641935912445, "METEOR": 0.26775284230690105, "ROUGE_L": 0.23229246001523232, "CIDEr": 2.4272640987179168e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.09375, "f": 0.13043478260869562, "fn": 29.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image showcases a kitchen with green cabinets and a white countertop. A sink is located in the middle of the kitchen. An oven is on the right side of the kitchen. \n\nThere is no refrigerator or microwave in the scene."}, "230226": {"image_id": 230226, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.14341779190946682, "Bleu_3": 7.161533241989528e-07, "Bleu_4": 1.6075475827855697e-09, "METEOR": 0.21455526962032104, "ROUGE_L": 0.20383158832702158, "CIDEr": 2.5695451467270502e-15, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.2, "f": 0.18750000000000003, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a bathroom counter with a clear plastic container filled with various toiletries. Inside the container, there are multiple toothbrushes, a toothpaste tube, and a bottle of mouthwash. The toothbrushes are arranged in different positions, with some in a row and others in a circle. Brushes and a holder are also placed on the bathroom counter."}, "319534": {"image_id": 319534, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.32128773155046275, "Bleu_3": 0.24237254658051569, "Bleu_4": 0.15016650105358673, "METEOR": 0.3140721965509548, "ROUGE_L": 0.4769351055512119, "CIDEr": 0.009428768942694614, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.10344827586206896, "f": 0.13043478260869565, "fn": 26.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a man wearing a white shirt, standing in front of a bus. The man is standing on the side of the bus. The bus is filled with people."}, "427476": {"image_id": 427476, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.24911189772076184, "Bleu_3": 0.18894426063218775, "Bleu_4": 0.11064891248238046, "METEOR": 0.27541039890775537, "ROUGE_L": 0.329136690647482, "CIDEr": 1.1451709192005565e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a girl standing in a bathroom. The girl is playing with a wii remote. The girl is standing in front of a white toilet, which is located on the left side of the bathroom. The girl appears to be enjoying her time in the bathroom."}, "101223": {"image_id": 101223, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.22941573386460196, "Bleu_3": 0.11246435365320531, "Bleu_4": 1.4098910172173328e-05, "METEOR": 0.2307995406884813, "ROUGE_L": 0.3381843381843382, "CIDEr": 2.658948804535785e-05, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3, "f": 0.24489795918367346, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5555555555555556, "f": 0.4166666666666667, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image captures a bird's-eye view of an airplane wing as it flies over a snow-covered mountain range. The wing of the airplane is prominently visible in the foreground. The majestic mountain range stretches across the background."}, "123570": {"image_id": 123570, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1373143068093302, "Bleu_3": 0.07085740383081722, "Bleu_4": 9.094693994314411e-06, "METEOR": 0.19347431941782733, "ROUGE_L": 0.24610951008645532, "CIDEr": 1.9849973306196166e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts two men and two women standing on a city street at night. The men are wearing suits, with one of them wearing a black suit. The women are dressed in business attire, with one of them wearing a black dress. They are all holding an umbrella to protect themselves from the rain."}, "368581": {"image_id": 368581, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.1613643827195938, "Bleu_4": 0.12729922658111098, "METEOR": 0.26813771385356033, "ROUGE_L": 0.3285457809694794, "CIDEr": 1.612163287451035e-08, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.20833333333333334, "f": 0.2631578947368421, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a plastic container filled with a variety of healthy food items. Inside the container, there are sliced apples, strawberries, cucumbers, and a sandwich. The sandwich, strawberries, and cucumbers are placed on the left side of the container. The sandwich, strawberries, and cucumbers are positioned on the right side."}, "446984": {"image_id": 446984, "Bleu_1": 0.21212121211799817, "Bleu_2": 0.1142524093978523, "Bleu_3": 0.05886406548165309, "Bleu_4": 7.543146679700617e-06, "METEOR": 0.22336762655548165, "ROUGE_L": 0.21243781094527364, "CIDEr": 4.651400195892171e-20, "SPICE": {"All": {"pr": 0.2, "re": 0.38461538461538464, "f": 0.2631578947368421, "fn": 8.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a group of nine people riding bicycles. Some of the people are wearing helmets. \n\nThe group appears to be participating in various activities, such as riding skateboards, bikes, and even a horse. Some of the people are wearing green jackets, pink vests, yellow vests, yellow dresses, and black shirts. The scene is lively and dynamic, with people scattered throughout the foreground and background."}, "514668": {"image_id": 514668, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.12082769166967569, "Bleu_4": 0.09358212443043776, "METEOR": 0.22839877505848216, "ROUGE_L": 0.3010487353485503, "CIDEr": 7.310606722571669e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.125, "f": 0.16326530612244897, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "In the image, there are two cats sitting in the car. One cat is on the left side of the car, while the other cat is on the right side. Both cats are looking out the window, enjoying the view.\n\nThe cats are enjoying a ride in the car."}, "532129": {"image_id": 532129, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.3713906763415107, "Bleu_3": 0.3254872647264351, "Bleu_4": 0.28268454192252473, "METEOR": 0.2595592362310941, "ROUGE_L": 0.45073891625615764, "CIDEr": 0.009407855848006895, "SPICE": {"All": {"pr": 0.1875, "re": 0.2, "f": 0.19354838709677422, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a cheese pizza sitting on top of a tray. The pizza is sliced and ready to be eaten, with a generous amount of cheese covering its surface."}, "200168": {"image_id": 200168, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.20080483221924839, "Bleu_3": 0.11035932143410065, "Bleu_4": 1.4672606369386344e-05, "METEOR": 0.24787869069804017, "ROUGE_L": 0.2803308823529412, "CIDEr": 0.0009699988083030162, "SPICE": {"All": {"pr": 0.375, "re": 0.24, "f": 0.2926829268292683, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts a ski slope covered in snow. There are two skiers in the scene, with snow surrounding them. The girl is wearing a helmet as she skis down the slope."}, "470801": {"image_id": 470801, "Bleu_1": 0.5714285714013606, "Bleu_2": 0.5606119105540249, "Bleu_3": 0.43569276482624975, "Bleu_4": 0.3096168826464989, "METEOR": 0.32557838664242544, "ROUGE_L": 0.5960912052117263, "CIDEr": 0.315750767049887, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "In the image, a woman is flying a colorful kite in a blue sky. The kite is gliding through the sky."}, "138713": {"image_id": 138713, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.28867513458302535, "Bleu_3": 0.19351158546623434, "Bleu_4": 0.13471766853114558, "METEOR": 0.27778281731343374, "ROUGE_L": 0.3715736040609137, "CIDEr": 0.03396802905785798, "SPICE": {"All": {"pr": 0.32, "re": 0.26666666666666666, "f": 0.2909090909090909, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.06666666666666667, "f": 0.08695652173913045, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5454545454545454, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image depicts four men playing frisbee in a park. They are engaged in a game of frisbee, with the frisbee being white and green."}, "195917": {"image_id": 195917, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.22216879699110492, "Bleu_3": 0.1731998482473103, "Bleu_4": 0.12945466293620692, "METEOR": 0.28645381826166666, "ROUGE_L": 0.32250755287009064, "CIDEr": 1.1789731560150164e-05, "SPICE": {"All": {"pr": 0.3, "re": 0.3157894736842105, "f": 0.3076923076923077, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "In the image, a man is brushing his teeth with a green toothbrush. He appears to be focused on brushing his teeth. Another person can be seen in the background, but they are not the main subject of the scene."}, "145391": {"image_id": 145391, "Bleu_1": 0.39999999999111113, "Bleu_2": 0.25226248954908703, "Bleu_3": 0.1139582137122124, "Bleu_4": 1.3700830775392178e-05, "METEOR": 0.26330633096269535, "ROUGE_L": 0.33559288731702525, "CIDEr": 0.001842602835564068, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.1935483870967742, "f": 0.23076923076923075, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a table with a pair of blue scissors and a roll of tape placed on it. The scissors are positioned on the left side of the table, while the tape is on the right side. The table is covered with wrapping paper."}, "459303": {"image_id": 459303, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.10942600553008858, "Bleu_4": 0.08466528301619354, "METEOR": 0.25877213854731507, "ROUGE_L": 0.2684268426842684, "CIDEr": 1.995474811798415e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a train parked at a train station. The train is black and yellow. There are several people waiting for a bus. Some of the people are taking a selfie, while others are walking on the street or standing. A man is holding a bag. The people are positioned on the platform."}, "497334": {"image_id": 497334, "Bleu_1": 0.3103448275755054, "Bleu_2": 0.23541180770711662, "Bleu_3": 0.16011827597751022, "Bleu_4": 0.11209528409740795, "METEOR": 0.15114807651106996, "ROUGE_L": 0.272078501338091, "CIDEr": 0.005224665090623901, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.13513513513513514, "f": 0.16949152542372883, "fn": 32.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a book lying on top of a white bedspread. The cover of the book is red. The book is positioned in the center of the bedspread."}, "173138": {"image_id": 173138, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.26261286571054043, "Bleu_3": 0.2309305147272122, "Bleu_4": 0.19233147636031842, "METEOR": 0.2917351484589839, "ROUGE_L": 0.39757914338919925, "CIDEr": 0.0021995357819887145, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21875, "f": 0.18918918918918917, "fn": 25.0, "numImages": 1.0, "fp": 35.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.38461538461538464, "f": 0.3225806451612903, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "The image features two boys wearing wetsuits, sitting on a surfboard in the ocean. Both boys are smiling and enjoying their time in the water. The surfboard is positioned horizontally."}, "404984": {"image_id": 404984, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.2545139051836993, "Bleu_3": 0.15185080561293815, "Bleu_4": 0.0993086778757067, "METEOR": 0.22882379019033555, "ROUGE_L": 0.3559445660102115, "CIDEr": 8.845673779829934e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a living room with hardwood floors. There are two couches in the living room. A television is mounted on the wall. \n\nThe living room is connected to a dining area, featuring a dining table and chairs."}, "427965": {"image_id": 427965, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.2717786532439402, "Bleu_3": 0.19263273100143882, "Bleu_4": 0.1477490668198833, "METEOR": 0.3149850669857364, "ROUGE_L": 0.4082705868292101, "CIDEr": 0.0005315739543364662, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.2777777777777778, "f": 0.3703703703703704, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image depicts a living room filled with various furniture. There is a couch in the room. A chair and ottoman are also present. A television can be seen in the living room."}, "445834": {"image_id": 445834, "Bleu_1": 0.4210526315567868, "Bleu_2": 0.3058876451442025, "Bleu_3": 0.22245131744653424, "Bleu_4": 2.8800248891758127e-05, "METEOR": 0.24626271459866225, "ROUGE_L": 0.5005861664712778, "CIDEr": 0.25958050444183145, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.28, "f": 0.30434782608695654, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a group of four people standing near a white bus. One person is wearing a backpack."}, "386958": {"image_id": 386958, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.16302782918400804, "Bleu_3": 0.08654590923115621, "Bleu_4": 1.1282878483696187e-05, "METEOR": 0.2166038428061735, "ROUGE_L": 0.2616154395997141, "CIDEr": 1.2889233804320717e-06, "SPICE": {"All": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a red and white fire hydrant situated on the side of a road. The fire hydrant is positioned next to a yellow pole, creating a striking contrast between the red and yellow colors. The fire hydrant appears to be rusted."}, "306135": {"image_id": 306135, "Bleu_1": 0.29032258064047867, "Bleu_2": 0.20696492241485778, "Bleu_3": 0.12890046917630668, "Bleu_4": 0.0923071558104454, "METEOR": 0.2531706650391623, "ROUGE_L": 0.21675126903553296, "CIDEr": 2.6462738798994072e-15, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.125, "f": 0.17777777777777778, "fn": 28.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image depicts a man riding a skateboard in front of a statue of a horse. The man is wearing a red shirt and appears to be the main focus of the scene. There are several other people in the background, some of whom are walking down the street, riding bikes, riding horses, or playing football. The man is walking up stairs."}, "335839": {"image_id": 335839, "Bleu_1": 0.404255319140335, "Bleu_2": 0.3247428357002883, "Bleu_3": 0.21085094168690133, "Bleu_4": 2.1484165518058135e-05, "METEOR": 0.3338551679777307, "ROUGE_L": 0.4268221574344023, "CIDEr": 2.475700602103317e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "In the image, there is a man standing on a sidewalk next to a red fire hydrant. The man is wearing a black and red jacket and appears to be posing for a picture. He is positioned in front of a wall that is covered in graffiti."}, "190313": {"image_id": 190313, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.16026009915056863, "Bleu_4": 0.1375449327243505, "METEOR": 0.2762299165369066, "ROUGE_L": 0.33443564528761643, "CIDEr": 1.3550853398224003e-08, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a woman sitting on a bench outside a store window. The woman is wearing glasses and a black jacket. She appears to be enjoying her time outdoors. There is a handbag placed on the bench next to her.\n\nIn the background, there is a bicycle parked."}, "85328": {"image_id": 85328, "Bleu_1": 0.14736842105108033, "Bleu_2": 0.07918962457547574, "Bleu_3": 0.04070219898923736, "Bleu_4": 5.203151220021486e-06, "METEOR": 0.1612660874718681, "ROUGE_L": 0.15653640296209398, "CIDEr": 3.865471730007553e-44, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts a train station with a green and yellow train parked on the tracks. The train occupies a significant portion of the scene, stretching from the left side to the right side of the image.\n\nThere are four people present at the train station. Some people are riding a bike, some are riding a skateboard, and a group of people are posing for a picture. Others are simply walking down the street.\n\nThe train is parked on the tracks. The people are standing on the platform. The train is close to the people."}, "104002": {"image_id": 104002, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.1587768372028858, "Bleu_3": 9.14155586877348e-07, "Bleu_4": 2.2104342120771487e-09, "METEOR": 0.18190315696497542, "ROUGE_L": 0.2469635627530364, "CIDEr": 4.104180285738862e-05, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.75, "re": 1.0, "f": 0.8571428571428571, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts a large herd of nine cows grazing in a lush green field. Some of the cows are walking in the field, while others are standing or eating grass. The field is brown."}, "37389": {"image_id": 37389, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.14129296641606834, "Bleu_3": 0.1125566132145619, "Bleu_4": 0.08485844890318373, "METEOR": 0.2869921210773055, "ROUGE_L": 0.2807825086306099, "CIDEr": 3.664134514621901e-15, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16, "f": 0.16326530612244897, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts a clock tower towering over a city street. A clock is prominently displayed on the side of the tower, and the crest of the king of the dwarves is also prominently displayed on the side of the tower. The tower is situated in front of a building, adding to the urban atmosphere of the scene."}, "383594": {"image_id": 383594, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.2390457218620491, "Bleu_3": 0.19258567855148653, "Bleu_4": 0.15702128401926804, "METEOR": 0.2597746065381897, "ROUGE_L": 0.38143576417086233, "CIDEr": 1.4639367967662695e-08, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.22727272727272727, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a delicious meal on a dining table, consisting of a sandwich cut in half and placed on a white plate. The sandwich appears to be a chicken sandwich, and it is accompanied by pickles and onions on the side. A knife is also present on the table."}, "319696": {"image_id": 319696, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.2704409323110328, "Bleu_3": 0.16833306223397848, "Bleu_4": 0.10146679426757717, "METEOR": 0.2580113502894313, "ROUGE_L": 0.28696236559139787, "CIDEr": 5.640402551894086e-10, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2, "f": 0.22727272727272727, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a red microwave oven sitting on top of a kitchen counter. \n\nThere is no clock in the scene.\n\nThere are two bottles placed on the counter. One is a glass bottle with a skull and crossbones, and the other is a silver plated coffee pot."}, "318911": {"image_id": 318911, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.17864740024886272, "Bleu_3": 0.12767884383539146, "Bleu_4": 0.08246811684519831, "METEOR": 0.2070308829323594, "ROUGE_L": 0.270595690747782, "CIDEr": 2.8019692660334426e-09, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2777777777777778, "f": 0.31250000000000006, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.6666666666666666, "f": 0.6153846153846153, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image depicts a herd of eleven sheep gathered together in a fenced-in area. The sheep are of various sizes, indicating a mix of ages and stages of growth. Some of the sheep are standing, while others are sitting or lying down. They are a herd of sheep."}, "455506": {"image_id": 455506, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.24445060351331568, "Bleu_3": 0.18300341915451226, "Bleu_4": 0.13401579985634196, "METEOR": 0.32115598431585635, "ROUGE_L": 0.39638989169675093, "CIDEr": 2.3828138767471583e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16666666666666666, "f": 0.21621621621621623, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "In the image, a dog is running through a lush green field, carrying a green frisbee in its mouth. The dog is playing with the frisbee. The field is surrounded by trees, creating a serene and natural environment for the dog."}, "444631": {"image_id": 444631, "Bleu_1": 0.2027027026999635, "Bleu_2": 0.13941752208425523, "Bleu_3": 0.08142868214257813, "Bleu_4": 9.338313881143505e-06, "METEOR": 0.25255831194691963, "ROUGE_L": 0.19641214351425942, "CIDEr": 2.2747018780310718e-26, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.06896551724137931, "f": 0.1142857142857143, "fn": 27.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image captures a beach scene with two women. One woman is walking on the wet sand, carrying a surfboard. She is wearing a wetsuit and appears to be enjoying her time at the beach. The other woman is walking on the street, carrying a bag of groceries. She is wearing a white shirt and a black jacket. \n\nThere is sand in the scene, and a person with a surfboard is on the sand."}, "497014": {"image_id": 497014, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2976467318172675, "Bleu_3": 0.18645750912795347, "Bleu_4": 2.0064110493528108e-05, "METEOR": 0.2672054653443364, "ROUGE_L": 0.3238221632382216, "CIDEr": 4.567453387432143e-06, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.19047619047619047, "f": 0.14545454545454542, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "In the image, a dog is catching a blue frisbee. The dog is positioned in the middle of the scene, with the frisbee in its mouth as it attempts to catch it. The dog's excitement and determination are evident as it leaps."}, "502749": {"image_id": 502749, "Bleu_1": 0.17741935483584811, "Bleu_2": 0.12059257882752877, "Bleu_3": 0.06234906879538532, "Bleu_4": 8.00588736534904e-06, "METEOR": 0.09961228894497455, "ROUGE_L": 0.16275346851654215, "CIDEr": 5.3855739308698644e-18, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.22727272727272727, "f": 0.29411764705882354, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts a kitchen with white cabinets and gray countertops. A light fixture is above the countertop. A counter top is on the left side of the kitchen. A counter with a sink is on the right side of the kitchen. There is no refrigerator or microwave in the scene. There is an oven on the right side of the kitchen."}, "230593": {"image_id": 230593, "Bleu_1": 0.5624999999648439, "Bleu_2": 0.3354101966033067, "Bleu_3": 0.2002971772439066, "Bleu_4": 2.803950119799468e-05, "METEOR": 0.1935802993745296, "ROUGE_L": 0.3065326633165829, "CIDEr": 0.41796693488495085, "SPICE": {"All": {"pr": 0.19444444444444445, "re": 0.2692307692307692, "f": 0.22580645161290322, "fn": 19.0, "numImages": 1.0, "fp": 29.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "There are no geese in this image. The image shows a paved path in a park."}, "364636": {"image_id": 364636, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.21223817998318864, "Bleu_3": 0.13704703969756082, "Bleu_4": 1.658756031133264e-05, "METEOR": 0.20675350557201613, "ROUGE_L": 0.2848249027237354, "CIDEr": 0.0001161167959521361, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a brown dog standing on a dirt field. The dog is wearing a red collar. Its tongue is hanging out of its mouth, indicating that it might be panting or enjoying the outdoor environment."}, "288313": {"image_id": 288313, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.24809883171680105, "Bleu_3": 0.12568860753791988, "Bleu_4": 1.6039529419560237e-05, "METEOR": 0.21791963566388456, "ROUGE_L": 0.397329425175053, "CIDEr": 0.003342462915247856, "SPICE": {"All": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a table with a black tablecloth. On the table, there is a plate filled with ham, cheese, pickles, and radishes. There is also a bowl of cereal on the table."}, "384503": {"image_id": 384503, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.08219949365042624, "Bleu_3": 5.779497498191423e-07, "Bleu_4": 1.5436464226375294e-09, "METEOR": 0.13748016133096058, "ROUGE_L": 0.20115416323165708, "CIDEr": 4.698259189839611e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a green train traveling down a street, passing by a building. The street is lined with trees, creating a pleasant atmosphere.\n\nThe train is an old-fashioned model, adding a nostalgic touch to the scene."}, "190156": {"image_id": 190156, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.31790537866317753, "Bleu_3": 0.2486825545852068, "Bleu_4": 0.1922852004748076, "METEOR": 0.2937016725616413, "ROUGE_L": 0.32562277580071175, "CIDEr": 4.643502812615854e-08, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.047619047619047616, "f": 0.060606060606060615, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image features a black and white cat sitting on a desk in front of a computer monitor. The cat is drinking from a cup. The cup is positioned on the desk. The cat's head is close to the cup.\n\nThere is no coffee in the scene."}, "174123": {"image_id": 174123, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.2073316795323305, "Bleu_3": 0.09508684604043703, "Bleu_4": 1.1509098628155357e-05, "METEOR": 0.24774142469889077, "ROUGE_L": 0.2995440196422308, "CIDEr": 2.752763784001948e-08, "SPICE": {"All": {"pr": 0.35, "re": 0.2413793103448276, "f": 0.2857142857142857, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "In the image, there are two people. One person is sitting at a dining table with a white plate in front of them. The plate is topped with a pizza. A fork is placed on the plate, ready to be used to enjoy the meal. The other person is cutting a mushroom."}, "557239": {"image_id": 557239, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.161880977056518, "Bleu_3": 0.10026270761741987, "Bleu_4": 0.06667484695194902, "METEOR": 0.2812653863299024, "ROUGE_L": 0.31443298969072164, "CIDEr": 4.1890231424386964e-12, "SPICE": {"All": {"pr": 0.5, "re": 0.2777777777777778, "f": 0.35714285714285715, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features an orange and white cat sitting inside a white toilet bowl. The cat appears to be relaxed and comfortable in the unusual setting. The toilet bowl takes up a lot of space in the frame. The cat's position suggests it is relaxed. The cat's expression suggests it is curious."}, "184474": {"image_id": 184474, "Bleu_1": 0.19999999999000004, "Bleu_2": 0.1025978352032506, "Bleu_3": 8.362471099100377e-07, "Bleu_4": 2.421802605156986e-09, "METEOR": 0.1873219023652703, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.06381789157622919, "SPICE": {"All": {"pr": 0.2, "re": 0.20689655172413793, "f": 0.20338983050847456, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5, "f": 0.48000000000000004, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features a bench made of wood, positioned in the middle of a field. Tall grass surrounds the bench."}, "335099": {"image_id": 335099, "Bleu_1": 0.249999999996875, "Bleu_2": 0.1687631851367807, "Bleu_3": 0.10308465606670299, "Bleu_4": 0.06141477122628834, "METEOR": 0.1676236554187138, "ROUGE_L": 0.2036727879799666, "CIDEr": 7.277753711399386e-25, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two dogs sitting on the ground in front of a metal fence. One dog is brown and the other is white and brown. Both dogs are looking through a window, possibly observing their surroundings. One dog is positioned in the center of the scene, with a cat behind it. The other dog is also positioned in the center of the scene, with a brick wall behind it.\n\nThe overall scene shows the dogs sitting behind the gate."}, "431306": {"image_id": 431306, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1403458930502932, "Bleu_3": 7.708626205337203e-07, "Bleu_4": 1.817274019118142e-09, "METEOR": 0.22368238512803418, "ROUGE_L": 0.24887800897592818, "CIDEr": 2.3750602572677438e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.11764705882352941, "f": 0.14285714285714285, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a restroom with two sinks positioned next to each other. A man is standing in front of one of the sinks, taking a selfie. The man is reflected in the mirror above the sink. The restroom can be seen in the mirror."}, "125815": {"image_id": 125815, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1825741858309521, "Bleu_3": 0.13248819441873214, "Bleu_4": 0.08626220664499869, "METEOR": 0.24050069706080843, "ROUGE_L": 0.3233929754804506, "CIDEr": 7.878181436806842e-07, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.125, "f": 0.16216216216216217, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a train parked at a train station. The train occupies a significant portion of the scene, stretching from the left side to the right side of the image. The train appears to be a vintage model, possibly from the early 20th century."}, "521106": {"image_id": 521106, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.11536522398785581, "Bleu_3": 0.06194229136940917, "Bleu_4": 8.107739336218946e-06, "METEOR": 0.20393826484248379, "ROUGE_L": 0.20220994475138118, "CIDEr": 2.8428520813850166e-12, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.05263157894736842, "f": 0.041666666666666664, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image captures a tennis player in action on a tennis court. The male tennis player is playing tennis. He is swinging a tennis racket. A tennis ball is in the air, as the male tennis player swings to hit it. The player is wearing a yellow shirt and yellow shorts. The tennis ball is on the court."}, "508672": {"image_id": 508672, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.16487339804051732, "Bleu_4": 0.1293698116812338, "METEOR": 0.25998910978990125, "ROUGE_L": 0.27319257837492, "CIDEr": 1.5223128728567473e-10, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.3157894736842105, "f": 0.39999999999999997, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.8, "f": 0.8000000000000002, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image depicts a red bicycle parked next to a flooded road. The bicycle is leaning against a metal fence or gate, which appears to be a part of a bridge. The fence is located near the center of the scene. The bicycle is positioned on the side of the road."}, "221737": {"image_id": 221737, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.17807996398101744, "Bleu_3": 0.11472822500028991, "Bleu_4": 1.3853411725353961e-05, "METEOR": 0.20943638906822687, "ROUGE_L": 0.2197406340057637, "CIDEr": 4.024305477134959e-07, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.34782608695652173, "f": 0.3555555555555555, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image depicts two roads, with a traffic light hanging above one of them. The traffic light is currently displaying a red light. The road with the traffic light is surrounded by a lush green field, giving the impression of a peaceful countryside setting."}, "345580": {"image_id": 345580, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.13663794162380996, "Bleu_4": 0.11296250966115559, "METEOR": 0.23595443961045887, "ROUGE_L": 0.23252858958068615, "CIDEr": 3.172322385441357e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.23529411764705882, "f": 0.2162162162162162, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a zebra standing in a dirt field. The zebra is black and white. Its head is tilted downward. The zebra is standing in the dirt. The zebra is positioned in the center of the scene. The person in the black shirt is capturing the viewer's attention."}, "46440": {"image_id": 46440, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.3638034375324306, "Bleu_3": 0.26034991751675446, "Bleu_4": 3.350704079297443e-05, "METEOR": 0.25369349452293266, "ROUGE_L": 0.3257676902536716, "CIDEr": 0.4667244673449482, "SPICE": {"All": {"pr": 0.15, "re": 0.2, "f": 0.17142857142857143, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image depicts three men playing basketball on a court. They are actively participating in the game."}, "270066": {"image_id": 270066, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.29277002187631135, "Bleu_3": 0.23272771163825715, "Bleu_4": 0.16625131470017054, "METEOR": 0.27529327988783553, "ROUGE_L": 0.3341158059467919, "CIDEr": 0.00038455992179691183, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.35294117647058826, "f": 0.33333333333333337, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a white motorcycle parked in a parking lot. The motorcycle is prominently positioned in the foreground, occupying a parking space. \n\nIn the background, there is a truck parked in front of the motorcycle."}, "419867": {"image_id": 419867, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.08845670453991433, "Bleu_4": 1.1398615456851686e-05, "METEOR": 0.21820242547336674, "ROUGE_L": 0.29735376044568246, "CIDEr": 5.464294623175259e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2608695652173913, "f": 0.2926829268292683, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a grocery store aisle with a large display of bananas. Bananas are hanging from the shelves, showcasing a variety of sizes and ripeness levels. Some of the bananas are closer to the front of the display, while others are further back."}, "194724": {"image_id": 194724, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 0.10886194393769152, "Bleu_4": 1.2611435407275347e-05, "METEOR": 0.17561952266519767, "ROUGE_L": 0.2738496071829405, "CIDEr": 1.2697910422631592e-09, "SPICE": {"All": {"pr": 0.375, "re": 0.45, "f": 0.4090909090909091, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a dining table with a delicious pizza placed on a wooden platter. The pizza is topped with olives, mushrooms, onions, peppers, and olives. A glass of wine is next to the pizza. A loaf of bread is also next to the pizza. \n\nThere are no other items on the dining table."}, "236426": {"image_id": 236426, "Bleu_1": 0.49999999998076927, "Bleu_2": 0.3162277660044321, "Bleu_3": 0.16091489742782825, "Bleu_4": 2.06307601736959e-05, "METEOR": 0.2933748250665894, "ROUGE_L": 0.36761751707513063, "CIDEr": 0.04376242045100371, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a man playing tennis on a tennis court. The man is wearing a blue shirt and blue shorts. He is preparing to serve."}, "499826": {"image_id": 499826, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.10523401123300179, "Bleu_3": 6.464120807060151e-07, "Bleu_4": 1.6120076571346083e-09, "METEOR": 0.1710038102734402, "ROUGE_L": 0.24286662242866625, "CIDEr": 2.1504011284731927e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image depicts four elephants walking down a road. The woman is standing in front of the elephants. The woman is waving to the elephants. The elephants are spread out along the road, with some closer to the woman and others further away."}, "514904": {"image_id": 514904, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.1609148974309868, "Bleu_4": 0.13722641665543406, "METEOR": 0.3271815161870132, "ROUGE_L": 0.34099378881987574, "CIDEr": 2.184543514167226e-10, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2631578947368421, "f": 0.21739130434782608, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a woman wearing sunglasses and holding two hot dogs in her hands. She is smiling and appears to be enjoying the moment. The hot dogs are wrapped in paper, making them easy to carry and eat on the go.\n\nIn the background, there is a bus parked."}, "359864": {"image_id": 359864, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.19867985355623988, "Bleu_3": 0.15309875502062964, "Bleu_4": 0.09028805642930539, "METEOR": 0.2902214704913292, "ROUGE_L": 0.3284868066774367, "CIDEr": 2.364842213534101e-13, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.5, "f": 0.3684210526315789, "fn": 7.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man wearing a red cap and sunglasses, standing on a boat and looking out over the water. He appears to be enjoying his time on the boat and taking in the view. The man is wearing a red jacket, which complements his hat and sunglasses.\n\nThere is no other hat in the scene."}, "247333": {"image_id": 247333, "Bleu_1": 0.382352941165225, "Bleu_2": 0.24069122088509454, "Bleu_3": 1.2187749155325176e-06, "Bleu_4": 2.764408418598239e-09, "METEOR": 0.2580000680444418, "ROUGE_L": 0.3954619124797406, "CIDEr": 0.0004663521061592862, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.17391304347826086, "f": 0.2222222222222222, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a plate filled with a delicious assortment of food. The plate is topped with a salad, consisting of ham, lettuce, tomatoes, and carrots. The plate is placed on a dining table."}}}