{"overall": {"Bleu_1": 0.2635599290921993, "Bleu_2": 0.17860995043605854, "Bleu_3": 0.1143015938624711, "Bleu_4": 0.07407951383771867, "METEOR": 0.21914802001366618, "ROUGE_L": 0.2584694813964993, "CIDEr": 0.004242659069567901, "SPICE": 0.1825090435439611}, "imgToEval": {"502090": {"image_id": 502090, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.28224912794839524, "Bleu_3": 0.19712602266947096, "Bleu_4": 0.11070453843215756, "METEOR": 0.27584071247315645, "ROUGE_L": 0.2853801169590643, "CIDEr": 3.285228279228833e-12, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a kite flying in the sky over the ocean. The kite is made of white and blue fabric and has a long tail. There are two people standing on the beach, one holding the kite and the other holding a surfboard. The sky is clear and blue, with a few clouds"}, "3084": {"image_id": 3084, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.22496063532707972, "Bleu_3": 0.11100361229353628, "Bleu_4": 1.3961343379881599e-05, "METEOR": 0.21669993621054193, "ROUGE_L": 0.3559445660102115, "CIDEr": 0.00038078152968042936, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.1724137931034483, "f": 0.17857142857142858, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a brick wall with a clock on it. The clock has Roman numerals and hands. The brick wall is red and has a lot of cracks in it. There are no other objects in the image."}, "440529": {"image_id": 440529, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.18216065373578985, "Bleu_3": 0.08722608547574777, "Bleu_4": 1.0787871557193924e-05, "METEOR": 0.22041032734274338, "ROUGE_L": 0.22536945812807885, "CIDEr": 2.983782856620527e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a man holding a bird in his hand. The bird is a small, brown and white bird with a distinctive black stripe on its head. The man is wearing a green shirt and khaki pants, and has a friendly expression on his face. The background is a green and"}, "4495": {"image_id": 4495, "Bleu_1": 0.1904761904716554, "Bleu_2": 0.11805626721734595, "Bleu_3": 0.07036759386059058, "Bleu_4": 9.722173654629655e-06, "METEOR": 0.19315143709109758, "ROUGE_L": 0.2279521674140508, "CIDEr": 2.2605230484282987e-07, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.12, "f": 0.10344827586206896, "fn": 22.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.42857142857142855, "f": 0.26086956521739124, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The room is empty except for a couch and a television. The walls are painted yellow and there are no windows.\n\nThe room is empty except for a couch and a television. The walls are painted yellow and there are no windows."}, "537692": {"image_id": 537692, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.17188791273498485, "Bleu_3": 0.11796125658360214, "Bleu_4": 0.08871418644312987, "METEOR": 0.23052116800241607, "ROUGE_L": 0.2622527944969905, "CIDEr": 1.4845352380315927e-12, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3125, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a table with a lamp on it and a bunch of scissors on it. The lamp is a small, white lamp with a shade that is made of a material that looks like it is made of metal. The scissors are made of metal and have a handle that is made of a"}, "297267": {"image_id": 297267, "Bleu_1": 0.35087719297630043, "Bleu_2": 0.22388683141585963, "Bleu_3": 0.13983156609704764, "Bleu_4": 0.08435396018679067, "METEOR": 0.2452432555863431, "ROUGE_L": 0.2543369816097089, "CIDEr": 2.5628622024230454e-12, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a train traveling down a track next to a group of people standing on the platform. The train has a red and black engine and is pulling a number of cars behind it. The people on the platform are wearing casual clothing and are looking at the train as it passes by. The train"}, "474167": {"image_id": 474167, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.14953924108841646, "Bleu_3": 0.07548065617692518, "Bleu_4": 9.582618669737836e-06, "METEOR": 0.21356740663161222, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.51174467333409e-12, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a table with two slices of pizza on it. The slices are cut into small pieces and are placed on top of a white paper plate. There is a glass of soda on the table next to the pizza. The table is made of wood and has a white tablecloth on"}, "24601": {"image_id": 24601, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2497770842103635, "Bleu_3": 0.12492568368856392, "Bleu_4": 1.5836105185157607e-05, "METEOR": 0.26884668500517034, "ROUGE_L": 0.3669172932330827, "CIDEr": 0.0037328042172881225, "SPICE": {"All": {"pr": 0.25, "re": 0.17857142857142858, "f": 0.20833333333333331, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a woman playing tennis on a clay court. She is wearing a white dress and has a racket in her hand. There are several people in the background watching the match."}, "199310": {"image_id": 199310, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.14979742339481708, "Bleu_4": 0.12039217537167975, "METEOR": 0.2799029712855335, "ROUGE_L": 0.29847094801223245, "CIDEr": 2.3954904761204066e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.06896551724137931, "f": 0.08, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The man is holding a tennis racket and standing in the grass. He is wearing a black shirt and jeans. The grass is green and there are some flowers in the background.\n\nThe man is holding a tennis racket and standing in the grass. He is wearing a black shirt and"}, "198139": {"image_id": 198139, "Bleu_1": 0.1428571428545919, "Bleu_2": 0.10192943828568843, "Bleu_3": 0.07273528851712341, "Bleu_4": 9.230812022099043e-06, "METEOR": 0.18895124271987543, "ROUGE_L": 0.20795454545454545, "CIDEr": 3.75596511961804e-13, "SPICE": {"All": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a white car parked on the side of the road. The car has a green license plate on the front and a red light on the back. There is a white wall in the background with a green and blue mural on it. The mural depicts a man and a woman standing on"}, "210032": {"image_id": 210032, "Bleu_1": 0.31034482758085613, "Bleu_2": 0.23333765443696047, "Bleu_3": 0.14287874532628775, "Bleu_4": 1.517522183850875e-05, "METEOR": 0.18732143608718646, "ROUGE_L": 0.23591160220994478, "CIDEr": 1.1890741464177912e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1875, "f": 0.19999999999999998, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a table with a bird perched on top of it. The bird is eating a piece of bread. There are two people sitting at the table, one with a drink in their hand and the other with a plate of food in front of them. The background is a body of water with a bridge"}, "50277": {"image_id": 50277, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.10484363678213089, "Bleu_4": 0.06999971125156287, "METEOR": 0.1997016815477026, "ROUGE_L": 0.2544392801811465, "CIDEr": 2.243520468554377e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6666666666666666, "f": 0.5217391304347826, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "This image shows a group of seagulls flying over the beach. The birds are in mid-air, with their wings spread out and their beaks open. They are flying in a line, with one bird leading the way and the others following behind. The sky is blue and cloudy, with a few"}, "171695": {"image_id": 171695, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.09337611011479056, "Bleu_4": 1.1534197288455865e-05, "METEOR": 0.23705690422944192, "ROUGE_L": 0.2208811104405552, "CIDEr": 2.7424980156856227e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a parade of trucks with people on them, driving down a street with tall buildings on either side. The trucks are decorated with flags and banners, and people are waving and cheering from the sides of the road. There are also people standing on the sidewalk"}, "277162": {"image_id": 277162, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.08748177652616675, "Bleu_3": 0.0546066804601931, "Bleu_4": 7.713382612340196e-06, "METEOR": 0.15992530009380845, "ROUGE_L": 0.26341764342998153, "CIDEr": 5.106794752777141e-10, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.25, "f": 0.1702127659574468, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a person holding a hot dog in their hand. The hot dog is topped with cheese, lettuce, and tomato. The person is wearing a white shirt and black pants. There is a table in the background with a white tablecloth and a red and white striped"}, "404618": {"image_id": 404618, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.20195126571496114, "Bleu_3": 0.09406593130377756, "Bleu_4": 1.1475297679846865e-05, "METEOR": 0.24638519039501605, "ROUGE_L": 0.2238532110091743, "CIDEr": 6.330252415419047e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.14285714285714285, "f": 0.15094339622641512, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person walking down the sidewalk in front of a yellow fire hydrant. The person is wearing a black jacket and black pants, and has a black backpack on their back. The hydrant is painted with black and white stripes. The sidewalk is made of concrete and has"}, "399759": {"image_id": 399759, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.24798277706238742, "Bleu_3": 0.19216029128039422, "Bleu_4": 0.1535925639033445, "METEOR": 0.31674351920196986, "ROUGE_L": 0.308080808080808, "CIDEr": 2.500697640462571e-11, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2631578947368421, "f": 0.23809523809523808, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman sitting on a bench in front of a fountain in the middle of a city. The woman is holding a hot dog in her hand and looking at the camera. The fountain is made of bronze and has a mermaid statue in the center. The statue is surrounded by"}, "44627": {"image_id": 44627, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.08206702275709715, "Bleu_4": 1.041362763232212e-05, "METEOR": 0.25314997676287926, "ROUGE_L": 0.30310559006211185, "CIDEr": 2.207148427460509e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.13333333333333333, "f": 0.1568627450980392, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a young man performing a skateboard trick on a ramp. He is wearing a blue shirt and black pants, and has a black and white skateboard under his feet. There are several people watching him from the sidelines, and a few more are standing on the s"}, "35963": {"image_id": 35963, "Bleu_1": 0.13793103448038055, "Bleu_2": 0.08520286456697913, "Bleu_3": 5.061044102501325e-07, "Bleu_4": 1.2390516745962156e-09, "METEOR": 0.119382643061422, "ROUGE_L": 0.17192784667418262, "CIDEr": 1.1991635614393133e-12, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image is of a statue of a woman holding a baby in her arms. The statue is made of stone and is located in a park. The park is surrounded by trees and has a path leading to a house. The house is white with a red roof and has a porch with a bench. The statue"}, "24629": {"image_id": 24629, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.19154015512649578, "Bleu_3": 0.1283943344001008, "Bleu_4": 0.08026327033859419, "METEOR": 0.2765092110114764, "ROUGE_L": 0.2738496071829405, "CIDEr": 5.926718358777122e-12, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08, "f": 0.08695652173913043, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a stop sign on a street at night. The sign is white with red letters that say stop in English and Arabic. There are also streetlights on the side of the road. The image is taken at night, and there are no cars or people in the scene.\n\nThe image is"}, "456236": {"image_id": 456236, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.24902912254001586, "Bleu_3": 0.11479037464672631, "Bleu_4": 1.3944858351007464e-05, "METEOR": 0.2702203649485509, "ROUGE_L": 0.26852531181217903, "CIDEr": 1.5195261076099488e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.09302325581395349, "f": 0.11764705882352942, "fn": 39.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.0625, "f": 0.10526315789473684, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a plate of food with a steak, mushrooms, and broccoli on it. The steak is cooked to perfection and the mushrooms are sauteed in butter. The broccoli is steamed and served on the side. The plate is set on a white"}, "529314": {"image_id": 529314, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.14189834119414174, "Bleu_4": 1.5702128401926803e-05, "METEOR": 0.19451244124182757, "ROUGE_L": 0.27262569832402234, "CIDEr": 1.979546839724863e-08, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.23076923076923078, "f": 0.13043478260869568, "fn": 10.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.2, "f": 0.1111111111111111, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a soccer game being played on a field with a large crowd of people watching from the sidelines. The players are wearing orange and white jerseys and black shorts, and they are running with the ball on their feet. There are several umbrellas open on the field"}, "334222": {"image_id": 334222, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.23328473740311126, "Bleu_3": 0.17956220625337854, "Bleu_4": 0.1259590106072628, "METEOR": 0.28382684471476993, "ROUGE_L": 0.3010487353485503, "CIDEr": 5.913276576016658e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young man riding a skateboard down a grassy hill. He is wearing a black shirt and blue jeans, and has a backpack on his back. The sky is cloudy and there are trees in the background.\n\nThe image is taken in a park or other"}, "567825": {"image_id": 567825, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.2936101097470465, "Bleu_3": 0.14725139422493916, "Bleu_4": 1.8719800869234396e-05, "METEOR": 0.2427147598924926, "ROUGE_L": 0.34743694060211555, "CIDEr": 0.008979605958548548, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.17857142857142858, "f": 0.17543859649122806, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a hamburger with a bun and a slice of cheese on top. There is a bottle of red wine on the table next to the hamburger."}, "423464": {"image_id": 423464, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.11175167395708337, "Bleu_3": 6.522766823207914e-07, "Bleu_4": 1.584749856288676e-09, "METEOR": 0.1609086116187714, "ROUGE_L": 0.16277518345563707, "CIDEr": 1.245476779355572e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14814814814814814, "f": 0.16666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person doing a trick on a skateboard. The person is wearing a white t-shirt and blue jeans, and has a red and black helmet on their head. The skateboard is red and has white wheels. The person is jumping off a ledge and"}, "472030": {"image_id": 472030, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.08081586876451534, "Bleu_3": 5.040508737561903e-07, "Bleu_4": 1.2650662740672959e-09, "METEOR": 0.16116398371724627, "ROUGE_L": 0.14796846573681016, "CIDEr": 2.109474757739187e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a path through a forest with benches and trees. The path is lined with greenery and there are several benches along the way. The trees are tall and green, and there are many ferns and other plants growing in the area. The sky is clear and blue, and there are"}, "40989": {"image_id": 40989, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.22562131409418867, "Bleu_3": 0.12674769789184412, "Bleu_4": 0.08028899837277662, "METEOR": 0.24551324113663275, "ROUGE_L": 0.2897862232779097, "CIDEr": 1.9721332562700444e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a beach with people sunbathing and umbrellas on the sand\n\nThe beach is surrounded by trees and hills in the background. There are no buildings or structures on the beach. The sand is white and the water is clear and blue. The sky is cloudy with a few white"}, "176180": {"image_id": 176180, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.15569978882944752, "Bleu_3": 0.12230758461254293, "Bleu_4": 0.09158971449059616, "METEOR": 0.26959196638722266, "ROUGE_L": 0.28636096906697955, "CIDEr": 7.877560107789461e-13, "SPICE": {"All": {"pr": 0.32, "re": 0.3076923076923077, "f": 0.3137254901960784, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a person holding a bird in their hand. The bird is perched on top of a book. The person is wearing a white shirt and black pants. The bird is a small bird with a brown body and black wings. The book is open and has a page with text on it."}, "21470": {"image_id": 21470, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.17377018855424126, "Bleu_3": 0.12273221526854444, "Bleu_4": 0.09368414970841243, "METEOR": 0.19039238252346752, "ROUGE_L": 0.25553560742070613, "CIDEr": 7.930688953058609e-11, "SPICE": {"All": {"pr": 0.39285714285714285, "re": 0.4230769230769231, "f": 0.4074074074074074, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 11.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6153846153846154, "re": 0.6153846153846154, "f": 0.6153846153846154, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}}, "caption": "The image shows a baseball player in a white jersey and blue pants, standing on a baseball field. The player is holding a baseball bat and looking down at the ground. The image is in black and white.\n\nThe image shows a baseball player in a white jersey and blue pants,"}, "232187": {"image_id": 232187, "Bleu_1": 0.3636363636297521, "Bleu_2": 0.23210354127000468, "Bleu_3": 0.12667936754426512, "Bleu_4": 0.07907306606562477, "METEOR": 0.23618536502318005, "ROUGE_L": 0.27882173692229556, "CIDEr": 3.460474251687308e-06, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a woman in a white tennis outfit standing in front of a chain link fence. She is holding a tennis racket and has a ball in her hand. There are other people in the background, including a boy in a baseball cap and a girl in a pink shirt. The sky is"}, "347018": {"image_id": 347018, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.14280110945625535, "Bleu_3": 0.07466017915299245, "Bleu_4": 9.649536682952496e-06, "METEOR": 0.21576236054646783, "ROUGE_L": 0.25831820931639443, "CIDEr": 7.5191642180931e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a baseball player at the plate, with a bat in his hand and a ball in his glove. The player is wearing a black and yellow jersey with the number 23 on the back. The umpire is standing behind the plate, with a yellow and black striped sh"}, "404367": {"image_id": 404367, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.11651034560483009, "Bleu_3": 6.475197095245912e-07, "Bleu_4": 1.5342308957715506e-09, "METEOR": 0.24633060274869986, "ROUGE_L": 0.1920654911838791, "CIDEr": 1.049828287734197e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white shirt and black shorts, and has a racket in her hand. The court is made of red clay and has a net in the middle. There are trees in the background and a fence around the court."}, "137315": {"image_id": 137315, "Bleu_1": 0.3999999999927273, "Bleu_2": 0.34426518632323083, "Bleu_3": 0.29082674542346143, "Bleu_4": 0.23988297789923863, "METEOR": 0.30331910647361243, "ROUGE_L": 0.38956891963810536, "CIDEr": 3.6520338873386044e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man sitting at a table with a plate of food in front of him. There are several glasses of wine on the table, as well as a bottle of wine on the side. The man is wearing a yellow shirt and has a beard. The table is made of wood and"}, "580255": {"image_id": 580255, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.25161813986556425, "Bleu_3": 0.2271764864240277, "Bleu_4": 0.20510491285479543, "METEOR": 0.37845528919102595, "ROUGE_L": 0.42451820128479656, "CIDEr": 1.7162323588092737e-11, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows two dogs sitting in the back seat of a car. The dogs are black and brown, and they are looking out the window. The car is parked on the side of the road, and there is a tree in the background. The sky is cloudy and there are no other cars in sight."}, "345275": {"image_id": 345275, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.12993504870706918, "Bleu_3": 0.08551250345584478, "Bleu_4": 0.05860750703211417, "METEOR": 0.17302296927889207, "ROUGE_L": 0.22858672376873657, "CIDEr": 8.045317230147861e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a view of a body of water with mountains in the background. The water is calm and there are no boats or other objects in the water. The sky is clear and there are no clouds in the sky. The sun is shining and there is a light breeze blowing. The temperature is"}, "461722": {"image_id": 461722, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.14754891442234067, "Bleu_3": 0.11952367853238387, "Bleu_4": 0.10060701777161159, "METEOR": 0.23969350078860624, "ROUGE_L": 0.25341246290801184, "CIDEr": 2.8510972255963986e-11, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.22727272727272727, "f": 0.1724137931034483, "fn": 17.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a young girl sitting at a table with a plate of food in front of her. She is wearing a green shirt and has long blonde hair. The background is a kitchen with a countertop and cabinets. There is a window in the background with a view of the outside."}, "496575": {"image_id": 496575, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.088065799309334, "Bleu_4": 0.0607943136593165, "METEOR": 0.1749829281673948, "ROUGE_L": 0.22195269860521533, "CIDEr": 4.672396144495294e-10, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.24242424242424243, "f": 0.25, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people skiing down a mountain. They are all wearing ski gear and helmets. The snow is covered in trees and there are some rocks in the background. The sky is blue and there are some clouds in the distance.\n\nThe image is taken from a high angle"}, "102735": {"image_id": 102735, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 0.06923138992163505, "Bleu_4": 9.071482520661878e-06, "METEOR": 0.1822434383405104, "ROUGE_L": 0.18373493975903615, "CIDEr": 3.7798909496931537e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.18518518518518517, "f": 0.20408163265306123, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a dog standing in front of a parked motorcycle. The dog is looking up at the motorcycle with its tongue hanging out of its mouth. The motorcycle has a license plate on the back of it. There are several other motorcycles parked nearby. The image is taken in a"}, "316112": {"image_id": 316112, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.20603150145092247, "Bleu_3": 0.12093499873471332, "Bleu_4": 1.392802503749998e-05, "METEOR": 0.2630906807837758, "ROUGE_L": 0.22938079719227877, "CIDEr": 3.7960772561078923e-10, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.5, "f": 0.3181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 1.0, "f": 0.5882352941176471, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a herd of sheep grazing on a green field. The sheep are of various colors, including black, white, and brown. They are standing in a line, with their heads down and their tails wagging. The sky is blue and cloudy, with a few white clouds scattered throughout"}, "503210": {"image_id": 503210, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.1250180897226835, "Bleu_4": 0.09600584732205708, "METEOR": 0.19403674476497212, "ROUGE_L": 0.236281471917366, "CIDEr": 9.698457775797826e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a living room with a couch, chairs, and a table. There is a large window with curtains and a view of the outdoors. The walls are painted yellow and there are wooden beams on the ceiling. The floor is made of hardwood and there are rugs"}, "42743": {"image_id": 42743, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.1878672873218244, "Bleu_3": 0.11293938405626279, "Bleu_4": 0.07401568312653971, "METEOR": 0.2317494122271014, "ROUGE_L": 0.2799770510613884, "CIDEr": 3.341191184668223e-09, "SPICE": {"All": {"pr": 0.0625, "re": 0.16666666666666666, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.07692307692307693, "re": 0.3333333333333333, "f": 0.125, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The man is wearing a blue shirt and white shorts. He is holding a tennis racket in his right hand and is about to hit the ball with his left hand. The ball is on the ground in front of him. There are several people in the background watching the game."}, "389684": {"image_id": 389684, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.11113289333084049, "Bleu_4": 0.07274999134048009, "METEOR": 0.18748693854256976, "ROUGE_L": 0.24349908759124086, "CIDEr": 2.4311903057669833e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.16666666666666666, "f": 0.2051282051282051, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a bus driving on a road with a sign on the side of the road that reads, \"Bangalore to Mumbai\". The bus is blue and white and has a number on the side. There are people standing on the side of the road and a building in the background."}, "455299": {"image_id": 455299, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.18726241522375653, "Bleu_3": 0.10715656750302463, "Bleu_4": 1.217494725595168e-05, "METEOR": 0.23006015724675052, "ROUGE_L": 0.2799592044875064, "CIDEr": 9.415321284512469e-11, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.17647058823529413, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a computer keyboard and mouse sitting on a desk in front of a computer monitor. The keyboard has a black and white design with a mouse on the right side. The monitor is a flat screen with a blue light on the bottom. There are two speakers on the left side of the monitor and a"}, "206473": {"image_id": 206473, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.1400280084000279, "Bleu_3": 0.09284415754233383, "Bleu_4": 1.136333016795187e-05, "METEOR": 0.18246153737596593, "ROUGE_L": 0.19513755598208574, "CIDEr": 1.3358465629713975e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.3157894736842105, "f": 0.2727272727272727, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a flock of sheep grazing in a green field. The sheep are standing in a line, with their heads down and their tails wagging. The sky is cloudy and there is a hill in the background.\n\nThe image is in black and white, with the sheep and the"}, "64030": {"image_id": 64030, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.14819171472405493, "Bleu_3": 0.07652745233046604, "Bleu_4": 9.829979956142771e-06, "METEOR": 0.21581413193766344, "ROUGE_L": 0.26505276225946617, "CIDEr": 7.457319211562913e-10, "SPICE": {"All": {"pr": 0.24242424242424243, "re": 0.3076923076923077, "f": 0.2711864406779661, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 8.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35294117647058826, "re": 0.5, "f": 0.41379310344827586, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The image shows a group of white swans swimming in a body of water. The swans are swimming in a line, with one swan leading the way and the others following behind. The water is calm and clear, reflecting the sky above. The swans are all facing the same direction, with"}, "82518": {"image_id": 82518, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.21195755288798743, "Bleu_3": 0.10227029320912329, "Bleu_4": 1.2709139936847498e-05, "METEOR": 0.28762904379838955, "ROUGE_L": 0.23890339425587467, "CIDEr": 0.036313552583213934, "SPICE": {"All": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.46153846153846156, "f": 0.4444444444444445, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white shirt and shorts, and has a racket in her hand. The crowd is watching her play. The court is made of grass and there are trees in the background."}, "274599": {"image_id": 274599, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.13363062095380426, "Bleu_3": 0.06915221111259608, "Bleu_4": 8.887622216194529e-06, "METEOR": 0.1876815020009038, "ROUGE_L": 0.2096700274977085, "CIDEr": 2.3457056241105496e-13, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.18181818181818182, "f": 0.1764705882352941, "fn": 27.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5454545454545454, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a group of sheep standing in a barn with a large wooden door in the background. The sheep are all different colors and are standing in a line, looking at the camera. The barn has a large wooden beam in the center of the roof, and there are hay bales stacked in the"}, "550162": {"image_id": 550162, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.18216065373578985, "Bleu_3": 0.1491545080862942, "Bleu_4": 0.11938742404395866, "METEOR": 0.29137142270004496, "ROUGE_L": 0.31697459584295606, "CIDEr": 1.3650924494487588e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The man is holding a bunch of bananas in his hands. He is wearing a white shirt and black pants. The background is a dark brown wall with a white door and a black motorcycle parked next to it. There is a small table with a white umbrella on it. The man"}, "452793": {"image_id": 452793, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 0.07925015807505881, "Bleu_4": 0.05645482725503897, "METEOR": 0.18452554744525548, "ROUGE_L": 0.22048192771084338, "CIDEr": 9.36775878571057e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a kitchen with a refrigerator, stove, and sink. The walls are painted a light beige color and there are no windows in the room. The floor is made of hardwood and there is a small table with two chairs in the corner. The room is well lit and there"}, "87194": {"image_id": 87194, "Bleu_1": 0.1538461538431953, "Bleu_2": 0.12281268769488377, "Bleu_3": 0.09672659665842726, "Bleu_4": 0.06555569265748386, "METEOR": 0.2537988928901417, "ROUGE_L": 0.2688916876574307, "CIDEr": 1.0752534877616558e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a polar bear in a pool of water, holding a fish in its mouth. The bear is white with black fur and has a long, curved tusk. The fish is a small, silver fish with a long, curved tail. The background is a blue, cloudy sky with some white"}, "163728": {"image_id": 163728, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.14836636618698068, "Bleu_3": 0.1082919756727211, "Bleu_4": 0.08400635913890077, "METEOR": 0.2523080574085765, "ROUGE_L": 0.2853801169590643, "CIDEr": 6.575009959040327e-12, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.07692307692307693, "f": 0.07407407407407408, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a cat sleeping on a table with a mouse on its paw. The cat is wearing a collar and has a tag on its neck. The mouse is on the cat's paw and is wearing a tag on its neck as well. The table has a laptop on it and"}, "20913": {"image_id": 20913, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.245934688411173, "Bleu_3": 0.18219922530638885, "Bleu_4": 0.12017396627813878, "METEOR": 0.24291465156729117, "ROUGE_L": 0.36810344827586206, "CIDEr": 0.0007274250464469971, "SPICE": {"All": {"pr": 0.12, "re": 0.12, "f": 0.12, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two hot dogs with ketchup and mustard on them. The hot dogs are on a blue plate with a white background. There are no other objects in the image."}, "105885": {"image_id": 105885, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 0.09041487870756197, "Bleu_4": 1.0972040044962827e-05, "METEOR": 0.13947759041228422, "ROUGE_L": 0.1783625730994152, "CIDEr": 1.7640817451806228e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a fire hydrant in the rain. The hydrant is located on the side of a road and has a sign on it that says \"stop\". There are people standing on the sidewalk and a train passing by in the background.\n\nThe image is taken from a low angle, looking"}, "100678": {"image_id": 100678, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.14877229733819122, "Bleu_4": 0.09198184025804361, "METEOR": 0.25011514318068545, "ROUGE_L": 0.22578655151141266, "CIDEr": 3.522737832567949e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.17647058823529413, "f": 0.13953488372093026, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people walking on a beach. They are all wearing swimsuits and sunglasses. The sky is blue and there are palm trees in the background. The people are walking towards the water.\n\nThe image is taken from a low angle, looking down at the"}, "317656": {"image_id": 317656, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.16487339804051732, "Bleu_4": 0.11689882104179117, "METEOR": 0.2798357918595701, "ROUGE_L": 0.33608815426997246, "CIDEr": 4.081089835131658e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a slice of pizza on a plate with a fork and knife on the side. The pizza has cheese, pepperoni, and olives on it. There is a glass of water on the table next to the plate. The table is made of wood and has a white tablecl"}, "13300": {"image_id": 13300, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.19738550848437394, "Bleu_3": 0.08969032338542009, "Bleu_4": 1.0801653085536467e-05, "METEOR": 0.18165235224358264, "ROUGE_L": 0.2663755458515284, "CIDEr": 1.3582817194070956e-12, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.21428571428571427, "f": 0.20338983050847456, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image is of a vase with a bouquet of flowers in it. The vase is on a shelf in a room with a window to the left and a door to the right. The room has a hardwood floor and white walls. There is a small table with a lamp on it in the corner"}, "45959": {"image_id": 45959, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.21128856367777224, "Bleu_3": 0.12384962799919483, "Bleu_4": 1.4255471031839077e-05, "METEOR": 0.28037785734979354, "ROUGE_L": 0.2663755458515284, "CIDEr": 4.665915166829647e-09, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2857142857142857, "f": 0.24000000000000002, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.7142857142857143, "f": 0.4761904761904762, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a bicycle lane sign on a street corner. The sign has a green and white design with the words \"bicycle lane\" written in black letters. The sign is mounted on a pole next to a sidewalk. There are no other vehicles or pedestrians in the image"}, "349888": {"image_id": 349888, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.23481448977773262, "Bleu_3": 0.17114033061959188, "Bleu_4": 0.11672754025820242, "METEOR": 0.26229110446283227, "ROUGE_L": 0.2900158478605388, "CIDEr": 4.739837502901792e-13, "SPICE": {"All": {"pr": 0.16, "re": 0.2857142857142857, "f": 0.20512820512820512, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on a couch in front of a television. The cat is looking at the television with its head tilted to the side. The television is showing a family with a black cat in the foreground. The family is standing in front of a white background with a black outline of a"}, "69121": {"image_id": 69121, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.10289915108346752, "Bleu_3": 6.000800213279683e-07, "Bleu_4": 1.456620999046851e-09, "METEOR": 0.17760667508864394, "ROUGE_L": 0.19074421513445905, "CIDEr": 2.1208446804794447e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a bathroom with a sink, toilet, and mirror. The walls are made of stone and the floor is made of wood. There is a window on the left side of the room and a light fixture on the ceiling.\n\nThe sink is made of stone and has a fauc"}, "148309": {"image_id": 148309, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.194191754997615, "Bleu_3": 0.14171480766163438, "Bleu_4": 0.08601230531574432, "METEOR": 0.24185805672016478, "ROUGE_L": 0.27961037898010965, "CIDEr": 1.1903825353256623e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.10526315789473684, "f": 0.11764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of birds perched on a wooden bird feeder in a garden. The birds are all different sizes and colors, and they are all looking at each other. The feeder is made of wood and has a metal roof. There are some leaves on the ground around the feeder, and there"}, "426542": {"image_id": 426542, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.09672659665842727, "Bleu_4": 0.06555569265748387, "METEOR": 0.23994038585336758, "ROUGE_L": 0.22048192771084338, "CIDEr": 4.9063377954370735e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.11764705882352941, "f": 0.13559322033898305, "fn": 30.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two baseball players standing on the field, one holding a bat and the other holding a glove. The players are wearing uniforms with the numbers 1 and 2 on their backs. The field is green and there are no spectators in the stands. The sky is cloudy and there"}, "150930": {"image_id": 150930, "Bleu_1": 0.17543859648815024, "Bleu_2": 0.1480872194371519, "Bleu_3": 0.10615274788259942, "Bleu_4": 0.08158446869155907, "METEOR": 0.26490602027030846, "ROUGE_L": 0.24413950829045164, "CIDEr": 9.764011432074456e-14, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2631578947368421, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a black and white photograph of a clock on the side of a building. The clock has two hands and is mounted on a pole. The building is made of brick and has a large window on the side. There are people walking on the sidewalk in front of the building.\n\nThe image is taken"}, "555772": {"image_id": 555772, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 8.378836055206644e-07, "Bleu_4": 1.861395885683349e-09, "METEOR": 0.19280040384174796, "ROUGE_L": 0.22536945812807885, "CIDEr": 1.343566300265309e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a red and white stop sign with the words \"stop zamboni crossing\" written on it. The sign is mounted on a pole in the middle of a parking lot. There are several cars parked in the lot, and the road is covered in snow.\n\nThe image is taken from"}, "541158": {"image_id": 541158, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 0.0974311856710336, "Bleu_4": 0.06558144622470677, "METEOR": 0.21977806144312054, "ROUGE_L": 0.25894481503941785, "CIDEr": 1.8900455919527116e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black and white cat sitting under an umbrella in a room with a white floor and a black and white wall. The cat is looking up at the umbrella with its eyes. The umbrella is open and has a black handle. The cat is wearing a collar with a"}, "151492": {"image_id": 151492, "Bleu_1": 0.2830188679191884, "Bleu_2": 2.3329531792993197e-09, "Bleu_3": 4.743300325935382e-12, "Bleu_4": 2.1494035723042316e-13, "METEOR": 0.21116799071597797, "ROUGE_L": 0.2334609075997813, "CIDEr": 1.8744018520149043e-09, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a red neon sign that reads, `The End'. They are all holding cell phones and looking at them. The man in the center is wearing a black shirt and black pants, while the woman on the left is wearing a white sh"}, "158849": {"image_id": 158849, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.17574056770956026, "Bleu_4": 0.123943015938953, "METEOR": 0.23967556961881079, "ROUGE_L": 0.26940063091482647, "CIDEr": 6.3721421597971e-10, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.23076923076923078, "f": 0.26666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of people standing in a long line at an airport. They are all wearing black clothing and carrying luggage. The airport has a large sign that reads, \"Welcome to the airport.\"\n\nThe image is taken from the perspective of someone standing in line at"}, "136680": {"image_id": 136680, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.11524490328511487, "Bleu_4": 1.3433582021760985e-05, "METEOR": 0.23856963323878735, "ROUGE_L": 0.22938079719227877, "CIDEr": 3.6915759965704444e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.09523809523809523, "f": 0.09523809523809523, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a pair of sneakers on the floor in front of a toilet. The sneakers are red and have white laces. The toilet is white and has a seat and a handle. The floor is made of wood and has a pattern of wood grain. The wall behind"}, "471868": {"image_id": 471868, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.126168012373563, "Bleu_3": 6.921800773739778e-07, "Bleu_4": 1.6298208029972444e-09, "METEOR": 0.20862202071475666, "ROUGE_L": 0.26228501228501233, "CIDEr": 6.182969865704329e-10, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.20689655172413793, "f": 0.20689655172413793, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.35714285714285715, "f": 0.3703703703703704, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a street scene with a motorcycle parked on the sidewalk. There are several shops and houses in the background. The sky is cloudy and there is a lot of rain.\n\nThe image is taken from a low angle, looking down on the street. The motorcycle is parked"}, "68128": {"image_id": 68128, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.12386606438093092, "Bleu_4": 1.4033475286316117e-05, "METEOR": 0.18967702828508826, "ROUGE_L": 0.22241127856101123, "CIDEr": 1.4391611970140227e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a train station with a large glass roof and a sign that says \"sorrie\". There are people walking in the station and on the platform.\n\nThe train station is made of steel and glass, with a large sign on the front that says \"sorrie\". There are people walking in"}, "374061": {"image_id": 374061, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.24943374785244946, "Bleu_3": 0.1954476967373084, "Bleu_4": 0.1321239036290445, "METEOR": 0.28970655603987044, "ROUGE_L": 0.32370283018867924, "CIDEr": 8.82058563180866e-11, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.16666666666666666, "f": 0.0975609756097561, "fn": 10.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.4, "f": 0.2222222222222222, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a black and white cat lying on a couch with a stuffed animal next to it. The cat is wearing a collar and has a tag on its neck. The stuffed animal is a teddy bear with a red heart on its chest. The cat is pawing at the"}, "204640": {"image_id": 204640, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1824897193978171, "Bleu_3": 0.11396323345568955, "Bleu_4": 1.354286043960901e-05, "METEOR": 0.2355985866885183, "ROUGE_L": 0.3076091850517784, "CIDEr": 1.9384761780768658e-08, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.26666666666666666, "f": 0.19047619047619047, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two brown bears hugging each other. The bears are standing on their hind legs and their front paws are touching each other. The bears are in a zoo or wildlife sanctuary. The image is taken in a sunny day. The bears are in a"}, "445933": {"image_id": 445933, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.20225995873532804, "Bleu_3": 0.09116091793048703, "Bleu_4": 1.0934213504423326e-05, "METEOR": 0.2612659158595808, "ROUGE_L": 0.2772727272727273, "CIDEr": 2.1292860009545634e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. The man is wearing a blue shirt and white shorts, and he is holding a tennis racket in his right hand. The net is made of white strings and has a blue border. The court is made of green grass"}, "449392": {"image_id": 449392, "Bleu_1": 0.3962264150868637, "Bleu_2": 0.24689655731133917, "Bleu_3": 0.1684638136346001, "Bleu_4": 0.09888660568274775, "METEOR": 0.2850612027528055, "ROUGE_L": 0.30254184748915064, "CIDEr": 3.6044442160357934e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a church with a clock tower in the background. The church has a steeple with a cross on top. There are trees in the foreground and a blue sky in the background.\n\nThe church is made of brick and has a red roof. The steeple is made of stone and"}, "457461": {"image_id": 457461, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.20203050890627616, "Bleu_3": 0.0954066585882441, "Bleu_4": 1.172180673188117e-05, "METEOR": 0.22966772244933936, "ROUGE_L": 0.2822440717177559, "CIDEr": 4.509426488892211e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a breakfast sandwich with bacon, eggs, and cheese on top of a toasted English muffin. There is a glass of orange juice on the side. The table has a white tablecloth and a red napkin. The background is a white wall with a window in the"}, "326428": {"image_id": 326428, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.10238251947041137, "Bleu_3": 0.05863398711091721, "Bleu_4": 7.929020238697525e-06, "METEOR": 0.15002943513234923, "ROUGE_L": 0.2053872053872054, "CIDEr": 3.005721744509643e-12, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1875, "f": 0.12244897959183672, "fn": 13.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a stop sign on the side of the road. The sign is made of metal and has a red and white background. The word \"stop\" is written in black letters on the sign. There are no other objects in the image.\n\nThe image is taken from a bird's eye view,"}, "246442": {"image_id": 246442, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.1581995558142908, "Bleu_4": 0.12477720076473013, "METEOR": 0.27602099250086226, "ROUGE_L": 0.2544696066746126, "CIDEr": 3.6848375402438755e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.38095238095238093, "f": 0.3018867924528302, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a woman standing in the rain holding an umbrella. She is wearing a white coat and has a scarf around her neck. There are buildings in the background.\n\nThe woman in the image is wearing a white coat and has a scarf around her neck. She is standing in"}, "183199": {"image_id": 183199, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.11322770341226081, "Bleu_3": 6.352994280046227e-07, "Bleu_4": 1.5124632406335529e-09, "METEOR": 0.21053659132313196, "ROUGE_L": 0.30432372505543237, "CIDEr": 1.2129799912382036e-07, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.2857142857142857, "f": 0.2909090909090909, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.6363636363636364, "f": 0.5833333333333334, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image shows a brown and white dog sitting on top of a green couch, looking up at the camera. The dog is wearing a collar and tag on its neck. The couch is covered in a green and white striped blanket. There is a window in the background with curtains open"}, "563040": {"image_id": 563040, "Bleu_1": 0.3157894736786704, "Bleu_2": 0.23746784506878557, "Bleu_3": 0.17242714834053904, "Bleu_4": 0.1299080632334, "METEOR": 0.27449590135615903, "ROUGE_L": 0.32533333333333336, "CIDEr": 3.434330232132088e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08333333333333333, "f": 0.0851063829787234, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of police cars parked on the side of the street. There are two police officers standing next to the cars, one of them is holding a baton and the other is holding a gun. The buildings in the background are tall and made of brick. There is a fire hydrant on the"}, "170658": {"image_id": 170658, "Bleu_1": 0.4081632652977926, "Bleu_2": 0.2608202654732723, "Bleu_3": 0.17956220625337854, "Bleu_4": 0.13939655966239878, "METEOR": 0.31786611620523497, "ROUGE_L": 0.3801699716713881, "CIDEr": 9.148330186019367e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 15.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.7142857142857143, "f": 0.4761904761904762, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a plate with a breakfast sandwich on it. The sandwich consists of scrambled eggs, bacon, and cheese on a bun. There are two cups of coffee on the table next to the plate. The background is a wooden table with a red and white checkered tablecl"}, "312289": {"image_id": 312289, "Bleu_1": 0.3399999999932, "Bleu_2": 0.28855728394737223, "Bleu_3": 0.24993195426480846, "Bleu_4": 0.19092239431594976, "METEOR": 0.3132260078834922, "ROUGE_L": 0.3317220543806646, "CIDEr": 2.8561807536185783e-09, "SPICE": {"All": {"pr": 0.5, "re": 0.1875, "f": 0.2727272727272727, "fn": 26.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.46153846153846156, "f": 0.5714285714285714, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a bride and groom cutting a wedding cake at their reception\n\nThe bride and groom are standing in front of a large mirror, with the bride holding a knife and the groom holding a plate. They are both smiling and looking at each other as they cut"}, "3145": {"image_id": 3145, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.18663625434394554, "Bleu_3": 0.1397957424660571, "Bleu_4": 0.08597614289216929, "METEOR": 0.2320122032729868, "ROUGE_L": 0.28355607205113303, "CIDEr": 1.4426534510988544e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.19230769230769232, "f": 0.16393442622950818, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a living room with a couch, coffee table, and chairs. There is a window on the left side of the room with curtains open. The walls are painted a light green color and there is a ceiling fan in the center of the room. The floor is made of hardwood"}, "373521": {"image_id": 373521, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.16791512356189472, "Bleu_3": 8.003359263491407e-07, "Bleu_4": 1.7553179515165212e-09, "METEOR": 0.24253300250130558, "ROUGE_L": 0.26798462383305877, "CIDEr": 1.1095916583083816e-13, "SPICE": {"All": {"pr": 0.09375, "re": 0.3333333333333333, "f": 0.14634146341463417, "fn": 6.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.3333333333333333, "f": 0.13333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.5, "f": 0.2105263157894737, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image is of a white school bus parked on the side of the road in front of a house with trees in the background. The bus has a large window on the side and a door on the back. The bus is parked on the grass in front of the house.\n\nThe bus is an old"}, "497021": {"image_id": 497021, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.21798903029455755, "Bleu_3": 0.09704101083926576, "Bleu_4": 1.156974906782253e-05, "METEOR": 0.20946944601104694, "ROUGE_L": 0.3028368794326241, "CIDEr": 1.0138200915708217e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a road with a sign that says \"dip\" on it. There are trees on either side of the road and a church in the distance. The sky is blue and there are clouds in the sky.\n\nThe image is taken from a bird's eye view, looking down on the road"}, "89154": {"image_id": 89154, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.12629784955337583, "Bleu_4": 1.4627961137305314e-05, "METEOR": 0.23991165279436358, "ROUGE_L": 0.26771159874608147, "CIDEr": 1.0557779473395974e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of children playing on a playground with a large flock of seagulls flying overhead\n\nThe children are playing on a playground with a large flock of seagulls flying overhead. The playground has a blue slide, a yellow swing set, and a sandbox"}, "40839": {"image_id": 40839, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.2162249910430379, "Bleu_3": 0.1629781336014208, "Bleu_4": 0.11305389682845625, "METEOR": 0.26461282265616326, "ROUGE_L": 0.29967248908296945, "CIDEr": 1.0845971260517915e-12, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.23333333333333334, "f": 0.2692307692307693, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of people standing in front of a large, colorful building with a dome on top. The building has a lot of intricate details and patterns on the walls and roof. There are several people standing in front of the building, looking at it. The sky is blue and there are some"}, "535179": {"image_id": 535179, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.23791547571099586, "Bleu_3": 0.10286809102467988, "Bleu_4": 1.2086984532188798e-05, "METEOR": 0.26262491950185557, "ROUGE_L": 0.29047619047619044, "CIDEr": 1.5924707434149608e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.12121212121212122, "f": 0.14285714285714288, "fn": 29.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2, "f": 0.21428571428571427, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a skier jumping off a ramp on a snowy mountain. The skier is wearing a black and white suit with a red scarf around their neck. They are holding a black and white ski pole in their right hand and their left hand is in the air. The background is a"}, "504500": {"image_id": 504500, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.09267924750141882, "Bleu_4": 0.06449817351321535, "METEOR": 0.23221986860334037, "ROUGE_L": 0.236281471917366, "CIDEr": 5.002312390224488e-10, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8571428571428571, "f": 0.631578947368421, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows three people standing on the beach with surfboards. They are wearing yellow shirts and shorts, and one of them is holding a surfboard. The sky is blue and there are palm trees in the background. The beach is sandy and there are waves in the distance."}, "26735": {"image_id": 26735, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.14026224587471375, "ROUGE_L": 0.21721068249258166, "CIDEr": 9.432506293275171e-12, "SPICE": {"All": {"pr": 0.28, "re": 0.4375, "f": 0.34146341463414637, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.8, "f": 0.5000000000000001, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a small room with a bed, desk, and chair. The walls are painted white and there is a window on one side. The floor is made of wood and there is a rug on top. The room is well lit and there are no curtains on the windows.\n\nThe image"}, "308715": {"image_id": 308715, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.10167765666209894, "Bleu_3": 5.728348820235567e-07, "Bleu_4": 1.365914929670925e-09, "METEOR": 0.16945715148842444, "ROUGE_L": 0.20926243567753, "CIDEr": 3.4124184823753215e-15, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.15384615384615385, "f": 0.15384615384615385, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a cell phone on a wooden table. The phone is black and has a small screen on the front. There are two earbuds attached to the phone and a microphone on the side. The phone is lying on its side and there is a small speaker on the bottom of the phone. The background"}, "524775": {"image_id": 524775, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.17407765595250352, "Bleu_3": 0.08299846557886469, "Bleu_4": 1.0240041382038528e-05, "METEOR": 0.2687920945057416, "ROUGE_L": 0.24610951008645532, "CIDEr": 7.088765750743376e-13, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.10714285714285714, "f": 0.11111111111111112, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a yellow bus parked on the side of a street in front of a building with a large clock tower. There are several cars parked on the street and people walking on the sidewalk. The sky is clear and blue.\n\nThe bus is a double decker with a large sign on the"}, "169098": {"image_id": 169098, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.11843515045025206, "Bleu_3": 0.09037934933366287, "Bleu_4": 0.07165762335428273, "METEOR": 0.22254554444536015, "ROUGE_L": 0.20344635908838243, "CIDEr": 1.986748034348834e-15, "SPICE": {"All": {"pr": 0.15625, "re": 0.22727272727272727, "f": 0.18518518518518515, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.5, "f": 0.3, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a blue and yellow train parked on the tracks in front of a large brick building. The train has a number of windows on the sides and a large front end with a red light on top. The building appears to be a large, old structure with many windows and a tall clock tower. There are"}, "248085": {"image_id": 248085, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.07529519927190922, "Bleu_4": 9.612424997506294e-06, "METEOR": 0.18130167898418825, "ROUGE_L": 0.24469914040114613, "CIDEr": 1.8561863823219646e-09, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.17647058823529413, "f": 0.19047619047619047, "fn": 28.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.35714285714285715, "f": 0.3846153846153846, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a blue umbrella hanging from a metal pole in a room with a white wall and a wooden floor. The umbrella is open and has a handle on the side. There is a wooden chair in front of the umbrella. The room is dimly lit and has a window on"}, "230838": {"image_id": 230838, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.18625278992847225, "Bleu_3": 0.11552456765769871, "Bleu_4": 1.3681779747950839e-05, "METEOR": 0.22339040962982126, "ROUGE_L": 0.2501708817498291, "CIDEr": 1.3315872157400426e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.19047619047619047, "f": 0.1509433962264151, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a zebra standing in the middle of a dry, dusty field with a group of antelope grazing in the background. The zebra is wearing a halter and has a tag on its ear. The antelope are standing in a line, looking at the zeb"}, "379659": {"image_id": 379659, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.22677868380095453, "Bleu_3": 0.18593942826853238, "Bleu_4": 0.16171364085849804, "METEOR": 0.34309436271773086, "ROUGE_L": 0.370595382746051, "CIDEr": 7.529429738428739e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a desk with a laptop, headphones, and a lamp on it. The lamp is a white, round, and shaped like a ball. It is sitting on top of the desk and is turned on. The desk is made of wood and has a white surface. There is"}, "341804": {"image_id": 341804, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.083971912273837, "Bleu_3": 5.703763329560112e-07, "Bleu_4": 1.4964792230382814e-09, "METEOR": 0.192964824120603, "ROUGE_L": 0.23036253776435048, "CIDEr": 1.464194178694407e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.2857142857142857, "f": 0.20512820512820512, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The kitchen has a stove, oven, and refrigerator. The walls are covered in peeling paint and there are broken tiles on the floor. The room is empty except for some old appliances.\n\nThe kitchen has a stove, oven, and refrigerator."}, "281766": {"image_id": 281766, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.128337789581408, "Bleu_3": 6.952980477333491e-07, "Bleu_4": 1.626739259997693e-09, "METEOR": 0.20275754763914502, "ROUGE_L": 0.19513755598208574, "CIDEr": 1.4562832490685135e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.38095238095238093, "f": 0.32653061224489793, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of people walking down a street with bicycles and shopping carts. There are several people walking in the background. The sky is blue and there are trees in the background.\n\nThe image is taken from a high angle, looking down on the people and bicycles. The"}, "95692": {"image_id": 95692, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.11293938405626278, "Bleu_4": 0.08801997699586785, "METEOR": 0.25033420362643183, "ROUGE_L": 0.2519174041297935, "CIDEr": 4.4484575388081076e-10, "SPICE": {"All": {"pr": 0.15625, "re": 0.2777777777777778, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man standing on a dock overlooking a body of water. He is wearing a black shirt and black pants, and has a yellow umbrella in his hand. The sky is blue and there are trees in the background.\n\nThe image is taken from a low angle, looking"}, "417911": {"image_id": 417911, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.2142857142812956, "Bleu_3": 9.92269235704213e-07, "Bleu_4": 2.146756008495857e-09, "METEOR": 0.2671755869774825, "ROUGE_L": 0.2945081472540736, "CIDEr": 6.482377453895107e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.21052631578947367, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man surfing on a wave in the ocean. He is wearing a black wetsuit and holding onto his surfboard with one hand while riding the wave with the other. The water is choppy and there are whitecaps on the surface. The sky is overcast and"}, "543742": {"image_id": 543742, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.2819695067162573, "Bleu_3": 0.22792999994317542, "Bleu_4": 0.1791334365859636, "METEOR": 0.24069555161572345, "ROUGE_L": 0.33443564528761643, "CIDEr": 3.4418324120029315e-09, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2608695652173913, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a man standing in front of a table with a large pizza on it. The man is wearing a white shirt and black pants, and has a serious expression on his face. The pizza appears to be a large pepperoni pizza with melted cheese on top."}, "391067": {"image_id": 391067, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.22303564279534369, "Bleu_3": 0.1469796854787658, "Bleu_4": 0.09114933979368468, "METEOR": 0.2498676871840722, "ROUGE_L": 0.27566171723692706, "CIDEr": 8.377519982272024e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a plate of food on a table with a white tablecloth. There are two glasses of wine on the table and a fork and knife on the plate. The food appears to be a pizza with various toppings such as cheese, pepperoni, and olives. There is"}, "152360": {"image_id": 152360, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.20579830216693504, "Bleu_3": 0.12001600426559361, "Bleu_4": 0.07746741482634781, "METEOR": 0.185892798408072, "ROUGE_L": 0.2238532110091743, "CIDEr": 3.1773941773652725e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.34782608695652173, "f": 0.3404255319148936, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a street with a fruit stand on the sidewalk. There are several bananas hanging from the stand, and a few other fruits and vegetables are visible in the background. The street is lit by streetlights and there are some buildings in the background.\n\nThe image is taken at"}, "356427": {"image_id": 356427, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.10386373237947197, "Bleu_4": 1.2360545409967114e-05, "METEOR": 0.27415301246376517, "ROUGE_L": 0.2519174041297935, "CIDEr": 2.0269534213045716e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man standing on the platform of a train station. He is wearing a black shirt and jeans and has a backpack on his back. There are several bags and suitcases on the platform next to him. The train station has a large sign that reads, \"Train Station\""}, "207826": {"image_id": 207826, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.10050378152407698, "Bleu_3": 5.754792186290893e-07, "Bleu_4": 1.3836345500640894e-09, "METEOR": 0.20724898068533498, "ROUGE_L": 0.2127164942461932, "CIDEr": 3.716466974027924e-12, "SPICE": {"All": {"pr": 0.5882352941176471, "re": 0.3448275862068966, "f": 0.4347826086956522, "fn": 19.0, "numImages": 1.0, "fp": 7.0, "tp": 10.0}, "Relation": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a woman holding a book in her hand. The book is pink and has a cover with a picture of a woman on it. The woman is wearing a white shirt and has long, curly hair. She is sitting on a bed and looks like she is reading the book. The background"}, "311746": {"image_id": 311746, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.15041420939612582, "Bleu_3": 7.677195064444563e-07, "Bleu_4": 1.7432228564084153e-09, "METEOR": 0.15644444444444444, "ROUGE_L": 0.18780788177339902, "CIDEr": 3.426220228417954e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10256410256410256, "f": 0.12698412698412698, "fn": 35.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.1875, "f": 0.21428571428571427, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a hummingbird perched on a pink flower. The bird is looking down and appears to be eating the flower. The flower is a type of pink flower that is commonly found in gardens. The background of the image is a green field with tall grasses and trees. The sky"}, "96097": {"image_id": 96097, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.24754688702791705, "Bleu_3": 0.20077626444815685, "Bleu_4": 0.1579604779680037, "METEOR": 0.2932457926803876, "ROUGE_L": 0.2872277810476751, "CIDEr": 3.0944777165617224e-13, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on top of a wooden chair. The cat is looking up at the camera with its eyes closed. The chair has a wooden backrest and arms, and the cat's paws are resting on the edge of the seat. The floor is made of hardwood and there is a"}, "54747": {"image_id": 54747, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.2516911128489292, "Bleu_3": 0.23312485867630608, "Bleu_4": 0.2062609099646998, "METEOR": 0.21550305672438183, "ROUGE_L": 0.30432372505543237, "CIDEr": 7.242399547525183e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a black and white photograph of a bride and groom standing in front of a church. The bride is wearing a white wedding dress and the groom is wearing a military uniform. They are holding hands and smiling at each other. The church has stained glass windows and a ste"}, "259422": {"image_id": 259422, "Bleu_1": 0.13725490195809306, "Bleu_2": 0.11715583722348111, "Bleu_3": 0.09436646347757238, "Bleu_4": 0.06468490584061692, "METEOR": 0.21020614552132, "ROUGE_L": 0.19513755598208574, "CIDEr": 7.47652557327075e-12, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.22727272727272727, "f": 0.24390243902439024, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a plate of food with a hot dog, fries, and coleslaw. The food is on a table with a white tablecloth and a red and white checkered napkin. There are two glasses of water on the table. The background is a white wall with a window in the"}, "415841": {"image_id": 415841, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 0.12084372700297995, "Bleu_4": 0.07746741482637884, "METEOR": 0.19783795376228538, "ROUGE_L": 0.26293103448275856, "CIDEr": 1.0013440266460739e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a white refrigerator, a stove, and a sink. There are two chairs in the corner of the room and a table with a white tablecloth. The walls are painted a light brown color and there are no windows in the room. The floor is made of"}, "140640": {"image_id": 140640, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.07830779525362613, "Bleu_4": 1.0001000249872884e-05, "METEOR": 0.21812959422320874, "ROUGE_L": 0.25831820931639443, "CIDEr": 1.357746636681478e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of people standing around a table with a cake on it. They are all wearing hats and scarves. The table has a white tablecloth on it and there are plates and utensils on the table. The room is dimly lit and there are plants in the"}, "363577": {"image_id": 363577, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.2943920288717648, "Bleu_3": 0.2605465565131347, "Bleu_4": 0.2253607108976273, "METEOR": 0.30799154457076694, "ROUGE_L": 0.41146711635750427, "CIDEr": 9.300784990545386e-09, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.1, "f": 0.10169491525423728, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a young girl sitting at a table with a birthday cake in front of her. The cake has a pink and white design with pink and white frosting on top. The girl is wearing a pink dress and has a pink bow in her hair. The table has"}, "532747": {"image_id": 532747, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.18712785740116275, "Bleu_3": 0.14893279556267885, "Bleu_4": 0.11749577059988188, "METEOR": 0.28973677293336464, "ROUGE_L": 0.28126801152737757, "CIDEr": 5.142018709973346e-13, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.25925925925925924, "f": 0.25925925925925924, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a living room with a couch, coffee table, and television. The walls are painted blue and there are two windows on the left side of the room. There is a wooden bench in the corner of the room. The floor is made of hardwood and there are two lamps on the table"}, "361282": {"image_id": 361282, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.11651034560483009, "Bleu_3": 6.475197095245912e-07, "Bleu_4": 1.5342308957715506e-09, "METEOR": 0.19624493726731068, "ROUGE_L": 0.23047858942065497, "CIDEr": 1.6278485584085722e-12, "SPICE": {"All": {"pr": 0.15, "re": 0.14285714285714285, "f": 0.14634146341463414, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a wooden clock hanging on the wall with a wooden shelf below it. There are several items on the shelf, including a pencil sharpener, a pen holder, and a small wooden box. The clock has a wooden face with numbers and hands. The wall behind the clock has a"}, "213054": {"image_id": 213054, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1456862718139933, "Bleu_3": 0.09598617210562839, "Bleu_4": 0.06586156404600876, "METEOR": 0.15635668151303617, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.3663856521663808e-09, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.05, "f": 0.05714285714285715, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a woman holding a pair of scissors and a pencil. The scissors are orange and the pencil is black. The woman is wearing a white shirt and has a black hair tie on her head. There is a table in the background with a pile of papers"}, "235595": {"image_id": 235595, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.09641854808598063, "Bleu_4": 1.1689882104179119e-05, "METEOR": 0.20685299587704364, "ROUGE_L": 0.2501464557703574, "CIDEr": 6.575541711502227e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.17647058823529413, "f": 0.13953488372093026, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of motorcycles parked on the side of a street. The bikes are all different colors and styles, with some having chrome accents and others having black and silver accents. The bikes are parked in a row, with some of them facing the opposite direction. There are"}, "450728": {"image_id": 450728, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.18257418583143972, "Bleu_3": 0.12684342881783403, "Bleu_4": 0.09602806318555375, "METEOR": 0.2325603948912324, "ROUGE_L": 0.25553560742070613, "CIDEr": 3.345806905680014e-08, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.058823529411764705, "f": 0.04651162790697675, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man riding an elephant down a dirt road in front of a group of houses. The elephant is wearing a saddle and the man is holding onto its back. There are several small cars parked on the side of the road. The sky is cloudy and there"}, "130773": {"image_id": 130773, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.22677868380095453, "Bleu_3": 0.14758022201791693, "Bleu_4": 1.6171364085849802e-05, "METEOR": 0.22445049584217308, "ROUGE_L": 0.25386444708680145, "CIDEr": 6.3094546008569605e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a young boy holding a small turtle in his hand. The turtle is sitting on a plate and the boy is smiling. There are several people standing around the boy, looking at the turtle. The grass is green and the sky is blue.\n\nThe image shows a"}, "297698": {"image_id": 297698, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.06140634384744192, "Bleu_3": 4.224923263061475e-07, "Bleu_4": 1.1138202232666472e-09, "METEOR": 0.11797094017247549, "ROUGE_L": 0.15365239294710328, "CIDEr": 9.486991447664116e-13, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.22727272727272727, "f": 0.2777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a black and white photograph of a person jumping off a cliff. The person is wearing a black and white outfit and has a black and white helmet on their head. The sky is cloudy and there are some trees in the background.\n\nThe person is jumping off the cl"}, "85735": {"image_id": 85735, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.19264477878804065, "Bleu_3": 0.14437034871858073, "Bleu_4": 0.09561650802074656, "METEOR": 0.22086975215040092, "ROUGE_L": 0.2741573033707865, "CIDEr": 7.616410604238852e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.14814814814814814, "f": 0.18604651162790697, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a cake with candles on it. The cake is shaped like a burrito and has a happy birthday message written on it. There is also a knife and fork on the counter next to the cake."}, "81070": {"image_id": 81070, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.18474632789942436, "Bleu_3": 0.14370920818358404, "Bleu_4": 0.10716866428428544, "METEOR": 0.17723362257502603, "ROUGE_L": 0.25058685446009393, "CIDEr": 2.113246557163044e-08, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08, "f": 0.0909090909090909, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a tree with balloons tied to it. There are several cars parked on the street.\n\nThe image is taken from a street view.\n\nThe image is taken from a street view.\n\nThe image is taken from a street view.\n\nThe image is taken from a"}, "67122": {"image_id": 67122, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.17339191115885713, "Bleu_3": 0.08742085527780723, "Bleu_4": 1.1100642574269578e-05, "METEOR": 0.18496509549285026, "ROUGE_L": 0.23404527433175598, "CIDEr": 1.1511631951181705e-08, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a cat sleeping in a hammock on a balcony. The hammock is made of canvas and has a red and white striped pattern. The cat is lying on its back with its paws tucked under its body. The balcony has a railing and a"}, "155540": {"image_id": 155540, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.16087993330478273, "Bleu_3": 0.10184644872865577, "Bleu_4": 0.06849346044918843, "METEOR": 0.17625981146197642, "ROUGE_L": 0.26505276225946617, "CIDEr": 6.705333932976931e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.4444444444444444, "f": 0.2285714285714286, "fn": 5.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.75, "f": 0.3529411764705882, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a brown bear standing on its hind legs in a zoo enclosure. The bear is wearing a collar and has a tag on its ear. The enclosure is surrounded by trees and rocks.\n\nThe bear is standing on its hind legs, looking at something in the distance. Its"}, "54750": {"image_id": 54750, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.16751484856166823, "Bleu_3": 0.13366660488533524, "Bleu_4": 0.08488437004364349, "METEOR": 0.25685098271545026, "ROUGE_L": 0.23091482649842268, "CIDEr": 2.7048661522306464e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.17857142857142858, "f": 0.1851851851851852, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person on a surfboard in the ocean, with the sun shining behind them. The person is wearing a wetsuit and a helmet, and is holding onto the surfboard with one hand while the other hand is in the air. The surfboard is being pulled by"}, "187888": {"image_id": 187888, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.20080483221924839, "Bleu_3": 1.1035932143410068e-06, "Bleu_4": 2.6091993798285682e-09, "METEOR": 0.16622707092500963, "ROUGE_L": 0.22426470588235295, "CIDEr": 0.00019713567493300649, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.2, "f": 0.13953488372093023, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a plate with a breakfast dish consisting of scrambled eggs, bacon, and toast. There are also some fruit slices on the plate. The plate is on a white tablecloth."}, "99024": {"image_id": 99024, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.1347912565777208, "Bleu_4": 0.11181553360980999, "METEOR": 0.2566047200220614, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.7184919054397966e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person sitting on the floor with a piece of paper on their lap. The person is wearing a white shirt and blue pants. There are several plastic straws on the floor next to the person. The image is taken in a kitchen or living room setting."}, "200739": {"image_id": 200739, "Bleu_1": 0.39285714285012757, "Bleu_2": 0.3273268353480904, "Bleu_3": 0.2403749283801967, "Bleu_4": 0.1272324553931115, "METEOR": 0.2972970257490123, "ROUGE_L": 0.34528301886792445, "CIDEr": 2.669538174372074e-09, "SPICE": {"All": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a black and white photograph of a city street with several buildings on either side. There are several cars parked on the street, and a horse and wagon are parked in front of one of the buildings. There are people walking on the sidewalk and in the street. The buildings are made of brick"}, "14756": {"image_id": 14756, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.15698856690934238, "Bleu_4": 0.12535938934526375, "METEOR": 0.31575272905922785, "ROUGE_L": 0.37888198757763975, "CIDEr": 5.0745670765861526e-08, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.23333333333333334, "f": 0.2692307692307693, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.46153846153846156, "f": 0.46153846153846156, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The man in the image is holding a baseball bat and smoking a cigarette. He is wearing a white shirt and black pants. The background is black and there is a baseball field in the distance.\n\nThe man in the image is holding a baseball bat and smoking a cigarette"}, "22461": {"image_id": 22461, "Bleu_1": 0.6206896551510107, "Bleu_2": 0.5157614295370251, "Bleu_3": 0.4100882563010343, "Bleu_4": 0.33935727473833577, "METEOR": 0.3624847088044093, "ROUGE_L": 0.6163531789211877, "CIDEr": 0.30502686179265676, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a bowl of cereal with a spoon and a glass of juice on a blue table. There is also a bowl of grapes on the table."}, "160126": {"image_id": 160126, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.10555271104180952, "Bleu_4": 0.07110703768133433, "METEOR": 0.17081418309866045, "ROUGE_L": 0.18711656441717792, "CIDEr": 1.1870743417593544e-09, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08695652173913043, "f": 0.07999999999999999, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a person skateboarding on a ramp in the middle of a park. The person is wearing a black shirt and jeans, and has a helmet on their head. The ramp is made of concrete and has a graffiti design on it. There are trees and grass"}, "27570": {"image_id": 27570, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.1383208337902698, "Bleu_3": 0.07411266771245849, "Bleu_4": 9.699065152691652e-06, "METEOR": 0.2681415663950201, "ROUGE_L": 0.27354260089686094, "CIDEr": 1.396789592655833e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a woman standing in a bathroom, holding a hair dryer to her hair. She is wearing a white tank top and has a towel wrapped around her waist. The bathroom has a sink, toilet, and shower in it. There is a window on the left side"}, "66519": {"image_id": 66519, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.14129296641606834, "Bleu_3": 0.08933624311138665, "Bleu_4": 1.0670385044190443e-05, "METEOR": 0.20091267997053908, "ROUGE_L": 0.20383158832702158, "CIDEr": 1.6991692725442102e-14, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.07692307692307693, "f": 0.08, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a white bird standing on the edge of a pond with tall reeds growing in the water. The bird is looking out at the water and appears to be waiting for something to happen. The sky is clear and blue with a few clouds scattered across it. The water is calm and reflects the sky"}, "268375": {"image_id": 268375, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.09986796846096184, "Bleu_4": 0.06680779845343547, "METEOR": 0.1800327428340375, "ROUGE_L": 0.27326688318960685, "CIDEr": 3.824135091780073e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2727272727272727, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a field. They are all different sizes and colors, with some having spots and others having stripes. They are all looking at each other and seem to be communicating with each other. The background is a green field with some trees in the distance."}, "161185": {"image_id": 161185, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1191907417701306, "Bleu_4": 1.3498619260852726e-05, "METEOR": 0.18662198616874529, "ROUGE_L": 0.2445589919816724, "CIDEr": 1.5474823382595622e-12, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2727272727272727, "f": 0.21818181818181817, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a train station with a train on the tracks\n\nThe train station has a platform with a sign that reads \"train station\" in white letters. The train is a yellow and black engine with a red caboose. There are several people standing on the platform, looking at the train. The sky"}, "27438": {"image_id": 27438, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.10562592656622659, "Bleu_4": 0.06866871671512177, "METEOR": 0.22024138808885005, "ROUGE_L": 0.21682464454976302, "CIDEr": 1.2289114579741471e-11, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.16666666666666666, "f": 0.15, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows two white sheep standing in a green field. They are grazing on the grass and appear to be happy. The sky is blue and there are some clouds in the background. The grass is tall and green, and there are some flowers in the foreground. The sheep are standing in a line, with"}, "67213": {"image_id": 67213, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1189176779999305, "Bleu_3": 0.06437822382780045, "Bleu_4": 8.463566423155675e-06, "METEOR": 0.21982389822413867, "ROUGE_L": 0.29500268672756585, "CIDEr": 8.419620760230899e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a dog jumping into a swimming pool. The dog is wearing a red collar and has its tongue hanging out of its mouth. The pool is surrounded by a fence and there are people standing on the side of the pool watching the dog jump. The sky is blue and there are"}, "118607": {"image_id": 118607, "Bleu_1": 0.222222222217284, "Bleu_2": 0.10050378152366245, "Bleu_3": 6.170193490770501e-07, "Bleu_4": 1.5378421667838189e-09, "METEOR": 0.15211470590018297, "ROUGE_L": 0.168391994478951, "CIDEr": 1.1288845125756711e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.125, "f": 0.1276595744680851, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a variety of food items, including salads, noodles, and vegetables. There are also several bowls of soup on the table. The overall appearance of the image is quite colorful and appetizing.\n\nThe image shows a variety of food items, including salads, no"}, "382345": {"image_id": 382345, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 7.446639778133948e-07, "Bleu_4": 1.67868582615359e-09, "METEOR": 0.25560918369087654, "ROUGE_L": 0.2513243084167157, "CIDEr": 3.058813618621427e-11, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13043478260869565, "f": 0.11764705882352941, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man standing on the beach holding a kite. The kite is flying in the sky and there are people in the background watching the kite fly. The sky is blue and there are clouds in the background. The beach is sandy and there are palm trees in the background. The man"}, "190700": {"image_id": 190700, "Bleu_1": 0.387755102032903, "Bleu_2": 0.2696369441112524, "Bleu_3": 0.1457125561712116, "Bleu_4": 1.6103981936785925e-05, "METEOR": 0.2823116417474881, "ROUGE_L": 0.3386798272671191, "CIDEr": 7.758634851286164e-09, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.10714285714285714, "f": 0.10526315789473684, "fn": 25.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a teddy bear sitting on a couch next to a stuffed animal. The teddy bear is wearing a red hat and a scarf, and the stuffed animal is wearing a red scarf. The background is a white wall with a window in the background.\n\nThe image"}, "51334": {"image_id": 51334, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.12366938847771936, "Bleu_3": 6.783327450171972e-07, "Bleu_4": 1.5968781455284126e-09, "METEOR": 0.1830750893921335, "ROUGE_L": 0.19513755598208574, "CIDEr": 1.8050844784527032e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.0625, "f": 0.08333333333333333, "fn": 30.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a snowy street with cars parked on the side of the road. There are buildings in the background, and a few people walking on the sidewalk. The sky is dark and there are streetlights on the corners.\n\nThe image is taken at night, and the snow is piled"}, "344268": {"image_id": 344268, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.15352206215446232, "Bleu_3": 0.07632882442935535, "Bleu_4": 9.61646807937354e-06, "METEOR": 0.14261926242598522, "ROUGE_L": 0.20254565578306588, "CIDEr": 2.5292437631893243e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.21052631578947367, "f": 0.17391304347826086, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a red flag with the words \"socialist republic of the united states\" written on it. The man is wearing a suit and tie and has his hands clasped together in front of him. The background is a dark blue color with a few stars in the"}, "389108": {"image_id": 389108, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.194191754997615, "Bleu_3": 0.08927473462734822, "Bleu_4": 1.0815474806811216e-05, "METEOR": 0.2562141521205714, "ROUGE_L": 0.20666290231507625, "CIDEr": 3.6466989261219907e-13, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a living room with a couch, coffee table, and television. There are two women sitting on the couch, one of them is holding a remote control and the other is reading a book. There is a man standing in the corner of the room, looking at the television. The room is well"}, "53668": {"image_id": 53668, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.13430879685706595, "Bleu_3": 7.373360496991947e-07, "Bleu_4": 1.7373444521894353e-09, "METEOR": 0.14078200006103345, "ROUGE_L": 0.19869706840390877, "CIDEr": 1.3500784919414199e-08, "SPICE": {"All": {"pr": 0.027777777777777776, "re": 0.038461538461538464, "f": 0.03225806451612904, "fn": 25.0, "numImages": 1.0, "fp": 35.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a person skateboarding on a concrete sidewalk in front of a row of houses. The person is wearing a black shirt and jeans, and has a black and white skateboard with red wheels. The sky is cloudy and there are trees in the background."}, "117458": {"image_id": 117458, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.20741995429139695, "ROUGE_L": 0.3386798272671191, "CIDEr": 5.0511758749735594e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14814814814814814, "f": 0.14545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a motorcycle rider wearing a helmet and riding on the road. The rider is wearing a black suit and white shirt, and has a black helmet on their head. The motorcycle is black and has a white stripe on the side. The road is empty and"}, "574200": {"image_id": 574200, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.10433283794475068, "Bleu_3": 0.05976183926619196, "Bleu_4": 8.083053722298239e-06, "METEOR": 0.16467345631644292, "ROUGE_L": 0.21908296420447745, "CIDEr": 3.5005083507049274e-12, "SPICE": {"All": {"pr": 0.20588235294117646, "re": 0.30434782608695654, "f": 0.2456140350877193, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a group of school buses parked on the side of a road. They are painted in bright colors and have the words `school bus' written on the side. There are trees and grass in the background.\n\nThe image is taken from a bird's eye view, looking down on the"}, "98674": {"image_id": 98674, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 0.08640378216299736, "Bleu_4": 1.060491082518161e-05, "METEOR": 0.22541583747727534, "ROUGE_L": 0.21403508771929822, "CIDEr": 1.5390868680770146e-11, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.038461538461538464, "f": 0.04545454545454546, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a black and white bird perched on a branch of a tree with red berries hanging from it. The bird is looking down at the berries and appears to be eating one. The background is a winter scene with snow covered trees and a blue sky.\n\nThe bird is a common"}, "121783": {"image_id": 121783, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.17264741623354635, "Bleu_3": 0.10150601280148307, "Bleu_4": 1.1690196731973607e-05, "METEOR": 0.21973944445299456, "ROUGE_L": 0.2239119035133718, "CIDEr": 9.864892235135711e-15, "SPICE": {"All": {"pr": 0.32, "re": 0.3076923076923077, "f": 0.3137254901960784, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The cat is sitting on the floor in front of the door. It looks like it is waiting for someone to come out of the house. The cat is looking at the door with its ears perked up. The door is made of wood and has a large window on it. The window is open and there is a"}, "116461": {"image_id": 116461, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.191273013914278, "Bleu_3": 9.789208946234303e-07, "Bleu_4": 2.229024282744491e-09, "METEOR": 0.253422154358455, "ROUGE_L": 0.33493479752916955, "CIDEr": 2.138123537695521e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a pizza with cheese, pepperoni, and mushrooms on top. There is a knife on the side of the plate. The plate is on a wooden table.\n\nThe image shows a pizza with cheese, pepperoni, and mushrooms on top."}, "126340": {"image_id": 126340, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.21958464589702661, "Bleu_3": 0.16172097930516127, "Bleu_4": 0.11086265218442463, "METEOR": 0.2638408711580356, "ROUGE_L": 0.3168831168831169, "CIDEr": 8.61120210220587e-14, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1, "f": 0.09302325581395349, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a young boy standing in front of a white wall with a television on the wall behind him. The boy is holding a remote control in his hand and appears to be playing a video game on the television. The room is dimly lit and there are several pieces of furniture in the background, including a"}, "104715": {"image_id": 104715, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.15534712747310678, "Bleu_3": 7.8441426562788e-07, "Bleu_4": 1.7715772413454909e-09, "METEOR": 0.19440506334483948, "ROUGE_L": 0.22536945812807885, "CIDEr": 1.5995422299167352e-11, "SPICE": {"All": {"pr": 0.44, "re": 0.2972972972972973, "f": 0.3548387096774193, "fn": 26.0, "numImages": 1.0, "fp": 14.0, "tp": 11.0}, "Relation": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5833333333333334, "re": 0.5, "f": 0.5384615384615384, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image shows a person holding a kite in the sky. The kite has a long tail with many colorful streamers attached to it. The person is wearing a black shirt and a hat. The sky is blue and there are some clouds in the background.\n\nThe image is taken from a"}, "160421": {"image_id": 160421, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1504928025607928, "Bleu_3": 0.08272888216792641, "Bleu_4": 1.0976824366455691e-05, "METEOR": 0.16253225731500942, "ROUGE_L": 0.2881241565452092, "CIDEr": 5.863780856218662e-07, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.22727272727272727, "f": 0.20833333333333331, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bowl of curry with chicken, vegetables, and rice. The curry is made with coconut milk and has a spicy flavor. The chicken is cooked in the curry and is tender and flavorful. The vegetables are cooked in the curry"}, "520840": {"image_id": 520840, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2455273669893519, "Bleu_3": 0.13787662975419968, "Bleu_4": 0.08736045067556263, "METEOR": 0.28389908062771496, "ROUGE_L": 0.27371794871794874, "CIDEr": 1.6710249183951984e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.4, "f": 0.2222222222222222, "fn": 6.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.3333333333333333, "f": 0.125, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of giraffes standing in a field with a small puddle of water in front of them. The giraffes are all facing the same direction and appear to be drinking from the puddle. The image is in black and white and has a grainy"}, "177952": {"image_id": 177952, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.06739642517978216, "Bleu_3": 4.4370071280182084e-07, "Bleu_4": 1.143997435182621e-09, "METEOR": 0.12695316192723602, "ROUGE_L": 0.1783625730994152, "CIDEr": 1.3825734939528982e-12, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2, "f": 0.1886792452830189, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The man in the image is wearing a black shirt with white sleeves and a white collar. He has a black and white striped tie around his neck and is holding a black and white striped scarf in his hand. He is standing in front of a white wall with a black and white"}, "331339": {"image_id": 331339, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.3012578671433264, "Bleu_3": 0.2020666786028542, "Bleu_4": 0.12671660613426308, "METEOR": 0.30446484079505015, "ROUGE_L": 0.3951417004048583, "CIDEr": 0.0001562716837149656, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a plate of waffles with bananas and bacon on top. The waffles are made with chocolate chips and topped with bananas and bacon. The plate is on a countertop in a kitchen."}, "344555": {"image_id": 344555, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.16658955971162087, "Bleu_3": 0.10724350864958367, "Bleu_4": 1.2939428392854091e-05, "METEOR": 0.18794532909902306, "ROUGE_L": 0.26771159874608147, "CIDEr": 4.644682753032811e-08, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.06896551724137931, "f": 0.07017543859649124, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a variety of sewing tools, including scissors, a needle, and thread. The scissors are open and the needle is in the middle of the image. The thread is coiled around the needle. There are also several other sewing tools on the table, including a"}, "221232": {"image_id": 221232, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2477973138852387, "Bleu_3": 0.18793910397558025, "Bleu_4": 0.1533619254553493, "METEOR": 0.23684045150838176, "ROUGE_L": 0.3398802061568464, "CIDEr": 9.78500166934949e-05, "SPICE": {"All": {"pr": 0.08, "re": 0.09090909090909091, "f": 0.0851063829787234, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The man is holding a white parrot in his hands. The parrot is looking up at the man with its beak open. The man is wearing a hat and sunglasses. The background is a wooden fence with a gate."}, "494634": {"image_id": 494634, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.18405922400671818, "Bleu_3": 0.10655791496998812, "Bleu_4": 0.06848549721346939, "METEOR": 0.22801402981712832, "ROUGE_L": 0.23041225987481118, "CIDEr": 1.1413568739659211e-13, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a black and white cat sitting on top of a laptop. The cat is looking at the screen with its head tilted to the side. The laptop is open and has a keyboard and mouse on it. There is a table in front of the laptop with a cup of coffee on it. The room"}, "463884": {"image_id": 463884, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.11881770515484788, "Bleu_3": 0.06604735246466956, "Bleu_4": 8.801997699586786e-06, "METEOR": 0.16714684484421755, "ROUGE_L": 0.19074421513445905, "CIDEr": 1.7097708225087276e-11, "SPICE": {"All": {"pr": 0.15625, "re": 0.2777777777777778, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a person on a water skiing, with a rope attached to their wrist and a life jacket on their body. They are standing on the water, with their arms outstretched and their legs bent in a skiing position. The water is choppy and there are waves in the"}, "378126": {"image_id": 378126, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1565560727682472, "Bleu_3": 0.0788478660803684, "Bleu_4": 1.0001000249876893e-05, "METEOR": 0.24437039797271012, "ROUGE_L": 0.1920654911838791, "CIDEr": 4.5283462911839207e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.21428571428571427, "f": 0.15789473684210525, "fn": 11.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two women playing soccer on a field. One woman is wearing a blue shirt and the other is wearing a red shirt. They are both holding soccer balls and running towards each other. The field is green and there are trees in the background.\n\nThe image shows two women"}, "171310": {"image_id": 171310, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.26271583096647133, "Bleu_3": 0.19168235533449896, "Bleu_4": 0.15564719247748715, "METEOR": 0.3154615812788217, "ROUGE_L": 0.33577981651376143, "CIDEr": 4.835143525035688e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a vase with a bouquet of flowers on a table next to a chair. The vase is made of ceramic and has a floral pattern on it. The flowers are a mix of pink, yellow, and white. The table has a wooden top and four legs. The chair"}, "362348": {"image_id": 362348, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.10820697408694996, "Bleu_4": 1.2680676386324485e-05, "METEOR": 0.19663626041400975, "ROUGE_L": 0.25176886792452824, "CIDEr": 7.285243992541679e-10, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man standing behind a table filled with bananas. The man is wearing a black jacket and a white shirt. The table is made of wood and has a red and white checkered tablecloth on it. There are several bananas on the table, some of which are still green"}, "551660": {"image_id": 551660, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.22578837914038788, "Bleu_3": 0.1732709269360296, "Bleu_4": 0.13428091081718418, "METEOR": 0.26324104898814915, "ROUGE_L": 0.33485818847209514, "CIDEr": 1.1247237265057158e-09, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.3333333333333333, "f": 0.3111111111111111, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a bowl of broccoli and apples on a table with a white and blue striped tablecloth. There is a glass of water on the table and a lemon slice on the side. The background is a white wall with a window in the background.\n\nThe image shows a"}, "242287": {"image_id": 242287, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.13041013273663615, "Bleu_3": 0.08978110312668927, "Bleu_4": 1.1199515753588485e-05, "METEOR": 0.2163081223505599, "ROUGE_L": 0.18815545959284388, "CIDEr": 3.7378329454164456e-10, "SPICE": {"All": {"pr": 0.09375, "re": 0.14285714285714285, "f": 0.11320754716981132, "fn": 18.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a bicycle parked in front of a building with a blue door and a sign that reads \"Shop\". There are several small shops and cafes along the street, with people walking and biking by. The buildings are made of brick and have arched windows and doors."}, "481628": {"image_id": 481628, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.2753807233863433, "Bleu_3": 0.195174151667895, "Bleu_4": 0.13132025673052627, "METEOR": 0.2114171819724194, "ROUGE_L": 0.27774615822424586, "CIDEr": 2.1562706848652752e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1875, "f": 0.20689655172413793, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of white swans swimming in a body of water. They are in a line, with their heads facing the same direction. The water is clear and calm, with a few ripples on the surface. The sky is blue and cloudy, with a few white clouds scattered across it"}, "202799": {"image_id": 202799, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.22760466886504876, "Bleu_3": 0.13204641200979725, "Bleu_4": 1.5124526410231296e-05, "METEOR": 0.17868806961776024, "ROUGE_L": 0.2749517063747585, "CIDEr": 2.105321763560296e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.2, "f": 0.15, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a skateboarder performing a trick on a halfpipe in a skate park. The skateboarder is wearing a black shirt and blue jeans, and has a red helmet on his head. The halfpipe is made of concrete and has a smooth surface. There are several"}, "360660": {"image_id": 360660, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.6908492796475699, "Bleu_3": 0.5231536876398398, "Bleu_4": 0.4223464418801229, "METEOR": 0.41318579058993543, "ROUGE_L": 0.6224489795918368, "CIDEr": 1.6230334035844622, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.23809523809523808, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a plate of broccoli with a sauce on top"}, "118051": {"image_id": 118051, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.19069251784483274, "Bleu_3": 9.456554943341475e-07, "Bleu_4": 2.1182996284447625e-09, "METEOR": 0.19610363129544398, "ROUGE_L": 0.25902335456475584, "CIDEr": 1.8382061064727263e-09, "SPICE": {"All": {"pr": 0.04, "re": 0.06666666666666667, "f": 0.05, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "This is an office space with a desk, chair, and computer. There are several posters on the walls and a whiteboard on the wall.\n\nThe desk has a computer, keyboard, mouse, and monitor on it. The chair has a cushion and a backrest. The whiteboard"}, "522232": {"image_id": 522232, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.17238297400489144, "Bleu_4": 0.15044258140708106, "METEOR": 0.3435910673562835, "ROUGE_L": 0.30254184748915064, "CIDEr": 1.7875014088661158e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.16666666666666666, "f": 0.13953488372093023, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man standing next to a red motorcycle parked in front of a gas station. The man is wearing a black shirt and pants, and has a white helmet on his head. The motorcycle has a black seat and red paint on the body. The gas station has a blue"}, "427133": {"image_id": 427133, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.22131333406452386, "Bleu_3": 0.14519947954201504, "Bleu_4": 0.08983577738158222, "METEOR": 0.215673800084473, "ROUGE_L": 0.3096446700507614, "CIDEr": 6.8987496389660694e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in a field with a group of sheep in the background. The people are wearing white shirts and black pants, and the sheep are wearing white collars and black coats. The people are holding leashes and the sheep are standing on leashes"}, "35012": {"image_id": 35012, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.20100756304815393, "Bleu_3": 0.09135163170376535, "Bleu_4": 1.100364056976739e-05, "METEOR": 0.1911114683534638, "ROUGE_L": 0.207506520013607, "CIDEr": 6.407107049033619e-13, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.19047619047619047, "f": 0.21052631578947367, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a large, old brick building with a sign on the front that reads \"The Old Building\". The building has a large window on the front with a sign that reads \"The Old Building\". The building is surrounded by a fence and there is a street in front of it.\n\nThe image is"}, "481793": {"image_id": 481793, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.08268590713763764, "Bleu_4": 1.0646588104479637e-05, "METEOR": 0.19160314489245614, "ROUGE_L": 0.20346897931954633, "CIDEr": 1.6322290740984149e-09, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 24.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The surfer is riding a wave on a surfboard. The wave is large and has a lot of white water on it. The surfer is wearing a wetsuit and a helmet. The sky is blue and there are clouds in the background.\n\nThe surfer is riding a"}, "116061": {"image_id": 116061, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.13160986848342304, "Bleu_4": 0.0839028829006261, "METEOR": 0.3287294806201739, "ROUGE_L": 0.35280508964719487, "CIDEr": 1.335324225012572e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.1724137931034483, "f": 0.19999999999999998, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of people riding motorcycles on the street. They are wearing helmets and some of them are holding bags. There are cars and buses passing by on the road. The sky is cloudy and there are buildings in the background.\n\nThe image is taken in"}, "298994": {"image_id": 298994, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.14607233344869358, "Bleu_3": 0.10583300875240852, "Bleu_4": 0.07628670307141627, "METEOR": 0.24413271144731383, "ROUGE_L": 0.23940345368916802, "CIDEr": 9.92703896233488e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3157894736842105, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a variety of vegetables and fruits arranged on a wooden pallet. The vegetables include carrots, beets, broccoli, cauliflower, and kale. The fruits include apples, oranges, and lemons. The image also shows a small bag of"}, "196210": {"image_id": 196210, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.08701138391057635, "Bleu_4": 1.1125382292156774e-05, "METEOR": 0.16859495051661988, "ROUGE_L": 0.25452016689847007, "CIDEr": 9.262672380815819e-10, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.29411764705882354, "f": 0.3846153846153846, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5714285714285714, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a bowl filled with broccoli. The broccoli is green and has florets on the top. There is a spoon in the bowl and a cutting board on the side. The cutting board has a knife on it. The background is a white countertop."}, "115241": {"image_id": 115241, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.24880667575704968, "Bleu_3": 0.19383626994586653, "Bleu_4": 0.14494568695672289, "METEOR": 0.30351053027634, "ROUGE_L": 0.38730158730158726, "CIDEr": 9.700709163656941e-05, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.15384615384615385, "f": 0.09090909090909091, "fn": 11.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a pizza with various toppings, including pepperoni, onions, and mushrooms. The pizza is cut into slices and placed on a wooden cutting board. The background is a wooden table with a white tablecloth."}, "90802": {"image_id": 90802, "Bleu_1": 0.35714285713647964, "Bleu_2": 0.25482359571422103, "Bleu_3": 0.19323194406172686, "Bleu_4": 0.1421577492280265, "METEOR": 0.28190566904458625, "ROUGE_L": 0.324468085106383, "CIDEr": 4.748232264584587e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.125, "f": 0.12000000000000001, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a glass of beer sitting on a table next to a bottle of beer. The glass is filled with a dark brown liquid, and the bottle is also filled with a dark brown liquid. The table is made of wood and has a smooth surface. There are no other objects in the image"}, "252857": {"image_id": 252857, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.21932534684462168, "Bleu_3": 0.1748417105556144, "Bleu_4": 0.13816591886120846, "METEOR": 0.3106753471715652, "ROUGE_L": 0.32555036691127415, "CIDEr": 1.9045403521565837e-08, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.47058823529411764, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a white bathtub, a white toilet, and a black and white tiled floor. The walls are painted white and there is a black and white tiled ceiling. The bathroom has a black and white tiled floor and a white toilet. The"}, "64150": {"image_id": 64150, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.15613914506966814, "Bleu_3": 0.10196049127995216, "Bleu_4": 0.06966598967664618, "METEOR": 0.18631441078459057, "ROUGE_L": 0.29901960784313725, "CIDEr": 1.1797414222179225e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.20689655172413793, "f": 0.24000000000000002, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.13333333333333333, "f": 0.16666666666666669, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image is of a large clock tower with a sign that reads \"Coca-Cola\" on it. The clock tower is made of metal and has a large, round clock face on it. The sign is made of metal and has the words \"Coca-Cola\" written on it in bold,"}, "399966": {"image_id": 399966, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.1169829962474529, "Bleu_4": 0.08858266023053883, "METEOR": 0.1920915310543695, "ROUGE_L": 0.2513243084167157, "CIDEr": 2.7684451773956677e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a large, old airplane sitting on the ground in a snowy area. The plane has a long, curved nose and two large engines on the sides. The plane is painted in a dark blue and white color scheme with red and white stripes on the wings. There are several people standing around"}, "516430": {"image_id": 516430, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.11895773785545558, "Bleu_3": 6.522364605376366e-07, "Bleu_4": 1.5348336186916813e-09, "METEOR": 0.19668927807563694, "ROUGE_L": 0.21356050881082975, "CIDEr": 1.49550709899944e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.3333333333333333, "f": 0.22857142857142854, "fn": 8.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a white vw beetle with a red roof and a black hood. The car has a large trunk and a small back seat. There are two people standing next to the car, one with a surfboard and the other with a beach ball. The sky is clear and blue with"}, "544451": {"image_id": 544451, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.0933181271719728, "Bleu_3": 5.547797716282368e-07, "Bleu_4": 1.3594021798767564e-09, "METEOR": 0.1911003839878553, "ROUGE_L": 0.226906385616863, "CIDEr": 6.08535176139463e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a computer desk with a computer, keyboard, mouse, and monitor. The desk is made of wood and has a blue and white color scheme. There is a lamp on the desk and a window in the background.\n\nThe room is well lit and has a comfortable chair in front of the"}, "230661": {"image_id": 230661, "Bleu_1": 0.15999999999680004, "Bleu_2": 0.08081220356254415, "Bleu_3": 5.143249039205921e-07, "Bleu_4": 1.3043787072240774e-09, "METEOR": 0.16408066685280723, "ROUGE_L": 0.1937738246505718, "CIDEr": 4.2856322888198616e-11, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a yellow food truck parked on the side of the road. The truck has a sign on the side that reads \"queen library\" in black letters. There is a person standing next to the truck, looking at it. The person is wearing a black shirt and jeans"}, "381551": {"image_id": 381551, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.07923964199176128, "Bleu_4": 1.0198056661125237e-05, "METEOR": 0.21061346738162112, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.975531157137432e-09, "SPICE": {"All": {"pr": 0.1, "re": 0.12, "f": 0.1090909090909091, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a black and white photograph of a park with people sitting on benches and walking on the sidewalk. There are trees in the background and a building in the distance.\n\nThe people in the image are dressed in casual clothing, such as t-shirts and jeans. They are"}, "499810": {"image_id": 499810, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.21573723181113055, "Bleu_3": 0.14478976911907138, "Bleu_4": 0.10777245529572334, "METEOR": 0.2518630813142024, "ROUGE_L": 0.31282051282051276, "CIDEr": 4.9399851253596113e-08, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.25, "f": 0.23076923076923075, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in line at an airport. They are all wearing casual clothing and carrying luggage. The airport is filled with other people and luggage.\n\nThe image is taken from a low angle, looking up at the people in line. The light"}, "253227": {"image_id": 253227, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.18219102867095022, "Bleu_3": 0.08610272124760734, "Bleu_4": 1.0577185330931625e-05, "METEOR": 0.2618695595037368, "ROUGE_L": 0.21403508771929822, "CIDEr": 1.0312645349575076e-11, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.16129032258064516, "f": 0.17543859649122806, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a clock tower with a bird perched on top of it. The clock has Roman numerals and hands, and the bird is looking down at the clock. The sky is blue and there are clouds in the background.\n\nThe clock tower is made of black and white stone, with a stee"}, "235984": {"image_id": 235984, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.12741179785711051, "Bleu_3": 0.09661597203086345, "Bleu_4": 0.06422701351555532, "METEOR": 0.23279597740261035, "ROUGE_L": 0.25296208530805686, "CIDEr": 1.4765615968873927e-13, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a stop sign on the side of the road in front of a house with a red roof. The sign is surrounded by cacti and other plants. The house is painted a light brown color and has a small porch with a white railing. There is a small tree in the front yard."}, "460049": {"image_id": 460049, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1501878522938693, "Bleu_3": 7.429660597762622e-07, "Bleu_4": 1.6600772237793931e-09, "METEOR": 0.21314343484661535, "ROUGE_L": 0.20504201680672268, "CIDEr": 2.205729182614748e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a train traveling along a track through a lush green valley surrounded by mountains. The train is yellow and has a number on the side. There are trees and bushes on either side of the track and a river running through the valley. The sky is blue and there are clouds in the distance."}, "226171": {"image_id": 226171, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 0.12275560174315096, "Bleu_4": 0.0927461706910221, "METEOR": 0.16331609315814624, "ROUGE_L": 0.27453186530579443, "CIDEr": 1.278587736365731e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a desk with a computer, keyboard, mouse, and cup of coffee on it. There is a whiteboard on the wall with a list of tasks written on it. The room is well lit and has a window with a view of the outside.\n\nThe image shows a desk with a"}, "194208": {"image_id": 194208, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.15937104245046027, "Bleu_3": 0.09986796846096183, "Bleu_4": 0.06680779845343547, "METEOR": 0.1590999975130491, "ROUGE_L": 0.28355607205113303, "CIDEr": 3.3177204258827176e-12, "SPICE": {"All": {"pr": 0.0625, "re": 0.058823529411764705, "f": 0.06060606060606061, "fn": 32.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.06666666666666667, "re": 0.1111111111111111, "f": 0.08333333333333334, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}}, "caption": "The image shows a living room with a couch, coffee table, and chairs. There is a window on the left side of the room and a door on the right side. The room is empty and there are no people or objects in it.\n\nThe image shows a living room with a couch,"}, "575637": {"image_id": 575637, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 8.61888809829365e-07, "Bleu_4": 1.9110767207150235e-09, "METEOR": 0.19457761337036564, "ROUGE_L": 0.272108843537415, "CIDEr": 1.444611770997176e-08, "SPICE": {"All": {"pr": 0.09375, "re": 0.11538461538461539, "f": 0.10344827586206896, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man in a boat on a river. The man is wearing sunglasses and a life jacket. There are trees and mountains in the background. The water is calm and there are no other boats in sight. The man is smiling and appears to be enjoying the ride."}, "483587": {"image_id": 483587, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.08359497709435722, "Bleu_3": 5.122150570969723e-07, "Bleu_4": 1.2740800388313793e-09, "METEOR": 0.14814505574908274, "ROUGE_L": 0.21403508771929822, "CIDEr": 3.0268665881321556e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.3076923076923077, "f": 0.27586206896551724, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a black and white dog standing in a grassy area with a fence in the background. The dog is wearing a collar and leash. There are several other dogs in the background, but they are not visible in the image. The image is taken from a low angle, looking down at"}, "270066": {"image_id": 270066, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.18890811128268284, "Bleu_3": 0.14281978481313226, "Bleu_4": 0.10496354025791335, "METEOR": 0.25974270871924343, "ROUGE_L": 0.26704190118824267, "CIDEr": 2.983828572771371e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.16666666666666666, "f": 0.15789473684210525, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a white motorcycle parked in front of a building with a green roof. The motorcycle has a black seat and a black handlebar. The building has a green roof and a white wall. There is a sign on the wall that reads, \"Welcome to the Motorcycle Shop\". The"}, "144373": {"image_id": 144373, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1824897193978171, "Bleu_3": 0.11396323345568955, "Bleu_4": 0.07615710086477687, "METEOR": 0.2197062579568779, "ROUGE_L": 0.20346897931954633, "CIDEr": 3.9329661352503005e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.09375, "f": 0.1111111111111111, "fn": 29.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person holding a doughnut in their hand. The doughnut appears to be filled with chocolate and has a sprinkle of powdered sugar on top. The person's hand is covered in flour and there is a plate of doughnuts on the table in"}, "46463": {"image_id": 46463, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.25425669045977695, "Bleu_3": 0.1818494973816351, "Bleu_4": 0.1300856091891505, "METEOR": 0.23499082756388426, "ROUGE_L": 0.25258799171842644, "CIDEr": 9.902309404089086e-09, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.3888888888888889, "f": 0.3111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6666666666666666, "f": 0.5217391304347826, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a person holding a sandwich in their hand. The sandwich appears to be made of bread, tomato, and cheese. The person is wearing a white shirt and black pants. There is a kitchen counter in the background with a stove and sink."}, "181655": {"image_id": 181655, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2126329371370835, "Bleu_3": 0.12526923159832437, "Bleu_4": 1.4457066598210432e-05, "METEOR": 0.18922187525431305, "ROUGE_L": 0.2804597701149425, "CIDEr": 4.329263517758525e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.125, "f": 0.16326530612244897, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table with food and drinks on it. There are several plates of food on the table, including sandwiches, salads, and fruit. The people in the image are all wearing casual clothing and appear to be enjoying their meal."}, "245902": {"image_id": 245902, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.20701966779852365, "Bleu_3": 0.13887830606912108, "Bleu_4": 0.08688630801612651, "METEOR": 0.27237547050908734, "ROUGE_L": 0.2594167679222357, "CIDEr": 2.9192971951769393e-10, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.18518518518518517, "f": 0.17241379310344826, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image is of a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of black and white tiles. There is a window on the left side of the room with white curtains. The toilet is on the right side of the"}, "393692": {"image_id": 393692, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.21602468994265056, "Bleu_3": 0.1418983411941997, "Bleu_4": 1.561969968428557e-05, "METEOR": 0.2963197620209789, "ROUGE_L": 0.3285457809694794, "CIDEr": 4.313526625825985e-09, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.30434782608695654, "f": 0.31111111111111117, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a desk with a laptop, cell phone, and other electronic devices on it. The desk is made of wood and has a lamp on it. The room is small and has a window with curtains. There are no other objects in the room.\n\nThe image shows a desk"}, "187348": {"image_id": 187348, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.12993504870706918, "Bleu_3": 0.08551250345584478, "Bleu_4": 0.05860750703211417, "METEOR": 0.18098974355072484, "ROUGE_L": 0.2096700274977085, "CIDEr": 3.41019492082581e-13, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.23809523809523808, "f": 0.1923076923076923, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a white tent. They are all smiling and holding glasses of wine. The woman on the left is wearing a red dress and the man on the right is wearing a black suit. The other people in the group are wearing various colors and styles"}, "289712": {"image_id": 289712, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.09901475429574468, "Bleu_3": 0.05809560444813122, "Bleu_4": 7.953502757119053e-06, "METEOR": 0.1786941012443853, "ROUGE_L": 0.1920654911838791, "CIDEr": 2.684714950805135e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.23076923076923078, "f": 0.22641509433962265, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a large room filled with suitcases and other luggage. The room is dimly lit and there are no windows. The floor is made of wood and the walls are painted white. There are no chairs or other furniture in the room.\n\nThe image is taken from the perspective of"}, "24260": {"image_id": 24260, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1027524665455226, "Bleu_3": 0.059548592709689166, "Bleu_4": 8.102230734220573e-06, "METEOR": 0.14072938150197783, "ROUGE_L": 0.18780788177339902, "CIDEr": 8.048734604876095e-07, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.045454545454545456, "f": 0.04166666666666667, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows two horses in a field, one of which is jumping over a fence\n\nThe horses are brown and white with long manes and tails. The one on the left is jumping over a fence made of wood and has a white stripe on its back. The one on the"}, "462978": {"image_id": 462978, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.1415984650784514, "Bleu_3": 0.07143616536435347, "Bleu_4": 9.06442292469654e-06, "METEOR": 0.17729615775194232, "ROUGE_L": 0.2483460559796438, "CIDEr": 1.4794713788408178e-10, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.24, "f": 0.21428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is a pair of wine glasses with a bird design on the side of one of them. The other glass has a floral design on it. The glasses are sitting on a table in front of a window with a view of the city outside. The lighting in the room is dim and the colors"}, "86426": {"image_id": 86426, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.09125318612878565, "Bleu_4": 1.1336958836408244e-05, "METEOR": 0.22855881026586297, "ROUGE_L": 0.32526449428692333, "CIDEr": 3.819775129318879e-08, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.10526315789473684, "f": 0.09523809523809525, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a desk with a computer, keyboard, and mouse on it. There is also a chair and a lamp on the desk. The room is well lit and has a window with curtains.\n\nThe image shows a desk with a computer, keyboard, and mouse on it. There"}, "460705": {"image_id": 460705, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2663118206400466, "Bleu_3": 0.1975442319449809, "Bleu_4": 0.13605128106221753, "METEOR": 0.33323141230955466, "ROUGE_L": 0.34398496240601506, "CIDEr": 3.438875540047454e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16666666666666666, "f": 0.1702127659574468, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man standing on the beach holding a surfboard. He is wearing a black wetsuit and a black hoodie. The sky is blue and there are trees in the background.\n\nThe man is standing on the beach holding a surfboard. He is wearing a black"}, "386912": {"image_id": 386912, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.2449489742734669, "Bleu_3": 0.1944026318804929, "Bleu_4": 0.15730093122505484, "METEOR": 0.2734926459121228, "ROUGE_L": 0.29847094801223245, "CIDEr": 9.461275841761679e-11, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.3333333333333333, "f": 0.3111111111111111, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a woman sitting at a desk in a cluttered office. She is wearing a black shirt and jeans, and has a laptop open in front of her. There are several books and papers on the desk, as well as a whiteboard with notes written on it. The walls"}, "122745": {"image_id": 122745, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.09087496586948689, "Bleu_4": 1.1854610697110774e-05, "METEOR": 0.25496359131657126, "ROUGE_L": 0.30049261083743845, "CIDEr": 3.6805148790502706e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a stop sign at night with the sun setting in the background. The sign is red and white, with the words \"stop\" written in black letters. The sky is dark and the mountains are visible in the distance."}, "557556": {"image_id": 557556, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.18504536999744126, "Bleu_3": 0.14876737580907046, "Bleu_4": 0.10659718390951979, "METEOR": 0.20958015938218566, "ROUGE_L": 0.25326215895610915, "CIDEr": 2.470373295393265e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16666666666666666, "f": 0.15686274509803924, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young man in a white shirt and shorts holding a frisbee on a beach. The man is standing in front of a group of people who are watching him play the game. The sky is blue and there are trees in the background. The image is in black and white."}, "331162": {"image_id": 331162, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1189176779999305, "Bleu_3": 0.06437822382780045, "Bleu_4": 8.463566423155675e-06, "METEOR": 0.19868135436288692, "ROUGE_L": 0.207506520013607, "CIDEr": 2.4997288581882456e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.1891891891891892, "f": 0.2153846153846154, "fn": 30.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.35714285714285715, "f": 0.3448275862068965, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a classroom with several computers on desks. There are no people in the room. The walls are painted white and there are no windows. The floor is made of hardwood and there are no chairs or tables in the room. The room is well lit and there are no windows. The room"}, "317441": {"image_id": 317441, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.14285714285419707, "Bleu_3": 0.07572431510387477, "Bleu_4": 9.856825261135735e-06, "METEOR": 0.1514008437471713, "ROUGE_L": 0.16126900198281557, "CIDEr": 2.0554814797899038e-10, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.1111111111111111, "f": 0.08888888888888888, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a street sign with the words \"90 street\" and \"debour\" written on it. The sign is mounted on a pole in the middle of the street. There are buildings on either side of the street, with windows and doors visible. The sky is clear and blue."}, "47559": {"image_id": 47559, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.12430587656291649, "Bleu_4": 1.4143550190666945e-05, "METEOR": 0.2280668014340476, "ROUGE_L": 0.2501464557703574, "CIDEr": 2.0879762447351211e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.18181818181818182, "f": 0.20512820512820512, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of hardwood. There is a wooden door with a window above it. The room is well lit and has a large mirror on the wall.\n\nThe image shows a bath"}, "102668": {"image_id": 102668, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.1878672873218244, "Bleu_3": 0.08964004852977604, "Bleu_4": 1.106792615545272e-05, "METEOR": 0.1863503902292324, "ROUGE_L": 0.21997836278398844, "CIDEr": 8.406128325610732e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a city street with a bus stop on the corner. There are several cars parked on the side of the road, and a few pedestrians walking in the area. The sky is clear and the sun is shining.\n\nThe bus stop has a sign that reads \"Bus Stop\""}, "159561": {"image_id": 159561, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.11836112830783165, "Bleu_4": 0.07706946743067312, "METEOR": 0.25414521389161854, "ROUGE_L": 0.22938079719227877, "CIDEr": 1.2038478177837375e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.14705882352941177, "f": 0.1724137931034483, "fn": 29.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a bookshelf with several books on it. The books are arranged in a row on the shelf, with the titles facing outwards. There are also some flowers and plants on the shelf, including a bird feeder and a bird bath. The window behind the bookshelf is open,"}, "409914": {"image_id": 409914, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.0823386969578779, "Bleu_3": 4.889449842587157e-07, "Bleu_4": 1.1966751775119417e-09, "METEOR": 0.09155937052932761, "ROUGE_L": 0.16721491228070173, "CIDEr": 2.330967340859041e-17, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15789473684210525, "f": 0.15, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a train car with a large screen on the wall displaying a map of the train route. There are two people sitting in the seats, one of them is looking at the screen and the other is looking out the window. The train car has a white and red color scheme with a black and white striped"}, "270303": {"image_id": 270303, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.09073607102736221, "Bleu_4": 1.1055858618542048e-05, "METEOR": 0.2562563888667202, "ROUGE_L": 0.27036011080332406, "CIDEr": 7.640948248120732e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.21739130434782608, "f": 0.23255813953488372, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a plate of food with a white sauce and a slice of fish on top. There is a lemon wedge on the side of the plate. The plate is on a white tablecloth.\n\nThe image is a plate of food with a white sauce and a slice of fish on"}, "11721": {"image_id": 11721, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.11997212723629987, "Bleu_4": 0.07914930403806009, "METEOR": 0.19319456974042507, "ROUGE_L": 0.2848565710473649, "CIDEr": 2.2361747112876814e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a large, ornate clock on the wall. The clock has a large face with Roman numerals and hands. The clock is surrounded by a large, ornate frame with intricate carvings. The walls are made of yellow and white tiles, with a large, ornate mosaic"}, "188173": {"image_id": 188173, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.08668270200700183, "Bleu_4": 1.0908370302144318e-05, "METEOR": 0.15477234274269772, "ROUGE_L": 0.22679390259015986, "CIDEr": 8.439302814512783e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.21739130434782608, "f": 0.19230769230769232, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of giraffes standing in a field with a fence in the background. The giraffes are brown and have spots on their backs. They are standing in a line, with their heads down and their necks stretched out. There are some trees in the background"}, "279818": {"image_id": 279818, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.23094010767127685, "Bleu_3": 0.1869180748641801, "Bleu_4": 0.15273661558332743, "METEOR": 0.2863007615096909, "ROUGE_L": 0.38146674246731094, "CIDEr": 2.9644986648459103e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 10.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4666666666666667, "re": 0.5384615384615384, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}}, "caption": "The image shows a man sitting on a bench in front of a red fire hydrant. He is wearing a green shirt and blue jeans, and has a backpack on his back. There is a small tree in the background.\n\nThe image is taken from a low angle, looking up at"}, "531581": {"image_id": 531581, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 0.06980462899277687, "Bleu_4": 9.223350291134877e-06, "METEOR": 0.1592232206741085, "ROUGE_L": 0.22732919254658387, "CIDEr": 4.139073526521275e-10, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.03125, "f": 0.03333333333333333, "fn": 31.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.06666666666666667, "f": 0.07407407407407407, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows three children standing on the sidewalk in front of a building. They are wearing casual clothing, including a black shirt and blue jeans. The boy on the left is wearing a red shirt and the boy in the middle is wearing a blue shirt. The boy on"}, "139130": {"image_id": 139130, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.20195126571496114, "Bleu_3": 0.14932035830598486, "Bleu_4": 0.09125968348670661, "METEOR": 0.17335962748405084, "ROUGE_L": 0.22584228063680117, "CIDEr": 1.1372763599300214e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of zebras standing in a field with trees in the background. The zebras are standing in a line, with their heads down and their ears up. They are wearing brown and white stripes. The image is taken from a low angle, with the zebras in the"}, "549845": {"image_id": 549845, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 8.042523996560112e-07, "Bleu_4": 1.8144038748380883e-09, "METEOR": 0.172688045323662, "ROUGE_L": 0.25553560742070613, "CIDEr": 4.352274259167634e-10, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man sitting on a chair with his hands on his lap, looking up at the skyline of a city in the background. The man is wearing glasses and has a beard. The skyline of the city is visible in the background, with several tall buildings and skyscrapers"}, "110313": {"image_id": 110313, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.10942520359115704, "Bleu_3": 6.16909583375895e-07, "Bleu_4": 1.4720536435426584e-09, "METEOR": 0.13705032661698408, "ROUGE_L": 0.18100890207715134, "CIDEr": 4.926596191556332e-12, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.09523809523809523, "f": 0.12698412698412698, "fn": 38.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people walking through a large, open space with columns and arches. There are several people walking in the background, and some are carrying umbrellas. The floor is made of marble and there are several large windows on the walls. The ceiling is high and there are several"}, "548500": {"image_id": 548500, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.08606629658080774, "Bleu_3": 5.189555018762679e-07, "Bleu_4": 1.2804032108833407e-09, "METEOR": 0.14072938150197783, "ROUGE_L": 0.14672279013830425, "CIDEr": 6.543627555331662e-14, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a dog standing in front of a doorway, with its mouth open and its tongue hanging out. The dog is wearing a collar and tag on its neck. The background is a dark brown color with a white ceiling and a white wall. There is a small table with a white table"}, "334466": {"image_id": 334466, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.0645198590415134, "Bleu_3": 4.522633916831482e-07, "Bleu_4": 1.2041494936393691e-09, "METEOR": 0.17427482393968954, "ROUGE_L": 0.20346897931954633, "CIDEr": 3.0420648961546405e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.08, "f": 0.0784313725490196, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The giraffe is standing in the middle of a grassy field, looking up at the sky. It has a long neck and legs, and its fur is brown and spotted. The giraffe is wearing a collar with a tag on it. The tag has the words \"Giraffe\""}, "88552": {"image_id": 88552, "Bleu_1": 0.4313725490111496, "Bleu_2": 0.26271583096647133, "Bleu_3": 0.14123276695717468, "Bleu_4": 1.5564719247748716e-05, "METEOR": 0.1931958075810987, "ROUGE_L": 0.2966050186680559, "CIDEr": 0.0006318882335337458, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.10526315789473684, "f": 0.0816326530612245, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in the snow. They are wearing ski gear and helmets. There is a snowboard on the ground next to one of the people. The sky is cloudy and there is snow on the ground.\n\nThe image is taken in a winter setting, with"}, "498940": {"image_id": 498940, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.16816819849581244, "Bleu_3": 0.08270007684490462, "Bleu_4": 1.0365265119381272e-05, "METEOR": 0.18349116756330539, "ROUGE_L": 0.21131639722863746, "CIDEr": 4.781675654693646e-11, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.38095238095238093, "f": 0.37209302325581395, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of soldiers playing soccer on a grassy field. They are wearing military uniforms and carrying rifles. The field is surrounded by trees and there are several people watching from the sidelines. The sun is shining down on the field and there is a cloudy sky in the"}, "419816": {"image_id": 419816, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.298142396991572, "Bleu_3": 0.21868022761928713, "Bleu_4": 0.1334223706634388, "METEOR": 0.27802444724519254, "ROUGE_L": 0.37654320987654316, "CIDEr": 0.00042982610876357173, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3157894736842105, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a woman lying on a bed in a hotel room. She is wearing a black dress and has her head resting on her hand. There is a mirror on the wall behind her."}, "332914": {"image_id": 332914, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.2589571847366968, "Bleu_3": 0.1762408642104436, "Bleu_4": 0.10334028405267877, "METEOR": 0.27138568077776226, "ROUGE_L": 0.2858816637375513, "CIDEr": 7.457017802552482e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a young boy sitting on a bed, holding a remote control in his hand. He is wearing a baseball cap and a t-shirt. The bed is covered in a blue and white striped blanket. The room has a window with curtains and a door leading to a hallway"}, "77473": {"image_id": 77473, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.148586412828113, "Bleu_3": 0.07422009036633678, "Bleu_4": 9.371781221139703e-06, "METEOR": 0.1316274541539237, "ROUGE_L": 0.22426470588235295, "CIDEr": 2.613058143507541e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.13333333333333333, "f": 0.14545454545454545, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.2857142857142857, "f": 0.29629629629629634, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in a room. They are all wearing black clothing and one person is holding a laptop. The room appears to be a conference room with a table and chairs. There are several windows in the room and a whiteboard on the wall. The image is well lit and"}, "296871": {"image_id": 296871, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.21512668786420022, "Bleu_3": 0.14896589444910865, "Bleu_4": 0.11587901042045703, "METEOR": 0.23266934488109975, "ROUGE_L": 0.2660850599781897, "CIDEr": 3.003933207466939e-13, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.391304347826087, "f": 0.391304347826087, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a black and white cat sitting on top of a wooden table in a kitchen. The cat is looking up at the camera with its eyes wide open. The table has a few bottles of alcohol on it, and there are some other objects on the table as well. The walls of the kitchen are"}, "398628": {"image_id": 398628, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.1096274741694192, "Bleu_4": 0.07439991547036208, "METEOR": 0.19316311688237328, "ROUGE_L": 0.24830393487109906, "CIDEr": 2.3399446930698157e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15, "f": 0.13953488372093023, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of giraffes standing in a fenced enclosure. They are wearing collars and are being led by a person in a yellow shirt. There are trees in the background and a fence in the foreground.\n\nThe giraffes are standing in a f"}, "54007": {"image_id": 54007, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.2620817976974896, "Bleu_3": 0.21805327398716068, "Bleu_4": 0.18597687056297119, "METEOR": 0.30657638511735563, "ROUGE_L": 0.31642651296829977, "CIDEr": 3.476017017195546e-12, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a young boy holding a baseball bat and walking on a baseball field. The boy is wearing a blue shirt and red pants, and has a baseball cap on his head. The field is green and there are no other people in the image.\n\nThe image is in focus and the colors"}, "194425": {"image_id": 194425, "Bleu_1": 0.1739130434744802, "Bleu_2": 0.06216698721465449, "Bleu_3": 4.44517628108609e-07, "Bleu_4": 1.1955001291193746e-09, "METEOR": 0.14402134899217175, "ROUGE_L": 0.2019867549668874, "CIDEr": 1.9971113754887363e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.125, "f": 0.14545454545454545, "fn": 28.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is of a sculpture of a pair of scissors made out of metal. The scissors are standing on a stone pedestal in the middle of a courtyard. The courtyard is surrounded by adobe buildings with red roofs and white walls. There are cacti and"}, "17714": {"image_id": 17714, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2639435221237223, "Bleu_3": 0.18973201303741505, "Bleu_4": 0.1285643204879068, "METEOR": 0.20732854683681867, "ROUGE_L": 0.28879537085744345, "CIDEr": 1.9816316297403694e-09, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.5294117647058824, "f": 0.391304347826087, "fn": 8.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.8333333333333334, "f": 0.5263157894736842, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a table with a plate of food on it, including a slice of pizza, a banana, and a glass of orange juice. There is also a cup of coffee on the table. The table is made of wood and has a white tablecloth on it. The floor is made of"}, "346138": {"image_id": 346138, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.19507682662422146, "Bleu_3": 0.12191693142366875, "Bleu_4": 0.08153649775377378, "METEOR": 0.23396065078644512, "ROUGE_L": 0.24465240641711228, "CIDEr": 8.872812000782096e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is a collage of different types of food, including noodles, rice, and soup. There are also various types of vegetables, such as carrots, potatoes, and onions. The dishes are arranged on a table with different types of sauces and condiments. The overall"}, "230432": {"image_id": 230432, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.2014440620697061, "Bleu_3": 0.14038665933156294, "Bleu_4": 0.08956271819971037, "METEOR": 0.22378562675433727, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.8718153787762838e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.29411764705882354, "f": 0.2380952380952381, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and a helmet, and is standing on the board with his arms outstretched. The wave is large and white, with a lot of foam on top. The sur"}, "386370": {"image_id": 386370, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 6.912848008424654e-07, "Bleu_4": 1.5876030342373218e-09, "METEOR": 0.16462188328026175, "ROUGE_L": 0.20254565578306588, "CIDEr": 1.8189948450221405e-11, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.25, "f": 0.20408163265306123, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a bridge over a river with a city skyline in the background. The bridge is made of steel and has a large arch in the middle. There are two lampposts on either side of the bridge. The river is calm and there are some boats on it. The sky is clear and"}, "502998": {"image_id": 502998, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.11605769149245462, "Bleu_3": 6.54689746724509e-07, "Bleu_4": 1.563155525234599e-09, "METEOR": 0.21405211666365112, "ROUGE_L": 0.1586475942782835, "CIDEr": 2.1806889539101414e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are all wearing ski gear and helmets. The trees in the background are covered in snow.\n\nThe image is taken in a mountainous area with a lot of trees and snow. The sun is shining through the"}, "241934": {"image_id": 241934, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.18663625434394554, "Bleu_3": 0.08806579930933402, "Bleu_4": 1.0810927622781055e-05, "METEOR": 0.20483200270213475, "ROUGE_L": 0.21356050881082975, "CIDEr": 1.2311284530143918e-11, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1875, "f": 0.13636363636363635, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a box filled with various types of donuts. There are six donuts in total, each with a different flavor. The donuts are arranged in a row on the box, with each one having a different color and design. The donuts are all different shapes and sizes, with some being round"}, "342819": {"image_id": 342819, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1189176779999305, "Bleu_3": 6.437822382780047e-07, "Bleu_4": 1.5050585905794507e-09, "METEOR": 0.20238410133580412, "ROUGE_L": 0.24559637644690488, "CIDEr": 1.7894046096722496e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image is a bedroom with a bed, nightstand, and lamp. The walls are painted a light blue color and there is a large window on one side of the room. The floor is made of hardwood and there is a rug in the middle of the room. The room has a ceiling fan and"}, "466339": {"image_id": 466339, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.22288685594608834, "Bleu_3": 0.1516298425242195, "Bleu_4": 0.08882628649241174, "METEOR": 0.2768700499806546, "ROUGE_L": 0.31987414787624535, "CIDEr": 4.5343851250051887e-14, "SPICE": {"All": {"pr": 0.12, "re": 0.1111111111111111, "f": 0.11538461538461538, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a black cat sitting on the floor in front of a white door. The door has a large archway with a wooden frame and a glass window above it. The wall behind the door is painted white and has a few small windows. There is a small table with a vase on it next to the"}, "76962": {"image_id": 76962, "Bleu_1": 0.3333333333274854, "Bleu_2": 0.21821789023212987, "Bleu_3": 0.15129549700953046, "Bleu_4": 0.10642130023002942, "METEOR": 0.29430837380381614, "ROUGE_L": 0.28728414442700156, "CIDEr": 2.9473958615496484e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1875, "f": 0.16216216216216214, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is of a yellow fire hydrant on the side of the road. The hydrant is made of metal and has a large handle on top. There is a small patch of grass in front of the hydrant and a few trees in the background. The sky is cloudy and there are no buildings or people"}, "157019": {"image_id": 157019, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.08321444966006321, "Bleu_4": 1.046739829058619e-05, "METEOR": 0.1944676308702533, "ROUGE_L": 0.19074421513445905, "CIDEr": 2.445655222112994e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a city street with tall buildings on either side. There are cars parked on the side of the road and pedestrians walking in the rain. The sky is overcast with clouds.\n\nThe image is taken from a high vantage point, looking down on the street. The buildings are"}, "159667": {"image_id": 159667, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.22562131409418867, "Bleu_3": 0.15969209259965045, "Bleu_4": 1.6979055929960036e-05, "METEOR": 0.2917228669610901, "ROUGE_L": 0.29397590361445786, "CIDEr": 2.1529712144047313e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a laptop computer with a keyboard and mouse on top of it. There are several stickers on the laptop, including a ghost, a skull, and a smiley face. The laptop is sitting on a table with a white sheet of paper on top of it.\n\nThe laptop is a"}, "20979": {"image_id": 20979, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.12483755678422238, "Bleu_3": 6.608439529502604e-07, "Bleu_4": 1.5275844289614858e-09, "METEOR": 0.1767066552954159, "ROUGE_L": 0.20795454545454545, "CIDEr": 1.743821281403891e-12, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.15384615384615385, "f": 0.14545454545454548, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a street with a bus stop on the left side of the road. There are two parked motorcycles on the right side of the road. The buildings on either side of the street are tall and made of brick. There are no people in the image. The sky is cloudy and there is"}, "6226": {"image_id": 6226, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 0.07176233678698053, "Bleu_4": 9.226349141829447e-06, "METEOR": 0.17771049658777485, "ROUGE_L": 0.21863799283154117, "CIDEr": 6.031305290191948e-12, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.06451612903225806, "f": 0.07272727272727274, "fn": 29.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a train traveling down a track next to a sign that reads \"stop\". The train has a number of passengers on board and is traveling at a moderate speed. The sky is clear and there are no other vehicles or people in the area.\n\nThe train is traveling down the track"}, "427870": {"image_id": 427870, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.11531640100118269, "Bleu_3": 6.612130898132252e-07, "Bleu_4": 1.5920362546205505e-09, "METEOR": 0.1517042232222803, "ROUGE_L": 0.19110275689223058, "CIDEr": 7.005263693252026e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.26666666666666666, "f": 0.2051282051282051, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a skateboarder performing a trick on a halfpipe. The skateboarder is wearing a black shirt and black pants, and has a black helmet on his head. The halfpipe is made of concrete and has a blue and white color scheme. There are several people watching"}, "185925": {"image_id": 185925, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.07269451760681338, "Bleu_4": 9.458362067955946e-06, "METEOR": 0.21882022672786483, "ROUGE_L": 0.268870523415978, "CIDEr": 1.3807813788970372e-09, "SPICE": {"All": {"pr": 0.12, "re": 0.16666666666666666, "f": 0.13953488372093023, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a red shirt and white shorts, and has a racket in his hand. The net is in the background, and there are other players on the court. The sky is blue and there are trees in the background."}, "356800": {"image_id": 356800, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.144034534600296, "Bleu_4": 0.10455985518811584, "METEOR": 0.2202582312596578, "ROUGE_L": 0.30314743235781333, "CIDEr": 7.192120831008767e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.11764705882352941, "f": 0.14814814814814817, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a woman standing in the middle of a pile of leaves. She is wearing a black jacket and holding an umbrella. The leaves are blowing in the wind and the woman is looking down at the ground. The image is taken from a low angle, looking up at the woman."}, "3983": {"image_id": 3983, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.23354968324417125, "Bleu_3": 0.16026827490989917, "Bleu_4": 0.11217403309457756, "METEOR": 0.23142636505660683, "ROUGE_L": 0.28636096906697955, "CIDEr": 1.3215449847407998e-12, "SPICE": {"All": {"pr": 0.15625, "re": 0.20833333333333334, "f": 0.17857142857142858, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a group of people standing in the snow near a bus. They are all wearing ski gear and some of them are carrying skis. The bus is parked on the side of the road and there are mountains in the background.\n\nThe image is taken in the winter and the snow is"}, "228764": {"image_id": 228764, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.18725633517633355, "Bleu_3": 0.14807546137424474, "Bleu_4": 0.10520850572898884, "METEOR": 0.24672928579984063, "ROUGE_L": 0.3056792873051225, "CIDEr": 3.3920306902247843e-13, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a cat and a dog playing on the beach. The cat is sitting on the sand and the dog is running around the beach. There are buildings in the background.\n\nThe cat is a brown and white cat with a collar on. The dog is a black and white dog with a collar"}, "455480": {"image_id": 455480, "Bleu_1": 0.3157894736786704, "Bleu_2": 0.19867985355623985, "Bleu_3": 0.08953269507572546, "Bleu_4": 1.0737119910549713e-05, "METEOR": 0.2912879572711874, "ROUGE_L": 0.30123456790123454, "CIDEr": 1.4103158318181863e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.27586206896551724, "f": 0.2711864406779661, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a small blue boat docked at a wooden pier on a lake. The boat has an umbrella on top of it and there are no people in sight. The water is calm and there are no other boats or objects in the image. The sky is cloudy and there are no trees or buildings"}, "270505": {"image_id": 270505, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.09671474291033856, "Bleu_3": 5.838426740772723e-07, "Bleu_4": 1.442223004001259e-09, "METEOR": 0.17523173942116663, "ROUGE_L": 0.2139099941554646, "CIDEr": 8.937570178790438e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows an elephant standing on the side of a road with a person on its back. The elephant is wearing a colorful headdress and has a large, curved tusk on its face. The person on its back is wearing a red and white striped shirt and a"}, "400569": {"image_id": 400569, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.10562592656622659, "Bleu_4": 1.2211216504829663e-05, "METEOR": 0.21872666324766932, "ROUGE_L": 0.2401574803149606, "CIDEr": 2.786597382950415e-13, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16129032258064516, "f": 0.18867924528301885, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a brown horse standing in a field with a barn in the background. The horse is wearing a halter and bridle and has a bit in its mouth. The horse is standing on a patch of grass and there are some trees in the background. The sky is cloudy and there are some"}, "542755": {"image_id": 542755, "Bleu_1": 0.4090909090816116, "Bleu_2": 0.27588029391667884, "Bleu_3": 0.1935310651946666, "Bleu_4": 0.11531002095179026, "METEOR": 0.3479298578750573, "ROUGE_L": 0.37602739726027395, "CIDEr": 9.230941822114957e-08, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man in a yellow shirt and white shorts holding a tennis racket and standing on a tennis court. He is wearing white shoes and has a determined expression on his face. The background is a blue sky with white clouds."}, "256220": {"image_id": 256220, "Bleu_1": 0.3749999999933036, "Bleu_2": 0.2335496832442485, "Bleu_3": 0.14470893702124177, "Bleu_4": 0.1034094067285757, "METEOR": 0.25034570938900486, "ROUGE_L": 0.3056792873051225, "CIDEr": 8.813357467915685e-13, "SPICE": {"All": {"pr": 0.16, "re": 0.26666666666666666, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a view of a city street with a large building under construction in the background. The building has a large crane on top of it, and there are several trucks and construction workers on the street. The sky is clear and blue, with a few clouds scattered about. The buildings on either side"}, "242297": {"image_id": 242297, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2285817953234835, "Bleu_3": 0.10081017475123802, "Bleu_4": 1.1964258135320573e-05, "METEOR": 0.1908118165523857, "ROUGE_L": 0.2381483547127719, "CIDEr": 7.007256797641055e-11, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.2413793103448276, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07142857142857142, "f": 0.08695652173913043, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The dog is standing on the grass in the foreground, looking at the camera. The dog is wearing a red collar and has a red leash attached to its neck. The dog is standing in front of a fence made of wooden posts and barbed wire. The fence is surrounded by trees and"}, "42215": {"image_id": 42215, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 8.64037821629974e-07, "Bleu_4": 1.8858494565719337e-09, "METEOR": 0.17734733880506345, "ROUGE_L": 0.24355464293862653, "CIDEr": 1.5647797349721032e-11, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.05, "f": 0.04545454545454545, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a table with a cup of coffee, a book, and a bunch of oranges on it. The oranges are arranged in a row, with one orange on the left and two on the right. The book is open on the table, with a pen and notebook next to it. The cup"}, "431256": {"image_id": 431256, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1577557537051747, "Bleu_3": 0.11429850643054774, "Bleu_4": 0.08835657960756262, "METEOR": 0.23657727143062462, "ROUGE_L": 0.23047858942065497, "CIDEr": 3.63475695984316e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.22727272727272727, "f": 0.20408163265306123, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person on a snowboard jumping over a ramp in the snow. The person is wearing a black jacket and black pants, and has a black helmet on their head. The ramp is made of wood and has a white surface. The background is a mountain range with snow"}, "327186": {"image_id": 327186, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.16791512356189472, "Bleu_3": 0.11542841458786292, "Bleu_4": 0.07305267243158185, "METEOR": 0.25652690838683323, "ROUGE_L": 0.24413950829045164, "CIDEr": 1.8208475724470357e-14, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2857142857142857, "f": 0.2727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image is of a passenger jet taking off from the runway. The plane is white with green stripes on the tail and wings. The plane is flying in the sky with the sun shining on it. There are people on the ground looking up at the plane as it takes off. The sky is blue with"}, "142585": {"image_id": 142585, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1211406307163407, "Bleu_3": 6.559319301112625e-07, "Bleu_4": 1.5337392624752068e-09, "METEOR": 0.1652880382738916, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.4189959683378201e-12, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.4, "f": 0.2222222222222222, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a busy street with cars and buses driving on it. There are people walking on the sidewalk and a sign on the side of the road that says 'stop' in English. The sky is blue and there are buildings in the background.\n\nThe image is taken from a high angle, looking"}, "82794": {"image_id": 82794, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.23260756692519302, "Bleu_3": 0.1071350722675485, "Bleu_4": 1.300413999698558e-05, "METEOR": 0.19657243260880425, "ROUGE_L": 0.3084702907711757, "CIDEr": 5.6939605226467754e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a hot dog on a plate with ketchup, mustard, and relish on it. There is also a glass of beer on the table. The background is a blue and white checkered tablecloth.\n\nThe image shows a hot dog on a plate with ketchup,"}, "250001": {"image_id": 250001, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.18164975363435543, "Bleu_3": 0.12315111185169988, "Bleu_4": 1.3766638772277382e-05, "METEOR": 0.25108830427764944, "ROUGE_L": 0.17221908526256355, "CIDEr": 9.378128860474447e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a tennis match in progress on a grass court. There are two players on the court, one hitting a ball with a racket and the other watching from the sidelines. The crowd is watching from the stands, and there are several people in the background. The sky is cloudy and there are"}, "556091": {"image_id": 556091, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.19010380264692892, "Bleu_3": 0.09161387440820473, "Bleu_4": 1.1370550193640665e-05, "METEOR": 0.21172469775937872, "ROUGE_L": 0.27648725212464587, "CIDEr": 1.9821997385346306e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a computer desk with a keyboard, mouse, and headphones. There are also some books and papers on the desk.\n\nThe computer is running a music software program, and there are several other electronic devices on the desk, including a laptop and a tablet. The room is well"}, "245440": {"image_id": 245440, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2015901948875348, "Bleu_3": 0.13370981749106944, "Bleu_4": 0.08315339223523018, "METEOR": 0.21350499423665734, "ROUGE_L": 0.2507339988256019, "CIDEr": 1.0228841425709581e-11, "SPICE": {"All": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on the edge of a river, looking up at a group of kites flying in the sky. The people are wearing white shirts and shorts, and some of them are holding kites. The sky is clear and blue, with a few clouds scattered across it"}, "185901": {"image_id": 185901, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.13965509692979164, "Bleu_3": 0.09465173555893981, "Bleu_4": 0.06588602516958998, "METEOR": 0.24796148307903038, "ROUGE_L": 0.2459677419354839, "CIDEr": 8.037491123786163e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.23076923076923078, "f": 0.21428571428571427, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is a clear glass bowl filled with lemons. The lemons are yellow and have a sour taste. They are a popular fruit that is often used in cooking and baking. The bowl is on a white surface, and there are no other objects in the image."}, "257910": {"image_id": 257910, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.15508644003992356, "Bleu_3": 0.10224805260881925, "Bleu_4": 0.07020662805225339, "METEOR": 0.18342151675485008, "ROUGE_L": 0.17098808689558512, "CIDEr": 1.9072205692669147e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1111111111111111, "f": 0.0975609756097561, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The giraffe is looking up at the camera with its mouth open. It has a long neck and spots on its body.\n\nThe giraffe is standing in a barn with a red roof and white walls. There are hay bales in the background.\n\nThe giraffe is we"}, "129803": {"image_id": 129803, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.15632047282649467, "Bleu_3": 0.0961390165871351, "Bleu_4": 1.1325993722540616e-05, "METEOR": 0.23371249219825224, "ROUGE_L": 0.2136602451838879, "CIDEr": 1.2062745748721538e-14, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.1282051282051282, "f": 0.14285714285714285, "fn": 34.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a horse grazing on the beach. The horse is white with black spots and has a red ribbon tied around its neck. The horse is standing in the sand and has its head down to eat. There are people standing on the beach in the background. The sky is blue and there are clouds"}, "181026": {"image_id": 181026, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 0.07502652544655376, "Bleu_4": 9.635230436528825e-06, "METEOR": 0.1956829216956983, "ROUGE_L": 0.2167219327333018, "CIDEr": 1.7522320090442574e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12903225806451613, "f": 0.13559322033898305, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a person skiing down a snowy slope. The person is wearing a green jacket and blue pants, and has a black helmet on their head. They are holding a pair of skis and appear to be skiing down the slope at a high speed. The snow is white and"}, "247576": {"image_id": 247576, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.09135163170376533, "Bleu_4": 0.06187801819921283, "METEOR": 0.1919272405127185, "ROUGE_L": 0.18340348767288037, "CIDEr": 7.079505055481782e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19230769230769232, "f": 0.17857142857142855, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a busy street with tall buildings on either side. There are people walking on the sidewalk and cars driving down the street. The buildings are made of stone and have tall windows and balconies. The street is lined with trees and there are cars parked on the side of the road. The"}, "413341": {"image_id": 413341, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.21004201260012265, "Bleu_3": 0.18347636436880105, "Bleu_4": 0.15844501336955027, "METEOR": 0.2591412453972539, "ROUGE_L": 0.2921655833048238, "CIDEr": 4.139448275012113e-11, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2857142857142857, "f": 0.2727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows three gummy bears sitting on top of a keyboard. The bears are made of different colors, including pink, blue, and yellow. They are arranged in a row on top of the keyboard, with their heads facing towards the left. The keyboard has a black background with white keys. The"}, "278175": {"image_id": 278175, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.11740724488886634, "Bleu_3": 0.06304863686903067, "Bleu_4": 8.253883526780069e-06, "METEOR": 0.18859748339539573, "ROUGE_L": 0.20098846787479405, "CIDEr": 5.017763844684625e-14, "SPICE": {"All": {"pr": 0.12, "re": 0.17647058823529413, "f": 0.14285714285714282, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a brown bear standing on a rocky path in the woods. The bear is looking down and appears to be sniffing the ground. The trees in the background are tall and green, and there is a small stream running through the middle of the image. The sky is blue and there are clouds in"}, "167572": {"image_id": 167572, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.22086305214437038, "Bleu_3": 0.1540881120701569, "Bleu_4": 0.11703565707209887, "METEOR": 0.2549969111193102, "ROUGE_L": 0.36166007905138337, "CIDEr": 6.137274873953991e-05, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15, "f": 0.12765957446808512, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a plate of food with a sandwich, salad, and fruit on it. The sandwich appears to be made of bread with lettuce, tomato, and cheese on it. The salad consists of mixed greens with cucumber, carrot, and cherry tomatoes."}, "467285": {"image_id": 467285, "Bleu_1": 0.3199999999936, "Bleu_2": 0.18070158057739935, "Bleu_3": 0.11080794149538384, "Bleu_4": 1.3043787072240775e-05, "METEOR": 0.22478572330462376, "ROUGE_L": 0.29647630619684084, "CIDEr": 8.456914824139105e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a baseball player in a white jersey and black pants standing at the plate, holding a bat and looking at the umpire. The umpire is wearing a black and white striped shirt and a cap, and is holding a baseball and looking at the player. The background"}, "254824": {"image_id": 254824, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.14638501093964223, "Bleu_3": 0.1256579068525738, "Bleu_4": 0.1106212078963913, "METEOR": 0.25965953811756215, "ROUGE_L": 0.2772727272727273, "CIDEr": 4.748950697887996e-13, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2631578947368421, "f": 0.20833333333333334, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image is a red brick building with a large clock tower on top. The building has several windows and a large entrance with a sign that reads \"The Grand Hotel\". There are several people standing outside the building, looking at it.\n\nThe image is a red brick building with a large clock tower on top."}, "117759": {"image_id": 117759, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.13572088082697478, "Bleu_4": 0.10155891128878049, "METEOR": 0.27056325381702523, "ROUGE_L": 0.26521739130434785, "CIDEr": 4.0104068218499254e-10, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.0967741935483871, "f": 0.09999999999999999, "fn": 28.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a woman standing in front of a mirror, holding a hair dryer. She is wearing a pink shirt and has a pink hair tie on her head. The mirror is reflecting her image. The room appears to be a bathroom, with a sink and toilet in the"}, "528011": {"image_id": 528011, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.08377724227293193, "Bleu_4": 1.063298221330347e-05, "METEOR": 0.2665978733261029, "ROUGE_L": 0.26940063091482647, "CIDEr": 2.6020865780268956e-09, "SPICE": {"All": {"pr": 0.03125, "re": 0.045454545454545456, "f": 0.037037037037037035, "fn": 21.0, "numImages": 1.0, "fp": 31.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.08333333333333333, "f": 0.08695652173913043, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a zebra walking on the dirt road. The zebra is black and white with a long mane and tail. The zebra is walking away from the camera, with its head down and ears up. The background is a grassy field with some trees in the distance."}, "404839": {"image_id": 404839, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 6.47433787030964e-07, "Bleu_4": 1.558500916173644e-09, "METEOR": 0.1383678279418541, "ROUGE_L": 0.26940063091482647, "CIDEr": 1.9769890661403121e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two people standing in a room with a table in the foreground. The woman is holding a red balloon and the man is holding a white balloon. They are both wearing pink shirts and black pants. The room has a white ceiling and a brown floor."}, "170250": {"image_id": 170250, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.20180183819497494, "Bleu_3": 0.15969209259965045, "Bleu_4": 0.1256590733027619, "METEOR": 0.22226655226587508, "ROUGE_L": 0.2610024449877751, "CIDEr": 2.2258856515675297e-11, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of giraffes standing in a field with tall trees in the background. The giraffes are brown with white spots and their long necks are bent down to eat leaves from the trees. They are standing in a line, with their heads facing the same direction. The image"}, "49688": {"image_id": 49688, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.25537695922201126, "Bleu_3": 0.19496661443068222, "Bleu_4": 0.1362575490458981, "METEOR": 0.25776440446398674, "ROUGE_L": 0.2827814569536423, "CIDEr": 1.943769476147724e-06, "SPICE": {"All": {"pr": 0.037037037037037035, "re": 0.047619047619047616, "f": 0.041666666666666664, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and a helmet, and is standing on the board with his arms outstretched. The wave is large and white, and the surfer is moving quickly through it. The"}, "496800": {"image_id": 496800, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.10457151389178666, "Bleu_4": 0.08143605172498536, "METEOR": 0.22421166719997854, "ROUGE_L": 0.21542083578575633, "CIDEr": 1.0562301051298225e-13, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.16666666666666666, "f": 0.1276595744680851, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a train on the tracks, with a city skyline in the background. The train is made up of several cars, each with a different color. The cars are parked on the tracks, with some of them having people standing on the platform. There is a bridge over the tracks, with a sign"}, "159440": {"image_id": 159440, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.20101781827408566, "Bleu_3": 0.18062393702670793, "Bleu_4": 0.1582338936289326, "METEOR": 0.22366675787656784, "ROUGE_L": 0.29865361077111385, "CIDEr": 7.926724210816968e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a person on a horse jumping over a wooden obstacle. The horse is wearing a blue and white jumpsuit and the rider is wearing a black and white jumpsuit. The background is a green field with trees in the distance.\n\nThe image is taken from a bird"}, "228914": {"image_id": 228914, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.11952367853238388, "Bleu_4": 1.3594021798767565e-05, "METEOR": 0.21429876898940325, "ROUGE_L": 0.25341246290801184, "CIDEr": 4.400221202833094e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.17857142857142858, "f": 0.18181818181818182, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of horses racing on a track. The horses are wearing jockey caps and riding on the track. There are people in the stands watching the race. The sky is clear and blue.\n\nThe image shows a group of horses racing on a track. The horses are wearing j"}, "521419": {"image_id": 521419, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.08456484271613046, "Bleu_4": 1.0435177484324181e-05, "METEOR": 0.17565222246289736, "ROUGE_L": 0.17468499427262313, "CIDEr": 1.7240544659714938e-10, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2, "f": 0.1886792452830189, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a living room with a couch, a coffee table, and a television. There are two chairs in the corner of the room, and a small table with a lamp on it. The floor is made of hardwood and there are no rugs. The walls are painted white and there are no"}, "438364": {"image_id": 438364, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.16087993330478273, "Bleu_3": 0.13822689730834656, "Bleu_4": 0.12180051043910704, "METEOR": 0.3125076395205456, "ROUGE_L": 0.33577981651376143, "CIDEr": 1.0492436190952537e-10, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.25, "f": 0.1702127659574468, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a red double decker bus driving down the street. The bus has a large sign on the front that reads \"Food for Thought\" and a smaller sign on the side that reads \"Food for Thought\". The bus is driving down the street with other cars and pedestrians in"}, "497127": {"image_id": 497127, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.18463723646567207, "Bleu_3": 0.10808321953937244, "Bleu_4": 1.2423665140816246e-05, "METEOR": 0.19985524481279943, "ROUGE_L": 0.23680124223602486, "CIDEr": 9.157240453569098e-13, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a photograph of a large building with a lot of windows and a large clock tower on top. The building is made of stone and has a lot of details on it, including columns and arches. There are also several cars parked on the street in front of the building.\n\nThe building appears to"}, "248238": {"image_id": 248238, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.1703995441436427, "Bleu_3": 0.12961821613297472, "Bleu_4": 0.08644370615425391, "METEOR": 0.2471928903703266, "ROUGE_L": 0.2663755458515284, "CIDEr": 6.948331403593341e-07, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.2962962962962963, "f": 0.3333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a hot dog with sauerkraut and mustard on a bun. The hot dog is topped with a slice of cheese and a dollop of mustard. The bun is lightly toasted and has a crispy texture. The sauerkraut is shredded"}, "85772": {"image_id": 85772, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.191273013914278, "Bleu_3": 0.12333630413179801, "Bleu_4": 1.4906383786424012e-05, "METEOR": 0.30099759891656774, "ROUGE_L": 0.3083032490974729, "CIDEr": 2.407423818294087e-06, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.16666666666666666, "f": 0.15, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a young man playing tennis on a court. He is wearing a blue shirt and black shorts, and has a tennis racket in his hand. The court is made of grass and there are trees in the background."}, "311068": {"image_id": 311068, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.07930515857033198, "Bleu_3": 4.945382002622933e-07, "Bleu_4": 1.240958731067451e-09, "METEOR": 0.126638868608862, "ROUGE_L": 0.14575866188769412, "CIDEr": 6.779680660752292e-13, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2631578947368421, "f": 0.20833333333333334, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a street with a stop sign on the corner. There are cars parked on the side of the road and a building in the background. The sky is blue and there are trees in the foreground.\n\nThe image is taken from a bird's eye view, looking down on the street."}, "310564": {"image_id": 310564, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 0.060526698984524764, "Bleu_4": 8.120218167477751e-06, "METEOR": 0.16623224570669645, "ROUGE_L": 0.2445589919816724, "CIDEr": 1.3936915013437948e-12, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.11764705882352941, "f": 0.14035087719298242, "fn": 30.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a fire hydrant on the sidewalk outside a building. The hydrant is made of metal and has a handle on top. There are no people or objects in the image. The sky is cloudy and there are no windows or doors visible. The building appears to be a restaurant or cafe,"}, "551018": {"image_id": 551018, "Bleu_1": 0.12727272727041325, "Bleu_2": 0.06865715340466512, "Bleu_3": 0.044637367313674126, "Bleu_4": 6.43091979619629e-06, "METEOR": 0.1668971132590042, "ROUGE_L": 0.16991643454038996, "CIDEr": 2.99273285716984e-13, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.15625, "f": 0.17857142857142858, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.35714285714285715, "f": 0.3703703703703704, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a busy street with several cars and buses driving by\n\nThe image shows a busy street with several cars and buses driving by. There are buildings on either side of the street, with some of them having windows and doors. The sky is cloudy and there are some trees in the background."}, "293794": {"image_id": 293794, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.08238525545556362, "Bleu_3": 0.05139367340347394, "Bleu_4": 7.254929979746852e-06, "METEOR": 0.1485814938411506, "ROUGE_L": 0.16906873614190687, "CIDEr": 2.1412084445974267e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a market with a variety of fruits and vegetables on display. There are several people walking around the market, some of whom are carrying baskets of fruit. The market appears to be in a bustling area with many people walking by.\n\nThe image shows a market with a variety"}, "497626": {"image_id": 497626, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.13453455879664997, "Bleu_3": 7.126876576918604e-07, "Bleu_4": 1.6486383890708068e-09, "METEOR": 0.1904948081411032, "ROUGE_L": 0.35427666314677936, "CIDEr": 1.563262013673779e-05, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.18518518518518517, "f": 0.19999999999999998, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image is a hotel room with a large bed, a desk, and a lamp on the nightstand. The walls are painted white and there is a window with curtains. The floor is covered in carpet and there is a chair in the corner of the room.\n\nThe room is well lit"}, "456578": {"image_id": 456578, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.27263927062982823, "Bleu_3": 0.1773152254708225, "Bleu_4": 0.10934360033350278, "METEOR": 0.31534915195510227, "ROUGE_L": 0.38364779874213834, "CIDEr": 1.1560033564109402e-05, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a woman standing in front of a small pizza oven made of wood. She is holding a plate of pizza in her hand and smiling at the camera. The background is a green field with trees in the distance."}, "474452": {"image_id": 474452, "Bleu_1": 0.404255319140335, "Bleu_2": 0.2964482941687364, "Bleu_3": 0.2137396697161003, "Bleu_4": 0.12205362467005458, "METEOR": 0.23364192081455956, "ROUGE_L": 0.2543180464562239, "CIDEr": 5.694854830354642e-07, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.19047619047619047, "f": 0.16, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a parking lot with cars parked in it. There are signs on the side of the building that say no parking at any time. The sky is clear and there are no clouds in sight. The temperature is warm and there is no wind."}, "145369": {"image_id": 145369, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.17928009705955203, "Bleu_4": 0.1480313662530794, "METEOR": 0.28462438632118714, "ROUGE_L": 0.35735207967193905, "CIDEr": 5.673193527669201e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a grassy field. They are all facing the same direction and appear to be grazing. There are several other elephants in the background, some of which are standing on the edge of the field. The sky is clear and blue.\n\nThe ele"}, "530500": {"image_id": 530500, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.08518740546037545, "Bleu_3": 5.220677531965598e-07, "Bleu_4": 1.298831014470151e-09, "METEOR": 0.2059503888680723, "ROUGE_L": 0.24469914040114613, "CIDEr": 1.7737839598223406e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a woman standing in front of a table with a laptop on it. She is wearing a purple shirt and black pants. The room is dimly lit and there are several pieces of furniture in the background, including a couch and a coffee table. The woman is holding a cup"}, "573149": {"image_id": 573149, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.19794866371815809, "Bleu_3": 0.1483569743355745, "Bleu_4": 0.09129700088701911, "METEOR": 0.17922793645389176, "ROUGE_L": 0.26228501228501233, "CIDEr": 2.702644738211247e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man and woman standing in a kitchen, preparing food on a stove. The man is wearing a white shirt and black pants, while the woman is wearing a black shirt and white pants. They are both holding pizza dough and rolling it out on a cutting"}, "65465": {"image_id": 65465, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.17251638983203116, "Bleu_3": 0.1363141538186681, "Bleu_4": 0.11336958836408242, "METEOR": 0.2542645789321419, "ROUGE_L": 0.28222075346992725, "CIDEr": 5.314016816110469e-10, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.34782608695652173, "f": 0.31999999999999995, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of elephants standing in a field with their babies. The elephants are all different sizes and colors, with some having spots and others not. They are all standing in a line, with their trunks curled up and their ears flapping in the wind. The"}, "542024": {"image_id": 542024, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.17039568890752202, "Bleu_3": 0.1051136375718304, "Bleu_4": 1.2407814132465894e-05, "METEOR": 0.22331559823236832, "ROUGE_L": 0.22536945812807885, "CIDEr": 2.9006964131024217e-11, "SPICE": {"All": {"pr": 0.02702702702702703, "re": 0.05, "f": 0.03508771929824561, "fn": 19.0, "numImages": 1.0, "fp": 36.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.14285714285714285, "f": 0.09523809523809523, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "The image shows a baseball player hitting a ball with a bat. The player is wearing a white jersey with the number 2 on the back and a blue cap with the letters \"B\" and \"R\" on it. The player is standing on the plate and swinging the bat in a downward"}, "31345": {"image_id": 31345, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.10484363678213089, "Bleu_4": 0.06999971125156287, "METEOR": 0.29096617722637425, "ROUGE_L": 0.26704190118824267, "CIDEr": 1.9919144001693217e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The cat is laying on the couch with its paws up in the air. It appears to be sleeping or relaxing. The couch is covered in a patterned fabric, and there is a remote control on the floor next to the cat. The room is dimly lit, and there are no"}, "33131": {"image_id": 33131, "Bleu_1": 0.1296296296272291, "Bleu_2": 0.08565936145673987, "Bleu_3": 5.206135179390748e-07, "Bleu_4": 1.2897158477492774e-09, "METEOR": 0.15000835982546867, "ROUGE_L": 0.1821983273596177, "CIDEr": 3.2280220132455593e-13, "SPICE": {"All": {"pr": 0.1, "re": 0.21428571428571427, "f": 0.13636363636363638, "fn": 11.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a silver cell phone on a white surface. The phone has a small screen and a keypad on the front. There is a small stylus on the side of the phone. The phone is lying on its side and appears to be turned off.\n\nThe image is taken in a kitchen."}, "338108": {"image_id": 338108, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.16606082435802713, "Bleu_3": 8.146819001060783e-07, "Bleu_4": 1.813420619820594e-09, "METEOR": 0.18622174205554207, "ROUGE_L": 0.2633567188343227, "CIDEr": 2.56005634515157e-08, "SPICE": {"All": {"pr": 0.08, "re": 0.06896551724137931, "f": 0.07407407407407408, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man in a black jacket and ski goggles standing on a snowy slope. He is holding a ski pole in one hand and has a ski helmet on his head. There are several other people in the background, some of whom are also wearing ski gear and standing on"}, "313034": {"image_id": 313034, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.2399494896298897, "Bleu_3": 0.12951833785876507, "Bleu_4": 1.4297088676759185e-05, "METEOR": 0.2551537768643271, "ROUGE_L": 0.3288409703504044, "CIDEr": 4.10542237662076e-10, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09090909090909091, "f": 0.08163265306122448, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man and a woman standing in a room. The man is holding a plate of food and the woman is holding a plate of food. They are both smiling and looking at each other. The room is decorated with a Christmas tree and some decorations on the walls.\n\nThe man is"}, "534394": {"image_id": 534394, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.13957263155725563, "Bleu_3": 7.118725684669195e-07, "Bleu_4": 1.615223877663139e-09, "METEOR": 0.19710205145269147, "ROUGE_L": 0.2096700274977085, "CIDEr": 7.500405564342562e-12, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a flock of sheep standing in a field next to a road. The sheep are grazing on the grass and seem to be enjoying themselves. The sky is clear and blue, and there are no other cars or people in sight. The trees in the background are tall and green, and the road"}, "208589": {"image_id": 208589, "Bleu_1": 0.13725490195809306, "Bleu_2": 0.09074852129550587, "Bleu_3": 5.518584262016769e-07, "Bleu_4": 1.3679192122845403e-09, "METEOR": 0.13675844327643116, "ROUGE_L": 0.18654434250764526, "CIDEr": 1.7460506947138557e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.34782608695652173, "f": 0.3404255319148936, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a blackbird sitting in a birdbath with a worm in its beak. The bird is surrounded by potted plants and a pile of leaves. The background is a wooden fence with a gate in the center. The sky is cloudy with a few birds flying in the distance."}, "542510": {"image_id": 542510, "Bleu_1": 0.16363636363338846, "Bleu_2": 0.1100963765106158, "Bleu_3": 0.061153792306271486, "Bleu_4": 8.143605172498537e-06, "METEOR": 0.1629135986484734, "ROUGE_L": 0.23168746608790014, "CIDEr": 1.9453132322345485e-12, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.5384615384615384, "f": 0.3888888888888889, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 1.0, "f": 0.6153846153846153, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man pushing a cart with a large box on it through a field. The man is wearing a black shirt and pants, and has a baseball cap on his head. The cart has a white top and wheels, and the box is made of wood and has a handle on top."}, "421307": {"image_id": 421307, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.13469311460752553, "Bleu_3": 0.08927233005016631, "Bleu_4": 1.0921823440882955e-05, "METEOR": 0.21627983956202854, "ROUGE_L": 0.18908865468071917, "CIDEr": 2.809430504825899e-12, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.25, "f": 0.18604651162790697, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows two kites flying in the sky with red and black stripes. The kites are flying in the direction of the sun. The sky is blue and there are clouds in the background.\n\nThe kites are made of lightweight materials and are designed to fly in the wind. They are attached"}, "343680": {"image_id": 343680, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.25900956329042873, "Bleu_3": 0.17280756432599467, "Bleu_4": 0.1192715921391621, "METEOR": 0.2554230005017973, "ROUGE_L": 0.3355335533553355, "CIDEr": 3.662218115178101e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.0967741935483871, "f": 0.10526315789473684, "fn": 28.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a small pug dog sitting on top of a table with its paws on the edge of the table\n\nThe dog is looking down at something on the table. The table has a book on it. There is a lamp on the table. The dog is wearing a collar and tag."}, "262119": {"image_id": 262119, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1666666666629209, "Bleu_3": 0.10891466159390667, "Bleu_4": 1.3243489672957344e-05, "METEOR": 0.15415021981264315, "ROUGE_L": 0.2350674373795761, "CIDEr": 1.1973445052576695e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.1724137931034483, "f": 0.1851851851851852, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a skateboarder performing a trick on a skateboard ramp in a park. The skateboarder is wearing a black shirt and jeans, and has a backpack on his back. The ramp is made of concrete and has a metal railing around it. There"}, "155125": {"image_id": 155125, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.2084219669570065, "Bleu_3": 0.1557386407653264, "Bleu_4": 0.1138286684235099, "METEOR": 0.26782876266089084, "ROUGE_L": 0.29901960784313725, "CIDEr": 7.776343506160988e-09, "SPICE": {"All": {"pr": 0.09375, "re": 0.15, "f": 0.11538461538461538, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The man is sitting at a table in a restaurant, eating a slice of pizza. He is wearing a black shirt and jeans, and has a serious expression on his face. The restaurant appears to be a casual, family-friendly establishment, with tables and chairs arranged in a simple"}, "92173": {"image_id": 92173, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.21381869073854032, "Bleu_3": 0.17520942675548123, "Bleu_4": 0.13403120253766126, "METEOR": 0.22699563284810603, "ROUGE_L": 0.27453186530579443, "CIDEr": 8.490042154564136e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.3157894736842105, "f": 0.24489795918367346, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a black and white cat lying on a table next to a laptop and a notebook. The cat is wearing a collar and has a tag on its neck. The table has a notebook and a laptop on it. There is a window in the background with blinds on it."}, "578092": {"image_id": 578092, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.11536522398785581, "Bleu_3": 6.194229136940919e-07, "Bleu_4": 1.441782592356079e-09, "METEOR": 0.1557247335444531, "ROUGE_L": 0.1908237747653806, "CIDEr": 1.2863286191201225e-14, "SPICE": {"All": {"pr": 0.125, "re": 0.15789473684210525, "f": 0.13953488372093023, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a street with a house on the left side and a car parked on the right side. The house has a red door and a white roof. The car has a black hood and a white body. There are no other cars or people in the image. The sky is blue and there are no"}, "204432": {"image_id": 204432, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.13609999140195853, "Bleu_4": 0.08513012360711482, "METEOR": 0.22074592853406574, "ROUGE_L": 0.3117546848381601, "CIDEr": 9.627779606238169e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a man and woman sitting on a bench outside a building. They are both wearing sunglasses and smiling at the camera. The woman is holding a sandwich in her hand and the man is holding a drink. There is graffiti on the walls of the building behind them."}, "167647": {"image_id": 167647, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.21764287502183505, "Bleu_3": 1.3806135595106663e-06, "Bleu_4": 3.527295712509229e-09, "METEOR": 0.14307101083237977, "ROUGE_L": 0.3519230769230769, "CIDEr": 0.12048569447940236, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.0625, "f": 0.07407407407407407, "fn": 30.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a pizza with various toppings on it. There is a plate on the table next to it."}, "268484": {"image_id": 268484, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.17188791273498485, "Bleu_3": 0.13985853457714958, "Bleu_4": 0.08476133000336279, "METEOR": 0.22110946828844508, "ROUGE_L": 0.25296208530805686, "CIDEr": 2.0757926323471336e-12, "SPICE": {"All": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a large crowd of people in a park, with kites flying in the sky. The sky is clear and blue, with a few clouds scattered about. The trees in the background are green and lush, and the buildings in the distance are tall and modern. The people in the image are dressed in"}, "251798": {"image_id": 251798, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.08435451529716312, "Bleu_4": 1.057477026987749e-05, "METEOR": 0.20114381788018879, "ROUGE_L": 0.21997836278398844, "CIDEr": 9.441369591878071e-11, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.20833333333333334, "f": 0.18867924528301888, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young man standing in front of a closet with clothes hanging on the wall. The man is wearing a white shirt and blue jeans, and he is holding a hanger in his hand. The closet has a shelf on top of it, and there are clothes hanging"}, "502311": {"image_id": 502311, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.1347912565777208, "Bleu_4": 0.10103674020452826, "METEOR": 0.19364669851661362, "ROUGE_L": 0.18944099378881987, "CIDEr": 8.280696140844443e-10, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.3181818181818182, "f": 0.31111111111111117, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a giraffe standing in a fenced enclosure with a baby giraffe standing next to it. The giraffe is brown with a white patch on its forehead and a long neck. The baby giraffe is brown with a white patch on its forehead and a shorter neck than"}, "322858": {"image_id": 322858, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.06185895741189865, "Bleu_3": 4.3341351003500945e-07, "Bleu_4": 1.1534197288455865e-09, "METEOR": 0.1612320683526544, "ROUGE_L": 0.15752098127824402, "CIDEr": 8.864436412347804e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.16666666666666666, "f": 0.13953488372093023, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a field with a small pond in the background. The elephants are standing on the ground and appear to be drinking from the pond. There are trees in the background and a fence surrounding the field.\n\nThe elephants are brown"}, "475678": {"image_id": 475678, "Bleu_1": 0.23529411764244526, "Bleu_2": 2.1693045781436012e-09, "Bleu_3": 4.579467647238886e-12, "Bleu_4": 2.1149540539754974e-13, "METEOR": 0.1651709413341377, "ROUGE_L": 0.14294083186877565, "CIDEr": 1.945287801919765e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.13636363636363635, "f": 0.11538461538461538, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of suitcases stacked on top of each other in a room. There are several different colors of suitcases, including black, blue, and red. The suitcases are all different sizes and shapes, with some having wheels and others not. There are also several different types of lugg"}, "297078": {"image_id": 297078, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.10635890745081387, "Bleu_3": 6.093393760732184e-07, "Bleu_4": 1.465869850942177e-09, "METEOR": 0.23476393403280219, "ROUGE_L": 0.18373493975903615, "CIDEr": 1.0558031063241503e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person skiing down a snowy slope. The person is wearing a black and red jacket, black pants, and black ski boots. The person is holding a black ski pole in their right hand and has a black ski helmet on their head. The snow is covered in trees"}, "247999": {"image_id": 247999, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 7.913235571850137e-07, "Bleu_4": 1.7569715736518148e-09, "METEOR": 0.16366412213740458, "ROUGE_L": 0.207506520013607, "CIDEr": 1.4842613508680757e-12, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person on a jet ski performing a trick on the water. The person is wearing a life jacket and has their arms outstretched as they jump off the back of the jet ski. The water is choppy and there are some waves in the background. The sky is blue and there"}, "194875": {"image_id": 194875, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.17205295744403565, "Bleu_3": 8.697022430943884e-07, "Bleu_4": 1.9663678889647942e-09, "METEOR": 0.20366997954520205, "ROUGE_L": 0.20847573479152426, "CIDEr": 1.8277204544497568e-07, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.23809523809523808, "f": 0.21276595744680848, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting at a table outside a bar. They are all wearing motorcycle helmets and some of them are holding drinks. There are several motorcycles parked nearby, some of which are also decorated with stickers and decals. The atmosphere is lively"}, "506656": {"image_id": 506656, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 7.176233678698055e-07, "Bleu_4": 1.6407026708745589e-09, "METEOR": 0.2341873887024762, "ROUGE_L": 0.25507765830346474, "CIDEr": 2.009245827742712e-11, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.2692307692307692, "f": 0.28571428571428575, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of horses pulling a carriage down the street. The horses are wearing harnesses and are being led by a man in a black suit and hat. The carriage is decorated with red and white ribbons and has a large red bow on the front. The street is lined with"}, "255529": {"image_id": 255529, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.0953462589224164, "Bleu_3": 5.957256316301674e-07, "Bleu_4": 1.4978640318582358e-09, "METEOR": 0.16599940025922585, "ROUGE_L": 0.24646464646464644, "CIDEr": 5.84002435954313e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a table with a variety of donuts on it. There are several different types of donuts, including chocolate frosted, sprinkles, and glazed. The table is covered with a red and white checkered tablecloth. There are several people standing around the table, eating"}, "314426": {"image_id": 314426, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.21148042285421853, "Bleu_3": 0.11981807301850095, "Bleu_4": 1.3551869285792872e-05, "METEOR": 0.16835867928627443, "ROUGE_L": 0.21403508771929822, "CIDEr": 5.585731426343106e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.2608695652173913, "f": 0.22641509433962265, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows the Houses of Parliament in London, England. The building is a large, imposing structure with a clock tower in the center. The clock tower is adorned with a large clock face and a flag flying from the top. The building is surrounded by a large, open space with trees and buildings"}, "79955": {"image_id": 79955, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.05825517280241507, "Bleu_3": 4.0791185612592327e-07, "Bleu_4": 1.0848650703059749e-09, "METEOR": 0.13039199667038662, "ROUGE_L": 0.16052631578947368, "CIDEr": 4.80934622857932e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.12, "f": 0.12, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a highway with several cars driving on it. The cars are traveling in both directions on the highway. There are no pedestrians or bicycles on the road. The highway is surrounded by trees and a fence. The sky is clear and there are no clouds in the sky. The"}, "424721": {"image_id": 424721, "Bleu_1": 0.15999999999680004, "Bleu_2": 0.12777531299740644, "Bleu_3": 0.08794832144810151, "Bleu_4": 1.0968473790380012e-05, "METEOR": 0.1980906938483809, "ROUGE_L": 0.22938079719227877, "CIDEr": 6.022612994931127e-11, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.18181818181818182, "f": 0.21621621621621623, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a metal pan with carrots, potatoes, and a roasting chicken in it. The pan is on a stove top. There is a wooden cutting board next to the pan. The cutting board has a knife and a cutting board on it. The room is well lit and"}, "233315": {"image_id": 233315, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1177966073469684, "Bleu_3": 6.755917700609673e-07, "Bleu_4": 1.6270469822163273e-09, "METEOR": 0.0743691899070385, "ROUGE_L": 0.158957654723127, "CIDEr": 1.3220677657328481e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14814814814814814, "f": 0.1509433962264151, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two children standing in a kitchen, one of them pouring a liquid into a bowl while the other watches. The kitchen has a white countertop and a stove in the background. The children are wearing black shirts and white pants.\n\nThe image is well-lit"}, "526044": {"image_id": 526044, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.2201927530212316, "Bleu_3": 0.15409790041514113, "Bleu_4": 0.12053884309481194, "METEOR": 0.315597875228292, "ROUGE_L": 0.2872277810476751, "CIDEr": 1.7567812842516318e-13, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.05, "f": 0.06451612903225806, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a brown and white cow standing on the beach next to a body of water. The cow is looking out at the water with its head tilted to the side. The sky is cloudy and there are some trees in the background.\n\nThe image is in black and white, with the cow"}, "383826": {"image_id": 383826, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.15041420939612582, "Bleu_3": 7.677195064444563e-07, "Bleu_4": 1.7432228564084153e-09, "METEOR": 0.16277862049264918, "ROUGE_L": 0.22048192771084338, "CIDEr": 4.8568708500796136e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.08108108108108109, "f": 0.09523809523809523, "fn": 34.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.07142857142857142, "f": 0.08, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.15384615384615385, "f": 0.15384615384615385, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people surfing on the ocean. They are standing on their surfboards and paddling through the waves. The sky is clear and blue, with a few clouds scattered across it. The water is calm and the waves are small. The beach is sandy and there are some"}, "14248": {"image_id": 14248, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.2179708976339486, "Bleu_3": 0.1417912480658796, "Bleu_4": 1.553059336992734e-05, "METEOR": 0.27581878183943587, "ROUGE_L": 0.29397590361445786, "CIDEr": 1.837136967658462e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a young girl lying in bed with a stuffed animal. She is wearing a green sweater and has a stuffed monkey on her lap. The bed is covered in a colorful quilt and there are pillows on either side of her. The room is dimly lit and there are"}, "39951": {"image_id": 39951, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1295047816452144, "Bleu_3": 6.857872734978661e-07, "Bleu_4": 1.5858040477395045e-09, "METEOR": 0.20419608932825137, "ROUGE_L": 0.1821983273596177, "CIDEr": 1.590129260183875e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. The man is wearing a white shirt and black shorts, and he is holding a tennis racket in his right hand. The ball is flying through the air as he swings his racket to hit it. The image"}, "437564": {"image_id": 437564, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1501878522938693, "Bleu_3": 0.09360785780695649, "Bleu_4": 1.1101605489146436e-05, "METEOR": 0.17315319888021835, "ROUGE_L": 0.25779186476492344, "CIDEr": 3.852342331469745e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a laptop computer on a bed with a mouse and keyboard on the desk next to it. There is a camera on the bed and a lamp on the nightstand. The walls are painted a light blue color and there is a window in the background.\n\nThe laptop is a black and silver color"}, "38666": {"image_id": 38666, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.10238251947041137, "Bleu_3": 0.05863398711091721, "Bleu_4": 7.929020238697525e-06, "METEOR": 0.18682138896602568, "ROUGE_L": 0.21403508771929822, "CIDEr": 1.9664526164358815e-12, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.10526315789473684, "f": 0.07999999999999999, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.2857142857142857, "f": 0.18181818181818182, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a young boy sitting on the ground with a stuffed bear in his arms. The boy is wearing a blue shirt and black pants, and has a backpack on his back. The bear is brown and has a red collar. The image is taken in a park with trees and grass"}, "532463": {"image_id": 532463, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.10714285714064781, "Bleu_3": 6.250904486134178e-07, "Bleu_4": 1.5179857311603866e-09, "METEOR": 0.23531964249223938, "ROUGE_L": 0.19690122659780504, "CIDEr": 5.017599763038058e-11, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a bench with several bags on it. The bags are made of different materials, such as canvas, nylon, and leather. They are of different sizes and shapes, and some of them have handles. The bench is made of wood and has a blue and white striped"}, "222811": {"image_id": 222811, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.12712834523041283, "Bleu_3": 6.730845772977349e-07, "Bleu_4": 1.5561497729243848e-09, "METEOR": 0.21746461736527553, "ROUGE_L": 0.21542083578575633, "CIDEr": 1.2999311949278165e-13, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2777777777777778, "f": 0.22222222222222224, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a staircase leading up to a window on the second floor of a building. The stairs are made of wood and have a railing on either side. The window is large and has a view of the street outside. There is a bench in front of the window. The room is dim"}, "393093": {"image_id": 393093, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.12483755678422238, "Bleu_3": 0.06608439529502602, "Bleu_4": 8.590238521223447e-06, "METEOR": 0.1690782144835083, "ROUGE_L": 0.21229698375870068, "CIDEr": 1.6240817980679244e-14, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2727272727272727, "f": 0.24489795918367346, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a train passing under a bridge in a city. The train is green and white, and has a number on the side. The bridge is made of concrete and has a metal railing. There are buildings on either side of the bridge, and a sign on one of them reads 'train station'. The"}, "312343": {"image_id": 312343, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.20603150145092247, "Bleu_3": 0.15236855057487514, "Bleu_4": 0.09314231711296979, "METEOR": 0.31183182683950034, "ROUGE_L": 0.34099378881987574, "CIDEr": 4.215914134064418e-09, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 25.0, "numImages": 1.0, "fp": 28.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}}, "caption": "The image shows a red fire hydrant on the side of the road. The hydrant is spraying water into the air, creating a rainbow effect. There are cars parked on the side of the road and buildings in the background. The sky is clear and sunny.\n\nThe image is taken"}, "485452": {"image_id": 485452, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.18890811128268284, "Bleu_3": 0.12976038602389878, "Bleu_4": 0.08213840916378097, "METEOR": 0.2715032363285287, "ROUGE_L": 0.3216168717047452, "CIDEr": 2.1567984890097292e-10, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.05, "f": 0.046511627906976744, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are painted blue and white stripes. There is a window on the left side of the room with a view of the outside. The floor is made of hardwood and the cabinets are made of wood. The to"}, "166664": {"image_id": 166664, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 7.963639705150248e-07, "Bleu_4": 1.756971573652418e-09, "METEOR": 0.2377582579582158, "ROUGE_L": 0.2401574803149606, "CIDEr": 2.7819759118115316e-12, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2916666666666667, "f": 0.27999999999999997, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a large elephant standing on the side of a road next to a car. The elephant is looking down at the car and appears to be curious about it. The car is parked on the side of the road and appears to be empty. The sky is clear and there are no other"}, "569096": {"image_id": 569096, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.11216649288903491, "Bleu_4": 1.323451095652116e-05, "METEOR": 0.21433973030617276, "ROUGE_L": 0.19690122659780504, "CIDEr": 6.884090884416425e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows an elephant standing in a field of tall grass. The elephant is brown with a large tusk on its front. The elephant is walking away from the camera, its trunk curled up and its ears flapping in the wind. The sky is clear and blue, with"}, "15862": {"image_id": 15862, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.10219406022809462, "Bleu_4": 0.06730826637311355, "METEOR": 0.2358955636188278, "ROUGE_L": 0.27555053642010163, "CIDEr": 1.186563822890931e-12, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2857142857142857, "f": 0.24242424242424243, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a red fire hydrant on the sidewalk in front of a building. The hydrant is made of metal and has a large handle on top. There are no other objects in the image.\n\nThe image is taken in a city setting with tall buildings and trees in the background. The sky is"}, "496571": {"image_id": 496571, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.19010380264692892, "Bleu_3": 0.11542624882932234, "Bleu_4": 0.07603945204244975, "METEOR": 0.20878944498301671, "ROUGE_L": 0.22679390259015986, "CIDEr": 5.831263007865091e-07, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1111111111111111, "f": 0.10909090909090909, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a table with a white tablecloth, a plate of food, and two glasses of water. There are two people sitting at the table, one man and one woman, both wearing black shirts and black pants. The woman is holding a fork and knife, while the man"}, "258541": {"image_id": 258541, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.23329531792993197, "Bleu_3": 0.14738536958247936, "Bleu_4": 0.08945369410433845, "METEOR": 0.25075243158370175, "ROUGE_L": 0.3124644280022766, "CIDEr": 2.339613787878276e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.13043478260869565, "f": 0.12499999999999997, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The man in the image is wearing a white shirt and orange tie. He is standing in front of a large window with a view of the city. There are several chairs and tables in the room, and a large mirror on the wall. The man is smiling and looking at the camera."}, "560474": {"image_id": 560474, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 8.587253589737383e-07, "Bleu_4": 1.926199466506815e-09, "METEOR": 0.16936052728721696, "ROUGE_L": 0.2208811104405552, "CIDEr": 1.920207357686429e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.2608695652173913, "f": 0.22641509433962265, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a car with a large number of candy canes attached to the front of it. The car is parked in front of a blue tent with a sign that reads, \"Candy Cane Carnival.\" There are people standing around the car, looking at it.\n\nThe image is"}, "145665": {"image_id": 145665, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.19802950859148932, "Bleu_3": 0.15769573216073673, "Bleu_4": 0.11247951467489567, "METEOR": 0.2779822104115346, "ROUGE_L": 0.330722891566265, "CIDEr": 2.7391610198280173e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.17647058823529413, "f": 0.14285714285714282, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man lying on his back on the ground in front of a parking lot. He is wearing a black shirt and jeans, and has his arms and legs stretched out in front of him. There is a skateboard next to him, and a tree in the background. The"}, "371042": {"image_id": 371042, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.09792829216201589, "Bleu_4": 0.07828816852535843, "METEOR": 0.2083839449020549, "ROUGE_L": 0.226906385616863, "CIDEr": 5.908315739815729e-12, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13636363636363635, "f": 0.11320754716981131, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.3333333333333333, "f": 0.19047619047619044, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a group of people playing tennis on a court. They are wearing tennis shoes and holding rackets. The court is surrounded by a green fence and there are trees in the background.\n\nThe image is in black and white and the people are in the foreground. The court is in"}, "119113": {"image_id": 119113, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.2504897164290992, "Bleu_3": 0.1856883150846676, "Bleu_4": 0.14143550190666943, "METEOR": 0.29782350207397557, "ROUGE_L": 0.32455029136052693, "CIDEr": 1.1316260430034929e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 9.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a large, brick building with a clock tower on top. The building has a large, open courtyard in front of it, with trees and benches. There are several cars parked on the street in front of the building. The sky is clear and blue.\n\nThe building is the"}, "166731": {"image_id": 166731, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.0951302988290515, "Bleu_3": 5.656605687724057e-07, "Bleu_4": 1.3863341114193003e-09, "METEOR": 0.1566802860073338, "ROUGE_L": 0.14489311163895485, "CIDEr": 3.536320881885191e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a street with a few cars parked on it. There are several political signs on the sidewalk, including one that reads, \"Vote for the candidate you trust.\"\n\nThe sky is blue and there are some trees in the background. The image is taken from a bird's eye view"}, "450313": {"image_id": 450313, "Bleu_1": 0.33928571427965565, "Bleu_2": 0.2356257212561474, "Bleu_3": 0.12716293502632556, "Bleu_4": 0.07892261016858565, "METEOR": 0.20106647732958272, "ROUGE_L": 0.27354260089686094, "CIDEr": 3.268962960590888e-10, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.1111111111111111, "f": 0.08333333333333334, "fn": 16.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a yellow bus driving down a city street. The bus has a large advertisement on the side that reads, \"The bus is the best way to get around the city.\" The bus is driving through a busy city street with tall buildings on either side. There are people walking on the sidewalk and"}, "166060": {"image_id": 166060, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.09983569293155374, "Bleu_4": 0.06819851521727724, "METEOR": 0.20898557450214789, "ROUGE_L": 0.236281471917366, "CIDEr": 1.0033001376007757e-08, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.21052631578947367, "f": 0.163265306122449, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing in a circus tent with people watching it. The giraffe is wearing a red and white striped shirt and a blue hat. The people are wearing various colors of clothing and are standing in front of the giraffe. The tent is made of"}, "361265": {"image_id": 361265, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.11704480209465776, "Bleu_4": 0.07769640590855424, "METEOR": 0.24800375482087134, "ROUGE_L": 0.29186602870813394, "CIDEr": 4.077042775820385e-09, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13636363636363635, "f": 0.11320754716981131, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a woman standing in the middle of a cobblestone street, holding an umbrella over her head. She is wearing a pink and black striped sweater, black pants, and white sneakers. The buildings on either side of the street are made of brick and have"}, "465735": {"image_id": 465735, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.23431167444696221, "Bleu_3": 0.18873292695514476, "Bleu_4": 0.12936981168123382, "METEOR": 0.21843187776662584, "ROUGE_L": 0.3042123074182919, "CIDEr": 3.3958540766425545e-10, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a large airplane parked on the tarmac at an airport. The plane has a large logo on the side of it and is painted in a white and black color scheme. There are several other airplanes parked nearby, and the airport is surrounded by buildings and other structures."}, "540925": {"image_id": 540925, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.24943374785244946, "Bleu_3": 0.1954476967373084, "Bleu_4": 0.15712268625759354, "METEOR": 0.22401185527389392, "ROUGE_L": 0.2897862232779097, "CIDEr": 4.4974874301028296e-11, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.17391304347826086, "f": 0.14035087719298242, "fn": 19.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing in a field with trees in the background\n\nThe giraffe is standing on the grass with its head up and its long neck stretched out. It is wearing a brown and white patterned coat with a long mane on its neck. The trees in the background"}, "160233": {"image_id": 160233, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.17902871850638163, "Bleu_3": 0.10863467408253681, "Bleu_4": 0.0715199709377467, "METEOR": 0.22786497978824877, "ROUGE_L": 0.26293103448275856, "CIDEr": 2.6634945115498816e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a busy street with tall buildings on either side. There are several cars parked on the side of the road, and people are walking on the sidewalk. The sky is cloudy and there is a light drizzle.\n\nThe image is taken from a high angle, looking down on the"}, "357941": {"image_id": 357941, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.2307304479757116, "Bleu_3": 0.18809327886505683, "Bleu_4": 0.1568309548408512, "METEOR": 0.2676895908294461, "ROUGE_L": 0.3277052954719877, "CIDEr": 6.129908791220725e-12, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black and white cat sitting on top of a red blanket in front of a television. The cat has green eyes and is looking directly at the camera. The television is playing a movie with a woman's face on it. The room is dimly lit and there are several other objects in the"}, "159240": {"image_id": 159240, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.210132920205885, "Bleu_3": 0.13486685460653283, "Bleu_4": 1.466763027702615e-05, "METEOR": 0.20975797527265141, "ROUGE_L": 0.26124197002141325, "CIDEr": 5.296825652817419e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.2777777777777778, "f": 0.23255813953488372, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a living room with a couch, chair, and television. The walls are painted orange and there is a window on the left side of the room. The floor is made of hardwood and there is a rug in the middle of the room. The room is well lit and there are no curtain"}, "394659": {"image_id": 394659, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.11656242933815306, "Bleu_4": 1.3408182811888846e-05, "METEOR": 0.22805587725755094, "ROUGE_L": 0.2760180995475113, "CIDEr": 5.880440223936887e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.14814814814814814, "f": 0.14035087719298248, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a blue and white tiled floor, a stove, and a sink. There are wooden cabinets above the sink and a wooden countertop with a blue and white tiled backsplash. The walls are painted white and there is a window on the left side of the room."}, "294228": {"image_id": 294228, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.07457725404314713, "Bleu_4": 9.591924934151242e-06, "METEOR": 0.24868971785543503, "ROUGE_L": 0.2167219327333018, "CIDEr": 2.7031244512855054e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.11538461538461539, "f": 0.13043478260869565, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of children playing in a field with a kite flying in the sky. The children are wearing colorful clothing and are running around the field. The kite is made of brightly colored fabric and has a long tail. The sky is clear and blue.\n\nThe image is"}, "273059": {"image_id": 273059, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.1308640594505956, "Bleu_4": 1.455032821874003e-05, "METEOR": 0.19590403472415088, "ROUGE_L": 0.21721068249258166, "CIDEr": 6.699530070517551e-12, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2916666666666667, "f": 0.2916666666666667, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2222222222222222, "f": 0.3636363636363636, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of men playing a game of flag football on a grass field. They are wearing black and white jerseys and black pants, and are running and throwing the ball around the field. There are trees and a sky in the background.\n\nThe image is in color and has"}, "489613": {"image_id": 489613, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.128337789581408, "Bleu_3": 6.952980477333491e-07, "Bleu_4": 1.626739259997693e-09, "METEOR": 0.16944100405966778, "ROUGE_L": 0.22584228063680117, "CIDEr": 3.965136354890526e-09, "SPICE": {"All": {"pr": 0.03125, "re": 0.029411764705882353, "f": 0.030303030303030304, "fn": 33.0, "numImages": 1.0, "fp": 31.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.07142857142857142, "f": 0.07692307692307691, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are painted white and there are no windows. The floor is covered in brown carpet and there is a small table with a lamp on it.\n\nThe image is taken in a room with a white wall, brown"}, "263202": {"image_id": 263202, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 6.912848008424654e-07, "Bleu_4": 1.5876030342373218e-09, "METEOR": 0.24397780094289373, "ROUGE_L": 0.207506520013607, "CIDEr": 1.3410034609810185e-12, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.047619047619047616, "f": 0.044444444444444446, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a woman sitting in a chair, holding a cell phone to her ear. She is wearing a red shirt and has a look of concentration on her face. The background is a group of people standing in a room, looking at something on a screen.\n\nThe image is taken from a book"}, "160330": {"image_id": 160330, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.19154015512649578, "Bleu_3": 0.08902365931905547, "Bleu_4": 1.0845174330682731e-05, "METEOR": 0.2311284680490164, "ROUGE_L": 0.20962199312714777, "CIDEr": 3.0507769104948608e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.29411764705882354, "f": 0.21276595744680848, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a laptop computer with a keyboard and mouse on a table. The laptop has a screen with a website open on it. There is a person sitting in a chair in front of the laptop, looking at the screen. The person is wearing a t-shirt and shorts. The room is dim"}, "503081": {"image_id": 503081, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.10132945277550723, "Bleu_4": 0.06823252823824055, "METEOR": 0.20545802890052822, "ROUGE_L": 0.25553560742070613, "CIDEr": 5.48580527775298e-10, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.21428571428571427, "f": 0.13333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a large, open space with a high ceiling and a lot of windows. There are several escalators leading up to the second floor, and a large clock on the wall. There are also several shops and restaurants in the area. The overall atmosphere is very modern and sleek."}, "238355": {"image_id": 238355, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.0958411776672495, "Bleu_4": 0.06544158309931196, "METEOR": 0.14976744186046512, "ROUGE_L": 0.22584228063680117, "CIDEr": 3.83388514144058e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2608695652173913, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 1.0, "f": 0.18181818181818182, "fn": 0.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a bathroom with a sink, toilet, and shower. The walls are made of white tiles and there is a window with blinds. The floor is made of wood and there is a rug in the corner. The bathroom has a wooden door and a wooden countertop with a"}, "270096": {"image_id": 270096, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.1412673303879691, "Bleu_3": 0.0731427188861825, "Bleu_4": 9.405585246221825e-06, "METEOR": 0.17605989572510003, "ROUGE_L": 0.25707405177603854, "CIDEr": 6.163365956182877e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a desk with a computer, phone, and other office supplies. There is a whiteboard on the wall with a message written on it.\n\nThe room is well lit and has a window with a view of the outside. There are two chairs in front of the desk and a small"}, "312306": {"image_id": 312306, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.1184508853673932, "Bleu_3": 0.06683330244266764, "Bleu_4": 8.975429359940367e-06, "METEOR": 0.15345476470158093, "ROUGE_L": 0.19690122659780504, "CIDEr": 9.764242862451003e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a green field with trees in the background. There are several animals grazing in the field, including cows and sheep. The sky is blue and there are clouds in the distance. The image is taken from a bird's eye view, looking down on the field."}, "224093": {"image_id": 224093, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.13997719075795917, "Bleu_3": 0.11539884283203243, "Bleu_4": 0.0744575238640195, "METEOR": 0.20959717936931294, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.5601207164608958e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image is a black and white photograph of a herd of cows grazing in a field. The cows are standing in a line, with their heads down and their tails swishing back and forth. The sky is cloudy and there are trees in the background. The image is taken from a distance"}, "558717": {"image_id": 558717, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.23121228231834207, "Bleu_3": 0.16021117897522516, "Bleu_4": 0.0947604399191132, "METEOR": 0.23480119696503055, "ROUGE_L": 0.26666666666666666, "CIDEr": 4.334440873142298e-11, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2222222222222222, "f": 0.2142857142857143, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on a beach with a small child standing in the sand. The people are wearing casual clothing and the child is wearing a yellow sundress. The beach is covered in sand and there are some rocks in the background. The sky is cloudy and there are"}, "40361": {"image_id": 40361, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1177966073469684, "Bleu_3": 0.0675591770060967, "Bleu_4": 9.14955756126488e-06, "METEOR": 0.17823331839414802, "ROUGE_L": 0.19869706840390877, "CIDEr": 1.6643956407222623e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a baseball player in a batting stance, holding a bat and wearing a helmet\n\nThe player is wearing a black and orange jersey with the number 23 on the back. The player is also wearing black pants and black cleats. The player is standing"}, "300121": {"image_id": 300121, "Bleu_1": 0.16071428571141586, "Bleu_2": 0.120873444601629, "Bleu_3": 0.09328169537915308, "Bleu_4": 0.06255735178585906, "METEOR": 0.18729635212758547, "ROUGE_L": 0.18068720379146921, "CIDEr": 1.9733567234955518e-14, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.2962962962962963, "f": 0.31999999999999995, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is of a large clock tower with a red glow coming from the inside. The clock tower is made of metal and has a large clock face on the front. The clock face has numbers and hands, and the clock is ticking away. The image is taken at night, and the red glow from"}, "409116": {"image_id": 409116, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.27206675522841467, "Bleu_3": 0.21658395134536354, "Bleu_4": 0.16884655390197964, "METEOR": 0.3070301148651106, "ROUGE_L": 0.3819009675583381, "CIDEr": 4.2379338047318633e-11, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.28, "f": 0.2692307692307692, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a hospital room with a bed, a desk, and a clock on the wall. There are also curtains on the windows.\n\nThe room is clean and well maintained. There are no signs of any medical equipment or supplies in the room. The bed is made up with a white sheet and"}, "573891": {"image_id": 573891, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.16026009915056863, "Bleu_4": 0.12799998273815197, "METEOR": 0.2976143566354979, "ROUGE_L": 0.28222075346992725, "CIDEr": 5.404223362930377e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10714285714285714, "f": 0.1276595744680851, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two teddy bears sitting on a couch. One of the bears is wearing a sweater and the other is wearing a scarf. They are both looking at the camera.\n\nThe image is taken in a living room with a couch and a coffee table. There is"}, "217156": {"image_id": 217156, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1211406307163407, "Bleu_3": 6.559319301112625e-07, "Bleu_4": 1.5337392624752068e-09, "METEOR": 0.22381281990644264, "ROUGE_L": 0.2367487247726769, "CIDEr": 2.1731175265715634e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.29411764705882354, "f": 0.2631578947368421, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a city street with tall buildings on either side of the road. There are cars parked on the side of the road and people walking on the sidewalk. The sky is clear and blue.\n\nThe image is taken from a bird's eye view, looking down on the city. The buildings"}, "526459": {"image_id": 526459, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.10301575072546125, "Bleu_3": 0.06046749936735668, "Bleu_4": 8.281653236265511e-06, "METEOR": 0.18089534392209497, "ROUGE_L": 0.1813317479191439, "CIDEr": 1.778696688088314e-09, "SPICE": {"All": {"pr": 0.08, "re": 0.09523809523809523, "f": 0.08695652173913043, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a white van parked in a garage. The van has a large window on the side and a door on the back. There are several newspapers and magazines on the floor next to the van. The garage appears to be well-lit and clean.\n\nThe van"}, "35594": {"image_id": 35594, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.12632278815731815, "Bleu_3": 7.026437559457351e-07, "Bleu_4": 1.6662810872720655e-09, "METEOR": 0.21152640448243243, "ROUGE_L": 0.23680124223602486, "CIDEr": 3.129332759985622e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16666666666666666, "f": 0.1923076923076923, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows an elephant and its baby standing in a field with trees in the background. The elephant is holding its baby in its trunk and the baby is suckling on the elephant's trunk. The elephant is standing on its hind legs and the baby is"}, "285314": {"image_id": 285314, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.11455372707190037, "Bleu_4": 1.351928705097216e-05, "METEOR": 0.18703130963425388, "ROUGE_L": 0.20497311827956988, "CIDEr": 1.2916412215586816e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a person on a skateboard riding down a street with other people on skateboards in the background. The person is wearing a black shirt and black pants, and has a black helmet on their head. The skateboard has black wheels and a black deck. The"}, "65271": {"image_id": 65271, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.13479285035956426, "Bleu_3": 0.070433097826065, "Bleu_4": 9.097876739853199e-06, "METEOR": 0.21924642476873746, "ROUGE_L": 0.2738496071829405, "CIDEr": 2.345227050724714e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a woman in a green dress holding an umbrella while standing on a stage. She is wearing a white hat and has a smile on her face. There are people in the background watching her perform.\n\nThe image is taken at a festival or event, possibly in a park or outdoor"}, "526728": {"image_id": 526728, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.11919074177008733, "Bleu_4": 0.07628504220422326, "METEOR": 0.27317039408606847, "ROUGE_L": 0.2896142433234421, "CIDEr": 4.415804661669368e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.3, "f": 0.2666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.5, "f": 0.2, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a couple standing outside a building with luggage. The building appears to be a restaurant or bar, with a sign reading \"The Pub\" on the front. The couple is dressed in casual clothing and appears to be waiting for something. The sidewalk is covered in snow and there are no"}, "476843": {"image_id": 476843, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.1448554036562842, "Bleu_4": 0.09015951515832439, "METEOR": 0.1720087896489539, "ROUGE_L": 0.2622527944969905, "CIDEr": 1.447650358161006e-08, "SPICE": {"All": {"pr": 0.1875, "re": 0.17142857142857143, "f": 0.1791044776119403, "fn": 29.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3333333333333333, "f": 0.2962962962962963, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a man and a woman surfing on a wave in the ocean. The man is standing on the board with his arms outstretched, while the woman is lying on the board with her arms around the man's waist. They are both wearing wetsuits and sunglass"}, "523252": {"image_id": 523252, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.15075567228616532, "Bleu_3": 0.07494071883573872, "Bleu_4": 9.439944120577903e-06, "METEOR": 0.24867437758475394, "ROUGE_L": 0.21682464454976302, "CIDEr": 1.0288550934544678e-14, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.13793103448275862, "f": 0.15384615384615385, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The train is a steam locomotive with a green and red caboose. It is pulling into a station with a platform and a sign that reads \"Welcome to the station\". There are people standing on the platform and others waiting on the platform. The train is moving slowly and the engineer is looking out the window"}, "489733": {"image_id": 489733, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.19659902977179203, "Bleu_4": 0.16952707578778212, "METEOR": 0.3200146202926384, "ROUGE_L": 0.3386798272671191, "CIDEr": 1.658630234306634e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.18518518518518517, "f": 0.1923076923076923, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of people sitting around a table with pizzas on it. There are two adults and two children at the table. The adults are drinking beer and the children are drinking juice. The table has a red and white checkered tablecloth on it. There are"}, "126429": {"image_id": 126429, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.25270668299793647, "Bleu_3": 0.20618343602654898, "Bleu_4": 0.15143565565465383, "METEOR": 0.3305168908467269, "ROUGE_L": 0.25707405177603854, "CIDEr": 1.6052286613072594e-10, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a table with several bottles of wine on it. There are people standing around the table, looking at the bottles. The table is covered with a white tablecloth.\n\nThe image is taken in a room with a lot of windows and a view of the outside. There are people standing"}, "15070": {"image_id": 15070, "Bleu_1": 0.3199999999936, "Bleu_2": 0.29137254362798654, "Bleu_3": 0.26054655651302827, "Bleu_4": 0.22654999076737387, "METEOR": 0.36242509549943724, "ROUGE_L": 0.39892984542211646, "CIDEr": 2.0965945032506844e-09, "SPICE": {"All": {"pr": 0.1, "re": 0.06451612903225806, "f": 0.0784313725490196, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows two cats looking out the window at a squirrel in the snow. The cats are white and have black spots on their fur. The squirrel is brown and has a bushy tail. The window is covered in frost and snow. The cats are sitting on the windows"}, "499884": {"image_id": 499884, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.2102800206225174, "Bleu_3": 0.1675544845458638, "Bleu_4": 0.13234510956521162, "METEOR": 0.25333490953933707, "ROUGE_L": 0.28222075346992725, "CIDEr": 4.6150878115027223e-10, "SPICE": {"All": {"pr": 0.36, "re": 0.45, "f": 0.39999999999999997, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a group of young men standing on a tennis court, holding tennis rackets and smiling at the camera. They are wearing white shirts and black pants, and one of them is holding a tennis ball. The background is a green field with trees in the distance."}, "32391": {"image_id": 32391, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 7.126876576918604e-07, "Bleu_4": 1.6486383890708068e-09, "METEOR": 0.1303826320715626, "ROUGE_L": 0.21131639722863746, "CIDEr": 6.498678587822476e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13636363636363635, "f": 0.15584415584415584, "fn": 38.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.35294117647058826, "f": 0.3870967741935484, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a small, two-story building with a sign on the front that reads \"Ko\". The building is surrounded by trees and has a small parking lot in front. There are no people in the image.\n\nThe image is taken in a residential area with a mix of old and new"}, "406908": {"image_id": 406908, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.11952286093128565, "Bleu_3": 0.08088091677194871, "Bleu_4": 9.995754509692036e-06, "METEOR": 0.2501983196041502, "ROUGE_L": 0.18068720379146921, "CIDEr": 7.039169351065704e-14, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.17391304347826086, "f": 0.15384615384615385, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a soccer field with a goal at one end and a soccer ball on the ground\n\nThe field is surrounded by trees and there are people playing soccer on it. The sky is clear and there are no clouds in the sky. The grass is green and there are no weeds or other"}, "419098": {"image_id": 419098, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.11605769149245462, "Bleu_3": 0.06546897467245089, "Bleu_4": 8.790269495390407e-06, "METEOR": 0.2223941711507184, "ROUGE_L": 0.25386444708680145, "CIDEr": 3.3449544534966285e-10, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15, "f": 0.13953488372093023, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is a pink pair of scissors hanging from a metal pole. The scissors are made of metal and have sharp blades. They are hanging from a metal pole with a chain. The pole is made of metal and has a hook at the top. The scissors are p"}, "575815": {"image_id": 575815, "Bleu_1": 0.2758620689560048, "Bleu_2": 0.19851666678721847, "Bleu_3": 0.113434038700165, "Bleu_4": 1.539267887805166e-05, "METEOR": 0.20814918503860955, "ROUGE_L": 0.3286047764410127, "CIDEr": 0.0059578858914232195, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.15151515151515152, "f": 0.15625, "fn": 28.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a pizza on a baking sheet with cheese and pepperoni on top. The pizza is cut into slices and there are crumbs on the baking sheet."}, "412407": {"image_id": 412407, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.1905193970494735, "Bleu_3": 0.13737787270193344, "Bleu_4": 0.08286037947510198, "METEOR": 0.2311144647436635, "ROUGE_L": 0.28096212896622313, "CIDEr": 4.580706249948309e-13, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.19047619047619047, "f": 0.16666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a person holding a cell phone in their hand. The phone has a screen with a black and white display. The person is standing in front of a group of people who are all looking at the phone. The background is a dark room with a few people standing in it.\n\nThe image shows a"}, "552074": {"image_id": 552074, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.10942600553008858, "Bleu_4": 0.08466528301619354, "METEOR": 0.17987991531280362, "ROUGE_L": 0.2738496071829405, "CIDEr": 3.015848085803831e-10, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.125, "f": 0.1081081081081081, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of tile. There is a window on the left side of the room and a door on the right side. The room is well lit and there is a fan on the ceiling"}, "192730": {"image_id": 192730, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1940285000252239, "Bleu_3": 0.13209470492933909, "Bleu_4": 0.09899454101416073, "METEOR": 0.19198335664587465, "ROUGE_L": 0.22889305816135083, "CIDEr": 7.008184692655189e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.29411764705882354, "f": 0.24390243902439027, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of cows standing in the middle of a dirt road. The cows are wearing collars and are being led by a person on a bicycle. The person is wearing a hat and has a backpack on their back. The sky is cloudy and there are trees"}, "478522": {"image_id": 478522, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.1278888396607359, "Bleu_4": 1.4301512965898685e-05, "METEOR": 0.23510790900253128, "ROUGE_L": 0.25707405177603854, "CIDEr": 1.8482325976276204e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a person on a surfboard in the ocean, with the sun setting in the background. The person is holding onto the rope and jumping off the wave. The water is choppy and there are some whitecaps on the surface. The sky is a deep blue and there are some clouds"}, "345209": {"image_id": 345209, "Bleu_1": 0.13725490195809306, "Bleu_2": 1.6568337391262165e-09, "Bleu_3": 3.826372616523305e-12, "Bleu_4": 1.8483326514023874e-13, "METEOR": 0.14237134990388173, "ROUGE_L": 0.14707655213984328, "CIDEr": 2.8355619804623996e-11, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.25, "f": 0.2692307692307692, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5833333333333334, "f": 0.5384615384615384, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The image shows a mother horse and her foal in a barn. The mother horse is standing next to the foal, who is nursing. The barn is made of wood and has a large door in the front. There are several bales of hay in the background. The lighting is soft"}, "268670": {"image_id": 268670, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.25318484176600003, "Bleu_3": 0.1857626796562003, "Bleu_4": 0.15124632406335528, "METEOR": 0.29650662355026547, "ROUGE_L": 0.3978260869565217, "CIDEr": 1.8559660346269878e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.23529411764705882, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The man is sitting on a couch with a cup of coffee in his hand. He is wearing a white shirt and jeans. The background is a living room with a couch, coffee table, and television.\n\nThe man is holding a cup of coffee in his hand and looking at the television"}, "134715": {"image_id": 134715, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.24462302738989036, "Bleu_3": 0.15744155315169847, "Bleu_4": 0.09650201809404371, "METEOR": 0.2568839249987278, "ROUGE_L": 0.285809906291834, "CIDEr": 4.780306288699302e-09, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.42105263157894735, "f": 0.3333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.75, "f": 0.631578947368421, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a bathroom with a sink, toilet, and shower. The walls are white and the floor is made of tile. There is a large window with curtains and a mirror on the wall. The bathroom has a large bathtub with a shower head and a toile"}, "343708": {"image_id": 343708, "Bleu_1": 0.20370370369993146, "Bleu_2": 1.9604759900272585e-09, "Bleu_3": 4.1966869140147396e-12, "Bleu_4": 1.951135289807993e-13, "METEOR": 0.1084010840108401, "ROUGE_L": 0.22274387063119458, "CIDEr": 1.5834148417243445e-10, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.1, "f": 0.0784313725490196, "fn": 18.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a large, modern shopping mall with a large clock tower in the center. The building is made of glass and steel, with a flat roof and a large, open atrium in the center. There are several large windows on the sides of the building, and a large, open entrance on the"}, "368291": {"image_id": 368291, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.16094080478419465, "Bleu_3": 0.10480530666648923, "Bleu_4": 1.2718160040773629e-05, "METEOR": 0.2664694247880666, "ROUGE_L": 0.2501708817498291, "CIDEr": 9.464561454855512e-10, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08333333333333333, "f": 0.0851063829787234, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a bowl of food with a spoon in it. The food appears to be a vegetarian dish with carrots, potatoes, and other vegetables. There is a blue plate and a blue napkin on the table. The background is a blue and white checkered tablecloth"}, "143217": {"image_id": 143217, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.164121987969432, "Bleu_3": 7.980300087819457e-07, "Bleu_4": 1.7681275091206876e-09, "METEOR": 0.22286258248761676, "ROUGE_L": 0.22008418520745643, "CIDEr": 1.1621054589720197e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.2777777777777778, "f": 0.23255813953488372, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The train is traveling down the tracks at a slow pace. It has a blue and yellow paint job and is pulling a large cargo car behind it. There are buildings on either side of the tracks and a few people standing on the platform. The sky is clear and sunny.\n\nThe train is traveling"}, "246590": {"image_id": 246590, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.21602468994265056, "Bleu_3": 0.12395961884573889, "Bleu_4": 1.4113991930504503e-05, "METEOR": 0.2760451967961464, "ROUGE_L": 0.26116207951070336, "CIDEr": 1.4280921822669755e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1111111111111111, "f": 0.13043478260869565, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a yellow motorcycle parked on the side of the road. The motorcycle has a bike rack on the back with two bikes attached to it. There are people walking on the sidewalk in front of the motorcycle. The sky is blue and there are trees in the background."}, "193401": {"image_id": 193401, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.21004201260012265, "Bleu_3": 0.17428681334439358, "Bleu_4": 0.14418310531901232, "METEOR": 0.29081868269166955, "ROUGE_L": 0.30049261083743845, "CIDEr": 1.130361579770333e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.17857142857142858, "f": 0.17543859649122806, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The woman is kneeling down next to a white horse in a forest. The horse is wearing a red and white striped blanket. The woman is holding a small bag in her hand. There are trees in the background.\n\nThe woman is kneeling down next to a white horse in a forest."}, "248912": {"image_id": 248912, "Bleu_1": 0.4285714285591838, "Bleu_2": 0.2970442628843906, "Bleu_3": 0.1748716728043272, "Bleu_4": 2.021864764469666e-05, "METEOR": 0.2693880923282191, "ROUGE_L": 0.4423495286439449, "CIDEr": 0.0010108211514069806, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image is a sandwich with chicken, lettuce, and sauce on a plate. There is a glass of apple juice on the side. The plate is green and there is a napkin on the side."}, "150417": {"image_id": 150417, "Bleu_1": 0.14285714285422743, "Bleu_2": 0.09449111825035836, "Bleu_3": 5.748590503681597e-07, "Bleu_4": 1.4255471031839075e-09, "METEOR": 0.13217019322809567, "ROUGE_L": 0.21618428824571767, "CIDEr": 2.504955906856869e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a woman in a kitchen, surrounded by other people, preparing a cake. The woman is wearing a red sweater and has a white apron on. The other people in the kitchen are wearing different colored sweaters and aprons. There are several kitchen appliances in the background"}, "433845": {"image_id": 433845, "Bleu_1": 0.4347826086862004, "Bleu_2": 0.29488391230331257, "Bleu_3": 0.18099097209374854, "Bleu_4": 0.12886443367349681, "METEOR": 0.24899997714381564, "ROUGE_L": 0.39109075770191504, "CIDEr": 0.01339870396243829, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.08333333333333333, "f": 0.07547169811320754, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and a helmet, and is standing on the board with his arms outstretched. The wave is large and white, and the sky is cloudy and blue. The sur"}, "243569": {"image_id": 243569, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.14002800840008178, "Bleu_3": 0.09222102361569189, "Bleu_4": 1.1247951467489566e-05, "METEOR": 0.23247012813789786, "ROUGE_L": 0.26293103448275856, "CIDEr": 9.224095929907666e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The woman is sitting on the bed with her laptop in front of her. She is wearing a white shirt and black pants. There are several photos on the wall, including one of a man and woman holding hands. The room is dimly lit and there are several lamps on the nightstand."}, "80865": {"image_id": 80865, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.27664166758053954, "Bleu_3": 0.22504970945193684, "Bleu_4": 0.18761254967400462, "METEOR": 0.3050172082534307, "ROUGE_L": 0.3463722397476341, "CIDEr": 2.7254779093842806e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.5333333333333333, "f": 0.37209302325581395, "fn": 7.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a tennis court with a man playing tennis on it. The man is wearing a white shirt and black shorts, and he is holding a tennis racket in his hand. There are palm trees in the background, and the sun is shining down on the court."}, "15978": {"image_id": 15978, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.22893427324353557, "Bleu_3": 0.18218943070472146, "Bleu_4": 0.15604229933011285, "METEOR": 0.3655961432787484, "ROUGE_L": 0.3567251461988304, "CIDEr": 1.1650244689046273e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13333333333333333, "f": 0.15384615384615383, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image is a black cat wearing a yellow bow tie sitting on a chair. The cat is looking up at the camera with its eyes closed. The background is a blurred image of a room with a table and chairs. The cat's fur is shiny and smooth, and its eyes are bright"}, "504732": {"image_id": 504732, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.13041013273663615, "Bleu_3": 0.08978110312668927, "Bleu_4": 1.1199515753588485e-05, "METEOR": 0.18711424214071762, "ROUGE_L": 0.2469635627530364, "CIDEr": 1.5606930057100026e-08, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.16666666666666666, "f": 0.13636363636363638, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The woman in the image is wearing a black coat and black pants. She is standing on the sidewalk and talking on her phone. There are several bicycles parked on the sidewalk. The streetlights are on and there are people walking in the background.\n\nThe image is taken at"}, "488736": {"image_id": 488736, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.13608276348545723, "Bleu_3": 7.043309782608963e-07, "Bleu_4": 1.6100218008380818e-09, "METEOR": 0.19900540672533848, "ROUGE_L": 0.21542083578575633, "CIDEr": 6.554862338655592e-13, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.2, "f": 0.13953488372093023, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a clock hanging from the side of a building. The clock has two hands and is surrounded by a metal frame. The building is made of brick and has large windows on the sides. The sky is clear and blue.\n\nThe image is taken in the afternoon, with the sun shining bright"}, "486479": {"image_id": 486479, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.2853908964871544, "Bleu_3": 0.22507957633966116, "Bleu_4": 0.1846909213573168, "METEOR": 0.2741289308592973, "ROUGE_L": 0.2897862232779097, "CIDEr": 5.356957585030234e-10, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a dog peeking out from under a red and white striped curtain. The dog is white with brown spots on its face and ears. The curtain is red and white striped, and it is hanging from a rod on the wall. The floor is made of wood and has"}, "120398": {"image_id": 120398, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.12281268769488378, "Bleu_3": 0.06706647632268699, "Bleu_4": 8.857886206727456e-06, "METEOR": 0.1448871091170692, "ROUGE_L": 0.18373493975903615, "CIDEr": 1.184866537291171e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.16, "f": 0.17777777777777778, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person holding a hot dog in their hand. The hot dog appears to be topped with cheese, tomato, and onion. The person is sitting in a car with the windows rolled down. The background is a road with trees and buildings in the distance.\n\nThe image is in"}, "29521": {"image_id": 29521, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.1797866299868988, "Bleu_3": 0.13461691545954688, "Bleu_4": 0.10891914013328477, "METEOR": 0.24915469138133134, "ROUGE_L": 0.36744352814628906, "CIDEr": 3.741635221075627e-09, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.2916666666666667, "f": 0.2545454545454545, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a man sitting at a table outside, looking at his phone. The table is made of wood and has a white tablecloth on it. There are two chairs next to the table, one of which is occupied by a woman who is also looking at her phone. The man is wearing a"}, "128528": {"image_id": 128528, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.08217664461402949, "Bleu_4": 1.0264051022519406e-05, "METEOR": 0.2237916510425373, "ROUGE_L": 0.24302788844621512, "CIDEr": 4.266000152016296e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.09523809523809523, "f": 0.1081081081081081, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The dog is running with a red ball in its mouth. It is wearing a red backpack and has a collar on its neck. The dog is running on the snow covered ground.\n\nThe dog is running with a red ball in its mouth. It is wearing a red backpack and has a"}, "52161": {"image_id": 52161, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.21128856367777224, "Bleu_3": 0.15604075333783501, "Bleu_4": 0.12546407368639798, "METEOR": 0.2842286641933639, "ROUGE_L": 0.31504196255648803, "CIDEr": 4.2361032009976954e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.22727272727272727, "f": 0.19607843137254902, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a woman riding a red motorcycle on a road. She is wearing a black leather jacket and helmet, and has a pair of sunglasses on her face. The motorcycle has a white stripe on the side and a black seat. The road is straight and there"}, "519716": {"image_id": 519716, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.15352206215446232, "Bleu_3": 0.11008521423530733, "Bleu_4": 0.0711698266549331, "METEOR": 0.23234585058617466, "ROUGE_L": 0.27006087437742116, "CIDEr": 1.8750825975592744e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13333333333333333, "f": 0.14814814814814814, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a white cat sleeping on a green blanket in a room with a wooden floor and a wooden table with a lamp on it. There is a window on the left side of the room with curtains open. The room is well lit and there are no other objects in the room."}, "204324": {"image_id": 204324, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.15861031714066393, "Bleu_3": 0.0989076400524586, "Bleu_4": 0.06599785727714086, "METEOR": 0.18550278136789342, "ROUGE_L": 0.24970760233918127, "CIDEr": 7.395738663134325e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.16666666666666666, "f": 0.14634146341463414, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a beach in front of a large rock formation. The sky is clear and blue, with a few clouds scattered across it. The people are all wearing sunglasses and some are holding kites. The beach is sandy and there are some rocks scattered along the"}, "94501": {"image_id": 94501, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.2842676218010918, "Bleu_3": 0.21101764911117346, "Bleu_4": 0.16095596505948398, "METEOR": 0.3179165803809155, "ROUGE_L": 0.3609467455621302, "CIDEr": 9.464583139168437e-08, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.5, "f": 0.3888888888888889, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.6666666666666666, "f": 0.6153846153846153, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a slice of chocolate cake with a fork on the side. The cake is topped with whipped cream and has a sprinkle of chocolate shavings on top. There is a bottle of beer on the table next to the cake. The background"}, "249884": {"image_id": 249884, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.1469436716703117, "Bleu_3": 0.08356671880332696, "Bleu_4": 1.1283644306066042e-05, "METEOR": 0.20371562857583525, "ROUGE_L": 0.22846441947565538, "CIDEr": 5.929541999899652e-06, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.4, "f": 0.3137254901960784, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.8571428571428571, "f": 0.6666666666666665, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows two pizzas on a grill, one with tomato sauce and cheese, and the other with pepperoni and mushrooms. The pizzas are cooking on the grill, with the cheese melted and the toppings cooked through. The grill"}, "315939": {"image_id": 315939, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.15475060698405138, "Bleu_3": 0.07772573699771664, "Bleu_4": 9.84421602524371e-06, "METEOR": 0.23639248149100345, "ROUGE_L": 0.23894795747062114, "CIDEr": 4.752026439683591e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a woman in a pink dress and a man in a white shirt and pants standing on a bench in a park. They are both looking at something in front of them. There are trees and flowers in the background.\n\nThe woman in the pink dress is wearing a wide"}, "283471": {"image_id": 283471, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.24371914504394585, "Bleu_3": 0.1045342600539371, "Bleu_4": 1.2233520189533797e-05, "METEOR": 0.20946944601104694, "ROUGE_L": 0.27949599083619703, "CIDEr": 1.3960254503784326e-11, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.14285714285714285, "f": 0.15625, "fn": 30.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.06666666666666667, "f": 0.07407407407407407, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.2857142857142857, "f": 0.29629629629629634, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a dog lying on a red carpet in front of a couch. The dog is black and white and has a collar on. The couch is brown and has a pattern of white and black stripes. There is a lamp on the table next to the couch. The room is well"}, "448657": {"image_id": 448657, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.15613914506966814, "Bleu_3": 0.08092609555849525, "Bleu_4": 1.0417495275554298e-05, "METEOR": 0.13727128769627084, "ROUGE_L": 0.22426470588235295, "CIDEr": 4.635792210545932e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2857142857142857, "f": 0.24489795918367344, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person riding a horse over a jump. The horse is wearing a saddle and bridle, and the rider is wearing a helmet and riding boots. The background is a green field with trees in the distance.\n\nThe image is in black and white, and"}, "292032": {"image_id": 292032, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.28867513458920707, "Bleu_3": 0.24662120742821012, "Bleu_4": 0.21515344521246546, "METEOR": 0.29505333466403505, "ROUGE_L": 0.3719512195121952, "CIDEr": 1.3590225323578101e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a plate of food with a meat skewer, a side of rice, and a glass of orange juice on the table. There is also a bowl of fruit on the table. The background is a wooden floor with a rug on it.\n\nThe image is well-lit and the colors"}, "571834": {"image_id": 571834, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.10219406022809462, "Bleu_4": 0.06730826637311355, "METEOR": 0.23094115226689305, "ROUGE_L": 0.21542083578575633, "CIDEr": 1.9486042628016624e-13, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2857142857142857, "f": 0.2790697674418604, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a building with a sign that reads \"Mash House\". The building appears to be a restaurant or bar, with a large window on the front and a sign that reads \"Mash House\" in the window. There are people standing in front of the building,"}, "148286": {"image_id": 148286, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.10942520359115704, "Bleu_3": 6.16909583375895e-07, "Bleu_4": 1.4720536435426584e-09, "METEOR": 0.16474964075508414, "ROUGE_L": 0.14796846573681016, "CIDEr": 1.3650959843897943e-11, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.32, "f": 0.30769230769230765, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a river with a small bridge over it. There are trees on both sides of the river and a small village in the background. The water is murky and there are some rocks in the river. There are also some animals in the river, including elephants and monkeys.\n\nThe image"}, "52661": {"image_id": 52661, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.087675151639143, "Bleu_3": 5.287494182785523e-07, "Bleu_4": 1.304802808756457e-09, "METEOR": 0.14065057001768197, "ROUGE_L": 0.19741100323624594, "CIDEr": 1.4562901051673938e-11, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.36363636363636365, "f": 0.3555555555555555, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on the sidewalk in front of a large ship that is docked at the pier. There are several other boats in the background, and a few people are walking on the sidewalk. The sky is cloudy and there are some buildings in the background.\n\nThe image"}, "484066": {"image_id": 484066, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.1346716546900339, "Bleu_4": 0.0853626107680773, "METEOR": 0.24079348820653293, "ROUGE_L": 0.36030714707619615, "CIDEr": 6.502861259727704e-08, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.07142857142857142, "f": 0.07692307692307691, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image is of a man standing in front of a large painting of a giraffe. The man is wearing a black shirt and jeans, and has a surprised expression on his face. The painting depicts a giraffe standing on its hind legs, with its front legs stretched out"}, "288633": {"image_id": 288633, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.11673403265989704, "Bleu_3": 6.399271623835167e-07, "Bleu_4": 1.5055852953281506e-09, "METEOR": 0.21949993875455684, "ROUGE_L": 0.1821983273596177, "CIDEr": 4.452558893355074e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14814814814814814, "f": 0.1509433962264151, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a street with horse-drawn carriages and people walking on the sidewalk. There are buildings on either side of the street, with one of them being a large red brick building with a clock tower. The street is lined with trees and there are cars parked on the side of the road"}, "349489": {"image_id": 349489, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.1480872194371519, "Bleu_3": 0.10615274788259942, "Bleu_4": 0.06860408726311093, "METEOR": 0.182840062018115, "ROUGE_L": 0.2136602451838879, "CIDEr": 1.9111582105882854e-14, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a cup of coffee on a blue plate with a cookie on the side. There is a white kettle on the counter next to the plate. The walls are painted white and there is a window in the background.\n\nThe image shows a cup of coffee on a blue plate with a cookie on"}, "343445": {"image_id": 343445, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.2243088616326247, "Bleu_3": 0.09890764005245863, "Bleu_4": 1.1736263070262706e-05, "METEOR": 0.24964617085612661, "ROUGE_L": 0.2694941462337088, "CIDEr": 8.875345272098309e-10, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.2222222222222222, "f": 0.16326530612244897, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.5, "f": 0.3, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a wooden birdhouse with a bird perched on top of it. The birdhouse is made of wood and has a red and white striped design on it. The bird is a small bird with a yellow beak and a red chest. There are two small flowers in a vase on the"}, "309836": {"image_id": 309836, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.13957263155725563, "Bleu_3": 7.118725684669195e-07, "Bleu_4": 1.615223877663139e-09, "METEOR": 0.23059532867128418, "ROUGE_L": 0.17329545454545456, "CIDEr": 1.362358543168851e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a bird flying in the sky with a rocket in the background. The bird is flying in a straight line and the rocket is flying in a curved line. The sky is clear and there are no clouds in the background. The bird is flying at a high altitude and the rocket is"}, "296684": {"image_id": 296684, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.09436646347757241, "Bleu_4": 1.1502783619667552e-05, "METEOR": 0.21585373086095475, "ROUGE_L": 0.2519174041297935, "CIDEr": 7.954239259637765e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a wetsuit and holding onto the surfboard with one hand while the other hand is in the air. The wave is white and foamy, and the sky is blue and cloudy. The person is jump"}, "190637": {"image_id": 190637, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.16402518938356242, "Bleu_3": 0.1011461250097803, "Bleu_4": 1.1934916719944687e-05, "METEOR": 0.24786938380916426, "ROUGE_L": 0.24970760233918127, "CIDEr": 6.871656413177735e-13, "SPICE": {"All": {"pr": 0.125, "re": 0.11538461538461539, "f": 0.12000000000000001, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a young boy sitting on a couch with a blanket wrapped around him. He is holding a remote control in his hand and looking at the television. The room is dimly lit and there are no other objects in the room.\n\nThe boy is wearing a blue shirt and white p"}, "461573": {"image_id": 461573, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.09701425001261196, "Bleu_3": 5.76976768606882e-07, "Bleu_4": 1.4143550190666944e-09, "METEOR": 0.15188630544087336, "ROUGE_L": 0.22889305816135083, "CIDEr": 2.9648003094557904e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.125, "f": 0.12000000000000001, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a pair of old metal benches sitting on the sidewalk in front of a row of trees. The benches are rusted and have a worn, weathered appearance. The trees are tall and green, with leaves that are a deep shade of green. The sidewalk is cracked and une"}, "478906": {"image_id": 478906, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.1216598129318781, "Bleu_3": 6.902831277935676e-07, "Bleu_4": 1.65351170890051e-09, "METEOR": 0.1590507538107259, "ROUGE_L": 0.16277518345563707, "CIDEr": 6.955679825275015e-10, "SPICE": {"All": {"pr": 0.15625, "re": 0.19230769230769232, "f": 0.1724137931034483, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a stone wall. They are all wearing black suits and white shirts, and one of them is holding a glass of wine. The background is a stone wall with a large window on the left side."}, "385985": {"image_id": 385985, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.19958027235629977, "Bleu_3": 9.149779456371165e-07, "Bleu_4": 1.9686360129176833e-09, "METEOR": 0.19589595356290385, "ROUGE_L": 0.2582010582010582, "CIDEr": 6.899757895422869e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two people sitting on the ground, one holding a cell phone and the other looking at it. The person on the left is wearing black pants and a white shirt, while the person on the right is wearing black pants and a black shirt. The person on the left is looking"}, "203690": {"image_id": 203690, "Bleu_1": 0.15094339622356714, "Bleu_2": 0.12047318414543882, "Bleu_3": 0.09486600651870754, "Bleu_4": 0.07644480232985446, "METEOR": 0.16303070755712348, "ROUGE_L": 0.226906385616863, "CIDEr": 2.360121991171389e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on a beach with a large wave crashing against the shore. The people are wearing wetsuits and surfboards, and the sky is cloudy with a sun setting in the background. The beach is covered in sand and rocks, and there are some buildings in the"}, "147769": {"image_id": 147769, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 0.07913235571850134, "Bleu_4": 9.880177230491347e-06, "METEOR": 0.242176694090124, "ROUGE_L": 0.24610951008645532, "CIDEr": 3.6157733812829513e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11538461538461539, "f": 0.11320754716981132, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a man standing on the field, wearing a baseball uniform and holding a bat. He is looking down at the ground and appears to be deep in thought. The background is a baseball stadium with a large crowd of people in the stands.\n\nThe image is in black and white, with the"}, "91615": {"image_id": 91615, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2065984676302324, "Bleu_3": 0.12983940805705807, "Bleu_4": 0.08711822053257058, "METEOR": 0.2618826122063341, "ROUGE_L": 0.34634492547906315, "CIDEr": 0.0001874467888640386, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.22727272727272727, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a kitchen with wooden cabinets and stainless steel appliances. There is a large island in the center of the room with a sink and stove. The floor is made of hardwood and there are no windows in the room."}, "33243": {"image_id": 33243, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.15939996379066856, "Bleu_3": 0.09681429081061077, "Bleu_4": 0.06373293648487792, "METEOR": 0.20663982023556962, "ROUGE_L": 0.23591160220994478, "CIDEr": 1.763023875731656e-14, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.21052631578947367, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a bathroom with a large mirror on the wall and a white sink on the counter\n\nThe bathroom has a large mirror on the wall and a white sink on the counter. The floor is made of wood and there are two windows in the room. The walls are painted white and there are two lights"}, "112867": {"image_id": 112867, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.09531293854471146, "Bleu_3": 5.590278679123735e-07, "Bleu_4": 1.360449889464037e-09, "METEOR": 0.15902394972012113, "ROUGE_L": 0.1783625730994152, "CIDEr": 6.851374594562731e-12, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.16666666666666666, "f": 0.10526315789473684, "fn": 10.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.3333333333333333, "f": 0.19047619047619044, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a wooden bench with four pots of plants on it. The plants are in different sizes and shapes, and they are all different colors. The bench is made of wood and has a smooth surface. The plants are growing in the soil and are healthy looking. The bench is in a"}, "406329": {"image_id": 406329, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.20641345956409557, "Bleu_3": 0.13245800111969533, "Bleu_4": 0.0809953726265708, "METEOR": 0.2702927444704784, "ROUGE_L": 0.2627894453419494, "CIDEr": 2.3068305463772576e-13, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.3181818181818182, "f": 0.31111111111111117, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a white bus parked on the side of the road. The bus has a blue and white striped design on the side and a large window on the front. There are several cars parked on the other side of the road, and a house with a red roof in the background. The sky is"}, "286583": {"image_id": 286583, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1666666666629209, "Bleu_3": 0.10891466159390667, "Bleu_4": 0.07447361532835538, "METEOR": 0.18576042411979324, "ROUGE_L": 0.26804770872567485, "CIDEr": 1.0530025900834244e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.1935483870967742, "f": 0.21818181818181817, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people walking down a city street with umbrellas. The street is lined with tall buildings and there are cars parked on the side of the road. The sky is cloudy and there are puddles of water on the ground."}, "347529": {"image_id": 347529, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.1297498240245396, "Bleu_3": 0.068230605987166, "Bleu_4": 8.840637545603441e-06, "METEOR": 0.20954522408062248, "ROUGE_L": 0.24358243011979464, "CIDEr": 2.8081556103610693e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a black bear climbing a tree in a forest. The bear is hanging from a branch with its front paws and is looking down at the ground. The tree is tall and has a lot of branches. The forest is dense and there are many trees in the background.\n\nThe image is"}, "123677": {"image_id": 123677, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.11726797422183437, "Bleu_4": 0.08917631496980527, "METEOR": 0.258843079769336, "ROUGE_L": 0.22344322344322343, "CIDEr": 3.552942791429178e-13, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people holding glasses of wine in their hands. They are standing around a table with a white tablecloth and a vase of flowers on it. There is a man in the background holding a camera. The room is dimly lit and there are some candles on the table."}, "62661": {"image_id": 62661, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.23008949664965453, "Bleu_3": 0.1864588148443747, "Bleu_4": 0.14187543101933917, "METEOR": 0.3089019277700708, "ROUGE_L": 0.3051907442151345, "CIDEr": 4.910968805882846e-09, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a fire hydrant on the side of the road. The hydrant is red and has a yellow sign on it that says \"nyc taxi\". The hydrant is next to a yellow taxi cab. The image is taken from a low angle, looking down at the hydrant and taxi"}, "494320": {"image_id": 494320, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.168845408373504, "Bleu_3": 0.10120810002156609, "Bleu_4": 0.0661931446961295, "METEOR": 0.22595983978921094, "ROUGE_L": 0.2392156862745098, "CIDEr": 1.3941846408983935e-14, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2631578947368421, "f": 0.2040816326530612, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black and white photograph of a train on a track. The train is a steam locomotive with a black and white body and a red and white cab. The train is parked on the track in front of a large building with windows and a door. There are no people in the image."}, "107216": {"image_id": 107216, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.22678604710454314, "Bleu_3": 0.175591310079564, "Bleu_4": 0.1305000179020057, "METEOR": 0.2483731773544007, "ROUGE_L": 0.29202127659574467, "CIDEr": 2.595575734241126e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21052631578947367, "f": 0.186046511627907, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is a reflection of a red and white boat in a body of water. The boat is docked at a dock and has a small cabin on the top. The water is calm and there are no other boats in the image. The sky is clear and there are no clouds. The reflection of the boat in"}, "417355": {"image_id": 417355, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.11531640100118269, "Bleu_3": 0.0661213089813225, "Bleu_4": 8.952677771744006e-06, "METEOR": 0.20109865085521572, "ROUGE_L": 0.2616421568627451, "CIDEr": 3.060331587063637e-09, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person in pink clothing and a skiing outfit walking on the snow. The person is wearing a pink hat and has a pink scarf around their neck. The person is also wearing pink gloves and has a pink backpack on their back. The image"}, "494629": {"image_id": 494629, "Bleu_1": 0.339622641503026, "Bleu_2": 0.24244760629354595, "Bleu_3": 0.1664339314884709, "Bleu_4": 0.11653232247001571, "METEOR": 0.30089427528965385, "ROUGE_L": 0.34560906515580736, "CIDEr": 1.846358155613288e-10, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a desk in front of a computer monitor. He is wearing a blue shirt and jeans and has a laptop on his lap. There is a white toilet seat in the background.\n\nThe man is looking at the computer screen with a serious expression on his"}, "283028": {"image_id": 283028, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.20604084591910862, "Bleu_3": 0.13567065103689688, "Bleu_4": 0.09997224149434299, "METEOR": 0.23729396113367138, "ROUGE_L": 0.22195269860521533, "CIDEr": 3.4269572705009794e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.24242424242424243, "f": 0.2807017543859649, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The cat is sitting on top of a computer keyboard. The keyboard has a mouse on it. The cat is looking at the mouse. The computer screen is showing a picture of a cat. The cat is wearing a collar with a tag on it. The tag has the words \"Kitty\" written on"}, "515043": {"image_id": 515043, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.08206099398471602, "Bleu_3": 5.02727403256082e-07, "Bleu_4": 1.2502549517017175e-09, "METEOR": 0.1732326367638729, "ROUGE_L": 0.20666290231507625, "CIDEr": 3.6085324352831613e-13, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.12903225806451613, "f": 0.13333333333333333, "fn": 27.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a small plane taking off from a runway on a cloudy day. The plane has a red and yellow paint job and is flying low to the ground. The runway is made of asphalt and there are no other planes in sight. The sky is filled with clouds and there is a"}, "76518": {"image_id": 76518, "Bleu_1": 0.46153846152958583, "Bleu_2": 0.3295410218222544, "Bleu_3": 0.22144862565722637, "Bleu_4": 0.16057799674555318, "METEOR": 0.2238904497222313, "ROUGE_L": 0.349063614744352, "CIDEr": 0.00028648328770273715, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.42857142857142855, "f": 0.3243243243243243, "fn": 8.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 1.0, "f": 0.7142857142857143, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a table with a plate of toast, a cup of coffee, and a book on the table. There are also some books on the shelf behind the table. The table has a white tablecloth on it. The room has a wooden floor and a window with curtains. There is"}, "429726": {"image_id": 429726, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 8.077421359130519e-07, "Bleu_4": 1.8710588175603566e-09, "METEOR": 0.16010168207691258, "ROUGE_L": 0.2019867549668874, "CIDEr": 6.011165624744461e-09, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2631578947368421, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man and woman walking down a sidewalk with skateboards. The man is wearing a black shirt and pants, while the woman is wearing a white shirt and pants. They are both wearing sunglasses and have their hands in their pockets. The side"}, "463199": {"image_id": 463199, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.18171094607444632, "Bleu_3": 0.12476834639035371, "Bleu_4": 1.403898833994283e-05, "METEOR": 0.21050554038829378, "ROUGE_L": 0.3190005810575247, "CIDEr": 1.0581757549997084e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a group of people standing on a bus. They are all wearing sunglasses and looking at their phones. The bus is a large, white vehicle with windows on the sides and a driver's seat in the front. There are other people standing on the bus, looking out"}, "328536": {"image_id": 328536, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.14458880781007946, "Bleu_3": 0.10148763200900296, "Bleu_4": 0.07195213544079326, "METEOR": 0.19937516327888366, "ROUGE_L": 0.2663755458515284, "CIDEr": 5.515294895187119e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.17857142857142858, "f": 0.17857142857142858, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image is a bowl of broccoli with cheese sauce and croutons. The broccoli is green and has florets. The cheese sauce is yellow and has a creamy texture. The croutons are small and crunchy. The bowl is made of white cer"}, "301093": {"image_id": 301093, "Bleu_1": 0.387755102032903, "Bleu_2": 0.2980948577450177, "Bleu_3": 0.19628647116875306, "Bleu_4": 2.013623716016975e-05, "METEOR": 0.32717478513050835, "ROUGE_L": 0.36030714707619615, "CIDEr": 5.665215183216587e-09, "SPICE": {"All": {"pr": 0.28125, "re": 0.2903225806451613, "f": 0.28571428571428575, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 9.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "The image shows a bed with a quilted blanket on it. The bed is made up with a pillow and a sheet. There is a lamp on the nightstand next to the bed. The room is dimly lit.\n\nThe image shows a bed with a quilted blanket on it"}, "173545": {"image_id": 173545, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.08243669902025869, "Bleu_4": 1.0393938325822104e-05, "METEOR": 0.21855940671245727, "ROUGE_L": 0.314974182444062, "CIDEr": 4.362733071314631e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14814814814814814, "f": 0.16666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two elephants standing in a field with trees in the background. The elephants are wearing colorful umbrellas and are standing next to each other. The trees are tall and green, with branches reaching up towards the sky. The sky is blue and there are clouds in the background"}, "126671": {"image_id": 126671, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.20412414522772235, "Bleu_3": 0.1385492093235938, "Bleu_4": 0.10369816700419776, "METEOR": 0.27168396070944933, "ROUGE_L": 0.3753846153846154, "CIDEr": 5.0166886128426634e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.22727272727272727, "f": 0.27027027027027023, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image is of a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of tile. There is a window on the left side of the room with curtains. The shower has a curtain and a shower head. The sink has"}, "274591": {"image_id": 274591, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.0767719506444456, "Bleu_4": 9.802862511748142e-06, "METEOR": 0.15785927119682117, "ROUGE_L": 0.18373493975903615, "CIDEr": 2.555110363346264e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.375, "f": 0.3243243243243243, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a black bear standing on a log in a zoo enclosure. The bear is looking down at something on the ground. There are other animals in the enclosure, including a deer and a fox. The trees in the background are tall and green. The sky is blue and cloudy."}, "180787": {"image_id": 180787, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.15075567228616532, "Bleu_3": 7.494071883573874e-07, "Bleu_4": 1.6786858261541668e-09, "METEOR": 0.2004581263959451, "ROUGE_L": 0.21682464454976302, "CIDEr": 6.887524986201106e-14, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.13793103448275862, "f": 0.14545454545454548, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a photograph of a restaurant kitchen. There are several people working in the kitchen, including a chef and a server. The chef is cutting up a large piece of meat on a cutting board, while the server is preparing food on a grill. There are several other people in the kitchen, including a d"}, "6614": {"image_id": 6614, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.11524490328511487, "Bleu_4": 0.07554258316170323, "METEOR": 0.20858511237220714, "ROUGE_L": 0.27128335451080055, "CIDEr": 8.871638765792256e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.2, "f": 0.1702127659574468, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is a black and white drawing of a bowl of fruit, including apples, oranges, and grapes. The fruit is arranged in a bowl with a white background. The drawing is done in a realistic style, with each piece of fruit drawn in detail. The overall effect is one"}, "75076": {"image_id": 75076, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.24836183164306555, "Bleu_3": 0.19360515975280349, "Bleu_4": 0.16412989648742127, "METEOR": 0.3201882163135312, "ROUGE_L": 0.3544450900639163, "CIDEr": 1.580368789783976e-11, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.22580645161290322, "f": 0.2456140350877193, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a wooden bench sitting in the middle of a forest with colorful leaves on the trees. The bench is made of wood and has a rustic look to it. The trees in the background are a mix of deciduous and evergreen trees, with bright red, orange, and yellow leaves on"}, "217016": {"image_id": 217016, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.25761406704390316, "Bleu_3": 0.21022727514366074, "Bleu_4": 0.15443583821399115, "METEOR": 0.35335112403627017, "ROUGE_L": 0.41402714932126705, "CIDEr": 1.1523244989139032e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.15789473684210525, "f": 0.15384615384615385, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This image shows a yellow car parked on the beach next to a body of water. The car has a surfboard on top of it. There are people walking on the beach in the background. The sky is cloudy and there are palm trees in the distance.\n\nThe car is parked on"}, "148549": {"image_id": 148549, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.1878672873218244, "Bleu_3": 0.08964004852977604, "Bleu_4": 1.106792615545272e-05, "METEOR": 0.2615707183084223, "ROUGE_L": 0.2238532110091743, "CIDEr": 2.4910320776772654e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.13793103448275862, "f": 0.14285714285714285, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The man in the image is wearing a white shirt and black pants, and he is holding a banana in his hand. He is standing in front of a fruit stand in a grocery store, surrounded by various types of fruit. The fruit stand has a variety of fruits, including bananas"}, "112949": {"image_id": 112949, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.21554026869932671, "Bleu_3": 0.10511522304355245, "Bleu_4": 1.313660254719646e-05, "METEOR": 0.2271519476967648, "ROUGE_L": 0.2622527944969905, "CIDEr": 4.4080996415706724e-05, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person on a snowboard, wearing a helmet and gloves, standing on a snowy slope. The sky is cloudy and the trees are bare.\n\nThe person is wearing a white snowboarding suit, black goggles, and black gloves. They are"}, "237075": {"image_id": 237075, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.15097578581028312, "Bleu_3": 0.07367382993796891, "Bleu_4": 9.192590808034453e-06, "METEOR": 0.18890027921215505, "ROUGE_L": 0.20344635908838243, "CIDEr": 2.336043594821752e-16, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2222222222222222, "f": 0.1951219512195122, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is of a group of people standing in front of a building. They are all holding suitcases and looking at each other. There is a woman in the front of the group who is holding a baby. The building behind them is made of glass and has a large window on the side. There are trees and"}, "436555": {"image_id": 436555, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.23819653366515028, "Bleu_3": 0.19487438801482035, "Bleu_4": 0.1601503686261675, "METEOR": 0.22038019614992713, "ROUGE_L": 0.31077147016011636, "CIDEr": 1.7293213160046733e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of people walking down a street in a city. They are all wearing different types of clothing, including hats and sunglasses. Some of them are carrying bags or backpacks. The street is lined with buildings on both sides, and there are cars parked"}, "352478": {"image_id": 352478, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.08804509063049051, "Bleu_3": 5.73951873233632e-07, "Bleu_4": 1.4744892493104464e-09, "METEOR": 0.12158054711246201, "ROUGE_L": 0.17003484320557494, "CIDEr": 8.042741812491375e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a market with a variety of vegetables and fruits on display. There are several baskets of fresh produce on the table, including broccoli, kale, and lettuce. The baskets are labeled with prices and the vendors are wearing aprons and hats."}, "469755": {"image_id": 469755, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.11113289333084049, "Bleu_4": 1.2936981168128564e-05, "METEOR": 0.22670873276381417, "ROUGE_L": 0.2688916876574307, "CIDEr": 7.81520562225911e-12, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.19047619047619047, "f": 0.16666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people surfing on the ocean. They are standing on the waves and riding them towards the shore. The water is choppy and there are rocks in the distance. The sky is cloudy and there are some birds flying overhead. The people are wearing wetsuits and sur"}, "277587": {"image_id": 277587, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.15118578920063636, "Bleu_3": 7.808966656031396e-07, "Bleu_4": 1.78410623850286e-09, "METEOR": 0.22519950754361168, "ROUGE_L": 0.22732919254658387, "CIDEr": 5.964620905532361e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The room is decorated with white and gold accents. There is a large bed with white sheets and pillows. The bathroom has a large shower and a sink. The room has a large window with a view of the garden.\n\nThe room is decorated with white and gold accents. There"}, "58089": {"image_id": 58089, "Bleu_1": 0.1666666666631945, "Bleu_2": 0.11909826683257516, "Bleu_3": 0.08511922922359433, "Bleu_4": 1.081976014400406e-05, "METEOR": 0.17405269601725845, "ROUGE_L": 0.23461538461538461, "CIDEr": 3.0523986344303746e-09, "SPICE": {"All": {"pr": 0.04, "re": 0.05, "f": 0.044444444444444446, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a parking meter on the side of the road. The meter has a red light on top and a number three on the front. There are cars parked on both sides of the road. The sky is cloudy and there are trees in the background."}, "51880": {"image_id": 51880, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 6.789968544843665e-07, "Bleu_4": 1.581824583382231e-09, "METEOR": 0.204772978797801, "ROUGE_L": 0.25341246290801184, "CIDEr": 2.840816836942927e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on the hood of a car. The car is parked in a parking lot and there are other cars parked nearby. The cat appears to be looking at something on the ground.\n\nThe image is taken in a parking lot. The car is a white van with"}, "331317": {"image_id": 331317, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.12399138853119372, "Bleu_3": 6.66182522208817e-07, "Bleu_4": 1.5516807838487133e-09, "METEOR": 0.14889479108721024, "ROUGE_L": 0.20962199312714777, "CIDEr": 8.729674180759845e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.09375, "f": 0.10526315789473684, "fn": 29.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image is of a large clock with a gold frame and a black face. The clock has a large, ornate face with Roman numerals and hands. The clock is surrounded by a large, ornate frame with a gold border. The image is taken in a large, dimly lit room with a high ce"}, "319024": {"image_id": 319024, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.27186953392208474, "Bleu_3": 0.20327289436966717, "Bleu_4": 0.1671889180298872, "METEOR": 0.2698912125980973, "ROUGE_L": 0.3248520710059172, "CIDEr": 8.818282194827876e-07, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.21052631578947367, "f": 0.15999999999999998, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a young girl standing in front of a refrigerator, looking at something on the counter. She is wearing a pink sweater and pink pants. The refrigerator is open, revealing a variety of food and drinks inside. The girl is holding a small bag"}, "449424": {"image_id": 449424, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.23354968324417125, "Bleu_3": 0.10096268659466019, "Bleu_4": 1.1860959909843713e-05, "METEOR": 0.23652734406789133, "ROUGE_L": 0.27961037898010965, "CIDEr": 4.365037770048351e-12, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.25, "f": 0.20408163265306123, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is a 360 degree view of a bedroom. There is a bed in the center of the room with a desk and chair in front of it. There is a closet on the right side of the room and a window on the left side. The walls are painted white and the floor"}, "542549": {"image_id": 542549, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.07457725404314713, "Bleu_4": 9.591924934151242e-06, "METEOR": 0.22250722794491623, "ROUGE_L": 0.26293103448275856, "CIDEr": 3.2891253733535583e-12, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.043478260869565216, "f": 0.038461538461538464, "fn": 22.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image is of a bed with a blanket on it. There are two pillows on the bed and a book on the nightstand. The room is dimly lit and there is a window in the background.\n\nThe image is of a bed with a blanket on it. There are two pillows"}, "90754": {"image_id": 90754, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.30486390176421546, "Bleu_3": 0.24271663931023996, "Bleu_4": 0.21047796135420604, "METEOR": 0.3341946761402496, "ROUGE_L": 0.34231200897867564, "CIDEr": 4.942588956368701e-10, "SPICE": {"All": {"pr": 0.0625, "re": 0.06451612903225806, "f": 0.06349206349206349, "fn": 29.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows three women sitting on a couch in front of a window. They are all smiling and looking at something in front of them. The window is open and there is a cat sitting on the windowsill. The room is well lit and there are plants on the windowsill.\n\nThe image is"}, "568318": {"image_id": 568318, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.19847906537590718, "Bleu_3": 0.15489634938591235, "Bleu_4": 0.1093421350441957, "METEOR": 0.2325026734725464, "ROUGE_L": 0.28126801152737757, "CIDEr": 2.847313210491216e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2631578947368421, "f": 0.2040816326530612, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a calendar on a table with a bottle of wine and two glasses. There are several people standing around the table, looking at the calendar. The calendar appears to be a monthly calendar, with each day of the month marked. The bottle of wine is on the right side of the table"}, "281609": {"image_id": 281609, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.07587175464144183, "Bleu_4": 9.619833423045096e-06, "METEOR": 0.18315862938807742, "ROUGE_L": 0.1821983273596177, "CIDEr": 5.414894746005747e-12, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.3125, "f": 0.2380952380952381, "fn": 11.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a small room with a table in the center of the room. On the table are several stuffed animals, including a teddy bear, a rabbit, and a cat. There are also several books and toys on the table. The walls of the room are painted a light blue color and there"}, "546826": {"image_id": 546826, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.24330354977564592, "Bleu_3": 0.11211985653831966, "Bleu_4": 1.3616513966805828e-05, "METEOR": 0.25418728267126706, "ROUGE_L": 0.2809210526315789, "CIDEr": 1.702171098741986e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image is a table with a red scissors, a green marker, and a white sheet of paper. The scissors are open and the marker is on top of the paper. The paper is blank and there are no other objects on the table."}, "21029": {"image_id": 21029, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.09288407280072536, "Bleu_3": 5.60482607100497e-07, "Bleu_4": 1.3839209880654026e-09, "METEOR": 0.12369764291824933, "ROUGE_L": 0.21997836278398844, "CIDEr": 2.2233876206964197e-10, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a group of men playing baseball in a field. They are wearing baseball uniforms and helmets, and one of them is holding a bat. The field is surrounded by a fence, and there are people watching from the sidelines. The sky is cloudy and there are trees in"}, "518262": {"image_id": 518262, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.11531640100118269, "Bleu_3": 0.0661213089813225, "Bleu_4": 8.952677771744006e-06, "METEOR": 0.17401295628176627, "ROUGE_L": 0.23461538461538461, "CIDEr": 1.2447563928727511e-09, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.19047619047619047, "f": 0.16, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on the sidewalk, looking at a small dog that is wearing a rainbow collar\n\nThe people in the image are wearing colorful clothing and hats, and the dog is wearing a rainbow collar. The image is taken on a sun"}, "427823": {"image_id": 427823, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.2247332874836235, "Bleu_3": 0.15620909290310706, "Bleu_4": 0.11003640569767388, "METEOR": 0.28417600238755425, "ROUGE_L": 0.31642651296829977, "CIDEr": 3.0781496614939868e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man sitting at a table in a restaurant. He is wearing a black shirt and has a glass of wine in front of him. There are other people sitting at tables nearby, and the room has a modern decor with white walls and wooden floors.\n\nThe man in the image is"}, "484415": {"image_id": 484415, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.10067569617030046, "Bleu_4": 1.2138611630520416e-05, "METEOR": 0.18259256213650119, "ROUGE_L": 0.2901307966706302, "CIDEr": 5.22367614476229e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.14285714285714285, "f": 0.12765957446808512, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a person standing in front of a toilet with their hand on the handle. The toilet is white and has a seat and lid. The person is wearing a white shirt and pants. The floor is made of tiles and there is a sink in the background."}, "25282": {"image_id": 25282, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.10484363678213089, "Bleu_4": 0.06999971125156287, "METEOR": 0.2536590619015108, "ROUGE_L": 0.26704190118824267, "CIDEr": 2.58328552006129e-11, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2, "f": 0.1923076923076923, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman sitting on the back of a green motorcycle. She is wearing a black shirt and jeans, and has a helmet on her head. The motorcycle has a black seat and a white gas tank. The woman is smiling and has her hands on the handlebars. The"}, "246597": {"image_id": 246597, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.16917307297107978, "Bleu_3": 0.11744538443824148, "Bleu_4": 0.08884513024805765, "METEOR": 0.24101014021745365, "ROUGE_L": 0.24610951008645532, "CIDEr": 8.074375886459688e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a man in a white shirt and black pants playing tennis on a sandy court. He is holding a tennis racket in his right hand and his left hand is on his hip. The court is lined with white lines and there are two umpires standing on either side of the court"}, "246076": {"image_id": 246076, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.17504208247906033, "Bleu_3": 8.330473575461913e-07, "Bleu_4": 1.8260027717719216e-09, "METEOR": 0.24299268935777085, "ROUGE_L": 0.24956165984804207, "CIDEr": 2.356622853889495e-13, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.25, "f": 0.18604651162790697, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of a living room with a couch, a cat, and a dog. The cat is lying on the couch and the dog is sitting next to it. The room is well lit and there are no other objects in the room.\n\nThe cat is a medium s"}, "351589": {"image_id": 351589, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.18563715382699006, "Bleu_3": 0.13583417042986284, "Bleu_4": 0.09815577016450608, "METEOR": 0.22085566737404272, "ROUGE_L": 0.2492702860478692, "CIDEr": 8.323318167346722e-15, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2857142857142857, "f": 0.24489795918367344, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a bench sitting in front of a building with a window on the side. The bench is made of metal and has a green plant growing on it. The building has a door and a window on the side. The ground is covered in dirt and there are no other objects in the image."}, "425481": {"image_id": 425481, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.10497813183144382, "Bleu_3": 6.123299201527432e-07, "Bleu_4": 1.4866702340294172e-09, "METEOR": 0.12076948019019788, "ROUGE_L": 0.1450653983353151, "CIDEr": 5.762441585056366e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The man in the image is wearing a red and blue superhero costume, including a cape, boots, and gloves. He is standing in front of a large window with a city skyline visible in the background. The man is holding a red and blue cape in one hand and gest"}, "33325": {"image_id": 33325, "Bleu_1": 0.37037037036351167, "Bleu_2": 0.3446709203311237, "Bleu_3": 0.2929091080720899, "Bleu_4": 0.25805824571925506, "METEOR": 0.2731778987846438, "ROUGE_L": 0.38730158730158726, "CIDEr": 1.1612566697612861e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on a bench in front of a tiled wall. The wall has a mural of a man and woman standing on a beach, with a large wave in the background. The people are dressed in casual clothing and are looking at something on their phones. There"}, "76307": {"image_id": 76307, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.327592846633487, "Bleu_3": 0.17655420655385867, "Bleu_4": 1.950799577836031e-05, "METEOR": 0.2707604873921937, "ROUGE_L": 0.2713120830244626, "CIDEr": 2.147861128817388e-06, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.09523809523809523, "f": 0.0784313725490196, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows two sandwiches on a plate with lettuce and tomato on top\n\nThe sandwiches are cut in half and there is a fork on the side of the plate. The plate is on a table with a white background."}, "183014": {"image_id": 183014, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.18164975363435543, "Bleu_3": 0.0853882118511922, "Bleu_4": 1.0460383410651184e-05, "METEOR": 0.1895559950359613, "ROUGE_L": 0.2658241638522715, "CIDEr": 7.076752450575165e-12, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.14285714285714285, "f": 0.1395348837209302, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person holding a plate of food in their hand. The food is a pastry with a sweet filling and a crispy exterior. The person is standing in front of a crowd of people, who are all looking at the food. The sky is blue and there are clouds in the background."}, "18750": {"image_id": 18750, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.0903507902886997, "Bleu_3": 5.540397074769196e-07, "Bleu_4": 1.3792125616624927e-09, "METEOR": 0.15292672285109812, "ROUGE_L": 0.1937738246505718, "CIDEr": 9.242231967478021e-11, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.47058823529411764, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.8, "f": 0.47058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a large, ornate building with a steeple on top. The building is covered in snow and the trees are bare. The sky is blue and there are clouds in the background.\n\nThe building is a cathedral, with a large steeple on top. The building is covered in"}, "488030": {"image_id": 488030, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.1412331707135344, "Bleu_3": 7.569000412718941e-07, "Bleu_4": 1.7618777384959807e-09, "METEOR": 0.17686597513358338, "ROUGE_L": 0.1601049868766404, "CIDEr": 4.501009017578168e-10, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2631578947368421, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two zebras grazing on a grassy plain. They are standing in a line, with their heads down and their tails swishing behind them. The zebras are black and white striped, with long necks and legs. The background is a clear blue sky with some clouds."}, "276631": {"image_id": 276631, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.16256402218685123, "Bleu_3": 0.13602535177985353, "Bleu_4": 0.11649284258883924, "METEOR": 0.23850980295700064, "ROUGE_L": 0.29985955056179775, "CIDEr": 5.232356039945343e-07, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bowl of pasta salad with vegetables and cheese. The pasta is cooked and has a crunchy texture. The vegetables are chopped and have a fresh appearance. The cheese is shredded and has a melted appearance. The overall appearance of the"}, "449976": {"image_id": 449976, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.11952367853238388, "Bleu_4": 1.3594021798767565e-05, "METEOR": 0.22595309093058438, "ROUGE_L": 0.25894481503941785, "CIDEr": 2.110440173915748e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image is of a bench with a green plastic bottle sitting on it. The bottle is sitting on the bench with its cap open, and there is a small amount of water in it. The bench is made of metal and has a black and white striped pattern on it. The background"}, "312870": {"image_id": 312870, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.09712858623387621, "Bleu_3": 5.697810303144272e-07, "Bleu_4": 1.3868787330575517e-09, "METEOR": 0.154700530283489, "ROUGE_L": 0.17722254503195814, "CIDEr": 3.750305012727822e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.26666666666666666, "f": 0.2285714285714286, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a street with several cars parked on the side of the road. There are buildings on either side of the street, with windows and balconies visible. The sky is blue and there are clouds in the distance.\n\nThe image is taken from a high vantage point, looking down on the"}, "574810": {"image_id": 574810, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.10132945277550723, "Bleu_4": 0.06823252823824055, "METEOR": 0.20625501060058576, "ROUGE_L": 0.2501464557703574, "CIDEr": 5.486429318953789e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.17391304347826086, "f": 0.15094339622641512, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on a windowsill, looking out the window. The cat has a fluffy coat and is looking out the window with its ears perked up. The background is a cloudy sky with some sunlight peeking through the clouds. The cat's eyes are focused on something"}, "199358": {"image_id": 199358, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.07930515857033198, "Bleu_3": 0.04945382002622932, "Bleu_4": 6.978423773350046e-06, "METEOR": 0.20339410765506885, "ROUGE_L": 0.2445589919816724, "CIDEr": 1.5967660110238075e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.17391304347826086, "f": 0.15094339622641512, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a hotel room with a large bed, a desk, and a chair. The walls are painted a light yellow color and there is a large window with curtains. The room has a large mirror on the wall and a lamp on the desk. There are two suitcases on the bed and"}, "540859": {"image_id": 540859, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.15508644003992356, "Bleu_3": 0.08115433313646976, "Bleu_4": 1.0498339569158865e-05, "METEOR": 0.20246129697639717, "ROUGE_L": 0.22775357809583074, "CIDEr": 1.2998933625763799e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a zebra standing in a grassy area. The zebra has a long, black and white striped body with a white belly and black stripes on its back. It has a long neck and legs, and its hooves are black and white. The zebra is"}, "374184": {"image_id": 374184, "Bleu_1": 0.13725490195809306, "Bleu_2": 0.09074852129550587, "Bleu_3": 5.518584262016769e-07, "Bleu_4": 1.3679192122845403e-09, "METEOR": 0.13412831096532862, "ROUGE_L": 0.18654434250764526, "CIDEr": 1.9781096390133443e-11, "SPICE": {"All": {"pr": 0.35, "re": 0.2692307692307692, "f": 0.3043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a bathroom with a toilet and sink. The walls are painted a light blue color and there is a floral pattern on the floor. The toilet is white and has a seat and lid. The sink is white and has a faucet and drain. There is a window"}, "382728": {"image_id": 382728, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.14254579382569355, "Bleu_3": 7.358334830308166e-07, "Bleu_4": 1.6801271827773928e-09, "METEOR": 0.2560703342800096, "ROUGE_L": 0.22195269860521533, "CIDEr": 4.22001016689899e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a train traveling down a railroad track. The train is made up of several black and white locomotives, each with a large cab on the front and a long, curved hood on the back. The train is pulling several cars filled with coal, which are being transported to a power"}, "414374": {"image_id": 414374, "Bleu_1": 0.39215686273740874, "Bleu_2": 0.3193129880065749, "Bleu_3": 0.21830768818150026, "Bleu_4": 0.12133650006096253, "METEOR": 0.26659787332610285, "ROUGE_L": 0.3051907442151345, "CIDEr": 2.1356717790091444e-10, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.19230769230769232, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of cows grazing in a field. The cows are black and white and have brown spots on their coats. They are standing in a line, with their heads down and their tails up. The grass in the field is green and the sky is blue.\n\nThe"}, "367535": {"image_id": 367535, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 1.0024266962117514e-06, "Bleu_4": 2.187390385842088e-09, "METEOR": 0.18485596680453656, "ROUGE_L": 0.2543180464562239, "CIDEr": 3.114441900148563e-08, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09523809523809523, "f": 0.0851063829787234, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image is of a bedroom with a bed, a dresser, and a window. The walls are painted white and there are curtains on the windows. The bed has a pink and purple comforter and pillows. There is a bookshelf on the wall with books on it."}}}