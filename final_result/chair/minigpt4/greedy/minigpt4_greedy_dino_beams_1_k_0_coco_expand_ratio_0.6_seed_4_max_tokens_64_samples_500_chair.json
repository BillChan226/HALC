{"overall": {"Bleu_1": 0.2563457716618978, "Bleu_2": 0.16689676900483857, "Bleu_3": 0.10364375458121025, "Bleu_4": 0.06464922443393373, "METEOR": 0.2087719229977473, "ROUGE_L": 0.2465135161486483, "CIDEr": 0.0002987494234417673, "SPICE": 0.16912441555535612}, "imgToEval": {"504142": {"image_id": 504142, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.09372067452880309, "Bleu_4": 1.1566104086421967e-05, "METEOR": 0.1854943034287041, "ROUGE_L": 0.25957446808510637, "CIDEr": 1.7318494918126989e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.1724137931034483, "f": 0.18867924528301888, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a dog sleeping on a couch with a blanket over its head. The dog is wearing a collar and tag. The couch is covered in a blanket and there are pillows on the floor. The room is dimly lit by a lamp on the table.\n\nThe"}, "49115": {"image_id": 49115, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.08206099398471602, "Bleu_3": 0.05027274032560819, "Bleu_4": 7.030700263657399e-06, "METEOR": 0.18121400792758113, "ROUGE_L": 0.20254565578306588, "CIDEr": 3.149386298461676e-12, "SPICE": {"All": {"pr": 0.037037037037037035, "re": 0.03333333333333333, "f": 0.03508771929824562, "fn": 29.0, "numImages": 1.0, "fp": 26.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a giraffe standing on a rock in a park. The giraffe is brown with spots on its back and neck. It has a long neck and legs and is looking up at the sky. There are trees in the background and a path leading to the right. The image is taken in"}, "328284": {"image_id": 328284, "Bleu_1": 0.1694915254208561, "Bleu_2": 0.12087736925536453, "Bleu_3": 6.352407958060766e-07, "Bleu_4": 1.4627051116544652e-09, "METEOR": 0.14800077159743866, "ROUGE_L": 0.2326975476839237, "CIDEr": 3.326052317731729e-16, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.16129032258064516, "f": 0.16666666666666669, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a woman in a red jacket and blue pants walking through the snow on a ski trail. She is holding a ski pole in her right hand and has a backpack on her back. The trees in the background are covered in snow and there is a small stream running through the middle of the image"}, "434662": {"image_id": 434662, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.10939874362111757, "Bleu_3": 6.383942191769577e-07, "Bleu_4": 1.5506492764453139e-09, "METEOR": 0.17642114401534603, "ROUGE_L": 0.1601049868766404, "CIDEr": 2.031636506628184e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.18518518518518517, "f": 0.1923076923076923, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person on skis, wearing a helmet and goggles, standing on a snowy road. The person is holding a ski pole in their left hand and has their right hand on their knee. The person is wearing a black and white jacket and black pants."}, "307166": {"image_id": 307166, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.17817416126992966, "Bleu_3": 0.12314407142557375, "Bleu_4": 1.5423454131176364e-05, "METEOR": 0.18012531027769588, "ROUGE_L": 0.24918300653594777, "CIDEr": 0.0002084726642527004, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.11764705882352941, "f": 0.08888888888888889, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a table with several pizzas on it. There are also some drinks and utensils on the table. The table is in a kitchen or dining area.\n\nThe image is in black and white."}, "386352": {"image_id": 386352, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.1428571428542566, "Bleu_3": 0.09473945732893252, "Bleu_4": 0.06521893536120389, "METEOR": 0.22192141673984064, "ROUGE_L": 0.19830949284785435, "CIDEr": 8.977910251066999e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a blue shirt and white shorts, and has a racket in her hand. There are several people in the background watching her play. The image is in color and appears to be taken from a live event."}, "74059": {"image_id": 74059, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.18504536999744126, "Bleu_3": 0.10961273969013748, "Bleu_4": 1.267661295444545e-05, "METEOR": 0.2346707734817482, "ROUGE_L": 0.2738496071829405, "CIDEr": 6.869316769929574e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11538461538461539, "f": 0.11320754716981132, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a tall, stone tower with a clock face on the front. The clock face has Roman numerals and hands. The tower is surrounded by a stone wall with a gate on the left side. The sky is blue and there are clouds in the background.\n\nThe image is taken at sunset,"}, "466882": {"image_id": 466882, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.10612555247189982, "Bleu_4": 0.06992338944679112, "METEOR": 0.20868829857557342, "ROUGE_L": 0.18496058217101274, "CIDEr": 5.493109592563511e-12, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.17857142857142858, "f": 0.2127659574468085, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image is of a tennis court with two players playing a match. The players are wearing white shirts and black shorts, and they are holding rackets. The court is made of blue and white tiles, and there are lines on the court to mark the boundaries of the game. The stands are"}, "264124": {"image_id": 264124, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.14280110945625535, "Bleu_3": 0.09406593130377755, "Bleu_4": 1.1475297679846863e-05, "METEOR": 0.17799603827339658, "ROUGE_L": 0.2544392801811465, "CIDEr": 2.476282649478198e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 10.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.7142857142857143, "f": 0.4761904761904762, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The man is wearing a black shirt and has a beard. He is holding a cell phone to his ear and smiling. The background is a city street with buildings and trees.\n\nThe man is wearing a black shirt and has a beard. He is holding a cell phone to his"}, "92205": {"image_id": 92205, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.22696949467552002, "Bleu_3": 0.17999901177222294, "Bleu_4": 0.14553476618419592, "METEOR": 0.2769827104679439, "ROUGE_L": 0.3038184836745988, "CIDEr": 6.336368949429674e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2777777777777778, "f": 0.24390243902439024, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5555555555555556, "f": 0.4166666666666667, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a man standing on the side of a road holding a stop sign. The road is empty and there are no other cars or pedestrians in sight. The sky is clear and blue, with a few clouds in the distance. The man is wearing a yellow vest and hard hat, and has"}, "34071": {"image_id": 34071, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.11952286093128565, "Bleu_3": 0.0641952261839719, "Bleu_4": 8.405394134956185e-06, "METEOR": 0.16143865940907343, "ROUGE_L": 0.20460644007155634, "CIDEr": 1.2284454922031396e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a car parked on the side of the road with the sun setting in the background. The car has two mirrors on the side, one with a reflection of the sun and the other with a reflection of the car. The image is taken at night with the headlights of the car illumin"}, "555066": {"image_id": 555066, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.20225995873532804, "Bleu_3": 0.16565038123296855, "Bleu_4": 0.1439023424524574, "METEOR": 0.2330410278979549, "ROUGE_L": 0.29389721627408993, "CIDEr": 2.4470319884049795e-12, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.3076923076923077, "f": 0.28571428571428575, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.5384615384615384, "f": 0.5833333333333334, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image shows a street with a few cars parked on the side of the road. There are buildings on either side of the street, with a few people walking on the sidewalk. The sky is cloudy and there are some trees in the background. The image is taken from a low angle, looking down the"}, "448786": {"image_id": 448786, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.21381869073854032, "Bleu_3": 0.13906381417319807, "Bleu_4": 0.08563831261527419, "METEOR": 0.21121004511848812, "ROUGE_L": 0.226906385616863, "CIDEr": 2.881000344682623e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 30.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.3333333333333333, "f": 0.3571428571428571, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The train is a high speed train that is designed to travel at speeds of up to 300 km/h. It has a sleek and modern design, with a white and blue body and a red and white stripe running along the side. The train has a large window on the front and a"}, "324308": {"image_id": 324308, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.06140634384744192, "Bleu_3": 4.224923263061475e-07, "Bleu_4": 1.1138202232666472e-09, "METEOR": 0.16350692371345082, "ROUGE_L": 0.15365239294710328, "CIDEr": 9.403439075201923e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a banana plant growing on a fence. The plant has green leaves and yellow bananas hanging from it. The fence is made of wood and has a gate in the middle. The sky is blue and there are clouds in the background.\n\nThe image is taken from a bird'"}, "42837": {"image_id": 42837, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.14457494718760727, "Bleu_4": 0.10825902502501075, "METEOR": 0.24828858609901316, "ROUGE_L": 0.22775357809583074, "CIDEr": 3.7146994945892915e-08, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.06666666666666667, "f": 0.07142857142857144, "fn": 28.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a wetsuit and a helmet, and is standing on the board with his feet on the ground. The wave is crashing down on the surfer, and the surfer is jumping off the"}, "314690": {"image_id": 314690, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.144034534600296, "Bleu_4": 0.11571450126317166, "METEOR": 0.1979135340648206, "ROUGE_L": 0.27774615822424586, "CIDEr": 3.533917440046912e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.23076923076923078, "f": 0.21428571428571427, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a living room with a couch, coffee table, and television. There is also a window in the background.\n\nThe walls are painted white and there are some posters on the wall. The floor is made of hardwood and there is a rug on it. The room is well lit and"}, "263780": {"image_id": 263780, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.11673403265989704, "Bleu_3": 6.399271623835167e-07, "Bleu_4": 1.5055852953281506e-09, "METEOR": 0.16386554190070104, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.3532983063550628e-12, "SPICE": {"All": {"pr": 0.21875, "re": 0.23333333333333334, "f": 0.22580645161290322, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows two elephants standing in a dirt area with a small pond in the background. The elephants are both brown with a small white patch on their backs. They are standing next to each other and appear to be looking at something in the distance. The image is taken from a bird"}, "256035": {"image_id": 256035, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1010152544531381, "Bleu_3": 6.010242872773113e-07, "Bleu_4": 1.4739391640949855e-09, "METEOR": 0.17650782012087146, "ROUGE_L": 0.2622527944969905, "CIDEr": 7.537216602072904e-09, "SPICE": {"All": {"pr": 0.08, "re": 0.06896551724137931, "f": 0.07407407407407408, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a person wearing a black and white ski suit, black gloves, and a black helmet, standing on skis with poles in hand, ready to start a race on a snowy track. The person is wearing a black and white ski suit, black gloves, and a black"}, "413900": {"image_id": 413900, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.15007505629280368, "Bleu_3": 0.10877430749251783, "Bleu_4": 0.07843772989138478, "METEOR": 0.16456765335096257, "ROUGE_L": 0.2848249027237354, "CIDEr": 7.415450114683454e-06, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2222222222222222, "f": 0.2608695652173913, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a group of people standing around a table with a projector on it. They are all wearing casual clothing and looking at the screen. There are plants on the table and in the background."}, "357978": {"image_id": 357978, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.11053526637390183, "Bleu_3": 0.060563785357161955, "Bleu_4": 8.00868696488474e-06, "METEOR": 0.15294787553014438, "ROUGE_L": 0.19709208400646203, "CIDEr": 3.684773953319841e-13, "SPICE": {"All": {"pr": 0.24242424242424243, "re": 0.2857142857142857, "f": 0.26229508196721313, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.45454545454545453, "f": 0.3846153846153846, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a woman standing in front of a white wall with a red and blue striped shirt on. She is holding a white cane in her right hand and has a look of concentration on her face. There are several other people in the room, including a man sitting on a couch and a woman"}, "521874": {"image_id": 521874, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.1480872194371519, "Bleu_3": 0.09273296682831636, "Bleu_4": 0.06199079070677168, "METEOR": 0.2014213706085133, "ROUGE_L": 0.20504201680672268, "CIDEr": 9.37220973773723e-14, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.19230769230769232, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a blue and red train traveling along a track next to a building with a red roof and white walls\n\nThe train is traveling in the direction of the camera, with the front of the train facing the viewer. The train has a red and blue body with a white roof and red whe"}, "49517": {"image_id": 49517, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.1506556909135452, "Bleu_4": 1.65120006937825e-05, "METEOR": 0.22274698586489525, "ROUGE_L": 0.20158625247851947, "CIDEr": 1.5397049373643555e-09, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.15789473684210525, "f": 0.125, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a stove, sink, and refrigerator. There are pots and pans on the stove and a bowl of food on the counter. The floor is made of hardwood and there are cabinets above the counter. The walls are painted white and there are windows"}, "67616": {"image_id": 67616, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.194191754997615, "Bleu_3": 0.15265764885871064, "Bleu_4": 0.12861839592392574, "METEOR": 0.20337074098170932, "ROUGE_L": 0.2597126130920702, "CIDEr": 3.053399295623743e-11, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.125, "f": 0.10256410256410256, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a street with tall buildings on either side. There are cars parked on the side of the street and people walking on the sidewalk. The buildings are made of brick and have large windows on the upper floors. There are also trees and plants in the area.\n\nThe image is taken from"}, "154071": {"image_id": 154071, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.19069251784561925, "Bleu_3": 0.08819903067638854, "Bleu_4": 1.0717587139270824e-05, "METEOR": 0.19043103062887856, "ROUGE_L": 0.17134831460674158, "CIDEr": 2.7717290286747008e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17857142857142858, "f": 0.17241379310344826, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a baseball game in progress on a field with a large crowd of people watching from the stands. The players are wearing uniforms with the names of their teams on the back. The umpire is standing behind home plate, ready to call the next pitch. The scoreboard in the background shows the"}, "351133": {"image_id": 351133, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.1103716852403353, "Bleu_4": 1.293698116812338e-05, "METEOR": 0.2509548075102367, "ROUGE_L": 0.2544392801811465, "CIDEr": 1.9423778395648542e-10, "SPICE": {"All": {"pr": 0.20588235294117646, "re": 0.2916666666666667, "f": 0.2413793103448276, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.45454545454545453, "f": 0.3703703703703703, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The woman in the image is standing in front of a sink in a bathroom. She is holding a toothbrush in her hand and smiling at the camera. The sink is made of white porcelain and has a faucet on the right side. There are two mirrors on the walls above"}, "270165": {"image_id": 270165, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.13682045713838573, "Bleu_4": 1.5044258140708106e-05, "METEOR": 0.24434259857692406, "ROUGE_L": 0.33165048543689324, "CIDEr": 5.306690286201699e-10, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.30434782608695654, "f": 0.2978723404255319, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a red cow with a pink hat on its head standing on the sidewalk in front of a building. The cow is wearing a pink hat and has a pink nose. The building has a red and white striped awning over the door. The street is lined with tall trees"}, "200250": {"image_id": 200250, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.13609999140195853, "Bleu_4": 0.08513012360711482, "METEOR": 0.16608646448395192, "ROUGE_L": 0.20911895783339046, "CIDEr": 1.1758827090291124e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2222222222222222, "f": 0.22641509433962265, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a woman walking down the street with a large billboard on the side of a building. The billboard has a picture of a man on it, with the words \"the man on the moon\" written underneath. The woman is wearing a black jacket and jeans, and has a"}, "302990": {"image_id": 302990, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.1312556959732308, "Bleu_4": 0.11143093224782376, "METEOR": 0.24317728248409298, "ROUGE_L": 0.31063017186505404, "CIDEr": 8.802201190947302e-09, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.11764705882352941, "f": 0.08888888888888889, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and has his arms outstretched as he jumps off the wave. The wave is white and has a lot of foam on it. There are other surfers in the"}, "147425": {"image_id": 147425, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.12701286121266542, "Bleu_4": 1.422798090025241e-05, "METEOR": 0.17780507586506006, "ROUGE_L": 0.21908296420447745, "CIDEr": 5.038687794320333e-12, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a cat sitting on a black suitcase. The cat is brown and has a white patch on its forehead. The suitcase is black and has a handle on top. There is a small white patch on the bottom of the suitcase. The cat is looking up at the camera.\n\nThe"}, "152245": {"image_id": 152245, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.24414717515239445, "Bleu_3": 0.16945554045207906, "Bleu_4": 0.13205712377262024, "METEOR": 0.26712958532942727, "ROUGE_L": 0.30860033726812813, "CIDEr": 2.1136594064531496e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in a line at an airport. They are all wearing luggage and looking at their phones. There are several suitcases on the ground in front of them. The airport has a large screen displaying flight information and a security checkpoint in the background."}, "191689": {"image_id": 191689, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.11375929179665137, "Bleu_3": 0.06415924230513619, "Bleu_4": 8.612596688347549e-06, "METEOR": 0.1541485401969367, "ROUGE_L": 0.2238532110091743, "CIDEr": 3.537330588081533e-11, "SPICE": {"All": {"pr": 0.15, "re": 0.16666666666666666, "f": 0.15789473684210525, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a brown bear standing on a rocky outcropping in a forest. The bear is looking down at the ground and appears to be sniffing something. The background is a mix of trees and rocks.\n\nThe image shows a brown bear standing on a rocky outcropping in a forest"}, "51484": {"image_id": 51484, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.1297498240245396, "Bleu_3": 0.08596517673031359, "Bleu_4": 0.05912090648432852, "METEOR": 0.22196266869483258, "ROUGE_L": 0.21095100864553315, "CIDEr": 1.8755456735288483e-13, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.16666666666666666, "f": 0.14035087719298245, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a couple walking on the beach with surfboards. They are standing on the sand and looking out at the ocean. The sky is blue and there are some clouds in the distance. The beach is lined with palm trees and there are some rocks in the foreground. The water is calm and"}, "66181": {"image_id": 66181, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.20870354281255962, "Bleu_3": 0.11586898532647615, "Bleu_4": 1.296835022155032e-05, "METEOR": 0.2167992361945687, "ROUGE_L": 0.20631341600901915, "CIDEr": 4.373139380136058e-14, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.1, "f": 0.08163265306122448, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.125, "f": 0.09090909090909091, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "The image shows a white frame with a black and white photo of a baby in it. The frame is sitting on a wooden table next to a vase with a plant in it. There is a white wall behind the table with a painting on it.\n\nThe image is of a baby in a black and white"}, "289263": {"image_id": 289263, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.121479758333828, "Bleu_4": 1.3901690971832786e-05, "METEOR": 0.233920950655921, "ROUGE_L": 0.26116207951070336, "CIDEr": 1.9645343574428458e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.21052631578947367, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The woman is standing on the beach holding a surfboard. She is wearing a bikini and has her hair tied back in a ponytail. The waves are crashing against the shore in the background. The sky is blue and there are clouds in the distance. The woman is smiling and looks"}, "536426": {"image_id": 536426, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.17787191480959694, "Bleu_3": 0.10294507813494948, "Bleu_4": 1.176211650340224e-05, "METEOR": 0.21610987575817903, "ROUGE_L": 0.26236559139784943, "CIDEr": 3.081878002709606e-15, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08695652173913043, "f": 0.07999999999999999, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a red traffic cone on the side of the road in front of a house. The house is a two story building with a white roof and a black front door. There is a small tree in the front yard and a fire hydrant on the side of the road. The image is taken in the early"}, "377814": {"image_id": 377814, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1543033499589101, "Bleu_3": 0.10043712727569681, "Bleu_4": 0.06850641701834057, "METEOR": 0.1991017969672582, "ROUGE_L": 0.20158625247851947, "CIDEr": 2.8742679412015873e-06, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a box of donuts with different flavors and toppings. The box is made of cardboard and has a clear plastic window on the top. The donuts are arranged in rows on the tray inside the box. There are three different flavors of donuts, including chocolate fro"}, "411754": {"image_id": 411754, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.09078730341863991, "Bleu_4": 0.06316759949914878, "METEOR": 0.21815805004173028, "ROUGE_L": 0.23252858958068615, "CIDEr": 8.109751620043628e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.10714285714285714, "f": 0.14634146341463414, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The man in the red shirt is sitting on a bench, looking at his phone. He is wearing a red shirt and jeans, and has a beard. There are other people in the background, walking down the hallway. The walls are painted a light blue color, and there are windows"}, "340034": {"image_id": 340034, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.11741874968995038, "Bleu_4": 0.07744617268822214, "METEOR": 0.21412777952724937, "ROUGE_L": 0.29901960784313725, "CIDEr": 5.031392591993954e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a young boy sitting on the toilet, looking at his phone. He is wearing a pair of slippers and a pair of socks. The bathroom is dimly lit, with a window in the background. The boy is wearing a white shirt and black pants. The"}, "193050": {"image_id": 193050, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1182211503531082, "Bleu_3": 0.08130907204696847, "Bleu_4": 0.05697859151205073, "METEOR": 0.2427133366825213, "ROUGE_L": 0.25507765830346474, "CIDEr": 1.9287088163797375e-12, "SPICE": {"All": {"pr": 0.08, "re": 0.09090909090909091, "f": 0.0851063829787234, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a group of sheep grazing in a green field. The sheep are standing in a line, with their heads down and their tails hanging behind them. The fence in the background is made of wooden posts and barbed wire. The sky is clear and blue, with a few white clouds scattered"}, "217269": {"image_id": 217269, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.14527180078437643, "Bleu_3": 0.09211555193837166, "Bleu_4": 0.0619698937576483, "METEOR": 0.2644537921230868, "ROUGE_L": 0.25296208530805686, "CIDEr": 9.157023117345865e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.0967741935483871, "f": 0.10714285714285714, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a computer desk with a computer monitor, keyboard, and mouse on it. There are also two chairs in front of the desk. The walls are painted white and there are windows on the left and right sides of the room. The floor is made of wood and there are no other objects in"}, "437290": {"image_id": 437290, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.15569978882944752, "Bleu_3": 0.12230758461254293, "Bleu_4": 0.07701746258925352, "METEOR": 0.26547508733539227, "ROUGE_L": 0.2513243084167157, "CIDEr": 3.879514484106573e-12, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3157894736842105, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in a room. They are all wearing different costumes and some are holding props. There are several tables set up in the room with people sitting at them. There is a large screen in the background showing a video.\n\nThe image is taken from a bird's"}, "282928": {"image_id": 282928, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.20304239863369572, "Bleu_3": 0.14333375493847259, "Bleu_4": 0.0920588180270657, "METEOR": 0.19412578327430988, "ROUGE_L": 0.285427807486631, "CIDEr": 1.450804494030209e-07, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1111111111111111, "f": 0.12, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man holding a sandwich in his hand. The sandwich appears to be a hamburger with lettuce, tomato, and cheese on top. The man is wearing a white shirt and blue jeans. The background is a blue sky with some clouds."}, "188084": {"image_id": 188084, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 1.0257472592290205e-06, "Bleu_4": 2.2129782496476084e-09, "METEOR": 0.2683513516557679, "ROUGE_L": 0.308080808080808, "CIDEr": 1.1950729197189077e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.13043478260869565, "f": 0.12499999999999997, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a sandwich with a drink on the side. The sandwich has a meat and vegetable filling, and the drink is a cup of iced coffee. The table has a white tablecloth and a napkin. The background is a white tablecloth with a napkin. The foreground"}, "552320": {"image_id": 552320, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.142442462319253, "Bleu_3": 7.725775597136251e-07, "Bleu_4": 1.8096286076349793e-09, "METEOR": 0.16026407633737924, "ROUGE_L": 0.23135271807838179, "CIDEr": 1.5240660711278106e-07, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.16666666666666666, "f": 0.16393442622950818, "fn": 25.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows two men standing in a kitchen, one holding a large pizza in his hands and the other holding a knife. The pizza appears to be topped with various ingredients, including cheese, pepperoni, and vegetables. The men are smiling and appear to be enjoying"}, "530313": {"image_id": 530313, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.13608276348545723, "Bleu_3": 0.10158210507509738, "Bleu_4": 0.07968371423587568, "METEOR": 0.17515207882062572, "ROUGE_L": 0.2127164942461932, "CIDEr": 1.9490240274641767e-12, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09523809523809523, "f": 0.08888888888888889, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting on chairs in a room. They are all wearing suits and ties and appear to be in a meeting or conference. There are several people standing in the background, looking on. The room appears to be well lit and there are several windows on the walls. The"}, "242060": {"image_id": 242060, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.21808478994970526, "Bleu_3": 0.1346083645525044, "Bleu_4": 1.5916887131478695e-05, "METEOR": 0.22691536954608799, "ROUGE_L": 0.32685867381111855, "CIDEr": 3.4288341873993868e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.3076923076923077, "f": 0.2285714285714286, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a plate of cinnamon rolls on a wooden table with a teapot and cups on the side. There are also some lemons and herbs on the table. The background is a wooden floor with a rug on it."}, "391214": {"image_id": 391214, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 8.939035350783205e-07, "Bleu_4": 1.9744381169756647e-09, "METEOR": 0.17178903683150165, "ROUGE_L": 0.22235722964763066, "CIDEr": 2.7144299211755944e-10, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.13793103448275862, "f": 0.13793103448275862, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on the ocean. The surfer is wearing a wetsuit and has a board under their arm. The wave is large and white, with foam on top. The sky is blue and cloudy, with a few clouds visible in the distance. The beach"}, "482367": {"image_id": 482367, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.07926525909642891, "Bleu_4": 9.990095999341766e-06, "METEOR": 0.2081703273199884, "ROUGE_L": 0.24007646463510626, "CIDEr": 9.58084258651178e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.17391304347826086, "f": 0.16326530612244897, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting on chairs in front of a tennis court. They are all wearing tennis shoes and holding rackets. One of them is holding a tennis ball in his hand. The image is in black and white.\n\nThe image shows a group of people sitting on chairs"}, "402334": {"image_id": 402334, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.161880977056518, "Bleu_3": 7.95785637725362e-07, "Bleu_4": 1.772982824869927e-09, "METEOR": 0.18829946481985663, "ROUGE_L": 0.21863799283154117, "CIDEr": 1.8432631645980636e-13, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.1, "f": 0.10169491525423728, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a large brick building with a steeple on top. The building has a large stained glass window on the front and a small bell tower on top. The sky is blue and there are clouds in the background.\n\nThe building appears to be a church or other religious institution. The stained"}, "469398": {"image_id": 469398, "Bleu_1": 0.15094339622356714, "Bleu_2": 0.0933181271719728, "Bleu_3": 0.05547797716282366, "Bleu_4": 7.644480232985446e-06, "METEOR": 0.2581833162471724, "ROUGE_L": 0.21266705403834982, "CIDEr": 3.698217437242446e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.12, "f": 0.12244897959183673, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man holding a baby in his arms while looking at a cell phone. The baby is lying in a crib with a blanket over it. The man is wearing a white shirt and pants, and the baby is wearing a white onesie. The background is a hospital room with"}, "316648": {"image_id": 316648, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.0799063530041829, "Bleu_4": 1.0207315006261666e-05, "METEOR": 0.21952403715545898, "ROUGE_L": 0.23797139141742527, "CIDEr": 8.161836907164866e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people walking down a street in a city. They are all wearing sunglasses and carrying bags. There are tall buildings on either side of the street, with signs and advertisements on them. The street is lined with cars and buses, and there are ped"}, "254004": {"image_id": 254004, "Bleu_1": 0.15686274509496353, "Bleu_2": 0.1252448582145496, "Bleu_3": 0.08618888098293648, "Bleu_4": 0.060433552207849656, "METEOR": 0.20111545540233045, "ROUGE_L": 0.19513755598208574, "CIDEr": 2.984637704995486e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14285714285714285, "f": 0.16, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people loading luggage onto a truck. The truck is parked on the side of a runway, and there are other vehicles and people in the background. The sky is cloudy and there is a plane in the distance.\n\nThe image is in black and white"}, "399369": {"image_id": 399369, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.142442462319253, "Bleu_3": 7.725775597136251e-07, "Bleu_4": 1.8096286076349793e-09, "METEOR": 0.21607373746171374, "ROUGE_L": 0.27619663648124193, "CIDEr": 9.68366532925622e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.1935483870967742, "f": 0.21818181818181817, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a person playing frisbee on a sandy beach. The person is wearing a black and white striped shirt and black pants. They are running towards the camera with their arms outstretched, holding a frisbee in their hand. The sky is blue and there"}, "206838": {"image_id": 206838, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 0.06474337870309639, "Bleu_4": 8.764094705114603e-06, "METEOR": 0.22215898460266248, "ROUGE_L": 0.26940063091482647, "CIDEr": 3.241192455424498e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.11428571428571428, "f": 0.13114754098360656, "fn": 31.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two women on horseback in the water. They are wearing bikinis and sunglasses. The horses are brown and white. The sky is blue and there are mountains in the background.\n\nThe image is taken from the perspective of the horses. The women are standing in the"}, "146672": {"image_id": 146672, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.08081586876451534, "Bleu_3": 5.040508737561903e-07, "Bleu_4": 1.2650662740672959e-09, "METEOR": 0.15811931459605455, "ROUGE_L": 0.14796846573681016, "CIDEr": 7.0310194088621345e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15, "f": 0.14634146341463414, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a clock, a glass of champagne, and a vase with flowers. The clock is in the center of the image, with the champagne glass and vase on either side of it. The clock has two hands, one pointing to the hour and the other pointing to the minute. The champ"}, "431256": {"image_id": 431256, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1577557537051747, "Bleu_3": 0.11429850643054774, "Bleu_4": 0.08835657960756262, "METEOR": 0.23657727143062462, "ROUGE_L": 0.23047858942065497, "CIDEr": 3.395155078706303e-12, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.11538461538461539, "f": 0.13953488372093026, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.23076923076923078, "f": 0.3157894736842105, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person on a snowboard jumping over a ramp in the snow. The person is wearing a black jacket and black pants, and has a black helmet on their head. The ramp is made of wood and has a white surface. The background is a mountain range with snow"}, "506454": {"image_id": 506454, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.1187339225343928, "Bleu_3": 0.06352270457072846, "Bleu_4": 8.300386118896969e-06, "METEOR": 0.23272467293396656, "ROUGE_L": 0.22628510863804976, "CIDEr": 3.977767492500717e-10, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a wooden bench in the middle of a grassy area. The bench is surrounded by trees and there are no other objects in the image. The sky is blue and there are no clouds. The grass is green and there are no other plants in the image. The image is taken from a bird"}, "212384": {"image_id": 212384, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.19507682662422146, "Bleu_3": 0.12191693142366875, "Bleu_4": 1.4499467512222074e-05, "METEOR": 0.2691096687449721, "ROUGE_L": 0.2924657534246575, "CIDEr": 1.0216074294616455e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.14285714285714285, "f": 0.15094339622641512, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image is a cake with a zebra and a giraffe on it. The cake is brown and has a zebra and a giraffe on it. The zebra and giraffe are made of fondant and are brown in color. The cake is decorated with"}, "181969": {"image_id": 181969, "Bleu_1": 0.13461538461279587, "Bleu_2": 1.6246591474205239e-09, "Bleu_3": 3.751326272327691e-12, "Bleu_4": 1.8117138691105227e-13, "METEOR": 0.13804574797361133, "ROUGE_L": 0.15024630541871922, "CIDEr": 4.1571598889283864e-13, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image is a brown and white dog lying on its side on a couch. The dog is wearing a collar and has its paws tucked under its body. The dog's eyes are closed and it appears to be sleeping. The couch is a light brown color and has a pattern"}, "450889": {"image_id": 450889, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.174582229926461, "Bleu_3": 0.13370981749106947, "Bleu_4": 0.109436018609632, "METEOR": 0.25284064233964054, "ROUGE_L": 0.30619074177356387, "CIDEr": 1.004559739362251e-10, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.13043478260869565, "f": 0.10526315789473685, "fn": 20.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a fireplace, holding a remote control in his hand. The man is wearing a white shirt and black pants, and has a beard. The fireplace has a large television on top of it, and there are several books and other objects on the mant"}, "84073": {"image_id": 84073, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.09108032686789493, "Bleu_3": 5.494899059541206e-07, "Bleu_4": 1.356503033114134e-09, "METEOR": 0.13985352860333075, "ROUGE_L": 0.21131639722863746, "CIDEr": 2.34945879445074e-11, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09090909090909091, "f": 0.08163265306122448, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a refrigerator with a handle on the door. The handle is made of metal and has a small hole in the center. There is a small keyhole on the handle. The refrigerator is white and has a small window on the top. There is a small shelf on the"}, "293207": {"image_id": 293207, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.17583479290167828, "Bleu_3": 0.08890352562172174, "Bleu_4": 1.1306342156768618e-05, "METEOR": 0.16429991007761247, "ROUGE_L": 0.28010204081632656, "CIDEr": 6.0870472427612945e-05, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of people playing a game of frisbee on a grassy field. They are wearing green shirts and white pants, and one of them is holding a frisbee. The sun is shining down on them, casting a warm glow over the scene."}, "431691": {"image_id": 431691, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.10033557298297395, "Bleu_4": 1.1749577059992224e-05, "METEOR": 0.18448795852134953, "ROUGE_L": 0.20460644007155634, "CIDEr": 2.740981824980391e-13, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man and a woman standing outside, looking at something on the ground. The man is holding a piece of bread in his hand and the woman is holding a plate in her hand. They are both wearing casual clothing and the man has a beard. The background is a stone wall with"}, "218470": {"image_id": 218470, "Bleu_1": 0.15094339622356714, "Bleu_2": 0.07619393177449452, "Bleu_3": 0.04846447707252927, "Bleu_4": 6.907567655081503e-06, "METEOR": 0.1856819937808974, "ROUGE_L": 0.2083096186681844, "CIDEr": 3.808524938339585e-11, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.2, "f": 0.1639344262295082, "fn": 20.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a street light on the corner of a busy street. The light is mounted on a pole and has a red and white striped canopy. The pole is made of metal and has a ladder leaning against it. There are several cars parked on the street and a few pedestrians"}, "9050": {"image_id": 9050, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.13187609467625871, "Bleu_3": 7.338824344329119e-07, "Bleu_4": 1.741216427287497e-09, "METEOR": 0.16462093862815885, "ROUGE_L": 0.26390605686032137, "CIDEr": 2.415586738830156e-08, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.03333333333333333, "f": 0.03846153846153846, "fn": 29.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a table set with a variety of food and drinks. There are several plates of food, including roasted vegetables, meat, and cheese. There are also several glasses of wine and beer on the table. The tablecloth is white and the chairs are wooden."}, "390769": {"image_id": 390769, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1458649914948234, "Bleu_3": 7.733595213409628e-07, "Bleu_4": 1.7905355543488007e-09, "METEOR": 0.19270045398092173, "ROUGE_L": 0.20013123359580048, "CIDEr": 1.3395607092552743e-09, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.25806451612903225, "f": 0.2807017543859649, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.5833333333333334, "f": 0.5599999999999999, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The woman is standing on the sidewalk, looking at her phone. She is wearing a black shirt and jeans. The building behind her has a green awning over the door.\n\nThe woman is standing on the sidewalk, looking at her phone. She is wearing a black shirt and"}, "175718": {"image_id": 175718, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.24866794885861784, "Bleu_3": 0.14112555009560282, "Bleu_4": 0.08991602966703008, "METEOR": 0.22778191019701563, "ROUGE_L": 0.2827814569536423, "CIDEr": 3.5688516207283654e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.0967741935483871, "f": 0.10714285714285714, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a pizza on a wooden cutting board with a beer bottle next to it. The pizza has cheese, pepperoni, and onions on it. The beer bottle has a label that reads \"Bud Light.\" There is a coffee mug on the cutting board as"}, "288430": {"image_id": 288430, "Bleu_1": 0.15999999999680004, "Bleu_2": 0.09897433185907904, "Bleu_3": 0.05887550428177755, "Bleu_4": 8.117578843784567e-06, "METEOR": 0.12618296529968454, "ROUGE_L": 0.1586475942782835, "CIDEr": 3.4975315139963614e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on the beach, holding kites. The kites are made of colorful fabric and have long tails that are attached to the ground. The people are wearing sunglasses and hats to protect themselves from the sun. The sky is clear and blue, with"}, "568150": {"image_id": 568150, "Bleu_1": 0.41509433961480957, "Bleu_2": 0.2963248521365562, "Bleu_3": 0.15100754859324209, "Bleu_4": 1.6199682095720423e-05, "METEOR": 0.23492799972342274, "ROUGE_L": 0.32927667091961915, "CIDEr": 5.473457278344034e-08, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3, "f": 0.24489795918367346, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are white and the floor is made of tile. There is a window on the left side of the room that lets in natural light. The toilet is in the corner of the room and the sink is on the"}, "200109": {"image_id": 200109, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.20952908872569917, "Bleu_3": 0.13106438047696783, "Bleu_4": 0.08773393530881987, "METEOR": 0.23140788863929357, "ROUGE_L": 0.29550173010380626, "CIDEr": 1.4295102187505353e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person holding a cell phone with a pizza on it. The person is sitting in a chair and looking at the phone. The pizza has cheese and pepperoni on it. The background is a dark blue color."}, "292617": {"image_id": 292617, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.12043890313249785, "Bleu_4": 0.10068455695657638, "METEOR": 0.23152503478067377, "ROUGE_L": 0.29151732377538825, "CIDEr": 5.880954621835196e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a living room with a couch, coffee table, and television. There is a window on the left side of the room with curtains open. The room is well lit with natural light coming in from the window. The walls are painted white and the floor is made of hardwood. There is"}, "467990": {"image_id": 467990, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.13608276348545723, "Bleu_3": 7.043309782608963e-07, "Bleu_4": 1.6100218008380818e-09, "METEOR": 0.242997933983157, "ROUGE_L": 0.21542083578575633, "CIDEr": 6.161652764663827e-13, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.21052631578947367, "f": 0.17777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a train traveling on the tracks at a high speed. The train is yellow and has a number on the side. There are people standing on the platform and looking at the train as it passes by. The train is traveling in the direction of the tracks.\n\nThe train is traveling at"}, "443713": {"image_id": 443713, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.16968474448956103, "Bleu_3": 0.11198948449446593, "Bleu_4": 0.07697823272799358, "METEOR": 0.26794434780349874, "ROUGE_L": 0.3132795304475422, "CIDEr": 4.1376626639183674e-07, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.23529411764705882, "f": 0.16666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people skateboarding on a street. They are wearing various types of clothing, including t-shirts, hoodies, and jeans. One person is doing a trick on the skateboard, while the others watch. There are several people in the background"}, "365129": {"image_id": 365129, "Bleu_1": 0.35714285713647964, "Bleu_2": 0.27914526311451127, "Bleu_3": 0.17938064677084012, "Bleu_4": 0.12148431820733999, "METEOR": 0.262718314112279, "ROUGE_L": 0.2576946288473144, "CIDEr": 9.882251250951697e-12, "SPICE": {"All": {"pr": 0.16, "re": 0.21052631578947367, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a body of water with boats in the foreground and a sunset in the background. The sky is cloudy with a few stars visible. The water is calm and there are no waves. The boats are small and white. The sun is setting behind the mountains in the distance. The image is taken"}, "462904": {"image_id": 462904, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.18173629401703337, "Bleu_4": 0.12575592044457554, "METEOR": 0.1748246418023142, "ROUGE_L": 0.26505276225946617, "CIDEr": 2.957789991828732e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.13793103448275862, "f": 0.17777777777777778, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a small black horse standing in front of a wooden fence. The horse is wearing a halter and has a tag on its neck. There are several tables and chairs set up outside under a wooden awning. The atmosphere is peaceful and serene.\n\nThe image shows a small"}, "3466": {"image_id": 3466, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.14285714285419707, "Bleu_3": 0.09540665858824407, "Bleu_4": 1.1721806731881168e-05, "METEOR": 0.19337598203087067, "ROUGE_L": 0.23303196230739842, "CIDEr": 5.754998647223567e-10, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.16666666666666666, "f": 0.1276595744680851, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image is of a person standing in front of a toilet. The person is wearing orange boots and has a backpack on their back. The toilet is made of red tiles and has a toilet seat and handle. There is a sink in the background with a faucet"}, "134760": {"image_id": 134760, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.10314212462370773, "Bleu_3": 6.138158588631339e-07, "Bleu_4": 1.505654929036229e-09, "METEOR": 0.17436189113983705, "ROUGE_L": 0.15641025641025638, "CIDEr": 2.1074349651884736e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.1875, "f": 0.14285714285714285, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people skiing down a snowy slope. There are several ski lifts in the background, and the trees are covered in snow. The sky is cloudy and there is a light snowfall.\n\nThe people in the image are wearing ski gear, including helmets"}, "364705": {"image_id": 364705, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.06989787123302858, "Bleu_4": 9.090870283563952e-06, "METEOR": 0.12575864462761505, "ROUGE_L": 0.14796846573681016, "CIDEr": 4.98426196012618e-12, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.1111111111111111, "f": 0.08333333333333334, "fn": 16.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of stuffed animals in various colors and sizes sitting on a blue carpet. They are all wearing pink bows and have white fur. The stuffed animals are arranged in a row, with some of them sitting on top of each other. There are also some stuffed animals sitting"}, "191296": {"image_id": 191296, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.1412673303879691, "Bleu_3": 7.314271888618252e-07, "Bleu_4": 1.6725758582722137e-09, "METEOR": 0.13212680175499172, "ROUGE_L": 0.18496058217101274, "CIDEr": 3.0978019890890327e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a rusty pipe lying on the ground in a field of tall grass. The pipe has a small hole in the side and is covered in dirt and debris. The background is a green field with tall grass and wildflowers growing in it.\n\nThe image is taken in a field"}, "457817": {"image_id": 457817, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1348399724902187, "Bleu_3": 0.08765119647604921, "Bleu_4": 0.059703448811482686, "METEOR": 0.18583762754453592, "ROUGE_L": 0.21682464454976302, "CIDEr": 3.9689951433031066e-14, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a tennis player hitting a ball on a tennis court. The player is wearing a white shirt and white shorts, and has a white racket in his hand. The ball is flying through the air and the player is running to hit it. The background is a blue and white tennis court with"}, "531995": {"image_id": 531995, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.18504536999744126, "Bleu_3": 0.13810339807225144, "Bleu_4": 0.10081339222579669, "METEOR": 0.2312726142054209, "ROUGE_L": 0.26468309313497596, "CIDEr": 6.427340256638132e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.19047619047619047, "f": 0.16666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a black and white cat sitting on the floor in front of a fireplace. The cat is wearing a pair of black boots and has a toy mouse in its mouth. There is a pile of toys on the floor next to the cat. The room is dimly lit and there"}, "276673": {"image_id": 276673, "Bleu_1": 0.3399999999932, "Bleu_2": 0.22038926600328315, "Bleu_3": 0.10039526102358762, "Bleu_4": 1.2113243442494859e-05, "METEOR": 0.24197999621752117, "ROUGE_L": 0.26228501228501233, "CIDEr": 9.882307102664397e-07, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.047619047619047616, "f": 0.04081632653061224, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a baseball game in progress on a field with a fence surrounding it. There are several players on the field, including one who is holding a bat and another who is catching a ball. The crowd is watching from the stands. The sky is clear and blue."}, "112800": {"image_id": 112800, "Bleu_1": 0.30508474575754096, "Bleu_2": 0.2614977317360467, "Bleu_3": 0.21251209914187338, "Bleu_4": 0.13606556771520278, "METEOR": 0.2975452022940595, "ROUGE_L": 0.2644576914144151, "CIDEr": 1.945106974905612e-11, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.17857142857142858, "f": 0.16393442622950818, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a small plane flying over a body of water with a small boat in the foreground. The plane is white with a red tail and has a large propeller on the back. The boat is red and has a white cabin on top. There are several trees in the background and a small island in the"}, "390685": {"image_id": 390685, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.15569978882944752, "Bleu_3": 0.11112381532950555, "Bleu_4": 0.0716728249212735, "METEOR": 0.2738368964033247, "ROUGE_L": 0.2978838849701574, "CIDEr": 9.06750575822441e-12, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.22727272727272727, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a stop sign on the side of the road. The sign is red and has the words \"stop\" written on it in white letters. There are cars parked on the side of the road and people walking in the background. The sky is blue and there are trees in the distance.\n\nThe"}, "195002": {"image_id": 195002, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.11740724488886634, "Bleu_3": 0.07943630475846972, "Bleu_4": 9.815577016450608e-06, "METEOR": 0.20823943970191305, "ROUGE_L": 0.2392156862745098, "CIDEr": 7.978560150172433e-14, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.10344827586206896, "f": 0.10526315789473684, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a young girl sitting at a table with a plate of food in front of her. She is wearing a princess dress and has a crown on her head. There are two other people in the background, one of whom is holding a camera. The walls of the room are painted with a floral"}, "104626": {"image_id": 104626, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.07830779525362613, "Bleu_4": 1.0001000249872884e-05, "METEOR": 0.21424169449846914, "ROUGE_L": 0.26704190118824267, "CIDEr": 3.4182331710496706e-11, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.1724137931034483, "f": 0.17857142857142858, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a blue and white truck parked on the side of a road. The truck has a canvas top and is parked next to a white tent. There are people standing around the truck and the tent. The image is taken in a park.\n\nThe truck is a 1"}, "291370": {"image_id": 291370, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.12126781251581158, "Bleu_3": 0.0665028658415205, "Bleu_4": 8.801997699590313e-06, "METEOR": 0.1398796815562912, "ROUGE_L": 0.2302631578947368, "CIDEr": 1.0776709819678641e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a building. They are all wearing hats and some are holding flowers. There is a horse and carriage in the background. The building appears to be a hotel or restaurant. The sky is blue and there are trees in the background."}, "434804": {"image_id": 434804, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.12166026344082319, "Bleu_4": 0.09306979428413018, "METEOR": 0.22913058928212793, "ROUGE_L": 0.22889305816135083, "CIDEr": 9.475205253350825e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.2857142857142857, "f": 0.1951219512195122, "fn": 10.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of giraffes standing in a fenced enclosure. They are all wearing collars and appear to be healthy. The fence is made of metal and has a gate that is open. There is a building in the background with a roof and windows. The building appears to"}, "143": {"image_id": 143, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.18504536999744126, "Bleu_3": 0.10961273969013748, "Bleu_4": 1.267661295444545e-05, "METEOR": 0.18979272147614948, "ROUGE_L": 0.21048999309868874, "CIDEr": 5.83652687410424e-12, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2857142857142857, "f": 0.25531914893617025, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of birds perched on a tree branch. They are all facing the same direction and appear to be looking at something in the distance. The birds are small and have a brown and white plumage. They are perched on the branch with their beaks open and their heads tilted"}, "249219": {"image_id": 249219, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.14519947954201504, "Bleu_4": 0.11823053204528565, "METEOR": 0.30813036543758804, "ROUGE_L": 0.317295188556567, "CIDEr": 9.24213174773982e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a purple and white double decker bus driving down a street lined with trees and houses. The bus has a destination sign on the front that reads \"Town Centre\". The road is lined with parked cars and there are pedestrians walking on the sidewalk. The sky is"}, "19716": {"image_id": 19716, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.07387419460030926, "Bleu_4": 9.42924728285967e-06, "METEOR": 0.23797035274676018, "ROUGE_L": 0.32275132275132273, "CIDEr": 1.5561652508662148e-10, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.3888888888888889, "f": 0.34146341463414637, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The man in the image is wearing a black suit and tie, and is standing in front of a large window. He is smiling and looking down at the ground. The building behind him appears to be a large office complex with many windows and a high ceiling. The man's hair is slicked"}, "517973": {"image_id": 517973, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.2550510152998425, "Bleu_3": 0.2025050394193863, "Bleu_4": 0.16392772674163156, "METEOR": 0.29132078283667184, "ROUGE_L": 0.4293255131964809, "CIDEr": 8.531495256897626e-08, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2608695652173913, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a white Volkswagen Beetle parked in a parking lot with other cars nearby. The car has a surfboard on top of it. The sky is cloudy and there are trees in the background.\n\nThe image is taken from a low angle, looking up at the car."}, "23019": {"image_id": 23019, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.11673403265989704, "Bleu_3": 6.399271623835167e-07, "Bleu_4": 1.5055852953281506e-09, "METEOR": 0.1690211595542265, "ROUGE_L": 0.14575866188769412, "CIDEr": 8.896239772749691e-13, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.20689655172413793, "f": 0.23076923076923075, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a city skyline at night with tall buildings and bright lights. There are cars and pedestrians on the street, and a busy intersection with traffic lights. The buildings are made of glass and steel, and there are many lights on the street. The image is taken from a high angle, looking"}, "177213": {"image_id": 177213, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.17496355305233344, "Bleu_3": 8.668270200700186e-07, "Bleu_4": 1.9398130305383298e-09, "METEOR": 0.23721804902686128, "ROUGE_L": 0.3242764323685765, "CIDEr": 8.312320420298482e-08, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.13333333333333333, "f": 0.126984126984127, "fn": 26.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a plate of pizza with cheese and tomato sauce on top. There are two glasses of beer on the table. The background is a white wall with a window in the background.\n\nThe image shows a plate of pizza with cheese and tomato sauce on top"}, "514773": {"image_id": 514773, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 8.64037821629974e-07, "Bleu_4": 1.8858494565719337e-09, "METEOR": 0.22439494115750713, "ROUGE_L": 0.2445589919816724, "CIDEr": 8.433295292698261e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image is of a room with a desk, chair, and computer in it. There is a leopard print blanket on the floor and a lamp on the desk. The walls are painted a light blue color and there are windows on the left and right sides of the room. The room is well"}, "259253": {"image_id": 259253, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.19522428815262632, "Bleu_3": 0.15041225572379988, "Bleu_4": 0.1167218223841498, "METEOR": 0.19083552760774808, "ROUGE_L": 0.26961325966850824, "CIDEr": 2.8455100067309097e-13, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of sheep standing in a field with a tree in the background. The sheep are white with black spots and are standing in a line, looking at the camera. The tree is a tall, green tree with branches reaching up towards the sky. The sky is blue and there are clouds in the"}, "85340": {"image_id": 85340, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.24094636829087762, "Bleu_3": 0.16574618012457856, "Bleu_4": 0.11617097758561083, "METEOR": 0.25555816624283034, "ROUGE_L": 0.27774615822424586, "CIDEr": 2.3900796271725737e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows three people sitting at a table, one of them holding a hot dog. The other two people are smiling and holding drinks. The background is a restaurant with a bar and tables.\n\nThe image is in color and the lighting is good. The people in the image are wearing cas"}, "94025": {"image_id": 94025, "Bleu_1": 0.14545454545190087, "Bleu_2": 0.08989331499344942, "Bleu_3": 0.05342275830329975, "Bleu_4": 7.358577950477175e-06, "METEOR": 0.16213870841113218, "ROUGE_L": 0.17579250720461098, "CIDEr": 7.420589270897286e-13, "SPICE": {"All": {"pr": 0.24, "re": 0.2222222222222222, "f": 0.23076923076923075, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a stop sign on the side of a dirt road. The sign is rusted and has a few scratches on it. There are trees in the background and a mountain range in the distance. The sky is clear and there are no clouds in sight.\n\nThe image is taken from a low"}, "21746": {"image_id": 21746, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.09288407280072536, "Bleu_3": 5.60482607100497e-07, "Bleu_4": 1.3839209880654026e-09, "METEOR": 0.2417098489310826, "ROUGE_L": 0.2238532110091743, "CIDEr": 7.494959951391374e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.25, "f": 0.24489795918367346, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white shirt and shorts, and has a racket in her hand. The court is made of concrete and has a net in the middle. There are several people watching the game from the sidelines.\n\nThe image is"}, "338291": {"image_id": 338291, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.11605769149245462, "Bleu_3": 6.54689746724509e-07, "Bleu_4": 1.563155525234599e-09, "METEOR": 0.17429044953690806, "ROUGE_L": 0.1937738246505718, "CIDEr": 6.885247571575551e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man standing in front of a building with a snowboard on his back. He is wearing a blue jacket and black pants. There are other people in the background, some of whom are also wearing snowboards. The building appears to be a ski resort, with snow-covered"}, "10142": {"image_id": 10142, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1234482786556696, "Bleu_3": 0.06685490874553476, "Bleu_4": 8.792400740713413e-06, "METEOR": 0.18533327954573509, "ROUGE_L": 0.27774615822424586, "CIDEr": 1.0092621630042378e-11, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.24, "f": 0.21428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a man in a blue jacket and black pants standing on a snowy trail with skis on his feet. He is looking down at the ground and appears to be enjoying the snowy conditions. The trees in the background are bare and snow covered.\n\nThe image is taken in a"}, "327433": {"image_id": 327433, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.08435451529716312, "Bleu_4": 1.057477026987749e-05, "METEOR": 0.1936735430605171, "ROUGE_L": 0.19513755598208574, "CIDEr": 4.135095313850697e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of zebras grazing on the grass in the foreground, with a giraffe in the background. The sky is clear and blue, with a few clouds scattered across it. The landscape is flat and open, with no trees or other vegetation in sight. The only other animals"}, "177935": {"image_id": 177935, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.0762492851645493, "Bleu_3": 5.172979462771284e-07, "Bleu_4": 1.3555314602468016e-09, "METEOR": 0.16463022508038586, "ROUGE_L": 0.2197406340057637, "CIDEr": 2.775459646203661e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 30.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a kitchen with white appliances, including a stove, oven, and refrigerator. The walls are painted yellow and there are wooden cabinets and countertops. The floor is made of hardwood.\n\nThe image is well lit and shows a clean and organized kitchen."}, "100354": {"image_id": 100354, "Bleu_1": 0.15094339622356714, "Bleu_2": 0.0933181271719728, "Bleu_3": 0.05547797716282366, "Bleu_4": 7.644480232985446e-06, "METEOR": 0.1844924349130822, "ROUGE_L": 0.22195269860521533, "CIDEr": 9.682353557551552e-13, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.07142857142857142, "f": 0.07017543859649124, "fn": 26.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.15384615384615385, "f": 0.14814814814814817, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a mother goat and her baby in a pen. The mother goat is standing on the ground and the baby is standing on her back. The mother goat has a long, curly coat and the baby has a short, curly coat. The mother goat is looking down at the baby"}, "377326": {"image_id": 377326, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.20159019488753482, "Bleu_3": 0.14716669660616322, "Bleu_4": 0.08935413502510754, "METEOR": 0.27077570048274435, "ROUGE_L": 0.28785708266621723, "CIDEr": 5.637300328002106e-12, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.24, "f": 0.21428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of cows standing in a field next to a body of water. The cows are brown and white and have long, curly tails. They are drinking from the water and appear to be enjoying themselves. The sky is clear and blue, with a few clouds scattered across it"}, "300471": {"image_id": 300471, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.22287961924216945, "Bleu_3": 0.17672557428704666, "Bleu_4": 0.13294925176959613, "METEOR": 0.2578181317195721, "ROUGE_L": 0.33152173913043476, "CIDEr": 6.288091952538237e-10, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.29411764705882354, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on a blue chair in front of a blue building with a blue roof. The cat is wearing a yellow collar and has a blue ribbon tied around its neck. The building has a blue door and windows with blue shutters. There are blue tables and chairs outside the building"}, "512729": {"image_id": 512729, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.11998523349247527, "Bleu_3": 0.07054895444072659, "Bleu_4": 9.679500319009214e-06, "METEOR": 0.22343499197431782, "ROUGE_L": 0.21801286633309508, "CIDEr": 3.51478567309995e-06, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.23529411764705882, "f": 0.15384615384615385, "fn": 13.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image is a bowl of broccoli with sauce on top of it. The sauce is made with caramelized onions and garlic. The broccoli is cooked with garlic and butter. The dish is served with a side of rice. The overall dish is"}, "14151": {"image_id": 14151, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.19026059765810294, "Bleu_3": 0.11313211375448105, "Bleu_4": 0.07372935016556142, "METEOR": 0.20697247824711262, "ROUGE_L": 0.2784479947831757, "CIDEr": 7.484850220118468e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.3157894736842105, "f": 0.22641509433962262, "fn": 13.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.2, "f": 0.10526315789473682, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image is of a person jumping off a snowboard on a slope. The person is wearing a red and white suit and has a helmet on their head. The background is a white snowy slope with a few trees in the distance.\n\nThe person is jumping off the snowboard and is"}, "323726": {"image_id": 323726, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.06989787123302858, "Bleu_4": 9.090870283563952e-06, "METEOR": 0.15510735447529028, "ROUGE_L": 0.17722254503195814, "CIDEr": 1.8462465975400147e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a baseball player swinging a bat at a ball during a game. The player is wearing a black and orange jersey with the number 10 on the back. The ball is flying through the air and the player is running towards first base. The crowd is cheering in the background."}, "270351": {"image_id": 270351, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.06317667074948415, "Bleu_3": 4.277412148886299e-07, "Bleu_4": 1.1185188895571612e-09, "METEOR": 0.14421179873356307, "ROUGE_L": 0.18100890207715134, "CIDEr": 1.923194402586895e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11428571428571428, "f": 0.12698412698412698, "fn": 31.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of pigeons perched on the ledge of a building. The building is painted a light pink color and has a large window on the side. The pigeons are all facing the same direction and appear to be looking at something in the distance. There is a small birdhouse"}, "290113": {"image_id": 290113, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.07284313590699668, "Bleu_3": 4.799308605281424e-07, "Bleu_4": 1.2383960073346406e-09, "METEOR": 0.18418293505200292, "ROUGE_L": 0.14932680538555693, "CIDEr": 3.4987387123840345e-10, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.08333333333333333, "f": 0.07547169811320754, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are wearing ski gear and holding their skis. The snow is deep and there are trees in the background.\n\nThe image is taken from a high angle, looking down on the skiers. The sky is cloudy and"}, "535312": {"image_id": 535312, "Bleu_1": 0.512195121938727, "Bleu_2": 0.3394759232012375, "Bleu_3": 0.18079834398016015, "Bleu_4": 1.9858659849333717e-05, "METEOR": 0.2288946074406286, "ROUGE_L": 0.42113648433351036, "CIDEr": 0.11938542676875369, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is a collage of images showing a living room, kitchen, and bedroom. The living room has a couch, coffee table, and TV. The kitchen has a table, chairs, and appliances. The bedroom has a bed, dresser, and closet.\n\nThe images"}, "478282": {"image_id": 478282, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.08243669902025869, "Bleu_4": 1.0393938325822104e-05, "METEOR": 0.16215435684608473, "ROUGE_L": 0.3216168717047452, "CIDEr": 4.174264318561423e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.11538461538461539, "f": 0.11538461538461539, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a vase with flowers on top of a fireplace mantle. The mantle is made of wood and has a decorative design on it. The flowers are in a vase on top of the mantle. The vase is made of glass and has a decorative design on it. The"}, "64796": {"image_id": 64796, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.13479285035956426, "Bleu_3": 0.08874014256036408, "Bleu_4": 0.060841168656473245, "METEOR": 0.1574541885819475, "ROUGE_L": 0.20962199312714777, "CIDEr": 9.92050066754489e-13, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.17647058823529413, "f": 0.13636363636363638, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a small potted plant with red flowers on a wooden stand. The plant is sitting on a wooden table with a white surface. The background is a light gray wall with a window in the distance.\n\nThe plant is a small, bushy shrub with bright red flowers. The leaves are dark"}, "525297": {"image_id": 525297, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.21398889174339228, "Bleu_3": 0.15118969592806583, "Bleu_4": 0.1073737962825756, "METEOR": 0.1999344346213073, "ROUGE_L": 0.2813941568426448, "CIDEr": 1.3108823336664953e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.13636363636363635, "f": 0.18749999999999997, "fn": 38.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.07142857142857142, "f": 0.11111111111111112, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.2222222222222222, "f": 0.27586206896551724, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person holding a smartphone with a picture of a cow on the screen. The person is wearing a white shirt and has a blue background. The image is taken in a dark room with a blue light.\n\nThe image shows a person holding a smartphone with a picture of a cow"}, "158414": {"image_id": 158414, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.0914699403543824, "Bleu_4": 1.129625096611556e-05, "METEOR": 0.1858750112831395, "ROUGE_L": 0.24854481955762517, "CIDEr": 3.5919215775272206e-09, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14285714285714285, "f": 0.14545454545454545, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a bus with a sign that reads, \"welcome to metro.\" The bus is parked in front of a building with a sign that reads, \"metro.\"\n\nThe image is taken from the perspective of someone standing on the sidewalk looking at the bus. The bus is parked in"}, "170346": {"image_id": 170346, "Bleu_1": 0.15094339622356714, "Bleu_2": 0.10775449168602044, "Bleu_3": 6.10614148358271e-07, "Bleu_4": 1.4607727077509402e-09, "METEOR": 0.12166506083138215, "ROUGE_L": 0.18496058217101274, "CIDEr": 5.5422557382847244e-12, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.32, "f": 0.3333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of bighorn sheep standing on a rocky cliffside. They are all facing the same direction and appear to be looking out at the landscape. The sheep are white with black horns and are standing on their hind legs. The background is a mountain range with snow covered peaks"}, "328315": {"image_id": 328315, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.13950389246791473, "Bleu_4": 0.1026002037142516, "METEOR": 0.21578469870103492, "ROUGE_L": 0.34269662921348315, "CIDEr": 4.3260344634477785e-10, "SPICE": {"All": {"pr": 0.28, "re": 0.25, "f": 0.2641509433962264, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is of a desk with a computer, printer, and other office supplies on it. There is a lamp on the desk and a bookshelf behind it. The walls are painted a light blue color and there is a window in the background.\n\nThe desk is made of wood and has"}, "113246": {"image_id": 113246, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.13608276348545723, "Bleu_3": 0.08874014256039511, "Bleu_4": 0.060546529641682174, "METEOR": 0.15712956732380043, "ROUGE_L": 0.21542083578575633, "CIDEr": 8.004274027675775e-13, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.12, "f": 0.1132075471698113, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on a couch in a living room. They are all wearing casual clothing and are looking at a laptop on the coffee table in front of them. The room is well lit and there are no windows in the background.\n\nThe image is in black and white"}, "1290": {"image_id": 1290, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.17407765595250352, "Bleu_3": 0.08299846557886469, "Bleu_4": 1.0240041382038528e-05, "METEOR": 0.22978771599603842, "ROUGE_L": 0.21542083578575633, "CIDEr": 1.0366460422922456e-12, "SPICE": {"All": {"pr": 0.35, "re": 0.3684210526315789, "f": 0.358974358974359, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman holding a cake with candles on it. The woman is wearing a yellow dress and has a baby in a high chair next to her. The baby is wearing a onesie and has a pacifier in its mouth. The background of the image is a white wall with a window"}, "292365": {"image_id": 292365, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.0958411776672495, "Bleu_4": 0.06544158309931196, "METEOR": 0.20796943718690247, "ROUGE_L": 0.22889305816135083, "CIDEr": 2.4991914709958653e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.06666666666666667, "f": 0.09090909090909091, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on the toilet seat, looking up at the camera. The cat has a collar on and is looking directly at the camera. The toilet seat is white and the cat's fur is brown. The background is a bathroom with a sink and a shower."}, "246746": {"image_id": 246746, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.13965509692979164, "Bleu_3": 0.09465173555893981, "Bleu_4": 0.06588602516958998, "METEOR": 0.23554362959487066, "ROUGE_L": 0.28018372703412076, "CIDEr": 4.5502070172692193e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a woman riding a brown horse on a grassy field. The horse is wearing a saddle and bridle, and the woman is wearing a white shirt and riding boots. The background is a blue sky with white clouds.\n\nThe image is of a woman riding"}, "328464": {"image_id": 328464, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.14280110945625535, "Bleu_3": 0.07466017915299245, "Bleu_4": 9.649536682952496e-06, "METEOR": 0.14683859975758168, "ROUGE_L": 0.21997836278398844, "CIDEr": 5.775025628710389e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.15789473684210525, "f": 0.13953488372093023, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a sailboat on a frozen lake. The sailboat is white with a red sail and a blue hull. The lake is covered in snow and there are trees in the background. The sky is cloudy and there is a sun in the top right corner of the image."}, "420852": {"image_id": 420852, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.07387419460030926, "Bleu_4": 9.42924728285967e-06, "METEOR": 0.20714919524078937, "ROUGE_L": 0.16776677667766776, "CIDEr": 9.476275704789527e-12, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2222222222222222, "f": 0.20689655172413793, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a street with a few buildings on either side. There are power lines and telephone poles in the background. The sky is blue and there are clouds in the sky. There are no people in the image.\n\nThe image is taken from a bird's eye view, looking down on the"}, "97646": {"image_id": 97646, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.08359497709435722, "Bleu_3": 5.122150570969723e-07, "Bleu_4": 1.2740800388313793e-09, "METEOR": 0.16663043551830395, "ROUGE_L": 0.1821983273596177, "CIDEr": 1.3264677079608256e-13, "SPICE": {"All": {"pr": 0.1, "re": 0.11538461538461539, "f": 0.10714285714285714, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man walking on a wooden bridge over a stream in a forest. The man is wearing a black shirt and black pants, and he is carrying a black backpack on his back. The bridge is made of wooden planks and has a railing on either side. The stream is shall"}, "545796": {"image_id": 545796, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.13284223282838353, "Bleu_3": 0.07114735366732347, "Bleu_4": 9.306979428413019e-06, "METEOR": 0.17517698668166393, "ROUGE_L": 0.19074421513445905, "CIDEr": 3.048088463620671e-12, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.11764705882352941, "f": 0.10256410256410256, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young child sitting in a high chair, sucking on a pacifier. The child is wearing a white onesie and has a bow in its hair. The background is a white wall with a window in the background.\n\nThe image is in black and white, with the child'"}, "332407": {"image_id": 332407, "Bleu_1": 0.13207547169562125, "Bleu_2": 0.05039754872188373, "Bleu_3": 3.679167415154084e-07, "Bleu_4": 9.990095999341766e-10, "METEOR": 0.14245269131533844, "ROUGE_L": 0.13887307911212293, "CIDEr": 4.646375834809197e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people playing baseball on a field. There are two adults and two children playing the game. The adults are wearing baseball caps and the children are wearing baseball gloves. The adults are holding bats and the children are holding balls. The field is made of grass and"}, "204448": {"image_id": 204448, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.1027737074612707, "Bleu_4": 0.0696982798311994, "METEOR": 0.18411693438844942, "ROUGE_L": 0.236281471917366, "CIDEr": 1.0167651831920647e-06, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a kitchen with a stove, refrigerator, and sink. There is a wooden table and chairs in the dining area. The walls are painted white and the floor is made of hardwood. The room is well lit by natural light from the windows.\n\nThe image shows a"}, "480842": {"image_id": 480842, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.06262242910727484, "Bleu_3": 4.309444049146827e-07, "Bleu_4": 1.1363330167951873e-09, "METEOR": 0.15974613651644076, "ROUGE_L": 0.0780550223928343, "CIDEr": 1.5918815602205398e-12, "SPICE": {"All": {"pr": 0.15, "re": 0.10714285714285714, "f": 0.125, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in a field of tall grass. The giraffe is looking down at the ground, and its long neck is stretched out in front of it. The giraffe's fur is brown and its spots are white. The background is a green field with tall grass"}, "224155": {"image_id": 224155, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.2543735095295466, "Bleu_3": 0.17415497758044282, "Bleu_4": 0.10242161260431779, "METEOR": 0.2826447704274115, "ROUGE_L": 0.26704190118824267, "CIDEr": 8.823273282809151e-11, "SPICE": {"All": {"pr": 0.04, "re": 0.043478260869565216, "f": 0.041666666666666664, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The man in the image is wearing a green shirt and has a beard. He is holding a cell phone in his hand and is taking a selfie. The background is a bathroom with a toilet, sink, and shower. The man is standing in front of the sink and is looking"}, "303647": {"image_id": 303647, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.22019275302032337, "Bleu_3": 0.13113617972964073, "Bleu_4": 1.5222275337401534e-05, "METEOR": 0.29678756710878007, "ROUGE_L": 0.35260115606936415, "CIDEr": 2.2407110045052273e-07, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.35714285714285715, "f": 0.23255813953488377, "fn": 9.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.75, "f": 0.375, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a pizza pan with a pizza in it. The pizza has mushrooms, onions, and cheese on top of it. There is a wooden cutting board on the counter next to the pizza pan. The kitchen has a stove and an oven.\n\n\nThe"}, "448868": {"image_id": 448868, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.06502560887474053, "Bleu_3": 4.65200159363572e-07, "Bleu_4": 1.251797059186196e-09, "METEOR": 0.12873563218390804, "ROUGE_L": 0.20265780730897012, "CIDEr": 9.226357013418622e-08, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.07692307692307693, "f": 0.07407407407407408, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a large truck parked on the side of the road with a hose attached to it. There are several other trucks parked nearby, and a large building in the background. The sky is cloudy and there is snow on the ground."}, "360705": {"image_id": 360705, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 7.178791139239357e-07, "Bleu_4": 1.649286056998e-09, "METEOR": 0.15578240471216284, "ROUGE_L": 0.18496058217101274, "CIDEr": 6.026054354945589e-12, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.07142857142857142, "f": 0.0784313725490196, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a green field with cows grazing in the foreground. In the background, there is a row of trees with leaves turning red in the fall. The sky is blue with a few clouds.\n\nThe image is taken from a bird's eye view, looking down on the field and trees"}, "122678": {"image_id": 122678, "Bleu_1": 0.3571428571258504, "Bleu_2": 0.22861497841865355, "Bleu_3": 0.15767283456157452, "Bleu_4": 0.11907182322002588, "METEOR": 0.25789242342062785, "ROUGE_L": 0.3339198435972629, "CIDEr": 0.008025642483192985, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.20689655172413793, "f": 0.2142857142857143, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a woman in a white uniform standing in front of a large whiteboard with a blackboard on it. She is holding a pen and looking at the board with a serious expression. The background is a dark blue color."}, "253843": {"image_id": 253843, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.22538468968297923, "Bleu_3": 0.1707718239117117, "Bleu_4": 0.11880293241977447, "METEOR": 0.2920113808389717, "ROUGE_L": 0.24007646463510626, "CIDEr": 7.647924303920412e-11, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man and a woman standing in a barn with a horse in the background. The man is wearing a black and white striped shirt and the woman is wearing a red and white striped shirt. The horse is brown and white and has a saddle on its back. There"}, "301421": {"image_id": 301421, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.0930756528209598, "Bleu_4": 0.06305717703637675, "METEOR": 0.2720429814522424, "ROUGE_L": 0.25507765830346474, "CIDEr": 6.809025335646024e-13, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.42105263157894735, "f": 0.380952380952381, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a desk with a computer, speakers, and a lamp on it. The desk is made of wood and has a clear glass top. The computer is a black and silver laptop with a large screen and speakers on either side. The speakers are black and have a small LED display on"}, "248965": {"image_id": 248965, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.09180747086790693, "Bleu_4": 1.1327499538368697e-05, "METEOR": 0.232228996145234, "ROUGE_L": 0.2594167679222357, "CIDEr": 1.6165590313987505e-09, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.125, "f": 0.10344827586206896, "fn": 21.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person standing on a beach holding a kite. The kite is made of colorful fabric and has a long tail. The person is wearing a pink shirt and blue pants. The background is a sandy beach with some trees in the distance.\n\nThe image is taken"}, "274134": {"image_id": 274134, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1398811515077607, "Bleu_3": 7.219465044848078e-07, "Bleu_4": 1.6481100947130725e-09, "METEOR": 0.2008085988839223, "ROUGE_L": 0.29047619047619044, "CIDEr": 1.3092028037228469e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a small room with a wooden table and chairs in the center of the room. There is a bookshelf on the wall with books on it. The room has a window with a view of the street outside.\n\nThe room is dimly lit with a small lamp on the table. There"}, "527193": {"image_id": 527193, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.12371791482379726, "Bleu_3": 6.880010617668035e-07, "Bleu_4": 1.631181823642126e-09, "METEOR": 0.12412947257290796, "ROUGE_L": 0.21618428824571767, "CIDEr": 2.747660413876696e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.21052631578947367, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of elephants standing in a field with a fence in the background. The elephants are standing in a line, with one of them holding a rope in its trunk. The other elephants are standing nearby, looking at the one holding the rope. The sky"}, "277383": {"image_id": 277383, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.06262242910727484, "Bleu_3": 4.309444049146827e-07, "Bleu_4": 1.1363330167951873e-09, "METEOR": 0.13305173764159225, "ROUGE_L": 0.1561100447856686, "CIDEr": 9.398630108674073e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people playing a game of soccer on a grass field. The players are wearing red and white jerseys and black shorts. The field is surrounded by trees and there are spectators in the background watching the game.\n\nThe image is taken from a bird's"}, "417015": {"image_id": 417015, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1311863860222524, "Bleu_4": 0.09700218812496947, "METEOR": 0.20671948279173283, "ROUGE_L": 0.2445589919816724, "CIDEr": 1.863508473531295e-11, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.34782608695652173, "f": 0.31999999999999995, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a small pink flower sitting on a table next to a mirror. The mirror is reflecting the flower and the table. The table has a small vase with a pink flower in it. The flower is sitting on top of a small pile of books. The books are stacked on top"}, "349525": {"image_id": 349525, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.14189834119414174, "Bleu_4": 0.11620875224195953, "METEOR": 0.2250674096746797, "ROUGE_L": 0.3674698795180723, "CIDEr": 2.6820759808705737e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a stove, oven, and refrigerator. There are several people in the room, including a woman sitting at a table and a man standing near the stove. The room appears to be a kitchen, with a table and chairs in the center of the room."}, "567254": {"image_id": 567254, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.23940600197905648, "Bleu_3": 0.13185907348916004, "Bleu_4": 0.08270532924169824, "METEOR": 0.22892923894157535, "ROUGE_L": 0.30191377034755823, "CIDEr": 1.5914282453734824e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.16129032258064516, "f": 0.17857142857142855, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a young girl sitting on the floor in front of a television, looking at the screen with a curious expression on her face. She has long, curly blonde hair and is wearing a pink t shirt and white shorts. The room is decorated with a blue and white striped"}, "19783": {"image_id": 19783, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.06520506636831809, "Bleu_3": 4.4890551563344676e-07, "Bleu_4": 1.184204612229436e-09, "METEOR": 0.11182851938220997, "ROUGE_L": 0.19690122659780504, "CIDEr": 2.131562210933309e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.2631578947368421, "f": 0.22727272727272727, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a man standing on the shore of a body of water, looking out at a group of seagulls flying overhead. The man is wearing a hat and sunglasses, and has a fishing rod in his hand. The seagulls are flying in a circular pattern around the"}, "562292": {"image_id": 562292, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.13644420572458105, "Bleu_3": 0.09319532338930897, "Bleu_4": 1.1580903993958114e-05, "METEOR": 0.1681102524742473, "ROUGE_L": 0.19110275689223058, "CIDEr": 7.829640488048769e-10, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.06666666666666667, "f": 0.07017543859649124, "fn": 28.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a woman sitting on a bench in a park, wearing black leggings and a black top, with a white handbag on her lap. She is surrounded by other people sitting on the bench, some of whom are also wearing black leggings and tops. The bench"}, "538819": {"image_id": 538819, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.08433490103776005, "Bleu_3": 5.824214923868025e-07, "Bleu_4": 1.5413846635645837e-09, "METEOR": 0.12044457612255897, "ROUGE_L": 0.19709208400646203, "CIDEr": 1.8038519039540123e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.23529411764705882, "f": 0.21052631578947367, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a plate with two slices of toasted bread topped with cheese, pepperoni, and tomato slices. The bread is toasted and crispy, while the cheese is melted and gooey. The pepperoni is crispy and slightly browned"}, "521259": {"image_id": 521259, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.07520710469806294, "Bleu_3": 4.836329832921367e-07, "Bleu_4": 1.2326447028857739e-09, "METEOR": 0.1637602451114314, "ROUGE_L": 0.20492721164613664, "CIDEr": 4.388173659518667e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of children playing soccer on a field in front of a school building. The children are wearing soccer jerseys and cleats, and one of them is kicking the ball with his foot. The field is made of grass and there are trees in the background. The sky"}, "470779": {"image_id": 470779, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.12166026344082319, "Bleu_4": 0.09306979428413018, "METEOR": 0.20112406821992654, "ROUGE_L": 0.33485818847209514, "CIDEr": 6.2051338323886966e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.11764705882352941, "f": 0.14035087719298242, "fn": 30.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on a snowy slope at night. They are all wearing ski gear and holding their skis. The woman in the center is wearing a black jacket and black pants, while the man on the left is wearing a blue jacket and black pants"}, "92053": {"image_id": 92053, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.11455372707190037, "Bleu_4": 0.07602453795872412, "METEOR": 0.24862538081301258, "ROUGE_L": 0.3057644110275689, "CIDEr": 3.5257485695165206e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.25, "f": 0.2162162162162162, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a table with three plates of food on it. The plates have different types of food on them, including sausages, burgers, and fries. There are also two beers on the table. The table is in a dimly lit room with a fireplace in the background."}, "361687": {"image_id": 361687, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.11881770515484788, "Bleu_3": 6.604735246466958e-07, "Bleu_4": 1.565241127638514e-09, "METEOR": 0.15785417011901773, "ROUGE_L": 0.21441124780316342, "CIDEr": 6.529887625813114e-11, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.13636363636363635, "f": 0.10909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a baby lying on a bed in a nursery. The baby is wearing a onesie and has its hands clasped together. The baby's face is not visible. The background is a white wall with a window in the background.\n\nThe baby is lying on a bed in"}, "386879": {"image_id": 386879, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2804120134978465, "Bleu_3": 0.17371366811579753, "Bleu_4": 0.10447498658372112, "METEOR": 0.24426289535232554, "ROUGE_L": 0.31063017186505404, "CIDEr": 1.1628237451545108e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.12, "f": 0.11538461538461538, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a woman in a red tennis dress holding a tennis racket. She is standing in a grassy area with trees in the background. The woman is smiling and appears to be enjoying the game. The image is in focus and the colors are vibrant."}, "461855": {"image_id": 461855, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1577557537051747, "Bleu_3": 0.09984894236626275, "Bleu_4": 1.1938742404395867e-05, "METEOR": 0.14610088720702874, "ROUGE_L": 0.18373493975903615, "CIDEr": 5.067407084834351e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.12121212121212122, "f": 0.14545454545454545, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young girl sitting on a couch with a stuffed animal in her lap. She is wearing a white dress and has a stuffed animal in her lap. The background is dark and the lighting is dim.\n\nThe image is in black and white and has a vintage look"}, "315610": {"image_id": 315610, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.20579830216693504, "Bleu_3": 0.15121069009849425, "Bleu_4": 0.09212480089236008, "METEOR": 0.30062620162412435, "ROUGE_L": 0.2858816637375513, "CIDEr": 2.457805510723326e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a ferris wheel with planes flying overhead. The ferris wheel has a large wheel with seats inside and a large wheel with seats outside. The planes are flying in the sky above the ferris wheel. The sky is cloudy and there are some clouds in the background. The"}, "419560": {"image_id": 419560, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.1442707907155283, "Bleu_3": 7.733595213406049e-07, "Bleu_4": 1.8006234777217801e-09, "METEOR": 0.17875344728821, "ROUGE_L": 0.24416277518345564, "CIDEr": 4.6560242577300005e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two giraffes standing in a clearing surrounded by tall trees. They are both looking in the same direction, their heads tilted slightly to the side. The giraffes are brown with white spots on their backs and necks. The trees are tall and green, with"}, "136271": {"image_id": 136271, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.24414717515239445, "Bleu_3": 0.15396057606248625, "Bleu_4": 0.11104636198911245, "METEOR": 0.21784287844292644, "ROUGE_L": 0.28549141965678626, "CIDEr": 5.7261693864173637e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a fruit stand with various types of fruit, including apples, oranges, and bananas. The stand is made of metal and has a glass front. The fruit is arranged in rows on the stand, with each row having a different color. The stand is in a grocery store, with"}, "174633": {"image_id": 174633, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.1272154058119733, "Bleu_4": 0.08051110007486427, "METEOR": 0.21529721936966245, "ROUGE_L": 0.23047858942065497, "CIDEr": 6.473473682543622e-11, "SPICE": {"All": {"pr": 0.04, "re": 0.03125, "f": 0.03508771929824561, "fn": 31.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man and a child on skis, walking down a snowy slope. The man is wearing a black and white jacket and the child is wearing a blue and white jacket. They are both holding ski poles and smiling at each other. The background is a mountain with snow"}, "122120": {"image_id": 122120, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.14580296087694455, "Bleu_3": 0.07676176340636935, "Bleu_4": 9.95793413350648e-06, "METEOR": 0.2213727769331488, "ROUGE_L": 0.20158625247851947, "CIDEr": 2.6139218428744726e-10, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.034482758620689655, "f": 0.0392156862745098, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a young man in a red shirt and black pants performing a skateboard trick on a halfpipe. The halfpipe is made of concrete and has a blue tarp on top. The young man is wearing a helmet and knee pads, and is holding onto the skate"}, "34015": {"image_id": 34015, "Bleu_1": 0.3620689655109988, "Bleu_2": 0.23909994568600282, "Bleu_3": 0.14522143621591616, "Bleu_4": 0.086383813655512, "METEOR": 0.29053490788128733, "ROUGE_L": 0.3065326633165829, "CIDEr": 3.2384823583974046e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11538461538461539, "f": 0.11320754716981132, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man in a red shirt and white pants standing on a tennis court. He is holding a tennis racket in his right hand and has a tennis ball in his left hand. The man is looking down at the ground and appears to be walking towards the net. The background is a white f"}, "369460": {"image_id": 369460, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.10514001031125872, "Bleu_3": 6.172759988054166e-07, "Bleu_4": 1.5037307654525653e-09, "METEOR": 0.19883478938636412, "ROUGE_L": 0.2208811104405552, "CIDEr": 5.902481914370946e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The woman is walking down the sidewalk, looking at her phone. She is wearing black pants and a black shirt. She has long, curly brown hair and is wearing sunglasses. The building behind her has a large window with a reflection of the woman in it. The street is"}, "240049": {"image_id": 240049, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.11262478804206155, "Bleu_4": 0.07425078089806363, "METEOR": 0.21101396111070914, "ROUGE_L": 0.2820809248554913, "CIDEr": 9.46199202843558e-07, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.0625, "f": 0.045454545454545456, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.2, "f": 0.10526315789473682, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "The image shows a woman holding a baby while standing next to a giraffe in a zoo enclosure. The giraffe is standing on its hind legs and looking at the woman and baby. The woman is wearing a black jacket and jeans, and the baby is wearing a pink ones"}, "168686": {"image_id": 168686, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 0.09808593569034826, "Bleu_4": 1.2472080427479296e-05, "METEOR": 0.19430581801342886, "ROUGE_L": 0.2531120331950207, "CIDEr": 7.584461531791551e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17391304347826086, "f": 0.1568627450980392, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a display of fresh fruits and vegetables in a green basket on a kitchen counter. The fruits include blueberries, strawberries, and oranges, while the vegetables include broccoli, carrots, and lettuce. The display is arranged in a neat and organized"}, "195172": {"image_id": 195172, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.1511926461656511, "Bleu_3": 0.12148343141342467, "Bleu_4": 0.10184169067891133, "METEOR": 0.2666274151299741, "ROUGE_L": 0.2896142433234421, "CIDEr": 3.3760633494750218e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in a field of tall grass. The giraffe is brown with white spots on its back and legs. It has a long neck and long legs. The giraffe is looking down at something on the ground. The background is a green field with trees in the distance"}, "124798": {"image_id": 124798, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.161880977056518, "Bleu_3": 0.07957856377253618, "Bleu_4": 9.970215112770837e-06, "METEOR": 0.18523169031430187, "ROUGE_L": 0.23487348734873487, "CIDEr": 1.4988282412047684e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.13043478260869565, "f": 0.1276595744680851, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a city street with a bus driving down the road. There are several cars parked on the side of the road and people walking on the sidewalk. The sky is clear and blue.\n\nThe image is taken from a bird's eye view, looking down on the city. The buildings are"}, "279809": {"image_id": 279809, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 7.178791139239357e-07, "Bleu_4": 1.649286056998e-09, "METEOR": 0.23140824577719604, "ROUGE_L": 0.18908865468071917, "CIDEr": 6.090786544710751e-13, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.10344827586206896, "f": 0.13043478260869565, "fn": 26.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows two cats sitting on a windowsill looking out at the snowy landscape. The cats are black and white and have piercing eyes. The window is open and there is a view of the snowy landscape outside. The cats are looking out at the snow and seem to be enjoying the"}, "170898": {"image_id": 170898, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 7.990635300418294e-07, "Bleu_4": 1.8151458107416433e-09, "METEOR": 0.19582915204864149, "ROUGE_L": 0.26228501228501233, "CIDEr": 6.654967976207242e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.21739130434782608, "f": 0.19607843137254902, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a greyhound dog lying on a bed next to a white pillow. The dog is wearing an orange collar and has its head resting on its paws. The bed is covered in a floral patterned blanket and there is a white pillow on the bed. The room"}, "274411": {"image_id": 274411, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.13644420572458105, "Bleu_3": 7.396917719335283e-07, "Bleu_4": 1.731749067280523e-09, "METEOR": 0.19776689118163115, "ROUGE_L": 0.2293233082706767, "CIDEr": 3.367400899513377e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white dress and has a racket in her hand. The net is in the background and there are other players on the court. The sky is blue and there are trees in the background."}, "449379": {"image_id": 449379, "Bleu_1": 0.22222222221810703, "Bleu_2": 2.047650389408227e-09, "Bleu_3": 4.320189108149872e-12, "Bleu_4": 1.9940430225541666e-13, "METEOR": 0.17143393124789724, "ROUGE_L": 0.14896214896214896, "CIDEr": 8.262676425626536e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.21052631578947367, "f": 0.1702127659574468, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bedroom with a red bedspread and a cat sleeping on top of it. There are two other cats on the bed, one on the left and one on the right. The cat on the left is lying on its back with its paws in the air, while the cat on"}, "475660": {"image_id": 475660, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.22562131409418867, "Bleu_3": 0.1828018128219654, "Bleu_4": 0.14943466403629294, "METEOR": 0.2773385882063444, "ROUGE_L": 0.3670678336980307, "CIDEr": 7.459525113678019e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on the steps of the capitol building in Washington, DC. They are dressed in suits and ties and are holding microphones. The building is visible in the background, with a large dome on top. There are people in the background, walking and standing on"}, "125535": {"image_id": 125535, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.20225995873532804, "Bleu_3": 0.1314767947140738, "Bleu_4": 0.08092223395271034, "METEOR": 0.25218717747063785, "ROUGE_L": 0.2717149220489977, "CIDEr": 2.1155954138019181e-13, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}}, "caption": "The image shows a group of brown pelicans perched on a tree branch. They are all facing the same direction and have their beaks open. The sky is blue and there are some clouds in the background. The tree is covered in green leaves and there are some branches growing out of it. The pelicans are"}, "353898": {"image_id": 353898, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.15617933312062784, "Bleu_4": 0.11283678602769266, "METEOR": 0.2774105081319583, "ROUGE_L": 0.3100381194409149, "CIDEr": 1.8320176073523205e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14285714285714285, "f": 0.1568627450980392, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man sitting on a bench in a park surrounded by pigeons. The man is wearing a black shirt and pants, and has a white hat on his head. The pigeons are standing around him, looking at him. The trees in the background are tall and green,"}, "177539": {"image_id": 177539, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.1287696884067729, "Bleu_3": 7.066046274188938e-07, "Bleu_4": 1.6641516502234788e-09, "METEOR": 0.21319861372956495, "ROUGE_L": 0.23091482649842268, "CIDEr": 7.615449509172155e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.16666666666666666, "f": 0.13636363636363638, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a person standing on the beach holding a surfboard. The person is wearing a black and white striped shirt and black shorts. The surfboard has a yellow stripe on it. The sky is blue and there are palm trees in the background. The beach is sandy"}, "467791": {"image_id": 467791, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.10353608435894587, "Bleu_4": 1.220608250473103e-05, "METEOR": 0.2310686055311952, "ROUGE_L": 0.22195269860521533, "CIDEr": 4.1564797095184227e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress on a field. There are several players on the field, including a pitcher and a catcher. The pitcher is throwing the ball to the catcher, who is holding a bat. The other players are standing on the field, watching the game. The stands are filled"}, "197918": {"image_id": 197918, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 6.880010617668035e-07, "Bleu_4": 1.631181823642126e-09, "METEOR": 0.21198650189324425, "ROUGE_L": 0.23091482649842268, "CIDEr": 1.4534641236068532e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.19230769230769232, "f": 0.19230769230769232, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of children playing with stuffed animals in a toy store. The children are standing in front of a shelf filled with toys, including stuffed animals, dolls, and toy cars. One of the children is holding a stuffed panda bear, while another is holding a"}, "153524": {"image_id": 153524, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.10457151389178666, "Bleu_4": 0.06847928396795629, "METEOR": 0.19496408455252565, "ROUGE_L": 0.21542083578575633, "CIDEr": 2.2436382633558594e-13, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a computer desk with two computers on it. The computers are connected to a monitor and a keyboard. There is a lamp on the desk and a window in the background.\n\nThe room is empty except for the computers and lamp. The window is open and there is a view of the outside."}, "449428": {"image_id": 449428, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.1027737074612707, "Bleu_4": 0.0696982798311994, "METEOR": 0.1737522351363409, "ROUGE_L": 0.22578655151141266, "CIDEr": 7.927756998447754e-10, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1, "f": 0.0975609756097561, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a herd of cows grazing in a field. The cows are standing in a line, with their heads down and their tails hanging behind them. They are wearing collars and are standing in a line, with their heads down and their tails hanging behind them. The"}, "231140": {"image_id": 231140, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.0986616396109014, "Bleu_4": 1.1893260654292823e-05, "METEOR": 0.23791752559270346, "ROUGE_L": 0.29204069419509276, "CIDEr": 6.328163983381394e-11, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.1111111111111111, "f": 0.08333333333333334, "fn": 16.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a large, white house with a red roof and a large, white door. There are several zebras grazing in the grass in front of the house. The house has a large, stone chimney and a large, stone balcony. There are several windows on the first floor and a"}, "540449": {"image_id": 540449, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.175350303278286, "Bleu_3": 0.143524673573961, "Bleu_4": 0.11483722661875433, "METEOR": 0.3271815161870132, "ROUGE_L": 0.3210526315789473, "CIDEr": 1.0704496897260873e-11, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.12121212121212122, "f": 0.14814814814814814, "fn": 29.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a dog sitting in the back seat of a car. The dog is wearing a collar and leash. The car is parked on the side of the road. The sky is cloudy and there are trees in the background. The dog appears to be looking out the window. The car has"}, "182755": {"image_id": 182755, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.1942571724677524, "Bleu_3": 0.11395620606288538, "Bleu_4": 0.07375831475580244, "METEOR": 0.16789794798675764, "ROUGE_L": 0.21908296420447745, "CIDEr": 7.454018223540108e-12, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08695652173913043, "f": 0.07999999999999999, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a desk with a computer, keyboard, mouse, and monitor. The desk is made of wood and has a lamp on it. There is a window in the background with a view of the outside.\n\nThe image is taken in a room with wooden walls and a wooden floor. The des"}, "159170": {"image_id": 159170, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.0903507902886997, "Bleu_3": 5.540397074769196e-07, "Bleu_4": 1.3792125616624927e-09, "METEOR": 0.19833870465198344, "ROUGE_L": 0.19830949284785435, "CIDEr": 3.305734171514777e-10, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.25925925925925924, "f": 0.27999999999999997, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a cat lying on a couch with its paws stretched out in front of it. The cat's eyes are closed and it appears to be sleeping. The background is a blue and white striped blanket.\n\nThe cat is a orange and white tabby with a short,"}, "408480": {"image_id": 408480, "Bleu_1": 0.1538461538431953, "Bleu_2": 0.0776735637365534, "Bleu_3": 4.941500225511973e-07, "Bleu_4": 1.2526942807511536e-09, "METEOR": 0.1410147592706871, "ROUGE_L": 0.21131639722863746, "CIDEr": 1.1015403053173213e-12, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.3181818181818182, "f": 0.2692307692307693, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a red and white lighthouse on the waterfront, with a large ship in the background. There are several buildings in the background, including a large building with a clock tower. The sky is blue and there are trees in the foreground.\n\nThe image is taken from a bird's"}, "538242": {"image_id": 538242, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.10514001031125872, "Bleu_3": 6.172759988054166e-07, "Bleu_4": 1.5037307654525653e-09, "METEOR": 0.16000000000000003, "ROUGE_L": 0.18815545959284388, "CIDEr": 1.1597591935374764e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.2857142857142857, "f": 0.29629629629629634, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a parked motorcycle. The people are wearing military uniforms and helmets. The motorcycle is an old style bike with a sidecar attached to the back. The background is a parking lot with trees and buildings in the distance."}, "552153": {"image_id": 552153, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.13241452366608922, "Bleu_3": 0.10715656750302463, "Bleu_4": 0.0814187794101698, "METEOR": 0.20343916540806958, "ROUGE_L": 0.2326975476839237, "CIDEr": 1.0073822645974942e-15, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14814814814814814, "f": 0.17391304347826086, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a small plane flying over a body of water with mountains in the background. The plane is white and has a red tail. There are clouds in the sky and the sun is shining. The water is calm and there are no other boats or people in the image. The mountains are covered in snow and"}, "63617": {"image_id": 63617, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.18463723646567207, "Bleu_3": 0.1237244007877382, "Bleu_4": 1.3749045587752487e-05, "METEOR": 0.2097292247409286, "ROUGE_L": 0.2459677419354839, "CIDEr": 4.197207269289761e-13, "SPICE": {"All": {"pr": 0.12, "re": 0.14285714285714285, "f": 0.13043478260869565, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a young boy playing catch with his father on a wooden deck. The boy is wearing a baseball glove and holding a baseball in his hand. The father is standing behind him, holding a baseball bat. The background is a clear blue sky with some clouds. The overall mood of the image is"}, "366529": {"image_id": 366529, "Bleu_1": 0.340909090901343, "Bleu_2": 0.19909945244613453, "Bleu_3": 0.12358723393320391, "Bleu_4": 0.08237287895426529, "METEOR": 0.17028850737015072, "ROUGE_L": 0.27232142857142855, "CIDEr": 3.6345995971729197e-07, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.15789473684210525, "f": 0.1276595744680851, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a wedding photo of a bride and groom. The bride is wearing a white wedding dress and the groom is wearing a tuxedo. They are standing in front of a fountain and smiling at each other.\n\nThe bride and groom are both"}, "282841": {"image_id": 282841, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.0799063530041829, "Bleu_4": 1.0207315006261666e-05, "METEOR": 0.21069646527509603, "ROUGE_L": 0.23797139141742527, "CIDEr": 1.1130951188099128e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.21739130434782608, "f": 0.17241379310344826, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a wooden wall with a mirror hanging on it. There are several leather straps hanging from the wall, and a pair of scissors on the table. The room is dimly lit, with a small window on the left side of the image.\n\nThe image shows a wooden"}, "169679": {"image_id": 169679, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.10921336092038615, "Bleu_4": 1.2972311576394404e-05, "METEOR": 0.17588982946200102, "ROUGE_L": 0.23091482649842268, "CIDEr": 8.151323961129478e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows three people standing on a snowy slope, wearing ski gear and holding skis. The woman on the left is wearing a blue jacket and pants, while the man in the middle is wearing a black jacket and pants. The woman on the right is wearing a"}, "427034": {"image_id": 427034, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.1415984650784514, "Bleu_3": 0.07143616536435347, "Bleu_4": 9.06442292469654e-06, "METEOR": 0.19878831123562948, "ROUGE_L": 0.25616797900262467, "CIDEr": 4.98310024274849e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a small black and tan dog sitting on top of a laptop computer. The dog is looking up at the camera with its tongue hanging out of its mouth. The laptop has a screen that shows a picture of a cat on it. The dog is wearing a collar with a tag that reads \""}, "381527": {"image_id": 381527, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.192868005722087, "Bleu_3": 0.15009834309313902, "Bleu_4": 0.1119882114534188, "METEOR": 0.2882306629932022, "ROUGE_L": 0.33107191316146534, "CIDEr": 4.6281466069761196e-08, "SPICE": {"All": {"pr": 0.03125, "re": 0.047619047619047616, "f": 0.03773584905660377, "fn": 20.0, "numImages": 1.0, "fp": 31.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.0625, "re": 0.14285714285714285, "f": 0.08695652173913043, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}}, "caption": "The image shows a skateboarder performing a trick on a halfpipe at a skate park. The skateboarder is wearing a black and white striped shirt and black pants, and has a red and black striped helmet on his head. The halfpipe is made of concrete and"}, "81661": {"image_id": 81661, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.18136906252429263, "Bleu_3": 0.10615274788259942, "Bleu_4": 1.2199723582450367e-05, "METEOR": 0.2145652739803371, "ROUGE_L": 0.28249459709786967, "CIDEr": 4.6832188612907315e-12, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16666666666666666, "f": 0.1702127659574468, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a laptop computer with a mouse and a keyboard on the desk. There is a can of soda on the desk next to the laptop. The laptop has a black and white screen and a black keyboard. The mouse has a black and white cord attached to it. The keyboard has a black and"}, "501368": {"image_id": 501368, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1978218215826409, "Bleu_3": 0.11460186406839476, "Bleu_4": 0.07370572412364096, "METEOR": 0.20207424054223436, "ROUGE_L": 0.2853801169590643, "CIDEr": 9.933886088598411e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.16129032258064516, "f": 0.19607843137254902, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a woman standing in a bathroom, looking at her hair in the mirror. She is wearing a yellow towel around her neck and has a blue light shining on her head. The background is a white wall with a window on the left side.\n\nThe woman in the image is we"}, "51119": {"image_id": 51119, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.22287961924216945, "Bleu_3": 0.15438400931646754, "Bleu_4": 0.10855260950677467, "METEOR": 0.22392669305168672, "ROUGE_L": 0.26124197002141325, "CIDEr": 1.3316607371856892e-12, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.06896551724137931, "f": 0.07547169811320754, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a burnt out bus that has been involved in an accident. The bus is on the side of the road and there are several other vehicles parked nearby. There are also several people standing around the bus, looking at it. The bus has been completely destroyed and there is debris scattered around it"}, "502006": {"image_id": 502006, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.12712834523041283, "Bleu_3": 0.06730845772977347, "Bleu_4": 8.750873255009596e-06, "METEOR": 0.14983666874529206, "ROUGE_L": 0.23351197637536913, "CIDEr": 1.9240995690756476e-12, "SPICE": {"All": {"pr": 0.28, "re": 0.1794871794871795, "f": 0.21875, "fn": 32.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07142857142857142, "f": 0.09523809523809523, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.25, "f": 0.2962962962962963, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a brown bear and its cubs in a grassy field. The bear is standing on its hind legs and looking at something in the distance. The cubs are standing next to their mother and looking at something in the distance. The background is a green field with some trees in the distance."}, "213457": {"image_id": 213457, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.05825517280241507, "Bleu_3": 4.0791185612592327e-07, "Bleu_4": 1.0848650703059749e-09, "METEOR": 0.13724998740156105, "ROUGE_L": 0.14698795180722893, "CIDEr": 1.4186449974137186e-11, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.14285714285714285, "f": 0.11538461538461538, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.125, "f": 0.09090909090909091, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "The image shows a person skiing down a snowy slope. The person is wearing a black and white ski suit and a black helmet. The snow is white and there are trees in the background.\n\nThe image is taken from a high angle, looking down at the person skiing. The sun is"}, "138549": {"image_id": 138549, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.25900956329042873, "Bleu_3": 0.17280756432599467, "Bleu_4": 1.7835262993961052e-05, "METEOR": 0.2647730809457749, "ROUGE_L": 0.29151732377538825, "CIDEr": 2.3403164232499813e-12, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.125, "f": 0.14634146341463414, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a table with a plate of food on it. There is a beer glass on the table and a book on the table. The background is a wooden floor with a white tablecloth. The lighting is from a window on the left side of the image.\n\nThe image shows a table"}, "579303": {"image_id": 579303, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.08081586876451534, "Bleu_3": 0.05040508737561902, "Bleu_4": 7.113990450126207e-06, "METEOR": 0.1465167162409895, "ROUGE_L": 0.21908296420447745, "CIDEr": 6.256266631741915e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a plate with a sandwich on it. The sandwich has a fried egg on top of it and is served with a side of lettuce and tomato. There is a glass of orange juice on the table next to the plate. The table has a white tablecloth and a v"}, "351744": {"image_id": 351744, "Bleu_1": 0.16071428571141586, "Bleu_2": 0.07644707871426631, "Bleu_3": 4.765509535913812e-07, "Bleu_4": 1.1953994172638397e-09, "METEOR": 0.15781729824251042, "ROUGE_L": 0.20378619153674835, "CIDEr": 1.110581452405574e-13, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.08695652173913043, "f": 0.08163265306122448, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a train on the tracks, with a large container car attached to the back. The train is traveling through a tunnel, with the tracks leading into the distance. The tunnel is made of stone and has a large arched roof. There are trees and buildings visible in the background. The sky is cloud"}, "521605": {"image_id": 521605, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1403458930502932, "Bleu_3": 7.708626205337203e-07, "Bleu_4": 1.817274019118142e-09, "METEOR": 0.21869212600861251, "ROUGE_L": 0.25902335456475584, "CIDEr": 1.157356140827457e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.26666666666666666, "f": 0.1951219512195122, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a plate of food with various ingredients such as bacon, eggs, broccoli, and potatoes. There are also slices of bread on the plate. The overall appearance of the dish is quite appetizing and inviting.\n\nThe image shows a plate of food with"}, "494439": {"image_id": 494439, "Bleu_1": 0.16071428571141586, "Bleu_2": 0.09362816758816678, "Bleu_3": 0.05455146638784257, "Bleu_4": 7.439364783947175e-06, "METEOR": 0.17434088089181554, "ROUGE_L": 0.18068720379146921, "CIDEr": 4.906787926970851e-14, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.13333333333333333, "f": 0.15094339622641512, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a train on the tracks in front of a building. The train is red and white with black wheels and has a number on the side. The building is a large, brick structure with windows and a roof. There are people standing on the platform in front of the train.\n\nThe train is"}, "209753": {"image_id": 209753, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.234935746945449, "Bleu_3": 0.15990233738253712, "Bleu_4": 1.6665645580942163e-05, "METEOR": 0.25182788515382937, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.179119782643711e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a woman wearing a black dress and holding a phone in her hand. She is standing in front of a window with a view of the city outside. There are lights on the walls and a TV in the background. The woman is looking at her phone with a smile on her face."}, "435709": {"image_id": 435709, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.18164975363435543, "Bleu_3": 0.10758240552419991, "Bleu_4": 1.2439562377602817e-05, "METEOR": 0.18714033872260083, "ROUGE_L": 0.2127164942461932, "CIDEr": 2.7840859305955503e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a city street with tall buildings on either side. There are cars parked on the side of the road and people walking in the street. The sky is clear and blue.\n\nThe image is in black and white, with the buildings and cars in shades of gray. The sky is a deep"}, "38029": {"image_id": 38029, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.06989787123302858, "Bleu_4": 9.090870283563952e-06, "METEOR": 0.24396432821326905, "ROUGE_L": 0.2707672796448954, "CIDEr": 4.093961212228664e-12, "SPICE": {"All": {"pr": 0.24, "re": 0.20689655172413793, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3076923076923077, "f": 0.29629629629629634, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a red fire truck driving down the street with people walking on the sidewalk. The truck has a large red fire hydrant on the back and a ladder on the side. There are people standing on the sidewalk and watching the truck drive by. The sky is clear and blue."}, "434494": {"image_id": 434494, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.16329931618231128, "Bleu_3": 0.0816439893537324, "Bleu_4": 1.0318886931044728e-05, "METEOR": 0.12089870389552992, "ROUGE_L": 0.2238532110091743, "CIDEr": 6.210437303217234e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 1.0, "f": 0.5555555555555556, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on a road next to a large construction site. They are wearing hard hats and safety vests, and one of them is holding a shovel. The road is covered in black tar, and there are large piles of dirt and gravel nearby. The"}, "171062": {"image_id": 171062, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.24716436952309112, "Bleu_3": 0.18818576254538588, "Bleu_4": 0.14905846009098764, "METEOR": 0.2819431472519354, "ROUGE_L": 0.30148270181219106, "CIDEr": 3.578827783285377e-13, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.21875, "f": 0.23728813559322032, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on a table in front of a television. The cat is looking at the television with its ears perked up. The television is showing a video game with a character running through a forest. The room is dimly lit with a few lamps on the table. There is a window on"}, "238866": {"image_id": 238866, "Bleu_1": 0.2333333333255556, "Bleu_2": 0.08969937018144897, "Bleu_3": 6.598930970176177e-07, "Bleu_4": 1.8061933873841354e-09, "METEOR": 0.16774842513789318, "ROUGE_L": 0.11753371868978806, "CIDEr": 0.0004391937968613183, "SPICE": {"All": {"pr": 0.1875, "re": 0.21428571428571427, "f": 0.19999999999999998, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a tray filled with doughnuts. The doughnuts are arranged in a circular pattern and appear to be freshly baked. There are no other objects in the image."}, "428454": {"image_id": 428454, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.1518578172003014, "Bleu_3": 0.0762588621312534, "Bleu_4": 9.656621220138898e-06, "METEOR": 0.2203360420356287, "ROUGE_L": 0.25507765830346474, "CIDEr": 4.562066075786697e-13, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a person in a snowboarding outfit standing on a snowy slope. The person is holding a kite in their hand and appears to be flying it. The sky is clear and blue, with a few clouds in the distance. The snow on the ground is packed and there are tracks from"}, "200945": {"image_id": 200945, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 0.08077421359130517, "Bleu_4": 1.0521736949759788e-05, "METEOR": 0.19414920727353688, "ROUGE_L": 0.28413627894596755, "CIDEr": 1.0957411524645593e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a hot dog on a bun with ketchup, mustard, and relish on top. There are also two slices of bread on the side. The bun is made of white bread and the hot dog is made of beef. The ketchup, mustard, and rel"}, "391139": {"image_id": 391139, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.19321055028292738, "Bleu_3": 0.1551269397027825, "Bleu_4": 0.12295514672072634, "METEOR": 0.3401996344907926, "ROUGE_L": 0.2995440196422308, "CIDEr": 1.0448122078147723e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.125, "f": 0.12244897959183673, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a small dog sitting on a wooden bench in front of a pumpkin patch. The dog is wearing a red collar and has a white patch on its forehead. The pumpkins in the patch are orange and yellow. The bench is made of wood and has a wooden seat"}, "440093": {"image_id": 440093, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.15508644003992356, "Bleu_3": 0.08115433313646976, "Bleu_4": 1.0498339569158865e-05, "METEOR": 0.19473453413357425, "ROUGE_L": 0.23843648208469054, "CIDEr": 3.4958981317484204e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.12, "f": 0.12499999999999997, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a person skateboarding on a skateboard. The person is wearing a black shirt and black pants, and has a black helmet on their head. The skateboard is black and has four wheels. The background is a concrete skate park with a few trees in"}, "555356": {"image_id": 555356, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.1474419561516563, "Bleu_3": 0.09960317042671256, "Bleu_4": 0.06923692285350443, "METEOR": 0.1525627578924223, "ROUGE_L": 0.2378476735118274, "CIDEr": 8.898281174533445e-09, "SPICE": {"All": {"pr": 0.09375, "re": 0.10714285714285714, "f": 0.09999999999999999, "fn": 25.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a microwave oven on a countertop next to a sink. The microwave has a piece of aluminum foil on top of it. The sink has a faucet and a drain. The countertop is made of white marble. The room is well lit by"}, "561270": {"image_id": 561270, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.11919074177008733, "Bleu_4": 0.07628504220422326, "METEOR": 0.23920285306415026, "ROUGE_L": 0.30917384693360367, "CIDEr": 6.630118080228568e-08, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1, "f": 0.09302325581395349, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a small fishing boat docked at a pier on a body of water. The boat is red and has a white hull. There are several other boats docked at the pier, and the water is calm and peaceful. The sky is cloudy and there are some clouds in the distance."}, "351557": {"image_id": 351557, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.0767719506444456, "Bleu_4": 9.802862511748142e-06, "METEOR": 0.1708869750311956, "ROUGE_L": 0.18373493975903615, "CIDEr": 9.906764990916254e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.20833333333333334, "f": 0.1851851851851852, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a building with a large flag on top\n\nThe people in the image are wearing different colored shirts and pants, and some of them are holding umbrellas. The building in the background has a large flag on top of it, and"}, "123131": {"image_id": 123131, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.17104186372845756, "Bleu_3": 0.12402886070651384, "Bleu_4": 0.08069357142283248, "METEOR": 0.27037905397490125, "ROUGE_L": 0.2401574803149606, "CIDEr": 5.21768436984133e-10, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.10344827586206896, "f": 0.10526315789473684, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a black semi-truck parked in a lot. The truck has a large grille on the front and a large bumper on the back. The truck is parked next to a white trailer with a large bumper on the back. There are several other"}, "326248": {"image_id": 326248, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.15075567228616532, "Bleu_3": 0.07494071883573872, "Bleu_4": 9.439944120577903e-06, "METEOR": 0.19546660842609362, "ROUGE_L": 0.18068720379146921, "CIDEr": 2.292865003563851e-13, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.13333333333333333, "f": 0.0975609756097561, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a tennis match in progress on a court. There are several players on the court, including one who is serving and another who is hitting the ball back and forth with his opponent. The crowd is watching from the stands, and there are several people on the sidelines, including a coach and a"}, "531852": {"image_id": 531852, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.1312781889814525, "Bleu_4": 0.11657633846364332, "METEOR": 0.2681729655968265, "ROUGE_L": 0.29397590361445786, "CIDEr": 1.60768019655508e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21052631578947367, "f": 0.186046511627907, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two men standing in a living room, one holding a video game controller and the other holding a remote control. The room is decorated with a large flat screen television and a couch. The men are wearing casual clothing and appear to be in their mid to late 20s."}, "205720": {"image_id": 205720, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.20391006635932993, "Bleu_3": 0.09281638782109244, "Bleu_4": 1.1189893497623519e-05, "METEOR": 0.22448434990643543, "ROUGE_L": 0.3272030651340996, "CIDEr": 2.901155423367986e-10, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.0625, "f": 0.052631578947368425, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a man standing on the deck of a boat, looking at his phone. The boat is docked at a pier in the background. The sky is clear and blue, with a few clouds in the distance. The man is wearing a red shirt and has a beard. The pier is made"}, "69223": {"image_id": 69223, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.13469311460752553, "Bleu_3": 7.085549531664319e-07, "Bleu_4": 1.6331935371037682e-09, "METEOR": 0.21280353147212408, "ROUGE_L": 0.18496058217101274, "CIDEr": 5.677986982118199e-13, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a large bathtub, a sink, and a toilet. The walls are made of marble and the floor is made of tile. There is a large window on one side of the room and a door on the other. The room is well lit and has a large"}, "233311": {"image_id": 233311, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.2912876324964225, "Bleu_3": 0.2520322252593822, "Bleu_4": 0.2154595406193038, "METEOR": 0.3767683622750232, "ROUGE_L": 0.34269662921348315, "CIDEr": 8.010523997776368e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16, "f": 0.1568627450980392, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a small monkey sitting on top of a wooden table with a bowl of oranges in front of it. The monkey is wearing a red scarf around its neck and has a toy in its hand. The table has a white cloth on it and there are some books and other items"}, "460294": {"image_id": 460294, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.1390596095466697, "Bleu_4": 0.10288402441619092, "METEOR": 0.2117095454946595, "ROUGE_L": 0.25553560742070613, "CIDEr": 1.3008639995829937e-09, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.06666666666666667, "f": 0.0689655172413793, "fn": 28.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people standing under umbrellas in a parking lot. They are all wearing sunglasses and some of them are holding bags. The building in the background is a brick structure with windows on the top floor. There are cars parked in the lot and a few"}, "107907": {"image_id": 107907, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.08359497709435722, "Bleu_3": 5.122150570969723e-07, "Bleu_4": 1.2740800388313793e-09, "METEOR": 0.1613760113663608, "ROUGE_L": 0.23961840628507297, "CIDEr": 3.4087814208852324e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a room with a large painting on the wall and a small table with a vase on it\n\nThe painting is a large abstract piece with bright colors and geometric shapes. The vase is made of ceramic and has a floral design on it. The room is dimly lit and has"}, "463084": {"image_id": 463084, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.25354627641398625, "Bleu_3": 0.22045556915017553, "Bleu_4": 0.18662062992784134, "METEOR": 0.27178928137827907, "ROUGE_L": 0.277834008097166, "CIDEr": 4.8338484334369166e-11, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.1, "f": 0.10256410256410256, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a bus stop on a street with buildings on either side. The bus stop has a sign that says \"Bus Stop\" and a bench for people to sit on. There are also some cars parked on the side of the road. The sky is cloudy and there are some trees in the background"}, "279621": {"image_id": 279621, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.11485555942835955, "Bleu_4": 0.07312149273625368, "METEOR": 0.22017091706459505, "ROUGE_L": 0.23775055679287305, "CIDEr": 3.6699203957151996e-13, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.05555555555555555, "f": 0.0425531914893617, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a train traveling along a track next to a river. The train is pulling a large container car and has a number of cars behind it. The track is surrounded by trees and hills in the background. The sky is clear and there are no clouds in sight.\n\nThe train is traveling at"}, "199438": {"image_id": 199438, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.18216065373578985, "Bleu_3": 0.15850031615011761, "Bleu_4": 0.13427296449588372, "METEOR": 0.20115916786973198, "ROUGE_L": 0.2760180995475113, "CIDEr": 8.751354653729352e-10, "SPICE": {"All": {"pr": 0.04, "re": 0.038461538461538464, "f": 0.0392156862745098, "fn": 25.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a man and woman in a canoe on a lake. The man is paddling the canoe while the woman is sitting in the back, looking out at the water. There are ducks swimming in the water around them. The sky is blue and there are trees on the shore."}, "160341": {"image_id": 160341, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 0.09970052069750876, "Bleu_4": 1.1749577059988188e-05, "METEOR": 0.15425415239176435, "ROUGE_L": 0.20666290231507625, "CIDEr": 2.8171959653792544e-12, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.07692307692307693, "f": 0.07692307692307693, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a ski resort with a small house on the left side of the image. There are several skiers and snowboards on the ground in front of the house. The sky is cloudy and there are some trees in the background.\n\nThe image is taken from a high angle, looking down at the"}, "571196": {"image_id": 571196, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1565560727682472, "Bleu_3": 0.0788478660803684, "Bleu_4": 1.0001000249876893e-05, "METEOR": 0.19691922591883226, "ROUGE_L": 0.2610024449877751, "CIDEr": 8.873271453727091e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bed with a book on it. The bed has a colorful floral pattern on the sheets and pillowcases. There is a lamp on the nightstand next to the bed. The room has a wooden floor and white walls.\n\nThe image shows a bed with a book on it."}, "370266": {"image_id": 370266, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1311863860222524, "Bleu_4": 0.09700218812496947, "METEOR": 0.19166305723349814, "ROUGE_L": 0.21863799283154117, "CIDEr": 5.71693045755854e-12, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.19047619047619047, "f": 0.16, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of sheep grazing in a green pasture with a white fence in the background. The sheep are standing in a line, looking at the camera. The sky is blue and there are trees in the background.\n\nThe image is taken from a distance, so the details are not very"}, "458487": {"image_id": 458487, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.06567895774161787, "Bleu_3": 4.448553400606041e-07, "Bleu_4": 1.163734197858576e-09, "METEOR": 0.14471570732993086, "ROUGE_L": 0.14602034709754638, "CIDEr": 1.5918866080348636e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.15625, "f": 0.17857142857142858, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.3333333333333333, "f": 0.3846153846153846, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a baseball game in progress. There are two players on the field, one at bat and the other on the mound. The umpire is standing behind the plate, watching the game. The crowd is seated in the stands, cheering and waving their arms. The field is green and"}, "521879": {"image_id": 521879, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.087675151639143, "Bleu_3": 5.287494182785523e-07, "Bleu_4": 1.304802808756457e-09, "METEOR": 0.14095311580708444, "ROUGE_L": 0.24710648148148148, "CIDEr": 6.334780867753404e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.3076923076923077, "f": 0.27586206896551724, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.2857142857142857, "re": 1.0, "f": 0.4444444444444445, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on the sidewalk in front of a horse drawn carriage. The people are dressed in costumes and hats, and they are holding flowers and other items. The carriage is decorated with flowers and other decorations. The sky is blue and there are trees in the background."}, "307784": {"image_id": 307784, "Bleu_1": 0.41176470587427916, "Bleu_2": 0.256675579162816, "Bleu_3": 0.1591835156119781, "Bleu_4": 0.09574437304568634, "METEOR": 0.26148976843226723, "ROUGE_L": 0.3999063451182393, "CIDEr": 0.014204073209547006, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image is of a kitchen with a white sink, a stove, and a refrigerator. There is a wooden cutting board on the counter and a knife on the counter. The walls are painted a light beige color and there is a tiled floor. The cabinets are white and the counter"}, "154095": {"image_id": 154095, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 9.222102361565573e-07, "Bleu_4": 2.0105373453653653e-09, "METEOR": 0.17605989572510003, "ROUGE_L": 0.22584228063680117, "CIDEr": 1.738448053976058e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a bedroom with a bed, a desk, and a television. There is a backpack on the floor next to the bed. The backpack has a blue and orange color scheme. The bed has a blue and white striped blanket on it. The desk has a computer and a"}, "222322": {"image_id": 222322, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.19908326484038252, "Bleu_3": 0.10053909397198176, "Bleu_4": 1.2788079462564404e-05, "METEOR": 0.20861895539611655, "ROUGE_L": 0.26703633445206476, "CIDEr": 1.0394777191054534e-06, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.13793103448275862, "f": 0.14545454545454548, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a view of the beach from a restaurant. There are several umbrellas on the sand, and people are sitting at tables on the beach. The water is clear and blue, and there are palm trees in the background."}, "227042": {"image_id": 227042, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 0.07502652544655376, "Bleu_4": 9.635230436528825e-06, "METEOR": 0.21601096963655053, "ROUGE_L": 0.28175519630484985, "CIDEr": 1.15835495993519e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of young men playing soccer on a field. They are wearing red and blue jerseys and white shorts. One player is kicking the ball with his foot while another player is trying to block it with his hand. The other players are watching the action and cheering."}, "155897": {"image_id": 155897, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.09078730341863991, "Bleu_4": 0.06316759949914878, "METEOR": 0.20435368459500278, "ROUGE_L": 0.19830949284785435, "CIDEr": 4.688852728736905e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman sitting on a bench, holding a sandwich in her hand. The sandwich appears to be made of bread, meat, and cheese. The woman is wearing a blue shirt and shorts, and has a red hat on her head. There are several people in the background"}, "33798": {"image_id": 33798, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.1671899541887144, "Bleu_3": 0.08130907204696848, "Bleu_4": 1.0132385609889835e-05, "METEOR": 0.24749364493209675, "ROUGE_L": 0.24355464293862653, "CIDEr": 4.464263612407936e-12, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.15151515151515152, "f": 0.18518518518518517, "fn": 28.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a living room with a couch, a coffee table, and a television. There is a window on the left side of the room with curtains open. The room is well lit with natural light coming in from the window. The walls are painted white and the floor is made of hardwood."}, "490794": {"image_id": 490794, "Bleu_1": 0.14545454545190087, "Bleu_2": 1.64121987969432e-09, "Bleu_3": 3.704127177650189e-12, "Bleu_4": 1.7681275091206876e-13, "METEOR": 0.11428571428571428, "ROUGE_L": 0.18340348767288037, "CIDEr": 3.0188631319201436e-13, "SPICE": {"All": {"pr": 0.41379310344827586, "re": 0.4444444444444444, "f": 0.4285714285714286, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 12.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5454545454545454, "re": 0.42857142857142855, "f": 0.4799999999999999, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a street with cars parked on both sides. There are trees on both sides of the street and a building in the background. The sky is blue and there are clouds in the sky.\n\nThe image is taken from a bird's eye view, looking down on the street. The camera is"}, "381925": {"image_id": 381925, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.09382178207455442, "Bleu_4": 0.06312871110153481, "METEOR": 0.2755387030989775, "ROUGE_L": 0.2658241638522715, "CIDEr": 5.86191685118415e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a girl sitting on a bench in front of a stone wall. She is wearing a grey hoodie and has her arms around her knees. The wall is made of large stones and has a small opening in it. There is a small tree growing out of the wall. The sky is"}, "145312": {"image_id": 145312, "Bleu_1": 0.1481481481454047, "Bleu_2": 1.6718995418871443e-09, "Bleu_3": 3.774032808846262e-12, "Bleu_4": 1.801821270464176e-13, "METEOR": 0.15046077677435793, "ROUGE_L": 0.17468499427262313, "CIDEr": 3.751360461389392e-13, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.2608695652173913, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a black and white dog standing on the grass with its head tilted back and its tongue hanging out of its mouth. The dog is wearing a purple collar with a silver tag on it. The dog is standing next to a tree with a large branch hanging down from it."}, "65798": {"image_id": 65798, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 0.09452749871058641, "Bleu_4": 0.06443466940642391, "METEOR": 0.24645114842480428, "ROUGE_L": 0.25176886792452824, "CIDEr": 1.8002653322312487e-09, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress on a large field. There are several players on the field, including a pitcher and a catcher. The crowd is cheering and waving their arms in the air. The field is covered in grass and there are several stands of seats in the background."}, "358817": {"image_id": 358817, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.06023659207271943, "Bleu_3": 4.143654503114468e-07, "Bleu_4": 1.0921823440882956e-09, "METEOR": 0.11672087484081159, "ROUGE_L": 0.14480712166172105, "CIDEr": 1.2180907041803177e-12, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a street with houses on either side. There are no cars on the road, and the sky is clear.\n\nThe houses are made of wood and have white trim around the windows and doors. There are no trees or other vegetation in the area. The street is lined with sidewalks"}, "188465": {"image_id": 188465, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.0930756528209598, "Bleu_4": 1.1213327957896794e-05, "METEOR": 0.21906566619766032, "ROUGE_L": 0.23961840628507297, "CIDEr": 1.7806884100443416e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19230769230769232, "f": 0.17857142857142855, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a baseball player hitting a home run in a stadium. The player is wearing a baseball uniform and has a bat in his hand. The crowd is cheering in the stands. The stadium is filled with people watching the game.\n\nThe image shows a baseball player hitting a home run in"}, "14285": {"image_id": 14285, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.2541301157273416, "Bleu_3": 0.1503555819220509, "Bleu_4": 1.569613264254681e-05, "METEOR": 0.27511178177193135, "ROUGE_L": 0.33906013137948454, "CIDEr": 1.9714460991249876e-13, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.16666666666666666, "f": 0.14545454545454548, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a cat lying on a bed in a room with a television and a desk in the background. The cat is looking up at the camera with its eyes closed. The room has a white wall with a blue and white mural on it. There is a window on the left side of the room with"}, "499631": {"image_id": 499631, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.21879748724223513, "Bleu_3": 0.17328685148662828, "Bleu_4": 0.1364744627849704, "METEOR": 0.2820439810587313, "ROUGE_L": 0.31282051282051276, "CIDEr": 1.3339689714738583e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.45, "f": 0.339622641509434, "fn": 11.0, "numImages": 1.0, "fp": 24.0, "tp": 9.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.875, "f": 0.6363636363636364, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The image is of a group of teddy bears sitting on a bench in front of a Christmas tree. The bears are wearing various outfits, including hats and scarves. The tree has ornaments and lights on it, and there is a red and white striped ribbon around the"}, "67342": {"image_id": 67342, "Bleu_1": 0.1296296296272291, "Bleu_2": 0.08565936145673987, "Bleu_3": 5.206135179390748e-07, "Bleu_4": 1.2897158477492774e-09, "METEOR": 0.15233359569563648, "ROUGE_L": 0.14575866188769412, "CIDEr": 2.978356180924912e-14, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.1111111111111111, "f": 0.13793103448275862, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a small bird perched on a metal rod, looking at a larger bird on the ground. The larger bird is looking at the smaller bird. The background is a green field with trees in the distance. The lighting is bright and the colors are vivid.\n\nThe image is of a small"}, "295728": {"image_id": 295728, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 8.960727674188578e-07, "Bleu_4": 2.01091766876923e-09, "METEOR": 0.22637156699583288, "ROUGE_L": 0.31302116741500957, "CIDEr": 5.018407046153748e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.19230769230769232, "f": 0.20408163265306123, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The clock is an ornate, brass and gold clock with a large face and intricate details. It is mounted on a marble base and surrounded by a large, ornate frame. The clock is located in the lobby of a large building.\n\nThe clock is an ornate, brass"}, "267951": {"image_id": 267951, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1295047816452144, "Bleu_3": 0.0685787273497866, "Bleu_4": 8.91763149698053e-06, "METEOR": 0.12771916096853622, "ROUGE_L": 0.17115600448933782, "CIDEr": 3.8598098372414865e-12, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.17857142857142858, "f": 0.1694915254237288, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5555555555555556, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows two zebras standing in a pen. They are both black and white with long necks and stripes on their backs. They are standing next to each other and looking at the camera. The pen is made of wood and has a fence around it. There is a small table in the"}, "2302": {"image_id": 2302, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.09125318612878565, "Bleu_4": 1.1336958836408244e-05, "METEOR": 0.22403267230527832, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.5652107673454663e-09, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08695652173913043, "f": 0.0851063829787234, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a group of people riding horses on a dirt path in front of a mountain range. The horses are wearing saddles and the riders are wearing backpacks. The mountain range is covered in snow and there are rocks and trees in the foreground.\n\nThe image is"}, "146397": {"image_id": 146397, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.09124485969890858, "Bleu_3": 0.0569816167278448, "Bleu_4": 8.05263299613596e-06, "METEOR": 0.15827929586519413, "ROUGE_L": 0.24416277518345564, "CIDEr": 9.217216237085087e-10, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.15151515151515152, "f": 0.16666666666666666, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of young men in black shirts and jeans standing on a skateboard ramp. They are all wearing sunglasses and have their arms outstretched in different directions. The ramp is made of concrete and has a red line down the middle. There are"}, "122981": {"image_id": 122981, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.25354627641398625, "Bleu_3": 0.21196796658581052, "Bleu_4": 0.17313154670772338, "METEOR": 0.2392805193119185, "ROUGE_L": 0.2476798143851508, "CIDEr": 1.2989382185633156e-12, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.1875, "f": 0.14285714285714285, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a young boy wearing a green shirt and blue pants standing in front of a bus. The bus is white with a red stripe on the side. The boy is looking up at the bus with a serious expression on his face. There are two other people standing next to him, one of"}, "227878": {"image_id": 227878, "Bleu_1": 0.1694915254208561, "Bleu_2": 0.1081160058385353, "Bleu_3": 0.07429821419893697, "Bleu_4": 9.250959395998021e-06, "METEOR": 0.12909676459640598, "ROUGE_L": 0.15601023017902815, "CIDEr": 9.119567272912111e-13, "SPICE": {"All": {"pr": 0.24, "re": 0.23076923076923078, "f": 0.23529411764705882, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a living room with a fish tank on the floor and a cat sitting on the couch. The fish tank has a blue and green fish swimming in it. The cat is looking at the fish with a curious expression on its face. The walls of the room are painted a light blue color and there"}, "286858": {"image_id": 286858, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.11172119198541168, "Bleu_4": 1.2922875770638225e-05, "METEOR": 0.2015357493935701, "ROUGE_L": 0.22195269860521533, "CIDEr": 4.417278596205676e-12, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.17857142857142858, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a stuffed animal sitting on a bed. The animal is wearing a red shirt and has a big smile on its face. The bed is covered in a blue and white striped blanket. There is a lamp on the nightstand next to the bed. The lamp has a purple and"}, "459680": {"image_id": 459680, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.194191754997615, "Bleu_3": 0.12875644765560088, "Bleu_4": 0.08004346926940502, "METEOR": 0.2392620847339018, "ROUGE_L": 0.25676488274203246, "CIDEr": 2.103786605237428e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.2692307692307692, "f": 0.2592592592592593, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a woman in a pink dress standing in front of a building with an umbrella in her hand. She is wearing a white apron and has a white hat on her head. The building behind her has a large window on the top floor and a small balcony on the bottom floor"}, "462677": {"image_id": 462677, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.1412673303879691, "Bleu_3": 0.10549005488471223, "Bleu_4": 0.0696091190691511, "METEOR": 0.16319611159528571, "ROUGE_L": 0.28237472514755235, "CIDEr": 1.0236651799107236e-08, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.2857142857142857, "f": 0.3389830508474576, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.23076923076923078, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.5833333333333334, "re": 0.5384615384615384, "f": 0.5599999999999999, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image shows a blue mailbox on the side of the road. The mailbox has a sign on it that says, \"Please do not park on the sidewalk.\" The image is taken from a low angle, looking down at the mailbox. The sky is cloudy and there are no other objects in the"}, "90520": {"image_id": 90520, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.09288407280072536, "Bleu_3": 5.60482607100497e-07, "Bleu_4": 1.3839209880654026e-09, "METEOR": 0.16006475102301534, "ROUGE_L": 0.23416506717850286, "CIDEr": 1.70436251473573e-11, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.24, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.45454545454545453, "f": 0.3846153846153846, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a group of stuffed animals dressed in traditional Japanese clothing, including a white bear and a black bear. The white bear is wearing a red and white kimono, while the black bear is wearing a blue and white kimono. The bears are standing in front of a display"}, "552866": {"image_id": 552866, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.15891043153801604, "Bleu_3": 0.09840556216680423, "Bleu_4": 1.1634933331700792e-05, "METEOR": 0.22441769592671962, "ROUGE_L": 0.24110671936758893, "CIDEr": 7.976078038982862e-13, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.03225806451612903, "f": 0.037037037037037035, "fn": 30.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image is a black and white photograph of the Houses of Parliament in London, England. The building is a large, imposing structure with a clock tower in the center. The clock tower is covered in clocks and has a large bell at the top. The building is surrounded by a large, open space with"}, "337083": {"image_id": 337083, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.20100756304815393, "Bleu_3": 0.13175185157163616, "Bleu_4": 0.08143605172498537, "METEOR": 0.2730201113358892, "ROUGE_L": 0.2872277810476751, "CIDEr": 6.324777849136177e-13, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The building is a large, brick building with a clock tower on top. The building has a green awning over the front door and a large, green sign that reads \"The Hotel\". The building is surrounded by trees and has a sidewalk in front of it. There are several cars parked on the street in"}, "304828": {"image_id": 304828, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.15358798518821365, "Bleu_3": 8.063074221722026e-07, "Bleu_4": 1.8578571750592391e-09, "METEOR": 0.20200315618661976, "ROUGE_L": 0.26571250777846916, "CIDEr": 5.838074513111176e-09, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.3333333333333333, "f": 0.27450980392156865, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing in a dry, grassy area with trees in the background. The giraffe's legs are bent and its tail is long. The sun is shining down on the giraffe's back. The image is taken from a bird's eye view."}, "506115": {"image_id": 506115, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.20550493309104517, "Bleu_3": 0.15005305089310744, "Bleu_4": 0.09112438336159143, "METEOR": 0.25728572467286553, "ROUGE_L": 0.3505747126436782, "CIDEr": 2.5757615196356807e-06, "SPICE": {"All": {"pr": 0.1, "re": 0.12, "f": 0.1090909090909091, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on a bus, with soccer balls in their laps. They are all wearing soccer jerseys and have their arms around each other. The bus is parked in front of a building with a large window on the side. The sky is blue and there"}, "147179": {"image_id": 147179, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.13712011930431073, "ROUGE_L": 0.14796846573681016, "CIDEr": 3.748810385349578e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on a couch in a living room. They are all wearing casual clothing and appear to be relaxing. The room is decorated with a few pieces of furniture, including a coffee table and a television. There is a window in the background that provides natural"}, "549718": {"image_id": 549718, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.2047650389408227, "Bleu_3": 0.16912968543226087, "Bleu_4": 0.1298831014470632, "METEOR": 0.27215199568706333, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.2879788062165721e-12, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a yellow and blue bus driving down the street. The bus has a large windshield and a small front bumper. The bus is driving on the left side of the road and there are buildings on the right side of the road. There are no other vehicles on the road.\n\nThe"}, "160820": {"image_id": 160820, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.10033557298297395, "Bleu_4": 1.1749577059992224e-05, "METEOR": 0.20805993769268807, "ROUGE_L": 0.2426136363636364, "CIDEr": 2.753422012675079e-12, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of sheep grazing in a green field surrounded by trees. The sheep are white and have black spots on their backs. The trees are tall and green, with leaves on their branches. The sky is blue and there are clouds in it. The grass is green and there are yellow flowers"}, "517629": {"image_id": 517629, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.12126781251581158, "Bleu_3": 0.08378836055206638, "Bleu_4": 0.058862506260257914, "METEOR": 0.20114381788018879, "ROUGE_L": 0.2167219327333018, "CIDEr": 1.3668001767319884e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The cat is sitting in a sink, looking up at the camera with its mouth open. The cat's fur is white with black spots. The sink is made of stainless steel and has a faucet on the right side. There is a towel on the counter next to the sink. The"}, "433277": {"image_id": 433277, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.08058229640108601, "Bleu_3": 0.04935848712474826, "Bleu_4": 6.901641753463998e-06, "METEOR": 0.20563155565967622, "ROUGE_L": 0.1769141531322506, "CIDEr": 8.073611935299687e-14, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a desk with a computer monitor on it. The monitor is displaying a landscape image with mountains in the background. There is a lamp on the desk and a chair in front of it. The walls are painted a light color and there is a window on the left side of the room."}, "487498": {"image_id": 487498, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.08979301819262463, "Bleu_4": 0.06199874625320648, "METEOR": 0.16037795001378838, "ROUGE_L": 0.15365239294710328, "CIDEr": 1.9322887179769085e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.18518518518518517, "f": 0.20408163265306123, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people standing under an umbrella in a garden. They are all wearing red and white striped shirts and black pants. One of them is holding a sign that reads, `the best way to get to know someone is to talk to them`. The other two are"}, "90640": {"image_id": 90640, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.20604084591910862, "Bleu_3": 0.13567065103689688, "Bleu_4": 0.09997224149434299, "METEOR": 0.2605470883758139, "ROUGE_L": 0.2959369314736203, "CIDEr": 3.0487343178794777e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of elephants walking down a street in a city. They are wearing saddles and are led by a man on a horse. There are people standing on the sidewalk watching them. The street is lined with buildings and there are cars parked on the side of the road"}, "470173": {"image_id": 470173, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1295047816452144, "Bleu_3": 6.857872734978661e-07, "Bleu_4": 1.5858040477395045e-09, "METEOR": 0.20297311795618572, "ROUGE_L": 0.21048999309868874, "CIDEr": 1.8347897314185826e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13793103448275862, "f": 0.1509433962264151, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The statue is of a woman holding a jug of water on her head. She is standing in front of a tree with leaves and branches. The statue is made of bronze and has a green patina. The woman is wearing a long, flowing dress with a white sash around her waist. She has"}, "536183": {"image_id": 536183, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 0.09970052069750876, "Bleu_4": 0.06607272734339885, "METEOR": 0.21300354523335396, "ROUGE_L": 0.24358243011979464, "CIDEr": 4.052514048992813e-13, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.35294117647058826, "f": 0.27272727272727276, "fn": 11.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a pot of stew on a stove with vegetables and meat in it. The pot has a lid on it and there is a spoon in it. The stove has a burner on it and there is a wooden cutting board next to it. The kitchen has a window in the background"}, "523597": {"image_id": 523597, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.214201664184383, "Bleu_3": 0.15529943088229656, "Bleu_4": 0.1117698293151636, "METEOR": 0.2991259282871922, "ROUGE_L": 0.29415310427968655, "CIDEr": 7.01089838284062e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.23809523809523808, "f": 0.21276595744680848, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man riding a motorcycle on a dirt road. The man is wearing a white turban and a white shirt, and he is holding onto the handlebars of the motorcycle. The road is winding and there are trees on either side of it. The sky is blue and"}, "366178": {"image_id": 366178, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.2201927530212316, "Bleu_3": 0.12230758461254293, "Bleu_4": 0.07701746258925353, "METEOR": 0.2445183189720004, "ROUGE_L": 0.2324442025040827, "CIDEr": 4.813284053538785e-11, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a snowy road with a yellow sign on the side of the road. The sign has a picture of a person walking on the sidewalk. There are no other cars or people in the image. The sky is cloudy and there is no sunlight. The image is taken from a bird's"}, "11260": {"image_id": 11260, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.10050378152407698, "Bleu_3": 0.05754792186290891, "Bleu_4": 7.780748864621926e-06, "METEOR": 0.24244860162412504, "ROUGE_L": 0.27006087437742116, "CIDEr": 1.212840207744651e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a train traveling on a railroad track next to a body of water. The train is white and has a number on the side. There are people standing on the platform and in the background, there is a bridge. The sky is blue and there are clouds in the sky.\n\nThe train"}, "92765": {"image_id": 92765, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1234482786556696, "Bleu_3": 6.685490874553478e-07, "Bleu_4": 1.563534520202163e-09, "METEOR": 0.1590999975130491, "ROUGE_L": 0.24811156304474144, "CIDEr": 4.940659532256447e-12, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.3684210526315789, "f": 0.30434782608695654, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6666666666666666, "f": 0.5217391304347826, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a market with a variety of bananas on display\n\nThe market has a number of people shopping for produce. There are several tables with fruit and vegetables on them. There are also several people standing around the market, looking at the produce.\n\nThe sky is blue and there are some"}, "171936": {"image_id": 171936, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 0.07417848716778727, "Bleu_4": 9.65348251762417e-06, "METEOR": 0.21823536579210906, "ROUGE_L": 0.16245006657789615, "CIDEr": 1.1317840498167674e-10, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a small kitchen with a stove, sink, and refrigerator. There is a table and chairs in the living room. The walls are painted white and the floor is made of hardwood. The room is well lit and there are windows on two sides. The furniture is minimalist"}, "244401": {"image_id": 244401, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.21223817998318864, "Bleu_3": 0.15687969824156972, "Bleu_4": 0.10322985794503843, "METEOR": 0.29462105646824893, "ROUGE_L": 0.3017312448474856, "CIDEr": 1.4776047851800681e-05, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.03125, "f": 0.03571428571428572, "fn": 31.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.07692307692307693, "f": 0.08, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a variety of vegetables and fruits arranged on a wooden crate. The vegetables include carrots, beets, lettuce, and tomatoes. The fruits include apples, oranges, and grapes. The crate is labeled with the words \"CSA\""}, "534122": {"image_id": 534122, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.08062577022864871, "Bleu_4": 1.006845569565764e-05, "METEOR": 0.1696500685321523, "ROUGE_L": 0.24970760233918127, "CIDEr": 2.0130160528373563e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.1875, "f": 0.13043478260869568, "fn": 13.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man standing on the beach, looking out at the ocean. He is wearing a white shirt and blue shorts, and his hair is blowing in the wind. The sky is clear and blue, and there are no clouds in sight. The beach is covered in sand and there are some"}, "366099": {"image_id": 366099, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.29814239699327133, "Bleu_3": 0.20221483082839667, "Bleu_4": 0.11845337267219634, "METEOR": 0.21322221461025645, "ROUGE_L": 0.3233929754804506, "CIDEr": 6.410084270463998e-08, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.16129032258064516, "f": 0.17543859649122806, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a pizza with various toppings such as olives, tomatoes, and cheese on top of a crust. The pizza is cut into slices and placed on a wooden cutting board. The background is a white tablecloth with a red and white checkered pattern."}, "503135": {"image_id": 503135, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.13730875909260604, "Bleu_3": 0.07224517156389941, "Bleu_4": 9.366074329820156e-06, "METEOR": 0.14170830501547402, "ROUGE_L": 0.21131639722863746, "CIDEr": 1.0382143441570091e-10, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.22727272727272727, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a police officer on a motorcycle. The officer is wearing a helmet and has a radio on his chest. The motorcycle is black and has a blue light on the front. There are people standing on the sidewalk watching the officer ride by.\n\nThe image shows a police officer"}, "200807": {"image_id": 200807, "Bleu_1": 0.48076923075998523, "Bleu_2": 0.3500700210002044, "Bleu_3": 0.21402603671946785, "Bleu_4": 0.11893260654297591, "METEOR": 0.27889332298198105, "ROUGE_L": 0.28514190317195326, "CIDEr": 2.8365015154881315e-08, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.09523809523809523, "f": 0.07017543859649122, "fn": 19.0, "numImages": 1.0, "fp": 34.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a woman standing on a wooden floor, wearing a pair of black and white striped socks, a red umbrella, and a pair of black shoes. The woman is standing in front of a wooden door with a window on it. The floor is made of wooden planks and there"}, "328805": {"image_id": 328805, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1191907417701306, "Bleu_4": 0.09027070761263256, "METEOR": 0.19127337779050277, "ROUGE_L": 0.2770478507704785, "CIDEr": 1.8805246748889174e-09, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted yellow and the floor is made of black and white tiles. There is a window on the left side of the room and a door on the right side. The room is well lit and has a fan on the"}, "445055": {"image_id": 445055, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.08243669902025869, "Bleu_4": 1.0393938325822104e-05, "METEOR": 0.21878710827871067, "ROUGE_L": 0.2501464557703574, "CIDEr": 9.242983870692391e-08, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.1, "f": 0.0851063829787234, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man and a boy standing on a surfboard in the ocean. The man is holding the boy's hand and they are both wearing wetsuits. The waves are crashing against the shore and there are other people in the background surfing. The sky is cloudy and there"}, "387223": {"image_id": 387223, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.20195126571496114, "Bleu_3": 0.11851564692759443, "Bleu_4": 0.07673994070116022, "METEOR": 0.15307539833344208, "ROUGE_L": 0.24497991967871488, "CIDEr": 3.5982027866620726e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.08695652173913043, "f": 0.09302325581395349, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a flock of sheep grazing on a snowy hillside next to a river. The sky is cloudy and there are trees in the background.\n\nThe sheep are white with black spots and appear to be grazing on the grass. The river is frozen and there are no boats"}, "436349": {"image_id": 436349, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.07001400420004092, "Bleu_3": 4.611051180784598e-07, "Bleu_4": 1.189326065429759e-09, "METEOR": 0.12043010752688173, "ROUGE_L": 0.18373493975903615, "CIDEr": 5.216303366457658e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of trucks parked on the side of a road. The trucks are painted in bright colors and have different designs on them. There are people standing around the trucks and some are walking in the background. The sky is cloudy and there are buildings in the distance."}, "51335": {"image_id": 51335, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.23791547571099586, "Bleu_3": 0.18692372654627673, "Bleu_4": 0.15044258140713676, "METEOR": 0.3458755334318144, "ROUGE_L": 0.3279569892473118, "CIDEr": 7.288240003484113e-11, "SPICE": {"All": {"pr": 0.03125, "re": 0.038461538461538464, "f": 0.034482758620689655, "fn": 25.0, "numImages": 1.0, "fp": 31.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.08333333333333333, "f": 0.07692307692307691, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "The image shows a man sitting at a wooden table with a plate of food in front of him. He is wearing a white shirt and black pants, and has a beard. There are several other people sitting at the table, eating food. The background is a busy street with cars and people walking"}, "515531": {"image_id": 515531, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.20565318641151553, "Bleu_3": 0.14543068929524094, "Bleu_4": 0.08687475782560027, "METEOR": 0.2685190760203475, "ROUGE_L": 0.2627894453419494, "CIDEr": 1.3885813210004857e-12, "SPICE": {"All": {"pr": 0.04, "re": 0.05, "f": 0.044444444444444446, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a plane flying in front of a full moon. The plane is white and has a red tail. The moon is full and appears to be in the sky. The sky is dark and there are some clouds in the background. The image is taken at night.\n\nThe image shows a plane flying in"}, "20371": {"image_id": 20371, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 0.10819261558495435, "Bleu_4": 0.07243671671646894, "METEOR": 0.21459825166907928, "ROUGE_L": 0.24190350297422336, "CIDEr": 2.8384952934891e-10, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09090909090909091, "f": 0.08888888888888888, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a pigeon sitting on a ledge, looking down at the ground. The bird has a black and white plumage and a beak that is open. The ledge is made of metal and has a railing on either side. The sky is clear and blue.\n\nThe image"}, "180653": {"image_id": 180653, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.20824828195446654, "Bleu_3": 0.09735426869589826, "Bleu_4": 1.190081738688603e-05, "METEOR": 0.26130223522270524, "ROUGE_L": 0.20158625247851947, "CIDEr": 6.253887008622239e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.20689655172413793, "f": 0.21052631578947367, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two people skiing in the snow. They are wearing ski gear and standing on skis. The man is wearing a black jacket and the woman is wearing a red jacket. They are standing in a snowy forest with trees in the background.\n\nThe image is in"}, "373382": {"image_id": 373382, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.07250583813278431, "Bleu_4": 9.252921909857738e-06, "METEOR": 0.1801755815991933, "ROUGE_L": 0.24110671936758893, "CIDEr": 7.580773174592955e-12, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.06896551724137931, "f": 0.06896551724137931, "fn": 27.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a tennis player hitting a ball with a racket on a tennis court. The player is wearing white clothing and has a white hat on his head. The crowd is watching the player hit the ball.\n\nThe image shows a tennis player hitting a ball with a racket on a tennis court"}, "515642": {"image_id": 515642, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 0.0858725358973738, "Bleu_4": 1.0831815605763862e-05, "METEOR": 0.2823959008182302, "ROUGE_L": 0.26341764342998153, "CIDEr": 1.4080187224835603e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a remote control sitting on top of a book. The book is open and has a page with writing on it. The remote control has buttons on it and a screen that displays a channel number. The book is on a table next to a toilet."}, "276254": {"image_id": 276254, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.10654502541910188, "Bleu_4": 1.2409587310674509e-05, "METEOR": 0.1992258840710077, "ROUGE_L": 0.2770478507704785, "CIDEr": 3.444642770238611e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.23076923076923078, "f": 0.21428571428571427, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a view of a small town on the water with several boats docked at the shore. There are buildings on the hillside in the background. The sky is clear and blue.\n\nThe image is taken from a high vantage point, looking down on the town. The boats are all different sizes"}, "332377": {"image_id": 332377, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.09875106606632027, "Bleu_3": 5.962685701989571e-07, "Bleu_4": 1.4732563104646528e-09, "METEOR": 0.17313660880194431, "ROUGE_L": 0.20013123359580048, "CIDEr": 1.381455480562817e-09, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2777777777777778, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a table with two doughnuts on it. One of the doughnuts is red and the other is white. There are also two cups of coffee on the table. The table is made of wood and has a white tablecloth on it. The doughnuts are placed"}, "66675": {"image_id": 66675, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.09267924750141882, "Bleu_4": 1.1469577394366865e-05, "METEOR": 0.15133328553598524, "ROUGE_L": 0.2576946288473144, "CIDEr": 4.1416397132571177e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a woman and a man standing in a bedroom. The woman is wearing a black sweater and black pants, while the man is wearing a white shirt and black pants. They are both holding onto a blanket. The room has a white ceiling, a white wall,"}, "578752": {"image_id": 578752, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.21148042285421853, "Bleu_3": 0.13715745469957313, "Bleu_4": 1.499760871672908e-05, "METEOR": 0.2601451144889076, "ROUGE_L": 0.21863799283154117, "CIDEr": 1.1131948803446547e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14814814814814814, "f": 0.15686274509803924, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person walking on the beach at sunset. The sky is clear and the sun is setting behind the horizon. The person is wearing a hat and carrying a surfboard. The sand is wet and there are footprints leading to the water. The waves are calm and there are no other"}, "411177": {"image_id": 411177, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1457945082861785, "Bleu_3": 0.07846510342081583, "Bleu_4": 1.029533066265393e-05, "METEOR": 0.17401295628176627, "ROUGE_L": 0.24830393487109906, "CIDEr": 2.7605164333837807e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.12903225806451613, "f": 0.14035087719298245, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a living room with a couch, coffee table, and rug. The walls are painted red and there is a chandelier hanging from the ceiling. The furniture is made of leather and wood.\n\nThe couch is brown and black with brown accents. The coffee"}, "12192": {"image_id": 12192, "Bleu_1": 0.37037037036351167, "Bleu_2": 0.2507849312830716, "Bleu_3": 0.15366451712909157, "Bleu_4": 1.6331935371043732e-05, "METEOR": 0.29247548060731776, "ROUGE_L": 0.3663663663663663, "CIDEr": 2.5293847839231386e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.24, "f": 0.23529411764705882, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a young boy playing with a tennis racket on the beach at sunset. The boy is standing in the water, holding the racket in his hand and looking out at the horizon. The sky is a deep orange color, with clouds scattered across it. The water is calm and clear, reflecting"}, "403657": {"image_id": 403657, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 0.0974311856710336, "Bleu_4": 1.1662213550197087e-05, "METEOR": 0.22617781781599672, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.695473251272151e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a red double decker bus driving down the street in front of the Houses of Parliament. The bus is traveling in the direction of the camera, and there are other cars and pedestrians on the street. The sky is blue and there are some clouds in the background. The Houses"}, "191672": {"image_id": 191672, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.10921336092038615, "Bleu_4": 1.2972311576394404e-05, "METEOR": 0.2328804768499434, "ROUGE_L": 0.30329397141081416, "CIDEr": 1.3667744861607882e-09, "SPICE": {"All": {"pr": 0.04, "re": 0.045454545454545456, "f": 0.0425531914893617, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and a helmet. The wave is large and the surfer is jumping off the top of it. The sky is blue and there are clouds in the background. The ocean is"}, "461945": {"image_id": 461945, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.10238251947041137, "Bleu_3": 0.05863398711091721, "Bleu_4": 7.929020238697525e-06, "METEOR": 0.21627652544208195, "ROUGE_L": 0.1783625730994152, "CIDEr": 2.0718024218832855e-12, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2777777777777778, "f": 0.21276595744680854, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.16666666666666666, "f": 0.1, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a black shirt and white shorts, and has a tennis racket in his hand. The court is made of grass and there are trees in the background. The sun is shining down on the court and the man is wearing s"}, "502979": {"image_id": 502979, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.08979301819262463, "Bleu_4": 0.06199874625320648, "METEOR": 0.17254511793506289, "ROUGE_L": 0.2482558139534883, "CIDEr": 1.2666643986891258e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.35714285714285715, "f": 0.25641025641025644, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting at a table in a restaurant. They are all wearing casual clothing and are enjoying their meals. The table has a white tablecloth and there are several glasses of wine on the table. The restaurant has a modern decor with a lot of lighting"}, "43448": {"image_id": 43448, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.24909123653704068, "Bleu_3": 0.16946066413438396, "Bleu_4": 0.11811816077501729, "METEOR": 0.23621027242862253, "ROUGE_L": 0.29651633810423983, "CIDEr": 1.4181334892543463e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.26666666666666666, "f": 0.26666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5, "f": 0.48000000000000004, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows two elephants standing on a rocky beach with trees in the background. The elephants are brown with large ears and tusks. They are standing next to each other and appear to be looking at something in the distance. The sky is blue and there are clouds in the background. The"}, "55022": {"image_id": 55022, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.13187609467625871, "Bleu_3": 7.338824344329119e-07, "Bleu_4": 1.741216427287497e-09, "METEOR": 0.17146333036180225, "ROUGE_L": 0.16553595658073267, "CIDEr": 1.9018146032005387e-09, "SPICE": {"All": {"pr": 0.12, "re": 0.14285714285714285, "f": 0.13043478260869565, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bicycle parked in front of a store with a sign that reads, \"Bicycle Rental\"\n\nThe bicycle is a pink and white one with a basket on the front. The handlebars are black and the seat is black and white. The tires are"}, "204661": {"image_id": 204661, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.16903085094265752, "Bleu_3": 0.14697037943345037, "Bleu_4": 0.12441375328522758, "METEOR": 0.28639088730121665, "ROUGE_L": 0.2772727272727273, "CIDEr": 3.8398564902312476e-13, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a person holding a cell phone in their hand. The phone has a touch screen and a keyboard on the front. There are several other electronic devices on the table, including a laptop and a printer. The person is wearing a white shirt and black pants. The background is a dark brown color"}, "259983": {"image_id": 259983, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1922322627296484, "Bleu_3": 0.11391235988457692, "Bleu_4": 1.317889860975062e-05, "METEOR": 0.278841778233939, "ROUGE_L": 0.2544696066746126, "CIDEr": 4.1269868339740257e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.23076923076923078, "f": 0.15384615384615388, "fn": 10.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a white kitchen with a stove and oven. The stove has a gas burner on top and a dish rack on the side. The oven has a door that is open and there are pots and pans on the counter. There is a sink in the corner of the"}, "343561": {"image_id": 343561, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.18614286144776201, "ROUGE_L": 0.2293233082706767, "CIDEr": 1.1119348747861271e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a group of cyclists riding in a peloton on a road. They are all wearing yellow jerseys with blue shorts and white shoes. The riders are in a line, with the lead rider in the front. There are people watching from the side of the"}, "559665": {"image_id": 559665, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.10966267342231086, "Bleu_3": 0.06441223689630492, "Bleu_4": 8.828016109821917e-06, "METEOR": 0.1475237240476578, "ROUGE_L": 0.19869706840390877, "CIDEr": 5.039511638221411e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09090909090909091, "f": 0.08888888888888888, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a man riding a motorcycle on the side of the road. He is wearing a black leather jacket and sunglasses, and has a helmet on his head. There are other cars and trucks passing by on the road.\n\nThe image is taken from a"}, "137003": {"image_id": 137003, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.13026252642719696, "Bleu_3": 0.08788194533129831, "Bleu_4": 0.06100644612885832, "METEOR": 0.23735083738821056, "ROUGE_L": 0.23047858942065497, "CIDEr": 1.3218412630769966e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.24, "f": 0.2264150943396226, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young girl holding a kite in a field. The girl is wearing a pink and white striped shirt and blue jeans. The kite is made of colorful fabric and has a long tail. The background is a green field with trees in the distance. The sky is blue"}, "338203": {"image_id": 338203, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.10942600553008858, "Bleu_4": 0.08466528301619354, "METEOR": 0.249700825016702, "ROUGE_L": 0.2853801169590643, "CIDEr": 1.3258370866105662e-11, "SPICE": {"All": {"pr": 0.15, "re": 0.2, "f": 0.17142857142857143, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a large brown and black bird perched on a tree branch. The bird has a sharp beak and sharp talons. The bird is looking down at the ground. The tree is a tall, thin tree with a lot of branches. The sky is blue and cloudy. The background is a grass"}, "238691": {"image_id": 238691, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.0922138891935132, "Bleu_3": 5.655855085604915e-07, "Bleu_4": 1.4082645504822834e-09, "METEOR": 0.10507462686567165, "ROUGE_L": 0.15752098127824402, "CIDEr": 2.672119343993929e-09, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.0625, "f": 0.06451612903225808, "fn": 30.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in a line at an airport. They are all wearing sunglasses and carrying luggage. There are several other people in the background, walking through the airport. The floor is made of white tiles and there are several signs on the walls."}, "454610": {"image_id": 454610, "Bleu_1": 0.333333333325926, "Bleu_2": 0.17407765595178554, "Bleu_3": 0.0889895891077732, "Bleu_4": 1.1381305436598616e-05, "METEOR": 0.14545454545454548, "ROUGE_L": 0.168391994478951, "CIDEr": 3.416504020638455e-08, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.19047619047619047, "f": 0.14814814814814814, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a boat in a river. The boat is filled with various fruits and vegetables, including watermelons, pineapples, and bananas. There are also some baskets of fish on the boat. The people are wearing traditional Thai cl"}, "163057": {"image_id": 163057, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.17504208247906033, "Bleu_3": 0.12014621934667156, "Bleu_4": 0.07599442723762243, "METEOR": 0.18534672475802147, "ROUGE_L": 0.24358243011979464, "CIDEr": 6.144484915850342e-12, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 27.0, "numImages": 1.0, "fp": 29.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}}, "caption": "The image shows a group of people playing kite in a park. The kites are made of paper and have different shapes and colors. The people are standing on the grass and holding the kites with their hands. There are trees in the background and a building in the distance.\n\nThe image is taken on"}, "493623": {"image_id": 493623, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.17094086468637668, "Bleu_3": 8.148906680071045e-07, "Bleu_4": 1.7875390616780399e-09, "METEOR": 0.19998895898263008, "ROUGE_L": 0.2476798143851508, "CIDEr": 3.1168873457968034e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a woman standing in front of a white wall with a pink flower arrangement on the floor. She is wearing a white dress and has a bouquet of flowers in her hand. There are two white vases on the floor next to her. The wall has a white and gray pattern on it."}, "564940": {"image_id": 564940, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.2390457218620491, "Bleu_3": 0.15285535436331962, "Bleu_4": 1.660297934705131e-05, "METEOR": 0.23059914718319166, "ROUGE_L": 0.22938079719227877, "CIDEr": 7.330694571308797e-11, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.29411764705882354, "f": 0.2173913043478261, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of stuffed animals sitting on a table. They are all wearing black shirts with the word \"love\" written on them.\n\nThe stuffed animals are all different sizes and shapes, and they are all sitting in a row on the table. They are all looking at"}, "423229": {"image_id": 423229, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.09901475429574468, "Bleu_3": 5.809560444813124e-07, "Bleu_4": 1.414355019067261e-09, "METEOR": 0.21050352240830736, "ROUGE_L": 0.17428571428571427, "CIDEr": 6.597849280459571e-09, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.14285714285714285, "f": 0.09090909090909091, "fn": 12.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The train is traveling down the tracks, with people on board. The train is pulling into a station, with a sign that says `Welcome to the town of'. The train is made of wood and has a steam engine. The people on board are wearing hats and coats, and they are looking"}, "412571": {"image_id": 412571, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1577557537051747, "Bleu_3": 0.09984894236626275, "Bleu_4": 1.1938742404395867e-05, "METEOR": 0.17918843602165233, "ROUGE_L": 0.18780788177339902, "CIDEr": 9.795669970415994e-12, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.13333333333333333, "f": 0.13114754098360656, "fn": 26.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.2857142857142857, "f": 0.32, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a table with a variety of donuts on it. The donuts are arranged in a stack on the table. There are also some other food items on the table, such as cupcakes and cookies. The table is covered in a white tablecloth and there are some candles on it."}, "217760": {"image_id": 217760, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.12903971808302675, "Bleu_3": 0.07179233837245348, "Bleu_4": 9.576248453510562e-06, "METEOR": 0.19799778736676701, "ROUGE_L": 0.2749517063747585, "CIDEr": 4.219359146869342e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.13793103448275862, "f": 0.15384615384615385, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image is a black leather case with a zipper on the top and a pair of scissors inside. The scissors are open and the case is empty.\n\nThe image is a black leather case with a zipper on the top and a pair of scissors inside."}, "579893": {"image_id": 579893, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 0.09452749871058641, "Bleu_4": 0.06443466940642391, "METEOR": 0.20974308760416802, "ROUGE_L": 0.25176886792452824, "CIDEr": 1.4706566181683262e-10, "SPICE": {"All": {"pr": 0.08, "re": 0.09090909090909091, "f": 0.0851063829787234, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a street sign with the words \"stop\" and \"village\" written on it. The sign is on a tree lined street with leaves falling from the trees. The sky is blue and there are clouds in the background.\n\nThe image is taken in the fall season with the leaves changing"}, "5965": {"image_id": 5965, "Bleu_1": 0.16326530611911708, "Bleu_2": 0.1010152544531381, "Bleu_3": 6.010242872773113e-07, "Bleu_4": 1.4739391640949855e-09, "METEOR": 0.12157516643847228, "ROUGE_L": 0.15394321766561514, "CIDEr": 3.855855501105856e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a motorcycle parked in front of a building with a sign that reads \"country inn\" in the background. The motorcycle is black and has a white stripe down the side. The rider is wearing a helmet and sunglasses. The building is a two story structure with"}, "107375": {"image_id": 107375, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 0.06290089214849724, "Bleu_4": 8.441965712987706e-06, "METEOR": 0.1363330069427092, "ROUGE_L": 0.22048192771084338, "CIDEr": 6.553342627016504e-12, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.037037037037037035, "f": 0.03636363636363636, "fn": 26.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.07692307692307693, "f": 0.08, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The dog is standing in the middle of a dirt path surrounded by trees and bushes. The dog is wearing a collar and leash. The dog is looking up at the camera with its tongue hanging out of its mouth. The dog's fur is short and smooth. The dog's eyes"}, "115721": {"image_id": 115721, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1321752642838866, "Bleu_3": 0.06951827872345935, "Bleu_4": 9.009106352320882e-06, "METEOR": 0.18018761196548613, "ROUGE_L": 0.21863799283154117, "CIDEr": 1.7786030285420064e-12, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.21739130434782608, "f": 0.19230769230769232, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a dog lying on a couch with its head resting on its paws. The dog is wearing a red collar and has a tag on its neck. The background is a dark brown color with a pattern of small, white dots. The image is taken in a living room with a"}, "493509": {"image_id": 493509, "Bleu_1": 0.3962264150868637, "Bleu_2": 0.1511926461656511, "Bleu_3": 7.652976622561695e-07, "Bleu_4": 1.730335384335051e-09, "METEOR": 0.16728633613706104, "ROUGE_L": 0.18496058217101274, "CIDEr": 3.026668344949267e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.10526315789473684, "f": 0.0930232558139535, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows two people in yellow safety vests and hard hats standing in front of a building with a large window on the side. They are holding laptops and looking at something on the screen. The building appears to be under construction, with scaffolding and construction materials visible outside. The sky is"}, "507797": {"image_id": 507797, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.13820004148932422, "Bleu_4": 0.10188015780213461, "METEOR": 0.21573305756243674, "ROUGE_L": 0.26293103448275856, "CIDEr": 1.7201270788053938e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.1875, "f": 0.13043478260869568, "fn": 13.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 1.0, "f": 0.2857142857142857, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a bus. They are all wearing pink shirts and white pants. One woman is holding a purse and another woman is holding a suitcase. The bus is white and has a blue stripe down the side. There are no other people"}, "512830": {"image_id": 512830, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 0.10859118541728557, "Bleu_4": 0.07186801027046322, "METEOR": 0.25674439833963414, "ROUGE_L": 0.3051907442151345, "CIDEr": 5.7480165543179145e-11, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.19047619047619047, "f": 0.15384615384615383, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting in an airplane. They are all wearing military uniforms and have their hands on their laps. The plane is painted with a camouflage pattern and has a large window in the front. There are no other people in the plane.\n\nThe image is"}, "69969": {"image_id": 69969, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.08206099398471602, "Bleu_3": 0.05027274032560819, "Bleu_4": 7.030700263657399e-06, "METEOR": 0.15027109527466218, "ROUGE_L": 0.18047337278106512, "CIDEr": 2.181377524877572e-13, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.125, "f": 0.11320754716981132, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a large room with wooden tables and chairs. There are several people sitting at the tables, enjoying their meals. The walls are made of wood and there are windows on one side of the room that let in natural light. The floor is made of wood and there are rugs on it."}, "420466": {"image_id": 420466, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.0932504808219817, "Bleu_3": 0.058248287421989356, "Bleu_4": 8.233704127828195e-06, "METEOR": 0.17099913994678023, "ROUGE_L": 0.24830393487109906, "CIDEr": 4.141707472837973e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.21428571428571427, "f": 0.20689655172413796, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The giraffe is walking on the grassy hillside. It is a large animal with a long neck and legs. The giraffe is walking on the grassy hillside. It is a large animal with a long neck and legs.\n\nThe giraffe is walking on the grassy hillside"}, "529850": {"image_id": 529850, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.0799063530041829, "Bleu_4": 1.0207315006261666e-05, "METEOR": 0.21795345847240513, "ROUGE_L": 0.22732919254658387, "CIDEr": 6.10126931859366e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The man is sitting on the floor next to a suitcase. He is petting a black cat that is sitting on the suitcase. The man is wearing a white shirt and black pants. The cat is wearing a red collar. The room has a white countertop and a white refr"}, "397842": {"image_id": 397842, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.10090091909748747, "Bleu_3": 5.8831069922091e-07, "Bleu_4": 1.4277627265895718e-09, "METEOR": 0.16798082563751826, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.3561942257188915e-11, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.14285714285714285, "f": 0.08333333333333333, "fn": 12.0, "numImages": 1.0, "fp": 32.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a dog playing fetch in a backyard. The dog is brown and white with a long, fluffy coat. It is running towards the camera with its tongue hanging out of its mouth. The dog is wearing a collar and tag on its neck. The background is a green grassy"}, "48555": {"image_id": 48555, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.0986616396109014, "Bleu_4": 1.1893260654292823e-05, "METEOR": 0.21875810489476313, "ROUGE_L": 0.15259537210756724, "CIDEr": 1.9656442072835338e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two horses running on a beach with the ocean in the background. The horses are wearing saddles and riding on the sand. The sky is cloudy and there are waves crashing on the shore.\n\nThe image is in black and white and has a vintage feel to it"}, "51938": {"image_id": 51938, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1177966073469684, "Bleu_3": 6.755917700609673e-07, "Bleu_4": 1.6270469822163273e-09, "METEOR": 0.15235021065240667, "ROUGE_L": 0.19869706840390877, "CIDEr": 1.3853026910480619e-08, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1111111111111111, "f": 0.10256410256410256, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a person skiing down a snowy slope on a snowboard. The person is wearing a helmet and goggles, and has a ski pole in their hand. The background is a blue sky with fluffy white clouds.\n\nThe image is taken from a high angle,"}, "380516": {"image_id": 380516, "Bleu_1": 0.340909090901343, "Bleu_2": 0.21810252258335, "Bleu_3": 0.1313310331806951, "Bleu_4": 1.5331320282613666e-05, "METEOR": 0.28300764968655817, "ROUGE_L": 0.25318206972883234, "CIDEr": 6.915632076298602e-08, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09523809523809523, "f": 0.0851063829787234, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a young boy playing tennis on a blue court. He is wearing a white shirt and black shorts, and has a tennis racket in his hand. The court is surrounded by a fence, and there are people watching from the sidelines."}, "461009": {"image_id": 461009, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.24330354977564592, "Bleu_3": 0.17797917821545217, "Bleu_4": 0.1287770382798116, "METEOR": 0.22758355040033176, "ROUGE_L": 0.29735376044568246, "CIDEr": 8.074193101139049e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18518518518518517, "f": 0.17543859649122806, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man holding an apple in his hand. The man is wearing a white shirt and a black tie. The background is a blurred image of a group of people sitting at a table. The image is in black and white."}, "262323": {"image_id": 262323, "Bleu_1": 0.3599999999928, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.08491317075202565, "Bleu_4": 1.0683334564397808e-05, "METEOR": 0.2096827162588431, "ROUGE_L": 0.20696674960416198, "CIDEr": 1.2037637127153094e-08, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2222222222222222, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The giraffe is standing in the grass, looking at the camera. It has a long neck and spots on its fur. The zookeeper is standing next to it, holding a bucket of food. There are several other animals in the background, including a zebra and a lion. The sky is"}, "236049": {"image_id": 236049, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.20391006635932993, "Bleu_3": 0.1338643954524563, "Bleu_4": 0.09848356600726534, "METEOR": 0.19341340478814195, "ROUGE_L": 0.34173669467787116, "CIDEr": 1.1602223967319812e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.16666666666666666, "f": 0.17241379310344826, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a building with a large window on the side. The window has a bird perched on the sill, looking out. The building appears to be old and has a lot of damage to it.\n\nThe bird is looking out of the window, as if it is watching something outside. The building"}, "373374": {"image_id": 373374, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.0826422446045352, "Bleu_4": 1.0256732621419825e-05, "METEOR": 0.20369275714803373, "ROUGE_L": 0.2445589919816724, "CIDEr": 3.372248634165403e-12, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a plate of food on a table with a cup of coffee and a fork and knife on the side. The food appears to be a sandwich with shrimp and lettuce on a bun. There is also a glass of orange juice on the table. The background is a green la"}, "225603": {"image_id": 225603, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.08518740546037545, "Bleu_3": 5.220677531965598e-07, "Bleu_4": 1.298831014470151e-09, "METEOR": 0.14317111459968604, "ROUGE_L": 0.17183098591549298, "CIDEr": 2.363849511424391e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a plate of food with a steak on top and fries on the side. There is a glass of wine on the table and a bottle of beer on the shelf. The table has a white tablecloth and a red napkin. The background is a dark brown wall with a"}, "528729": {"image_id": 528729, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 6.47433787030964e-07, "Bleu_4": 1.558500916173644e-09, "METEOR": 0.15865364129174403, "ROUGE_L": 0.2208811104405552, "CIDEr": 6.631950860017084e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.10526315789473684, "f": 0.08888888888888889, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a man riding a bicycle on the sidewalk. He is wearing a white shirt and black pants. The bicycle has a red frame and black tires. There are cars parked on the street in the background. The sky is blue and there are trees in the"}, "317070": {"image_id": 317070, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.25392841118422627, "Bleu_3": 0.15698492397618355, "Bleu_4": 0.09426369082710973, "METEOR": 0.26071703788508593, "ROUGE_L": 0.25722891566265055, "CIDEr": 2.3722236792299416e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person on a surfboard in the ocean. The person is wearing a wetsuit and holding onto the board with their hands. The sky is cloudy and there are waves in the ocean. The person is jumping off the board and flying through the air. The water is choppy"}, "102331": {"image_id": 102331, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1360198059227937, "Bleu_3": 0.09368583412605459, "Bleu_4": 0.06574947308810801, "METEOR": 0.19530905043958366, "ROUGE_L": 0.19869706840390877, "CIDEr": 3.2132002929277734e-09, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.19047619047619047, "f": 0.14814814814814814, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a person on a dirt bike jumping over a sand dune. The person is wearing a green jersey and black pants, and has a helmet on their head. The background is a desert landscape with sand dunes and rocks.\n\nThe image is in focus,"}, "450452": {"image_id": 450452, "Bleu_1": 0.15999999999680004, "Bleu_2": 0.05714285714170266, "Bleu_3": 4.082199467684955e-07, "Bleu_4": 1.0968473790380015e-09, "METEOR": 0.14734947482090888, "ROUGE_L": 0.17753201396973226, "CIDEr": 2.5112110486889996e-10, "SPICE": {"All": {"pr": 0.08, "re": 0.1111111111111111, "f": 0.09302325581395349, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a broken clock hanging from a rusty metal pole on a dilapidated building. The clock has a cracked face and the hands are broken. The building is covered in graffiti and has a broken window.\n\n\nThe image is taken in a run down area of a city"}, "503292": {"image_id": 503292, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.13937882544862468, "Bleu_3": 7.557770425284017e-07, "Bleu_4": 1.769832242009009e-09, "METEOR": 0.18587370681895668, "ROUGE_L": 0.20847573479152426, "CIDEr": 5.705301247648003e-09, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.16, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a plane taking off from an airport runway. The plane is a Boeing 737, a narrow body, twin engine jet airliner. The plane is painted in the colors of Delta Air Lines, with a blue tail and white wings. The plane is taking off"}, "542248": {"image_id": 542248, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.23302069120966015, "Bleu_3": 0.1482450067653591, "Bleu_4": 1.605779967455532e-05, "METEOR": 0.24400670549998038, "ROUGE_L": 0.34269662921348315, "CIDEr": 4.945175815613715e-10, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.09375, "f": 0.10909090909090909, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a giraffe standing in a field of tall trees. The giraffe is brown with white spots on its back and legs. It is looking up at the trees with its head tilted to the side. The trees are tall and green, with leaves on the branches. There is a"}, "251019": {"image_id": 251019, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.22934123614279892, "Bleu_3": 0.16950408960775368, "Bleu_4": 0.11643235108895965, "METEOR": 0.26421398772259075, "ROUGE_L": 0.2830626450116009, "CIDEr": 2.328840531256331e-13, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.13636363636363635, "f": 0.10909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a young man in a red shirt and black shorts playing tennis on a court. He is holding a tennis racket and swinging it to hit the ball. The ball is flying through the air and the player is running to hit it. The background is a dark blue sky with white clouds."}, "48738": {"image_id": 48738, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.0933181271719728, "Bleu_3": 0.05547797716282366, "Bleu_4": 7.644480232985446e-06, "METEOR": 0.18255875143271785, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.3731489492316115e-12, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.17391304347826086, "f": 0.13793103448275862, "fn": 19.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.4444444444444444, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image shows a bighorn sheep standing on a rocky outcropping in the mountains. The sheep has a large horn on its head and is looking directly at the camera. The background is a blue sky with snow covered mountains in the distance.\n\nThe image is a photograph taken in the mountains. The"}, "22759": {"image_id": 22759, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.168845408373504, "Bleu_3": 0.11585435355644887, "Bleu_4": 0.07325475644331375, "METEOR": 0.22978817860473152, "ROUGE_L": 0.2392156862745098, "CIDEr": 7.027906689130653e-14, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2608695652173913, "f": 0.2608695652173913, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a cat lying on a bed with a white pillow under its head. The cat is brown and has a black spot on its nose. The bed has a pattern of white and black flowers on it. There is a window in the background with a view of the sky.\n\nThe cat is lying"}, "577065": {"image_id": 577065, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 0.11515158022011021, "Bleu_4": 0.07764975754306437, "METEOR": 0.2311137393820997, "ROUGE_L": 0.24646464646464644, "CIDEr": 1.5407213825706016e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.08333333333333333, "f": 0.15384615384615385, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of zebras grazing in a grassy field. The zebras are black and white with white stripes on their backs. They are standing in a clearing surrounded by trees and bushes. The sky is blue and cloudy.\n\nThe zebras are gra"}, "116461": {"image_id": 116461, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.191273013914278, "Bleu_3": 9.789208946234303e-07, "Bleu_4": 2.229024282744491e-09, "METEOR": 0.253422154358455, "ROUGE_L": 0.33493479752916955, "CIDEr": 1.85005609561763e-06, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.04, "f": 0.0425531914893617, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a pizza with cheese, pepperoni, and mushrooms on top. There is a knife on the side of the plate. The plate is on a wooden table.\n\nThe image shows a pizza with cheese, pepperoni, and mushrooms on top."}, "7214": {"image_id": 7214, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.17614871215260033, "Bleu_3": 8.770015703255858e-07, "Bleu_4": 1.967646828106159e-09, "METEOR": 0.25894378194207834, "ROUGE_L": 0.31077147016011636, "CIDEr": 1.6549009434724817e-09, "SPICE": {"All": {"pr": 0.4782608695652174, "re": 0.39285714285714285, "f": 0.4313725490196078, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 11.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.9, "re": 0.8181818181818182, "f": 0.8571428571428572, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 9.0}}, "caption": "The image is of a bathroom with a toilet, sink, and mirror. The walls are painted white and there is a window with blinds. The floor is made of wood and there is a rug in front of the toilet. The toilet is a white porcelain bowl with"}, "264336": {"image_id": 264336, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.1505903985438184, "Bleu_4": 0.1196425813532057, "METEOR": 0.3283516506196322, "ROUGE_L": 0.3190005810575247, "CIDEr": 1.5986141866526996e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.08333333333333333, "f": 0.09836065573770492, "fn": 33.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.1875, "f": 0.2222222222222222, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person riding a bicycle on a path through a park. The person is wearing a helmet and has a backpack on their back. The path is lined with trees and there are other people walking in the park. The sky is clear and there are clouds in the distance."}, "91994": {"image_id": 91994, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.20982172726164103, "Bleu_3": 0.16176672459792843, "Bleu_4": 0.11350940547325804, "METEOR": 0.24195355329975773, "ROUGE_L": 0.24710648148148148, "CIDEr": 1.123194789307542e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a desk in front of a computer. He is wearing a black shirt and black pants. The desk has a white surface and a black keyboard. The computer has a black screen and a white keyboard. The man is holding a black pen in his hand. The"}, "222831": {"image_id": 222831, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.08934530459950006, "Bleu_3": 5.38920160545791e-07, "Bleu_4": 1.3301506217263186e-09, "METEOR": 0.14155291629988057, "ROUGE_L": 0.27774615822424586, "CIDEr": 2.94097695828144e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is a white shelf with three hooks on it. There are two white vases on the shelf, one with a red ribbon tied around it and the other with a blue ribbon tied around it. There is also a white bag on the shelf with a red ribbon tied around it"}, "167122": {"image_id": 167122, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.19611613513437562, "Bleu_3": 0.13214760629865424, "Bleu_4": 0.08284102342923612, "METEOR": 0.2575038609284774, "ROUGE_L": 0.24653579676674361, "CIDEr": 5.406199878684337e-10, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.17857142857142858, "f": 0.17857142857142858, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a car parked in front of a building at night. The car has its headlights on and the driver is sitting inside. The building has a sign that reads, \"Welcome to the Hotel.\" The image is taken at night, and the only light source is from the headlights of"}, "561699": {"image_id": 561699, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.2142857142812956, "Bleu_3": 0.15751292285925483, "Bleu_4": 0.11417083671725523, "METEOR": 0.22791808473358122, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.9770336028120623e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a pizza with red sauce and cheese on top of a white plate. The pizza has a crust that is crispy and golden brown. There is a small amount of cheese on top of the pizza. The plate is on a table with a white tablecloth."}, "144932": {"image_id": 144932, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.19062587708942288, "Bleu_3": 0.14086619565212993, "Bleu_4": 1.5300743873925408e-05, "METEOR": 0.19154224115917823, "ROUGE_L": 0.24124293785310735, "CIDEr": 1.6161135825028807e-11, "SPICE": {"All": {"pr": 0.1875, "re": 0.13333333333333333, "f": 0.15584415584415587, "fn": 39.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.3125, "f": 0.35714285714285715, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a small boat in the water with a person standing on the back of it. The person is wearing a yellow life jacket and has their arms outstretched. The boat is traveling through the water with the waves crashing against it. There is a large body of water in the background"}, "267321": {"image_id": 267321, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.20565318641151553, "Bleu_3": 0.14543068929524094, "Bleu_4": 0.10331208012034214, "METEOR": 0.20725857096401282, "ROUGE_L": 0.3469237018982199, "CIDEr": 2.0264057324953374e-08, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a living room with a couch, a coffee table, and a chair. There is a window on the left side of the room and a door on the right side. The room is well lit and has a white ceiling and white walls. There are two plants on the coffee table and a v"}, "47837": {"image_id": 47837, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.20550493309104517, "Bleu_3": 0.16163974909461523, "Bleu_4": 0.11458284589810852, "METEOR": 0.26493551647112845, "ROUGE_L": 0.32370283018867924, "CIDEr": 2.587935479757412e-09, "SPICE": {"All": {"pr": 0.04, "re": 0.047619047619047616, "f": 0.043478260869565216, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a group of people sitting at a table on a deck. They are eating and drinking. There is a large window behind them with a view of the woods. The table is made of wood and has a white tablecloth. The people are wearing casual clothing and are enjoying"}, "119802": {"image_id": 119802, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.05714544883087091, "Bleu_3": 4.0006544362303344e-07, "Bleu_4": 1.0637896949215625e-09, "METEOR": 0.16056552289463757, "ROUGE_L": 0.17722254503195814, "CIDEr": 7.1513081569041105e-12, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3157894736842105, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a stuffed animal sitting on the sidewalk next to a streetlight. The animal is pink and has a bow on its head. There are other stuffed animals in the background, but they are not visible. The streetlight is on and there are no other cars or people in the image."}, "186624": {"image_id": 186624, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.20759971843926334, "Bleu_3": 0.1481650871060074, "Bleu_4": 0.08893210551641491, "METEOR": 0.2449938680400774, "ROUGE_L": 0.27006087437742116, "CIDEr": 3.109178308942446e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a green and yellow train parked in a large room with a high ceiling. The train has a long, curved body and a small cab at the front. There are two people standing next to the train, one of whom is wearing a hat and the other is holding a bag. The"}, "43345": {"image_id": 43345, "Bleu_1": 0.15789473683933522, "Bleu_2": 0.09197090092111697, "Bleu_3": 0.053577124023265116, "Bleu_4": 7.305267243158185e-06, "METEOR": 0.17488793306910083, "ROUGE_L": 0.17805020431990656, "CIDEr": 8.743159751332031e-15, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3157894736842105, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a brown and white dog sitting on top of a laptop computer. The dog is looking up at the camera with its tongue hanging out of its mouth. The laptop has a black screen with a white keyboard and a black mouse. The dog is wearing a collar with a tag on it. The"}, "260802": {"image_id": 260802, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.20025046972515906, "Bleu_3": 0.14287233072870692, "Bleu_4": 0.11282178612256669, "METEOR": 0.2414256457546752, "ROUGE_L": 0.26798462383305877, "CIDEr": 1.3306840425776556e-13, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man in a blue shirt and white shorts playing tennis on a clay court. He is holding a tennis racket in his right hand and is about to hit the ball with his left hand. The ball is flying through the air and is about to hit the ground. The man is running"}, "225537": {"image_id": 225537, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.1566749772899432, "Bleu_3": 0.0951447450989367, "Bleu_4": 0.06262411456109557, "METEOR": 0.18627786262709076, "ROUGE_L": 0.22822020309994653, "CIDEr": 2.4297686459821266e-15, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2, "f": 0.1851851851851852, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is of a laptop computer with a keyboard and a screen. The laptop is sitting on a table in front of a window. The window has a view of the outside, with trees and buildings visible in the distance. The laptop has a black and white screen, with a keyboard and a mouse on the right side"}, "533548": {"image_id": 533548, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.24343224777560685, "Bleu_3": 0.1647581019206144, "Bleu_4": 0.11452274472576594, "METEOR": 0.3404029068850536, "ROUGE_L": 0.28126801152737757, "CIDEr": 9.818209907881393e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.75, "f": 0.5217391304347827, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a man sitting at a desk in a library. He is wearing a red jacket and has a laptop on his lap. There are several books and papers on the desk, and the room has large windows with a view of the outside. The man appears to be working on his laptop."}, "120783": {"image_id": 120783, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.11651034560483009, "Bleu_3": 0.0815823712251846, "Bleu_4": 0.057696334521472034, "METEOR": 0.19696662551414318, "ROUGE_L": 0.21580188679245285, "CIDEr": 2.0378794734474883e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 24.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35294117647058826, "re": 0.46153846153846156, "f": 0.4000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The woman is holding a banana in her hand and smiling at the camera. She is wearing a grey and white striped dress and has a tattoo on her arm. The background is a white wall with a window and a door.\n\nThe woman is holding a banana in her hand and"}, "574823": {"image_id": 574823, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.1188942937395292, "Bleu_4": 0.07692375025894271, "METEOR": 0.2518630813142024, "ROUGE_L": 0.3051907442151345, "CIDEr": 4.851560790938845e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a baseball player in a red jersey and black pants standing on the field, holding a bat in his right hand and looking at the umpire. The umpire is wearing a blue shirt and white pants and is standing behind the plate. The field is made of grass"}, "455301": {"image_id": 455301, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.18663625434394554, "Bleu_3": 0.11095595432564728, "Bleu_4": 0.07229703035536629, "METEOR": 0.2187102482081024, "ROUGE_L": 0.2616621983914209, "CIDEr": 3.398865308027851e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a young girl sitting on a bed, reading a book while her mother lies next to her. The girl is wearing a pink dress and has a pink bow in her hair. The mother is wearing a white shirt and has a blanket over her. The room is dimly lit"}, "463498": {"image_id": 463498, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.18375590810914594, "Bleu_3": 0.1233303713651029, "Bleu_4": 0.07713181696889591, "METEOR": 0.22564115878951807, "ROUGE_L": 0.28222075346992725, "CIDEr": 2.2011690119444333e-13, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.21052631578947367, "f": 0.15999999999999998, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a living room with a large rug on the floor and a couch and chairs in the corner. There is a fireplace in the corner of the room and a window on the opposite side. The walls are painted a light color and there are curtains on the windows. The room is well"}, "132362": {"image_id": 132362, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.22019275302032337, "Bleu_3": 0.13113617972964073, "Bleu_4": 1.5222275337401534e-05, "METEOR": 0.2256162970509329, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.417986220057501e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17647058823529413, "f": 0.15789473684210528, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a table set with several bowls of food, including tacos, salad, and salsa. There are also several glasses of beer and wine on the table. The table is set with white linen tablecloths and white plates. The background is a light brown"}, "496198": {"image_id": 496198, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.23644230070621639, "Bleu_3": 0.18615130564191956, "Bleu_4": 0.14997608716729083, "METEOR": 0.31782384183405976, "ROUGE_L": 0.34231200897867564, "CIDEr": 4.588490026818032e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.2222222222222222, "f": 0.16, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a large brick building with a clock tower on top. There are several people standing outside the building, looking at something on the ground. There is a fire truck parked in front of the building.\n\nThe building appears to be a school or university, with several windows on the upper floors"}, "227830": {"image_id": 227830, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.20603150145092247, "Bleu_3": 0.17441844996026723, "Bleu_4": 0.1541389348613462, "METEOR": 0.2777862018185015, "ROUGE_L": 0.30310559006211185, "CIDEr": 5.236331839732238e-10, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.2, "f": 0.13636363636363635, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a white truck with the words \"Bud Light\" written on the side. The truck is parked in front of a gas station with a sign that reads \"Bud Light\" on it. There are several cars parked in the parking lot, and people are standing outside the gas"}, "440528": {"image_id": 440528, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.12430587656291649, "Bleu_4": 0.07953502757115866, "METEOR": 0.2353645875962737, "ROUGE_L": 0.29847094801223245, "CIDEr": 4.3472818305584537e-11, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.1891891891891892, "f": 0.22222222222222224, "fn": 30.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.11764705882352941, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a white cake on a plate with a fork and knife on the side. The cake has a red and white striped pattern on top and is topped with a sprinkle of powdered sugar. There is a small bowl of fruit on the table next to the cake"}, "163412": {"image_id": 163412, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.06185895741189865, "Bleu_3": 4.3341351003500945e-07, "Bleu_4": 1.1534197288455865e-09, "METEOR": 0.14400404904966205, "ROUGE_L": 0.22679390259015986, "CIDEr": 5.077750421294375e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This image shows a group of people on bicycles riding along a path next to a body of water. The sky is clear and blue, with some clouds in the distance. There are trees and buildings in the background.\n\nThe people on bicycles are wearing casual clothing, such as"}, "389174": {"image_id": 389174, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.11889429373952921, "Bleu_4": 1.3679192122845404e-05, "METEOR": 0.23736723659615727, "ROUGE_L": 0.18654434250764526, "CIDEr": 1.7326360118607912e-10, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.16666666666666666, "f": 0.17241379310344826, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.13333333333333333, "f": 0.18181818181818182, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a park with a pond in the center, surrounded by trees and benches. There are people sitting on the benches and looking at the pond. The sky is cloudy and there are leaves on the ground.\n\nThe image is taken from a bird's eye view, showing the"}, "250427": {"image_id": 250427, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.13644420572458105, "Bleu_3": 7.396917719335283e-07, "Bleu_4": 1.731749067280523e-09, "METEOR": 0.1422541625160559, "ROUGE_L": 0.2293233082706767, "CIDEr": 1.401581263228715e-09, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.25806451612903225, "f": 0.27586206896551724, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a group of people standing in front of a building. They are all wearing raincoats and carrying umbrellas. The building appears to be a theater or concert venue, with a large sign on the front reading 'the o2 arena'. There are several cars parked on"}, "399741": {"image_id": 399741, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.2669809468728851, "Bleu_3": 0.2018534368193611, "Bleu_4": 0.1340114993100507, "METEOR": 0.30487327300288897, "ROUGE_L": 0.33333333333333337, "CIDEr": 8.393143136964702e-08, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.047619047619047616, "f": 0.057142857142857134, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a young girl sitting on the floor surrounded by presents and toys. She is wearing a red dress and has a stuffed animal in her lap. There are several other toys and presents scattered around the room.\n\nThe girl is holding a small stuffed animal in her lap and appears to"}, "555461": {"image_id": 555461, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.20935894733588342, "Bleu_3": 0.16950408960775368, "Bleu_4": 0.13846218033148563, "METEOR": 0.3511255610467711, "ROUGE_L": 0.35920770877944325, "CIDEr": 3.503986443953925e-12, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The man in the image is sitting at a desk with a laptop in front of him. He is wearing a yellow hat and a black shirt. There are several other items on the desk, including a cup of coffee and a book. The background is a light brown color with a few windows visible in"}, "6593": {"image_id": 6593, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.121479758333828, "Bleu_4": 1.3901690971832786e-05, "METEOR": 0.24030478533285163, "ROUGE_L": 0.28113837999769564, "CIDEr": 3.1052293042386597e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.3125, "f": 0.21739130434782608, "fn": 11.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a clay court. He is wearing a white shirt and black shorts, and has a tennis racket in his hand. The other players are wearing similar outfits and are also playing tennis on the court. The court is surrounded by a fence and"}, "536088": {"image_id": 536088, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.21718612137747484, "Bleu_3": 0.09680257987643692, "Bleu_4": 1.1548422250765457e-05, "METEOR": 0.20793882080301115, "ROUGE_L": 0.27949599083619703, "CIDEr": 4.357168909424341e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is a wedding cake with white and yellow flowers on top. The cake is sitting on a table in front of a large window with a view of the outdoors. There are several chairs around the table and a large mirror on the wall behind the cake. The room appears to be"}, "106849": {"image_id": 106849, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.21398889174339228, "Bleu_3": 0.11999934118148196, "Bleu_4": 1.3501540091767586e-05, "METEOR": 0.22242262838812027, "ROUGE_L": 0.17951736315479697, "CIDEr": 2.2278844997059214e-13, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.10526315789473684, "f": 0.0930232558139535, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man standing at a counter in a wine shop, looking at a bottle of wine. There are several other people standing around the counter, looking at different bottles of wine. The walls of the shop are made of wood and have shelves with various types of wine on them. The floor"}, "38259": {"image_id": 38259, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.16329931618231128, "Bleu_3": 8.164398935373244e-07, "Bleu_4": 1.8349864163996563e-09, "METEOR": 0.16974163821857183, "ROUGE_L": 0.26704190118824267, "CIDEr": 7.071652155079614e-12, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.12903225806451613, "f": 0.14814814814814814, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a view of an airport terminal from the outside. There are several planes parked on the tarmac, and a large window in the background shows a cloudy sky. The terminal has a large glass wall with a view of the runway and a few planes parked on it."}, "535602": {"image_id": 535602, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 7.733118331435389e-07, "Bleu_4": 1.7439076818628815e-09, "METEOR": 0.19384901017993747, "ROUGE_L": 0.28355607205113303, "CIDEr": 1.7259298178706512e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on a table with a pizza box in front of it. The cat is looking at the pizza box with its head tilted to the side. There are several other items on the table, including a laptop, a phone, and a bag of trash. The room appears"}, "448600": {"image_id": 448600, "Bleu_1": 0.49999999998529415, "Bleu_2": 0.34815531190100074, "Bleu_3": 0.2248221565044877, "Bleu_4": 0.1383690338388886, "METEOR": 0.2863880747695374, "ROUGE_L": 0.38686296715741786, "CIDEr": 0.0018595511927885211, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a slice of cake on a plate with a fork and knife on the side. The cake has chocolate and strawberry toppings. There is a glass of milk on the table."}, "499226": {"image_id": 499226, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.22562131409418867, "Bleu_3": 0.14508989498764088, "Bleu_4": 0.08885438285000041, "METEOR": 0.22821768413209734, "ROUGE_L": 0.2482558139534883, "CIDEr": 1.1327218049570384e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a cat lying on a couch with its head resting on a remote control. The cat appears to be sleeping or relaxing. The couch is covered in a floral patterned fabric and there are several pillows on the couch. The room appears to be a living room with a"}, "286303": {"image_id": 286303, "Bleu_1": 0.43902439023319456, "Bleu_2": 0.31429363308854874, "Bleu_3": 0.19659657071545172, "Bleu_4": 2.1146381079887244e-05, "METEOR": 0.26888864361260434, "ROUGE_L": 0.37334240054403267, "CIDEr": 0.00034090481395144856, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.11538461538461539, "f": 0.11538461538461539, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The man is wearing a green shirt and a tie. He is holding a white handkerchief in his left hand and a black tie in his right hand. The background is a green wall with a white square pattern on it."}, "363072": {"image_id": 363072, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.16917307297107978, "Bleu_3": 0.10259799351869228, "Bleu_4": 1.2004755374502662e-05, "METEOR": 0.24995975225292671, "ROUGE_L": 0.2127164942461932, "CIDEr": 3.5971848820402055e-12, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.25, "f": 0.31034482758620685, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a subway train traveling on the tracks in front of a tall building. The train has a blue and white color scheme and is pulling into the station. There are people standing on the platform and others walking on the sidewalk. The sky is clear and there are trees in the background."}, "416193": {"image_id": 416193, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.22404481344004462, "Bleu_3": 0.10080712673232953, "Bleu_4": 1.2086710441569929e-05, "METEOR": 0.25038937329223504, "ROUGE_L": 0.2858816637375513, "CIDEr": 4.206874303247787e-10, "SPICE": {"All": {"pr": 0.21875, "re": 0.23333333333333334, "f": 0.22580645161290322, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of zebras grazing in a green field. There are several trees in the background, including a large oak tree. The sky is blue and there are clouds in the distance. The grass is green and there are no other animals in the field.\n\nThe zebras are"}, "390048": {"image_id": 390048, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.1371021242743437, "Bleu_3": 0.08808836678271832, "Bleu_4": 0.059647257268019734, "METEOR": 0.21210746263291447, "ROUGE_L": 0.20926243567753, "CIDEr": 1.254921243260991e-14, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.0625, "f": 0.06060606060606061, "fn": 30.0, "numImages": 1.0, "fp": 32.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man sitting at a table with a plate of food in front of him. He is wearing a white shirt and black pants. There are several other people in the background, including a woman sitting at a table and a man standing in the background. The room appears to be a restaurant or"}, "46924": {"image_id": 46924, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.10433283794475068, "Bleu_3": 0.05976183926619196, "Bleu_4": 8.083053722298239e-06, "METEOR": 0.13889128345831364, "ROUGE_L": 0.14796846573681016, "CIDEr": 3.5216547247251853e-12, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.8, "f": 0.4444444444444444, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a person holding a small, silver device in their hand. The device has a flat, rectangular shape and a small screen on the front. There are no visible buttons or controls on the device. The person's hand is visible in the image, with the device resting in their palm."}, "26026": {"image_id": 26026, "Bleu_1": 0.17777777777382722, "Bleu_2": 0.06356417261494428, "Bleu_3": 4.546237434540883e-07, "Bleu_4": 1.2230008607068681e-09, "METEOR": 0.12358620689655171, "ROUGE_L": 0.1643097643097643, "CIDEr": 1.8695293620735185e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of people standing around a large, circular enclosure with a circus tent in the background. The people are all wearing different types of clothing, including jeans, t shirts, and hats. The circus tent has a large, colorful banner hanging from"}, "382333": {"image_id": 382333, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.11856311014724848, "Bleu_4": 1.3722641665543406e-05, "METEOR": 0.20850930473590817, "ROUGE_L": 0.2692307692307692, "CIDEr": 2.0749294307903935e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.13043478260869565, "f": 0.12499999999999997, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a garden with several rows of plants growing in the soil. The plants are a mix of vegetables and herbs, including tomatoes, peppers, and basil. The garden is surrounded by a wooden fence and there are several gardening tools, such as a watering can and a ra"}, "508899": {"image_id": 508899, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.14285714285419707, "Bleu_3": 0.07572431510387477, "Bleu_4": 9.856825261135735e-06, "METEOR": 0.17669902912621357, "ROUGE_L": 0.19242902208201892, "CIDEr": 8.595913301516445e-08, "SPICE": {"All": {"pr": 0.24, "re": 0.35294117647058826, "f": 0.28571428571428564, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a living room with a couch, coffee table, and television. There is a dog on the floor.\n\nThe dog is a small, fluffy white dog with a pink nose and floppy ears. It is standing on its hind legs and looking at the camera. The dog"}, "20553": {"image_id": 20553, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 7.178791139239357e-07, "Bleu_4": 1.649286056998e-09, "METEOR": 0.13259764218989076, "ROUGE_L": 0.19624664879356574, "CIDEr": 1.689617638775754e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.16666666666666666, "f": 0.16949152542372883, "fn": 25.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a small, empty room with a table and chairs in the middle. There are several items on the table, including a bottle of water, a bag of food, and a small toy. The room is surrounded by a dirt field with some small plants growing in it. The sky is"}, "65465": {"image_id": 65465, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.17251638983203116, "Bleu_3": 0.1363141538186681, "Bleu_4": 0.11336958836408242, "METEOR": 0.2542645789321419, "ROUGE_L": 0.28222075346992725, "CIDEr": 6.406852135404674e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of elephants standing in a field with their babies. The elephants are all different sizes and colors, with some having spots and others not. They are all standing in a line, with their trunks curled up and their ears flapping in the wind. The"}, "320823": {"image_id": 320823, "Bleu_1": 0.340909090901343, "Bleu_2": 0.25184310024886714, "Bleu_3": 1.1472822500028998e-06, "Bleu_4": 2.4635236829988735e-09, "METEOR": 0.1616892371110544, "ROUGE_L": 0.214185393258427, "CIDEr": 1.1478253188302208e-07, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13043478260869565, "f": 0.11538461538461538, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a couple sitting at a table with a cake in front of them. The couple is wearing traditional Indian clothing and the cake has candles on it. The background is a brightly colored wall with a large window in the background."}, "477087": {"image_id": 477087, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.12326123997631012, "Bleu_4": 0.09398684880464062, "METEOR": 0.2260347776769097, "ROUGE_L": 0.2858816637375513, "CIDEr": 7.815962702273198e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 1.0, "f": 0.2857142857142857, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This image is a collection of baseball memorabilia, including a baseball bat, glove, and ball. The bat is made of wood and has a handle and a barrel. The glove is made of leather and has a pocket for the ball. The ball is made of leather and has a se"}, "71357": {"image_id": 71357, "Bleu_1": 0.17543859648815024, "Bleu_2": 0.11194341570792983, "Bleu_3": 0.06107706224793171, "Bleu_4": 8.059538325436327e-06, "METEOR": 0.15016311028939944, "ROUGE_L": 0.2136602451838879, "CIDEr": 4.674226319620619e-15, "SPICE": {"All": {"pr": 0.25, "re": 0.3181818181818182, "f": 0.28, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a yellow and black train on the tracks. The train has a large front end with a yellow and black striped nose. The train has a long body with windows on both sides. The train has a small rear end with a yellow and black striped tail. The train is traveling on the tracks"}, "343453": {"image_id": 343453, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.0885614885522557, "Bleu_3": 0.05429559270864281, "Bleu_4": 7.599116882063913e-06, "METEOR": 0.1848261397919513, "ROUGE_L": 0.21441124780316342, "CIDEr": 1.3059079194251925e-10, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13636363636363635, "f": 0.11764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a person standing on a snowy slope, wearing a blue hoodie and holding a pair of skis. The person is standing in front of a group of trees, with a mountain range in the background. The image is in black and white.\n\nThe person is wearing a blue"}, "34580": {"image_id": 34580, "Bleu_1": 0.3599999999928, "Bleu_2": 0.19166296949610961, "Bleu_3": 9.146994035438242e-07, "Bleu_4": 2.0087890503675583e-09, "METEOR": 0.24506509579226704, "ROUGE_L": 0.2901307966706302, "CIDEr": 9.937283075935024e-09, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.2857142857142857, "f": 0.2711864406779661, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a red fire hydrant in the grass in front of a parking lot. There are several cars parked in the lot, and the sky is cloudy.\n\nThe fire hydrant is a red, metal, and plastic device that is used to provide water to fight fires. It has"}, "151393": {"image_id": 151393, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1211406307163407, "Bleu_3": 0.06559319301112622, "Bleu_4": 8.624849693567767e-06, "METEOR": 0.20366887697943772, "ROUGE_L": 0.20962199312714777, "CIDEr": 3.7523676566972106e-08, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.24, "f": 0.24999999999999994, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a stop sign on a pole in the middle of a street. The sign has the words \"stop\" and \"do not pass\" written on it in white letters. There are also some parking signs on the pole. The street is lined with trees and there are cars parked on the side"}, "239351": {"image_id": 239351, "Bleu_1": 0.45999999999080005, "Bleu_2": 0.32134919654213584, "Bleu_3": 0.20492316911728564, "Bleu_4": 0.1163238675413271, "METEOR": 0.26980212082112015, "ROUGE_L": 0.31624423963133635, "CIDEr": 5.40939598515535e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a couple standing in the middle of a dirt road, holding an umbrella and a sign that says, \"We're engaged!\" The couple is dressed in formal attire, with the man wearing a black suit and tie, and the woman wearing a white dress. They are standing"}, "357109": {"image_id": 357109, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.20628424924741542, "Bleu_3": 0.14052875118914693, "Bleu_4": 0.08861775869596063, "METEOR": 0.22953053159918654, "ROUGE_L": 0.23680124223602486, "CIDEr": 4.648159463892208e-09, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.22727272727272727, "f": 0.17857142857142858, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a skateboarder performing a trick on a ramp in front of a crowd of people. The skateboarder is wearing a white shirt and black pants, and has a black helmet on his head. The crowd is made up of people of various ages and ethnicities"}, "174888": {"image_id": 174888, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.09701425001261196, "Bleu_3": 5.76976768606882e-07, "Bleu_4": 1.4143550190666944e-09, "METEOR": 0.1741874714278759, "ROUGE_L": 0.2238532110091743, "CIDEr": 1.7772392890957354e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a restaurant, holding a plate of food in his hand. The restaurant has a sign that reads \"Coffee Shop\" in large letters. The man is wearing a black shirt and jeans, and has a white hat on his head. There are other"}, "542934": {"image_id": 542934, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.14793835438670558, "Bleu_4": 0.09209953959056319, "METEOR": 0.2628396665768314, "ROUGE_L": 0.2675438596491228, "CIDEr": 1.6302410676591473e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.16666666666666666, "f": 0.10526315789473684, "fn": 10.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a kitchen with a wooden table and chairs. There is a stove and oven on the counter. There are pots and pans hanging from the ceiling. The walls are painted a light brown color.\n\nThe kitchen has a wooden table and chairs. There is a stove"}, "467848": {"image_id": 467848, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.10238251947041137, "Bleu_3": 0.05863398711091721, "Bleu_4": 7.929020238697525e-06, "METEOR": 0.16695325675727085, "ROUGE_L": 0.22421760134425545, "CIDEr": 3.074246410549838e-10, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a large truck with a trailer attached to it. The trailer has a large tank on the back of it. There are two people standing next to the truck, one of them is holding a hose and the other is standing on the side of the truck. There are several cars"}, "413124": {"image_id": 413124, "Bleu_1": 0.38461538460798816, "Bleu_2": 0.24562537538976753, "Bleu_3": 0.15354390128889114, "Bleu_4": 0.11025109391030485, "METEOR": 0.21444179251714263, "ROUGE_L": 0.30432372505543237, "CIDEr": 6.42717906469953e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a young boy wearing a baseball uniform and holding a baseball bat. He is standing on a grass field with a fence in the background. The sun is shining down on him, casting a warm glow on his face. The boy is wearing a green jersey with the number"}, "300773": {"image_id": 300773, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.08157553219491781, "Bleu_3": 0.049163629240560426, "Bleu_4": 6.817768943638042e-06, "METEOR": 0.1314460128103558, "ROUGE_L": 0.14039125431530494, "CIDEr": 1.5130273697804753e-16, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of people standing in front of a building. They are all wearing red robes and have their hands together in prayer. The building is made of wood and has a red roof. There are several windows on the building and a large door on the front. The people are all looking up at"}, "373440": {"image_id": 373440, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.15927956195690762, "Bleu_3": 8.453247893683395e-07, "Bleu_4": 1.959168274713403e-09, "METEOR": 0.24810682503030504, "ROUGE_L": 0.2840606705694519, "CIDEr": 4.003726330972585e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a store with a shelf full of teddy bears. The bears are wearing sunglasses and are standing in front of a sign that reads, \"travel necessities\".\n\nThe image is taken in a store with a shelf full of teddy bears. The"}, "334321": {"image_id": 334321, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.19720265943222184, "Bleu_3": 0.15351083131080304, "Bleu_4": 0.1145643364316842, "METEOR": 0.21854009879231856, "ROUGE_L": 0.26906112161310647, "CIDEr": 4.970529650461651e-07, "SPICE": {"All": {"pr": 0.12, "re": 0.10344827586206896, "f": 0.11111111111111112, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a white dog sitting on a bench in the park. The dog is wearing a collar and leash. There are people sitting on the bench and walking by in the background. The sky is blue and there are trees in the background."}, "535668": {"image_id": 535668, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.15475060698405138, "Bleu_3": 0.12338191667517893, "Bleu_4": 0.10303302411786948, "METEOR": 0.2578417071131705, "ROUGE_L": 0.22195269860521533, "CIDEr": 2.161683329227342e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a baseball player hitting a baseball with a bat. The player is wearing a red and white uniform and has a helmet on his head. The umpire is standing behind the player and watching him hit the ball. The crowd is cheering in the background.\n\nThe image is taken from"}, "157184": {"image_id": 157184, "Bleu_1": 0.12727272727041325, "Bleu_2": 0.0970958774988075, "Bleu_3": 0.08111147935548946, "Bleu_4": 0.056599279910093316, "METEOR": 0.17265130555013075, "ROUGE_L": 0.18340348767288037, "CIDEr": 1.0368139977420051e-13, "SPICE": {"All": {"pr": 0.08, "re": 0.08695652173913043, "f": 0.08333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The man is holding a large knife in his hand and is standing in front of a white wall. He is wearing a plaid shirt and glasses. The wall behind him is made of concrete and has a large window on it. There is a small table in front of the wall with a vase"}, "64390": {"image_id": 64390, "Bleu_1": 0.580645161271592, "Bleu_2": 0.39349550145746687, "Bleu_3": 0.29887105043154605, "Bleu_4": 0.23126168909213332, "METEOR": 0.278515649679918, "ROUGE_L": 0.4016933207902163, "CIDEr": 0.004549075769590211, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a red traffic light at an intersection with a car parked on the side of the road. The building in the background appears to be a shopping mall."}, "91857": {"image_id": 91857, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.1428571428542566, "Bleu_3": 0.07519475711342193, "Bleu_4": 9.75250555049218e-06, "METEOR": 0.17761952903884612, "ROUGE_L": 0.2852466682253917, "CIDEr": 8.790103131933949e-10, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.22727272727272727, "f": 0.25641025641025644, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in a field with trees in the background. The giraffe is wearing a halter and has a long neck. The trees in the background are tall and green.\n\nThe image shows a giraffe standing in a field with trees in the background. The g"}, "275202": {"image_id": 275202, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.1671899541887144, "Bleu_3": 8.130907204696851e-07, "Bleu_4": 1.801821270464176e-09, "METEOR": 0.2306647531110927, "ROUGE_L": 0.2738496071829405, "CIDEr": 7.627419744732812e-12, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a table with a pizza on it. There is a glass of red wine on the table and a fork and knife next to the pizza. The table is made of wood and has a red and white checkered tablecloth. The lighting in the room is dim and there are cand"}, "508811": {"image_id": 508811, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.18257418583143972, "Bleu_3": 0.08794832144813745, "Bleu_4": 1.0910894511579089e-05, "METEOR": 0.1748124032478387, "ROUGE_L": 0.25831820931639443, "CIDEr": 1.074066972879886e-07, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a tennis player in white and black clothing, with a racket in hand, jumping to hit a ball on a tennis court. The player is wearing a white shirt with black shorts and white shoes. The ball is flying through the air and the player is in mid-air"}, "511111": {"image_id": 511111, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.24468219368158126, "Bleu_3": 0.1674550240961753, "Bleu_4": 0.11706811738843625, "METEOR": 0.28143743486290607, "ROUGE_L": 0.2959369314736203, "CIDEr": 2.966272047182185e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.38095238095238093, "f": 0.3018867924528302, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a glass of orange juice on a countertop next to a blender with an orange peel in it. The blender has a black handle and a clear plastic jug with a spout on top. The countertop is made of wood and has a white sink on it. There is a"}, "70471": {"image_id": 70471, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.24371914504394585, "Bleu_3": 0.15076449164519362, "Bleu_4": 1.6100218008375077e-05, "METEOR": 0.23054380758586798, "ROUGE_L": 0.3109072375127421, "CIDEr": 1.4218547837569565e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man holding a baby in his arms while sitting on a couch. The baby is wearing a onesie and has a pacifier in its mouth. The man is wearing a t shirt and has a beard. The background is a living room with a coffee table and a television in"}, "95516": {"image_id": 95516, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.17864740024886272, "Bleu_3": 0.1115377437347146, "Bleu_4": 0.07451835561525198, "METEOR": 0.17014014045546247, "ROUGE_L": 0.2401574803149606, "CIDEr": 3.4806459286819822e-09, "SPICE": {"All": {"pr": 0.21875, "re": 0.35, "f": 0.2692307692307692, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a truck with a large pile of logs in the back. The truck is parked in a dirt lot with trees in the background. The truck's license plate reads \"Pine Logs.\"\n\nThe image is taken in a rural area with a dirt road leading"}, "299946": {"image_id": 299946, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 8.321444966006323e-07, "Bleu_4": 1.8613958856826033e-09, "METEOR": 0.17869410124438537, "ROUGE_L": 0.2858816637375513, "CIDEr": 1.8961675500560242e-09, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.32, "f": 0.3636363636363636, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a woman in a black shirt and black pants standing at a kitchen counter with a blender in her hands. She is mixing something in a bowl on the counter. There are several other kitchen utensils on the counter, including a knife, a cutting board, and a measuring"}, "356456": {"image_id": 356456, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.08062577022864871, "Bleu_4": 1.006845569565764e-05, "METEOR": 0.18411693438844942, "ROUGE_L": 0.2814302191464821, "CIDEr": 2.616629904282098e-10, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.3125, "f": 0.2325581395348837, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a train on the tracks in a rural area. The train is an old, red and white locomotive with a large, black smoke stack on top. The train is pulling a long, red and white freight car with a large, black tank on top. The train is traveling through a field"}, "420181": {"image_id": 420181, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.22117152024581002, "Bleu_3": 0.18743514831946917, "Bleu_4": 0.15075118319562195, "METEOR": 0.19849628856021403, "ROUGE_L": 0.27949599083619703, "CIDEr": 7.834991568750024e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.5, "f": 0.3, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a red and white striped tent. They are all wearing black jackets and black pants. The tent has a large red and white striped awning over it. There are several people standing in front of the tent, looking at something on the ground"}, "324785": {"image_id": 324785, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.17368336856959593, "Bleu_3": 0.08449846526122945, "Bleu_4": 1.0533861300924754e-05, "METEOR": 0.16612137493365953, "ROUGE_L": 0.23669623059866962, "CIDEr": 2.2333471681843535e-10, "SPICE": {"All": {"pr": 0.15625, "re": 0.16129032258064516, "f": 0.15873015873015875, "fn": 26.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of boats docked at a pier. The boats are made of wood and have a variety of colors, including red, blue, and green. There are also several lobster traps on the pier, which are made of wire mesh and have a variety of colors, including red, blue"}, "100329": {"image_id": 100329, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.1426954482435772, "Bleu_3": 0.10690314865377899, "Bleu_4": 0.07066328980326636, "METEOR": 0.2277042843793239, "ROUGE_L": 0.24653579676674361, "CIDEr": 6.860176345561145e-11, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.25, "f": 0.24561403508771928, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a brown bear standing on a rocky outcropping, looking out over a body of water. The bear is standing on its hind legs and has a large, fluffy coat. The water in the background is calm and clear, with a few boats and buildings visible in the distance. The"}, "191425": {"image_id": 191425, "Bleu_1": 0.30508474575754096, "Bleu_2": 0.22934868264969802, "Bleu_3": 0.15454651343685405, "Bleu_4": 0.10715313974803593, "METEOR": 0.22365803572951692, "ROUGE_L": 0.2558993183009963, "CIDEr": 1.8896447591836958e-14, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.25, "f": 0.2553191489361702, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image is a black and white photograph of a sunset over a body of water. The sky is dark and the sun is setting behind a mountain range. There are two boats in the water, one with a person standing on it and the other with a person sitting in it. The water is calm and there are"}, "494620": {"image_id": 494620, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.221323371633511, "Bleu_3": 0.15662032595896783, "Bleu_4": 0.12321792904178375, "METEOR": 0.2606590659464061, "ROUGE_L": 0.37273636262637483, "CIDEr": 1.455828768260957e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2222222222222222, "f": 0.1951219512195122, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man sitting on the back of a horse. The man is wearing a hat and a jacket, and the horse is wearing a saddle and bridle. The horse is standing in front of a brick building with a sign that reads \"stable\". The image is in black and white."}, "359260": {"image_id": 359260, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.16402518938356242, "Bleu_3": 0.08027973262151615, "Bleu_4": 1.003602868615311e-05, "METEOR": 0.20207424054223436, "ROUGE_L": 0.24710648148148148, "CIDEr": 1.938525152463988e-11, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man standing on a beach with a horse and cart. The man is wearing a white shirt and pants, and the horse is wearing a brown saddle and bridle. The cart has a wooden frame and is pulled by the horse. The beach is covered in sand and there are"}, "286342": {"image_id": 286342, "Bleu_1": 0.16363636363338846, "Bleu_2": 0.1100963765106158, "Bleu_3": 6.11537923062715e-07, "Bleu_4": 1.4481605401740616e-09, "METEOR": 0.19256494487320963, "ROUGE_L": 0.21542083578575633, "CIDEr": 2.75884712170405e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a computer keyboard and mouse on a pink fluffy carpet. The keyboard has a black and white design with a mouse on the right side. The mouse has a black and white design with a red button on the top. The carpet is pink and has a pattern of white and black"}, "576191": {"image_id": 576191, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.15061880827957486, "Bleu_3": 7.399291364795743e-07, "Bleu_4": 1.6474108592769675e-09, "METEOR": 0.18329570811134285, "ROUGE_L": 0.17192784667418262, "CIDEr": 7.415086513828984e-14, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.23076923076923078, "f": 0.21818181818181817, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a cat sitting on a bench in front of a building. The cat is looking up at the camera with its eyes closed. The bench is made of metal and has a wooden seat. The building is made of stone and has a large window on the top floor. There are trees in the background"}, "580908": {"image_id": 580908, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.09382178207455442, "Bleu_4": 1.1226048713415489e-05, "METEOR": 0.22772785470425244, "ROUGE_L": 0.2513243084167157, "CIDEr": 1.3944492919329481e-12, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.08333333333333333, "f": 0.07692307692307691, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a group of men in black and white uniforms standing on a baseball field. They are all wearing baseball caps and gloves, and some of them are holding baseball bats. The men are standing in a line, with one man in the front holding a baseball. The background is a green field"}, "556420": {"image_id": 556420, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 0.06912848008424652, "Bleu_4": 8.92774794149235e-06, "METEOR": 0.1282493549600852, "ROUGE_L": 0.16878804648588822, "CIDEr": 3.730324305811492e-12, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.21052631578947367, "f": 0.17391304347826086, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a beach with a hut on the sand. There are palm trees and a small body of water in the background. The sky is blue and there are clouds in the distance.\n\nThe image is taken from a high angle, looking down on the beach. The sand is white and there are"}, "81251": {"image_id": 81251, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.29625319819896073, "Bleu_3": 0.2372586752092234, "Bleu_4": 0.18562157151967446, "METEOR": 0.34759205102589996, "ROUGE_L": 0.43884892086330934, "CIDEr": 2.2169410685655234e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a pizza with tomato sauce, mozzarella cheese, and fresh basil leaves on top of a white plate. The pizza is served on a wooden table with a glass of wine next to it. The background is a white wall with a window in the background."}, "130437": {"image_id": 130437, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.13363062095380426, "Bleu_3": 0.09973474676294886, "Bleu_4": 0.07822100624658515, "METEOR": 0.1653948225143869, "ROUGE_L": 0.20460644007155634, "CIDEr": 2.2405849056526328e-13, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.21875, "f": 0.23728813559322032, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a train on the tracks, passing by a building with a red roof. The train is traveling in the direction of the camera, and there are trees and buildings visible in the background. The sky is blue and there are clouds in the distance.\n\nThe train is a red and white train with"}, "359546": {"image_id": 359546, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.16496470132732644, "Bleu_3": 0.10219130767434717, "Bleu_4": 0.06797010899383783, "METEOR": 0.20068897005081146, "ROUGE_L": 0.25341246290801184, "CIDEr": 2.6242197445355283e-12, "SPICE": {"All": {"pr": 0.08, "re": 0.10526315789473684, "f": 0.0909090909090909, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of umbrellas on the beach. The umbrellas are made of wood and have a round shape. They are placed on the sand next to each other. There is a body of water in the background. The sky is blue and there are clouds in the sky. The sun"}, "298979": {"image_id": 298979, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.26271583096647133, "Bleu_3": 0.19168235533449896, "Bleu_4": 0.13088316619862386, "METEOR": 0.29347262806729163, "ROUGE_L": 0.3216168717047452, "CIDEr": 5.543872626519964e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.14814814814814814, "f": 0.1951219512195122, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a herd of zebras grazing in a grassy field next to a body of water. The zebras are standing in a line, with their heads down and their tails up. The water in the background is calm and clear, with a few boats floating on it. The sky"}, "413079": {"image_id": 413079, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.10497813183144382, "Bleu_3": 0.061232992015274296, "Bleu_4": 8.360161095251491e-06, "METEOR": 0.2091079201713263, "ROUGE_L": 0.22938079719227877, "CIDEr": 2.2284888082521305e-10, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.21875, "f": 0.25, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.42857142857142855, "f": 0.4799999999999999, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a horse jumping over a fence at a horse show. The horse is wearing a saddle and bridle and is jumping over a fence made of wood. The rider is wearing a helmet and is holding the reins of the horse. The background is a green field"}, "403584": {"image_id": 403584, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.09983569293155374, "Bleu_4": 0.06819851521727724, "METEOR": 0.23341623973167736, "ROUGE_L": 0.26940063091482647, "CIDEr": 3.351520796825303e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15789473684210525, "f": 0.14634146341463414, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows two people standing on the beach at sunset. One person is holding a surfboard and the other is holding a surfboard and looking out at the ocean. The sky is cloudy and there are waves crashing on the shore. The people are wearing wetsuits and sunglass"}, "401004": {"image_id": 401004, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.11843515045025203, "Bleu_3": 0.06266554082896969, "Bleu_4": 8.141877941016982e-06, "METEOR": 0.1949345010300798, "ROUGE_L": 0.2157655381505811, "CIDEr": 3.8549744426214714e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a bar with a wooden floor and a large wooden table in the center of the room. There are several chairs around the table and a large wooden bar with a counter on the other side of the room. The walls are made of brick and there are several windows on the sides of the room."}, "489829": {"image_id": 489829, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2015901948875348, "Bleu_3": 0.13370981749106944, "Bleu_4": 0.09888660568274772, "METEOR": 0.27281682011374786, "ROUGE_L": 0.2896142433234421, "CIDEr": 1.3256116632318776e-11, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.05555555555555555, "f": 0.04545454545454546, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a man standing in front of a wall of clocks. The clocks are all different shapes and sizes, and some of them have numbers on them. The man is wearing a black shirt and pants, and he is holding a white clock in his hand. There are other clocks on"}, "177810": {"image_id": 177810, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.11524490328511486, "Bleu_4": 0.07554258316170322, "METEOR": 0.28080561705565904, "ROUGE_L": 0.26228501228501233, "CIDEr": 1.2195840285136203e-09, "SPICE": {"All": {"pr": 0.05, "re": 0.043478260869565216, "f": 0.046511627906976744, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a teddy bear sitting on a table next to a Christmas tree. The teddy bear is wearing a red scarf and a blue hat. The Christmas tree has lights on it and presents underneath it. The background is a white wall with a window in the background."}, "130225": {"image_id": 130225, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1922322627296484, "Bleu_3": 0.11391235988457692, "Bleu_4": 0.07411039308756416, "METEOR": 0.23176611180260565, "ROUGE_L": 0.23047858942065497, "CIDEr": 2.0281368769357596e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of people flying kites in a field. The sky is cloudy and there are trees in the background. The people are wearing casual clothing and are standing in a line, holding their kites. The kites are in various colors and shapes, and some of them have stream"}, "364010": {"image_id": 364010, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.13423832028711077, "Bleu_4": 0.10921823440886999, "METEOR": 0.270121503774556, "ROUGE_L": 0.2961165048543689, "CIDEr": 8.226320562108191e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.09375, "f": 0.10526315789473684, "fn": 29.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a small dog sitting on the back seat of a car. The dog is brown and black with a long, curly tail. The dog is looking up at the camera with its tongue hanging out of its mouth. The car is a silver sedan with tinted windows. The driver's seat"}, "527728": {"image_id": 527728, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.2241462600435509, "Bleu_3": 0.15074532670634294, "Bleu_4": 0.09447475603834063, "METEOR": 0.23714096696143822, "ROUGE_L": 0.2827814569536423, "CIDEr": 9.790428099009361e-09, "SPICE": {"All": {"pr": 0.09375, "re": 0.10714285714285714, "f": 0.09999999999999999, "fn": 25.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows an elephant standing in a small pond with its trunk in the water. The elephant is wearing a collar with a tag on it. There are several other animals in the pond, including a giraffe and a zebra. The background is a rocky"}, "8787": {"image_id": 8787, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.18171094607444632, "Bleu_3": 0.13732533424861082, "Bleu_4": 0.10088532476686506, "METEOR": 0.2312001516339298, "ROUGE_L": 0.25707405177603854, "CIDEr": 8.671438638141973e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man holding a camera and standing on the sidewalk. There are people walking by and sitting on benches in the background. The man is wearing a white shirt and black pants. The camera is a small, black device with a lens on the front. The man is holding the"}, "198717": {"image_id": 198717, "Bleu_1": 0.11538461538239647, "Bleu_2": 1.5041420939612579e-09, "Bleu_3": 3.563438288459304e-12, "Bleu_4": 1.7432228564084151e-13, "METEOR": 0.09633507853403143, "ROUGE_L": 0.10790094339622643, "CIDEr": 1.4407175153729515e-12, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.35, "f": 0.29787234042553196, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two men in a bedroom, one of them is holding a plate of food and the other is holding a cup of coffee. The room is dimly lit and there are no windows. The men are wearing pajamas and the bed is made up with a blanket and pillows."}, "465223": {"image_id": 465223, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.12281268769488378, "Bleu_3": 0.08449846526122942, "Bleu_4": 1.0533861300924752e-05, "METEOR": 0.1949086505308597, "ROUGE_L": 0.1920654911838791, "CIDEr": 4.703674570254647e-10, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a tennis match in progress on a court. There are several players on the court, including a woman in a white dress and a man in a black shirt. The crowd is cheering and waving flags. The image is in color and appears to be taken from a distance."}, "377595": {"image_id": 377595, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1824897193978171, "Bleu_3": 0.09045267833662957, "Bleu_4": 1.1388142795948563e-05, "METEOR": 0.17171973911595848, "ROUGE_L": 0.21613322310145272, "CIDEr": 1.1046254524386431e-08, "SPICE": {"All": {"pr": 0.3793103448275862, "re": 0.44, "f": 0.4074074074074074, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 11.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 8.0}}, "caption": "The image shows a large, white, plastic bag sitting on a wooden cutting board. The bag appears to be filled with various items, including a small, brown, plastic container with a lid, a large, brown, plastic container with a spout, and a small, white, plastic container with"}, "386968": {"image_id": 386968, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.27450794146236435, "Bleu_3": 0.1700165045338995, "Bleu_4": 0.10222689827660131, "METEOR": 0.27351655569400346, "ROUGE_L": 0.357981220657277, "CIDEr": 1.54315889922356e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a woman riding a bicycle down a city street. She is wearing a green coat and carrying a small dog on her lap. The dog is wearing a pink collar and tag. The woman is wearing a green hat and sunglasses. The street is lined"}, "405994": {"image_id": 405994, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.12126781251581158, "Bleu_3": 0.0665028658415205, "Bleu_4": 8.801997699590313e-06, "METEOR": 0.15569734679524888, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.2583282412380973e-11, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.0625, "f": 0.04761904761904762, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.16666666666666666, "f": 0.10526315789473684, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a display of baseball bats in a store window. The bats are made of wood and have colorful paint on them. They are arranged in a row on a shelf in the window. The display is in a storefront window of a sporting goods store.\n\nThe image shows a"}, "134815": {"image_id": 134815, "Bleu_1": 0.3399999999932, "Bleu_2": 0.2634155559173319, "Bleu_3": 0.17948735747185518, "Bleu_4": 1.8728411075322786e-05, "METEOR": 0.2721764455967667, "ROUGE_L": 0.326397146254459, "CIDEr": 1.457168436193484e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.25, "f": 0.2553191489361702, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a kitchen with wooden cabinets and a stove\n\nThe kitchen has a large wooden island in the center of the room. There are several pots and pans on the stove and countertops. The walls are painted yellow and there are several windows in the room.\n\nThe kitchen"}, "201934": {"image_id": 201934, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.21797089763394864, "Bleu_3": 0.1681121136269389, "Bleu_4": 0.14033475286316116, "METEOR": 0.23038002797504958, "ROUGE_L": 0.2995440196422308, "CIDEr": 8.901362009793395e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a white school bus parked on the side of the road. There are several people standing around the bus, looking at it. The bus has a large bumper sticker on the front that reads, \"School Bus.\" There are also several other cars parked along the side of the road"}, "320899": {"image_id": 320899, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 8.330762903217117e-07, "Bleu_4": 1.893260841337042e-09, "METEOR": 0.19036281733731056, "ROUGE_L": 0.27371794871794874, "CIDEr": 3.654417625577676e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bedroom with a bed, nightstand, and dresser. The bed has a brown and beige patterned comforter and pillows. The nightstand has a lamp and a clock on it. The dresser has a mirror and a few clothes on it. The floor is made of"}, "406217": {"image_id": 406217, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.10612555247189982, "Bleu_4": 0.06992338944679112, "METEOR": 0.26390851578350305, "ROUGE_L": 0.21721068249258166, "CIDEr": 1.1851514642274266e-11, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.2413793103448276, "f": 0.23333333333333334, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The sign on the side of the building reads factory trained technicians.\n\nThe building is a large, brick structure with a large window on the side. The sign is made of metal and has a black background with white letters. The letters are in a sans serif font and are spaced evenly apart."}, "130076": {"image_id": 130076, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.08330762903217113, "Bleu_4": 1.0646588104484678e-05, "METEOR": 0.21337542874625132, "ROUGE_L": 0.20497311827956988, "CIDEr": 1.92201800740793e-10, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.125, "f": 0.08888888888888889, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The man is standing in front of a fireplace, holding a remote control in his hand. He is wearing a brown sweater and jeans. The room is decorated with a couch, a coffee table, and a bookshelf. The fireplace is made of brick and has a large chimney"}, "407042": {"image_id": 407042, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 0.09044710069126459, "Bleu_4": 0.06202310247330943, "METEOR": 0.2379699137743066, "ROUGE_L": 0.2083096186681844, "CIDEr": 1.6674879603453496e-09, "SPICE": {"All": {"pr": 0.04, "re": 0.06666666666666667, "f": 0.05, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows two children standing in front of a large crowd of people at an event. The children are holding stuffed animals, one of which is a dog. The crowd is made up of people of all ages, including children, adults, and seniors. There are several tents and tables set up in"}, "170784": {"image_id": 170784, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.12549213105688165, "Bleu_4": 0.09791579531640562, "METEOR": 0.32456232830475373, "ROUGE_L": 0.36357615894039735, "CIDEr": 3.297491476864858e-08, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.30434782608695654, "f": 0.28571428571428575, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a red double decker bus parked on the side of a city street. The bus has a large red and white striped awning on the front and a sign on the side that reads, \"1234567890\". There are people walking on the sidewalk and"}, "189744": {"image_id": 189744, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.17614871215260033, "Bleu_3": 0.08770015703255855, "Bleu_4": 1.1064891248238045e-05, "METEOR": 0.22464228314665596, "ROUGE_L": 0.270595690747782, "CIDEr": 1.386312852767817e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The building is a red brick building with a white facade. It has a large sign on the front that reads \"the pelagate\". There are several cars parked in front of the building. The street is lined with trees and there are several other buildings in the background."}, "222440": {"image_id": 222440, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.13643933968471528, "Bleu_4": 0.08442327695098985, "METEOR": 0.19449818847241485, "ROUGE_L": 0.21721068249258166, "CIDEr": 8.841043940414825e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a large enclosure with several animals inside. The enclosure is surrounded by a fence and there are trees in the background.\n\nThe people in the image are wearing casual clothing and appear to be looking at the animals. There are several animals"}, "78060": {"image_id": 78060, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.08206702275709715, "Bleu_4": 1.041362763232212e-05, "METEOR": 0.22161801068167894, "ROUGE_L": 0.26228501228501233, "CIDEr": 7.677927080255099e-10, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a woman and a child standing on a snowy slope. The woman is wearing a black jacket and pants, while the child is wearing a pink snow suit. They are both holding skis and poles. The background is a mountain range with snow covered peaks and trees."}, "224647": {"image_id": 224647, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2680359137985001, "Bleu_3": 0.1916881510700032, "Bleu_4": 0.1433785763749558, "METEOR": 0.34552545605694585, "ROUGE_L": 0.3742331288343558, "CIDEr": 1.1710671008538754e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a young girl holding a tennis racket and standing on a grassy field with other children. She is wearing a bright orange dress with white polka dots and white shoes. The background is a dark blue sky with white clouds.\n\nThe image is of a young girl holding a tennis"}, "301326": {"image_id": 301326, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.09869275424218699, "Bleu_3": 5.65013632025846e-07, "Bleu_4": 1.358235968559138e-09, "METEOR": 0.1272429220291276, "ROUGE_L": 0.16648471615720525, "CIDEr": 2.070588419408787e-13, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.17647058823529413, "f": 0.13333333333333333, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a black and white cat and a black cat standing on the floor near a fence. The fence is made of metal and has a gate that is open. There is a small table with a bowl of food on it next to the fence. The fence is surrounded by plants and trees"}, "128058": {"image_id": 128058, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.13479285035956426, "Bleu_3": 0.070433097826065, "Bleu_4": 9.097876739853199e-06, "METEOR": 0.2481352902389526, "ROUGE_L": 0.21863799283154117, "CIDEr": 6.794937444671571e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.23333333333333334, "f": 0.2413793103448276, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and white shorts, and has a white racket in his hand. The court is made of grass and there are lines on it. The sun is shining down on the court and there are trees in the background."}, "123867": {"image_id": 123867, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.1647705109111272, "Bleu_3": 0.08158237122518461, "Bleu_4": 1.0260020371425162e-05, "METEOR": 0.16843202687957046, "ROUGE_L": 0.22241127856101123, "CIDEr": 2.4010688650818506e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a dog running in a park with a girl and a boy in the background\n\nThe dog is a small, fluffy brown dog with a red collar and a leash. The girl is wearing a pink dress and has a pink hat on her head. The boy is we"}, "331753": {"image_id": 331753, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1360198059227937, "Bleu_3": 0.07435849582310866, "Bleu_4": 9.831839444823975e-06, "METEOR": 0.21677591818709402, "ROUGE_L": 0.22775357809583074, "CIDEr": 1.2871263050901076e-08, "SPICE": {"All": {"pr": 0.1875, "re": 0.2222222222222222, "f": 0.20338983050847456, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a row of white toilets with black handles and white seats. The toilets are arranged in a row with the handles facing towards the viewer. The toilets are in a warehouse or storage area, with shelves and crates stacked around them. The floor is"}, "425690": {"image_id": 425690, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.22228757208608238, "Bleu_3": 0.1263440400692252, "Bleu_4": 1.4317123154265693e-05, "METEOR": 0.2102563869861696, "ROUGE_L": 0.22889305816135083, "CIDEr": 2.1222206205286268e-11, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.19047619047619047, "f": 0.1568627450980392, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of a city street at night. There are several cars and pedestrians crossing the street, and the buildings on either side are illuminated by streetlights. The sky is dark and cloudy, with a few stars visible in the distance. The image is taken"}, "225658": {"image_id": 225658, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.15075567228616532, "Bleu_3": 0.10808321953937244, "Bleu_4": 0.06986340319007754, "METEOR": 0.21600857315583866, "ROUGE_L": 0.2426136363636364, "CIDEr": 5.983095202803955e-14, "SPICE": {"All": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man wearing a suit and tie standing in front of a mirror. He is holding a phone in his hand and has a serious expression on his face. The background is a dimly lit room with a large mirror on the wall.\n\nThe man in the image is wearing a suit and"}, "331236": {"image_id": 331236, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.1184508853673932, "Bleu_3": 6.683330244266766e-07, "Bleu_4": 1.5960821227040779e-09, "METEOR": 0.20822178062170923, "ROUGE_L": 0.27566171723692706, "CIDEr": 9.056552016474816e-09, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08, "f": 0.07692307692307691, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image is a blue t-shirt with a red and white design on it. There is a red and white frisbee on the ground next to the t-shirt. There is also a red and white bag on the ground next to the t-shirt. The bag has a red and"}, "47225": {"image_id": 47225, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.18873292695514476, "Bleu_4": 0.14317123154265693, "METEOR": 0.28715357534304575, "ROUGE_L": 0.3216168717047452, "CIDEr": 3.0570812371333854e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of stuffed animals sitting on a table. There are two bears, one wearing a red shirt and the other wearing a blue shirt. There is also a tiger sitting on the table. The bears are looking at each other and the tiger is looking at the"}, "64300": {"image_id": 64300, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.23924685418403427, "Bleu_3": 0.17544010109425545, "Bleu_4": 0.12004755374502663, "METEOR": 0.2478066564149172, "ROUGE_L": 0.2872277810476751, "CIDEr": 1.3271559356571293e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a bird standing on the beach with its wings spread out. The bird is a pelican, which is a large waterbird with a long, pointed beak and long legs. The bird is standing on the beach with its back to the water, looking out towards the horizon. The sky is clear and"}, "59547": {"image_id": 59547, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.12354612406992554, "Bleu_3": 0.08786688777044825, "Bleu_4": 0.06266221810743723, "METEOR": 0.21098295356893026, "ROUGE_L": 0.26771159874608147, "CIDEr": 1.7189182087495226e-08, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.17857142857142858, "f": 0.16129032258064516, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The woman in the image is holding a plate of cupcakes. She is wearing a blue shirt and jeans, and has a smile on her face. The cupcakes are decorated with colorful frosting and sprinkles. The woman is standing in front of a house with a green"}, "501538": {"image_id": 501538, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 0.14563421111572247, "Bleu_4": 1.7361123498626597e-05, "METEOR": 0.23311196253147595, "ROUGE_L": 0.31466470154753134, "CIDEr": 4.0463048247672956e-05, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.038461538461538464, "f": 0.04081632653061224, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The woman in the image is holding a banana in her hand. She is wearing a t-shirt with the words `hello kitty' written on it. The background of the image is a blue wall with white graffiti."}, "318471": {"image_id": 318471, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1373143068093302, "Bleu_3": 0.07085740383081722, "Bleu_4": 9.094693994314411e-06, "METEOR": 0.17588982946200102, "ROUGE_L": 0.207506520013607, "CIDEr": 4.453223399417895e-13, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.07407407407407407, "f": 0.08163265306122448, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a street sign with the names of two people, one on each side of the street. The sign is made of metal and has a blue background with white letters. The two people are standing on either side of the street, looking at each other. They are both wearing sunglasses and have"}, "6091": {"image_id": 6091, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.07529519927190922, "Bleu_4": 9.612424997506294e-06, "METEOR": 0.20438019234686183, "ROUGE_L": 0.27774615822424586, "CIDEr": 6.638515495941379e-10, "SPICE": {"All": {"pr": 0.3125, "re": 0.21739130434782608, "f": 0.2564102564102564, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a person holding a stop sign in front of a car at night. The person is wearing a black shirt and pants, and has a white hat on their head. The car is parked on the side of the road, and there are streetlights on either side of it. The"}, "73": {"image_id": 73, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.09476070829395405, "Bleu_3": 5.719241732016864e-07, "Bleu_4": 1.412470464555783e-09, "METEOR": 0.16278021976214985, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.2118498294325497e-09, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.2692307692307692, "f": 0.28571428571428575, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a vintage motorcycle parked on the side of the road. The motorcycle is black and has a white number plate on the front. The tires are black and the handlebars are black. The motorcycle has a black seat and a black engine. The motorcycle is parked next"}, "196715": {"image_id": 196715, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.18890811128268284, "Bleu_3": 0.14281978481313226, "Bleu_4": 0.11616125223116953, "METEOR": 0.2967947825944817, "ROUGE_L": 0.26505276225946617, "CIDEr": 1.3262643824873193e-10, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a white truck parked on a sandy beach with people in the background. The sky is clear and blue.\n\nThe truck has a surfboard on the back and a person is standing on the side of the truck. There are other people in the background, some of whom"}, "461467": {"image_id": 461467, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.1772810520820019, "Bleu_3": 0.1094051585098822, "Bleu_4": 0.07265305576027399, "METEOR": 0.23056982432482395, "ROUGE_L": 0.2594167679222357, "CIDEr": 4.971689603773697e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.125, "f": 0.12000000000000001, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting at a table in a restaurant. They are all wearing glasses and have their hands on the table. There is a pizza on the table with various toppings. The background is a wall with a window and a view of the city."}, "398066": {"image_id": 398066, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.10167765666209894, "Bleu_3": 5.728348820235567e-07, "Bleu_4": 1.365914929670925e-09, "METEOR": 0.1612242018040177, "ROUGE_L": 0.13950829045168667, "CIDEr": 1.846249539948904e-14, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13793103448275862, "f": 0.1568627450980392, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a baseball game being played on a field with a large tree in the background. The players are wearing baseball uniforms and are holding bats. The sky is clear and there are no clouds in the sky. The trees are green and there are no leaves on them. The grass is green and there"}, "431140": {"image_id": 431140, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.10654502541910188, "Bleu_4": 0.06978423773350045, "METEOR": 0.2754121427210297, "ROUGE_L": 0.31077147016011636, "CIDEr": 3.6643359733264945e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2962962962962963, "f": 0.2909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a toilet, sink, and mirror. The walls are painted white and the floor is made of tile. There is a window on the left side of the room and a door on the right side. The toilet is a standard size and the sink is a standard size"}, "67315": {"image_id": 67315, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1191907417701306, "Bleu_4": 0.07590831443387894, "METEOR": 0.2346136292560522, "ROUGE_L": 0.28367380833748546, "CIDEr": 2.0750675698119573e-12, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.0625, "f": 0.07142857142857144, "fn": 30.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man wearing a suit and tie standing in front of a window. He is looking down at his hands, which are clasped together in front of him. The man is wearing a white shirt with a black tie and black pants. The background is a white wall with a window"}, "261777": {"image_id": 261777, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.128337789581408, "Bleu_3": 0.06952980477333488, "Bleu_4": 9.147827112062708e-06, "METEOR": 0.1296764159973769, "ROUGE_L": 0.2238532110091743, "CIDEr": 4.7085619507552634e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.19230769230769232, "f": 0.2173913043478261, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a person jumping off a snowboard while in mid air. The person is wearing a black jacket and black pants, and has a black helmet on their head. The background is a blue sky with some clouds in it.\n\nThe image is taken from a high angle, looking"}, "62296": {"image_id": 62296, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.06262242910727484, "Bleu_3": 4.309444049146827e-07, "Bleu_4": 1.1363330167951873e-09, "METEOR": 0.1189873417721519, "ROUGE_L": 0.18654434250764526, "CIDEr": 8.863126100401739e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a marina with several boats docked at the docks. The boats are of various sizes and colors, and there are several people standing on the docks, looking out at the water. In the background, there are several tall palm trees and a blue sky with fluffy white clouds."}, "329088": {"image_id": 329088, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1188177051548479, "Bleu_3": 6.604735246466958e-07, "Bleu_4": 1.5652411276385143e-09, "METEOR": 0.19115253459386114, "ROUGE_L": 0.17867603983596952, "CIDEr": 1.1050648558507849e-10, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.17391304347826086, "f": 0.14814814814814814, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person skiing down a snowy slope. The person is wearing a red jacket, black pants, and black ski boots. They are holding a ski pole in their right hand and have a backpack on their back. The sky is blue and there are mountains in the background."}, "337120": {"image_id": 337120, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.2556147957905549, "Bleu_3": 0.17129428553738008, "Bleu_4": 0.09963561645527105, "METEOR": 0.2742678154192711, "ROUGE_L": 0.31282051282051276, "CIDEr": 1.0458448466864968e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a brick building with a clock on the side. There are bicycles parked on the sidewalk in front of the building. The sky is blue and there are trees in the background.\n\nThe building appears to be old and has a lot of character. The clock on the side is old"}, "60240": {"image_id": 60240, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.20604084591910862, "Bleu_3": 0.17093430909432805, "Bleu_4": 0.14949336947451927, "METEOR": 0.32497096822439697, "ROUGE_L": 0.33292904790782296, "CIDEr": 4.736970052299491e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person holding a cell phone in their hand while driving a car. The person is wearing a black jacket and has their hands on the steering wheel. The car is a silver sedan with tinted windows and a sunroof. The background is a city street with buildings and trees."}, "134657": {"image_id": 134657, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.1125270530222903, "Bleu_3": 0.07769326548712253, "Bleu_4": 0.05454043082394592, "METEOR": 0.215742965952138, "ROUGE_L": 0.2476798143851508, "CIDEr": 1.8744101625906084e-13, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.17857142857142858, "f": 0.17857142857142858, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a highway with a bridge over it. The sky is clear and blue. There are no cars on the road.\n\nThe image shows a highway with a bridge over it. The sky is clear and blue. There are no cars on the road. The bridge is made of steel and has a large"}, "166979": {"image_id": 166979, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.1591372845179993, "Bleu_3": 0.07769326548712255, "Bleu_4": 9.69881251488752e-06, "METEOR": 0.2296675935699707, "ROUGE_L": 0.23461538461538461, "CIDEr": 1.265596268519576e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a boat in the water with a large building in the background\n\nThe boat is a red and white fireboat with a large red and white stripe on the side. The building in the background is a large, modern building with a lot of windows and a flat roof. There are several smaller"}, "160437": {"image_id": 160437, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.1313579154832357, "Bleu_3": 7.061638347858738e-07, "Bleu_4": 1.6457686856089725e-09, "METEOR": 0.14382014653754716, "ROUGE_L": 0.15259537210756724, "CIDEr": 1.143344308589988e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a zebra lying on the ground in a zoo enclosure. The zebra has a brown and white striped pattern on its body and is looking up at the camera. There are several other zebras in the enclosure, but they are not visible in the image. The image is"}, "426815": {"image_id": 426815, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.13997719075795917, "Bleu_3": 0.12430963509343392, "Bleu_4": 0.11133996756281148, "METEOR": 0.2238706868227662, "ROUGE_L": 0.28355607205113303, "CIDEr": 1.1981972176433674e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man riding a horse in the water. The horse is black and the man is wearing a hat and riding boots. The water is calm and there are no other people in the image.\n\nThe image is in black and white and the lighting is bright. The horse is"}, "31749": {"image_id": 31749, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.10942520359115704, "Bleu_3": 6.16909583375895e-07, "Bleu_4": 1.4720536435426584e-09, "METEOR": 0.14883059062585632, "ROUGE_L": 0.18496058217101274, "CIDEr": 1.1936326566993844e-11, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2608695652173913, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image is of a girl sitting on the floor with her back to the camera, looking at a clock on the wall. The clock is showing the time 12:00. The girl is wearing a black dress with white gloves and a black hat. The background is a dark brown wood floor with"}, "54337": {"image_id": 54337, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.21398889174339228, "Bleu_3": 0.13736495494745896, "Bleu_4": 0.08402453643289479, "METEOR": 0.27735657794844704, "ROUGE_L": 0.2513243084167157, "CIDEr": 9.488961795736733e-12, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.3333333333333333, "f": 0.3137254901960785, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "This is an image of a group of people sitting around a table in a room. They are all wearing suits and ties and appear to be having a meeting. There are several bottles of alcohol on the table and a whiteboard with notes written on it. The room is well lit and there are"}, "161044": {"image_id": 161044, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.11485555942835955, "Bleu_4": 0.07312149273625368, "METEOR": 0.2432997365495195, "ROUGE_L": 0.21682464454976302, "CIDEr": 7.812091446973856e-14, "SPICE": {"All": {"pr": 0.15, "re": 0.13043478260869565, "f": 0.13953488372093023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows two planes flying in the sky. One is a small plane with a red and white stripe on the side, and the other is a larger plane with a black and white stripe on the side. They are flying in a straight line, with the smaller plane in front of the larger one."}, "161978": {"image_id": 161978, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.13598594186873444, "Bleu_3": 8.008696616959508e-07, "Bleu_4": 1.9572863642501535e-09, "METEOR": 0.14479846231383095, "ROUGE_L": 0.23940345368916802, "CIDEr": 0.00016550482191895485, "SPICE": {"All": {"pr": 0.125, "re": 0.15789473684210525, "f": 0.13953488372093023, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people skateboarding on a concrete skate park. The skateboarders are wearing different types of clothing, including jeans, t-shirts, and sneakers. They are all wearing helmets and knee pads to protect themselves from"}, "106046": {"image_id": 106046, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.13308032829543895, "Bleu_4": 0.10747234966425785, "METEOR": 0.25543279427771076, "ROUGE_L": 0.2830626450116009, "CIDEr": 1.6551715618236536e-12, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09523809523809523, "f": 0.0909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young girl sitting at a table with a plate of food in front of her. The table is covered with a white tablecloth and there are two chairs on either side of the table. The girl is wearing a red sweater and has a bow in her hair. There are two pl"}, "138970": {"image_id": 138970, "Bleu_1": 0.16326530611911708, "Bleu_2": 0.1010152544531381, "Bleu_3": 0.06010242872773111, "Bleu_4": 8.288569027871298e-06, "METEOR": 0.19289778306466634, "ROUGE_L": 0.20158625247851947, "CIDEr": 5.6507569417841866e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.12, "f": 0.11538461538461538, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people standing around a white refrigerator. They are all wearing casual clothing and appear to be loading it into the back of a truck. The truck has a large open bed and the people are using ropes to secure the refrigerator. The scene"}, "450037": {"image_id": 450037, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.13093073413895012, "Bleu_3": 0.0709491705970709, "Bleu_4": 9.336541408128833e-06, "METEOR": 0.18124757255722895, "ROUGE_L": 0.22732919254658387, "CIDEr": 1.1695486012089912e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17391304347826086, "f": 0.1568627450980392, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in a field with horses. The people are wearing riding clothes and holding reins. The horses are wearing saddles and bridles. The background is a green field with trees in the distance.\n\nThe image is taken from a bird's eye view"}, "237869": {"image_id": 237869, "Bleu_1": 0.1525423728787705, "Bleu_2": 0.11467434132484902, "Bleu_3": 0.07727325671842704, "Bleu_4": 9.52741110674778e-06, "METEOR": 0.1415535996128534, "ROUGE_L": 0.19637300139499944, "CIDEr": 6.962231822157757e-14, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.06451612903225806, "f": 0.06896551724137931, "fn": 29.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image is of a clock on a shelf in a train station. The clock is made of metal and has a round face with numbers and hands. The clock is surrounded by a metal frame and has a small handle on the side. The clock is on a shelf in a train station and there are other objects"}, "323598": {"image_id": 323598, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.17708440082601892, "Bleu_3": 0.1161743378037171, "Bleu_4": 0.07962812737615463, "METEOR": 0.23841508614119586, "ROUGE_L": 0.2663755458515284, "CIDEr": 2.4435111156059726e-07, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.1935483870967742, "f": 0.19999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a bathroom with a large bathtub, sink, and toilet. The walls are painted white and there are wooden floors. The room has a skylight and a window with curtains. There is a mirror on the wall opposite the sink."}, "261948": {"image_id": 261948, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.09180747086790693, "Bleu_4": 1.1327499538368697e-05, "METEOR": 0.1774483015240143, "ROUGE_L": 0.26521739130434785, "CIDEr": 4.533133975010758e-10, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08695652173913043, "f": 0.0909090909090909, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image is of an old suitcase with a floral pattern on the outside. The suitcase has a green lining and a white handle. The suitcase is sitting on top of a wooden crate.\n\nThe suitcase is made of metal and has a green lining. The handle is made of"}, "438539": {"image_id": 438539, "Bleu_1": 0.1666666666631945, "Bleu_2": 1.883108942847125e-09, "Bleu_3": 4.255961461179721e-12, "Bleu_4": 2.034441173199727e-13, "METEOR": 0.17440758293838862, "ROUGE_L": 0.1601049868766404, "CIDEr": 2.983742352872949e-10, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.20833333333333334, "f": 0.1923076923076923, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people playing a game of frisbee on a grassy field. The people are wearing different colored shirts and pants, and they are all holding frisbees. The image is in black and white, and it looks like it was taken in the spring."}, "204044": {"image_id": 204044, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.17978662998615724, "Bleu_3": 0.09092474869081758, "Bleu_4": 1.1566428018171823e-05, "METEOR": 0.26938873365316274, "ROUGE_L": 0.25902335456475584, "CIDEr": 2.123244261022195e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a kitchen with white appliances and wooden cabinets. There is a stove, refrigerator, and sink in the kitchen. The floor is made of hardwood.\n\nThe kitchen has a window with a view of the outdoors. There is a table and chairs in the"}, "142454": {"image_id": 142454, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2285817953234835, "Bleu_3": 0.17238297400489144, "Bleu_4": 0.1324062816098676, "METEOR": 0.2813213985048859, "ROUGE_L": 0.3526011560693642, "CIDEr": 2.3730121048671146e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two cats sitting on a bathroom counter next to a sink. The cats are looking at each other and appear to be in a playful mood. The sink is filled with water and there are towels hanging on the wall. The mirror on the wall shows the reflection of the"}, "239455": {"image_id": 239455, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.23783150201248485, "Bleu_3": 0.1264135347961999, "Bleu_4": 0.07784926365543571, "METEOR": 0.23219247116343888, "ROUGE_L": 0.19904285403524036, "CIDEr": 7.202609910123499e-14, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.25, "f": 0.20833333333333331, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of boats docked at a pier on a body of water. The boats are red and white and have a small cabin on top. There are several other boats docked at the pier as well. The water is calm and there are some clouds in the sky. The pier is made of wood"}, "409725": {"image_id": 409725, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.0930756528209598, "Bleu_4": 0.06305717703637675, "METEOR": 0.212297627565478, "ROUGE_L": 0.22344322344322343, "CIDEr": 7.99735712091067e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.3076923076923077, "f": 0.1951219512195122, "fn": 9.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This image shows a group of people standing on a sidewalk in front of a large building. They are holding kites and looking up at the sky. There are other people in the background, some of whom are also holding kites. The sky is clear and blue.\n\nThe building in the background is a"}, "299493": {"image_id": 299493, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1348399724902187, "Bleu_3": 6.956880074617597e-07, "Bleu_4": 1.5876030342378672e-09, "METEOR": 0.22072963028819584, "ROUGE_L": 0.21682464454976302, "CIDEr": 2.0722662922773964e-13, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2, "f": 0.19672131147540983, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.38461538461538464, "f": 0.3571428571428571, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a yellow bus driving down the street. The bus is parked on the side of the road and there are buildings in the background. The sky is clear and there are no clouds.\n\nThe bus is a yellow school bus with a white roof and a black stripe down the side. It has"}, "460390": {"image_id": 460390, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.0939614522123186, "Bleu_4": 0.06414506805775248, "METEOR": 0.18647204009593926, "ROUGE_L": 0.1920654911838791, "CIDEr": 1.289282675108569e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17391304347826086, "f": 0.1568627450980392, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are wearing ski gear and have their skis pointed downwards. The snow is white and there are no trees or other obstacles in the way. The sky is blue and there are no clouds. The sun is shining and"}, "473002": {"image_id": 473002, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 0.08411954328528157, "Bleu_4": 1.0608359163741716e-05, "METEOR": 0.1957221516300489, "ROUGE_L": 0.2582869586256957, "CIDEr": 9.492349191748286e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.35714285714285715, "f": 0.25641025641025644, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a young boy standing on a skateboard, wearing a black shirt and jeans, and holding onto a red skateboard. He is standing on a sidewalk in front of a group of people, who are walking and standing around him. The sky is cloudy and there are trees"}, "523470": {"image_id": 523470, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.18625278992847225, "Bleu_3": 0.0916919101140012, "Bleu_4": 1.1504959544342732e-05, "METEOR": 0.18619198371419465, "ROUGE_L": 0.2749517063747585, "CIDEr": 4.7648748420515176e-08, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.0625, "f": 0.07272727272727272, "fn": 30.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a plate with two skewers of meat, one with chicken and the other with beef, on top of a bed of salad with carrots, cabbage, and lettuce. There is a small bowl of sauce on the side. The plate is on a white tablecl"}, "85944": {"image_id": 85944, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.19782182158264086, "Bleu_3": 0.1311863860222524, "Bleu_4": 0.08156879226605328, "METEOR": 0.21857128630602107, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.5185893529597713e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13043478260869565, "f": 0.11764705882352941, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people standing around a bar in a restaurant. They are all wearing casual clothing and smiling at each other. The bar has several bottles of wine on it, and there are glasses on the counter for people to drink from. The walls of the restaurant are made of"}, "258523": {"image_id": 258523, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.20948264539468747, "Bleu_3": 0.1562665723986159, "Bleu_4": 0.1141179431024917, "METEOR": 0.27537612718892646, "ROUGE_L": 0.31282051282051276, "CIDEr": 3.2022385747790227e-09, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.35294117647058826, "f": 0.2608695652173913, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black cat lying on top of a toilet seat. The cat is wearing a collar and has its paws tucked under its body. The toilet seat is made of white porcelain and has a clear glass cover on top. The bathroom is tiled with"}}}