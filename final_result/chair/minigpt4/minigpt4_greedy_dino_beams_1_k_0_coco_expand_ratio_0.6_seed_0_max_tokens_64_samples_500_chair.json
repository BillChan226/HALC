{"overall": {"Bleu_1": 0.2576825513268571, "Bleu_2": 0.17175550256440675, "Bleu_3": 0.10836610346436507, "Bleu_4": 0.06796411187397602, "METEOR": 0.21311264059363202, "ROUGE_L": 0.25173202672357614, "CIDEr": 5.9138929225068916e-05, "SPICE": 0.1754691713058786}, "imgToEval": {"472621": {"image_id": 472621, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.10939874362111757, "Bleu_3": 0.06383942191769575, "Bleu_4": 8.71994169021714e-06, "METEOR": 0.1811069808615452, "ROUGE_L": 0.20013123359580048, "CIDEr": 2.0999861545681313e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.23529411764705882, "f": 0.17777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is of a bathroom with a white bathtub, a white sink, and a white toilet. The walls are painted a light beige color and there is a wooden floor. The room is well lit with a chandelier hanging from the ceiling. There is a window on"}, "196053": {"image_id": 196053, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.2114602732248218, "Bleu_3": 0.13076028569422712, "Bleu_4": 1.5473577834500482e-05, "METEOR": 0.2803382791724472, "ROUGE_L": 0.31077147016011636, "CIDEr": 8.174994461698662e-07, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.14285714285714285, "f": 0.12000000000000001, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a woman playing tennis on a court with a net in the background. She is wearing a white shirt and blue shorts and is holding a tennis racket in her right hand. The image is in black and white."}, "42276": {"image_id": 42276, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.15059039854381842, "Bleu_4": 0.10810927622781054, "METEOR": 0.2593207887039401, "ROUGE_L": 0.3351648351648352, "CIDEr": 3.8610069048759486e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. There are several pairs of shoes and a pair of gloves on the floor. The walls are painted white and there is a window on the left side of the room. The floor is made of tile and there is a rug"}, "530226": {"image_id": 530226, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.1819804470697048, "Bleu_3": 0.1070438934390262, "Bleu_4": 0.06935894129229206, "METEOR": 0.2754121427210297, "ROUGE_L": 0.29967248908296945, "CIDEr": 2.2302000752002726e-12, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16666666666666666, "f": 0.1702127659574468, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a polar bear standing on the edge of a frozen lake, looking out at the water. The bear is covered in snow and ice, and its fur is white. The lake is frozen and there are no other animals or people in the image. The sky is clear and blue, with no clouds"}, "487421": {"image_id": 487421, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.13199091933393275, "Bleu_3": 7.580119263366549e-07, "Bleu_4": 1.828061815856166e-09, "METEOR": 0.14543235060904078, "ROUGE_L": 0.2279521674140508, "CIDEr": 1.1667271252809021e-05, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.125, "f": 0.11428571428571428, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image is of a bowl of pasta with vegetables and tofu. The pasta is made with wheat flour and water, and the vegetables are broccoli, carrots, and red onion. The tofu is cubed and fried in a pan with olive oil"}, "536990": {"image_id": 536990, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.20100756304815393, "Bleu_3": 0.09135163170376535, "Bleu_4": 1.100364056976739e-05, "METEOR": 0.2037534313009374, "ROUGE_L": 0.24358243011979464, "CIDEr": 1.0281179678429255e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.4, "f": 0.27906976744186046, "fn": 9.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.75, "f": 0.5714285714285714, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a vase with flowers in it on a shelf next to a window. The wall behind the vase has a painting on it. The painting depicts a woman in a red dress standing in front of a tree. The woman is looking down at the ground. There is a small table next"}, "101762": {"image_id": 101762, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.13469311460752553, "Bleu_3": 0.07085549531664316, "Bleu_4": 9.184122179472467e-06, "METEOR": 0.16539839605296816, "ROUGE_L": 0.21266705403834982, "CIDEr": 7.239820046646248e-12, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.25925925925925924, "f": 0.2641509433962264, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a cat sitting on the floor next to a bicycle. The cat is looking at the bicycle with interest. The bicycle has a red wheel and a black frame. The cat is a grey and white cat with a black nose and ears. The cat is sitting on its haunch"}, "100329": {"image_id": 100329, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.1426954482435772, "Bleu_3": 0.10690314865377899, "Bleu_4": 0.07066328980326636, "METEOR": 0.2277042843793239, "ROUGE_L": 0.24653579676674361, "CIDEr": 6.134379704082659e-11, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16666666666666666, "f": 0.1923076923076923, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a brown bear standing on a rocky outcropping, looking out over a body of water. The bear is standing on its hind legs and has a large, fluffy coat. The water in the background is calm and clear, with a few boats and buildings visible in the distance. The"}, "105234": {"image_id": 105234, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.2247332874836235, "Bleu_3": 0.14192537975093236, "Bleu_4": 0.08610814090205891, "METEOR": 0.28508350179255953, "ROUGE_L": 0.24956165984804207, "CIDEr": 2.612278566134022e-13, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.09375, "f": 0.10909090909090909, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a bride and groom standing at a table with a cake in front of them. They are both smiling and holding their hands up in the air. There are other people in the room, including a woman in a white dress and a man in a black suit, who are also smiling"}, "577355": {"image_id": 577355, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.11895773785545558, "Bleu_3": 0.06522364605376364, "Bleu_4": 8.631003710817792e-06, "METEOR": 0.12084524185814462, "ROUGE_L": 0.17722254503195814, "CIDEr": 1.8414913339712265e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a street with a few buildings on either side. There are some cars parked on the street and some people walking on the sidewalk. The sky is cloudy and there are some trees in the background. The lighting is dim and the colors are muted.\n\nThe image is taken from"}, "526645": {"image_id": 526645, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.15475060698405138, "Bleu_3": 0.0979282921620159, "Bleu_4": 1.1706811738843624e-05, "METEOR": 0.23676997656438042, "ROUGE_L": 0.21266705403834982, "CIDEr": 7.896066527231265e-12, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.13333333333333333, "f": 0.0975609756097561, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a giraffe standing in a forest. The giraffe is brown with spots on its back and legs. It is standing on the ground and looking around. The trees in the background are tall and green. The sky is blue and there are clouds in it. The sun is shining down"}, "476939": {"image_id": 476939, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.1162824824679724, "Bleu_4": 0.0886136602913258, "METEOR": 0.2299119382651872, "ROUGE_L": 0.21585279547062985, "CIDEr": 6.8779974564281414e-12, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people in a hospital room, including a doctor and a nurse. They are standing around a table with medical equipment on it. There are also several beds in the room.\n\nThe walls are painted white and there are windows on the sides. The floor is made of tiles"}, "546444": {"image_id": 546444, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.12950478164521437, "Bleu_3": 6.857872734978661e-07, "Bleu_4": 1.5858040477395045e-09, "METEOR": 0.18140950150528906, "ROUGE_L": 0.1783625730994152, "CIDEr": 2.3127599631422144e-12, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.2631578947368421, "f": 0.19230769230769232, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows two men sitting on the floor in front of a television, watching a game. They are both wearing black and white clothing and have their feet up on the couch. The room is dimly lit and there are no other objects in the room.\n\nThe image is taken in a living"}, "285734": {"image_id": 285734, "Bleu_1": 0.1481481481454047, "Bleu_2": 0.1182211503531082, "Bleu_3": 0.08130907204696847, "Bleu_4": 1.0132385609889831e-05, "METEOR": 0.21005480378951474, "ROUGE_L": 0.22344322344322343, "CIDEr": 3.7174380887713135e-13, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2, "f": 0.19607843137254902, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a young boy holding a kite in his hand, standing in a park with trees and grass in the background. The boy is wearing a red and white striped shirt and blue jeans, and has a determined look on his face. The kite is made of white and yellow paper and"}, "191013": {"image_id": 191013, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.23561672155300986, "Bleu_3": 0.163292915906478, "Bleu_4": 0.09660130805021472, "METEOR": 0.2605632210338882, "ROUGE_L": 0.33351558228540185, "CIDEr": 2.388701604645537e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a large building with a clock on the side. The clock has a face with numbers and hands, and is surrounded by a red and white striped awning. There are cars parked in front of the building, and people are walking on the sidewalk.\n\nThe image is taken at night"}, "50350": {"image_id": 50350, "Bleu_1": 0.333333333325926, "Bleu_2": 0.24618298195313262, "Bleu_3": 0.17797917821554635, "Bleu_4": 0.10763774116165369, "METEOR": 0.2566391486354152, "ROUGE_L": 0.2922655715263518, "CIDEr": 6.755894852874968e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a bathtub, sink, and toilet. The walls are made of wood and there is a rug on the floor. The bathroom has a window with a view of the outdoors.\n\nThe image shows a bathroom with a bathtub, sink"}, "412676": {"image_id": 412676, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.06520506636831809, "Bleu_3": 4.4890551563344676e-07, "Bleu_4": 1.184204612229436e-09, "METEOR": 0.12374019736828698, "ROUGE_L": 0.2139099941554646, "CIDEr": 2.2639815704081516e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2, "f": 0.16, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The building is a large, modern structure with a glass facade. It has a large, open courtyard in the center of the building, surrounded by tall, narrow windows. The building is surrounded by a large, open courtyard in the center of the building, surrounded by tall, narrow windows. The"}, "151742": {"image_id": 151742, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.22430886163262467, "Bleu_3": 0.19781528010491717, "Bleu_4": 0.1737161297459852, "METEOR": 0.2819058428740124, "ROUGE_L": 0.3407821229050279, "CIDEr": 2.3012320498928664e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2857142857142857, "f": 0.24489795918367344, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man in a black suit and tie holding a baby in a white dress. The man has a beard and is wearing glasses. The baby is wearing a white dress and has a bow on its head. The image is taken in a church with stained glass windows and pews"}, "433924": {"image_id": 433924, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.23644230070621639, "Bleu_3": 0.19596643100126745, "Bleu_4": 0.16481100947130725, "METEOR": 0.3113676042938747, "ROUGE_L": 0.34231200897867564, "CIDEr": 2.3634285420664987e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.13793103448275862, "f": 0.15384615384615385, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a woman holding a pair of scissors in her hand. She is wearing a white shirt and black pants. The scissors are open and the woman is looking at them with a serious expression on her face. The background is a dark brown color and there is a small table in"}, "160104": {"image_id": 160104, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.07529519927190922, "Bleu_4": 9.612424997506294e-06, "METEOR": 0.2059239366054245, "ROUGE_L": 0.2381483547127719, "CIDEr": 3.493905661657128e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "There are two plates on the table with food on them. One plate has a bowl of soup and the other has a bowl of cereal. There is also a glass of orange juice on the table. The woman is sitting at the table with a cup of coffee in front of her."}, "174198": {"image_id": 174198, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.15328483486852826, "Bleu_3": 0.07531449419024144, "Bleu_4": 9.431059457448739e-06, "METEOR": 0.21262933603147333, "ROUGE_L": 0.2733893557422969, "CIDEr": 1.2131844992332768e-14, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14814814814814814, "f": 0.1509433962264151, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The train is a green and white train with a yellow stripe on the front. It is traveling through a tunnel with other trains in the background. The tunnel is made of concrete and has a smooth surface. There are no people in the train or on the platform. The train is moving at a slow speed."}, "313341": {"image_id": 313341, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.22214157542810112, "Bleu_3": 0.1426495013657264, "Bleu_4": 0.08728913550550585, "METEOR": 0.24754403950482323, "ROUGE_L": 0.2507339988256019, "CIDEr": 1.4757427977898762e-11, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a group of people sitting at a table with laptops in front of them. They are all wearing black shirts and red hair. There is a white tablecloth on the table and a vase of flowers on the side. The walls are painted a light blue color and there are"}, "92355": {"image_id": 92355, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.1311312829167715, "Bleu_4": 0.10005391875419713, "METEOR": 0.19178706630758366, "ROUGE_L": 0.2804597701149425, "CIDEr": 1.0047344701142042e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a kitchen with a stove, a refrigerator, and a sink. There are several pots and pans on the stove, and a kettle on the counter. The walls are painted white and there are several clocks on the walls. The floor is made of tile and"}, "196681": {"image_id": 196681, "Bleu_1": 0.3157894736786704, "Bleu_2": 0.249058377064041, "Bleu_3": 0.1652341724911138, "Bleu_4": 0.11369306152249882, "METEOR": 0.24419280942135763, "ROUGE_L": 0.2627894453419494, "CIDEr": 1.9086006830100831e-13, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a small plane flying over a mountain range with trees and mountains in the background. The sky is clear and blue with a few clouds in the distance. The plane is flying low and appears to be on a straight path. The mountains are tall and rugged, with peaks visible in the distance. The"}, "53457": {"image_id": 53457, "Bleu_1": 0.30508474575754096, "Bleu_2": 0.2405429276791714, "Bleu_3": 0.19225137582285995, "Bleu_4": 0.1587075497326484, "METEOR": 0.3103165980189442, "ROUGE_L": 0.27680090754395914, "CIDEr": 6.050771072621442e-13, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on top of a television set. The cat is looking directly at the camera with its eyes wide open. The television set is mounted on the wall and has a flat screen. The room appears to be a living room with a couch and a coffee table in the background. The cat is"}, "245301": {"image_id": 245301, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.24046440328937668, "Bleu_3": 0.15454026854146363, "Bleu_4": 0.11255098183926564, "METEOR": 0.20825642277143078, "ROUGE_L": 0.23303196230739842, "CIDEr": 4.987524622784446e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.2222222222222222, "f": 0.18604651162790697, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman riding a horse on a grassy field. The woman is wearing a red coat and riding boots, and the horse is wearing a saddle and bridle. The background is a cloudy sky with some trees in the distance.\n\nThe image is of a woman"}, "297574": {"image_id": 297574, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.24174688920325796, "Bleu_3": 0.17556287237377596, "Bleu_4": 0.11953994172638398, "METEOR": 0.3146441011714372, "ROUGE_L": 0.2476798143851508, "CIDEr": 8.534730374860506e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 28.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a plate with three slices of pizza on it. The pizza slices are cut into small pieces and are arranged on the plate in a neat and organized manner. The plate is made of a white material and has a blue and white checkered pattern on it. There is a fork and kn"}, "392048": {"image_id": 392048, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 9.146994035438242e-07, "Bleu_4": 2.0087890503675587e-09, "METEOR": 0.1955372885471508, "ROUGE_L": 0.1852976913730255, "CIDEr": 6.690395586626205e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a plate of waffles with whipped cream and strawberries on a tray. There is a cup of coffee on the side of the plate. The plate is on a table with a white tablecloth. There is a baby in a high chair next to the table. The"}, "434511": {"image_id": 434511, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.2194268628641013, "Bleu_3": 0.18526807376841062, "Bleu_4": 0.14871836478447198, "METEOR": 0.35170886674552804, "ROUGE_L": 0.35158501440922196, "CIDEr": 5.172543063023314e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man sitting at a table in a coffee shop, using a laptop computer. He is wearing a blue shirt and jeans, and has a cup of coffee in front of him. The walls of the coffee shop are painted a light brown color, and there are several tables and chairs in"}, "454348": {"image_id": 454348, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.0971285862339108, "Bleu_3": 5.66104921326939e-07, "Bleu_4": 1.3733465907666018e-09, "METEOR": 0.18135716033088586, "ROUGE_L": 0.1821983273596177, "CIDEr": 6.553115936391143e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.22580645161290322, "f": 0.23728813559322032, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4666666666666667, "re": 0.5384615384615384, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}}, "caption": "The image shows a bench made of wood in the middle of a grassy field. The bench is surrounded by trees and there is a path leading to the bench. The sky is clear and there are no clouds in the sky. The sun is shining down on the bench and the trees. The"}, "554459": {"image_id": 554459, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.086841684284798, "Bleu_3": 5.323069753321686e-07, "Bleu_4": 1.324562934342616e-09, "METEOR": 0.12738853503184713, "ROUGE_L": 0.15024630541871922, "CIDEr": 2.5521667755126944e-11, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on the tarmac of an airport. They are all wearing sunglasses and smiling at the camera. The woman in the middle is holding a guitar and the man on the right is holding a suitcase. The woman on the left is holding a camera"}, "455981": {"image_id": 455981, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.14227759830242195, "Bleu_3": 8.178816083045061e-07, "Bleu_4": 1.974432115677638e-09, "METEOR": 0.23199865858090105, "ROUGE_L": 0.31145149525893506, "CIDEr": 1.0277045203975657e-05, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a toilet in a bathroom. The toilet is white and has a seat and lid. There is a sink in the background. The floor is made of tile and there is a window in the background."}, "498363": {"image_id": 498363, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.16163173752903065, "Bleu_3": 0.100810174751238, "Bleu_4": 0.06727996774735587, "METEOR": 0.2465391803986196, "ROUGE_L": 0.25894481503941785, "CIDEr": 2.3795629084215893e-12, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.07407407407407407, "f": 0.08163265306122448, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image is a black and white photo of a chain with a pair of scissors hanging from it\n\nThe chain is made of metal and has a large, heavy metal ring attached to the end of it. The scissors are also made of metal and have a sharp blade. The image is"}, "122572": {"image_id": 122572, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.13479285035956426, "Bleu_3": 0.070433097826065, "Bleu_4": 9.097876739853199e-06, "METEOR": 0.14574012587222102, "ROUGE_L": 0.1862026862026862, "CIDEr": 3.8232326963586525e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two sheep walking on the road. They are wearing collars and appear to be on a leash. The trees in the background are tall and green, and there is a mountain range in the distance.\n\nThe sheep are walking in a line, with one leading the way and the other following"}, "516143": {"image_id": 516143, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.16714975946414357, "Bleu_3": 0.1180105578990872, "Bleu_4": 0.0900441795848082, "METEOR": 0.27033304061057717, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.3849679883470575e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a bus driving down a street with buildings on either side. The bus is green and has the words \"Green Line\" written on the side. There are people standing on the sidewalk and a sign that says \"Welcome to the Beach\".\n\nThe image is taken from a bird's eye"}, "478621": {"image_id": 478621, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.2859388156341343, "Bleu_3": 0.1988402480400875, "Bleu_4": 0.11142577877688035, "METEOR": 0.27996172106137335, "ROUGE_L": 0.31282051282051276, "CIDEr": 7.093735077469607e-10, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.25, "f": 0.30434782608695654, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a man in a blue umbrella walking down a sidewalk in front of a row of houses. The houses are painted in different colors and have white shutters. The man is wearing a suit and tie and has an umbrella over his head. There are trees and flowers in the background"}, "353935": {"image_id": 353935, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.13857638305004102, "Bleu_3": 0.08110083286556014, "Bleu_4": 1.111096998955572e-05, "METEOR": 0.18181818181818182, "ROUGE_L": 0.23282442748091606, "CIDEr": 9.32157451644991e-06, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.11538461538461539, "f": 0.10909090909090909, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a plate with a breakfast dish on it. The dish consists of pancakes with fruit on top. There is a fork and knife on the plate. The background is a red and white checkered tablecloth."}, "443952": {"image_id": 443952, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.12875644765560088, "Bleu_4": 0.09518826316467809, "METEOR": 0.21464967389494805, "ROUGE_L": 0.24358243011979464, "CIDEr": 5.405224480485852e-13, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.3125, "f": 0.2564102564102564, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a large walk in shower, a toilet, and a sink. The walls are white and the floor is made of wood. There is a large window on one side of the room and a door on the other. The room is well lit and has a large mirror on"}, "364399": {"image_id": 364399, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1556997888288053, "Bleu_3": 8.261061662208591e-07, "Bleu_4": 1.9140997885086772e-09, "METEOR": 0.1677533783842574, "ROUGE_L": 0.17268223637650387, "CIDEr": 1.194279401129362e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17647058823529413, "f": 0.15789473684210528, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a table with three bowls of food on it. The bowls are filled with vegetables, including carrots, broccoli, and asparagus. There are also some pieces of chicken and beef in the bowls. The table is made of wood and has a white"}, "281733": {"image_id": 281733, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1458649914948234, "Bleu_3": 0.0974371940074102, "Bleu_4": 1.197403292686344e-05, "METEOR": 0.22286691218414165, "ROUGE_L": 0.2401574803149606, "CIDEr": 5.540732834629384e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a young boy holding a donut in his hand. The donut is covered in chocolate frosting and sprinkles. The boy is wearing a white shirt and blue jeans. There are other people in the background of the image, but they are not visible. The light"}, "250167": {"image_id": 250167, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.20995626366288764, "Bleu_3": 0.14018855614807782, "Bleu_4": 0.08750038373269002, "METEOR": 0.30026665231504174, "ROUGE_L": 0.26521739130434785, "CIDEr": 1.372591331746774e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.5, "f": 0.1818181818181818, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man standing on a beach holding a surfboard. The man is wearing a black shirt and shorts, and has a surfboard on his shoulder. The beach is sandy and there are palm trees in the background. The sky is cloudy and there are waves in the"}, "460346": {"image_id": 460346, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.17496355305240635, "Bleu_3": 8.607650943307257e-07, "Bleu_4": 1.9192830192327385e-09, "METEOR": 0.20983915316330637, "ROUGE_L": 0.23797139141742527, "CIDEr": 1.1610527244095082e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a young boy in a black shirt and black pants standing on top of a skateboard ramp, with his arms outstretched and his hands in the air. The sun is setting in the background, casting a warm orange glow over the scene. The boy is wearing a"}, "246263": {"image_id": 246263, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.13733380275681295, "Bleu_4": 0.08759310373578474, "METEOR": 0.23536536050298526, "ROUGE_L": 0.30367143746110764, "CIDEr": 1.0987263556220431e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are white and the floor is made of tile. There is a window on the left side of the room with blinds. The room is well lit and has a mirror on the wall."}, "402588": {"image_id": 402588, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2662233302496238, "Bleu_3": 0.19051219731381036, "Bleu_4": 0.13635924584802278, "METEOR": 0.31001204989491943, "ROUGE_L": 0.37770897832817335, "CIDEr": 2.5348010228303246e-05, "SPICE": {"All": {"pr": 0.0625, "re": 0.07142857142857142, "f": 0.06666666666666667, "fn": 26.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man in a black suit and tie walking down a street with other people in the background. The man is holding a briefcase in one hand and gesturing with the other. There are cars and buildings in the background."}, "470779": {"image_id": 470779, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.12166026344082319, "Bleu_4": 0.09306979428413018, "METEOR": 0.20112406821992654, "ROUGE_L": 0.33485818847209514, "CIDEr": 6.604135545613827e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15789473684210525, "f": 0.16216216216216214, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a snowy slope at night. They are all wearing ski gear and holding their skis. The woman in the center is wearing a black jacket and black pants, while the man on the left is wearing a blue jacket and black pants"}, "306281": {"image_id": 306281, "Bleu_1": 0.14999999999625002, "Bleu_2": 0.0877058019284822, "Bleu_3": 0.05871616519579067, "Bleu_4": 8.600383785666737e-06, "METEOR": 0.12404347555440165, "ROUGE_L": 0.2184813753581662, "CIDEr": 9.542794026869291e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23809523809523808, "f": 0.19607843137254902, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a bowl filled with broccoli, mushrooms, and soy sauce. The broccoli is cut into small pieces and the mushrooms are sliced thinly. The soy sauce is poured over the top of the vegetables and the bowl is stirred"}, "307790": {"image_id": 307790, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.10735372697093548, "Bleu_3": 6.304134548019102e-07, "Bleu_4": 1.5360875768147853e-09, "METEOR": 0.17962002207969024, "ROUGE_L": 0.20497311827956988, "CIDEr": 5.717812360074618e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.1935483870967742, "f": 0.21818181818181817, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a brown chicken standing on the ground in a jungle environment. The chicken has a distinctive black and white pattern on its feathers and is looking around with its head tilted to the side. The background is a dense jungle with tall trees and vines."}, "353231": {"image_id": 353231, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.16116459280217196, "Bleu_3": 0.11300272640516913, "Bleu_4": 0.07223500778671167, "METEOR": 0.1400644163445873, "ROUGE_L": 0.21229698375870068, "CIDEr": 5.950800090034703e-13, "SPICE": {"All": {"pr": 0.12, "re": 0.15, "f": 0.1333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a body of water with a large ship in the middle of it. There are buildings on the shore and a bridge in the background. The sky is clear and blue.\n\nThe image is taken from a high vantage point, looking down on the water and the boats in it. The water is"}, "199688": {"image_id": 199688, "Bleu_1": 0.3399999999932, "Bleu_2": 0.23560603574482045, "Bleu_3": 0.15138550030045467, "Bleu_4": 1.6483094398882965e-05, "METEOR": 0.24506509579226704, "ROUGE_L": 0.3205170975813178, "CIDEr": 7.085949488832256e-09, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.17391304347826086, "f": 0.14814814814814814, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a living room with a couch, coffee table, and chairs. There is a large window on the wall with a view of the ocean. The room is well lit and has a nice view.\n\nThe image shows a living room with a couch, coffee table, and chairs."}, "13992": {"image_id": 13992, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.12483755678422237, "Bleu_3": 6.608439529502603e-07, "Bleu_4": 1.5275844289614858e-09, "METEOR": 0.16944024205748864, "ROUGE_L": 0.20795454545454545, "CIDEr": 1.5439841910901241e-13, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.13157894736842105, "f": 0.15151515151515152, "fn": 33.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.38461538461538464, "f": 0.3703703703703704, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a sign with arrows pointing in different directions. The sign is made of metal and has a blue background with white letters. There are two people walking on the sidewalk in front of the sign. One is holding a child's hand and the other is pushing a stroller. The sky is clear"}, "567315": {"image_id": 567315, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.12186787521464361, "Bleu_4": 1.3863341114193003e-05, "METEOR": 0.2435520540373239, "ROUGE_L": 0.22536945812807885, "CIDEr": 3.2835353861723034e-11, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1875, "f": 0.13636363636363635, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a train traveling along a railroad track in the countryside. The train is a red and yellow tanker car with a black and white striped tank on the side. The train is traveling through a green and lush landscape with trees and fields on either side of the track."}, "437351": {"image_id": 437351, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1188177051548479, "Bleu_3": 6.604735246466958e-07, "Bleu_4": 1.5652411276385143e-09, "METEOR": 0.22162172177536554, "ROUGE_L": 0.19513755598208574, "CIDEr": 6.032231748520974e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1935483870967742, "f": 0.20338983050847456, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a woman sitting on the floor next to a pile of suitcases. She is wearing a red hat and a black dress. The suitcases are green and have the words \"vintage\" written on them. The woman is holding a black purse in her hand. The background is a"}, "531602": {"image_id": 531602, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.12909944487067912, "Bleu_3": 0.07291106321801014, "Bleu_4": 9.801278978426892e-06, "METEOR": 0.1915310391289239, "ROUGE_L": 0.25258799171842644, "CIDEr": 1.3974211814116401e-08, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.06896551724137931, "f": 0.0784313725490196, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a young boy holding a toothbrush in his mouth. He is wearing a yellow shirt and blue pants. The background is a bathroom with a sink, toilet, and shower. The boy is smiling and looking directly at the camera.\n\nThe image is"}, "430546": {"image_id": 430546, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 8.062577022864874e-07, "Bleu_4": 1.7904527454477097e-09, "METEOR": 0.20761194138831127, "ROUGE_L": 0.21863799283154117, "CIDEr": 2.437389082289426e-12, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.21739130434782608, "f": 0.19607843137254902, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person riding a motorcycle on a road. The person is wearing a helmet and is leaning forward on the bike. The road is straight and there are no other vehicles on it. The sky is blue and there are trees on either side of the road. The person is going"}, "309366": {"image_id": 309366, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.10050378152407698, "Bleu_3": 5.754792186290893e-07, "Bleu_4": 1.3836345500640894e-09, "METEOR": 0.1531395737371261, "ROUGE_L": 0.17579250720461098, "CIDEr": 1.1938594260343466e-13, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two yellow and white trains traveling on a train track. The trains are traveling in opposite directions and are not touching each other. There are no people or other objects in the image. The train tracks are made of steel and are covered in gravel. The image is taken from a bird'"}, "560111": {"image_id": 560111, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.19867985355623988, "Bleu_3": 0.1421242943487546, "Bleu_4": 0.1015454106026332, "METEOR": 0.26843387188164264, "ROUGE_L": 0.2697622996130459, "CIDEr": 1.3560889880566518e-13, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a red and yellow train on the tracks. The train has a number on the side and is pulling into a station. There are people standing on the platform and watching the train. The sky is clear and there are no clouds in the sky.\n\nThe train is a red and yellow passenger train."}, "152946": {"image_id": 152946, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 7.387419460030929e-07, "Bleu_4": 1.6767836295274806e-09, "METEOR": 0.1576467531426817, "ROUGE_L": 0.1783625730994152, "CIDEr": 8.12435725481685e-13, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.35714285714285715, "f": 0.27027027027027023, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a ski resort. They are all wearing ski gear and some of them are holding skis. The resort has a lot of snow and trees in the background.\n\nThe people in the image are all wearing ski gear and some of them are"}, "364016": {"image_id": 364016, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.21128856367777224, "Bleu_3": 0.1786220727645711, "Bleu_4": 0.15776272047747994, "METEOR": 0.2795802864278719, "ROUGE_L": 0.3386798272671191, "CIDEr": 2.286543534480741e-08, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.22727272727272727, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting around a table, looking at their laptops. They are all wearing black shirts and black pants, and one person is wearing a black hat. The table has a white tablecloth on it, and there are several cups of coffee on the"}, "449603": {"image_id": 449603, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.10412270358781489, "Bleu_4": 1.2197379410072965e-05, "METEOR": 0.21997042998313893, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.5004349917667666e-12, "SPICE": {"All": {"pr": 0.35, "re": 0.21875, "f": 0.2692307692307692, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.058823529411764705, "f": 0.08695652173913045, "fn": 16.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is holding onto the rope and jumping off the wave. The wave is large and has a lot of white foam on top. The sky is blue and there are clouds in the background. The person is wearing a w"}, "350289": {"image_id": 350289, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.12674769789184412, "Bleu_4": 0.08028899837277662, "METEOR": 0.18225869457131655, "ROUGE_L": 0.28175519630484985, "CIDEr": 1.0437937495336862e-07, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.13793103448275862, "f": 0.13559322033898305, "fn": 25.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two people standing on the beach, one holding a surfboard and the other holding a surfboard. The sun is setting in the background, casting a warm glow over the scene. The water is calm and clear, with small waves breaking on the shore. The sand is wet and sandy"}, "460621": {"image_id": 460621, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.1426954482435772, "Bleu_3": 0.10690314865377899, "Bleu_4": 0.07066328980326636, "METEOR": 0.20575097921210087, "ROUGE_L": 0.2610024449877751, "CIDEr": 9.04199366563166e-12, "SPICE": {"All": {"pr": 0.05, "re": 0.04, "f": 0.044444444444444446, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a bathroom with a toilet and a sink. The walls are made of blue tiles and there is a window in the background. The floor is made of white tiles and there is a white toilet seat. The sink is made of white porcelain and there is a f"}, "473199": {"image_id": 473199, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.17902871850638163, "Bleu_3": 8.622339795942076e-07, "Bleu_4": 1.901821839939215e-09, "METEOR": 0.20735437142336616, "ROUGE_L": 0.22536945812807885, "CIDEr": 2.869313906300589e-11, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15789473684210525, "f": 0.15789473684210525, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a sidewalk in front of a building with yellow umbrellas. There are several potted plants on the sidewalk and a large red sign with white letters that reads, \"Welcome to the city.\" The building has a large red awning over the entrance and"}, "322944": {"image_id": 322944, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.1162824824679724, "Bleu_4": 0.0745149092814863, "METEOR": 0.23027950146957957, "ROUGE_L": 0.31841909023117076, "CIDEr": 1.4722033361982667e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1111111111111111, "f": 0.10256410256410256, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The woman is holding a stuffed animal in her arms. She is wearing a black dress and has a bruise on her face. The background is dark and there is a light source coming from the left side of the image.\n\nThe woman is holding a stuffed animal in her arms. She is we"}, "110027": {"image_id": 110027, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.25184310024886714, "Bleu_3": 0.2084750202271059, "Bleu_4": 0.1604629854105837, "METEOR": 0.32591441862014175, "ROUGE_L": 0.29985955056179775, "CIDEr": 5.3917074745061744e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a garage with a table and chairs in it. There is a refrigerator in the corner and a window on the side. The walls are painted white and the floor is made of concrete. There are no other objects in the room."}, "74492": {"image_id": 74492, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.18871982178961313, "Bleu_3": 0.15817245013940903, "Bleu_4": 0.13772093427771898, "METEOR": 0.30319677510333715, "ROUGE_L": 0.27180140038192235, "CIDEr": 1.2476653881982849e-07, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.4, "f": 0.27906976744186046, "fn": 9.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a person holding a remote control in their hand. The remote control has a button on it that is being pressed. The person is wearing a black shirt and pants, and their hands are visible in the image. The background is a wooden floor."}, "280211": {"image_id": 280211, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1182211503531082, "Bleu_3": 6.453505325095797e-07, "Bleu_4": 1.5151450472612192e-09, "METEOR": 0.16344262902411522, "ROUGE_L": 0.14896214896214896, "CIDEr": 9.131228475516678e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13043478260869565, "f": 0.11764705882352941, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a train station with a fence surrounding it. The train station has a large sign on the front that reads \"train station\". There are several cars parked in front of the station, and a person is standing on the platform looking at the train. The sky is clear and blue.\n\nThe"}, "41247": {"image_id": 41247, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.20207803685797895, "ROUGE_L": 0.27326688318960685, "CIDEr": 8.723413757711217e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.17391304347826086, "f": 0.15094339622641512, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people surfing in the ocean. They are standing on the beach and the waves are crashing against the shore. The sky is clear and blue, with a few clouds scattered across it. The sun is shining down on the scene, casting a warm glow over everything. The"}, "419379": {"image_id": 419379, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 0.06474337870309639, "Bleu_4": 8.764094705114603e-06, "METEOR": 0.13625920075075668, "ROUGE_L": 0.16126900198281557, "CIDEr": 3.305814971549792e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.21739130434782608, "f": 0.19607843137254902, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.7142857142857143, "f": 0.4761904761904762, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a tray of donuts on a counter in a bakery. The donuts are arranged on the tray in a row, with each one having a different topping. The tray is made of metal and has a clear plastic cover on top. The bakery is well lit"}, "581731": {"image_id": 581731, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.08451542547132876, "Bleu_3": 5.095178478788676e-07, "Bleu_4": 1.2568995875390724e-09, "METEOR": 0.13370052775699703, "ROUGE_L": 0.1698218262806236, "CIDEr": 8.333207503767503e-14, "SPICE": {"All": {"pr": 0.125, "re": 0.10344827586206896, "f": 0.11320754716981132, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This image shows a path through a forest with tall trees on either side. The path is lined with small trees and there are no other people or objects in the image. The sky is clear and blue.\n\nThe image shows a path through a forest with tall trees on either side. The path is lined"}, "103584": {"image_id": 103584, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.21320071635169824, "Bleu_3": 0.17264376558872668, "Bleu_4": 0.1491436749876658, "METEOR": 0.26452973649162775, "ROUGE_L": 0.31642651296829977, "CIDEr": 1.764217770166781e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a dog sitting on a bed in a room with a red wall and a white ceiling. The dog is looking up at the ceiling with its head tilted to the side. The dog's fur is golden and it has a collar with a tag on it. The bed is made"}, "350132": {"image_id": 350132, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1889822365007167, "Bleu_3": 0.13160986848342301, "Bleu_4": 0.08390288290062609, "METEOR": 0.24084184639781117, "ROUGE_L": 0.2945081472540736, "CIDEr": 2.181140068144535e-09, "SPICE": {"All": {"pr": 0.3125, "re": 0.25, "f": 0.2777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a person playing frisbee in a park. The person is wearing a red shirt and black pants, and is holding a frisbee in their hand. The background is a city skyline with tall buildings and trees. The image is taken from a bird's eye view"}, "210448": {"image_id": 210448, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.20701966779852365, "Bleu_3": 0.12132137515765275, "Bleu_4": 0.07851064200963404, "METEOR": 0.24557751107985043, "ROUGE_L": 0.29647630619684084, "CIDEr": 2.861317231623115e-10, "SPICE": {"All": {"pr": 0.0625, "re": 0.07407407407407407, "f": 0.06779661016949153, "fn": 25.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.15384615384615385, "f": 0.14814814814814817, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a group of zebras standing in a fenced enclosure. They are all looking at each other and appear to be in good health. The fence is made of wood and has a gate that is open. There are trees and bushes in the background.\n\nThe zebras are"}, "267300": {"image_id": 267300, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.08206099398471602, "Bleu_3": 5.02727403256082e-07, "Bleu_4": 1.2502549517017175e-09, "METEOR": 0.15760739462641135, "ROUGE_L": 0.22724853645556145, "CIDEr": 1.0058286005246773e-10, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09523809523809523, "f": 0.1, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a dog sitting on a couch with a bowl of food in front of it. The dog is looking up at the camera with its tongue hanging out of its mouth. The background is a living room with a wooden floor and a window in the background.\n\nThe dog is a small,"}, "107939": {"image_id": 107939, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.14270041527824082, "Bleu_3": 0.09047027838968494, "Bleu_4": 1.0821339066753336e-05, "METEOR": 0.23432392085474193, "ROUGE_L": 0.26798462383305877, "CIDEr": 1.0319712690906902e-13, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.3181818181818182, "f": 0.2692307692307693, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image is a photograph of a street sign with the words \"stop\" written on it in white letters. The sign is mounted on a pole in the middle of the street, and there are trees and houses visible in the background. The sky is clear and blue, with some clouds visible in the distance. The image"}, "352760": {"image_id": 352760, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1360198059227937, "Bleu_3": 0.09368583412605459, "Bleu_4": 0.06574947308810801, "METEOR": 0.21895314975645513, "ROUGE_L": 0.2598904443091905, "CIDEr": 2.5817734317168868e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14814814814814814, "f": 0.16666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person in a yellow jumpsuit and black ski goggles jumping off a cliff on a snowboard. The person is wearing a helmet and has a pair of skis on their feet. The sky is cloudy and there are some trees in the background."}, "58210": {"image_id": 58210, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.31790537866317753, "Bleu_3": 0.20636338218010378, "Bleu_4": 0.11821466323977056, "METEOR": 0.26883183373049124, "ROUGE_L": 0.3202099737532808, "CIDEr": 9.465379165325308e-09, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2222222222222222, "f": 0.20689655172413793, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image is of a small bird standing on the grass. It has a white belly and a black and white striped back. The bird is looking down at the ground and has a small beak. The background is a green field with some trees in the distance."}, "529592": {"image_id": 529592, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.13390444632098428, "Bleu_4": 0.11067926155452719, "METEOR": 0.19303171038350772, "ROUGE_L": 0.21903052064631956, "CIDEr": 1.2591031570610688e-09, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows two men playing a game of dodgeball on a sandy beach. One man is wearing a yellow shirt and the other is wearing a black shirt. They are both holding dodgeballs and are in the process of throwing them at each other. There are several people watching the"}, "191112": {"image_id": 191112, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.18070977621815823, "Bleu_3": 0.12430963509343393, "Bleu_4": 0.07872924608075425, "METEOR": 0.24575808054830084, "ROUGE_L": 0.24469914040114613, "CIDEr": 5.120657513824144e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.2, "f": 0.1702127659574468, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a soccer goal. They are all wearing black and white jerseys and black pants. One person is holding a soccer ball and another is kicking it with their foot. The goal has a net on it and there are two people standing"}, "549338": {"image_id": 549338, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 0.1161912088962168, "Bleu_4": 0.07560832959746702, "METEOR": 0.2904836092863885, "ROUGE_L": 0.29204069419509276, "CIDEr": 1.4555089407377685e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a herd of horses grazing in a green pasture. The horses are brown and white and have long manes and tails. The fence is white and there are trees in the background.\n\nThe image is taken from a distance and the horses are in the foreground. The sky"}, "369849": {"image_id": 369849, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 0.07178791139239354, "Bleu_4": 9.274617069102212e-06, "METEOR": 0.17013959462907186, "ROUGE_L": 0.1763005780346821, "CIDEr": 3.4061353029267074e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.05128205128205128, "f": 0.06666666666666667, "fn": 37.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.14285714285714285, "f": 0.16, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of horses grazing in a field next to a dirt road. The horses are brown and white, and they are standing in a line, looking at the camera. The sky is cloudy and there are trees in the background.\n\nThe image is taken from a distance, and the"}, "206271": {"image_id": 206271, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.10654502541910188, "Bleu_4": 0.0829879120277201, "METEOR": 0.15863383031577877, "ROUGE_L": 0.21403508771929822, "CIDEr": 3.915807803245114e-13, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.10344827586206896, "f": 0.11538461538461538, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image is of a bathroom with two sinks and a toilet. The walls are made of tile and the floor is made of concrete. There is a window on the left side of the image and a door on the right side. The image is in black and white.\n\nThe image is of"}, "442301": {"image_id": 442301, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.12281268769488378, "Bleu_3": 0.09672659665842727, "Bleu_4": 0.07795929613721145, "METEOR": 0.23298196386410897, "ROUGE_L": 0.22241127856101123, "CIDEr": 2.08633242316273e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a person holding a carrot in their hand. The carrot is shaped like a finger and has a small piece of cheese on top. The person is wearing a white shirt and has a small tattoo on their wrist. There is a cutting board on the table in front"}, "578788": {"image_id": 578788, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.08748177652616675, "Bleu_3": 0.0546066804601931, "Bleu_4": 7.713382612340196e-06, "METEOR": 0.160580718035343, "ROUGE_L": 0.2208811104405552, "CIDEr": 1.8592280746743566e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person riding a skateboard down a ramp made of metal. The person is wearing a black and white striped shirt, black pants, and black shoes. The ramp is made of metal and has a yellow line down the middle. There are two sets of st"}, "5352": {"image_id": 5352, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.08939035350783202, "Bleu_4": 1.1103081472064331e-05, "METEOR": 0.21140601242783105, "ROUGE_L": 0.2901307966706302, "CIDEr": 5.056990535356307e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a plate of pizza with cheese and pepperoni on top. There is a beer glass on the table next to the plate. The table is made of wood and has a white tablecloth. The background is a wooden floor with a brown stain.\n\nThe image shows a"}, "236023": {"image_id": 236023, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.21557133227646622, "Bleu_3": 0.1389205969615558, "Bleu_4": 0.0851495655846529, "METEOR": 0.18986350306806074, "ROUGE_L": 0.2582010582010582, "CIDEr": 1.0578592372978403e-10, "SPICE": {"All": {"pr": 0.05, "re": 0.037037037037037035, "f": 0.0425531914893617, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a group of people standing in a kitchen. They are all wearing green shirts and black pants. One person is holding a cup of coffee and another is holding a plate of food. There are several bottles of alcohol on the counter. The walls are painted white and there are several"}, "339943": {"image_id": 339943, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.19062587708942288, "Bleu_3": 0.12798543247670327, "Bleu_4": 0.08007148098644415, "METEOR": 0.23104110353783502, "ROUGE_L": 0.22344322344322343, "CIDEr": 1.8648654730568273e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a sink, toilet, and bathtub. The walls are painted white and the floor is made of wood. There is a window on the left side of the room and a door on the right side. The room is well lit and has a large mirror on the wall"}, "491755": {"image_id": 491755, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.11952367853238388, "Bleu_4": 0.09090870283563951, "METEOR": 0.2184966448610122, "ROUGE_L": 0.28355607205113303, "CIDEr": 2.715840652598573e-11, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.23333333333333334, "f": 0.27450980392156865, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a living room with a couch, coffee table, and television. The walls are painted white and there are windows on either side of the room. The floor is made of hardwood and there are no rugs. The ceiling is made of white plaster and there are no lights. The room"}, "375405": {"image_id": 375405, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.18504536999744126, "Bleu_3": 0.10961273969013748, "Bleu_4": 1.267661295444545e-05, "METEOR": 0.22072963028819584, "ROUGE_L": 0.25326215895610915, "CIDEr": 3.2142648565278364e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two white birds perched on a branch of a tree. The birds are facing each other and appear to be in a loving embrace. The background is a green and brown forest with trees and leaves. The lighting is soft and natural, with the sun shining through the branches. The overall"}, "253624": {"image_id": 253624, "Bleu_1": 0.31034482758085613, "Bleu_2": 0.2556085937009373, "Bleu_3": 0.16711199429906562, "Bleu_4": 0.09597653001603111, "METEOR": 0.23716278591864123, "ROUGE_L": 0.3371859296482412, "CIDEr": 2.1328521229465477e-12, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on top of a wooden chair with its paws on the back of the chair. The cat is looking up at the camera with its eyes closed. The chair is in a dining room with a table and chairs in the background. The walls are painted a light color and there are"}, "510122": {"image_id": 510122, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1371021242743437, "Bleu_3": 0.10083600805943947, "Bleu_4": 0.06601054117823103, "METEOR": 0.1729528799270249, "ROUGE_L": 0.2392156862745098, "CIDEr": 5.21317314189512e-14, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.30434782608695654, "f": 0.2692307692307692, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a group of people standing on a wooden platform in front of a large building. They are all looking up at something in the sky. There are several birds flying overhead. The sky is blue and there are some clouds in the distance. The people are all wearing casual clothing and some of them"}, "484225": {"image_id": 484225, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.06994057575388038, "Bleu_3": 4.5479779894921654e-07, "Bleu_4": 1.1653898241136168e-09, "METEOR": 0.16377952755905512, "ROUGE_L": 0.1821983273596177, "CIDEr": 3.296039982072766e-13, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16666666666666666, "f": 0.1702127659574468, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of yellow and black trains traveling down a snowy track. The trains are pulling into a station and the people on the platform are waving at them. There are buildings in the background and a few trees in the foreground. The sky is clear and blue.\n\nThe image is"}, "271772": {"image_id": 271772, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.20982172726164103, "Bleu_3": 0.13643933968476482, "Bleu_4": 0.08400635913890077, "METEOR": 0.24752057966074437, "ROUGE_L": 0.31443298969072164, "CIDEr": 2.9901234622270386e-12, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.35294117647058826, "f": 0.2608695652173913, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man holding a kite in his hand while standing on a beach with a clear blue sky in the background. The kite is made of lightweight materials and has a long tail that is attached to the man's hand. The man is wearing a white shirt and shorts, and"}, "264013": {"image_id": 264013, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.216777492377193, "Bleu_3": 0.15062898838048286, "Bleu_4": 0.10606948946501396, "METEOR": 0.282451077254059, "ROUGE_L": 0.3284868066774367, "CIDEr": 2.3693868086660915e-13, "SPICE": {"All": {"pr": 0.32, "re": 0.27586206896551724, "f": 0.29629629629629634, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The train is a blue and yellow passenger train with two engines and two cars. The train is parked on the tracks next to a building with a clock tower. There are people standing on the platform and looking at the train.\n\nThe train is a blue and yellow passenger train with two engines and two cars."}, "138644": {"image_id": 138644, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.10314212462370773, "Bleu_3": 6.138158588631339e-07, "Bleu_4": 1.505654929036229e-09, "METEOR": 0.19076777433571873, "ROUGE_L": 0.20497311827956988, "CIDEr": 4.957736990841533e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.23529411764705882, "f": 0.16326530612244897, "fn": 13.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a woman holding a banana in her mouth. She has long, straight brown hair and is wearing a black shirt and jeans. The background is a kitchen with a stove, refrigerator, and countertops. There is a window on the left side of the image and"}, "525208": {"image_id": 525208, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 6.923138992163507e-07, "Bleu_4": 1.6131630585021e-09, "METEOR": 0.15843217036299434, "ROUGE_L": 0.18780788177339902, "CIDEr": 2.217290564372672e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a busy intersection with cars driving through it at night. The streetlights are on and the buildings are lit up. There are no pedestrians or other vehicles in the image.\n\nThe image is taken from a high angle, looking down on the intersection. The cars are moving quickly and"}, "548713": {"image_id": 548713, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 0.06923138992163505, "Bleu_4": 9.071482520661878e-06, "METEOR": 0.25572044382081627, "ROUGE_L": 0.28175519630484985, "CIDEr": 8.383328749797244e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.20689655172413793, "f": 0.23529411764705882, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two horses pulling a carriage down the street. The carriage is white and has a red and blue striped canopy. There are people walking on the sidewalk and in the background, there are tall buildings with windows and balconies.\n\nThe image is taken from a bird's eye view"}, "552186": {"image_id": 552186, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.14982983544985165, "Bleu_3": 7.76220525547567e-07, "Bleu_4": 1.7760875805722272e-09, "METEOR": 0.2200482745059634, "ROUGE_L": 0.22938079719227877, "CIDEr": 7.24934059211164e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a man skateboarding on a concrete skate park. The man is wearing a black shirt and jeans, and has a backpack on his back. There are several other people in the background, including a group of children playing on the playground. The sky is blue and there"}, "245513": {"image_id": 245513, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.19342948582067712, "Bleu_3": 0.16840936916301474, "Bleu_4": 0.14275792496153916, "METEOR": 0.2710583351217476, "ROUGE_L": 0.31504196255648803, "CIDEr": 1.8665927154721614e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing in a grassy area with trees in the background. The giraffe is wearing a halter and has a long neck. There are several birds flying in the sky. The image is taken from a bird's eye view.\n\nThe image shows a gira"}, "156999": {"image_id": 156999, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1188177051548479, "Bleu_3": 0.06604735246466957, "Bleu_4": 8.801997699586786e-06, "METEOR": 0.16578455285980265, "ROUGE_L": 0.18654434250764526, "CIDEr": 2.4437632094775163e-10, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}}, "caption": "The giraffe is standing on the ground, looking at something in its mouth. It has a long neck and legs, and its fur is brown and white. The giraffe is standing in front of a wooden fence, and there are trees in the background. The giraffe is looking at something in"}, "406211": {"image_id": 406211, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.19867985355623988, "Bleu_3": 0.12912849100142923, "Bleu_4": 0.07946357815569587, "METEOR": 0.2464541718928473, "ROUGE_L": 0.3353323338330835, "CIDEr": 1.4759389052995073e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on top of a blue cushion in front of a television. The cat is looking directly at the camera with its eyes wide open. The television is playing a movie with a blue and white screen. There is a couch in the background with a blue and white blanket on it"}, "403065": {"image_id": 403065, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 7.733118331435389e-07, "Bleu_4": 1.7439076818628815e-09, "METEOR": 0.14162841106803803, "ROUGE_L": 0.21356050881082975, "CIDEr": 9.832626578632184e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2777777777777778, "f": 0.2272727272727273, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a beach with a sandy shoreline and a few people walking on the sand. There is a small dune in the background, and a few palm trees are visible in the distance. The sky is overcast, with a few clouds visible in the distance. The image is in black and"}, "142697": {"image_id": 142697, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.23782574707262866, "Bleu_3": 0.1312781889814525, "Bleu_4": 1.4658698509421773e-05, "METEOR": 0.22670873276381417, "ROUGE_L": 0.22241127856101123, "CIDEr": 1.2134887052796845e-09, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13636363636363635, "f": 0.11764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This image shows a surfer riding a wave on a surfboard. The surfer is jumping off the wave and performing a trick in the air. The sky is blue and there are clouds in the background. The ocean is rough and there are waves crashing on the shore. The surfer is we"}, "546424": {"image_id": 546424, "Bleu_1": 0.45833333332378473, "Bleu_2": 0.3275202337895816, "Bleu_3": 0.2105035754209138, "Bleu_4": 0.14269178738293792, "METEOR": 0.2519232350538432, "ROUGE_L": 0.3028368794326241, "CIDEr": 1.1611994472461476e-07, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2, "f": 0.22727272727272727, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bride and groom walking down the aisle at a wedding. They are both wearing formal attire, with the bride in a white dress and the groom in a black tuxedo. They are holding hands and smiling at each other. The image is in black"}, "219798": {"image_id": 219798, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.1942571724677524, "Bleu_3": 0.13044729210752723, "Bleu_4": 0.081626993367812, "METEOR": 0.24290410074005542, "ROUGE_L": 0.25341246290801184, "CIDEr": 1.9418975031806192e-11, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3333333333333333, "f": 0.3255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a dog wearing a rainbow colored collar and leash walking on the sidewalk. The dog is a small white dog with a black nose and brown eyes. The collar is made of a rainbow colored material and has a chain attached to it. The leash is also made of the"}, "198223": {"image_id": 198223, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 0.07178791139239354, "Bleu_4": 9.274617069102212e-06, "METEOR": 0.18367911479944676, "ROUGE_L": 0.18496058217101274, "CIDEr": 8.521658830799078e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19230769230769232, "f": 0.17857142857142855, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a family of three standing on the beach. The father is holding a surfboard and the mother is holding a baby. The baby is standing on the sand and looking at the water. The father is wearing a black shirt and the mother is wearing a pink shirt. The baby"}, "288799": {"image_id": 288799, "Bleu_1": 0.1403508771905202, "Bleu_2": 0.07079923253922572, "Bleu_3": 4.5001964233160024e-07, "Bleu_4": 1.1397908406297794e-09, "METEOR": 0.1903658826019858, "ROUGE_L": 0.17438536306460833, "CIDEr": 4.789313799006564e-15, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.07692307692307693, "f": 0.0930232558139535, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a train on the tracks in front of a building with a red roof. The building has a large sign on the front that reads \"Hotel\". There are trees and bushes on either side of the tracks. The train is red and has a number on the side. There are people standing on the"}, "492366": {"image_id": 492366, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.20218927553934637, "Bleu_3": 0.15781960945622633, "Bleu_4": 0.13250832891618528, "METEOR": 0.261771263680129, "ROUGE_L": 0.2684268426842684, "CIDEr": 2.8975581956103214e-11, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man standing next to a horse and cart on the sidewalk. The man is wearing a hat and carrying a bag on his shoulder. The horse is wearing a harness and pulling the cart. The cart has a sign on the back that reads \"Hotel\". The buildings in the background"}, "313240": {"image_id": 313240, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 8.556026937263809e-07, "Bleu_4": 1.931527870007565e-09, "METEOR": 0.19322450951445522, "ROUGE_L": 0.2675438596491228, "CIDEr": 2.2756362829390526e-08, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.2692307692307692, "f": 0.2545454545454545, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a cluttered room with a desk, chair, and bookshelves. There are several books and papers on the desk and shelves. The room has a window with blinds and a door. The floor is covered with a rug and there are several plants in the room."}, "103705": {"image_id": 103705, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.18725633517633355, "Bleu_3": 0.12489168105266545, "Bleu_4": 0.07786300597635273, "METEOR": 0.1596269655017299, "ROUGE_L": 0.257867543447628, "CIDEr": 7.632386045967025e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows two beds in a room with a window that looks out onto a mountain range. The beds are covered in white sheets and there are pillows on them. The walls are painted a light blue color and there are curtains on the windows. The floor is made of wood and there are two"}, "148588": {"image_id": 148588, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.195019344635654, "ROUGE_L": 0.22426470588235295, "CIDEr": 5.467049633587565e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.09375, "f": 0.09999999999999999, "fn": 29.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a pizza oven with a pizza in it. The pizza is made with tomato sauce, cheese, and various toppings. The oven is made of brick and has a chimney on top. The room is dimly lit and has a wooden table in front of the"}, "240739": {"image_id": 240739, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.14979742339481708, "Bleu_4": 0.12039217537167975, "METEOR": 0.2578053682893071, "ROUGE_L": 0.3285457809694794, "CIDEr": 2.0517570628534073e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1875, "f": 0.19999999999999998, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and black pants, and has a tennis racket in his hand. The court is made of green grass and has a net in the center. There are several people watching the game from the sidelines."}, "213224": {"image_id": 213224, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.2201927530212316, "Bleu_3": 0.15409790041514113, "Bleu_4": 0.09158971449059618, "METEOR": 0.2757493303823831, "ROUGE_L": 0.24956165984804207, "CIDEr": 4.3702694020733424e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13793103448275862, "f": 0.1509433962264151, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a table with two vases of flowers on it. The flowers are colorful and look like they are arranged in a vase. There is a wooden floor and a wooden table with two chairs. The room has a wooden ceiling and a wooden floor. There is a window on the wall with"}, "440895": {"image_id": 440895, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.08206099398471602, "Bleu_3": 0.05027274032560819, "Bleu_4": 7.030700263657399e-06, "METEOR": 0.19282516777168696, "ROUGE_L": 0.21542083578575633, "CIDEr": 4.484959785495569e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.14285714285714285, "f": 0.12244897959183672, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a brick building with a red awning over the front door. There are two windows on either side of the door, and a window on the top floor. The building is surrounded by other buildings, and there are people walking on the sidewalk in front of it.\n\nThe image is taken from"}, "142934": {"image_id": 142934, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.11175167395708337, "Bleu_3": 6.522766823207914e-07, "Bleu_4": 1.584749856288676e-09, "METEOR": 0.15135580044711394, "ROUGE_L": 0.20847573479152426, "CIDEr": 8.101304999395341e-09, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a snowy mountain slope, with a snowboarder in the foreground and a snowboard in the background. The sky is clear and blue, with mountains in the distance.\n\nThe people in the image are wearing snowboarding gear, including helm"}, "164983": {"image_id": 164983, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.20604084591910862, "Bleu_3": 0.14932487317800128, "Bleu_4": 0.1074271647268228, "METEOR": 0.20849530487730794, "ROUGE_L": 0.27774615822424586, "CIDEr": 4.831198236142813e-10, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2777777777777778, "f": 0.21739130434782608, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a black and white dog lying on a bed next to a woman who is petting it. The woman is wearing a white shirt and black pants, and the dog is wearing a red collar. The room appears to be a bedroom, with a window in the background and a"}, "316672": {"image_id": 316672, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.18463723646567207, "Bleu_3": 8.578570819845488e-07, "Bleu_4": 1.8577712526620135e-09, "METEOR": 0.20058168596854206, "ROUGE_L": 0.23775055679287305, "CIDEr": 3.193650360532239e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.14285714285714285, "f": 0.1694915254237288, "fn": 30.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a red and yellow train traveling along a track through a park. The train has a large engine on the front and a small car on the back. There are trees and grass on either side of the track and a fence in the background. The sky is clear and blue.\n\nThe train"}, "386012": {"image_id": 386012, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.1184508853673932, "Bleu_3": 6.683330244266766e-07, "Bleu_4": 1.5960821227040779e-09, "METEOR": 0.1540039510455779, "ROUGE_L": 0.18815545959284388, "CIDEr": 1.393008001374338e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people on a beach, with kites flying in the sky. The people are wearing swimsuits and sunglasses, and some of them are holding boards. The beach is sandy and has some rocks and trees. The sky is blue and there are some clouds"}, "283290": {"image_id": 283290, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.11895773785545558, "Bleu_3": 6.522364605376366e-07, "Bleu_4": 1.5348336186916813e-09, "METEOR": 0.19678247612895866, "ROUGE_L": 0.21721068249258166, "CIDEr": 1.949462512502773e-12, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.17391304347826086, "f": 0.14814814814814814, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people on jet skis in the water. They are wearing life jackets and helmets, and one person is jumping off the back of another jet ski. There are several boats in the background, and a large building with a clock tower in the distance. The sky is"}, "527038": {"image_id": 527038, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.1351686025680867, "Bleu_4": 0.10179463955434002, "METEOR": 0.24829738374536092, "ROUGE_L": 0.27566171723692706, "CIDEr": 4.668449292494816e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2631578947368421, "f": 0.24390243902439024, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person holding an umbrella in the middle of a snowy street. The person is wearing a black coat and hat, and the umbrella is open. There are tall buildings in the background, and the street is lined with cars and pedestrians. The sky is gray"}, "209544": {"image_id": 209544, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.16870903059432618, "Bleu_4": 1.778457282414307e-05, "METEOR": 0.2493413813106001, "ROUGE_L": 0.3216168717047452, "CIDEr": 2.6420500788367085e-06, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.15, "f": 0.11764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man standing in a field with a frisbee in his hand. He is wearing a black shirt and jeans, and has a backpack on his back. There are several tents set up in the background, and a mountain range can be seen in the distance. The sky"}, "442223": {"image_id": 442223, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.15891043153801604, "Bleu_3": 0.07810454645155356, "Bleu_4": 9.783773730343155e-06, "METEOR": 0.16859379903936947, "ROUGE_L": 0.27006087437742116, "CIDEr": 1.11980672158338e-12, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}}, "caption": "The image shows a white building with a red roof and a bell tower on top. There is a cow standing in front of the building, and people are walking by on the sidewalk. The sky is blue and there are palm trees in the background.\n\nThe building appears to be a church or temple,"}, "301684": {"image_id": 301684, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.06593804733812939, "Bleu_3": 4.6231696364506e-07, "Bleu_4": 1.2312259432484024e-09, "METEOR": 0.13692551505546752, "ROUGE_L": 0.16968011126564672, "CIDEr": 5.405246812141827e-09, "SPICE": {"All": {"pr": 0.0625, "re": 0.1, "f": 0.07692307692307693, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a young elephant standing on its hind legs, with its trunk curled around the neck of a woman in a white shirt and black pants. The woman is holding the elephant's trunk and smiling. The elephant is wearing a red and white"}, "523529": {"image_id": 523529, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.1169829962474529, "Bleu_4": 1.3246197301306972e-05, "METEOR": 0.23256410226319613, "ROUGE_L": 0.28126801152737757, "CIDEr": 2.0082396190152464e-13, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a brown bear standing on a rock in a zoo. The bear is looking up at the sky and appears to be enjoying the sun. The bear's fur is shaggy and its eyes are brown. The background is a rocky terrain with some trees in the distance. The image is taken"}, "140289": {"image_id": 140289, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.0986616396109014, "Bleu_4": 0.06688071957169267, "METEOR": 0.1623417422072543, "ROUGE_L": 0.22584228063680117, "CIDEr": 1.3955632067038038e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.16, "f": 0.17777777777777778, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two brown bears standing on a dirt path in front of a rocky cliff. The bears are looking at each other and appear to be in a playful mood. The background is a rocky cliff with trees growing on it. The sky is cloudy and there are some"}, "71933": {"image_id": 71933, "Bleu_1": 0.3199999999936, "Bleu_2": 0.19794866371815806, "Bleu_3": 0.11775100856355505, "Bleu_4": 1.3652085900555668e-05, "METEOR": 0.2039887000506682, "ROUGE_L": 0.32379828959009144, "CIDEr": 2.6203761268411884e-08, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.17647058823529413, "f": 0.2105263157894737, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a hot dog in a bun with yellow mustard and ketchup on the side. The bun is made of white bread and has a red and white striped pattern on it. The hot dog is topped with yellow mustard and ketchup. The mustard is in a small"}, "115412": {"image_id": 115412, "Bleu_1": 0.12499999999739586, "Bleu_2": 0.08932370012443137, "Bleu_3": 5.576887186735733e-07, "Bleu_4": 1.4011697930921417e-09, "METEOR": 0.09959066152155235, "ROUGE_L": 0.15641025641025638, "CIDEr": 2.887588768313912e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.3125, "f": 0.2631578947368421, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image is a small, yellow, and white candle with a small, white, and yellow flower on top of it. The candle is sitting on a white surface.\n\nThe image is a small, yellow, and white candle with a small, white, and yellow flower on top of it."}, "71549": {"image_id": 71549, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.20935894733588342, "Bleu_3": 0.16950408960775368, "Bleu_4": 0.11643235108895965, "METEOR": 0.27559695765778564, "ROUGE_L": 0.2830626450116009, "CIDEr": 1.5668044096735166e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a brown teddy bear sitting on the floor next to a Christmas tree. The tree has presents wrapped in red and green paper, and a small stuffed animal is sitting on top of it. The floor is covered in a red and green carpet. The walls are painted a light blue color. There"}, "297022": {"image_id": 297022, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.18476851073338801, "Bleu_3": 0.0982466623305646, "Bleu_4": 1.2829843028855697e-05, "METEOR": 0.1203715611227308, "ROUGE_L": 0.23940345368916802, "CIDEr": 9.613750795083622e-05, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.18518518518518517, "f": 0.18518518518518517, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a group of people standing in a field, looking at something on the ground. They are all wearing hats and carrying tools. The background is a green field with trees in the distance."}, "272694": {"image_id": 272694, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.25112360116008, "Bleu_3": 0.1754995836599104, "Bleu_4": 0.11228903217058282, "METEOR": 0.21827455363727852, "ROUGE_L": 0.380351946792296, "CIDEr": 0.0003868808310566244, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a banana and a cup of coffee on a table. The banana is peeled and the coffee is in a cup with a lid on it. There is also a napkin on the table."}, "469067": {"image_id": 469067, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.10339796947386827, "Bleu_4": 0.06964012518749992, "METEOR": 0.1997082328632461, "ROUGE_L": 0.2357639783560938, "CIDEr": 2.1145259292186123e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1875, "f": 0.19999999999999998, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a woman lying in bed with a cat on her lap. The woman is wearing a white shirt and blue pajamas. The cat is black and white and is lying on the woman's lap. The room is dimly lit and there are curtains on the windows."}, "269311": {"image_id": 269311, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.16094080478419465, "Bleu_3": 0.08318402702711739, "Bleu_4": 1.0694655186909581e-05, "METEOR": 0.23092450464443837, "ROUGE_L": 0.2543180464562239, "CIDEr": 5.4812557472703674e-08, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.07692307692307693, "f": 0.08, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows three men standing in front of a house. They are wearing blue shirts and jeans and are holding baseball bats. The house has a white roof and a red door. There is a tree in the background.\n\nThe image is in black and white."}, "410724": {"image_id": 410724, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.10386373237947197, "Bleu_4": 0.06950845485916396, "METEOR": 0.17195210682788806, "ROUGE_L": 0.2858816637375513, "CIDEr": 1.2417540100363694e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.25, "f": 0.2580645161290323, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image is of a large, colorful cat statue sitting on a table in front of a window. The cat has a long, curly tail and is wearing a collar with a tag on it. The statue is made of metal and has a shiny, metallic finish. The table is made"}, "102056": {"image_id": 102056, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.2277316449803929, "Bleu_3": 0.15010784719911877, "Bleu_4": 0.11072786288043487, "METEOR": 0.23266368249270988, "ROUGE_L": 0.31282051282051276, "CIDEr": 2.150566211576623e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.17647058823529413, "f": 0.13636363636363638, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a blue bus. The bus has a large window on the side and a door on the front. The people are wearing winter clothing and are standing in a snowy area. There are trees in the background."}, "449406": {"image_id": 449406, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.17039568890752202, "Bleu_3": 0.1051136375718304, "Bleu_4": 1.2407814132465894e-05, "METEOR": 0.245068599109775, "ROUGE_L": 0.25722891566265055, "CIDEr": 5.488869155253549e-12, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a zebra standing in a dry, rocky area with a few trees in the background. The zebra is white with black stripes and appears to be grazing on the plants in the area. There are no other animals or people in the image. The sky is clear and blue."}, "225786": {"image_id": 225786, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.16402518938356242, "Bleu_3": 0.12743613201512047, "Bleu_4": 0.09491489917644469, "METEOR": 0.23106137603270896, "ROUGE_L": 0.308080808080808, "CIDEr": 6.5151757020356584e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man standing on the beach, looking out at the ocean. There are rocks and sand in the foreground, and a small boat in the distance. The sky is blue and there are clouds in the background. The man is wearing a black jacket and pants, and has a red scar"}, "252280": {"image_id": 252280, "Bleu_1": 0.1874999999960938, "Bleu_2": 1.9973386548003496e-09, "Bleu_3": 4.42637829346614e-12, "Bleu_4": 2.0952375423843238e-13, "METEOR": 0.10802193433840525, "ROUGE_L": 0.154040404040404, "CIDEr": 2.1380498435341418e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08, "f": 0.08695652173913043, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a street with bicycles parked on the sidewalk. There are several trees and buildings in the background. The sky is clear and sunny.\n\nThe image shows a street with bicycles parked on the sidewalk. There are several trees and buildings in the background. The sky"}, "126046": {"image_id": 126046, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.15617376188474938, "Bleu_3": 0.08551661700652094, "Bleu_4": 1.1326402344943274e-05, "METEOR": 0.2791930484438715, "ROUGE_L": 0.22021660649819497, "CIDEr": 5.75345361080399e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a street with a traffic cone on the side of the road. There are also some buildings in the background. The sky is clear and there are no clouds. The lighting is good and the colors are vivid."}, "8188": {"image_id": 8188, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.1109559543256473, "Bleu_4": 1.2856432048790682e-05, "METEOR": 0.2506725692992767, "ROUGE_L": 0.226906385616863, "CIDEr": 3.3790100894342647e-12, "SPICE": {"All": {"pr": 0.28, "re": 0.28, "f": 0.28, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "This is a beach scene with people sitting on the sand and umbrellas on the sand. There are also some beach chairs and umbrellas on the sand. The water is calm and there are some boats in the distance. The sky is blue and there are some clouds in the sky. The beach"}, "53145": {"image_id": 53145, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.10555271104180952, "Bleu_4": 0.07110703768133433, "METEOR": 0.16186839554467694, "ROUGE_L": 0.22578655151141266, "CIDEr": 3.737768906048157e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.15, "f": 0.1333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people surfing on a river. They are wearing wetsuits and holding their surfboards. The water is calm and there are trees and buildings in the background.\n\nThe image is in black and white and has a grainy texture. The lighting is bright and"}, "574825": {"image_id": 574825, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.21798903029455755, "Bleu_3": 0.15404300269030785, "Bleu_4": 0.12109305928332115, "METEOR": 0.26635361033497557, "ROUGE_L": 0.20962199312714777, "CIDEr": 1.998310926222352e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a building. They are all wearing black clothing and have their hands in their pockets. One person is holding a sign that reads, \"Welcome to the city.\" Another person is holding a camera and taking pictures of the group. There are several people"}, "16064": {"image_id": 16064, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.14887283354071895, "Bleu_3": 0.09877211597249048, "Bleu_4": 1.2096859591117994e-05, "METEOR": 0.14028726401985903, "ROUGE_L": 0.1639784946236559, "CIDEr": 1.5659610795840376e-09, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.125, "f": 0.08888888888888889, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a group of people playing frisbee in a park. They are all wearing different colored shirts and pants, and some of them are holding frisbees. The grass is green and there are trees in the background.\n\nThe image shows a group of people playing fr"}, "503926": {"image_id": 503926, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.13608276348545723, "Bleu_3": 0.10158210507509738, "Bleu_4": 0.07968371423587568, "METEOR": 0.2151904800880217, "ROUGE_L": 0.24610951008645532, "CIDEr": 2.503653486919095e-13, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a room with a desk, chair, and bookshelf. There is a window on the left side of the room and a door on the right side. The floor is made of hardwood and there is a rug in the middle of the room. The walls are painted white and there are no"}, "30828": {"image_id": 30828, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.23329531792993197, "Bleu_3": 0.18569392958350128, "Bleu_4": 0.1400025972732928, "METEOR": 0.263088282008854, "ROUGE_L": 0.29501684083254165, "CIDEr": 4.669431237001919e-07, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.22727272727272727, "f": 0.18867924528301885, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a person sleeping on a bench in a park. The person is wearing a blanket and has their head resting on their hand. The bench is made of wood and has a metal frame. The park is well maintained and has trees and grass. The sky is clear and blue."}, "381792": {"image_id": 381792, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.12654285084562092, "Bleu_4": 1.4487343343293782e-05, "METEOR": 0.21801227958910283, "ROUGE_L": 0.3386798272671191, "CIDEr": 4.028723216742184e-10, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.25, "f": 0.1702127659574468, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of tile. There is a window on the left side of the room and a door on the right.\n\nThe bathroom is clean and well maintained. The toilet"}, "254571": {"image_id": 254571, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1940285000252239, "Bleu_3": 0.13209470492933909, "Bleu_4": 0.0832441546684946, "METEOR": 0.2432997365495195, "ROUGE_L": 0.29204069419509276, "CIDEr": 1.5083224536275665e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person riding a bicycle on a dirt road surrounded by trees and mountains in the background. The person is wearing a helmet and has a backpack on their back. The road is winding and there are rocks and pebbles on the ground. The sky is clear and"}, "14781": {"image_id": 14781, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 0.08411954328528157, "Bleu_4": 1.0608359163741716e-05, "METEOR": 0.20541870350396513, "ROUGE_L": 0.23797139141742527, "CIDEr": 1.9882546577483996e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.23809523809523808, "f": 0.20833333333333334, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is of a bathroom with a toilet and a sink. The walls are made of tiles and the floor is made of black and white tiles. There is a toilet seat and a toilet paper holder on the wall. The toilet is empty and there is no to"}, "320972": {"image_id": 320972, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.19062587708942288, "Bleu_3": 0.12798543247670327, "Bleu_4": 1.4238946596951668e-05, "METEOR": 0.24687591800268993, "ROUGE_L": 0.2853801169590643, "CIDEr": 1.0388992706243427e-12, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.21875, "f": 0.2413793103448276, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of oranges and bananas on a table. The oranges are yellow and the bananas are green. There are also some papers and a pen on the table.\n\nThe image is taken in a white room with a white table and white walls. There are no other objects in the"}, "145025": {"image_id": 145025, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.11262478804206155, "Bleu_4": 1.3203863485033786e-05, "METEOR": 0.231628087466778, "ROUGE_L": 0.26521739130434785, "CIDEr": 1.7985471519280878e-09, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.12903225806451613, "f": 0.13793103448275862, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man sitting on the sidewalk next to a bicycle. He is wearing black clothing and has his arms crossed over his chest. The ocean is visible in the background.\n\nThe image is taken from a low angle, looking down at the man from above. The lighting"}, "564816": {"image_id": 564816, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.15943400149410505, "Bleu_4": 0.09688270405692424, "METEOR": 0.23674347358550585, "ROUGE_L": 0.28222075346992725, "CIDEr": 6.416312315743464e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.21052631578947367, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a green tiled floor, a white sink, and a toilet. There is a mirror on the wall and a window with blinds. The room is well lit and has a wooden door.\n\nThe image shows a bathroom with a green tiled floor, a"}, "430533": {"image_id": 430533, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.19034674690253633, "Bleu_3": 0.13518230023748667, "Bleu_4": 0.10353334820449549, "METEOR": 0.217259396373914, "ROUGE_L": 0.3084702907711757, "CIDEr": 2.2576820265133465e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a hot dog and a slice of watermelon on a tray. The hot dog is topped with ketchup, mustard, and relish. The watermelon slice is cut into small pieces and has a slice of cheese on top. There is a small container of"}, "364557": {"image_id": 364557, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.09267924750141882, "Bleu_4": 0.06449817351321535, "METEOR": 0.2431683144987751, "ROUGE_L": 0.2576946288473144, "CIDEr": 4.665725861833249e-10, "SPICE": {"All": {"pr": 0.09375, "re": 0.13043478260869565, "f": 0.10909090909090909, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.23076923076923078, "f": 0.21428571428571427, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a couple walking on the beach at sunset. The man is wearing a black wetsuit and the woman is wearing a black bikini. They are holding surfboards and walking towards the ocean. The sky is orange and pink, with a few clouds visible in the distance."}, "354424": {"image_id": 354424, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.10861276726025744, "Bleu_3": 5.950104277147966e-07, "Bleu_4": 1.3989518286920131e-09, "METEOR": 0.1624135671864272, "ROUGE_L": 0.23131094257854823, "CIDEr": 7.900113419204241e-15, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.11764705882352941, "f": 0.0930232558139535, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image is a black and white photograph of a cat sitting on top of a wooden beam in a dark room. The cat is looking up at the ceiling with its eyes closed. The beam is made of wood and has a few nails in it. The room is dimly lit by a small light on the"}, "508489": {"image_id": 508489, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.17902871850532517, "Bleu_3": 0.11904119237541844, "Bleu_4": 0.08217174698206589, "METEOR": 0.2197594026680642, "ROUGE_L": 0.28416149068322977, "CIDEr": 2.3085327562878707e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.12, "f": 0.11538461538461538, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a variety of vegetables and fruits on display in a wooden crate. The vegetables include carrots, beets, and lettuce, while the fruits include apples, oranges, and grapes. The crate is on a wooden shelf in a market."}, "203063": {"image_id": 203063, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.2162249910430379, "Bleu_3": 0.1629781336014208, "Bleu_4": 0.12511470357171806, "METEOR": 0.26071703788508593, "ROUGE_L": 0.3367507886435331, "CIDEr": 7.378606297204767e-13, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.03125, "f": 0.04, "fn": 31.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a group of sheep grazing in a snowy field. The sheep are white with black spots and are standing in a line, looking up at the camera. The sky is cloudy and there are mountains in the background. The ground is covered in snow and there are no other animals or people in"}, "125129": {"image_id": 125129, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.14505284310643746, "Bleu_3": 0.09037934933366287, "Bleu_4": 0.060256638604217205, "METEOR": 0.2378196920974981, "ROUGE_L": 0.2010326266066132, "CIDEr": 1.5949019399685735e-15, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting at a table in a room. One person is writing on a piece of paper while another person is looking on. There are two other people standing behind the table, one of whom is holding a pen and the other is looking at something on their phone. The room is dimly"}, "197859": {"image_id": 197859, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.08111147935548949, "Bleu_4": 1.0064933408714859e-05, "METEOR": 0.2101568192682952, "ROUGE_L": 0.22008418520745643, "CIDEr": 3.4734388848108506e-13, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.045454545454545456, "f": 0.04444444444444444, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows two beds in a room with white walls and a ceiling. The beds are made of wood and have white sheets on them. There is a window on the left side of the room with a view of the outside. The room is well lit and has a carpet on the floor."}, "427094": {"image_id": 427094, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.19026059765810294, "Bleu_3": 0.11313211375448105, "Bleu_4": 1.311113853149677e-05, "METEOR": 0.2510683358621371, "ROUGE_L": 0.22048192771084338, "CIDEr": 7.70535331744078e-11, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.05555555555555555, "f": 0.04545454545454546, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image is of a building with green and white paint on the sides. There are two street signs on the corner of the building. The signs are white with black letters that say \"Fell\" and \"Street\". There are also some trees in the background.\n\nThe image is taken from a bird'"}, "118743": {"image_id": 118743, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.08571428571255398, "Bleu_3": 5.349194562189742e-07, "Bleu_4": 1.3433582021760984e-09, "METEOR": 0.14975648730432994, "ROUGE_L": 0.22333414693678305, "CIDEr": 2.4451291514564606e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a woman standing in front of a wooden table with an umbrella in her hand. She is wearing a black and white striped shirt and black pants. The table has a white tablecloth on it and there are several objects on it, including a vase, a book,"}, "472109": {"image_id": 472109, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.1878672873218244, "Bleu_3": 0.11293938405626279, "Bleu_4": 1.3162056532389086e-05, "METEOR": 0.24555118754175434, "ROUGE_L": 0.2858816637375513, "CIDEr": 1.9518052175906221e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.19230769230769232, "f": 0.19230769230769232, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The room is a small office with a desk, chair, and bookshelf. There is a computer on the desk and a printer on the bookshelf. The walls are painted white and there are no windows. The floor is made of hardwood and there is a rug in the corner. The room"}, "173545": {"image_id": 173545, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.08243669902025869, "Bleu_4": 1.0393938325822104e-05, "METEOR": 0.21855940671245727, "ROUGE_L": 0.314974182444062, "CIDEr": 3.9742790777965496e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.2857142857142857, "f": 0.22641509433962265, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows two elephants standing in a field with trees in the background. The elephants are wearing colorful umbrellas and are standing next to each other. The trees are tall and green, with branches reaching up towards the sky. The sky is blue and there are clouds in the background"}, "6527": {"image_id": 6527, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1978218215826409, "Bleu_3": 0.11460186406839476, "Bleu_4": 0.07370572412364096, "METEOR": 0.20461524301758055, "ROUGE_L": 0.21863799283154117, "CIDEr": 8.440430116693273e-13, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a streetlight on the side of a building. The streetlight is made of metal and has a clock face on it. The clock face is white with black numbers and hands. The streetlight is mounted on a pole and is lit up at night. There are other buildings in the background."}, "219164": {"image_id": 219164, "Bleu_1": 0.1481481481454047, "Bleu_2": 0.05287010571355467, "Bleu_3": 3.7740328088462614e-07, "Bleu_4": 1.0132385609889835e-09, "METEOR": 0.1665457164729712, "ROUGE_L": 0.17468499427262313, "CIDEr": 9.84203989050196e-13, "SPICE": {"All": {"pr": 0.12, "re": 0.15, "f": 0.1333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a blue and white dress and has a racket in her hand. There are trees and buildings in the background.\n\nThe image is taken from a bird's eye view, showing the woman in the center of the court, with the"}, "270222": {"image_id": 270222, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.10811249552151898, "Bleu_3": 6.00416577777256e-07, "Bleu_4": 1.4215774922802648e-09, "METEOR": 0.13632286995515694, "ROUGE_L": 0.1769141531322506, "CIDEr": 2.8961062987821226e-13, "SPICE": {"All": {"pr": 0.04, "re": 0.05, "f": 0.044444444444444446, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image is a clock tower with a large clock face on the front. The clock face has numbers and hands, and there are several other clocks on the sides of the tower. The tower is made of stone and has a steeple on top. There are several windows on the sides of the tower, and"}, "548843": {"image_id": 548843, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.15927956195690762, "Bleu_3": 8.453247893683395e-07, "Bleu_4": 1.959168274713403e-09, "METEOR": 0.196373779637378, "ROUGE_L": 0.23890339425587467, "CIDEr": 1.9328917723883265e-07, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.05, "f": 0.041666666666666664, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a young boy wearing a blue jacket and holding a plate of food. He is standing in front of a group of people who are all wearing glasses. The background is a busy street with cars and buildings in the distance."}, "146126": {"image_id": 146126, "Bleu_1": 0.3199999999936, "Bleu_2": 0.21380899352561972, "Bleu_3": 0.12395961884568825, "Bleu_4": 1.418847468492011e-05, "METEOR": 0.24244713941485194, "ROUGE_L": 0.26228501228501233, "CIDEr": 2.50237404617862e-07, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.11538461538461539, "f": 0.11538461538461539, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a table with a television on it, a remote control, and a bag of food. The food appears to be french fries and a drink. There is also a cup of coffee on the table. The background is a white wall with a window in the background."}, "398066": {"image_id": 398066, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.10167765666209894, "Bleu_3": 5.728348820235567e-07, "Bleu_4": 1.365914929670925e-09, "METEOR": 0.1612242018040177, "ROUGE_L": 0.13950829045168667, "CIDEr": 1.750394770729277e-14, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.15384615384615385, "f": 0.14035087719298245, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a baseball game being played on a field with a large tree in the background. The players are wearing baseball uniforms and are holding bats. The sky is clear and there are no clouds in the sky. The trees are green and there are no leaves on them. The grass is green and there"}, "429323": {"image_id": 429323, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.22479304902841, "Bleu_3": 0.13000078456810668, "Bleu_4": 0.08359039001252586, "METEOR": 0.29883480770629905, "ROUGE_L": 0.3057644110275689, "CIDEr": 5.728359780829792e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are white and the floor is tiled. There is a window on the left side of the room with a view of the outside. The room is well lit and has a white ceiling fan."}, "69293": {"image_id": 69293, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.11216649288903491, "Bleu_4": 0.07442312429536306, "METEOR": 0.2412389310788975, "ROUGE_L": 0.3386798272671191, "CIDEr": 2.1975900304064228e-09, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.26666666666666666, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a toilet, sink, and mirror. The floor is made of tile and the walls are made of wood. There is a shower in the corner of the room. The toilet is a white porcelain bowl with a seat and lid. The sink is"}, "527573": {"image_id": 527573, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.07250583813278431, "Bleu_4": 9.252921909857738e-06, "METEOR": 0.2353970529568179, "ROUGE_L": 0.2513243084167157, "CIDEr": 1.2565747843927313e-12, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a street scene with a man standing on the sidewalk looking at a fountain in the middle of the road. The fountain is made of metal and has a large stone statue in the center. There are buildings on either side of the street, with windows and doors. The sky is cloud"}, "10966": {"image_id": 10966, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.19782182158264086, "Bleu_3": 0.14438930089696145, "Bleu_4": 0.10423563468018282, "METEOR": 0.2510434455534367, "ROUGE_L": 0.2850467289719626, "CIDEr": 4.449534662673986e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.11538461538461539, "f": 0.12000000000000001, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table in a living room. They are all wearing casual clothing and drinking beer from cans. There is a whiteboard on the wall with a list of names written on it. The room is well lit and there are no other objects in the"}, "487698": {"image_id": 487698, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1922322627296484, "Bleu_3": 0.130397100762736, "Bleu_4": 0.08201663209189095, "METEOR": 0.248363933254394, "ROUGE_L": 0.25176886792452824, "CIDEr": 7.682343461555557e-11, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.16129032258064516, "f": 0.16666666666666669, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a woman walking down a sidewalk in front of a red fire hydrant. She is wearing a black jacket and carrying a backpack. The sky is cloudy and there are buildings in the background.\n\nThe image is taken from a low angle, looking down at the woman from above"}, "301746": {"image_id": 301746, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 0.08077421359130517, "Bleu_4": 1.0521736949759788e-05, "METEOR": 0.2147186101395731, "ROUGE_L": 0.20691994572591585, "CIDEr": 3.1693053575062975e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people riding bicycles on the sidewalk at night. They are wearing dark clothing and helmets, and one person is holding a flashlight. The streetlights are on, and there are trees and houses in the background.\n\nThe image is taken at"}, "39053": {"image_id": 39053, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.13206763594580717, "Bleu_3": 7.460727407390932e-07, "Bleu_4": 1.7839797285703599e-09, "METEOR": 0.17186893193091204, "ROUGE_L": 0.266209476309227, "CIDEr": 3.9354292300399596e-07, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.0967741935483871, "f": 0.10526315789473684, "fn": 28.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a table with several dishes on it, including a bowl of soup, a plate of eggs, and a plate of bread. There are also several glasses of water and a fork on the table. The tablecloth is red and white checkered."}, "5033": {"image_id": 5033, "Bleu_1": 0.14545454545190087, "Bleu_2": 0.08989331499344942, "Bleu_3": 0.05342275830329975, "Bleu_4": 7.358577950477175e-06, "METEOR": 0.16107018523733946, "ROUGE_L": 0.18340348767288037, "CIDEr": 1.3829569785662308e-14, "SPICE": {"All": {"pr": 0.2, "re": 0.18518518518518517, "f": 0.1923076923076923, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image is of a lighthouse made out of wood. It has a small window on the top and a door on the side. The lighthouse is surrounded by trees and has a train track running in front of it.\n\nThe train track is made of metal and has a small train running on it"}, "379048": {"image_id": 379048, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.14002800840008178, "Bleu_3": 7.319587495056677e-07, "Bleu_4": 1.681961051814596e-09, "METEOR": 0.15578240471216284, "ROUGE_L": 0.18373493975903615, "CIDEr": 2.2817738444125987e-11, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a baseball bat and glove on display in a glass case. The bat is a brown and white baseball bat with a red stitching pattern on the handle. The glove is a brown leather glove with a red stitching pattern on the palm. The case is made of glass"}, "374342": {"image_id": 374342, "Bleu_1": 0.3157894736786704, "Bleu_2": 0.1501878522938693, "Bleu_3": 0.0742966059776262, "Bleu_4": 9.3353002593842e-06, "METEOR": 0.2891691871931475, "ROUGE_L": 0.2392156862745098, "CIDEr": 6.9472733459665515e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10810810810810811, "f": 0.13114754098360656, "fn": 33.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and black shorts and is holding a tennis racket in his hand. There are several people in the stands watching him play. The court is made of grass and there are lines on it to mark the boundaries of the game"}, "441841": {"image_id": 441841, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.1412673303879691, "Bleu_3": 0.10549005488471223, "Bleu_4": 0.08277965966610605, "METEOR": 0.2350195781196106, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.3619304320923494e-12, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1935483870967742, "f": 0.22641509433962262, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person riding a motorcycle down a winding road. The person is wearing a helmet and riding on the left side of the road. The road is lined with trees and there are hills in the background. The sky is cloudy and there are no other vehicles on the road"}, "201993": {"image_id": 201993, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.19341324859511805, "ROUGE_L": 0.21721068249258166, "CIDEr": 1.0077636466310543e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bench on the beach with a view of the ocean in the background. The sky is cloudy and there are some clouds in the sky. The sand is white and there are some shells on the beach.\n\nThe bench is made of wood and has a backrest. There are"}, "478433": {"image_id": 478433, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.20174997577993367, "Bleu_3": 0.16537181427527523, "Bleu_4": 0.13251445746049817, "METEOR": 0.21034994290891398, "ROUGE_L": 0.2781758957654723, "CIDEr": 4.068168726230057e-08, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1, "f": 0.0975609756097561, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a wetsuit and a helmet. The wave is breaking on the shore and the surfer is jumping off the wave. The sky is cloudy and there are palm trees in the background."}, "351930": {"image_id": 351930, "Bleu_1": 0.1481481481454047, "Bleu_2": 0.07476962054420824, "Bleu_3": 0.04754983378859276, "Bleu_4": 6.775934642896438e-06, "METEOR": 0.0980488895716792, "ROUGE_L": 0.2053872053872054, "CIDEr": 2.056221594506823e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.12, "f": 0.1132075471698113, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a military aircraft on the ground. The aircraft is painted in a red and white color scheme and has a large propeller on the front. There are people standing around the aircraft, looking at it. The sky is clear and blue.\n\nThe image is taken from a bird's eye view,"}, "519361": {"image_id": 519361, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.13957263155725563, "Bleu_3": 7.118725684669194e-07, "Bleu_4": 1.615223877663139e-09, "METEOR": 0.16804326109350426, "ROUGE_L": 0.17329545454545456, "CIDEr": 4.717416573749456e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of police officers standing in front of a line of cars on a street. The officers are wearing uniforms and holding their weapons. There are several other cars parked on the street, and a building can be seen in the background. The sky is cloudy and there are trees in the"}, "113001": {"image_id": 113001, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 7.387419460030929e-07, "Bleu_4": 1.6767836295274806e-09, "METEOR": 0.16044527749728715, "ROUGE_L": 0.20132013201320131, "CIDEr": 6.361426396878612e-12, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a blue tram traveling down the street with people walking on the sidewalk. There are tall buildings on either side of the street and a few cars parked on the side of the road. The sky is clear and sunny.\n\nThe tram is a light blue color with white stripes on"}, "545155": {"image_id": 545155, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.21797089763394864, "Bleu_3": 0.15606146188116843, "Bleu_4": 0.11160412118083014, "METEOR": 0.26356528764178405, "ROUGE_L": 0.28175519630484985, "CIDEr": 3.932955505471964e-11, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.391304347826087, "f": 0.36734693877551017, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a young boy sitting on the back of a horse, wearing a cowboy hat and holding onto the reins. The horse is brown and white, with a long mane and tail. The boy is wearing a cowboy hat and holding onto the reins. The horse is brown and white"}, "60677": {"image_id": 60677, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.17864740024886272, "Bleu_3": 0.1115377437347146, "Bleu_4": 0.07451835561525198, "METEOR": 0.25042454482198345, "ROUGE_L": 0.20497311827956988, "CIDEr": 1.530208793227362e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.3076923076923077, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two cars parked in a parking lot. One is a blue pickup truck with a large bumper and a tow hitch on the back. The other is a white car with a sunroof and a spoiler on the back. Both cars have tinted windows and"}, "526368": {"image_id": 526368, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.18136906252429263, "Bleu_3": 0.1337440815614704, "Bleu_4": 0.10737119910549711, "METEOR": 0.24589603471062324, "ROUGE_L": 0.2136602451838879, "CIDEr": 2.7120497676260497e-14, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3, "f": 0.27906976744186046, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The laptop is sitting on a wooden table with a keyboard and mouse attached to it\n\nThe laptop is open and has a keyboard and mouse attached to it. There is a cup of coffee on the table next to the laptop.\n\nThe laptop is open and has a keyboard and mouse attached to it. There is"}, "300737": {"image_id": 300737, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.18504536999744126, "Bleu_3": 0.12547526428859127, "Bleu_4": 0.07889074281873733, "METEOR": 0.15742519563999283, "ROUGE_L": 0.2053872053872054, "CIDEr": 7.895710435752341e-12, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08333333333333333, "f": 0.0930232558139535, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a goat standing in the grass next to a tree. The goat is looking at the camera with its head tilted to the side. The tree has green leaves and branches that are swaying in the wind. The sky is blue and there are clouds in the distance. The grass is"}, "292324": {"image_id": 292324, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.12875644765560088, "Bleu_4": 0.10534312981202536, "METEOR": 0.23266368249270988, "ROUGE_L": 0.2872277810476751, "CIDEr": 6.395951696196272e-13, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2631578947368421, "f": 0.24390243902439024, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is a living room with a couch, coffee table, and chairs. The walls are painted a light beige color and there are large windows on either side of the room. The floor is made of hardwood and there is a rug in the center of the room. The room is well lit and"}, "40839": {"image_id": 40839, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.2162249910430379, "Bleu_3": 0.1629781336014208, "Bleu_4": 0.11305389682845625, "METEOR": 0.26461282265616326, "ROUGE_L": 0.29967248908296945, "CIDEr": 1.2416932304344863e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a large, colorful building with a dome on top. The building has a lot of intricate details and patterns on the walls and roof. There are several people standing in front of the building, looking at it. The sky is blue and there are some"}, "6437": {"image_id": 6437, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.0885614885522557, "Bleu_3": 0.05429559270864281, "Bleu_4": 7.599116882063913e-06, "METEOR": 0.15399017709503884, "ROUGE_L": 0.19074421513445905, "CIDEr": 5.480597715210235e-10, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08695652173913043, "f": 0.0851063829787234, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a polar bear lying on its side, with its head resting on its paws. The bear's fur is white and fluffy, and its eyes are closed. The bear's mouth is open, and it appears to be chewing on something. The background of the image is a"}, "320823": {"image_id": 320823, "Bleu_1": 0.340909090901343, "Bleu_2": 0.25184310024886714, "Bleu_3": 1.1472822500028998e-06, "Bleu_4": 2.4635236829988735e-09, "METEOR": 0.1616892371110544, "ROUGE_L": 0.214185393258427, "CIDEr": 1.1041199168985094e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2, "f": 0.1923076923076923, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a couple sitting at a table with a cake in front of them. The couple is wearing traditional Indian clothing and the cake has candles on it. The background is a brightly colored wall with a large window in the background."}, "300753": {"image_id": 300753, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.06838765055261399, "Bleu_3": 4.633962375070945e-07, "Bleu_4": 1.2127601540611027e-09, "METEOR": 0.15694421147333737, "ROUGE_L": 0.2208811104405552, "CIDEr": 7.875150623305523e-10, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.09090909090909091, "f": 0.08, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a baseball game in progress. The players are wearing uniforms with numbers on the back and the umpire is wearing a white shirt and pants. The crowd is watching from the stands.\n\nThe image shows a baseball game in progress. The players are wearing uniforms with"}, "35770": {"image_id": 35770, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.18650096164396338, "Bleu_3": 0.09246339272901193, "Bleu_4": 1.1644216046141969e-05, "METEOR": 0.17310139130537988, "ROUGE_L": 0.24238410596026488, "CIDEr": 3.887131642395333e-09, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09090909090909091, "f": 0.08163265306122448, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image is of a bathroom with a sink, toilet, and shower. The sink is made of stainless steel and has two faucets. The toilet is a standard size and has a seat and lid. The shower is a glass enclosure with a curtain and a"}, "447558": {"image_id": 447558, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.11651034560483009, "Bleu_3": 0.0647519709524591, "Bleu_4": 8.627614350761504e-06, "METEOR": 0.2656939400696781, "ROUGE_L": 0.28175519630484985, "CIDEr": 2.4307365897097143e-10, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a baseball player hitting a ball off a tee. The player is wearing a red jersey and white pants, and has a bat in his hand. The ball is flying through the air and the umpire is watching from behind the plate. The crowd is cheering in the background"}, "160185": {"image_id": 160185, "Bleu_1": 0.35714285713647964, "Bleu_2": 0.19738550848437394, "Bleu_3": 0.11300272640516915, "Bleu_4": 1.2845402703111061e-05, "METEOR": 0.20740066736383198, "ROUGE_L": 0.33180276914382595, "CIDEr": 4.599570260474358e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a soccer player in green and blue uniform playing soccer on a grass field. The player is wearing cleats and has a ball at their feet. There are other players on the field, but the one in the image is the only one in green and blue. The field is surrounded by a"}, "134537": {"image_id": 134537, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.10540925533701173, "Bleu_3": 0.05940557542491761, "Bleu_4": 7.968371423587569e-06, "METEOR": 0.14944548491167234, "ROUGE_L": 0.17951736315479697, "CIDEr": 1.108857390985969e-12, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.2, "f": 0.15094339622641512, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a busy street with cars driving down it. There are people walking on the sidewalk and buildings on either side of the street. The street is decorated with Christmas lights and decorations.\n\nThe image is taken at night and the lights are on. The street is empty except for the cars driving"}, "277329": {"image_id": 277329, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.10079509744376741, "Bleu_3": 5.840314225182713e-07, "Bleu_4": 1.4128129251678322e-09, "METEOR": 0.15625, "ROUGE_L": 0.1763005780346821, "CIDEr": 1.895108161762011e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.2857142857142857, "f": 0.3243243243243243, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a green and rolling hillside with a small village in the distance. The sky is cloudy and there are some trees in the foreground.\n\nThe image is taken from a high vantage point, looking down on the landscape. The hillside is covered in green grass and there are some trees"}, "380634": {"image_id": 380634, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.16714975946414357, "Bleu_3": 0.13991698775013336, "Bleu_4": 0.12166770939446522, "METEOR": 0.37431913845228887, "ROUGE_L": 0.3190005810575247, "CIDEr": 1.2723131360894801e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.15625, "f": 0.17543859649122806, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.3333333333333333, "f": 0.4166666666666667, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a young girl sitting on the back of a brown horse. The horse is standing in a dirt area with a wooden fence in the background. The girl is wearing a white shirt and pants, and has a brown hat on her head. The horse is wearing a brown saddle"}, "388215": {"image_id": 388215, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.24909123653704068, "Bleu_3": 0.15396523123679995, "Bleu_4": 0.0924324560277985, "METEOR": 0.2767915091575876, "ROUGE_L": 0.25894481503941785, "CIDEr": 2.3488535758956913e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and black shorts and is holding a tennis racket in his hand. The net is in the background and there are other players on the court. The sky is blue and there are trees in the background."}, "102947": {"image_id": 102947, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.11843515045025206, "Bleu_3": 0.06266554082896969, "Bleu_4": 8.141877941016982e-06, "METEOR": 0.15335463258785942, "ROUGE_L": 0.169538632573652, "CIDEr": 6.252652334789989e-15, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.125, "f": 0.1276595744680851, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image is of a hotel room with a large window on the left side of the room. There is a desk in the corner of the room with a lamp on it. There is a couch in the center of the room with a coffee table in front of it. There is a television on the wall opposite"}, "458401": {"image_id": 458401, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.24010829142722329, "Bleu_3": 0.23018015884496237, "Bleu_4": 0.2211354502939862, "METEOR": 0.2890701799454643, "ROUGE_L": 0.34630981346309814, "CIDEr": 6.470802552718781e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.07692307692307693, "f": 0.09375000000000001, "fn": 36.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a black and white photograph of a dog standing on top of a fence. The dog is wearing a collar and leash. The fence is made of wood and has a gate in the center. There is a small shed in the background. The sky is cloudy and there are trees"}, "554625": {"image_id": 554625, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.10412270358781489, "Bleu_4": 1.2197379410072965e-05, "METEOR": 0.2656939400696781, "ROUGE_L": 0.25507765830346474, "CIDEr": 6.2995691561242315e-12, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.18181818181818182, "f": 0.1509433962264151, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of children sitting at desks in a classroom, using computers with monitors on them. The children are all wearing school uniforms and are focused on their work. The teacher is standing at the front of the room, looking over their shoulders. The room is well lit and there are"}, "138246": {"image_id": 138246, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.20550493309104514, "Bleu_3": 0.13633224439757732, "Bleu_4": 0.0848007939389795, "METEOR": 0.22369659213214657, "ROUGE_L": 0.25176886792452824, "CIDEr": 2.385827664226704e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.34782608695652173, "f": 0.30188679245283023, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a small church with a steeple in the center of a green field. There are two horses grazing in the field. The sky is cloudy and there are trees in the background.\n\nThe church is made of stone and has a tall steeple with a cross on top. The"}, "339974": {"image_id": 339974, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.13197176106186115, "Bleu_3": 6.98978712330286e-07, "Bleu_4": 1.6166107444596473e-09, "METEOR": 0.19136640242832603, "ROUGE_L": 0.18908865468071917, "CIDEr": 4.605369614891574e-12, "SPICE": {"All": {"pr": 0.04, "re": 0.0625, "f": 0.048780487804878044, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a street with traffic lights at night. The lights are green on the left and red on the right. There are cars parked on the side of the road and a pedestrian crossing in the distance.\n\nThe image is taken at night, with the street lights illuminating the road and"}, "176649": {"image_id": 176649, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.10619884880883856, "Bleu_3": 0.05896925524327533, "Bleu_4": 7.850020523433245e-06, "METEOR": 0.19487843446832498, "ROUGE_L": 0.17086834733893558, "CIDEr": 2.416405013253226e-14, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.25, "f": 0.22857142857142856, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a sign with the words low gear now written on it. The sign is on the side of the road and appears to be in good condition. The background is a city street with buildings and cars in the distance. The sky is clear and blue.\n\nThe image is taken from a low angle"}, "23899": {"image_id": 23899, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.09779674410658105, "Bleu_4": 1.2074805060760116e-05, "METEOR": 0.22863009526054207, "ROUGE_L": 0.23404527433175598, "CIDEr": 1.196063443603248e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.10344827586206896, "f": 0.11320754716981132, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows three men sitting on a couch playing video games on their laptops. They are all wearing t-shirts and jeans. The room is dimly lit and there are several posters on the walls.\n\nThe image shows three men sitting on a couch playing video games"}, "335532": {"image_id": 335532, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.15937104245046027, "Bleu_3": 0.1258257556742031, "Bleu_4": 0.07944830925849324, "METEOR": 0.23832416687074098, "ROUGE_L": 0.226906385616863, "CIDEr": 1.7176731517226233e-12, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.23333333333333334, "f": 0.2592592592592593, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a young girl eating a sandwich. She is wearing a pink shirt and has a big smile on her face. The sandwich appears to be a hot dog. There are several other people in the background, including a man and a woman. The image is taken in a restaurant or"}, "503772": {"image_id": 503772, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.1663895814060149, "Bleu_3": 0.1105349109648521, "Bleu_4": 0.07622713576919625, "METEOR": 0.2746355346329592, "ROUGE_L": 0.3132795304475422, "CIDEr": 1.1727205208933929e-07, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.20833333333333334, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.08333333333333333, "f": 0.08695652173913043, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a refrigerator, stove, and sink. The walls are painted white and the floor is made of hardwood. There is a table and chairs in the dining area. The room is well lit and there are no windows."}, "446861": {"image_id": 446861, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 6.912848008424654e-07, "Bleu_4": 1.5876030342373218e-09, "METEOR": 0.14488710911706923, "ROUGE_L": 0.14361389052383755, "CIDEr": 2.4803365307942983e-13, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.11538461538461539, "f": 0.10909090909090909, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a street with traffic lights at an intersection. The lights are red, yellow, and green, and there are cars driving on the road. The sky is clear and blue, with clouds in the distance. The road is straight and there are no obstacles in the way. The image is taken from a"}, "90476": {"image_id": 90476, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.12993504870706918, "Bleu_3": 0.06787131897112117, "Bleu_4": 8.763866421088602e-06, "METEOR": 0.17996973137418856, "ROUGE_L": 0.20460644007155634, "CIDEr": 3.2645918648697395e-13, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.20833333333333334, "f": 0.2631578947368421, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a small fishing village with a number of boats moored in the harbor. The boats are painted in various colors and have different shapes and sizes. There are also some buildings in the background, including a large white building with a red roof. The image is taken from a low angle, looking down"}, "508481": {"image_id": 508481, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2006088294094673, "Bleu_3": 0.10105205741245245, "Bleu_4": 1.283698314434347e-05, "METEOR": 0.21151424148590056, "ROUGE_L": 0.3434201266713582, "CIDEr": 1.834073207020494e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image is of a kitchen with wooden cabinets and a stove. There is a sink and a refrigerator in the kitchen. The walls are painted white and there are no windows in the room. The floor is made of hardwood."}, "339470": {"image_id": 339470, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.234935746945449, "Bleu_3": 0.15990233738253712, "Bleu_4": 0.11144988908428223, "METEOR": 0.2957884697207225, "ROUGE_L": 0.3111362992349108, "CIDEr": 4.149767770367023e-13, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2777777777777778, "f": 0.21739130434782608, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a brown dog standing on a bed next to a white blanket. The dog is looking up at the camera with its mouth open. The bed has a white blanket on it and there are some books on the nightstand. The room has a window with curtains and a view of the outside"}, "102848": {"image_id": 102848, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.07229440390503974, "Bleu_3": 5.074381600450152e-07, "Bleu_4": 1.3529171154640911e-09, "METEOR": 0.11152422409137402, "ROUGE_L": 0.2109266943291839, "CIDEr": 7.247345613544793e-08, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.25, "f": 0.20408163265306123, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on skateboards in a parking lot. They are wearing various types of clothing, including hats, sunglasses, and t-shirts. Some of them are holding skateboards, while others are standing on the ground. There are several"}, "511066": {"image_id": 511066, "Bleu_1": 0.41176470587427916, "Bleu_2": 0.32719844670348214, "Bleu_3": 0.2699124798412822, "Bleu_4": 0.23140962824608555, "METEOR": 0.34510054460850925, "ROUGE_L": 0.42841707185305244, "CIDEr": 3.5970995194021605e-06, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman standing in front of a door with a surfboard on the ground next to her. She is wearing a blue shirt and shorts, and has her hands on her hips. The door is open, revealing a room with a couch and a table in it. There"}, "130171": {"image_id": 130171, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 6.47433787030964e-07, "Bleu_4": 1.558500916173644e-09, "METEOR": 0.1901377507421998, "ROUGE_L": 0.19242902208201892, "CIDEr": 2.0593504384322102e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a pot of soup with carrots, onions, and potatoes. The soup is simmering in a pot on a stove. The pot has a lid on it and is covered in steam. The stove has a burner on it and is turned on. The kitchen is clean"}, "55772": {"image_id": 55772, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.22712838128148707, "Bleu_3": 0.12565790685020078, "Bleu_4": 1.6784459624551696e-05, "METEOR": 0.2629190878004177, "ROUGE_L": 0.38705583756345174, "CIDEr": 0.009612851844566726, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a plate with two pancakes on it, one with bacon and the other with syrup. There is also a cup of coffee on the table."}, "22969": {"image_id": 22969, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.11651034560483009, "Bleu_3": 6.475197095245912e-07, "Bleu_4": 1.5342308957715506e-09, "METEOR": 0.1549043303308873, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.6465202083346675e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of giraffes standing in a fenced in area. They are looking at each other and appear to be in a playful mood. The fence is made of wood and has a gate that is open. There is a small pond in the background with a few ducks"}, "59532": {"image_id": 59532, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 7.205793047605259e-07, "Bleu_4": 1.6797199261809358e-09, "METEOR": 0.18802734252173223, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.423282397008329e-10, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.11538461538461539, "f": 0.11111111111111112, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a parking lot with several motorcycles parked on the ground. The parking lot is painted green and there are no other vehicles parked in the area. The motorcycles are parked in rows and there are no other vehicles parked in the area. The parking lot is painted"}, "448151": {"image_id": 448151, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.21550898337204086, "Bleu_3": 0.12212282967165414, "Bleu_4": 1.3815135310163003e-05, "METEOR": 0.2414665723093359, "ROUGE_L": 0.3100818977689918, "CIDEr": 2.4673574963470013e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.3076923076923077, "f": 0.23529411764705882, "fn": 9.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a young boy sitting at a table with a cake in front of him. The cake is shaped like a car and has a number of candles on it. The boy is wearing a white shirt and black pants, and has a black tie around his neck. The background of"}, "327383": {"image_id": 327383, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.12539246564153583, "Bleu_3": 6.711916014355543e-07, "Bleu_4": 1.5604229933011285e-09, "METEOR": 0.19058964435844397, "ROUGE_L": 0.2367487247726769, "CIDEr": 7.632150696256354e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12903225806451613, "f": 0.14545454545454548, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is of a silver and white van parked on the side of the road. The van has a large mirror on the side and a sign on the back that reads \"Vegan Roots\". The image is taken in a city setting with tall buildings and trees in the background.\n\nThe van is"}, "164420": {"image_id": 164420, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.12741179785711051, "Bleu_3": 0.08440182574767095, "Bleu_4": 0.058035658098532374, "METEOR": 0.20513421068443424, "ROUGE_L": 0.21682464454976302, "CIDEr": 2.1279959396588806e-13, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.17391304347826086, "f": 0.16326530612244897, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a red fire hydrant on the side of the road in front of a house with a green lawn and trees in the background. The hydrant is surrounded by a white curb and has a green hose attached to it. There is a car parked on the side of the road in the"}, "398884": {"image_id": 398884, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.24077170616624616, "Bleu_3": 0.17402276782115267, "Bleu_4": 0.1052173694975979, "METEOR": 0.20655985384749212, "ROUGE_L": 0.2378476735118274, "CIDEr": 2.6800522244645147e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a green truck parked on a grassy field. The truck has a flatbed and is parked next to a red pickup truck. There are several other trucks parked in the background.\n\nThe image is in focus and the lighting is good."}, "20273": {"image_id": 20273, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1923483450237976, "Bleu_3": 0.12077745418377696, "Bleu_4": 1.4397710576737565e-05, "METEOR": 0.19953905593442478, "ROUGE_L": 0.25702247191011235, "CIDEr": 1.329915294235521e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bus stop with a sign that says \"Bus Stop\" in white letters on a blue background. The bus stop is located on a street with a lot of trees and buildings in the background. There are no people in the image."}, "207611": {"image_id": 207611, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.21573723181113055, "Bleu_3": 0.1264855137960998, "Bleu_4": 1.4562215827951557e-05, "METEOR": 0.2058297024687269, "ROUGE_L": 0.2616421568627451, "CIDEr": 7.589508764186352e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.14285714285714285, "f": 0.1395348837209302, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man in a suit and tie standing on a street corner. He is wearing sunglasses and has a cigarette in his hand. There are people walking in the background.\n\nThe image is in black and white.\n\nThe man is wearing a suit and tie."}, "522020": {"image_id": 522020, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.20544535089962757, "Bleu_3": 0.1575153781294635, "Bleu_4": 0.11019978611152552, "METEOR": 0.26605174811221965, "ROUGE_L": 0.21229698375870068, "CIDEr": 5.487781269379222e-13, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.10714285714285714, "f": 0.11999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.06666666666666667, "f": 0.10526315789473685, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image is of a white cat sitting in the grass. The cat has a fluffy coat and is looking directly at the camera. The background is a house with a window on the left side and a door on the right side. The sky is blue and there are some clouds in the background.\n\nThe"}, "252549": {"image_id": 252549, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.15927956195690762, "Bleu_3": 0.10650424961231203, "Bleu_4": 0.0736765427376396, "METEOR": 0.24317728248409298, "ROUGE_L": 0.32620320855614976, "CIDEr": 1.7688391887138605e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This image shows a clothing store with various types of clothing on display. There are suits, shirts, and ties on the racks, as well as shoes and accessories on the floor. The store appears to be well-organized and well-lit, with a variety of colors"}, "122239": {"image_id": 122239, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.2613021337786361, "Bleu_3": 0.12378303795219202, "Bleu_4": 1.5257340614283253e-05, "METEOR": 0.26538091775145733, "ROUGE_L": 0.362555720653789, "CIDEr": 2.3133799629323568e-05, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08695652173913043, "f": 0.07999999999999999, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a young boy standing in a field, holding an apple in his hand. The boy is wearing a blue jacket and has blonde hair. The background is a green field with trees in the distance."}, "257940": {"image_id": 257940, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.10167765666209894, "Bleu_3": 5.728348820235567e-07, "Bleu_4": 1.365914929670925e-09, "METEOR": 0.15088410553728712, "ROUGE_L": 0.19709208400646203, "CIDEr": 7.305958314728646e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.19230769230769232, "f": 0.1851851851851852, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a train on the tracks, with buildings on either side of the tracks. The train is moving at a slow pace, and there are people standing on the platform. The sky is clear and blue, with some clouds in the distance. The buildings are made of brick and have windows on the upper floors"}, "82263": {"image_id": 82263, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.09135163170376533, "Bleu_4": 1.1003640569767388e-05, "METEOR": 0.1944676308702533, "ROUGE_L": 0.24013046901360924, "CIDEr": 7.091445261595987e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.17391304347826086, "f": 0.16326530612244897, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a small boat floating on the water under a bridge. The bridge is made of concrete and has a large arch over it. There are some buildings in the background, and the sky is cloudy.\n\nThe image is taken from a low angle, looking down at the boat and the bridge. The"}, "53893": {"image_id": 53893, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 6.290089214849726e-07, "Bleu_4": 1.5012173807660588e-09, "METEOR": 0.12812130876400565, "ROUGE_L": 0.14698795180722893, "CIDEr": 7.729824851124327e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.15384615384615385, "f": 0.14285714285714288, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of zebras standing in a fenced enclosure. They are standing in a grassy area with some trees in the background. There is a wooden fence surrounding the enclosure and a small wooden bridge leading to the entrance. The zebras are all facing the same direction and appear"}, "550815": {"image_id": 550815, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.12094486170917773, "Bleu_3": 0.06825571246936571, "Bleu_4": 9.168559860005064e-06, "METEOR": 0.16555855879479814, "ROUGE_L": 0.20013123359580048, "CIDEr": 7.808362343247865e-09, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 35.0, "numImages": 1.0, "fp": 25.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}}, "caption": "The image shows a market with a variety of vegetables and fruits on display. There are several people shopping in the market, and the atmosphere is bustling and lively. The vegetables and fruits are arranged in wooden barrels, and there are several signs advertising different types of produce."}, "442487": {"image_id": 442487, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.13572088082697478, "Bleu_4": 0.08540052443980553, "METEOR": 0.24128134468382045, "ROUGE_L": 0.326397146254459, "CIDEr": 6.463539638651245e-10, "SPICE": {"All": {"pr": 0.03333333333333333, "re": 0.03571428571428571, "f": 0.03448275862068965, "fn": 27.0, "numImages": 1.0, "fp": 29.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a young boy standing on the floor, holding a toy in his hand. He is wearing a blue shirt and brown pants. The room is filled with furniture, including a couch, a coffee table, and a television. There is a window on the wall, and the floor"}, "412247": {"image_id": 412247, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.23763541030969573, "Bleu_3": 0.1048436367821309, "Bleu_4": 1.2447904522732415e-05, "METEOR": 0.29781676144780767, "ROUGE_L": 0.33577981651376143, "CIDEr": 1.8550238308018308e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.6428571428571429, "f": 0.3829787234042553, "fn": 5.0, "numImages": 1.0, "fp": 24.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 1.0, "f": 0.631578947368421, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a woman in a white shirt and pink pants standing in a baseball batting cage. She is holding a bat and looking at the pitcher. The batting cage is made of metal and has a green roof. There are two other people in the cage, one is we"}, "19817": {"image_id": 19817, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.06989787123302858, "Bleu_4": 9.090870283563952e-06, "METEOR": 0.20526854778060566, "ROUGE_L": 0.18908865468071917, "CIDEr": 1.1285645066979616e-11, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.14285714285714285, "f": 0.0975609756097561, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are painted blue and white, and there is a blue and white rug on the floor. There is a window on the left side of the room, and a door on the right side. The room is well lit and"}, "82696": {"image_id": 82696, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.1455115930560931, "Bleu_3": 7.23106703955395e-07, "Bleu_4": 1.6192396082012257e-09, "METEOR": 0.19153178634695633, "ROUGE_L": 0.20220994475138118, "CIDEr": 6.393235458487996e-14, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.25, "f": 0.21818181818181817, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a bird standing on the floor in front of a group of chairs in a restaurant. The bird is looking around and appears to be looking for something. The chairs are all empty and there are no people sitting in them. The floor is made of white tiles and there are no tables or other"}, "167003": {"image_id": 167003, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.12094486170917773, "Bleu_3": 6.825571246936573e-07, "Bleu_4": 1.630426121875635e-09, "METEOR": 0.10434782608695653, "ROUGE_L": 0.19551282051282048, "CIDEr": 1.3623423292986546e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.12121212121212122, "f": 0.1379310344827586, "fn": 29.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman standing on a balcony overlooking the ocean. She is holding a red lollipop in her hand and smiling at the camera. The balcony is made of metal and has a railing around it. There are several beach umbrellas set up on the sand"}, "87681": {"image_id": 87681, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.09319532338930898, "Bleu_4": 1.1580903993958116e-05, "METEOR": 0.18703130963425388, "ROUGE_L": 0.2663423153692615, "CIDEr": 2.2932928429407556e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.12903225806451613, "f": 0.14814814814814814, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a young man performing a trick on a skateboard in a skate park. The skateboarder is wearing a green shirt and black pants, and he is performing a trick on the skateboard. The skate park is made of concrete and has a ledge on one"}, "353317": {"image_id": 353317, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.22228757208608238, "Bleu_3": 0.1446278221289709, "Bleu_4": 0.08910017878799979, "METEOR": 0.2505673744386216, "ROUGE_L": 0.34221598877980364, "CIDEr": 2.2415663465593427e-05, "SPICE": {"All": {"pr": 0.1, "re": 0.09523809523809523, "f": 0.0975609756097561, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a kitchen with white cabinets and a white refrigerator. There is a white stove and oven in the corner of the room. The floor is made of hardwood and there is a large window on one side of the room.\n\nThe image shows a kitchen with white cabinets and"}, "432553": {"image_id": 432553, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.10540925533701173, "Bleu_3": 0.07484633495897125, "Bleu_4": 9.476043991914697e-06, "METEOR": 0.21120337383933369, "ROUGE_L": 0.2658241638522715, "CIDEr": 3.665728693630834e-12, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.26666666666666666, "f": 0.2758620689655172, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on a bus, with their dogs sitting on the floor. The people are wearing casual clothing and the dogs are wearing collars. The bus is a yellow school bus with a large window on the side. The people are looking out the window and the dogs are"}, "523245": {"image_id": 523245, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.08330762903217113, "Bleu_4": 1.0646588104484678e-05, "METEOR": 0.2107962985827532, "ROUGE_L": 0.25058685446009393, "CIDEr": 6.661033851609565e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.09375, "f": 0.1111111111111111, "fn": 29.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man driving a cart with two cows on it down a dirt road. The man is wearing a white shirt and pants, and the cows are wearing brown leather harnesses. The cart has a wooden frame and metal wheels. The road is lined with"}, "356586": {"image_id": 356586, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.16351748503705, "Bleu_3": 0.09418739954830285, "Bleu_4": 1.2813098990443002e-05, "METEOR": 0.2327483767431372, "ROUGE_L": 0.2680140597539543, "CIDEr": 0.00027565844271151124, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.11538461538461539, "f": 0.11111111111111112, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a plate with three doughnuts on it. The doughnuts are chocolate covered and have sprinkles on top. There is a fork on the plate. The plate is on a green table."}, "371155": {"image_id": 371155, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.11895773785545558, "Bleu_3": 0.06522364605376364, "Bleu_4": 8.631003710817792e-06, "METEOR": 0.18365098048783124, "ROUGE_L": 0.25341246290801184, "CIDEr": 2.096855410690764e-12, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.038461538461538464, "f": 0.04, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a small bench made of stone in the middle of a grassy area. The bench has a carved design on the top and is surrounded by flowers and trees. The sky is clear and blue.\n\nThe image shows a small bench made of stone in the middle of a grassy"}, "180983": {"image_id": 180983, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.1390096093683277, "Bleu_3": 7.601144519394984e-07, "Bleu_4": 1.7876896610284684e-09, "METEOR": 0.20383357556393766, "ROUGE_L": 0.2121001390820584, "CIDEr": 1.4954306110245059e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.15, "f": 0.125, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person wearing snowboarding gear standing on a snowy slope. The person is wearing a black jacket, black pants, and black boots. The person is also wearing a pair of goggles on their face. The snow on the ground is white and there"}, "127659": {"image_id": 127659, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.12262786789482262, "Bleu_3": 0.08177399592597044, "Bleu_4": 0.05641089306128336, "METEOR": 0.20660208334697508, "ROUGE_L": 0.2771152754116979, "CIDEr": 7.565938493736168e-13, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.21739130434782608, "f": 0.19607843137254902, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a train station with a train on the tracks. There are people standing on the platform and others walking down the platform. The train is a red and blue train with a white stripe on the front. There are buildings in the background.\n\nThe train station is a large building with a long platform"}, "69827": {"image_id": 69827, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1456862718139933, "Bleu_3": 0.09598617210562839, "Bleu_4": 0.06586156404600876, "METEOR": 0.23361669312081176, "ROUGE_L": 0.29647630619684084, "CIDEr": 5.931456249012232e-10, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man standing on the sidewalk next to a large truck. The man is wearing a yellow shirt and jeans, and has a backpack on his back. The truck is white with a red and blue stripe on the side. There is a fence in the background."}, "541887": {"image_id": 541887, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.15585730003579046, "Bleu_3": 0.0869128899641639, "Bleu_4": 1.1620839902584731e-05, "METEOR": 0.23677480970010792, "ROUGE_L": 0.33808392715756136, "CIDEr": 4.671577855563136e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.13793103448275862, "f": 0.15384615384615385, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a red stop sign on a road with trees in the background. The sign has the words \"stop\" and \"cantriolism\" written on it in white letters. The background is a mix of green and yellow leaves."}, "267725": {"image_id": 267725, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.09701425001261196, "Bleu_3": 5.76976768606882e-07, "Bleu_4": 1.4143550190666944e-09, "METEOR": 0.12609522824401584, "ROUGE_L": 0.2238532110091743, "CIDEr": 3.841828190434812e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image is of a dog lying on the ground in front of a building. The dog is wearing a collar and leash. The building appears to be abandoned and has broken windows and a broken door. There are trash cans and debris on the ground.\n\nThe image is in black"}, "147140": {"image_id": 147140, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.059110575176554124, "Bleu_3": 4.065453602348427e-07, "Bleu_4": 1.0713693373996204e-09, "METEOR": 0.14002807229183512, "ROUGE_L": 0.1821983273596177, "CIDEr": 3.1364933878545e-13, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.30434782608695654, "f": 0.26415094339622636, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a person skiing down a snowy slope. The person is wearing a green and black ski suit, and has a green and black helmet on their head. They are holding a pair of skis and are skiing down the slope at a fast pace. The image is taken in the winter"}, "24567": {"image_id": 24567, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.23328473740311126, "Bleu_3": 0.17956220625337854, "Bleu_4": 0.13939655966239878, "METEOR": 0.30922280050026274, "ROUGE_L": 0.3078864353312303, "CIDEr": 7.316850324457277e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a man in a hat and sunglasses holding a tray of hot dogs on a picnic blanket. The man is standing in front of a table with a red and white checkered tablecloth and a white umbrella. There are several chairs around the table, and a"}, "322145": {"image_id": 322145, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 6.052669898452478e-07, "Bleu_4": 1.4440016772249673e-09, "METEOR": 0.1756873020577432, "ROUGE_L": 0.1821983273596177, "CIDEr": 6.179731529180426e-12, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.16666666666666666, "f": 0.1276595744680851, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person skiing down a snowy mountain slope. The person is wearing a black and white ski suit and has a backpack on their back. The mountain in the background is covered in snow and has a few trees on it. The sky is clear and blue.\n\nThe image is taken"}, "11567": {"image_id": 11567, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.18725633517633355, "Bleu_3": 0.08659505513046915, "Bleu_4": 1.0520850572898885e-05, "METEOR": 0.25639824688439394, "ROUGE_L": 0.30221767851525644, "CIDEr": 2.128429868545198e-11, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.07142857142857142, "f": 0.07407407407407408, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man in a blue shirt and white shorts playing tennis on a green court. He is holding a tennis racket in his right hand and is about to hit the ball with his left hand. The ball is on the ground in front of him. The man is wearing white shoes and"}, "482487": {"image_id": 482487, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.17040572913395824, "Bleu_3": 0.10122088205002643, "Bleu_4": 1.1718227243707044e-05, "METEOR": 0.2487727367581999, "ROUGE_L": 0.28700522778192683, "CIDEr": 1.6039776632429064e-06, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image is a reflection of a clock on a wall. The clock has a face with numbers and hands, and is surrounded by a metal frame. The wall is made of wood and has a window on it. The window is open and there is a view of the street outside. The street is lined with trees"}, "132992": {"image_id": 132992, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.16903085094265752, "Bleu_3": 0.12839045236794375, "Bleu_4": 0.09453400953196897, "METEOR": 0.2514582813650079, "ROUGE_L": 0.2663755458515284, "CIDEr": 7.470520869175337e-13, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.35294117647058826, "f": 0.26666666666666666, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a brown teddy bear sitting on a wooden bench next to a window with a view of the mountains in the background. The bear is looking down at the ground with its head tilted to the side. The window has a view of the mountains in the background. The bear is wearing a"}, "411953": {"image_id": 411953, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.3015113445722309, "Bleu_3": 0.23940900263458353, "Bleu_4": 0.19058864535063264, "METEOR": 0.32516809147201625, "ROUGE_L": 0.31560793331417075, "CIDEr": 1.0510140082217038e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2857142857142857, "f": 0.24489795918367344, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a man playing a guitar on stage in front of a crowd of people. The stage is lit by bright lights and there are microphones on the ground. The man is wearing a white shirt and black pants and has a guitar strap around his neck. The crowd is made up of"}, "359314": {"image_id": 359314, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.06085806194390174, "Bleu_3": 4.1189525480153644e-07, "Bleu_4": 1.0766864701111474e-09, "METEOR": 0.0817717206132879, "ROUGE_L": 0.14672279013830425, "CIDEr": 1.538793223657498e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on the side of a road next to a large truck. The truck has a crane on the back and is parked on the side of the road. There are several people standing around the truck, including one person who is wearing a hard hat and another"}, "502220": {"image_id": 502220, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.10090091909748747, "Bleu_3": 5.8831069922091e-07, "Bleu_4": 1.4277627265895718e-09, "METEOR": 0.17624494722026252, "ROUGE_L": 0.22048192771084338, "CIDEr": 7.714635188966705e-12, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.1724137931034483, "f": 0.19230769230769232, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on a rooftop, looking up at a bird flying overhead. The people are wearing casual clothing and are standing in a circle around the bird. The bird is flying in a circular motion, with its wings spread wide. The sky is clear and blue,"}, "488723": {"image_id": 488723, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.08268590713763764, "Bleu_4": 1.0646588104479637e-05, "METEOR": 0.2691757586675709, "ROUGE_L": 0.2781758957654723, "CIDEr": 9.962680221559512e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.24, "f": 0.24999999999999994, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5454545454545454, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a vase filled with red roses on a table. The table is made of wood and has a white tablecloth on it. There are several bottles of alcohol on the table, including a bottle of whiskey, a bottle of vodka, and a bottle of"}, "400367": {"image_id": 400367, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.09073607102736221, "Bleu_4": 1.1055858618542048e-05, "METEOR": 0.2265131234929172, "ROUGE_L": 0.22195269860521533, "CIDEr": 2.994287483070774e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a street with cars parked on both sides. There are trees on both sides of the street and a building in the background. The street is lit by streetlights.\n\nThe image is taken at night and the cars are moving slowly down the street. The streetlights are casting a warm"}, "453330": {"image_id": 453330, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.10353608435894587, "Bleu_4": 0.06863984611093185, "METEOR": 0.24976556136813377, "ROUGE_L": 0.25894481503941785, "CIDEr": 1.3920020405811948e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.19047619047619047, "f": 0.2162162162162162, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a small bird perched on a branch in the middle of a forest. The bird has a black and white striped body and a long, curved beak. The bird is surrounded by green leaves and branches. The image is taken in a forest with tall trees in the background.\n\nThe"}, "272129": {"image_id": 272129, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 0.06290089214849724, "Bleu_4": 8.441965712987706e-06, "METEOR": 0.2085491943339848, "ROUGE_L": 0.18780788177339902, "CIDEr": 6.335539293979373e-12, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a man wearing a yellow hat and holding a kite with two aliens on it. The man is standing on the beach with his back to the camera, looking out at the sky. The aliens are flying in the air behind him. The sky is blue and cloudy.\n\nThe"}, "100543": {"image_id": 100543, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.16658955971162087, "Bleu_3": 0.12276317177256986, "Bleu_4": 0.09576248453510561, "METEOR": 0.23439855866921985, "ROUGE_L": 0.24069446271208733, "CIDEr": 4.094571625232246e-09, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.045454545454545456, "f": 0.045454545454545456, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "This image shows a group of people standing under umbrellas in a city. They are all wearing different colored shirts and pants, and some of them are holding umbrellas. The sky is cloudy and there are some buildings in the background.\n\nThe image is taken in a"}, "532919": {"image_id": 532919, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.08062577022864871, "Bleu_4": 1.006845569565764e-05, "METEOR": 0.14713476116781135, "ROUGE_L": 0.2694941462337088, "CIDEr": 3.1787595087915014e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.24, "f": 0.20689655172413793, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a horse and cart in front of a row of brick houses. The horse is pulling a cart with a pile of trash on it. The houses are all the same color, with windows and doors on the first floor. There are no people in the image.\n\n\nThe image is taken"}, "498274": {"image_id": 498274, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.148586412828113, "Bleu_3": 7.42200903663368e-07, "Bleu_4": 1.6665645580942163e-09, "METEOR": 0.2283580203334304, "ROUGE_L": 0.19978165938864628, "CIDEr": 5.217727622146623e-13, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a large bus parked on the side of a busy street. The bus is white and has a green stripe down the side. There are several people standing on the sidewalk and in the street, looking at the bus. The sky is clear and there are no clouds in the sky. The building"}, "536933": {"image_id": 536933, "Bleu_1": 0.3599999999928, "Bleu_2": 0.2571428571376619, "Bleu_3": 0.19026514322667332, "Bleu_4": 0.1308435921710671, "METEOR": 0.3289677353065023, "ROUGE_L": 0.29647630619684084, "CIDEr": 3.3520281045598336e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a snowy slope, wearing ski gear and holding skis. There are several other people in the background, also wearing ski gear and standing on the slope. The sky is cloudy and there is snow on the ground.\n\nThe image is taken"}, "273637": {"image_id": 273637, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.24902912254001588, "Bleu_3": 0.18221836147003703, "Bleu_4": 0.11089937663359, "METEOR": 0.2937171720087171, "ROUGE_L": 0.32830370014416144, "CIDEr": 7.285655409469691e-07, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10344827586206896, "f": 0.125, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a woman holding two glasses of wine in her hands. She is standing in a large room with stone walls and a high ceiling. There are several rows of barrels in the background. The woman is smiling and looks happy."}, "257887": {"image_id": 257887, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.07446639778133946, "Bleu_4": 9.43994412057466e-06, "METEOR": 0.187167732229075, "ROUGE_L": 0.22724853645556145, "CIDEr": 2.1835962171325593e-09, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2, "f": 0.22727272727272727, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a river with a bridge in the background. The river is lined with trees and there are some buildings in the distance. The sky is clear and blue.\n\nThe image is taken from a high vantage point, looking down at the river and the surrounding landscape. The bridge is an old one"}, "316123": {"image_id": 316123, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 0.10886194393769152, "Bleu_4": 0.0709193129947971, "METEOR": 0.28002185494387666, "ROUGE_L": 0.25507765830346474, "CIDEr": 9.305739191787695e-11, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.18181818181818182, "f": 0.20512820512820512, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of children playing soccer on a grass field. They are wearing green and white jerseys and white shorts. One child is kicking the ball with his left foot while another child is trying to block it with his right foot. There are trees in the background and a blue"}, "155488": {"image_id": 155488, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.2556147957905549, "Bleu_3": 0.15563118684222096, "Bleu_4": 0.09272138881290835, "METEOR": 0.26374684376275476, "ROUGE_L": 0.2738496071829405, "CIDEr": 1.878186021922552e-11, "SPICE": {"All": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6666666666666666, "f": 0.5217391304347826, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a small, white building with a red roof and a blue door. There is a car parked in front of the building, and a tree in the background. The sky is clear and blue.\n\nThe image is taken from the side of the road, looking towards the building. The building appears"}, "495513": {"image_id": 495513, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.09869275424218699, "Bleu_3": 5.65013632025846e-07, "Bleu_4": 1.358235968559138e-09, "METEOR": 0.16957464575670853, "ROUGE_L": 0.1689750692520776, "CIDEr": 9.929985335629672e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in a field at night, holding hot dogs. They are all wearing blue jackets and hats, and one person is holding a hot dog in each hand. The sky is dark and there are stars visible in the background. The ground is covered in snow and there are"}, "356337": {"image_id": 356337, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.15041420939612582, "Bleu_3": 7.677195064444563e-07, "Bleu_4": 1.7432228564084153e-09, "METEOR": 0.19299652207686754, "ROUGE_L": 0.2601279317697228, "CIDEr": 2.2005397098192735e-07, "SPICE": {"All": {"pr": 0.08, "re": 0.07692307692307693, "f": 0.0784313725490196, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a woman and a man standing next to a cake. The woman is holding a knife and the man is holding a plate. They are both smiling and looking at the cake. The cake appears to be blue and has colorful sprinkles on top. There are also several glass"}, "488": {"image_id": 488, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.20064727352407868, "ROUGE_L": 0.14277355178466938, "CIDEr": 5.89240031451003e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.14285714285714285, "f": 0.12765957446808512, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a baseball game in progress on a field with a dirt infield and a grass outfield. There are two umpires standing on the field, one holding a stop sign and the other holding a ball. The players are wearing baseball uniforms and are standing at the plate, ready to hit"}, "179599": {"image_id": 179599, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.24909123653704068, "Bleu_3": 0.15396523123679995, "Bleu_4": 1.6437073337356213e-05, "METEOR": 0.22550595731288245, "ROUGE_L": 0.28785708266621723, "CIDEr": 5.534344635307996e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.28, "f": 0.2641509433962264, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a baseball player in a blue jersey and white pants standing on a mound, ready to throw a pitch. The player has a glove on his right hand and is holding the ball in his left hand. The background is a green field with a dirt infield and a fence"}, "516601": {"image_id": 516601, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.18504536999744126, "Bleu_3": 0.14876737580907046, "Bleu_4": 0.1179691761236356, "METEOR": 0.24883532803522504, "ROUGE_L": 0.2853801169590643, "CIDEr": 1.915596565962695e-12, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.4, "f": 0.2222222222222222, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people skiing down a snowy mountain. They are wearing ski gear and have their skis pointed down the mountain. The sky is clear and blue, with some clouds in the distance. The mountain is covered in snow and has a few trees on it. The people are all"}, "574376": {"image_id": 574376, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.16870903059432618, "Bleu_4": 0.11893260654292824, "METEOR": 0.242679890358383, "ROUGE_L": 0.3216168717047452, "CIDEr": 2.2553301048650919e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.23809523809523808, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a woman standing on the beach with a surfboard in her hand. She is wearing a blue shirt and black pants, and has a surfboard under her arm. The sky is blue and there are palm trees in the background. The woman is looking out at the ocean."}, "469755": {"image_id": 469755, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.11113289333084049, "Bleu_4": 1.2936981168128564e-05, "METEOR": 0.22670873276381417, "ROUGE_L": 0.2688916876574307, "CIDEr": 8.542476853758375e-12, "SPICE": {"All": {"pr": 0.28, "re": 0.4375, "f": 0.34146341463414637, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.8571428571428571, "f": 0.7058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a group of people surfing on the ocean. They are standing on the waves and riding them towards the shore. The water is choppy and there are rocks in the distance. The sky is cloudy and there are some birds flying overhead. The people are wearing wetsuits and sur"}, "575957": {"image_id": 575957, "Bleu_1": 0.339622641503026, "Bleu_2": 0.3023852923313022, "Bleu_3": 0.23238944414093082, "Bleu_4": 0.17800606287595006, "METEOR": 0.30783555806772706, "ROUGE_L": 0.3190005810575247, "CIDEr": 8.661382583442191e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.13333333333333333, "f": 0.15094339622641512, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a dog lying on a bed in front of a fireplace. The dog is wearing a collar and tag on its neck. The bed is covered in a brown blanket. The fireplace has a large flame burning in it. The room is dimly lit by a lamp on the table"}, "112378": {"image_id": 112378, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.14724793258964716, "ROUGE_L": 0.18908865468071917, "CIDEr": 1.223682647988706e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2, "f": 0.1886792452830189, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a table with two chairs and a hammock in the background. There are palm trees in the background and a beach in the distance. The sky is blue and there are clouds in the sky. The table and chairs are made of wood and have a white tablecloth on them."}, "293811": {"image_id": 293811, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.11651034560483009, "Bleu_3": 0.0647519709524591, "Bleu_4": 8.627614350761504e-06, "METEOR": 0.161898977402151, "ROUGE_L": 0.18780788177339902, "CIDEr": 1.2213760376406913e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a baseball game in progress. There are several players on the field, including a pitcher and a catcher. The pitcher is throwing the ball to the catcher, who is holding his glove up to catch it. The other players are standing on the field, watching the game. The stands"}, "285534": {"image_id": 285534, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.1390596095466697, "Bleu_4": 0.0865148073184506, "METEOR": 0.24953819133284053, "ROUGE_L": 0.3051907442151345, "CIDEr": 3.3752649656223385e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.18181818181818182, "f": 0.20689655172413793, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a woman holding a stuffed animal in her arms. The woman is wearing a red shirt and black pants. The stuffed animal is a white teddy bear with blue eyes and a pink nose. The woman is smiling and looking down at the stuffed animal. The background of"}, "192714": {"image_id": 192714, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.1415984650784514, "Bleu_3": 7.14361653643535e-07, "Bleu_4": 1.6119076650872648e-09, "METEOR": 0.19879167971243442, "ROUGE_L": 0.19709208400646203, "CIDEr": 1.5874478883066267e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a street with a few cars parked on the side of the road. There are buildings on either side of the street, with windows and doors. The sky is clear and blue, with a few clouds in the distance. The light pole is green and has a traffic light on it. The street is"}, "510798": {"image_id": 510798, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.07930515857033198, "Bleu_3": 4.945382002622933e-07, "Bleu_4": 1.240958731067451e-09, "METEOR": 0.13472220064772553, "ROUGE_L": 0.21403508771929822, "CIDEr": 9.788424570848104e-12, "SPICE": {"All": {"pr": 0.125, "re": 0.10344827586206896, "f": 0.11320754716981132, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a baseball player hitting a ball on a field. The player is wearing a helmet and gloves, and the ball is flying through the air. There are several people in the stands watching the game. The field is green and there are trees in the background.\n\nThe image shows a baseball"}, "303358": {"image_id": 303358, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.15617933312062784, "Bleu_4": 0.11283678602769266, "METEOR": 0.25975993705141565, "ROUGE_L": 0.2692307692307692, "CIDEr": 8.769963967245162e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two elephants standing in a field with mountains in the background. The elephants are brown and have large ears. The sky is clear and blue.\n\nThe elephants are standing in a field with tall grass and some trees in the background. The elephants are brown and have"}, "66191": {"image_id": 66191, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.17831418028047516, "Bleu_3": 0.13473366913073784, "Bleu_4": 1.4798393066260672e-05, "METEOR": 0.2932457926803876, "ROUGE_L": 0.34936998854524626, "CIDEr": 3.463506645157852e-12, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a baseball player in a red jersey and white pants running towards the plate with a bat in his hand. The player is on a dirt field with a crowd of people watching from the stands. The sky is cloudy and there are lights on the field.\n\nThe image is taken"}, "89697": {"image_id": 89697, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.194191754997615, "Bleu_3": 0.14171480766163438, "Bleu_4": 0.08601230531574432, "METEOR": 0.27070827533845765, "ROUGE_L": 0.23788300835654594, "CIDEr": 7.695231670251538e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a couple sitting on a bench in a park. The man is holding the woman's hand and they are looking into each other's eyes. The bench is made of wood and has a rustic look to it. The trees in the background are tall and green, and there is a"}, "503799": {"image_id": 503799, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.2550510152998425, "Bleu_3": 0.19056453812361543, "Bleu_4": 0.13170419431721997, "METEOR": 0.2987869107814186, "ROUGE_L": 0.3386798272671191, "CIDEr": 2.5328027490519553e-09, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man on a skateboard riding down a sidewalk in front of a house. The man is wearing a black shirt and shorts, and has a helmet on his head. The skateboard has a red and blue stripe on it. The sky is blue and there"}, "256838": {"image_id": 256838, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.08217664461402949, "Bleu_4": 1.0264051022519406e-05, "METEOR": 0.23663807211076848, "ROUGE_L": 0.25894481503941785, "CIDEr": 5.581128608319295e-12, "SPICE": {"All": {"pr": 0.1875, "re": 0.13043478260869565, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The train is a silver and white subway car with a number on the side. It is pulling into a station with a sign that reads \"5:00 AM\"\n\nThe train is a silver and white subway car with a number on the side. It is pulling into a station with a sign that"}, "461839": {"image_id": 461839, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.17458222992646102, "Bleu_3": 0.08423190681730008, "Bleu_4": 1.0455985518811585e-05, "METEOR": 0.18411693438844942, "ROUGE_L": 0.18496058217101274, "CIDEr": 1.9954286774670562e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.13793103448275862, "f": 0.14545454545454548, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a bedroom with a desk, chair, and lamp. The walls are painted white and there are windows on either side of the room. The floor is made of hardwood and there is a rug in the middle of the room. The room has a large window with curtains on either side."}, "515612": {"image_id": 515612, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.22677868380095453, "Bleu_3": 0.17497570119022854, "Bleu_4": 0.12287579518093225, "METEOR": 0.2841876378094491, "ROUGE_L": 0.3100381194409149, "CIDEr": 7.039010736729715e-09, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2702702702702703, "f": 0.3076923076923077, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6153846153846154, "re": 0.6666666666666666, "f": 0.64, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}}, "caption": "The image shows a man sitting on a bench playing a keyboard. He is wearing a white shirt and black pants, and has a black hat on his head. The background is a concrete wall with graffiti on it.\n\nThe image is in black and white, with the man's"}, "408534": {"image_id": 408534, "Bleu_1": 0.3199999999936, "Bleu_2": 0.18070158057739935, "Bleu_3": 0.08794832144810152, "Bleu_4": 1.0968473790380014e-05, "METEOR": 0.22301475510752675, "ROUGE_L": 0.23252858958068615, "CIDEr": 1.304998204184895e-10, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.30434782608695654, "f": 0.2692307692307692, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a wetsuit and holding a surfboard. The sky is clear and there are no clouds in the sky. The water is choppy and there are whitecaps on the waves. The person is standing on"}, "321742": {"image_id": 321742, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.12634404006922517, "Bleu_4": 0.08051110007483202, "METEOR": 0.2213808483376468, "ROUGE_L": 0.3051907442151345, "CIDEr": 1.3351923219849672e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of motorcycles parked in a parking lot. The motorcycles are black and have a sleek design. They are parked next to each other and appear to be in good condition. There are no people in the image. The background is a concrete parking lot with a"}, "149469": {"image_id": 149469, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1543033499589101, "Bleu_3": 7.971700074705258e-07, "Bleu_4": 1.8216869827152143e-09, "METEOR": 0.21602339800280365, "ROUGE_L": 0.2663755458515284, "CIDEr": 7.909243997077173e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is a pizza with various toppings on it. There are slices of cheese, tomato, and pepperoni on top of the pizza. The pizza is on a plate with a fork and knife next to it. There is a glass of water on the table next to the"}, "355919": {"image_id": 355919, "Bleu_1": 0.49999999998611117, "Bleu_2": 0.39641248357487724, "Bleu_3": 0.16657324362289827, "Bleu_4": 1.9345299022264874e-05, "METEOR": 0.2956001201729111, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.0007027978212446045, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.13333333333333333, "f": 0.14285714285714288, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a pizza with pepperoni and mushrooms on top of a white plate. There is a drink cup on the side of the plate. The table has a white tablecloth and a red napkin."}, "369045": {"image_id": 369045, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.12091150252325192, "Bleu_4": 0.07599442723764853, "METEOR": 0.21106546083599811, "ROUGE_L": 0.21682464454976302, "CIDEr": 1.7399364826710257e-13, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14285714285714285, "f": 0.14545454545454545, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people walking on a sidewalk in front of a large brick building with a clock tower on top. The building has a large dome on top and is surrounded by trees and other buildings. The sky is clear and blue.\n\nThe image is taken from a bird's eye view"}, "439589": {"image_id": 439589, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.09124485969890858, "Bleu_3": 5.698161672784481e-07, "Bleu_4": 1.4319831453628615e-09, "METEOR": 0.16462956763274647, "ROUGE_L": 0.24416277518345564, "CIDEr": 2.007361442590808e-08, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.22727272727272727, "f": 0.20408163265306123, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of trains parked in a train yard. The trains are all different colors and have different numbers on them. There are also some people standing around the trains, looking at them. The background is a concrete wall with some graffiti on it."}, "467696": {"image_id": 467696, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.161880977056518, "Bleu_3": 0.10026270761741987, "Bleu_4": 0.06667484695194902, "METEOR": 0.18650578318856545, "ROUGE_L": 0.24970760233918127, "CIDEr": 3.026588774196366e-08, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.08333333333333333, "f": 0.07547169811320754, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a dock in front of a large boat. The people are wearing different types of clothing, including suits and dresses. There are several other boats in the background. The dock is made of wood and has a railing around it. The water is calm and"}, "519916": {"image_id": 519916, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.17472060423831776, "Bleu_3": 0.11070534149073814, "Bleu_4": 0.0745183556152167, "METEOR": 0.18371910077781747, "ROUGE_L": 0.23843648208469054, "CIDEr": 3.0864890626980817e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23076923076923078, "f": 0.25531914893617025, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of people playing volleyball on a sandy beach. The players are wearing white shirts and black shorts, and they are holding volleyballs in their hands. The sky is cloudy and there are no other people or objects in the image.\n\nThe image"}, "359136": {"image_id": 359136, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.21182963642996727, "Bleu_3": 0.13911530022530355, "Bleu_4": 0.08609583710213467, "METEOR": 0.25937523246145805, "ROUGE_L": 0.2983695652173913, "CIDEr": 1.888668637136692e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.21428571428571427, "f": 0.15, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 1.0, "f": 0.2222222222222222, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a woman lying on the floor in a bathroom. She is wearing black boots and a black top. There is a bathtub in the background. The walls are white and there is a window in the background. The floor is made of tile.\n\nThe woman is lying on the"}, "514904": {"image_id": 514904, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.21128856367777224, "Bleu_3": 0.15604075333783501, "Bleu_4": 0.11336958836408244, "METEOR": 0.257723655018851, "ROUGE_L": 0.2663755458515284, "CIDEr": 8.377757207839955e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.19230769230769232, "f": 0.19230769230769232, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a woman holding a hot dog in her hand. She is wearing a black and white striped shirt and a pair of sunglasses. She is standing on the sidewalk in front of a building with a red awning. There are several bicycles parked on the sidewalk"}, "333998": {"image_id": 333998, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.2084219669570065, "Bleu_3": 0.0981091958911253, "Bleu_4": 1.2035916294672372e-05, "METEOR": 0.2600421879164446, "ROUGE_L": 0.27371794871794874, "CIDEr": 5.066094465200126e-09, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14814814814814814, "f": 0.14814814814814814, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a kitchen with wooden cabinets, a stove, and a refrigerator. There is a sink and a dishwasher in the kitchen. The floor is made of hardwood and there is a rug in the middle of the room. The walls are painted a light yellow color."}, "395290": {"image_id": 395290, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.20921530481644351, "Bleu_3": 0.1794746125536907, "Bleu_4": 0.14521665550377105, "METEOR": 0.2621948526326521, "ROUGE_L": 0.33190827827438785, "CIDEr": 3.012005216274074e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.22727272727272727, "f": 0.1923076923076923, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a white cat sitting on the hood of a car. The cat is looking out of the windshield and appears to be enjoying the view. The car is parked on the side of the road and there are buildings in the background. The sky is clear and there are no clouds. The"}, "254892": {"image_id": 254892, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 6.980462899277689e-07, "Bleu_4": 1.6401693914301652e-09, "METEOR": 0.21573655165166564, "ROUGE_L": 0.19830949284785435, "CIDEr": 1.0041366025333639e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2631578947368421, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The giraffe is standing on the grass in front of a fence. It is wearing a halter and has a long neck. The fence is made of wood and has a gate in the middle. There are trees in the background.\n\nThe giraffe is standing on the grass in front"}, "517822": {"image_id": 517822, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.25588315785430304, "Bleu_3": 0.20294526915143524, "Bleu_4": 0.15280059828982856, "METEOR": 0.24918191346151153, "ROUGE_L": 0.28222075346992725, "CIDEr": 1.1781224898215085e-08, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1, "f": 0.10344827586206898, "fn": 27.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a young boy playing with a frisbee in a park. The boy is wearing a red shirt and blue shorts, and is running towards the camera with the frisbee in his hand. The grass is green and there are trees in the background.\n\nThe image is"}, "114549": {"image_id": 114549, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.13937882544862468, "Bleu_3": 0.07557770425284015, "Bleu_4": 9.95249808335953e-06, "METEOR": 0.23808916139893396, "ROUGE_L": 0.20346897931954633, "CIDEr": 6.543868283792071e-10, "SPICE": {"All": {"pr": 0.3225806451612903, "re": 0.3225806451612903, "f": 0.3225806451612903, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 10.0}, "Relation": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.6363636363636364, "f": 0.6086956521739131, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image shows a bunch of bananas hanging from a tree. The tree is tall and green, with leaves on the branches. The bananas are yellow and ripe, with some of them already fallen to the ground. There are no other plants or objects in the image."}, "145215": {"image_id": 145215, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.12121830534381621, "Bleu_3": 0.06739562828886043, "Bleu_4": 8.983577738158223e-06, "METEOR": 0.24726429563508612, "ROUGE_L": 0.1937738246505718, "CIDEr": 7.248908466460528e-11, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.16129032258064516, "f": 0.17543859649122806, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a person standing on the beach, looking out at the ocean. The person is wearing a black wetsuit and holding a surfboard. The waves are crashing against the shore and the sky is cloudy.\n\nThe image is taken from a low angle, looking down at the person"}, "380693": {"image_id": 380693, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.19999999999603923, "Bleu_3": 0.11775100856360317, "Bleu_4": 0.07636830779166373, "METEOR": 0.2566285233087117, "ROUGE_L": 0.314974182444062, "CIDEr": 9.110585198875092e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two sheep standing in a snowy field. They are both white with black spots on their backs. One of the sheep is eating grass from the ground while the other is standing next to it. The background is a snowy field with no other animals or objects visible."}, "532669": {"image_id": 532669, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.15249857032909853, "Bleu_3": 0.08211593041013024, "Bleu_4": 1.0780144922571383e-05, "METEOR": 0.18365098048783127, "ROUGE_L": 0.214185393258427, "CIDEr": 5.942102467064472e-08, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image is of a storefront with a large window display of colorful umbrellas hanging from the ceiling. The storefront has a black and white striped awning over the door and a sign that reads \"Umbrella Emporium\" in white letters. The sidewalk in front"}, "375902": {"image_id": 375902, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.08206099398471602, "Bleu_3": 5.02727403256082e-07, "Bleu_4": 1.2502549517017175e-09, "METEOR": 0.12001872045319377, "ROUGE_L": 0.16878804648588822, "CIDEr": 4.1537953202982414e-13, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man standing on top of a snowy mountain, holding a ski pole in one hand and a flag in the other. He is wearing a black and white ski suit and a black helmet. There are several other people in the background, some of whom are also skiing. The sky is"}, "105951": {"image_id": 105951, "Bleu_1": 0.16363636363338846, "Bleu_2": 0.1100963765106158, "Bleu_3": 0.061153792306271486, "Bleu_4": 8.143605172498537e-06, "METEOR": 0.17415801622390226, "ROUGE_L": 0.17951736315479697, "CIDEr": 2.736804769043786e-14, "SPICE": {"All": {"pr": 0.12, "re": 0.09375, "f": 0.10526315789473684, "fn": 29.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person holding a plate with food on it. The person is wearing a white shirt and black pants. The food on the plate appears to be fried and has a yellow sauce on top. There is a fork on the plate as well. The background is a white wall with a"}, "97679": {"image_id": 97679, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.16256402218685123, "Bleu_3": 8.569060201339632e-07, "Bleu_4": 1.9792649376644904e-09, "METEOR": 0.21020062245001478, "ROUGE_L": 0.20890410958904113, "CIDEr": 0.0003381666598838138, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two cars parked on a dirt road in front of a mountain range. The cars are white and have roof racks on them. There are no people in the image. The sky is cloudy and there is snow on the ground."}, "433505": {"image_id": 433505, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.10628002947657487, "Bleu_4": 0.07071775095333474, "METEOR": 0.2458779808419103, "ROUGE_L": 0.29415310427968655, "CIDEr": 7.18927326538606e-11, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.047619047619047616, "f": 0.04081632653061224, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a desk with a computer, keyboard, and mouse on it. There is also a lamp on the desk. The room is well lit and there are no other objects in the room.\n\nThe image shows a desk with a computer, keyboard, and mouse on it. There is also"}, "465424": {"image_id": 465424, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.2581988897420478, "Bleu_3": 0.17589664289627485, "Bleu_4": 0.10318886931044728, "METEOR": 0.28400716300782125, "ROUGE_L": 0.3202099737532808, "CIDEr": 6.128350121271782e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on the sidewalk in front of a building. They are all wearing leather jackets and riding motorcycles. There are several cars parked on the street and a few people walking by. The sky is cloudy and there are some trees in the background."}, "312024": {"image_id": 312024, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.2420412359447775, "Bleu_3": 0.12867139517270657, "Bleu_4": 1.4093312033343197e-05, "METEOR": 0.2574792974251458, "ROUGE_L": 0.3044925124792013, "CIDEr": 1.778008440400577e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image is of a small bird with a black and white striped body and a long, thin tail. It is standing on the grass in a field with a few blades of grass growing out of the ground. The bird is looking down at the ground with its beak open. The sky is blue and there"}, "55074": {"image_id": 55074, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.12121830534381621, "Bleu_3": 6.739562828886045e-07, "Bleu_4": 1.5975311320250798e-09, "METEOR": 0.14994453319723172, "ROUGE_L": 0.18263473053892215, "CIDEr": 2.765818741167346e-09, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.23809523809523808, "f": 0.25641025641025644, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a baseball player hitting a ball on a field. The player is wearing a helmet and batting gloves, and the ball is flying through the air. There are two umpires standing on the field, one holding a catcher's mask and the other holding a glove. The"}, "61418": {"image_id": 61418, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.11895773785545558, "Bleu_3": 6.522364605376366e-07, "Bleu_4": 1.5348336186916813e-09, "METEOR": 0.16012862721496277, "ROUGE_L": 0.21908296420447745, "CIDEr": 6.611080127003673e-12, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.15151515151515152, "f": 0.17857142857142858, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a black and white photograph of a group of children playing tic tac toe on a wooden board on the deck of a ship. The children are wearing shorts and t-shirts and are standing around the board, which is marked with numbers and letters. There is a large ship in the"}, "153994": {"image_id": 153994, "Bleu_1": 0.16326530611911708, "Bleu_2": 0.1010152544531381, "Bleu_3": 0.06010242872773111, "Bleu_4": 8.288569027871298e-06, "METEOR": 0.18852219650245483, "ROUGE_L": 0.23091482649842268, "CIDEr": 3.995228330265739e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.22727272727272727, "f": 0.1923076923076923, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person standing under an umbrella on a rainy day. The person is wearing a black jacket and black pants, and has a black hat on their head. The umbrella is open and has a white logo on it. The background is a dark green color."}, "2157": {"image_id": 2157, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.22496063532707972, "Bleu_3": 0.13985578774299565, "Bleu_4": 1.6602928882351334e-05, "METEOR": 0.2028928924871295, "ROUGE_L": 0.2971468336812804, "CIDEr": 5.610103062411403e-05, "SPICE": {"All": {"pr": 0.12, "re": 0.14285714285714285, "f": 0.13043478260869565, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a table set with a cake, fruit, cheese, crackers, and wine glasses. There are also plates of food on the table. The tablecloth is red and white. The background is a garden with trees and flowers."}, "561523": {"image_id": 561523, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.15414152154556138, "Bleu_3": 7.702150134515398e-07, "Bleu_4": 1.730081016760377e-09, "METEOR": 0.19598707878416458, "ROUGE_L": 0.24124293785310735, "CIDEr": 9.605481354212379e-12, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.14285714285714285, "f": 0.17543859649122806, "fn": 30.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.058823529411764705, "f": 0.1, "fn": 16.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a table set for a meal with glasses of champagne on it. There are two people sitting at the table, one with a laptop and the other with a book. The table is set with white linens and a centerpiece of flowers. The background is a wall with windows and a"}, "361073": {"image_id": 361073, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.12171612388780342, "Bleu_3": 0.0943004729222904, "Bleu_4": 0.07536020411278634, "METEOR": 0.16429637494258686, "ROUGE_L": 0.21095100864553315, "CIDEr": 1.2810648512201134e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image is of a bus parked on the side of the road in the snow. The bus is white with blue and green stripes on the side. There are no people in the image.\n\nThe bus is parked on the side of the road in the snow. The bus is white with blue and"}, "359442": {"image_id": 359442, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.12712834523041283, "Bleu_3": 6.730845772977349e-07, "Bleu_4": 1.5561497729243848e-09, "METEOR": 0.17351487371269816, "ROUGE_L": 0.17579250720461098, "CIDEr": 1.3458975164613507e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 1.0, "f": 0.4615384615384615, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a train track with graffiti on the sides of the cars. The cars are parked on the track and there are no people in the image. The sky is clear and there are no clouds. The image is taken from a high angle and the perspective is straight on.\n\nThe image is"}, "321943": {"image_id": 321943, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.20604084591910862, "Bleu_3": 0.16085534342964874, "Bleu_4": 0.11359039689503823, "METEOR": 0.34734331725141604, "ROUGE_L": 0.3544450900639163, "CIDEr": 1.2254278942691353e-11, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.13333333333333333, "f": 0.09523809523809523, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a vase with pink flowers in it. The flowers are in a blue vase with a white rim. The vase is sitting on a wooden table with a white tablecloth. There is a wooden chair next to the table. The background is a green lawn with trees in the distance"}, "363527": {"image_id": 363527, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.12701286121266542, "Bleu_4": 0.09514824286433506, "METEOR": 0.25110747701663516, "ROUGE_L": 0.24007646463510626, "CIDEr": 5.606497177472432e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15, "f": 0.13043478260869565, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a red double decker bus parked on the side of the road. The bus has a large advertisement on the side of it, and there are people standing on the sidewalk looking at it.\n\nThe image is taken from a high angle, looking down on the bus and the people"}, "468405": {"image_id": 468405, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.1797866299868988, "Bleu_3": 0.08480334272970087, "Bleu_4": 1.0406600737344433e-05, "METEOR": 0.254320607413973, "ROUGE_L": 0.27743035815804434, "CIDEr": 2.7410960087004193e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21739130434782608, "f": 0.18867924528301885, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a truck driving down a street in a city. The truck is white and has a blue and white striped canopy on top. There are several cars parked on the side of the road and people walking on the sidewalk. The sky is clear and there are no buildings in the background"}, "121123": {"image_id": 121123, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.18171094607444632, "Bleu_3": 0.14792923196271532, "Bleu_4": 0.12685657992627591, "METEOR": 0.28404109144324974, "ROUGE_L": 0.28554710356933877, "CIDEr": 8.420354318121006e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man sitting on the back of an elephant, with a woman standing next to him. The elephant is wearing a saddle and the man is holding onto the back of it. The woman is wearing a white dress and has a smile on her face. The background is a"}, "325208": {"image_id": 325208, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.06989787123302858, "Bleu_4": 9.090870283563952e-06, "METEOR": 0.14792159868735255, "ROUGE_L": 0.15127092374457532, "CIDEr": 1.4294599415914914e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This image shows a table with various items on it, including a pair of scissors, a pen, and a book. The table is made of wood and has a red and white checkered pattern on it. There are also several books and papers on the table.\n\nThe image is taken from a museum"}, "473214": {"image_id": 473214, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 0.08709642720538069, "Bleu_4": 0.05970344881146218, "METEOR": 0.19614462678800743, "ROUGE_L": 0.2412259021255561, "CIDEr": 6.03188815998145e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.25, "f": 0.20408163265306123, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a narrow street with tall buildings on either side. There are no cars parked on the street, but there are some parked on the side of the road. The buildings are made of brick and have large windows. There are no people in the image.\n\nThe image is taken from a low"}, "225198": {"image_id": 225198, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.13730875909260604, "Bleu_3": 0.09102321240662335, "Bleu_4": 1.1138202232666471e-05, "METEOR": 0.241925231418399, "ROUGE_L": 0.2688916876574307, "CIDEr": 2.704968853686232e-11, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.07692307692307693, "f": 0.05128205128205129, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a stuffed animal sitting on a bed with headphones on its head. The bed has a blue and white striped blanket on it and there are pillows and a lamp on the bed. The wall behind the bed has a blue and white striped pattern.\n\nThe image is taken"}, "142562": {"image_id": 142562, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.07126876576918603, "Bleu_4": 9.270974964697601e-06, "METEOR": 0.2181743785015466, "ROUGE_L": 0.2167219327333018, "CIDEr": 9.480490630312146e-12, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a horse jumping over a barrier in a field. The horse is wearing a saddle and bridle and is being ridden by a person on the back. The person is wearing a helmet and is holding the reins with both hands. The background is a green field with trees"}, "107853": {"image_id": 107853, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.12094486170917773, "Bleu_3": 0.06825571246936571, "Bleu_4": 9.168559860005064e-06, "METEOR": 0.18205193072107995, "ROUGE_L": 0.23461538461538461, "CIDEr": 1.2064869618007208e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.23529411764705882, "f": 0.16326530612244897, "fn": 13.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person skateboarding down a ramp in a parking garage. The person is wearing a black shirt and pants, and has a red helmet on their head. The ramp is made of metal and has a yellow and black striped pattern on it. The walls"}, "315474": {"image_id": 315474, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.12451456127000796, "Bleu_3": 7.231340467136466e-07, "Bleu_4": 1.7534731062750036e-09, "METEOR": 0.2090705115766276, "ROUGE_L": 0.2616154395997141, "CIDEr": 1.1745260213252659e-07, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.25806451612903225, "f": 0.30769230769230765, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.46153846153846156, "f": 0.5217391304347826, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a refrigerator with several beer bottles inside. The refrigerator is made of metal and has a glass door that is open. There are several beer bottles on the shelves inside the refrigerator. The beer bottles are different sizes and shapes."}, "365139": {"image_id": 365139, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2680359137985001, "Bleu_3": 0.17794751630848127, "Bleu_4": 1.8322150534285102e-05, "METEOR": 0.2958865582795543, "ROUGE_L": 0.34560906515580736, "CIDEr": 7.87565795016757e-11, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.4, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a small dog sitting in a sink, looking up at the camera. The dog is wearing a collar and has a tag on its neck. The sink is filled with water and there are two slices of pizza on the counter. The room appears to be a kitchen.\n\nThe image"}, "137844": {"image_id": 137844, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.20195126571496114, "Bleu_3": 0.11851564692759443, "Bleu_4": 1.3646505647648106e-05, "METEOR": 0.24299268935777085, "ROUGE_L": 0.26116207951070336, "CIDEr": 3.8720252276256546e-11, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1, "f": 0.12244897959183673, "fn": 27.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a person performing a trick on a skateboard in a skate park. The person is wearing a black shirt and black pants, and has a helmet on their head. The skate park is surrounded by a fence and there are rocks and trees in the background. The sky"}, "185950": {"image_id": 185950, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.19026059765810296, "Bleu_3": 0.15354390128889117, "Bleu_4": 0.12201289225771661, "METEOR": 0.2113456202669781, "ROUGE_L": 0.25722891566265055, "CIDEr": 2.5861774397262283e-11, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.1724137931034483, "f": 0.17543859649122806, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a young man performing a trick on a skateboard in a skate park. He is wearing a black shirt and jeans, and has his arms extended as he jumps off the ramp. The background is a blue sky with clouds and trees. The image is in focus and well"}, "383119": {"image_id": 383119, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.13479285035956426, "Bleu_3": 7.043309782606502e-07, "Bleu_4": 1.6178566881552979e-09, "METEOR": 0.16591443624032373, "ROUGE_L": 0.17468499427262313, "CIDEr": 3.437470953729908e-12, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image is of a river with several boats docked on the shore. The boats are old and rusted, and there are several people standing on the shore. The sky is cloudy and there are some buildings in the background.\n\nThe image is in black and white, and the boats are the only color"}, "218960": {"image_id": 218960, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.20100756304815393, "Bleu_3": 0.1450116762655686, "Bleu_4": 0.08750873255009596, "METEOR": 0.2570931987636461, "ROUGE_L": 0.3099943534726144, "CIDEr": 1.4653571426285627e-12, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.23809523809523808, "f": 0.1923076923076923, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a brown bear standing in a field of tall grass. The bear is looking down at the ground and appears to be sniffing something. The sky is cloudy and there are trees in the background.\n\nThe bear is standing in a field of tall grass, looking down at the ground and sn"}, "129362": {"image_id": 129362, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.19802950859148932, "Bleu_3": 0.15769573216073673, "Bleu_4": 0.11247951467489567, "METEOR": 0.203263685966947, "ROUGE_L": 0.29397590361445786, "CIDEr": 4.49938757159058e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a small bird perched on a branch in a jungle environment. The bird has a white belly and a brown back, with a black beak and legs. The bird is looking down at the camera with its beak open. The background is a dense jungle with tall trees and"}, "435894": {"image_id": 435894, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 0.07417848716778727, "Bleu_4": 9.65348251762417e-06, "METEOR": 0.1562011374513858, "ROUGE_L": 0.1586475942782835, "CIDEr": 2.7863806742355187e-11, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.20833333333333334, "f": 0.19607843137254902, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person standing in front of a tent with a dog sitting next to it. The tent is green and has a large, white banner on it that reads \"Snowboarding Adventures\". The person is wearing a black and white jacket and has a pair of snowboarding gog"}, "485673": {"image_id": 485673, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 6.052669898452478e-07, "Bleu_4": 1.4440016772249673e-09, "METEOR": 0.18967850835004263, "ROUGE_L": 0.1821983273596177, "CIDEr": 1.0853827824576869e-12, "SPICE": {"All": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6, "f": 0.631578947368421, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a baseball game in progress. There are several players on the field, including a pitcher and a catcher. The crowd is watching from the stands. The field is green and there are several trees in the background.\n\nThe image shows a baseball game in progress. There are several players on the"}, "546965": {"image_id": 546965, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 0.07913235571850134, "Bleu_4": 9.880177230491347e-06, "METEOR": 0.21190521050897987, "ROUGE_L": 0.21542083578575633, "CIDEr": 1.369062997084164e-13, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.23529411764705882, "f": 0.186046511627907, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a truck with several cars on the back, parked on the side of a road. The truck is white and has a large logo on the side. The cars are all different colors and appear to be parked in a line. There are no people in the image. The sky is cloud"}, "116861": {"image_id": 116861, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.1772810520820019, "Bleu_3": 0.1094051585098822, "Bleu_4": 1.2919743313490496e-05, "METEOR": 0.20462066189551634, "ROUGE_L": 0.2594167679222357, "CIDEr": 1.3858451742034853e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.18518518518518517, "f": 0.18518518518518517, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman lying on a couch with her arms around a stuffed animal. She is wearing a white shirt and pink pajamas. The couch is covered in a brown and white striped pattern. There is a window in the background with a view of the sky. The"}, "240565": {"image_id": 240565, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 0.07777190244898266, "Bleu_4": 1.0056053706911773e-05, "METEOR": 0.24988774646647105, "ROUGE_L": 0.26940063091482647, "CIDEr": 2.2821772700620768e-10, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bathroom with three urinals on the wall. The walls are made of tiled green and white. There are no toilets or sinks in the bathroom. The floor is made of green tiles. The bathroom has no windows. The lighting is bright and there are no"}, "539226": {"image_id": 539226, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.15075567228616532, "Bleu_3": 0.09441938915540041, "Bleu_4": 1.1226048713419345e-05, "METEOR": 0.2132526365601706, "ROUGE_L": 0.21682464454976302, "CIDEr": 5.831759164799713e-14, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a plane flying in the sky with a light on the wing\n\nThe plane is flying in the sky with a light on the wing. The sky is blue and there are some clouds in the background. The light on the wing is shining brightly and the plane is flying smoothly. There is"}, "361831": {"image_id": 361831, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.12121830534381622, "Bleu_3": 6.739562828886045e-07, "Bleu_4": 1.59753113202508e-09, "METEOR": 0.2471099290203124, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.024879686096513e-10, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07692307692307693, "f": 0.0851063829787234, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The sign is a white wooden sign with black letters that reads `fishing alley'\n\nThe sign is attached to a wooden fence that is painted black and has a white stripe running along the top. The fence is surrounded by trees and bushes.\n\nThe sign is in good condition and"}, "44839": {"image_id": 44839, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.24836183164306555, "Bleu_3": 0.18218943070465532, "Bleu_4": 0.1380162415922358, "METEOR": 0.282451077254059, "ROUGE_L": 0.3190005810575247, "CIDEr": 3.1764092652562726e-11, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.1724137931034483, "f": 0.18181818181818185, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of children sitting at a table with a large cake in the center. The children are all wearing party hats and holding forks and knives. There are also several adults standing around the table, looking on as the children eat their cake. The walls of the room are"}, "312384": {"image_id": 312384, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 0.08722608547574774, "Bleu_4": 1.0787871557193922e-05, "METEOR": 0.17624494722026252, "ROUGE_L": 0.25722891566265055, "CIDEr": 4.1273776023450614e-12, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.14285714285714285, "f": 0.1081081081081081, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a street with cars driving on it. There are tall buildings in the background. The sky is clear and blue.\n\nThe image is taken from a high angle, looking down on the street. The camera is positioned on the sidewalk, facing the street. The lighting is bright and clear"}, "1089": {"image_id": 1089, "Bleu_1": 0.3962264150868637, "Bleu_2": 0.2760387427794136, "Bleu_3": 0.144034534600296, "Bleu_4": 0.08792400740713413, "METEOR": 0.22251351925526955, "ROUGE_L": 0.2623857439127429, "CIDEr": 1.3388760800222513e-09, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.25925925925925924, "f": 0.2641509433962264, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a table with his head in his hands. He is wearing a suit and tie and has a serious expression on his face. The background is a dark wood panelled room with a large window in the background. The man appears to be deep in thought."}, "361992": {"image_id": 361992, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 0.08618888098293648, "Bleu_4": 1.0746774156673132e-05, "METEOR": 0.1783809486934069, "ROUGE_L": 0.24002248454187747, "CIDEr": 5.023277024748736e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.17391304347826086, "f": 0.19999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two young girls standing in front of a horse. One of the girls is holding a bowl of food while the other is holding a brush. The horse is standing in the background, looking at the girls.\n\nThe girls are wearing tan shirts and black pants, and the"}, "367818": {"image_id": 367818, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.23302069120966015, "Bleu_3": 0.1757638906625966, "Bleu_4": 0.13502946183195833, "METEOR": 0.26876553873378933, "ROUGE_L": 0.2482558139534883, "CIDEr": 7.814683067726545e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1724137931034483, "f": 0.16949152542372883, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The woman is standing next to a brown horse in a green field. The horse is wearing a red halter and bridle. The woman is holding a lead rope in her hand and smiling at the horse. The sky is blue and there are trees in the background.\n\nThe woman is wearing"}, "399665": {"image_id": 399665, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.22190634114281918, "Bleu_3": 0.11667896745206957, "Bleu_4": 1.5169250360908672e-05, "METEOR": 0.3067019659063997, "ROUGE_L": 0.34971334971334966, "CIDEr": 0.0007745153625378848, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.08695652173913043, "f": 0.08888888888888888, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This image shows a bowl of white beans and broccoli in a white sauce, with a spoon and fork on the side. The bowl is on a white table with a white background."}, "386879": {"image_id": 386879, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2804120134978465, "Bleu_3": 0.17371366811579753, "Bleu_4": 0.10447498658372112, "METEOR": 0.24426289535232554, "ROUGE_L": 0.31063017186505404, "CIDEr": 1.0744424952659022e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a woman in a red tennis dress holding a tennis racket. She is standing in a grassy area with trees in the background. The woman is smiling and appears to be enjoying the game. The image is in focus and the colors are vibrant."}, "567863": {"image_id": 567863, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.14002800840008178, "Bleu_3": 0.09222102361569189, "Bleu_4": 0.06325187933904816, "METEOR": 0.25096630733207886, "ROUGE_L": 0.26293103448275856, "CIDEr": 5.718220512989119e-11, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2857142857142857, "f": 0.24000000000000002, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a giraffe and its baby standing next to a fence. The giraffe is brown and has spots on its back. The baby is brown and has spots on its back as well. They are both standing on the ground and looking at each other. The fence is made of"}, "172702": {"image_id": 172702, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.14280110945625535, "Bleu_3": 0.09406593130377755, "Bleu_4": 0.06453034104238825, "METEOR": 0.1790591767197701, "ROUGE_L": 0.18654434250764526, "CIDEr": 5.432443532317742e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The sign is a street sign with the name of the street written in Chinese characters. The sign is mounted on a pole and is illuminated by streetlights. The street is lined with buildings and there are people walking on the sidewalk.\n\nThe image is taken at night and the streetlights"}, "513611": {"image_id": 513611, "Bleu_1": 0.3199999999936, "Bleu_2": 0.18070158057739935, "Bleu_3": 0.08794832144810152, "Bleu_4": 1.0968473790380014e-05, "METEOR": 0.19575253657444402, "ROUGE_L": 0.29947632555094916, "CIDEr": 0.01697179651634408, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.13333333333333333, "f": 0.126984126984127, "fn": 26.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of cows grazing in a green field. The cows are brown and black, and they are standing in a line, looking at the camera. There is a fence in the background, and trees in the distance. The sky is blue and cloudy.\n\nThe image is"}, "187285": {"image_id": 187285, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.16026009915056863, "Bleu_4": 0.1375449327243505, "METEOR": 0.26365430024244774, "ROUGE_L": 0.32864411852738695, "CIDEr": 1.3975461229591588e-08, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.08, "f": 0.06779661016949153, "fn": 23.0, "numImages": 1.0, "fp": 32.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.2222222222222222, "f": 0.16666666666666669, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a group of people surfing on a wave in the ocean. The sun is setting in the background, casting a warm orange glow over the scene. The surfers are wearing wetsuits and riding the wave with ease, their boards gliding through the water. The ocean is"}, "107516": {"image_id": 107516, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.1412673303879691, "Bleu_3": 0.10549005488471223, "Bleu_4": 0.0696091190691511, "METEOR": 0.18327600127629265, "ROUGE_L": 0.25707405177603854, "CIDEr": 2.3953104277855766e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.24, "f": 0.2181818181818182, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a kitchen with a large island in the center. There is a stove, oven, and refrigerator in the kitchen. The walls are painted a light color and there are windows on one side of the room. The floor is made of hardwood and there is a rug in the center of"}, "675": {"image_id": 675, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.10238251947041137, "Bleu_3": 0.05863398711091721, "Bleu_4": 7.929020238697525e-06, "METEOR": 0.1687932466909733, "ROUGE_L": 0.23961840628507297, "CIDEr": 1.0938417682764883e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.2631578947368421, "f": 0.22727272727272727, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black and white cat standing on its hind legs next to a bed with a lamp on it. The cat is looking at something on the bed.\n\nThe lamp is a white lamp with a shade on it. The bed has a blue and white striped blanket on it. There"}, "14600": {"image_id": 14600, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.19802950859148932, "Bleu_3": 0.14639174990113343, "Bleu_4": 1.59070055142381e-05, "METEOR": 0.26413967661928095, "ROUGE_L": 0.28175519630484985, "CIDEr": 4.035536722855593e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.125, "f": 0.14814814814814814, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.06666666666666667, "f": 0.09090909090909091, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is of a man holding an umbrella in the air. The man is wearing a black shirt and white pants, and has a green umbrella in his hand. The background is a concrete wall with a red and white striped pattern. The image is painted on a wall in a"}, "66397": {"image_id": 66397, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.09701425001261196, "Bleu_3": 5.76976768606882e-07, "Bleu_4": 1.4143550190666944e-09, "METEOR": 0.19678751465443806, "ROUGE_L": 0.22889305816135083, "CIDEr": 1.3337858415008246e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a person skiing down a snowy hill. The person is wearing a red jacket and black pants, and has a pair of skis on their feet. The snow is deep and there are trees in the background.\n\nThe image is taken in a winter setting, with snow covering"}, "520892": {"image_id": 520892, "Bleu_1": 0.1538461538431953, "Bleu_2": 0.10984700727408482, "Bleu_3": 0.07844142656278796, "Bleu_4": 9.962310935752862e-06, "METEOR": 0.14462760094947882, "ROUGE_L": 0.18373493975903615, "CIDEr": 1.0780437406341142e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13793103448275862, "f": 0.14035087719298248, "fn": 25.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The woman in the image is holding a hot dog in her hand. She is wearing a black jacket and a white shirt. The background is a green field with trees in the distance. The sky is blue and cloudy. The woman is smiling and appears to be enjoying her hot dog."}, "346687": {"image_id": 346687, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2285817953234835, "Bleu_3": 0.14539343121758774, "Bleu_4": 0.0885454171445769, "METEOR": 0.20680289284915923, "ROUGE_L": 0.32715748415407114, "CIDEr": 2.0073114766793307e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people on a surfboard in the water. They are all wearing life jackets and are standing on the board, which is floating on the water. The sky is blue and there are some clouds in the background. The water is calm and there are no waves.\n\nThe"}, "63939": {"image_id": 63939, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.24836183164306555, "Bleu_3": 0.19360515975280349, "Bleu_4": 0.16412989648742127, "METEOR": 0.27349719375392123, "ROUGE_L": 0.2959369314736203, "CIDEr": 2.3152506149353332e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10344827586206896, "f": 0.1276595744680851, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting around a table at a dinner party. They are all dressed in formal attire and appear to be enjoying themselves. The table is set with white linens and silverware, and there are candles on the table. The room is decorated with red and white ballo"}, "33882": {"image_id": 33882, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.214201664184383, "Bleu_3": 0.15529943088229656, "Bleu_4": 0.09398684880464063, "METEOR": 0.29989604066307163, "ROUGE_L": 0.3042123074182919, "CIDEr": 1.8729747846926894e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.11538461538461539, "f": 0.12499999999999997, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a young girl holding a teddy bear. She is wearing a pink dress and has long blonde hair. The background is white.\n\nThe image is a close up of the girl's face and the teddy bear she is holding. The girl is smiling and looking directly at"}, "371958": {"image_id": 371958, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.18164975363435543, "Bleu_3": 0.10758240552419991, "Bleu_4": 1.2439562377602817e-05, "METEOR": 0.2347400374614703, "ROUGE_L": 0.2872277810476751, "CIDEr": 5.948814345804079e-13, "SPICE": {"All": {"pr": 0.125, "re": 0.0967741935483871, "f": 0.10909090909090909, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a tall, stone church with a clock tower and a steeple. The church has a large, stone bell tower with a clock face on it. The clock is ticking away, and there are birds flying in the sky above it. The sky is a deep blue color with a few clouds scattered"}, "132622": {"image_id": 132622, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.14819171472405493, "Bleu_3": 0.07652745233046604, "Bleu_4": 9.829979956142771e-06, "METEOR": 0.16210942215323984, "ROUGE_L": 0.22584228063680117, "CIDEr": 3.268064080661825e-11, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a brown bear standing in a field of tall grass. The bear is looking down and appears to be sniffing the ground. The bear's fur is thick and shaggy, and its eyes are dark brown. The background is a green field with tall grasses and wildflowers. The"}, "470298": {"image_id": 470298, "Bleu_1": 0.1403508771905202, "Bleu_2": 0.10012523486257954, "Bleu_3": 0.07143616536435346, "Bleu_4": 9.06442292469654e-06, "METEOR": 0.23238837017239514, "ROUGE_L": 0.24247586598523563, "CIDEr": 2.845927471174453e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.8333333333333334, "f": 0.5555555555555556, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a polar bear swimming in a pool of water. The bear is wearing a harness and is being held by a person in a yellow suit. The person is standing on the edge of the pool and is holding the bear by the neck. The bear is swimming in the water and appears to"}, "444496": {"image_id": 444496, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.1883108942847125, "Bleu_3": 9.169191011404368e-07, "Bleu_4": 2.034441173199727e-09, "METEOR": 0.20198136443846748, "ROUGE_L": 0.2401574803149606, "CIDEr": 3.0817836934374166e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is a book cover with a glass bowl filled with sliced bananas. The book is titled \"Banana Cookbook\" and it appears to be a recipe book for cooking with bananas. The cover is yellow and has a picture of a banana on it. The book is"}, "550405": {"image_id": 550405, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.17407765595250352, "Bleu_3": 0.10457151389178666, "Bleu_4": 1.2177530069442514e-05, "METEOR": 0.199332180792211, "ROUGE_L": 0.2731707317073171, "CIDEr": 4.6598361792312646e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.21739130434782608, "f": 0.20833333333333331, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The laptop is sitting on a wooden table in a room with a window and a view of the outdoors. The laptop has a black screen and a keyboard with a mouse. There are two cups of coffee on the table next to the laptop. The room has a wooden floor and a wooden ceiling."}, "182056": {"image_id": 182056, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.13209470492933909, "Bleu_4": 0.09899454101416073, "METEOR": 0.24680766872967072, "ROUGE_L": 0.25553560742070613, "CIDEr": 8.837318844151173e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.15789473684210525, "f": 0.12244897959183673, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image is of a toilet in a bathroom. The toilet is white and has a seat and lid. The floor is made of tile and there is a toilet paper holder on the wall. The walls are painted white and there are no windows. The lighting is from overhead fluores"}, "193442": {"image_id": 193442, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 0.09955605444507261, "Bleu_4": 0.06881570893052942, "METEOR": 0.2281202299153592, "ROUGE_L": 0.27056139906222276, "CIDEr": 1.7978751205956725e-08, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 29.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}}, "caption": "The image shows a person holding a chocolate glazed donut in their hand. The donut has a hole in the center and is covered in chocolate glaze. The person's hand is visible in the foreground, with the donut resting on their palm. The background is a"}, "97899": {"image_id": 97899, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.13997719075795917, "Bleu_3": 0.10484680684954284, "Bleu_4": 1.2321792904178373e-05, "METEOR": 0.19175468491874978, "ROUGE_L": 0.21721068249258166, "CIDEr": 3.3594361327926947e-12, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.25925925925925924, "f": 0.27450980392156865, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a bus driving down the street. It is a large, white bus with pink and purple stripes on the side. The bus has a number on the front and back, and it is driving down the street with other cars and pedestrians. There are buildings on either side of the"}, "366178": {"image_id": 366178, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.2201927530212316, "Bleu_3": 0.12230758461254293, "Bleu_4": 0.07701746258925353, "METEOR": 0.2445183189720004, "ROUGE_L": 0.2324442025040827, "CIDEr": 4.381757264347895e-11, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.19230769230769232, "f": 0.20408163265306123, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a snowy road with a yellow sign on the side of the road. The sign has a picture of a person walking on the sidewalk. There are no other cars or people in the image. The sky is cloudy and there is no sunlight. The image is taken from a bird's"}, "563261": {"image_id": 563261, "Bleu_1": 0.333333333325926, "Bleu_2": 0.24618298195313262, "Bleu_3": 0.19172225782546998, "Bleu_4": 0.11381305436598617, "METEOR": 0.2980654069830341, "ROUGE_L": 0.38006230529595014, "CIDEr": 4.0186406624584984e-07, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.0625, "f": 0.07142857142857144, "fn": 30.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.14285714285714285, "f": 0.16, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image is a cupcake with a pink umbrella on top of it. The cupcake is sitting on a glass plate with a blue background. The umbrella is made of pink and white stripes. The cupcake has a pink and white frosting on top of"}, "286723": {"image_id": 286723, "Bleu_1": 0.19999999999500007, "Bleu_2": 0.1012739367058024, "Bleu_3": 6.462550193685986e-07, "Bleu_4": 1.6434349396413174e-09, "METEOR": 0.26030518239777745, "ROUGE_L": 0.28416149068322977, "CIDEr": 5.007665366915938e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a blue shirt and purple shorts, and has a tennis racket in her hand. The court is made of grass and there are trees in the background."}, "306931": {"image_id": 306931, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 0.07733118331435387, "Bleu_4": 9.806713568284028e-06, "METEOR": 0.1629080455130952, "ROUGE_L": 0.21721068249258166, "CIDEr": 4.035812353034817e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a baseball player wearing a black and white uniform, holding a baseball glove and looking at the camera\n\nThe image shows a baseball player wearing a black and white uniform, holding a baseball glove and looking at the camera. The player is standing on a dirt field with a fence"}, "234533": {"image_id": 234533, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.11455372707190037, "Bleu_4": 1.351928705097216e-05, "METEOR": 0.22749138531096405, "ROUGE_L": 0.28638497652582157, "CIDEr": 1.637039811304597e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2222222222222222, "f": 0.1951219512195122, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bicycle parked on the sidewalk next to a snow covered street. The bicycle has a basket on the front and a small box on the back. The box has a sign that reads, \"Bike Parking Only.\" The image is taken in the winter.\n\nThe"}, "349324": {"image_id": 349324, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.08979301819262463, "Bleu_4": 0.06199874625320648, "METEOR": 0.1551476678276406, "ROUGE_L": 0.25176886792452824, "CIDEr": 2.0349603151964384e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.20833333333333334, "f": 0.1851851851851852, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a train traveling on the tracks. The train is made up of several cars, including one with a red and white striped roof. The train is traveling through a rural area with trees and fields on either side of the tracks. There are no people visible in the image."}, "286018": {"image_id": 286018, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.22538468968297917, "Bleu_3": 0.15853051819285774, "Bleu_4": 0.11235687646097305, "METEOR": 0.22519867906260388, "ROUGE_L": 0.32707774798927614, "CIDEr": 7.864188126396968e-08, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a young girl wearing a pink helmet and skateboard standing on the edge of a swimming pool. She is looking out at the crowd of people gathered around the pool. The pool is surrounded by a railing and there are several people standing on the edge, watching the girl skate"}, "429108": {"image_id": 429108, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.18171094607444632, "Bleu_3": 0.12476834639035371, "Bleu_4": 0.07894703307415313, "METEOR": 0.27641870193343143, "ROUGE_L": 0.2959369314736203, "CIDEr": 3.0970995259728944e-12, "SPICE": {"All": {"pr": 0.04, "re": 0.05263157894736842, "f": 0.04545454545454545, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man in a yellow shirt and black shorts holding a tennis racket and walking on a tennis court. The man is wearing a pair of sneakers and has a tennis ball in his hand. The background of the image is a tennis court with a net in the middle."}, "76409": {"image_id": 76409, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.12632278815731815, "Bleu_3": 7.02643755945735e-07, "Bleu_4": 1.6662810872720653e-09, "METEOR": 0.15045145895022108, "ROUGE_L": 0.19110275689223058, "CIDEr": 7.526152115832303e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.24, "f": 0.2666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.5555555555555556, "f": 0.6666666666666667, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows a bedroom with a red bedspread and a painting on the wall. There is a window with a view of the outdoors.\n\nThe bedroom has a red bedspread and a painting on the wall. There is a window with a view of the outdoors. The"}, "478159": {"image_id": 478159, "Bleu_1": 0.255813953482423, "Bleu_2": 0.2064840403341673, "Bleu_3": 0.14611791249268313, "Bleu_4": 0.11175580607022101, "METEOR": 0.2116585495914207, "ROUGE_L": 0.29756097560975614, "CIDEr": 4.6200570528339364e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.18518518518518517, "f": 0.19607843137254902, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a desk with a computer, keyboard, mouse, and other office supplies. There is a whiteboard on the wall with the words \"Collaboration\" and \"Innovation\" written on it. The room is well lit and there are several windows on the walls."}, "391347": {"image_id": 391347, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1321752642838866, "Bleu_3": 0.10026270761741987, "Bleu_4": 0.07929020238697523, "METEOR": 0.16434332133490775, "ROUGE_L": 0.26666666666666666, "CIDEr": 3.435908963412302e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.24, "f": 0.23529411764705882, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a stop sign on the side of the road. The sign has the words \"stop\" written in white letters on a red background. The sign is surrounded by trees and the sky is blue and cloudy.\n\nThe image is taken from a bird's eye view, looking down on the road"}, "477940": {"image_id": 477940, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.0767719506444456, "Bleu_4": 9.802862511748142e-06, "METEOR": 0.2292519745158947, "ROUGE_L": 0.23669623059866962, "CIDEr": 4.1923756004768735e-10, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.06451612903225806, "f": 0.06557377049180328, "fn": 29.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man riding a horse in a dusty field. The man is wearing a white shirt and jeans, and has a rope in his hand. The horse is brown and white, and is running with the man on its back. There are other horses in the background, running in"}, "56137": {"image_id": 56137, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.07529519927190922, "Bleu_4": 9.612424997506294e-06, "METEOR": 0.22724186648068664, "ROUGE_L": 0.21721068249258166, "CIDEr": 3.952957727485213e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a fruit stand with various types of fruit on display. There are apples, oranges, and grapes on the stand. The stand is made of wood and has a glass front. The fruit is arranged in neat rows on the stand. There are several people standing around the stand, looking at"}, "453283": {"image_id": 453283, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.23644230070621639, "Bleu_3": 0.14774838920061847, "Bleu_4": 0.08917631496980528, "METEOR": 0.2475978944414561, "ROUGE_L": 0.29901960784313725, "CIDEr": 3.198859706223118e-10, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.07142857142857142, "f": 0.05, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a plate of food on a wooden table. There is a glass of milk on the table next to the plate. The plate has a sandwich, tomato, and cucumber on it. There is a laptop on the table next to the plate. The laptop has a screen that shows a website"}, "330122": {"image_id": 330122, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1321752642838866, "Bleu_3": 0.10026270761741987, "Bleu_4": 0.06667484695194902, "METEOR": 0.20025172762719273, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.186832904636198e-12, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2727272727272727, "f": 0.2790697674418604, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of people sitting on the floor in a living room. They are all wearing different types of clothing and are holding various items, such as books, toys, and drinks. There is a large window in the background with a view of the outside. The room is well lit and"}, "179397": {"image_id": 179397, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.11009637651061581, "Bleu_3": 0.061153792306271486, "Bleu_4": 8.143605172498537e-06, "METEOR": 0.13250198669135244, "ROUGE_L": 0.19781645227542968, "CIDEr": 3.577521080892194e-11, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.22727272727272727, "f": 0.20408163265306123, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This image shows a train station with a large brick building in the background. There are several cars parked on the platform, and people are walking on the sidewalk. The sky is clear and blue, with a few clouds in the distance. The image is taken from a bird's eye view, looking down on"}, "326555": {"image_id": 326555, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.0804252399656011, "Bleu_4": 1.0203142794069551e-05, "METEOR": 0.21318191434788675, "ROUGE_L": 0.29659643435980554, "CIDEr": 6.267875794464695e-09, "SPICE": {"All": {"pr": 0.24, "re": 0.2, "f": 0.2181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person standing on skis in the snow. The person is wearing a red jacket and black pants, and has a pair of skis on their feet. The background is a snowy landscape with trees and buildings in the distance.\n\nThe person is smiling and appears to be"}, "221105": {"image_id": 221105, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1321752642838866, "Bleu_3": 0.0875875427161453, "Bleu_4": 0.060247525296160884, "METEOR": 0.17916838920887374, "ROUGE_L": 0.24124293785310735, "CIDEr": 2.4955777322103295e-12, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in a room with a staircase leading up to the second floor. There are several bookshelves in the room, and a table with chairs in the center of the room. The walls are painted white and there are windows on either side of the room. The"}, "304404": {"image_id": 304404, "Bleu_1": 0.3199999999936, "Bleu_2": 0.24243661068763242, "Bleu_3": 0.1542974711761775, "Bleu_4": 0.09402528138217046, "METEOR": 0.2618723571076195, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.7236048792961534e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.12244897959183673, "f": 0.16216216216216214, "fn": 43.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.3125, "f": 0.35714285714285715, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a baseball player swinging a bat at a ball on a baseball field. The player is wearing a baseball cap and a jersey with the number 23 on it. The crowd is cheering in the background.\n\nThe image is taken from a bird's eye view, showing"}, "161010": {"image_id": 161010, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.1797866299868988, "Bleu_3": 0.13461691545954688, "Bleu_4": 0.09841955325589759, "METEOR": 0.21468299416733724, "ROUGE_L": 0.2978838849701574, "CIDEr": 4.59578380590373e-12, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.23333333333333334, "f": 0.2456140350877193, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a street with buildings on either side. There are cars parked on the side of the road and a fire hydrant on the corner. The sky is clear and blue.\n\nThe image shows a street with buildings on either side. There are cars parked on the side of the road and a"}, "164255": {"image_id": 164255, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.15475060698405138, "Bleu_3": 0.07772573699771664, "Bleu_4": 9.84421602524371e-06, "METEOR": 0.25760151165730816, "ROUGE_L": 0.226906385616863, "CIDEr": 3.22481751986456e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.17647058823529413, "f": 0.13636363636363638, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a colorful umbrella on a beach with a clear blue sky and a calm ocean in the background. The umbrella is open and has a striped pattern on it. There are no people or objects in the image. The beach is sandy and has some shells and rocks on it"}, "352734": {"image_id": 352734, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.13736056394607243, "Bleu_3": 0.07178791139239354, "Bleu_4": 9.274617069102212e-06, "METEOR": 0.1527300010635772, "ROUGE_L": 0.21266705403834982, "CIDEr": 3.395006759198215e-11, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.15, "f": 0.12244897959183673, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a young boy sitting at a table with a plate of food in front of him. He is wearing a white shirt and blue shorts. The table has a red and white checkered tablecloth on it. There are several other plates of food on the table as well. The background"}, "570810": {"image_id": 570810, "Bleu_1": 0.13999999999720003, "Bleu_2": 1.6903085094228824e-09, "Bleu_3": 3.904483328015701e-12, "Bleu_4": 1.8864626675179614e-13, "METEOR": 0.09337539432176656, "ROUGE_L": 0.11626429479034307, "CIDEr": 1.3284328704512023e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a large luggage conveyor belt in a blue and white color scheme. The conveyor belt is surrounded by a white wall with a blue and white striped pattern. There are two people standing on the conveyor belt, one with a suitcase and the other with a backpack"}, "344325": {"image_id": 344325, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1577557537051747, "Bleu_3": 0.09984894236626275, "Bleu_4": 0.06713648224794187, "METEOR": 0.2569773826478906, "ROUGE_L": 0.22536945812807885, "CIDEr": 1.906868269768822e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15, "f": 0.12765957446808512, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a person riding a motorcycle on a race track. The person is wearing a helmet and riding on the left side of the bike. The track is made of asphalt and has a few turns. There are some trees in the background and a few spectators in the stands"}, "580972": {"image_id": 580972, "Bleu_1": 0.14285714285422743, "Bleu_2": 0.07715167497945506, "Bleu_3": 5.021856363784844e-07, "Bleu_4": 1.2881272186771893e-09, "METEOR": 0.08347826086956522, "ROUGE_L": 0.15164698570540708, "CIDEr": 9.226729516953017e-12, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13636363636363635, "f": 0.11320754716981131, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a person skateboarding on a ramp made of metal. The person is wearing a black shirt and black pants, and has a green helmet on their head. The ramp is made of metal and has a chain link fence on either side. The person is jumping"}, "334813": {"image_id": 334813, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.27080128014916915, "Bleu_3": 0.20785103853274067, "Bleu_4": 0.15391613649325234, "METEOR": 0.26570474812233036, "ROUGE_L": 0.3790960451977401, "CIDEr": 1.7967082053939474e-07, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.034482758620689655, "f": 0.03773584905660377, "fn": 28.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The man in the image is sitting at a desk with a laptop and a glass of wine. He is wearing a white shirt and black pants. There are papers and other office supplies on the desk. The room is dimly lit and there are several windows with blinds open.\n\nThe"}, "471642": {"image_id": 471642, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.09486600651870754, "Bleu_4": 0.06428216024395343, "METEOR": 0.16354260868186518, "ROUGE_L": 0.22489861128179922, "CIDEr": 5.018202504892284e-12, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a group of people standing on a subway platform. They are wearing casual clothing and looking at their phones. The subway car is in the background, with the doors open and people getting on and off. The walls are painted with a red and white color scheme, with the words"}, "553962": {"image_id": 553962, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.14887283354071895, "Bleu_3": 0.07839548039992822, "Bleu_4": 1.017220586599864e-05, "METEOR": 0.19496720898870426, "ROUGE_L": 0.27799479166666663, "CIDEr": 1.8433242773816274e-09, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.15384615384615385, "f": 0.13559322033898305, "fn": 22.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.36363636363636365, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image shows a red stop sign on a wooden pole in the middle of a river. The sign is leaning against a concrete wall, and there is a large pile of debris in the background. The sky is cloudy and there are tall buildings in the distance."}, "551669": {"image_id": 551669, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.06317667074948415, "Bleu_3": 4.277412148886299e-07, "Bleu_4": 1.1185188895571612e-09, "METEOR": 0.1613025325116296, "ROUGE_L": 0.21721068249258166, "CIDEr": 3.737111091966483e-12, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a parking lot with several boats parked in it. The boats are of different sizes and colors, and some of them have fishing nets on them. There are also some people standing around the boats, looking at them. The sky is cloudy and there are some clouds in the background."}, "133964": {"image_id": 133964, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.0902516670662263, "Bleu_3": 5.290733975849901e-07, "Bleu_4": 1.2868813412039973e-09, "METEOR": 0.1942690594296097, "ROUGE_L": 0.20926243567753, "CIDEr": 4.4432308139492555e-15, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.19047619047619047, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of people on a dock in the middle of a lake. There are several small boats and a large boat in the water. The dock is surrounded by trees and there is a path leading to the shore. The sky is cloudy and there are some birds flying overhead.\n\nThe image shows"}, "386210": {"image_id": 386210, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 6.290089214849726e-07, "Bleu_4": 1.5012173807660588e-09, "METEOR": 0.1359201481113621, "ROUGE_L": 0.18373493975903615, "CIDEr": 4.117533015705908e-11, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.10526315789473684, "f": 0.0816326530612245, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a small greenhouse with a window on the side. There are several oranges hanging from the ceiling and a small potted plant on the ground. The greenhouse is surrounded by a white wall with a window on the side. The image is taken from the outside of a building."}, "252771": {"image_id": 252771, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.17529161909076163, "ROUGE_L": 0.23303196230739842, "CIDEr": 7.225987340020741e-09, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.03571428571428571, "f": 0.03571428571428571, "fn": 27.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.08333333333333333, "f": 0.08695652173913043, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a desk with several laptops on it. The laptops are all different colors and have different features. There are also some books and papers on the desk. The room is dimly lit and there are some cables and wires on the floor.\n\nThe image shows a"}, "403013": {"image_id": 403013, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.16816819849581244, "Bleu_3": 0.08270007684490462, "Bleu_4": 1.0365265119381272e-05, "METEOR": 0.21475515848033078, "ROUGE_L": 0.2167219327333018, "CIDEr": 5.322035722488792e-11, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a kitchen with white appliances, a white refrigerator, and a white stove. The floor is made of hardwood and the walls are painted white. There is a window on the left side of the room and a door on the right side. The room is well lit and has"}, "143671": {"image_id": 143671, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.09983374884360895, "Bleu_3": 6.241040020024952e-07, "Bleu_4": 1.5701014973153738e-09, "METEOR": 0.17386453094048307, "ROUGE_L": 0.22377109317681584, "CIDEr": 2.438037479325566e-07, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.4117647058823529, "f": 0.35, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 1.0, "f": 0.5714285714285715, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a basket filled with carrots. The carrots are green and have a long, thin shape. They are arranged in a row in the basket. There are also some green leaves in the basket. The background is a green, grassy field."}, "217183": {"image_id": 217183, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.22562131409418867, "Bleu_3": 0.12674769789184412, "Bleu_4": 1.4277627265895718e-05, "METEOR": 0.26324262978974483, "ROUGE_L": 0.2610024449877751, "CIDEr": 6.256242882408116e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.1935483870967742, "f": 0.20689655172413793, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.35714285714285715, "f": 0.35714285714285715, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a vase with white flowers in it. The flowers are arranged in a bouquet and are placed on a table. There is a doll on the table next to the vase.\n\nThe flowers in the vase are white and have a delicate appearance. They are arranged in a bouquet"}, "112739": {"image_id": 112739, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.07446639778133946, "Bleu_4": 9.43994412057466e-06, "METEOR": 0.18812349932285488, "ROUGE_L": 0.16549104720564298, "CIDEr": 1.5931802466770895e-12, "SPICE": {"All": {"pr": 0.08, "re": 0.1111111111111111, "f": 0.09302325581395349, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a street with cars parked on the side of the road. There are no people in the image. The sky is cloudy and there are no buildings in the background. The road is paved and there are no trees or other vegetation in the area. The image is in black and white."}, "187989": {"image_id": 187989, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.2047650389408227, "Bleu_3": 0.13423832028711077, "Bleu_4": 1.475756952410161e-05, "METEOR": 0.233299099492229, "ROUGE_L": 0.21048999309868874, "CIDEr": 1.007579460299725e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.3076923076923077, "f": 0.1951219512195122, "fn": 9.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of airplanes flying in formation in the sky. They are all painted in red, white, and blue colors and have smoke trails behind them. The sky is cloudy and there are some clouds in the background. The image is taken from a distance and the planes are small in"}, "170849": {"image_id": 170849, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.293211273104214, "Bleu_3": 0.19017369208087398, "Bleu_4": 1.9355919558434562e-05, "METEOR": 0.2400500712270764, "ROUGE_L": 0.2921655833048238, "CIDEr": 7.621720167817678e-11, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.07407407407407407, "f": 0.07407407407407407, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of seagulls flying over a beach with people walking on it. The sky is cloudy and there are some buildings in the background.\n\nThe image is taken from a low angle, looking down at the beach and the birds flying overhead. The lighting is soft and natural,"}, "101068": {"image_id": 101068, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.20870354281255962, "Bleu_3": 0.14598577364278748, "Bleu_4": 1.5422054353314752e-05, "METEOR": 0.24079621721200486, "ROUGE_L": 0.2973997833152763, "CIDEr": 1.1749426679856563e-14, "SPICE": {"All": {"pr": 0.12, "re": 0.10344827586206896, "f": 0.11111111111111112, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man in a baseball uniform holding a bat and throwing water on the ground. The man is standing on a baseball field with other players in the background. The image is in black and white.\n\nThe image shows a man in a baseball uniform holding a bat and throwing water on the ground. The"}, "509131": {"image_id": 509131, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.11764652669092619, "Bleu_4": 0.07713382612340196, "METEOR": 0.21896117295426837, "ROUGE_L": 0.3175245806824754, "CIDEr": 1.2851691922247186e-08, "SPICE": {"All": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a table with a vase of oranges, a bowl of bananas, and a bowl of apples on it. There is also a television in the background.\n\nThe table is made of wood and has a smooth surface. The vase of oranges is on the left side"}, "162021": {"image_id": 162021, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.14118624159718107, "Bleu_3": 0.07863217694465756, "Bleu_4": 1.0499901541586202e-05, "METEOR": 0.20221204385462235, "ROUGE_L": 0.2616154395997141, "CIDEr": 4.4016682737767855e-08, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.21052631578947367, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a group of people on skateboards, wearing helmets and knee pads, standing in a line on a sidewalk. They are all wearing casual clothing, including white shirts and black pants. The skateboards are all different colors and have different designs"}, "226147": {"image_id": 226147, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.10497813183144382, "Bleu_3": 0.061232992015274296, "Bleu_4": 8.360161095251491e-06, "METEOR": 0.17698061910207546, "ROUGE_L": 0.1852976913730255, "CIDEr": 1.8897264223564068e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.17142857142857143, "f": 0.19672131147540986, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a table with several plates of food on it. There are several people sitting at the table, eating their food. The table has a red and white checkered tablecloth on it. There are several flowers on the table, including roses and daisies. The people at the table"}, "314182": {"image_id": 314182, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.21046802246600352, "Bleu_3": 1.026115216917681e-06, "Bleu_4": 2.2797230913690414e-09, "METEOR": 0.20402234975202768, "ROUGE_L": 0.24286662242866625, "CIDEr": 2.9914721443578604e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bowl of dip with carrots, broccoli, and crackers on a table.\n\nThe bowl is made of white ceramic and has a small handle on the side. The carrots are orange and the broccoli is green. The crackers are light"}, "482007": {"image_id": 482007, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.24562537538976753, "Bleu_3": 0.18204642481324668, "Bleu_4": 0.10533861300924754, "METEOR": 0.2601187085754549, "ROUGE_L": 0.23047858942065497, "CIDEr": 1.7224799315271762e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.4090909090909091, "f": 0.3913043478260869, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.6363636363636364, "f": 0.6086956521739131, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image shows a large, open space with a high ceiling. There are several tall, clear glass vases on the floor, filled with yellow flowers. The walls are made of marble and there are several mirrors on the walls. The floor is made of black and white tiles. There are several ch"}, "292616": {"image_id": 292616, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.21381869073854032, "Bleu_3": 0.13906381417319807, "Bleu_4": 1.5228884803421859e-05, "METEOR": 0.25721966666112905, "ROUGE_L": 0.33351558228540185, "CIDEr": 8.195435205220632e-11, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2692307692307692, "f": 0.27999999999999997, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of birds sitting on top of a row of chairs. The chairs are made of metal and are painted purple. The birds are small and have brown feathers. They are perched on top of the chairs, looking out at the water. There are no other objects in the"}, "82662": {"image_id": 82662, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.15604694598027796, "Bleu_3": 0.0766841478193614, "Bleu_4": 9.604178638196449e-06, "METEOR": 0.18588165957603234, "ROUGE_L": 0.2401574803149606, "CIDEr": 2.345637716544386e-12, "SPICE": {"All": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a stop sign on a pole in the middle of a street. The sign has a red background with white letters that say \"stop\". There are some buildings in the background, but they are not visible. The image is in black and white.\n\nThe image shows a stop sign on a pole in"}, "368576": {"image_id": 368576, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.1103716852403353, "Bleu_4": 1.293698116812338e-05, "METEOR": 0.21511815835540748, "ROUGE_L": 0.26116207951070336, "CIDEr": 6.272070146952007e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a baseball player at bat, with a catcher standing behind him. The player is holding a bat and wearing a helmet, while the catcher is wearing a mask and glove. The field in the background is green and has a dirt path leading to the pitcher's m"}, "2299": {"image_id": 2299, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.22214157542810112, "Bleu_3": 0.1426495013657264, "Bleu_4": 0.08728913550550585, "METEOR": 0.23835410008129823, "ROUGE_L": 0.21356050881082975, "CIDEr": 1.1017622582484873e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of children sitting on the ground in front of a building. They are all wearing school uniforms and smiling at the camera. The building appears to be a school or church.\n\nThe image is in black and white and has a vintage look to it. The children are"}, "393864": {"image_id": 393864, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2285817953234835, "Bleu_3": 0.12701286121266542, "Bleu_4": 1.422798090025241e-05, "METEOR": 0.21673252393779036, "ROUGE_L": 0.30314743235781333, "CIDEr": 1.166717674306816e-08, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a plate of food on a table. The plate has a slice of pizza on it. There are two glasses of wine on the table. The table has a red and white checkered tablecloth. There is a vase of flowers on the table. The room has a wooden floor and"}, "198796": {"image_id": 198796, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.08681823924888467, "Bleu_4": 1.1239895308238822e-05, "METEOR": 0.18357093584668246, "ROUGE_L": 0.3347560975609756, "CIDEr": 8.603758417882457e-07, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.09375, "f": 0.10909090909090909, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a plate of food on a table with a fork and knife on the side. There are two glasses of wine on the table and a vase of flowers in the background. The tablecloth is white and the chairs are wooden."}, "513220": {"image_id": 513220, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 7.777190244898269e-07, "Bleu_4": 1.7882473253246786e-09, "METEOR": 0.20516265154715793, "ROUGE_L": 0.236281471917366, "CIDEr": 3.503524217120321e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a plate of food with a sandwich, fries, and a drink on the table. The sandwich appears to be made of meat and cheese, and the fries are cooked to a crispy golden brown. The drink is a beer. The table is made of wood and"}, "157891": {"image_id": 157891, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.19802950859148932, "Bleu_3": 0.11619120889626242, "Bleu_4": 1.3376143914343889e-05, "METEOR": 0.18967702828508826, "ROUGE_L": 0.22048192771084338, "CIDEr": 8.67653632373816e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.12, "f": 0.1132075471698113, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of giraffes standing in a field with tall trees in the background. The giraffes are brown with white spots and their long necks are stretched out to reach the leaves on the trees. There are no other animals in the image. The sky is clear and blue"}, "61715": {"image_id": 61715, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.1518578172003014, "Bleu_3": 0.0762588621312534, "Bleu_4": 9.656621220138898e-06, "METEOR": 0.19430630319552222, "ROUGE_L": 0.22344322344322343, "CIDEr": 2.2182782847371692e-13, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a train on the tracks in the foreground, with tall buildings in the background. The train is traveling in the direction of the camera, with the tracks leading to the left. The buildings are made of concrete and glass, with some having windows and others having balconies. The sky is clear"}, "249809": {"image_id": 249809, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.12948675740619273, "Bleu_4": 0.08288569027871298, "METEOR": 0.20306147868680155, "ROUGE_L": 0.32086499123319695, "CIDEr": 5.721129740835173e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person riding a skateboard on a sidewalk. The person is wearing a helmet and has a backpack on their back. The skateboard has yellow wheels and a black body. The person is standing on the sidewalk and has their hands on the handlebars of the"}, "57198": {"image_id": 57198, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.0903507902886997, "Bleu_3": 0.05540397074769194, "Bleu_4": 7.755882196444624e-06, "METEOR": 0.13240595705245123, "ROUGE_L": 0.1852976913730255, "CIDEr": 3.6566023556172445e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.17647058823529413, "f": 0.14634146341463414, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a banana peel on the ground with the words \"watch where you step\" written on it. The banana peel is lying on the ground, and the words are written in a bold, black font. The background is a light gray color.\n\nThe image is a reminder to"}, "235200": {"image_id": 235200, "Bleu_1": 0.13461538461279587, "Bleu_2": 0.051376233272761314, "Bleu_3": 3.75132627232769e-07, "Bleu_4": 1.0188015780213462e-09, "METEOR": 0.10455429397790354, "ROUGE_L": 0.18373493975903615, "CIDEr": 3.648717417332182e-12, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows three zebras standing in a field with a fence in the background. The zebras are standing in a line, with their heads down and their ears up. They are wearing collars and are looking at each other. The fence is made of metal and has a gate in the"}, "303210": {"image_id": 303210, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 0.06880010617668034, "Bleu_4": 9.172809483333237e-06, "METEOR": 0.14850231003467773, "ROUGE_L": 0.16126900198281557, "CIDEr": 4.948528453298378e-10, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.3181818181818182, "f": 0.27450980392156865, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of people skateboarding on a ramp in a park. The people are wearing casual clothing and are standing on their skateboards, looking at each other. The ramp is made of concrete and has a smooth surface. There are trees and bushes in the background"}, "274939": {"image_id": 274939, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1295047816452144, "Bleu_3": 0.08640378216299735, "Bleu_4": 0.05963579606958106, "METEOR": 0.15738703855760314, "ROUGE_L": 0.21863799283154117, "CIDEr": 1.7079011309504896e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a street with a few cars parked on the side of the road. There is a clock tower in the distance, and a few people walking down the sidewalk. The sky is clear and blue.\n\nThe image shows a street with a few cars parked on the side of the road."}, "253520": {"image_id": 253520, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1398811515077607, "Bleu_3": 7.219465044848078e-07, "Bleu_4": 1.6481100947130725e-09, "METEOR": 0.16839700561672405, "ROUGE_L": 0.23487348734873487, "CIDEr": 5.621567056366026e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.23529411764705882, "f": 0.17777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The sign on the street is pointing to the left.\n\nThe sign is made of metal and has a white background with black letters. The letters are in Hebrew and the sign is pointing to the left.\n\nThere are buildings on either side of the street and a few cars parked on the sidewalk"}, "132814": {"image_id": 132814, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.22430886163262467, "Bleu_3": 0.15700609186696476, "Bleu_4": 0.11099472319754802, "METEOR": 0.24577667646881476, "ROUGE_L": 0.21403508771929822, "CIDEr": 2.1047678118372305e-12, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of zebras standing in a grassy field. They are grazing on the grass and seem to be enjoying themselves. There is a large tree in the background with a bird perched on a branch. The sky is clear and blue with a few clouds scattered about. The sun is"}, "146837": {"image_id": 146837, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.10987673829748816, "Bleu_4": 1.2961487777593183e-05, "METEOR": 0.15018717112392707, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.0160535221003548e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a person in a colorful shirt and pants jumping over a skateboard on a sidewalk. The person is wearing a helmet and has a serious expression on their face. The background is a city street with trees and buildings in the distance.\n\nThe image is taken from"}, "389404": {"image_id": 389404, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 0.06290089214849724, "Bleu_4": 8.441965712987706e-06, "METEOR": 0.1301125147970791, "ROUGE_L": 0.18373493975903615, "CIDEr": 4.554469397079653e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a white chicken standing on a grassy field with its beak open and its eyes closed. The chicken is wearing a red collar and has a tag on its neck. There is a black dog standing next to the chicken, looking at it. The dog is wearing a blue"}, "122997": {"image_id": 122997, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.16302782918400804, "Bleu_3": 0.12482080040049896, "Bleu_4": 0.0993019377831466, "METEOR": 0.21133268176007544, "ROUGE_L": 0.3238221632382216, "CIDEr": 1.1238099180606545e-06, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.23076923076923078, "f": 0.15384615384615388, "fn": 10.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting around a table, using laptops and looking at a screen. They are all wearing casual clothing and appear to be working on something. The room is dimly lit and there are plants on the walls."}, "82174": {"image_id": 82174, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.12227087188800603, "Bleu_3": 0.07144207399267892, "Bleu_4": 9.771259394693747e-06, "METEOR": 0.19736727230607787, "ROUGE_L": 0.21254355400696864, "CIDEr": 6.415745710888407e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two peacocks sitting on chairs in a park. The peacocks are wearing sunglasses and have their feathers spread out. The chairs are white and have a red cushion on them. There are trees and flowers in the background.\n\nThe image"}, "448868": {"image_id": 448868, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.06502560887474053, "Bleu_3": 4.65200159363572e-07, "Bleu_4": 1.251797059186196e-09, "METEOR": 0.12873563218390804, "ROUGE_L": 0.20265780730897012, "CIDEr": 8.426796114973935e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a large truck parked on the side of the road with a hose attached to it. There are several other trucks parked nearby, and a large building in the background. The sky is cloudy and there is snow on the ground."}, "494913": {"image_id": 494913, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.15017092450871714, "Bleu_4": 0.09071871495754516, "METEOR": 0.24740240540944086, "ROUGE_L": 0.21908296420447745, "CIDEr": 1.8409071746783072e-11, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.24, "f": 0.2727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a living room with a couch, coffee table, and TV. There are two people sitting on the couch watching TV. The room is well lit and has a large window with curtains. The walls are painted white and there are some decorations on the walls. The floor is made of"}, "290355": {"image_id": 290355, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.09124485969890858, "Bleu_3": 0.0569816167278448, "Bleu_4": 8.05263299613596e-06, "METEOR": 0.18618715320482337, "ROUGE_L": 0.19303797468354428, "CIDEr": 2.495449091295515e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.11538461538461539, "f": 0.13636363636363638, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The dog is sitting on the log, looking up at the camera. The log is covered in moss and has a small hole in it. The dog's collar is visible in the foreground. The background is a forest with tall trees and a clear blue sky."}, "330554": {"image_id": 330554, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.10820697408694996, "Bleu_4": 0.07130868363395679, "METEOR": 0.21008947987906146, "ROUGE_L": 0.2784479947831757, "CIDEr": 4.063858176862089e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13793103448275862, "f": 0.1568627450980392, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a blender sitting on a counter in a kitchen. The blender has a liquid inside it and is plugged into a wall outlet. There is a sink in the background and a stove in the foreground. The countertop is made of white tile and has a faucet in the"}, "445766": {"image_id": 445766, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.10158210507506187, "Bleu_4": 1.1973479150365735e-05, "METEOR": 0.17922793645389176, "ROUGE_L": 0.21585279547062985, "CIDEr": 6.064593262725824e-12, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.0625, "f": 0.06666666666666667, "fn": 30.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a fire hydrant with a green and blue mural on it. The mural depicts a cartoon character with a green and blue body and a red and white face. The character is standing on top of a cloud with a rainbow coming out of its mouth. The image is taken in"}, "403793": {"image_id": 403793, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.18442777838702637, "Bleu_3": 0.0897811031266893, "Bleu_4": 1.1199515753588489e-05, "METEOR": 0.1761110096976763, "ROUGE_L": 0.15164698570540708, "CIDEr": 1.9638220700895886e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a truck. They are all wearing blue shirts with the word \"Subaru\" on them. The truck is blue and has the word \"Subaru\" written on the side. There are also two other cars parked next to the tr"}, "452836": {"image_id": 452836, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.12993504870706918, "Bleu_3": 6.787131897112119e-07, "Bleu_4": 1.5584603208953362e-09, "METEOR": 0.21229352609332613, "ROUGE_L": 0.21229698375870068, "CIDEr": 2.4779496898176444e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14814814814814814, "f": 0.14545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The woman in the image is wearing a green dress and carrying a purse. She is standing in front of a white building with a large window on the side. There are plants growing out of the walls of the building.\n\nThe woman is looking at something on the ground in front of her. There are"}, "285089": {"image_id": 285089, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.19026059765810296, "Bleu_3": 0.15354390128889117, "Bleu_4": 0.12201289225771661, "METEOR": 0.3196022543481938, "ROUGE_L": 0.2995440196422308, "CIDEr": 5.653003694579984e-11, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a black bear standing on a wooden fence. The bear is looking down and appears to be sniffing the air. The fence is made of wood and has a railing on top. The bear's fur is shiny and appears to be well groomed. The background is a green"}, "312144": {"image_id": 312144, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.2264554068245216, "Bleu_3": 0.1600854244658392, "Bleu_4": 0.09565657435362714, "METEOR": 0.282222473876329, "ROUGE_L": 0.34702110053785684, "CIDEr": 3.470974437842798e-07, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.2, "f": 0.1702127659574468, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is of a red wall with three black leather chairs in front of it. There is a clock on the wall with the hands pointing to 12 o'clock. The room is dimly lit and there are no other objects in the room.\n\nThe image is of a red wall with"}, "67463": {"image_id": 67463, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1413162504531272, "Bleu_4": 0.12197379410072966, "METEOR": 0.2703892710976267, "ROUGE_L": 0.2853801169590643, "CIDEr": 1.2725334925529087e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.13636363636363635, "f": 0.11538461538461538, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a large truck driving down the road with a crane on the back. The truck is white with black and red stripes on the sides. The crane is yellow with black and red stripes on the sides. The road is empty and there are no other vehicles in sight. The sky"}, "129054": {"image_id": 129054, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.18474632789942436, "Bleu_3": 0.11406207412406916, "Bleu_4": 0.0757796892461228, "METEOR": 0.2587118755696878, "ROUGE_L": 0.28018372703412076, "CIDEr": 2.833626551930251e-10, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.07142857142857142, "f": 0.0784313725490196, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of zebras standing in a field with a mountain in the background. The zebras are grazing on the grass in the field. The sky is clear and blue.\n\nThe image is taken from a distance, showing the zebras in the field. The zebras"}, "248364": {"image_id": 248364, "Bleu_1": 0.387755102032903, "Bleu_2": 0.25421614885264626, "Bleu_3": 0.16037741990927082, "Bleu_4": 1.7304854771899602e-05, "METEOR": 0.18159969638657047, "ROUGE_L": 0.23303196230739842, "CIDEr": 1.3546246149455724e-08, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.06896551724137931, "f": 0.07272727272727274, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people lying on the beach in front of a large rock formation. They are all wearing swimsuits and sunglasses, and one person is holding an umbrella. The water is calm and clear, and there are palm trees and other vegetation on the beach"}, "325152": {"image_id": 325152, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.15352206215446232, "Bleu_3": 0.11008521423530733, "Bleu_4": 0.08463566423155675, "METEOR": 0.17383447690364714, "ROUGE_L": 0.27006087437742116, "CIDEr": 1.2910542138163958e-12, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2916666666666667, "f": 0.27999999999999997, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a park with a bench in the middle of the grass. The trees are tall and green, and there is a path leading to the left of the image. The sky is cloudy and there are no people in the image.\n\nThe image shows a park with a bench in the middle"}, "406491": {"image_id": 406491, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.15861031714066393, "Bleu_3": 0.0989076400524586, "Bleu_4": 1.1736263070262705e-05, "METEOR": 0.2515493238405269, "ROUGE_L": 0.2684268426842684, "CIDEr": 6.132686204988509e-11, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a cat lying on the floor next to a pair of shoes. The cat is wearing a collar and appears to be sleeping. The shoes are black and have a high heel. The floor is made of wood and appears to be clean. There is a window in the background with"}, "414078": {"image_id": 414078, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.19154015512649578, "Bleu_3": 0.1283943344001008, "Bleu_4": 1.427305210255098e-05, "METEOR": 0.2289148392592537, "ROUGE_L": 0.2367487247726769, "CIDEr": 2.196809179663868e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a black and white cat lying on a blue blanket on a bed. The cat is looking up at the camera with its eyes. The bed has a blue sheet and a blue blanket on it. The cat is wearing a collar with a tag on it.\n\nThe image is taken"}, "316015": {"image_id": 316015, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.22771001701714594, "Bleu_3": 0.1899016831263663, "Bleu_4": 0.1676615926007501, "METEOR": 0.3704094709010689, "ROUGE_L": 0.3444381705251271, "CIDEr": 2.588793167233281e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.1724137931034483, "f": 0.17857142857142858, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on a desk in front of a computer monitor. The cat is looking at the screen with its ears perked up. The desk has a keyboard, mouse, and other office supplies on it. There is a window in the background with trees outside. The room is well lit and"}, "50434": {"image_id": 50434, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.08047040239209735, "Bleu_3": 5.240265333324465e-07, "Bleu_4": 1.344781695095211e-09, "METEOR": 0.14328358208955225, "ROUGE_L": 0.15531508593252702, "CIDEr": 7.563898528495684e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08695652173913043, "f": 0.08695652173913043, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a baseball game in progress. There are two players on the field, one pitching and the other catching. The pitcher is wearing a white jersey with red and blue stripes, and the catcher is wearing a black jersey with white and red stripes. The"}, "234555": {"image_id": 234555, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.17614871215260033, "Bleu_3": 8.770015703255858e-07, "Bleu_4": 1.967646828106159e-09, "METEOR": 0.1634053325338431, "ROUGE_L": 0.2663423153692615, "CIDEr": 1.0757778005698955e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.10869565217391304, "f": 0.15151515151515152, "fn": 41.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.2777777777777778, "f": 0.3703703703703704, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a desk with a laptop, a mouse, and a keyboard on it. There are also several other items on the desk, including a cup of coffee, a pen, and a notebook. The desk is cluttered with papers and other items.\n\nThe laptop is open and"}, "212759": {"image_id": 212759, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.10619884880883856, "Bleu_3": 5.896925524327534e-07, "Bleu_4": 1.3959529865204302e-09, "METEOR": 0.12216170635051844, "ROUGE_L": 0.25779186476492344, "CIDEr": 6.38429464436531e-14, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a street with a brick building on the left side and a tree on the right side. There are no cars or people in the image. The sky is blue and there are no clouds. The image is taken from a bird's eye view.\n\nThe building is a brick structure with a flat"}, "503724": {"image_id": 503724, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 0.10097712220824674, "Bleu_4": 1.3191601177260918e-05, "METEOR": 0.2277480647955457, "ROUGE_L": 0.2880528883991815, "CIDEr": 5.639670718113307e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.35, "f": 0.3414634146341463, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a red and white train on the tracks. It appears to be moving at a slow pace. There are buildings and trees in the background. The train has a number of passengers on board."}, "7050": {"image_id": 7050, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.1923802475574326, "Bleu_3": 0.11322098426534662, "Bleu_4": 0.0734011211371756, "METEOR": 0.21261687211820807, "ROUGE_L": 0.24302788844621512, "CIDEr": 2.565425695097679e-11, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.037037037037037035, "f": 0.04081632653061224, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a group of people in a canoe on a river. They are wearing life jackets and paddles and appear to be enjoying themselves. The water is calm and there are trees and grass on the banks of the river. The sky is blue and there are clouds in the distance."}, "371503": {"image_id": 371503, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.26884737596198516, "Bleu_3": 0.20974341370112826, "Bleu_4": 0.1566235649577389, "METEOR": 0.366218259317599, "ROUGE_L": 0.3463722397476341, "CIDEr": 7.874842667670793e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2857142857142857, "f": 0.2162162162162162, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of young men playing soccer on a field. They are wearing orange and blue jerseys and black shorts. One of the players is kicking the ball towards the goal while the others watch. The field is green and there are trees in the background."}, "462756": {"image_id": 462756, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.2473387769554387, "Bleu_3": 0.2153572226049549, "Bleu_4": 0.1879736976092812, "METEOR": 0.23905416782400032, "ROUGE_L": 0.33242506811989103, "CIDEr": 4.714537182206497e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a motorcycle parked on a dirt road in front of a small farmhouse. The motorcycle is a black and silver Harley Davidson with a white stripe down the middle. The farmhouse is a small, wooden structure with a red roof and white trim. There is a sign in"}, "311378": {"image_id": 311378, "Bleu_1": 0.339622641503026, "Bleu_2": 0.27995438151591834, "Bleu_3": 0.2400392661738198, "Bleu_4": 0.21689109106609877, "METEOR": 0.26982033122146026, "ROUGE_L": 0.36868131868131865, "CIDEr": 6.112315600145478e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.46153846153846156, "f": 0.3428571428571428, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a table with a pizza in front of him. He is wearing a black shirt and has a beard. The table has a white tablecloth and there are two glasses of water on it. The background is a large room with a high ceiling and white"}, "234057": {"image_id": 234057, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.08456484271613046, "Bleu_4": 1.0435177484324181e-05, "METEOR": 0.24568441235058655, "ROUGE_L": 0.25507765830346474, "CIDEr": 8.163972470004974e-13, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1875, "f": 0.15789473684210525, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of sheep grazing in a green field. The sheep are standing in a line, with their heads down and their tails wagging. The grass is tall and green, and there are no other animals in the field. The sky is cloudy and there is a light fog in the"}, "241297": {"image_id": 241297, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1373143068093302, "Bleu_3": 0.07085740383081722, "Bleu_4": 9.094693994314411e-06, "METEOR": 0.2304018085688955, "ROUGE_L": 0.18340348767288037, "CIDEr": 9.22005292538451e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The train is traveling down the tracks at a moderate speed. It has a yellow and black paint scheme and is pulling a large cargo car behind it. The train is traveling through a rural area with trees and fields on either side of the tracks. There are no other trains in sight.\n\nThe train"}, "493472": {"image_id": 493472, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.19794866371815809, "Bleu_3": 0.11775100856355507, "Bleu_4": 1.365208590055567e-05, "METEOR": 0.2129737346596356, "ROUGE_L": 0.26521739130434785, "CIDEr": 1.5687799182312472e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15, "f": 0.13043478260869565, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man sitting in a chair, holding a baby in his arms. The baby is wearing a onesie and has a pacifier in its mouth. The man is wearing a shirt and pants, and has a beard. The room is decorated with a blue and white striped"}, "392022": {"image_id": 392022, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.21182963642996727, "Bleu_3": 0.13911530022530355, "Bleu_4": 0.10238578205397379, "METEOR": 0.25096815816096024, "ROUGE_L": 0.28651949271958665, "CIDEr": 1.761574152054895e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2222222222222222, "f": 0.1951219512195122, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman skiing down a snowy slope. She is wearing a red jacket and black pants, and has a pair of skis on her feet. The snow is covered in trees and there is a mountain in the background. The woman is smiling and appears to be enjoying the"}, "21764": {"image_id": 21764, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.24323153526912705, "ROUGE_L": 0.23303196230739842, "CIDEr": 5.433082708448848e-10, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.22727272727272727, "f": 0.18867924528301885, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a man skateboarding on a ramp at an event. The man is wearing a black shirt and pants, and has a helmet on his head. The ramp is made of wood and has a metal rail on the side. There are several people watching the skateboard"}, "203171": {"image_id": 203171, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1258455564244646, "Bleu_3": 0.06816612219878869, "Bleu_4": 8.966592262802168e-06, "METEOR": 0.18102152079749603, "ROUGE_L": 0.18780788177339902, "CIDEr": 6.835673763701001e-11, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2, "f": 0.2380952380952381, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people flying kites in the sky. The sky is clear and blue, with a few clouds in the distance. The ground is covered in grass and dirt, with some buildings in the background. There are people standing on the ground, watching the kites fly.\n\nThe image"}, "109945": {"image_id": 109945, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.09983569293155374, "Bleu_4": 1.2127601540611025e-05, "METEOR": 0.21684745212595435, "ROUGE_L": 0.3059013163786155, "CIDEr": 3.036025086149447e-09, "SPICE": {"All": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a bowl of oatmeal with raspberries and nuts on a wooden table. The bowl is made of ceramic and has a white rim. The table is made of wood and has a red and white checkered pattern. The background is a blue sky with white clouds"}, "179765": {"image_id": 179765, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.13804538956739063, "Bleu_4": 0.0874406347440618, "METEOR": 0.2308977218234806, "ROUGE_L": 0.27799479166666663, "CIDEr": 1.037441084697377e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2857142857142857, "f": 0.24489795918367344, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a black motorcycle parked in a driveway\n\nThe motorcycle is parked on the left side of the driveway, with the front tire facing towards the viewer. The rear tire is facing away from the viewer. The motorcycle has a black seat and handle"}, "171632": {"image_id": 171632, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.25761406704390316, "Bleu_3": 0.1585003161501176, "Bleu_4": 0.09494532372505993, "METEOR": 0.2325372617497396, "ROUGE_L": 0.28514190317195326, "CIDEr": 1.2597591243523693e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.15625, "f": 0.18518518518518515, "fn": 27.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a bed with blue sheets and a window with curtains. The room is dimly lit and there is a lamp on the nightstand. The bed is made up with a blue blanket and pillows. There is a window with curtains on the left side of the room. The cur"}, "27519": {"image_id": 27519, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.059110575176554124, "Bleu_3": 4.065453602348427e-07, "Bleu_4": 1.0713693373996204e-09, "METEOR": 0.12448118936528839, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.0517363006142864e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.46153846153846156, "f": 0.2926829268292683, "fn": 7.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.8, "f": 0.4210526315789473, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people walking down a sidewalk in front of a building with a sign that reads \"Internet Cafe\". The people are all wearing casual clothing and some are carrying bags or other items. The building has a large window on the front with a sign that reads \"Internet Ca"}, "147300": {"image_id": 147300, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.12483755678422238, "Bleu_3": 6.608439529502604e-07, "Bleu_4": 1.5275844289614858e-09, "METEOR": 0.1568028836824707, "ROUGE_L": 0.1769141531322506, "CIDEr": 2.7703766646086712e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a green sign with white letters on a green background. The sign is on the side of a road with trees and grass on either side. There are no cars or people in the image.\n\nThe image is taken from a bird's eye view, looking down on the sign from above. The"}, "452947": {"image_id": 452947, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.18314741859482847, "Bleu_3": 0.1570060918669648, "Bleu_4": 0.1319957145542817, "METEOR": 0.31876947487826507, "ROUGE_L": 0.3279569892473118, "CIDEr": 7.617064782966636e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.23809523809523808, "f": 0.20833333333333334, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The room is a bedroom with a bed, desk, and chair. There is a window on the left side of the room with a view of the city. The walls are painted white and the floor is made of hardwood. There is a closet in the corner of the room with a shelf for"}, "100594": {"image_id": 100594, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.12712834523041283, "Bleu_3": 0.06730845772977347, "Bleu_4": 8.750873255009596e-06, "METEOR": 0.1465329690715407, "ROUGE_L": 0.20254565578306588, "CIDEr": 1.6607532371197508e-11, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.3157894736842105, "f": 0.24000000000000002, "fn": 13.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a street with a few cars driving down it. There are buildings on either side of the street, and a sign on the left side of the road. The sky is cloudy and there is no sun.\n\nThe image is taken from a bird's eye view, looking down on the street"}, "62068": {"image_id": 62068, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.12326123997631012, "Bleu_4": 0.09398684880464062, "METEOR": 0.2355223849297092, "ROUGE_L": 0.3117546848381601, "CIDEr": 1.055833981298765e-09, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.5, "f": 0.32558139534883723, "fn": 7.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.5, "f": 0.14285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The statue is of a man and woman standing next to each other, both wearing old fashioned clothing and holding suitcases. The man is wearing a hat and the woman is wearing a bonnet. They are standing in front of a large building with a sign that reads, \"Welcome to the"}, "276284": {"image_id": 276284, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.24159335035637264, "Bleu_3": 0.22201913607162, "Bleu_4": 0.1746961522681161, "METEOR": 0.2806225335057895, "ROUGE_L": 0.317295188556567, "CIDEr": 1.5375334436891354e-10, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.25, "f": 0.24561403508771928, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a blue motorcycle parked in a parking lot at night. The motorcycle is parked on the right side of the parking lot, with its front tire facing the camera. The parking lot is empty, with no other vehicles parked in the lot. The sky is dark and"}, "79906": {"image_id": 79906, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.20159019488753482, "Bleu_3": 0.13370981749106947, "Bleu_4": 0.08315339223523019, "METEOR": 0.2515916318940904, "ROUGE_L": 0.2943699731903485, "CIDEr": 7.445733350555807e-10, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a living room with a couch, coffee table, and chairs. There is a window on the left side of the room with a view of the ocean. The room is decorated with blue and white furniture and a painting on the wall.\n\nThe image shows a living room with a"}, "313924": {"image_id": 313924, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.10219406022809462, "Bleu_4": 1.1969290421672298e-05, "METEOR": 0.25560918369087654, "ROUGE_L": 0.21542083578575633, "CIDEr": 7.477029393908725e-13, "SPICE": {"All": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a black shirt and white shorts, and has a tennis racket in her hand. The court is made of grass and there are trees in the background. The woman is standing on the left side of the court, and there is a"}, "571384": {"image_id": 571384, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.25819888974242317, "Bleu_3": 0.19615288823180035, "Bleu_4": 0.13052770239210698, "METEOR": 0.2569324987106151, "ROUGE_L": 0.3038184836745988, "CIDEr": 2.461277150746126e-12, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.20833333333333334, "f": 0.2, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This image shows a group of people standing in front of a bus. They are all wearing suits and ties, and they appear to be waiting for something. The bus is white and has a large window on the side. There are several people standing in front of the bus, looking at it. The sky"}, "84889": {"image_id": 84889, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 7.990635300418294e-07, "Bleu_4": 1.8151458107416433e-09, "METEOR": 0.20891593176572903, "ROUGE_L": 0.19830949284785435, "CIDEr": 2.0505970327534687e-10, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.15625, "f": 0.15873015873015875, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.07692307692307693, "f": 0.08, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a bunch of bananas hanging from a tree in a market. The bananas are yellow and ripe, and they are arranged in a bunch. There are other fruits and vegetables hanging from the tree as well. The image is taken in a market in a tropical country."}, "311846": {"image_id": 311846, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.2363282967133546, "Bleu_3": 0.153862088884353, "Bleu_4": 1.6867300793997426e-05, "METEOR": 0.2171225736465116, "ROUGE_L": 0.3057644110275689, "CIDEr": 9.050776834646165e-08, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a table with three cakes on it. The cakes are decorated with flowers and other decorations. There are also several other tables with cakes on them.\n\nThe image is taken from a wedding reception. The tables are set up with white tablecloths and the cakes"}, "126974": {"image_id": 126974, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.14685945835002273, "Bleu_4": 0.10663135316252687, "METEOR": 0.19841217224595245, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.037730196078125e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.14705882352941177, "f": 0.1724137931034483, "fn": 29.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting at a table with laptops in front of them\n\nThe people in the image are wearing casual clothing and are working on their laptops. The table has a white surface and there are several chairs around it. The room is well lit and there"}, "410735": {"image_id": 410735, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.05825517280241507, "Bleu_3": 4.0791185612592327e-07, "Bleu_4": 1.0848650703059749e-09, "METEOR": 0.16387999551622892, "ROUGE_L": 0.14698795180722893, "CIDEr": 6.0942802886955615e-12, "SPICE": {"All": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a bowl of chili on the left and a pot of soup on the right. The bowl has a spoon in it and the pot has a ladle in it. There are several other bowls and pots on the table, as well as a cutting board and knife. The"}, "497568": {"image_id": 497568, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.17857142856774635, "Bleu_3": 0.08787028385478016, "Bleu_4": 1.1020265663118309e-05, "METEOR": 0.1912627994970485, "ROUGE_L": 0.19690122659780504, "CIDEr": 1.8971205726781224e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.0967741935483871, "f": 0.10344827586206896, "fn": 28.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a large airplane parked at an airport. The plane has a white and blue paint job with the words 'alaska airlines' written on the side. There are people standing around the plane, and a baggage cart is parked next to it. The airport is surrounded by"}, "266363": {"image_id": 266363, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.08058229640108601, "Bleu_3": 4.935848712474828e-07, "Bleu_4": 1.2273047425649952e-09, "METEOR": 0.1725039216053885, "ROUGE_L": 0.20795454545454545, "CIDEr": 8.583387428753515e-13, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a street sign with an arrow pointing to the left. The sign is on the side of the road and there are buildings in the background. The sky is cloudy and there are no people in the image.\n\nThe image is taken from a low angle, looking down the street. The buildings in"}, "555361": {"image_id": 555361, "Bleu_1": 0.3199999999936, "Bleu_2": 0.22857142856681054, "Bleu_3": 0.175896642896203, "Bleu_4": 0.12336052173195815, "METEOR": 0.24883256812325794, "ROUGE_L": 0.38143576417086233, "CIDEr": 2.3766936534748134e-06, "SPICE": {"All": {"pr": 0.08, "re": 0.08695652173913043, "f": 0.08333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The man in the image is wearing a blue shirt and black pants. He is smiling and has a hat on his head. The background is a city street with buildings and cars.\n\nThe man in the image is wearing a blue shirt and black pants. He is smiling and"}, "512495": {"image_id": 512495, "Bleu_1": 0.3199999999936, "Bleu_2": 0.19794866371815806, "Bleu_3": 0.1347912565777208, "Bleu_4": 0.08496143264690868, "METEOR": 0.2933178586328744, "ROUGE_L": 0.29647630619684084, "CIDEr": 2.240316343234743e-10, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08695652173913043, "f": 0.07999999999999999, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a bathroom with a sink, toilet, and shower. The walls are white and the floor is black and white checkered. There is a window on the left side of the room with blinds. The room is well lit and has a mirror on the wall.\n\nThe image"}, "294247": {"image_id": 294247, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.16034596594624356, "Bleu_3": 0.07714527825179367, "Bleu_4": 9.558535115770128e-06, "METEOR": 0.21691080527793738, "ROUGE_L": 0.20383158832702158, "CIDEr": 2.495293425509014e-14, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1, "f": 0.0975609756097561, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image is of a jet airplane flying in the sky. It is a white and red plane with a large wing and a tail. The plane is flying at a high altitude and is in the process of taking off. The sky is clear and blue with a few clouds in the distance. The plane is flying"}, "2124": {"image_id": 2124, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.07284313590699668, "Bleu_3": 4.799308605281424e-07, "Bleu_4": 1.2383960073346406e-09, "METEOR": 0.09862213226055686, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.5635736653829308e-09, "SPICE": {"All": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people watching a rodeo in a large arena. There are several horses and riders on the field, and a large crowd of people in the stands. The arena is surrounded by a fence, and there are several flags and banners hanging from the rafters"}, "477903": {"image_id": 477903, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.06520506636831809, "Bleu_3": 4.4890551563344676e-07, "Bleu_4": 1.184204612229436e-09, "METEOR": 0.126051438534108, "ROUGE_L": 0.19242902208201892, "CIDEr": 2.384173855546709e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.25, "f": 0.19512195121951217, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This image shows a table set with various dishes, including seafood, meat, and vegetables. There are also several glasses of wine and beer on the table. The tablecloth is white and the dishes are arranged in a neat and organized manner. The overall atmosphere is one of a formal"}, "92020": {"image_id": 92020, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.11429089766174176, "Bleu_3": 6.350643060633274e-07, "Bleu_4": 1.5044258140708105e-09, "METEOR": 0.17108642298963986, "ROUGE_L": 0.20331074325074994, "CIDEr": 3.7312568455221784e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.8, "f": 0.4210526315789473, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a man sitting on a chair, holding a blue curling iron in his hand. The dog is sitting on the floor next to him, looking up at him. The room is decorated with a red and white striped rug, a white couch, and a white table with a vase on"}, "267946": {"image_id": 267946, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.19957280121567952, "Bleu_3": 1.0342687475822788e-06, "Bleu_4": 2.371144604551199e-09, "METEOR": 0.25528877232751823, "ROUGE_L": 0.2793893129770992, "CIDEr": 1.6817803397116925e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.23529411764705882, "f": 0.17777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a blue and white sign with the words \"public toilet\" written in Chinese characters. The sign is mounted on a pole in the middle of a street. There are trees and buildings in the background."}, "365317": {"image_id": 365317, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.17238297400489144, "Bleu_4": 0.1324062816098676, "METEOR": 0.2809913322662873, "ROUGE_L": 0.2896142433234421, "CIDEr": 4.375365286105007e-12, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.07692307692307693, "f": 0.07692307692307693, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a tennis player hitting a ball on a tennis court. The player is wearing a red shirt and white shorts, and has a tennis racket in his hand. The court is made of red clay and there are several spectators in the stands watching the match. The sun is shining"}, "451561": {"image_id": 451561, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.3139278971887474, "Bleu_3": 0.22373076962696106, "Bleu_4": 0.12703610616458727, "METEOR": 0.3208060650141163, "ROUGE_L": 0.36357615894039735, "CIDEr": 2.6177897092628368e-08, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.23333333333333334, "f": 0.23728813559322037, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is of a vase with white flowers in it. The vase is sitting in the snow and the flowers are blooming. The background is a field with some trees in the distance. The sky is cloudy and there is some snow on the ground."}, "21232": {"image_id": 21232, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 6.290089214849726e-07, "Bleu_4": 1.5012173807660588e-09, "METEOR": 0.17826412010167303, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.9334810177331694e-11, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.10526315789473684, "f": 0.08695652173913043, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are white and the floor is made of tile. There is a window on the left side of the room and a curtain on the right side. The toilet is in the corner of the room and the sink"}, "238890": {"image_id": 238890, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.2247332874836235, "Bleu_3": 0.15620909290310706, "Bleu_4": 0.09252921909857739, "METEOR": 0.22734871181748315, "ROUGE_L": 0.27555053642010163, "CIDEr": 3.244796581630744e-12, "SPICE": {"All": {"pr": 0.24, "re": 0.3157894736842105, "f": 0.2727272727272727, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people walking on a beach at sunset. The sun is setting behind them, casting a golden glow on the water. The people are dressed in various colors and are walking in different directions. Some of them are holding surfboards and others are walking with their dogs. The beach is"}, "517315": {"image_id": 517315, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.11952286093128565, "Bleu_3": 0.0641952261839719, "Bleu_4": 8.405394134956185e-06, "METEOR": 0.19319349690806675, "ROUGE_L": 0.2772727272727273, "CIDEr": 1.1675977395212841e-13, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2727272727272727, "f": 0.2790697674418604, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a bed with a stack of books on it. There are also some clothes on the bed. The room is dimly lit and there is a window in the background.\n\nThe image shows a bed with a stack of books on it. There are also some clothes on the bed. The room is"}, "569272": {"image_id": 569272, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.25253813613284526, "Bleu_3": 0.18931078775968688, "Bleu_4": 0.1558500916173644, "METEOR": 0.3338558032519786, "ROUGE_L": 0.35442220787604906, "CIDEr": 2.6571353107109e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.18518518518518517, "f": 0.2127659574468085, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on top of a desk with a computer and other office supplies.\n\nThe cat is looking up at the camera with its ears perked up.\n\nThe desk has a computer, a keyboard, a mouse, and a cup of coffee on it.\n\nThere are"}, "163372": {"image_id": 163372, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.1771229771045114, "Bleu_3": 0.13681632034027527, "Bleu_4": 0.08546594915472348, "METEOR": 0.1806115201894988, "ROUGE_L": 0.22889305816135083, "CIDEr": 2.925044569394596e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows two zebras standing in the dirt, one of them appears to be injured. The zebras are brown and white in color, with long stripes on their backs. They are standing in a field with some trees in the background. The sky is cloudy and there is a small"}, "283910": {"image_id": 283910, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 0.09970052069750876, "Bleu_4": 0.06607272734339885, "METEOR": 0.22673809227466818, "ROUGE_L": 0.24610951008645532, "CIDEr": 4.919874207738583e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of sheep grazing in a green field with a dog running in the background. The sheep are white with black spots and the dog is brown with a black collar. The image is taken from a distance and the sheep are in the foreground.\n\nThe image is taken from a"}, "180188": {"image_id": 180188, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.25819888974242317, "Bleu_3": 0.19615288823180035, "Bleu_4": 0.13052770239210698, "METEOR": 0.24311698132686402, "ROUGE_L": 0.3038184836745988, "CIDEr": 2.3764671697559207e-12, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a train on the tracks, with a graffiti on the side of the train. The train is parked on the tracks, with no other trains in sight. The tracks are made of metal and are in good condition. The train is painted in a brown and gray color scheme. There are no"}, "442305": {"image_id": 442305, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.06726727939832501, "Bleu_3": 4.4896509096312353e-07, "Bleu_4": 1.1657633846364334e-09, "METEOR": 0.1724137931034483, "ROUGE_L": 0.2167219327333018, "CIDEr": 8.305657801885368e-11, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.13333333333333333, "f": 0.125, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a wall of paintings. They are all wearing suits and ties, and one of them is holding a microphone. The woman in the middle is smiling and talking to the man on her right, who is nodding his head. The man"}, "390134": {"image_id": 390134, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.31008683646516966, "Bleu_3": 0.2606715902216106, "Bleu_4": 0.20918707281841498, "METEOR": 0.3200958080479447, "ROUGE_L": 0.4236111111111111, "CIDEr": 0.00010247906272889567, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a slice of cake on a plate with a fork on the side. The cake appears to be made with blackberries and has a crumbly texture. There is a small amount of cake left on the plate."}, "261487": {"image_id": 261487, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.09531293854471146, "Bleu_3": 5.590278679123735e-07, "Bleu_4": 1.360449889464037e-09, "METEOR": 0.2014834655349517, "ROUGE_L": 0.23961840628507297, "CIDEr": 1.1951822660751796e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.3333333333333333, "f": 0.25641025641025644, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.8333333333333334, "f": 0.5555555555555556, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people playing tennis on a court. They are all wearing tennis shoes and holding rackets. One person is hitting the ball with a racket while another person is watching. There are several other people on the court, some of whom are also hitting the ball with rackets. The"}, "70744": {"image_id": 70744, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.23094010767127685, "Bleu_3": 0.17589664289627485, "Bleu_4": 0.13580418932543062, "METEOR": 0.2426783885411298, "ROUGE_L": 0.2501464557703574, "CIDEr": 1.982443405502051e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting at a table outside a restaurant, looking at a large window with surfboards on display. The window is made of glass and has a reflection of the surfboards on the outside. The people are all wearing sunglasses and some are holding drinks. The"}}}