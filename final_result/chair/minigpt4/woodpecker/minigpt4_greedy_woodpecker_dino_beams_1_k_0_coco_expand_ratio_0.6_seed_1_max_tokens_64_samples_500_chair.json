{"overall": {"Bleu_1": 0.2658639524488852, "Bleu_2": 0.17952672704470968, "Bleu_3": 0.11479889444781739, "Bleu_4": 0.07223674075516517, "METEOR": 0.2159508954809953, "ROUGE_L": 0.27386822866031, "CIDEr": 0.011640430510514794, "SPICE": 0.1908560689778131}, "imgToEval": {"281533": {"image_id": 281533, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2608202654732723, "Bleu_3": 0.19342752308546937, "Bleu_4": 0.14739391640949856, "METEOR": 0.3007520843018992, "ROUGE_L": 0.31504196255648803, "CIDEr": 1.721545195463044e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2727272727272727, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 32.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.5, "f": 0.1818181818181818, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5555555555555556, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a dog sitting in front of a television. The dog is watching the television, with its ears perked up. The television is showing a nature documentary with a herd of deer running across the screen. The room is decorated with a rug.\n\nThe dog is brown."}, "397773": {"image_id": 397773, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.14580296087694455, "Bleu_3": 0.07676176340636935, "Bleu_4": 9.95793413350648e-06, "METEOR": 0.19628400348103406, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.2584440069568804e-09, "SPICE": {"All": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 22.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This image shows a bowl of pasta with meatballs and broccoli. The pasta is cooked and has a golden brown color. The meatballs are made of ground beef and have a crispy exterior. The broccoli is steamed and has a green color. A fork is next to the bowl."}, "371250": {"image_id": 371250, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.17320508074981525, "Bleu_3": 1.0926082435777024e-06, "Bleu_4": 2.774870273442235e-09, "METEOR": 0.18349670209233923, "ROUGE_L": 0.3294329432943295, "CIDEr": 0.027654811530915122, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.24, "f": 0.2727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a living room with a couch. The couch is brown and has two pillows on it. A remote control is on the couch."}, "573877": {"image_id": 573877, "Bleu_1": 0.4444444444320988, "Bleu_2": 0.3187276291468583, "Bleu_3": 0.24628814285114745, "Bleu_4": 0.1919704825905453, "METEOR": 0.3034062020708504, "ROUGE_L": 0.37654320987654316, "CIDEr": 0.001367250319039266, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3181818181818182, "f": 0.3181818181818182, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a white cat sitting on a laptop. The cat is looking at a computer screen. The laptop is open and placed on a desk. The desk is not in front of a window."}, "181859": {"image_id": 181859, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.24671758189216153, "Bleu_3": 0.11142496535261216, "Bleu_4": 1.339275015027965e-05, "METEOR": 0.26448899100579093, "ROUGE_L": 0.2794502617801047, "CIDEr": 3.819950071154818e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10526315789473684, "f": 0.12121212121212122, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image is of a cat lying on a sink in a bathroom. The cat is gray and white with blue eyes. The sink is made of stone. The faucet is located on the sink. A towel is hanging on the left side of the sink."}, "119939": {"image_id": 119939, "Bleu_1": 0.1641791044751615, "Bleu_2": 0.0863868425568369, "Bleu_3": 0.048602724500592415, "Bleu_4": 6.5080438091593584e-06, "METEOR": 0.12357723577235774, "ROUGE_L": 0.15257628814407204, "CIDEr": 2.9064837181654986e-20, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of three people standing on the sidewalk in front of a building. They are all wearing black and white clothing and have skateboards in their hands. The building is a large, modern structure with large windows and a large sign on the front that reads 'no parking'. A tree is in front of the building.\n\nThe people are standing on the sidewalk."}, "385320": {"image_id": 385320, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.14887283354071895, "Bleu_3": 0.12444506805639836, "Bleu_4": 0.10646588104484676, "METEOR": 0.24136560567375717, "ROUGE_L": 0.29901960784313725, "CIDEr": 8.506288965247126e-09, "SPICE": {"All": {"pr": 0.3125, "re": 0.23809523809523808, "f": 0.27027027027027023, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a girl sitting in a chair. She is holding a toothbrush in her mouth. The girl is wearing a blue and white striped shirt and white shorts. The room features a bed in the background and a window.\n\nThere is no couch in the image."}, "490415": {"image_id": 490415, "Bleu_1": 0.15873015872763924, "Bleu_2": 0.13386988814827444, "Bleu_3": 0.10552741969670305, "Bleu_4": 0.07911223895597908, "METEOR": 0.222819667415662, "ROUGE_L": 0.24314897857498752, "CIDEr": 5.162682352891555e-17, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.1724137931034483, "f": 0.2173913043478261, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.058823529411764705, "f": 0.07999999999999999, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two men in a park. One man is flying a kite, holding it and looking at it. The other man is riding a bike, holding it and looking at it.\n\nThe sky is clear and blue, with a few white clouds scattered across it. The man is wearing a black shirt and jeans. There is no backpack in the scene."}, "432293": {"image_id": 432293, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.23973165073456326, "Bleu_3": 0.12708595986317403, "Bleu_4": 1.6604746091112762e-05, "METEOR": 0.20384374878721187, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.0024161926073769002, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.12, "f": 0.12499999999999997, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a pizza on a cutting board. The pizza is topped with shrimp, tomatoes, and cheese. The pizza is being spread with toppings. There is a spatula nearby."}, "256301": {"image_id": 256301, "Bleu_1": 0.16161616161452913, "Bleu_2": 0.07033799484461889, "Bleu_3": 3.7085380926091443e-07, "Bleu_4": 8.537569458059965e-10, "METEOR": 0.14508071483694923, "ROUGE_L": 0.1075837742504409, "CIDEr": 1.9491631700368603e-42, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.1724137931034483, "f": 0.18867924528301888, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two signs with red letters. The first sign is located on the left side of the image, while the second sign is located on the right side. The signs are surrounded by people, some of whom are taking pictures, standing on the sidewalk. The people are looking at a baseball game and are surrounded by a fence. \n\nIn the background, there is a building with a large window on the side. The building appears to be a restaurant. There are no other buildings or restaurants in the scene. \n\nOverall, the background of the signs is red."}, "361103": {"image_id": 361103, "Bleu_1": 0.151999999998784, "Bleu_2": 0.1212834589674888, "Bleu_3": 0.062073944609287175, "Bleu_4": 6.654141786656436e-06, "METEOR": 0.12528174736075215, "ROUGE_L": 0.1664392905866303, "CIDEr": 2.8629462997354947e-67, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.21739130434782608, "f": 0.23809523809523808, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a street with tall buildings on either side. A sidewalk is on either side of the street. There are people walking on the sidewalk and cars driving down the street. The buildings are made of brick and have large windows on the upper floors. There are also streetlights on the corners of the street.\n\nThere are no cars or buildings in the scene.\n\nPeople are walking on the street and on the sidewalk. Some people are talking on the phone, reading a paper, looking at their cell phones, playing a game of soccer, and doing a blurry image of a person in a yellow shirt. \n\nThe overall atmosphere of the scene is lively and bustling, with people going about their daily activities."}, "567562": {"image_id": 567562, "Bleu_1": 0.17808219177838244, "Bleu_2": 0.08613995196188708, "Bleu_3": 0.05934629792619968, "Bleu_4": 0.04156910885526344, "METEOR": 0.17841011856203476, "ROUGE_L": 0.1922557406573615, "CIDEr": 2.94359627040149e-22, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.19047619047619047, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of four people sitting around a table eating pizza and drinking soda. The table is made of plastic. The table is covered with a green tablecloth. There are two chairs around the table.\n\nThe people are eating pizza. They are wearing a red hat. Some of the people are playing with a box. They are wearing a pink shirt. Some of the people are wearing a white shirt."}, "448320": {"image_id": 448320, "Bleu_1": 0.3399999999932, "Bleu_2": 0.22038926600328315, "Bleu_3": 0.12649010267330832, "Bleu_4": 0.08100614113987657, "METEOR": 0.24244713941485194, "ROUGE_L": 0.3335358444714459, "CIDEr": 1.1593598506509366e-08, "SPICE": {"All": {"pr": 0.15, "re": 0.10714285714285714, "f": 0.125, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image is of a bathroom with a sink, toilet, and mirror. The sink is made of wood and has a spherical bowl in the center. The toilet has a seat. The mirror is mounted on the wall above the sink. There is no lid or light in the scene."}, "14874": {"image_id": 14874, "Bleu_1": 0.16666666666388893, "Bleu_2": 0.11884567213338457, "Bleu_3": 0.07867853199299275, "Bleu_4": 0.05406590440349788, "METEOR": 0.20688726364300392, "ROUGE_L": 0.19830949284785435, "CIDEr": 1.5955114743550994e-15, "SPICE": {"All": {"pr": 0.3, "re": 0.15789473684210525, "f": 0.20689655172413793, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a man standing on a snowy mountain. The man is wearing a blue and green jacket and black pants. He has goggles on his face. Snowboards are on the man's feet. The man has a smile on his face.\n\nThe background is a mountain range with snow. There are no peaks or trees in the scene."}, "373713": {"image_id": 373713, "Bleu_1": 0.2077922077895092, "Bleu_2": 0.1478947733273738, "Bleu_3": 0.09564344584528334, "Bleu_4": 1.0427578811980992e-05, "METEOR": 0.19127337779050274, "ROUGE_L": 0.21698532681191643, "CIDEr": 2.59581373654887e-27, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of three people sitting around a table in a room. They are all wearing black shirts and jeans, and one of them is holding a laptop. The room is dimly lit, and there are several laptops and other electronic devices on the table. The people are all looking at the laptops and engaging in various activities, such as talking to each other, playing a game with a Wii remote, and holding laptops."}, "539326": {"image_id": 539326, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.15352206215446232, "Bleu_3": 0.13052045381230626, "Bleu_4": 0.10642371354817973, "METEOR": 0.3279986480525746, "ROUGE_L": 0.3231312536786345, "CIDEr": 1.6462930700276943e-13, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.21428571428571427, "f": 0.14634146341463417, "fn": 11.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a herd of 14 cows grazing in a green field. The cows are brown and white. Some of the cows have long, curly horns. They are standing in a line, with their heads down and their tails swishing back and forth. \n\nIn the background, there is a hill with trees on it."}, "20059": {"image_id": 20059, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.191273013914278, "Bleu_3": 0.14118482396355853, "Bleu_4": 0.11031958317495014, "METEOR": 0.24910092025642588, "ROUGE_L": 0.3083032490974729, "CIDEr": 1.298980293135705e-06, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 31.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}}, "caption": "The image shows two zebras grazing on grass. The zebras are black and white with long manes and tails. They are standing in a fenced area. The grass is green and surrounds the clearing. There are two rocks in the scene."}, "530520": {"image_id": 530520, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.23401985301353292, "Bleu_3": 0.1825664475653434, "Bleu_4": 0.11482824114295145, "METEOR": 0.18478516906086095, "ROUGE_L": 0.2793893129770992, "CIDEr": 5.925918529862051e-06, "SPICE": {"All": {"pr": 0.06060606060606061, "re": 0.08333333333333333, "f": 0.07017543859649122, "fn": 22.0, "numImages": 1.0, "fp": 31.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a group of four people sitting on the grass outside a building. They are using laptops and wearing casual clothing. The people are working on their laptops. The building has windows and a flat roof."}, "117337": {"image_id": 117337, "Bleu_1": 0.05263157894598341, "Bleu_2": 1.1926756082899304e-09, "Bleu_3": 3.406021549710842e-12, "Bleu_4": 1.8330256088670778e-13, "METEOR": 0.04665523156089195, "ROUGE_L": 0.08187919463087248, "CIDEr": 9.533838140522014e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.19047619047619047, "f": 0.20512820512820512, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "I'm sorry, but I cannot provide a refined passage based on the given information. The supplementary information does not contain any counting, specific, or overall information that can be used to correct or refine the passage."}, "256504": {"image_id": 256504, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1655563685096674, "Bleu_4": 0.13582344277251354, "METEOR": 0.24597027091950266, "ROUGE_L": 0.3400696864111499, "CIDEr": 1.5466927021547215e-07, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.10344827586206896, "f": 0.10344827586206896, "fn": 26.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two people sitting on a bed with laptops in front of them. The bed is covered in a colorful tapestry with a large mandala design on it. The people are looking at their laptops. The people are wearing a hoodie."}, "265472": {"image_id": 265472, "Bleu_1": 0.3103448275755054, "Bleu_2": 0.23541180770711662, "Bleu_3": 0.18328967100454094, "Bleu_4": 0.12405382419427236, "METEOR": 0.2879082134193859, "ROUGE_L": 0.42152023692003954, "CIDEr": 0.0056881423402390455, "SPICE": {"All": {"pr": 0.1875, "re": 0.3333333333333333, "f": 0.24000000000000005, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a plate of food with bacon, bananas, and toast. The bacon is cooked and crispy. The bananas are sliced and placed on top of the bacon."}, "441083": {"image_id": 441083, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.2142857142812956, "Bleu_3": 0.09922692357042127, "Bleu_4": 1.207209618677905e-05, "METEOR": 0.20910650798539818, "ROUGE_L": 0.27096057745696833, "CIDEr": 4.872460171055486e-08, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.16666666666666666, "f": 0.1509433962264151, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a dog sitting in the back seat of a car, looking out the window. The car is parked on the side of the road, and there are trees visible in the background. The dog's collar is visible, and it appears to be a labrador retriever."}, "126958": {"image_id": 126958, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.29355449650608006, "Bleu_3": 0.14060645539827946, "Bleu_4": 1.744711530992254e-05, "METEOR": 0.2138021067311323, "ROUGE_L": 0.33395901767558267, "CIDEr": 0.002883087081059251, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.17391304347826086, "f": 0.22857142857142854, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a room with a blue ceiling. There is a mirror on the wall opposite the door, and a window on the left side of the room. The room is empty."}, "484075": {"image_id": 484075, "Bleu_1": 0.18292682926606188, "Bleu_2": 0.11640504929350137, "Bleu_3": 0.07979793176853725, "Bleu_4": 0.050360142885309316, "METEOR": 0.15939886230662242, "ROUGE_L": 0.19436036323084274, "CIDEr": 1.86674405917435e-29, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two desks with a computer, keyboard, mouse, and other office supplies on them. The desks are made of wood. There is a computer with a keyboard and a mouse on one of the desks. There are also office supplies on the desks. A small lamp is placed on one of the desks. \n\nThere is a window in the background, through which a cat can be seen. There is no view of the city or any books in the image."}, "274528": {"image_id": 274528, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.0958411776672495, "Bleu_4": 1.1637341978585758e-05, "METEOR": 0.15474520363148175, "ROUGE_L": 0.21903052064631956, "CIDEr": 5.2084937500597037e-11, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14285714285714285, "f": 0.1568627450980392, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a truck with a banner on it that reads \"save the date\". The people are wearing blue jackets and blue shirts. Some of the people are holding bicycles. The truck has a banner on it that reads \"save the date\"."}, "286820": {"image_id": 286820, "Bleu_1": 0.3157894736675901, "Bleu_2": 4.188539082690383e-09, "Bleu_3": 1.0105521745868431e-11, "Bleu_4": 5.039518688197803e-13, "METEOR": 0.1846700920520278, "ROUGE_L": 0.1598951507208388, "CIDEr": 0.0201780678360289, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.4, "f": 0.37500000000000006, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three carpets in different shades of green. There are no iPhones or screens on the carpets."}, "69236": {"image_id": 69236, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 7.901769277795583e-07, "Bleu_4": 1.8299115122529755e-09, "METEOR": 0.15831707652790872, "ROUGE_L": 0.20346897931954633, "CIDEr": 9.398376446503848e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.10714285714285714, "f": 0.14285714285714285, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a park at night with three benches and two trees. The benches are made of metal and wood. The trees have leaves on them. The park is well lit with two streetlights, which are made of metal. There are no people in the image."}, "333237": {"image_id": 333237, "Bleu_1": 0.47368421051385046, "Bleu_2": 0.3752666192913589, "Bleu_3": 0.2863141903004873, "Bleu_4": 0.22757792930620926, "METEOR": 0.3183733550202007, "ROUGE_L": 0.4317492416582407, "CIDEr": 0.00020501478474103414, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.15, "f": 0.11111111111111112, "fn": 17.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image is a bedroom with a bed, a dresser, and a window. The walls are covered in red and white striped wallpaper. There is a white bedspread on the bed. The dresser has a mirror on it."}, "285258": {"image_id": 285258, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2976467318172675, "Bleu_3": 0.22106982192970415, "Bleu_4": 0.15245427153839244, "METEOR": 0.32433310337360927, "ROUGE_L": 0.34882058613295214, "CIDEr": 2.1327569267477626e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.32142857142857145, "f": 0.2950819672131148, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 9.0}, "Relation": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a group of four dogs playing in a grassy area. The dogs are wearing collars and are of different breeds. The position of the dog in the line is third. They are playing with each other and with a frisbee."}, "574454": {"image_id": 574454, "Bleu_1": 0.13043478260586014, "Bleu_2": 0.07613869876101455, "Bleu_3": 5.088456599619498e-07, "Bleu_4": 1.3230383778958116e-09, "METEOR": 0.06339994216750083, "ROUGE_L": 0.12726008344923503, "CIDEr": 1.2574590926843899e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.21052631578947367, "f": 0.22857142857142856, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "There are no people in this image. There are no kite surfers in this image. The image features Table Mountain in the background. There are waves crashing on the shore. There are rocks and sand in the foreground. There are no kite surfers in this image."}, "57703": {"image_id": 57703, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.23260756692519305, "Bleu_3": 0.15451551194272495, "Bleu_4": 0.09624140398979388, "METEOR": 0.25293736711544357, "ROUGE_L": 0.28968792401628224, "CIDEr": 3.3377475354082176e-08, "SPICE": {"All": {"pr": 0.1875, "re": 0.2, "f": 0.19354838709677422, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of four people standing in a forest with their dogs. They are all wearing hiking boots and backpacks, and one person is holding a leash. The dogs are all different breeds and sizes, and they are all wearing collars and leashes."}, "70294": {"image_id": 70294, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.1857681456014507, "Bleu_3": 0.08897106801212076, "Bleu_4": 1.1005918527347897e-05, "METEOR": 0.2396476255941423, "ROUGE_L": 0.28113837999769564, "CIDEr": 9.738128668400457e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.08, "f": 0.10810810810810811, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a blue bus parked on the side of a road. The bus has a large window on the front and a small window on the side. The bus is parked in front of a building with a large window on the front. The building has a large sign."}, "279769": {"image_id": 279769, "Bleu_1": 0.23809523809145886, "Bleu_2": 0.1752768273470684, "Bleu_3": 0.12629700576227398, "Bleu_4": 0.07612143701114087, "METEOR": 0.21131694642965, "ROUGE_L": 0.21664129883307962, "CIDEr": 3.227269765969593e-17, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.3125, "f": 0.29411764705882354, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a banana on a table with a piece of paper on top of it. The banana is peeled and has a few brown spots on it. The paper has a few notes written on it. There are also some other objects on the table, including a pen and a pencil.\n\nThere is no other paper or pencil in the scene."}, "541474": {"image_id": 541474, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.08243669902025869, "Bleu_4": 1.0393938325822104e-05, "METEOR": 0.17443208334294732, "ROUGE_L": 0.2238532110091743, "CIDEr": 1.819860574011809e-11, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a person doing snowboarding on a steep slope. The person is wearing a blue and white jacket and blue and white pants, and has a white helmet on their head. They are holding onto a snowboard. The sky is blue and there are some clouds in the background."}, "217561": {"image_id": 217561, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.09837387536436676, "Bleu_3": 6.936182651865935e-07, "Bleu_4": 1.8580221322976231e-09, "METEOR": 0.10906855175422862, "ROUGE_L": 0.2149779735682819, "CIDEr": 0.0005423412864857098, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.14285714285714285, "f": 0.12698412698412698, "fn": 24.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a table set with white plates and silverware on it. There are no napkins or tablecloth in the scene. There are no flowers or vases on the table."}, "303778": {"image_id": 303778, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.26130213377863615, "Bleu_3": 0.17852603329789454, "Bleu_4": 2.0079789489222805e-05, "METEOR": 0.3562050359849653, "ROUGE_L": 0.41908396946564885, "CIDEr": 2.597408195367517e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.2777777777777778, "f": 0.2631578947368421, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a baseball player in a blue and white uniform, holding a bat and standing on the field. The player is wearing cleats and a helmet. \n\nThere are no other players or spectators in the background."}, "40426": {"image_id": 40426, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.20568833779665252, "Bleu_3": 0.16452500422386435, "Bleu_4": 0.13784906211126996, "METEOR": 0.3414700775244653, "ROUGE_L": 0.34078212290502796, "CIDEr": 1.7050426319143156e-05, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.14285714285714285, "f": 0.2051282051282051, "fn": 24.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a blender with strawberries in it on the kitchen countertop. The blender is turned on. There is a bowl of strawberries on the countertop. The bowl contains ice cream. There is also a spoon in the bowl."}, "324291": {"image_id": 324291, "Bleu_1": 0.18421052631336565, "Bleu_2": 0.11081832769926027, "Bleu_3": 0.0792569896913029, "Bleu_4": 0.05110312574946105, "METEOR": 0.13335572350565267, "ROUGE_L": 0.15940766550522648, "CIDEr": 3.487402212792925e-24, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.18181818181818182, "f": 0.16, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows three women riding horses in a green field. The women are wearing shirts, but there are no pants or saddles or bridles. The woman is riding a horse. The woman is walking a horse. The woman is walking a dog. The woman's shirt is blue. The horses are wearing ribbons, with one wearing a blue ribbon and the other two wearing red ribbons. The background is a blue sky with no clouds."}, "96241": {"image_id": 96241, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.10635890745081387, "Bleu_3": 6.093393760732184e-07, "Bleu_4": 1.465869850942177e-09, "METEOR": 0.20732994474956376, "ROUGE_L": 0.21580188679245285, "CIDEr": 8.117138471255454e-11, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.06666666666666667, "f": 0.07547169811320756, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of four people standing next to a train that is parked on the tracks. The train is black and orange. The people are standing on the platform and looking at the train. The image is in black and white.\n\nThere are no other people in the scene."}, "326911": {"image_id": 326911, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.12371791482379726, "Bleu_3": 0.09922692357042126, "Bleu_4": 0.08073097285651323, "METEOR": 0.21029481975825648, "ROUGE_L": 0.26341764342998153, "CIDEr": 5.421786347080031e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.22727272727272727, "f": 0.1923076923076923, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a black cat sitting on the sidewalk next to a bicycle. The cat is looking at the bicycle with its head tilted to the side. The bicycle has two baskets on the front and a bell on the handlebars. The cat is not wearing a hat."}, "209222": {"image_id": 209222, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 0.14508189984797495, "Bleu_4": 0.09234164414844837, "METEOR": 0.23358935100332584, "ROUGE_L": 0.29468599033816417, "CIDEr": 2.8731884926728763e-08, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.3684210526315789, "f": 0.3333333333333333, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two men in the scene. One man is sitting on a bench and the other man is walking. The man sitting on the bench is wearing a black hoodie. The bench is made of concrete. There is a tree in the scene."}, "362293": {"image_id": 362293, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.23791547571099586, "Bleu_3": 0.129605673244496, "Bleu_4": 0.08083053722301232, "METEOR": 0.24669269468327526, "ROUGE_L": 0.23565121412803533, "CIDEr": 2.50978345521445e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.26666666666666666, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a horse pulling a carriage on a city street. The carriage is decorated with green and white. Two people are inside the carriage. The street is lined with buildings and there are cars parked on the side of the road. The sky is cloudy and there are trees in the scene."}, "144481": {"image_id": 144481, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.11459194182328535, "Bleu_3": 6.280739235613542e-07, "Bleu_4": 1.4774310979864886e-09, "METEOR": 0.19675471486629503, "ROUGE_L": 0.17579250720461098, "CIDEr": 2.4629224093411704e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image is of a museum exhibit with several ancient Greek vases on display. The vases are made of clay and have intricate designs on them. They are displayed on a blue carpet in a dimly lit room. The room has white walls and a high ceiling. There are no other artifacts in the scene."}, "433804": {"image_id": 433804, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.09589266029382536, "Bleu_3": 6.899287365489461e-07, "Bleu_4": 1.867506984265124e-09, "METEOR": 0.18095238095238095, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.00231693095061385, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two boats traveling down a river. The boats are white and blue, with one boat having a blue stripe on the side. Palm trees surround the river."}, "142815": {"image_id": 142815, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.15450054281980155, "Bleu_3": 0.08931787952898414, "Bleu_4": 1.0193370718013012e-05, "METEOR": 0.2297491945486368, "ROUGE_L": 0.23756867654217953, "CIDEr": 1.1247838447741622e-19, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.25, "f": 0.32432432432432434, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5, "f": 0.6153846153846154, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows two men sitting on a bed. One man is holding a camera, while the other man is playing a video game. The man is wearing a gray shirt and has a relaxed expression on his face. The bed is made of wood and is covered with a black sheet. In the background, there is a window with a picture of a dog. The room is dim."}, "85292": {"image_id": 85292, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.18476851073338801, "Bleu_3": 0.0982466623305646, "Bleu_4": 1.2829843028855697e-05, "METEOR": 0.2378152344587821, "ROUGE_L": 0.3172362555720654, "CIDEr": 1.5119830325661382e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a train traveling along a track. The train is made up of a train car. A tank car is included in the train. The train is carrying cargo. The train is traveling slowly."}, "500423": {"image_id": 500423, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.15320195579385062, "Bleu_3": 0.08671123520251264, "Bleu_4": 1.1682600305257854e-05, "METEOR": 0.18791521611022935, "ROUGE_L": 0.24636510500807754, "CIDEr": 5.911846888677067e-06, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.24, "f": 0.2727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a train parked in a train station. The train is red and orange. There are people waiting for the train. The train has six windows. There is a sign on the front of the train."}, "196280": {"image_id": 196280, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.18712785740116275, "Bleu_3": 0.0870964272053807, "Bleu_4": 1.0616941372973598e-05, "METEOR": 0.19819339071068953, "ROUGE_L": 0.24358243011979464, "CIDEr": 3.339092464583797e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19230769230769232, "f": 0.17857142857142855, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a boy standing in front of a kitchen counter. The boy is wearing a blue shirt and blue pants. He is holding a pot in his hand. On the kitchen counter, there are several pans and a pot of soup. In the background, there are a few scattered objects, including a skeleton."}, "84752": {"image_id": 84752, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.18971331171167066, "Bleu_3": 0.1380949094291484, "Bleu_4": 0.10712127994780991, "METEOR": 0.1862367819220883, "ROUGE_L": 0.29756097560975614, "CIDEr": 1.971764206966599e-07, "SPICE": {"All": {"pr": 0.10810810810810811, "re": 0.14814814814814814, "f": 0.125, "fn": 23.0, "numImages": 1.0, "fp": 33.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21052631578947367, "re": 0.3333333333333333, "f": 0.2580645161290323, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}}, "caption": "The image shows a red and white plane sitting on the ground in front of a building. The plane has a red and white tail. There are people looking at the plane. The sky is cloudy and there are trees in the background."}, "222317": {"image_id": 222317, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.3001501125856073, "Bleu_3": 0.24903099802112147, "Bleu_4": 0.2064597158900768, "METEOR": 0.38220480914432287, "ROUGE_L": 0.4272373540856031, "CIDEr": 5.8220937048585496e-05, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2777777777777778, "f": 0.21276595744680854, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a dog sitting on a couch in a living room. The dog is wearing a brown collar. The dog is laying on a blanket that is blue. There is a lamp on the table."}, "544421": {"image_id": 544421, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.1923131632828435, "Bleu_3": 0.10090325449929138, "Bleu_4": 1.3089162801548402e-05, "METEOR": 0.20347520894242366, "ROUGE_L": 0.24636510500807754, "CIDEr": 0.00035893436437758484, "SPICE": {"All": {"pr": 0.09375, "re": 0.15789473684210525, "f": 0.11764705882352941, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image is a cake with a waterfall on top of it. The cake is made of chocolate. The icing on top of the cake is green. There are trees and rocks on the sides of the cake."}, "526827": {"image_id": 526827, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.2824395152347793, "Bleu_3": 1.4722118261223209e-06, "Bleu_4": 3.3956656085270314e-09, "METEOR": 0.28676668388337867, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.019646623025586653, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a pair of scissors on a table. The scissors are made of plastic and have red, yellow, and green handles. The table is blue."}, "527529": {"image_id": 527529, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.20739033893928357, "Bleu_3": 0.11404064937195534, "Bleu_4": 1.5170687183090523e-05, "METEOR": 0.21925656594403106, "ROUGE_L": 0.2869238005644403, "CIDEr": 0.0006874816177987032, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3125, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a white cat sitting on top of a black bag. The cat is sniffing the bag. The bag is black. \n\nThere are no other items in the scene."}, "152785": {"image_id": 152785, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.2236067977408484, "Bleu_3": 0.12954303153373917, "Bleu_4": 1.772984226393885e-05, "METEOR": 0.24167783907023005, "ROUGE_L": 0.3715736040609137, "CIDEr": 0.031119345142481575, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.30434782608695654, "f": 0.3333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a group of seven elephants walking across a dry field. The elephants are holding twigs and pointing them forward with their ears."}, "516212": {"image_id": 516212, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.21797089763394864, "Bleu_3": 0.1786457781290674, "Bleu_4": 0.14687928362449137, "METEOR": 0.3373200813540453, "ROUGE_L": 0.39563679245283023, "CIDEr": 6.14313886136164e-10, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.35294117647058826, "f": 0.35294117647058826, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on top of a white microwave oven in a kitchen. The cat is looking directly at the camera with its eyes wide open. The microwave oven does not have a digital display on the front. There are no other kitchen utensils or countertop in the scene."}, "403378": {"image_id": 403378, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.16001422411453173, "Bleu_3": 0.0892630166489473, "Bleu_4": 1.193951426417031e-05, "METEOR": 0.25515535244323556, "ROUGE_L": 0.28728414442700156, "CIDEr": 1.0970124299086801e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a woman holding a mirror and looking at herself. She is wearing a white dress and has long blonde hair. The background is dark. There is a table with candles and a vase on it."}, "216051": {"image_id": 216051, "Bleu_1": 0.382352941165225, "Bleu_2": 0.2636640221444497, "Bleu_3": 0.205590915082101, "Bleu_4": 0.17029144469375576, "METEOR": 0.34968178279559475, "ROUGE_L": 0.41567291311754684, "CIDEr": 0.0004506191243756428, "SPICE": {"All": {"pr": 0.07547169811320754, "re": 0.13793103448275862, "f": 0.0975609756097561, "fn": 25.0, "numImages": 1.0, "fp": 49.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.19047619047619047, "re": 0.3333333333333333, "f": 0.24242424242424246, "fn": 8.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}}, "caption": "The image shows a woman sitting on a bench in a park, holding a dog. The woman is wearing a purple shirt and pants. The dog is black. The bench is made of wood."}, "543043": {"image_id": 543043, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.15191090505870355, "Bleu_3": 0.10669435290940495, "Bleu_4": 0.07569298710692891, "METEOR": 0.22871655769993976, "ROUGE_L": 0.25558659217877094, "CIDEr": 7.93103410909479e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows two cars parked in front of two cabins. The sports car is red. The cabin has a large wooden porch with a small table on it. \n\nThere are no other cars parked in front of the cabin."}, "392493": {"image_id": 392493, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.12354612406992554, "Bleu_3": 0.06973999503999065, "Bleu_4": 9.370187147557456e-06, "METEOR": 0.18752786536727936, "ROUGE_L": 0.1941438574156588, "CIDEr": 3.410742384533599e-09, "SPICE": {"All": {"pr": 0.1875, "re": 0.10344827586206896, "f": 0.13333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a grassy field. They are holding colorful kites. The kites are flying in the sky, creating a lively and colorful scene. The people are wearing casual clothing and are standing in a line, with their kites held high."}, "524681": {"image_id": 524681, "Bleu_1": 0.24324324323995616, "Bleu_2": 0.16326908396679413, "Bleu_3": 0.10356163305503084, "Bleu_4": 0.06289043236215319, "METEOR": 0.26151144151096317, "ROUGE_L": 0.2172751558325913, "CIDEr": 3.0472826225275164e-25, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a group of five people standing on a sandy beach. The people are wearing casual clothing and some of them are playing frisbee, while others are playing a game or with a skateboard. A kite is flying in the sky. Some of the people are wearing a hat and looking up at a building, while others are wearing a green shirt and a black hat and looking up at the sky."}, "265816": {"image_id": 265816, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.23632829671335462, "Bleu_3": 0.153862088884353, "Bleu_4": 0.11279843877106886, "METEOR": 0.210883872690272, "ROUGE_L": 0.308080808080808, "CIDEr": 1.7114412717375502e-08, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.21428571428571427, "f": 0.1846153846153846, "fn": 22.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3076923076923077, "f": 0.29629629629629634, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a horse and a carriage in front of a building with a balcony and windows. The building has a red roof and white walls. The horse is wearing a black harness and has a yellow ribbon. The carriage is white and has a black canopy."}, "528984": {"image_id": 528984, "Bleu_1": 0.3214285714170919, "Bleu_2": 0.21821789022805463, "Bleu_3": 0.12234957142600308, "Bleu_4": 1.645192939931118e-05, "METEOR": 0.16538596471724312, "ROUGE_L": 0.28773584905660377, "CIDEr": 0.02964964712372144, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is not a ski resort. There are no people on the slopes. There are no slopes, ski gear, snowboarding gear, snow, trees, or rocks in the image."}, "565776": {"image_id": 565776, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.25300470311328, "Bleu_3": 0.17472644771604057, "Bleu_4": 0.11110969989555719, "METEOR": 0.28078656646152583, "ROUGE_L": 0.3441466854724965, "CIDEr": 5.6766016752803556e-05, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a large island in the center of the room. The island is surrounded by cabinets. There is a refrigerator, oven, and two sinks in the kitchen. The floor is made of hardwood."}, "208132": {"image_id": 208132, "Bleu_1": 0.20547945205197976, "Bleu_2": 0.14134061323349553, "Bleu_3": 0.11205086135219547, "Bleu_4": 0.09468951396570002, "METEOR": 0.25715550432742756, "ROUGE_L": 0.274651058081945, "CIDEr": 2.0895929808118604e-23, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.18518518518518517, "f": 0.19999999999999998, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a table with a plate of food on it. There are two plates on the table. One plate has a burger on it, and the other plate has a burger, lettuce, tomatoes, and a bottle of ketchup on it.\n\nThere are two glasses on the table. One glass has a spoon in it, and the other glass is filled with red wine. \n\nThe table is covered with a white cloth."}, "37017": {"image_id": 37017, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.3457820373893416, "Bleu_3": 0.2535719111447155, "Bleu_4": 2.9683905083130232e-05, "METEOR": 0.27427942225160434, "ROUGE_L": 0.43660531697341515, "CIDEr": 0.07099357340784132, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.10714285714285714, "f": 0.11999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a black dog sitting on the brown floor in front of the kitchen counter. The dog is looking at the camera."}, "20536": {"image_id": 20536, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.24124895480980643, "Bleu_3": 1.308134835363938e-06, "Bleu_4": 3.0761278458987864e-09, "METEOR": 0.23005001818237547, "ROUGE_L": 0.2978515625, "CIDEr": 0.017244248825353685, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a toilet in a bathroom. The toilet is white and has a seat and a lid. There is a toilet paper holder on the wall."}, "289264": {"image_id": 289264, "Bleu_1": 0.255813953482423, "Bleu_2": 0.13517553494737666, "Bleu_3": 7.638430164587324e-07, "Bleu_4": 1.8269980610770202e-09, "METEOR": 0.20754999876516123, "ROUGE_L": 0.2616154395997141, "CIDEr": 3.912350258190285e-07, "SPICE": {"All": {"pr": 0.15, "re": 0.17647058823529413, "f": 0.16216216216216214, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a dog resting its head on the windowsill. The dog is brown and is looking out at the view. The dog is wearing a red collar. The background is a rainy day with trees and buildings visible through the window."}, "18014": {"image_id": 18014, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.33166247902199714, "Bleu_3": 0.21227472238736536, "Bleu_4": 2.567840480519657e-05, "METEOR": 0.27251823719187307, "ROUGE_L": 0.377086338347414, "CIDEr": 0.02402212379456301, "SPICE": {"All": {"pr": 0.2, "re": 0.08695652173913043, "f": 0.12121212121212122, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image features a pizza inside a pizza box. The pizza box is sitting on a table. There is a knife next to the box."}, "381123": {"image_id": 381123, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.1400280084000279, "Bleu_3": 0.09284415754233383, "Bleu_4": 1.136333016795187e-05, "METEOR": 0.15152841818799917, "ROUGE_L": 0.2544392801811465, "CIDEr": 9.742842640504936e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of two people standing on a beach. The people are surfing and walking down the stairs. There are eight kayaks in the water. The kayaks are of different colors, including yellow and red. The image is taken from an aerial view. Mountains are in the background."}, "19608": {"image_id": 19608, "Bleu_1": 0.47368421051385046, "Bleu_2": 0.357802682486979, "Bleu_3": 0.22014152945079551, "Bleu_4": 2.3496840751813438e-05, "METEOR": 0.24179253315227742, "ROUGE_L": 0.25811001410437234, "CIDEr": 0.00032052288582242226, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09523809523809523, "f": 0.0851063829787234, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bird standing in the water. The bird is looking at a fish and it is a heron. The bird has a long neck. There is a bicycle parked on the side of the road."}, "497348": {"image_id": 497348, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.20870354281255962, "Bleu_3": 0.11586898532647615, "Bleu_4": 1.296835022155032e-05, "METEOR": 0.25965979535548545, "ROUGE_L": 0.259298618490967, "CIDEr": 1.4581780662536256e-13, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.2222222222222222, "f": 0.27586206896551724, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a road with no traffic on it. A red car is on the left side of the road. Houses are on both sides of the road. The road is lined with trees on both sides. There is a sign on the left side of the road that says \"no through road\". The sky is cloudy."}, "437594": {"image_id": 437594, "Bleu_1": 0.29999999999500004, "Bleu_2": 0.20168779363245437, "Bleu_3": 0.14103613869021897, "Bleu_4": 0.0837585389409558, "METEOR": 0.2522552070586535, "ROUGE_L": 0.2609227008860372, "CIDEr": 1.3951941678490648e-13, "SPICE": {"All": {"pr": 0.1875, "re": 0.15789473684210525, "f": 0.17142857142857143, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a woman sitting at a desk in front of a laptop computer. She is wearing a blue shirt and has a blue scarf around her neck. There are several photos on the wall behind her, including one of a man and one of a woman. The wall is made of brick, with a total of ten bricks."}, "413404": {"image_id": 413404, "Bleu_1": 0.23076923076035508, "Bleu_2": 0.09607689227928318, "Bleu_3": 7.272363035080195e-07, "Bleu_4": 2.0222027841473114e-09, "METEOR": 0.08506756489540475, "ROUGE_L": 0.23326959847036327, "CIDEr": 0.002448297776888402, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.21739130434782608, "f": 0.19230769230769232, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two people walking down the street and on the sidewalk. The people are wearing a black jacket. They are looking at a dog."}, "332775": {"image_id": 332775, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.1908854288877745, "Bleu_3": 0.1434900198264265, "Bleu_4": 0.09517889238074573, "METEOR": 0.20439120016746176, "ROUGE_L": 0.28175519630484985, "CIDEr": 3.0234009430555267e-06, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.06896551724137931, "f": 0.08, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two cats sitting in a black suitcase on a bed. The cats are wearing black suits. The cats' paws are inside the suitcase. The suitcase has wheels on the bottom. The bed is made of wood."}, "530624": {"image_id": 530624, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.33166247902199714, "Bleu_3": 0.21227472238736536, "Bleu_4": 2.567840480519657e-05, "METEOR": 0.28678103536049565, "ROUGE_L": 0.433502538071066, "CIDEr": 0.036165716617343066, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.14285714285714285, "f": 0.17647058823529413, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a brown dog lying under a floral patterned blanket on a bed. The dog is sleeping. The bed also has a pillow."}, "139113": {"image_id": 139113, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.09288407280072536, "Bleu_3": 5.60482607100497e-07, "Bleu_4": 1.3839209880654026e-09, "METEOR": 0.16090404227750796, "ROUGE_L": 0.1561100447856686, "CIDEr": 1.439809104917855e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10344827586206896, "f": 0.12000000000000001, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows three people playing soccer on a field. They are wearing red and blue and white jerseys and blue and red shorts. One player is kicking the ball with his left foot, and another player is running towards the goal. \n\nThere are no trees or fences in the scene."}, "192858": {"image_id": 192858, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.3237880628910851, "Bleu_3": 0.24089075598526072, "Bleu_4": 0.14817181525076897, "METEOR": 0.30089427528965385, "ROUGE_L": 0.38125000000000003, "CIDEr": 0.002891858022796123, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of seven people sitting at a table in a restaurant. The people are eating pizza. Some of the people are eating pizza. The people are all smiling."}, "482742": {"image_id": 482742, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.20203050890627616, "Bleu_3": 0.0954066585882441, "Bleu_4": 1.172180673188117e-05, "METEOR": 0.22123381277485996, "ROUGE_L": 0.20485839023844174, "CIDEr": 3.0931157068553856e-06, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.15151515151515152, "f": 0.18181818181818182, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a bicycle parked on the sidewalk next to a building with a brown roof. There is a tree in the background.\n\nThe image is taken from a low angle, looking down the street. The sun is shining and there are no other people in the image."}, "398818": {"image_id": 398818, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.19374606456772306, "Bleu_3": 0.14762944824530086, "Bleu_4": 0.09863022371386766, "METEOR": 0.2707920206628382, "ROUGE_L": 0.2930344275420336, "CIDEr": 1.2368990138515544e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.24, "f": 0.20338983050847456, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows three bananas on a countertop. The bananas are yellow. The bananas are arranged in a row on the countertop. The bananas have blue stickers on them, with the words \"Banana\" written on the stickers."}, "305871": {"image_id": 305871, "Bleu_1": 0.16666666666388893, "Bleu_2": 0.0531494003443801, "Bleu_3": 3.651933955437213e-07, "Bleu_4": 9.6144284585873e-10, "METEOR": 0.19389366082625786, "ROUGE_L": 0.15786749482401655, "CIDEr": 9.806489102697751e-16, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image does not show a street or a sidewalk. There are four signs in the image. The first sign reads \"one way\", the second sign reads \"liberty hill historic district\", and the third and fourth signs both read \"San Carlos\". There is a building in the image. The building is blue and made of brick. The sky is blue."}, "443818": {"image_id": 443818, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.2431322695333988, "Bleu_3": 0.1298495596904247, "Bleu_4": 1.7034799410092803e-05, "METEOR": 0.2323257056376929, "ROUGE_L": 0.3010858835143139, "CIDEr": 0.0029914535197495384, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08695652173913043, "f": 0.0909090909090909, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a dog lying on its back in a bed. The dog is brown and is wearing a sweater. The bed is made of a tan material."}, "421109": {"image_id": 421109, "Bleu_1": 0.17777777777382722, "Bleu_2": 0.06356417261494428, "Bleu_3": 4.546237434540883e-07, "Bleu_4": 1.2230008607068681e-09, "METEOR": 0.12968753772259187, "ROUGE_L": 0.1643097643097643, "CIDEr": 1.4614137312350334e-08, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15789473684210525, "f": 0.16666666666666669, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows three horses standing in a green field with mountains in the background. The horses are grazing and wearing different accessories, such as a saddle and a hat. One of the horses is also wearing a halter. The horse's mane is long."}, "416660": {"image_id": 416660, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.23063280200236536, "Bleu_3": 0.15138000825437875, "Bleu_4": 0.09370187147561893, "METEOR": 0.1814538953614706, "ROUGE_L": 0.28018372703412076, "CIDEr": 2.790699843792802e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.38461538461538464, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of five people standing in front of a store with a sign that reads \"johonnot shop\". The people are looking at a window display of the store. The people are dressed in clothing from the '50s. The store is located on a street."}, "322845": {"image_id": 322845, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.16922831695751037, "Bleu_3": 0.1261954612597963, "Bleu_4": 0.10186291694215503, "METEOR": 0.24532748801905693, "ROUGE_L": 0.3139475038600103, "CIDEr": 5.684844884901558e-14, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.17647058823529413, "f": 0.15, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a red stop sign on a metal pole in front of a rusty building. The sign is leaning against the pole. The sign has a white background with red letters. The building is made of a rusty metal. The building does not have a large window on the side.\n\nThere is no tree in the scene."}, "304361": {"image_id": 304361, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.25017774619423927, "Bleu_3": 0.15149848229213897, "Bleu_4": 1.775371322627821e-05, "METEOR": 0.24993317852810162, "ROUGE_L": 0.32153614457831325, "CIDEr": 2.9135944765152258e-05, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.3181818181818182, "f": 0.2692307692307693, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a child playing a game on a tablet in a room. The child is holding a remote control and looking at it. The child is wearing a pajama. A wii remote is on the floor."}, "446917": {"image_id": 446917, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.13430879685706595, "Bleu_3": 0.07373360496991944, "Bleu_4": 9.769805815563084e-06, "METEOR": 0.22380724012114223, "ROUGE_L": 0.23297262889879056, "CIDEr": 1.2431402859509992e-07, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3157894736842105, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "There is no person in this image. There is a cycling jersey in the image, which is blue and yellow. There is a banana on the handlebars, which are yellow. There is a bicycle in the background. The background is a street with no buildings or cars."}, "234676": {"image_id": 234676, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.2896048475706757, "Bleu_3": 0.14247474403149546, "Bleu_4": 1.792725954943498e-05, "METEOR": 0.22550595731288245, "ROUGE_L": 0.3925985518905873, "CIDEr": 0.00387887885208435, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13043478260869565, "f": 0.16216216216216214, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a group of seven people standing on a beach next to a surfboard. The people are wearing swimsuits. \n\nThere are no sunglasses or palm trees in the scene."}, "343692": {"image_id": 343692, "Bleu_1": 0.31147540983095945, "Bleu_2": 0.20378924074502994, "Bleu_3": 0.14120719542393748, "Bleu_4": 0.10985401537445105, "METEOR": 0.2312241936706581, "ROUGE_L": 0.28053142565150746, "CIDEr": 7.995272874822574e-16, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.19047619047619047, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a scooter parked in front of a yellow building. The building is yellow. A traffic hazard sign is on the side of the building. The sign says \"traffic hazard ahead\".\n\nThe scooter is silver. The building has a large window on the side. There is no mirror on the scooter. There is no parking area in the scene."}, "293011": {"image_id": 293011, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.3523321316968753, "Bleu_3": 0.2985148271491349, "Bleu_4": 0.21068857624163603, "METEOR": 0.34131575250743196, "ROUGE_L": 0.41136801541425827, "CIDEr": 0.04912597331911527, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1111111111111111, "f": 0.13043478260869565, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a birthday cake with an airplane on it. The cake is blue and white. There are six candles on the cake. The cake is on the table."}, "104625": {"image_id": 104625, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.1276351315918384, "Bleu_3": 0.0961390165871351, "Bleu_4": 0.07574148496172853, "METEOR": 0.27062574148415525, "ROUGE_L": 0.23448654585392636, "CIDEr": 4.380655391646582e-14, "SPICE": {"All": {"pr": 0.125, "re": 0.06451612903225806, "f": 0.0851063829787234, "fn": 29.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two cats sitting on a table in front of a television. The cats are looking at the television with their ears perked up. The television is showing a soccer match with players in blue and white uniforms playing on the field. The cats appear to be interested in the game and are watching intently."}, "175612": {"image_id": 175612, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.17213259316161544, "Bleu_3": 0.13076859215453357, "Bleu_4": 0.08097980939568503, "METEOR": 0.24801957726811558, "ROUGE_L": 0.24110671936758893, "CIDEr": 4.227510997103703e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image is of a skateboarder standing on a sidewalk with a skateboard in his hand. The skateboarder is wearing a red shirt and blue jeans. The skateboarder is standing on the sidewalk. A tree is behind the skateboarder. The skateboarder is holding a skateboard. The sun is shining, casting a shadow on the ground."}, "43448": {"image_id": 43448, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.14118624159718107, "Bleu_3": 0.07863217694465756, "Bleu_4": 1.0499901541586202e-05, "METEOR": 0.16319904970485868, "ROUGE_L": 0.19766688269604665, "CIDEr": 0.00029567218404846486, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.2857142857142857, "f": 0.29629629629629634, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows two elephants standing on a rocky beach with trees in the background. The elephants are brown and have tusks. They are walking and looking at something in the distance. The sky is blue and there are clouds in the background."}, "528705": {"image_id": 528705, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.0932504808219817, "Bleu_3": 5.824828742198937e-07, "Bleu_4": 1.4641826518869363e-09, "METEOR": 0.14729354751075957, "ROUGE_L": 0.19728331177231562, "CIDEr": 5.132505554792872e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23809523809523808, "f": 0.19607843137254902, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a woman wearing a red coat and holding a teddy bear. The woman is standing on a bench. The people around the bench are taking selfies and talking on their cell phones. They are looking at a person and a cell phone respectively."}, "319221": {"image_id": 319221, "Bleu_1": 0.2666666666622222, "Bleu_2": 0.11644450194595923, "Bleu_3": 0.061603207790807316, "Bleu_4": 8.0026492316705e-06, "METEOR": 0.14775479202499658, "ROUGE_L": 0.1937738246505718, "CIDEr": 3.912086719266947e-15, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.3333333333333333, "f": 0.2439024390243902, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a tray with broccoli, chicken, and sauces on it. There are four plates with various food items on them, including Asparta, a bowl of greens, broccoli, a plate of food, a spoon, Spinner, a salad, and a bowl of soup. \n\nThere is a man wearing a white shirt and black pants. The walls are brown in color."}, "338903": {"image_id": 338903, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.253320198544886, "Bleu_3": 0.1818738688549909, "Bleu_4": 0.11802861352029913, "METEOR": 0.33044100776764374, "ROUGE_L": 0.4033057851239669, "CIDEr": 0.0002225386395693973, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a bowl of cereal with bananas and a spoon. The bowl is on a table. The bowl contains bananas and cereal. The lighting is bright and the image is in focus."}, "364993": {"image_id": 364993, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.20159462811746034, "Bleu_3": 1.1460354422397831e-06, "Bleu_4": 2.758387014275457e-09, "METEOR": 0.1910316951555365, "ROUGE_L": 0.3286047764410127, "CIDEr": 0.0076666569852743005, "SPICE": {"All": {"pr": 0.3125, "re": 0.1724137931034483, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.38461538461538464, "f": 0.4545454545454546, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a person holding a sandwich in their hand. The sandwich is made of meat, cheese, lettuce, and pickles. The sandwich is on a white paper plate."}, "37616": {"image_id": 37616, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.35948681369506397, "Bleu_3": 0.29971482871347116, "Bleu_4": 0.26158582824725907, "METEOR": 0.31899672690128295, "ROUGE_L": 0.46653919694072654, "CIDEr": 0.0410063872164882, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2413793103448276, "f": 0.2916666666666667, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.46153846153846156, "f": 0.5217391304347826, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a man standing in a living room. The man is wearing a tan shirt. There is a window in the background with curtains."}, "157756": {"image_id": 157756, "Bleu_1": 0.255813953482423, "Bleu_2": 0.17451086522195614, "Bleu_3": 0.09056360369745191, "Bleu_4": 1.1673478125964725e-05, "METEOR": 0.2834853534990649, "ROUGE_L": 0.283344392833444, "CIDEr": 1.0253799925817278e-06, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.19047619047619047, "f": 0.15384615384615383, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a clock tower located in the centre of the town. The clock face is visible on the tower. A bus is in front of the sidewalk. The sky is dark. There are no other objects or people in the scene."}, "516508": {"image_id": 516508, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.10540925533657697, "Bleu_3": 6.369368049040698e-07, "Bleu_4": 1.5749252146545933e-09, "METEOR": 0.178216977418744, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.5474152661758405e-08, "SPICE": {"All": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a large, ornate clock hanging from the wall of a church. The clock has a face with Roman numerals. The clock is surrounded by intricate carvings and has a large, ornate frame. The walls of the church are made of white plaster."}, "520528": {"image_id": 520528, "Bleu_1": 0.34615384614718936, "Bleu_2": 0.2179708976339486, "Bleu_3": 0.12386606438093094, "Bleu_4": 1.4033475286316117e-05, "METEOR": 0.27533630000531434, "ROUGE_L": 0.30049261083743845, "CIDEr": 8.050042890374112e-12, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.0625, "f": 0.05714285714285714, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a young boy in a baseball uniform holding a baseball. The boy is standing on the mound of a baseball field. The boy is wearing a blue and white jersey with the number 0 on the back. He also has a blue and white baseball cap on his head."}, "37675": {"image_id": 37675, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.15541746803663614, "Bleu_3": 0.1180926166655855, "Bleu_4": 0.09355294087801785, "METEOR": 0.20768817213109644, "ROUGE_L": 0.24830393487109906, "CIDEr": 4.5538341095309486e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.13043478260869565, "f": 0.15789473684210528, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows two horses grazing in a field next to a wooden fence. The horses are brown and white. One of the horses is eating grass. The horses are wearing halters. The mane of the horses is white. The tail of the horses is white."}, "232383": {"image_id": 232383, "Bleu_1": 0.25806451612486997, "Bleu_2": 0.17208707350147742, "Bleu_3": 0.09956921453226814, "Bleu_4": 1.1373151070211031e-05, "METEOR": 0.22121243010560565, "ROUGE_L": 0.20310765815760268, "CIDEr": 3.850436646591044e-17, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.12, "f": 0.13636363636363635, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on a shelf. The cat is looking at the camera. The cat is also resting on the edge of the computer monitor. There is a laptop on top of the computer monitor.\n\nThere is no blue screen with white text on the monitor. There are no paws visible in the image. The room is dimly lit."}, "137658": {"image_id": 137658, "Bleu_1": 0.3214285714170919, "Bleu_2": 0.10910894511402736, "Bleu_3": 7.707540024261883e-07, "Bleu_4": 2.0687206009477373e-09, "METEOR": 0.12253309799614996, "ROUGE_L": 0.23018867924528305, "CIDEr": 0.002989643247567917, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3125, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a person holding a flashlight in their hand. The person is wearing a blue jacket. The person does not have a backpack on their back."}, "209322": {"image_id": 209322, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.2175970699379255, "Bleu_3": 0.14509689849254254, "Bleu_4": 1.7863365456276686e-05, "METEOR": 0.16128453493562148, "ROUGE_L": 0.2997542997542998, "CIDEr": 0.0009530799967202115, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. There is a mirror above the sink. The walls, however, do not have any pattern. The floor is not made of tile."}, "128644": {"image_id": 128644, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1489923873895453, "Bleu_3": 0.0808524074576599, "Bleu_4": 1.0655498021900177e-05, "METEOR": 0.19537308598236175, "ROUGE_L": 0.266209476309227, "CIDEr": 1.47973206344091e-05, "SPICE": {"All": {"pr": 0.15, "re": 0.1875, "f": 0.16666666666666663, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of an airplane on the runway. The airplane is a red and white plane. It has a red and white arrow on the front. The airplane has a large, round window on the side. The wheels are touching the ground."}, "342675": {"image_id": 342675, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.07963639705150245, "Bleu_4": 9.88017723049474e-06, "METEOR": 0.23088368284498617, "ROUGE_L": 0.21229698375870068, "CIDEr": 9.983297346040813e-14, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.375, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man standing on the platform of a train station. The man is looking at his phone and looking at a train. The train is red and has the number 1889 on the side. There is a sign on the wall. In the background, there are trees and a cloud in the sky."}, "200234": {"image_id": 200234, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.06185895741189865, "Bleu_3": 4.3341351003500945e-07, "Bleu_4": 1.1534197288455865e-09, "METEOR": 0.16330878859065795, "ROUGE_L": 0.17732558139534885, "CIDEr": 2.2061219048760605e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.21052631578947367, "f": 0.22857142857142856, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of people standing around a picnic table in a forest. The people are wearing white shorts and are playing frisbee. There is a tree in the background. A stream is running through the area.\n\nThe image is taken from a bird's eye view."}, "545390": {"image_id": 545390, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.26130213377863615, "Bleu_3": 0.21166601750481703, "Bleu_4": 0.16885023000536672, "METEOR": 0.3002185095239997, "ROUGE_L": 0.37251908396946565, "CIDEr": 2.5260893370772987e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13043478260869565, "f": 0.13636363636363635, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a woman holding a pizza in her hands and smiling at the camera. The pizza has various toppings on it, including cheese, pepperoni, mushrooms, onions, olives, and peppers. The woman is wearing a pink shirt."}, "43073": {"image_id": 43073, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 0.08709642720538069, "Bleu_4": 0.05970344881146218, "METEOR": 0.22348784597738017, "ROUGE_L": 0.2363032650802435, "CIDEr": 1.7208041565542285e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.17857142857142858, "f": 0.1886792452830189, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a boy sitting on a bed. The boy is brushing his teeth. The boy has blonde hair, and he is wearing a blue shirt and blue pants. \n\nThere is no woman in the image.\n\nThe boy's hair is blonde. The boy's shirt is blue. The boy's pants are blue."}, "188651": {"image_id": 188651, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.24806946916868503, "Bleu_3": 0.13687111262226093, "Bleu_4": 1.8272664874609172e-05, "METEOR": 0.33899137304810195, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.016900502558382123, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.125, "f": 0.1276595744680851, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a cat lying under a car. The cat is brown and white. The car is black. The roof of the car is black."}, "484551": {"image_id": 484551, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.26486423167652634, "Bleu_3": 0.20766660983010224, "Bleu_4": 0.14047306090779724, "METEOR": 0.2631125319691936, "ROUGE_L": 0.2622527944969905, "CIDEr": 5.660797673855777e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.11428571428571428, "f": 0.14035087719298245, "fn": 31.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a woman sitting on a boat on the water. She is wearing an orange shirt and jeans. The boat is moving through the water. There is a tree in the background.\n\nThere is no steering wheel in the scene.\n\nThere is no house in the scene."}, "396224": {"image_id": 396224, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.13363062095345665, "Bleu_3": 7.242770182814215e-07, "Bleu_4": 1.6952707578778211e-09, "METEOR": 0.10639934815905132, "ROUGE_L": 0.19690122659780504, "CIDEr": 8.542248062207798e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.13043478260869565, "f": 0.1276595744680851, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a table set with a roast turkey, mashed potatoes, and vegetables. There are two glasses of wine on the table and a bottle of wine. \n\nThere is no tablecloth or chair in the scene. There are no candles in the scene.\n\nThe room is dimly lit."}, "255067": {"image_id": 255067, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.18239004641192846, "Bleu_3": 0.10350476356783775, "Bleu_4": 1.3983656709932682e-05, "METEOR": 0.2597038939150508, "ROUGE_L": 0.32562277580071175, "CIDEr": 0.0015268676633203885, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.16129032258064516, "f": 0.1818181818181818, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a polar bear standing on a rock in the middle of a body of water. The bear is looking at a rock. The bear is trying to catch fish."}, "479129": {"image_id": 479129, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.2806917861005864, "Bleu_3": 0.24473362695163794, "Bleu_4": 0.21391720958763585, "METEOR": 0.3238579952970674, "ROUGE_L": 0.3588235294117647, "CIDEr": 4.876723548879442e-07, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2222222222222222, "f": 0.22641509433962265, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a plate of food with bananas and ice cream on it. The bananas are cut in half and topped with chocolate sauce. The ice cream is scooped into a bowl and topped with whipped cream. The plate is on a white tablecloth."}, "363887": {"image_id": 363887, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.11144846405416943, "Bleu_4": 0.07622713576923955, "METEOR": 0.19508500696447945, "ROUGE_L": 0.24583557227297154, "CIDEr": 5.736928407467511e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a red fire truck parked on the side of a dirt road. The fire truck has a large red ladder. A rope is coiled around the front bumper. There is a van parked nearby. There is no car in the scene."}, "441969": {"image_id": 441969, "Bleu_1": 0.2666666666622222, "Bleu_2": 0.20168779363245437, "Bleu_3": 0.12813983597376327, "Bleu_4": 0.0779461033297459, "METEOR": 0.22106673881706085, "ROUGE_L": 0.22956989247311832, "CIDEr": 3.983172424932461e-15, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a table on a balcony. There is a vase of flowers on the table. The balcony is surrounded by brick walls and there are plants on the table. A small window is on the left side of the balcony, providing a view of the city. The balcony is covered with a tarp, and the covering is green."}, "410225": {"image_id": 410225, "Bleu_1": 0.222222222217284, "Bleu_2": 0.15891043153736062, "Bleu_3": 8.374240954573334e-07, "Bleu_4": 1.933734150090014e-09, "METEOR": 0.16399079176299147, "ROUGE_L": 0.26212400245549416, "CIDEr": 1.023694882641797e-07, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.17142857142857143, "f": 0.19672131147540986, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.35714285714285715, "f": 0.3448275862068965, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a table with a cup of coffee and a laptop on it. There are also several cups of coffee on the table. The laptop has a screen that shows a website with a picture of a person holding a cup of coffee."}, "277073": {"image_id": 277073, "Bleu_1": 0.16666666666435187, "Bleu_2": 0.1083378475028446, "Bleu_3": 0.05514262737758893, "Bleu_4": 7.0210702529467e-06, "METEOR": 0.14855479165167407, "ROUGE_L": 0.16666666666666666, "CIDEr": 3.0233825697943324e-24, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14814814814814814, "f": 0.15999999999999998, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows three people riding on a motorcycle on a street. The people are wearing casual clothing. One person is wearing a red sari, another person is wearing a white shirt, and the third person is wearing black pants. The motorcycle is black. \n\nThere are no cars in the scene, but there is a bus on the street. There are no buildings in the background and the sky is not visible."}, "41011": {"image_id": 41011, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.24330354977564592, "Bleu_3": 0.16170481491531974, "Bleu_4": 0.1007734784396203, "METEOR": 0.24480801573815955, "ROUGE_L": 0.33190827827438785, "CIDEr": 3.315031636127615e-07, "SPICE": {"All": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a man in a black suit and top hat riding a horse through a field. The horse is wearing a saddle. The man is holding the reins with his left hand and has his right hand on the horse's neck."}, "343821": {"image_id": 343821, "Bleu_1": 0.255813953482423, "Bleu_2": 0.17451086522195614, "Bleu_3": 0.1306153185181404, "Bleu_4": 0.102739651078625, "METEOR": 0.18065897480961313, "ROUGE_L": 0.21254355400696864, "CIDEr": 8.854972547133885e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows four white swans in a body of water. The swans are surrounded by ducks swimming in the water. The sky is cloudy and there are no trees in the background. The image is taken from a low angle, looking down."}, "530620": {"image_id": 530620, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.14793835438670558, "Bleu_4": 0.09209953959056319, "METEOR": 0.2032350390174619, "ROUGE_L": 0.28018372703412076, "CIDEr": 6.481764773227678e-09, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2413793103448276, "f": 0.27450980392156865, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of two people standing next to a truck on the side of a road. The truck has a green and white canopy on top of it. The people are standing next to a hot air balloon and a motorcycle. The sky is blue."}, "22113": {"image_id": 22113, "Bleu_1": 0.4848484848337925, "Bleu_2": 0.3692744729266333, "Bleu_3": 0.20643767470015953, "Bleu_4": 0.13086135269887708, "METEOR": 0.32975185642637017, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.0006576144175929346, "SPICE": {"All": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a red fire hydrant on the sidewalk in front of a building. The fire hydrant has a green handle and a white cap. There is a fence in the background."}, "82836": {"image_id": 82836, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.1097107610987848, "Bleu_4": 0.07242301681257467, "METEOR": 0.19468341392467414, "ROUGE_L": 0.2544392801811465, "CIDEr": 9.998691258897075e-11, "SPICE": {"All": {"pr": 0.4, "re": 0.2727272727272727, "f": 0.3243243243243243, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5555555555555556, "f": 0.6250000000000001, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows two seagulls standing on the beach. The seagulls are looking out to sea. The sky is cloudy and there are waves crashing on the shore. The sand is brown and there are some rocks in the distance. The water is choppy. There are no boats in the scene."}, "538925": {"image_id": 538925, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.29301635765725875, "Bleu_3": 0.21532531602230645, "Bleu_4": 0.16341401895776847, "METEOR": 0.2999064860360665, "ROUGE_L": 0.41190914671577655, "CIDEr": 5.548927904169872e-06, "SPICE": {"All": {"pr": 0.24, "re": 0.375, "f": 0.2926829268292683, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a bed with a white sheet. There is a brown and white blanket on the bed. A wooden wall with a pattern of woven basket is behind the bed.\n\nThere is no floor, wood, table, vase, stripe, or ceiling in the image."}, "440189": {"image_id": 440189, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.17205295744403565, "Bleu_3": 0.08697022430943882, "Bleu_4": 1.105769924492212e-05, "METEOR": 0.13396751227240214, "ROUGE_L": 0.2676906198573779, "CIDEr": 1.3790028976355771e-05, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.2, "f": 0.14634146341463417, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two people playing frisbee on a sandy beach. The people are wearing black and white uniforms. They are ready to play a game of frisbee and are ready to serve. The beach is surrounded by tall trees and a rocky cliff in the background."}, "32777": {"image_id": 32777, "Bleu_1": 0.29508196720827734, "Bleu_2": 0.1983538814689071, "Bleu_3": 0.11007443464912503, "Bleu_4": 1.231424668332689e-05, "METEOR": 0.198348672426416, "ROUGE_L": 0.20187534473248758, "CIDEr": 1.1070786610503963e-16, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man standing on the platform of a train station. The man is wearing a blue jacket and does not have a camera around his neck. He is also carrying a backpack. \n\nThere are two trains at the station. The trains are blue and yellow. \n\nThere are also other people standing on the platform, looking at the trains."}, "50679": {"image_id": 50679, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.15943400149410505, "Bleu_4": 0.11521360098519728, "METEOR": 0.20863894753602397, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.7756348527818612e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15, "f": 0.13043478260869565, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows an orange lying on the ground in the middle of a parking lot. The orange is a bright orange color and has a rough texture. There are no cars visible in the image. The sky is cloudy and there are no other objects in the image."}, "86250": {"image_id": 86250, "Bleu_1": 0.4054054053944486, "Bleu_2": 0.280764721474242, "Bleu_3": 0.18905119556153185, "Bleu_4": 0.11873119581672731, "METEOR": 0.20170826505095482, "ROUGE_L": 0.3065326633165829, "CIDEr": 9.452652151028851e-05, "SPICE": {"All": {"pr": 0.12195121951219512, "re": 0.2631578947368421, "f": 0.16666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 36.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a woman sitting on a couch in a living room. The woman is wearing a black shirt and jeans. The blinds on the window are not open.\n\nThere is no carpet in the scene."}, "482432": {"image_id": 482432, "Bleu_1": 0.4444444444279836, "Bleu_2": 0.292352673091307, "Bleu_3": 0.2172693481609701, "Bleu_4": 0.17098323692086584, "METEOR": 0.22478572330462376, "ROUGE_L": 0.3986928104575163, "CIDEr": 0.046994973039681504, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a sink with a toothbrush and toothpaste on the counter. The sink is made of porcelain and has a faucet. The toothbrush is black."}, "330880": {"image_id": 330880, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.2287478554936478, "Bleu_3": 0.18399736015395765, "Bleu_4": 0.14611440826859995, "METEOR": 0.2818310788343163, "ROUGE_L": 0.31853785900783294, "CIDEr": 4.817422334062135e-07, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.11764705882352941, "f": 0.11764705882352941, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a man sitting at a table in a restaurant. The man is eating a pizza and looking at a pizza. The pizza has ham, cheese, and spinach toppings. The man is wearing a black shirt and does not have a beard."}, "201934": {"image_id": 201934, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.22288685594608834, "Bleu_3": 0.18272474598892796, "Bleu_4": 0.15277191390944114, "METEOR": 0.24584396694120234, "ROUGE_L": 0.2704885580806081, "CIDEr": 2.129091127126506e-14, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.8333333333333334, "f": 0.5882352941176471, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a white bus parked on the side of the road. There are two people standing on the sidewalk. The people are looking at a reflection in the window. The bus has a bumper sticker on the front that reads \"no guns on school buses\". There is also a car parked along the side of the road."}, "579462": {"image_id": 579462, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.20952908872569917, "Bleu_3": 0.13106438047696783, "Bleu_4": 1.5601545072136117e-05, "METEOR": 0.24545494528992856, "ROUGE_L": 0.27875095201827876, "CIDEr": 2.126798721248743e-06, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.041666666666666664, "f": 0.05128205128205127, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a woman standing on a bed with a suitcase on it. She is wearing a dress and has a look of concentration on her face. The room is dimly lit and there is a lamp on the nightstand."}, "183657": {"image_id": 183657, "Bleu_1": 0.20588235293512117, "Bleu_2": 2.497770842103635e-09, "Bleu_3": 5.79853658440281e-12, "Bleu_4": 2.8161019785976393e-13, "METEOR": 0.15200186540017074, "ROUGE_L": 0.19032761310452417, "CIDEr": 4.848252143716963e-05, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.26666666666666666, "f": 0.30769230769230765, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image is of a cup of coffee floating in the water. The cup is sitting on top of a rock. The water is frozen and there are no other objects in the image."}, "352652": {"image_id": 352652, "Bleu_1": 0.1494252873546043, "Bleu_2": 0.09320684903247198, "Bleu_3": 0.04675473240236538, "Bleu_4": 5.906080474621418e-06, "METEOR": 0.21120598467778198, "ROUGE_L": 0.16608323609490472, "CIDEr": 7.440015252033634e-35, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows three cars parked in the snow. The first car has a snow shovel on top of it and is covered with snow. The second car has a parking meter on top of it and is also covered with snow. The third car has a sled on top of it and is covered with snow and ice.\n\nThere are two people walking and looking at the cars. They are also looking out of the car and looking at a car with a person in it."}, "339823": {"image_id": 339823, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.35823642098878333, "Bleu_3": 0.3032917155626271, "Bleu_4": 0.24835336814534026, "METEOR": 0.33289431050949375, "ROUGE_L": 0.4779627815866797, "CIDEr": 0.08241780129648849, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.3333333333333333, "f": 0.3137254901960785, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a woman wearing an orange dress with a paisley pattern. The woman is holding an umbrella. The background is a blue sky."}, "203690": {"image_id": 203690, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.36115755924124826, "Bleu_3": 0.26511346924327256, "Bleu_4": 3.106821813431932e-05, "METEOR": 0.3664152658878306, "ROUGE_L": 0.5428253615127919, "CIDEr": 0.09361043978635311, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person walking on a beach. The person is wearing a wetsuit and holding a surfboard. The sky is cloudy."}, "344614": {"image_id": 344614, "Bleu_1": 0.18644067796294173, "Bleu_2": 0.15000487036450028, "Bleu_3": 0.1254397816965181, "Bleu_4": 0.10140509449349805, "METEOR": 0.17547702249857808, "ROUGE_L": 0.2659400544959128, "CIDEr": 1.9284503521993974e-15, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.16666666666666666, "f": 0.22727272727272724, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a clock tower in the middle of a city. The clock tower is made of stone. There is a clock face on the front of the clock tower. The clock face has numbers and hands. The clock is ticking away.\n\nThere is a building in the background. There is no skyscraper or window in the scene."}, "573549": {"image_id": 573549, "Bleu_1": 0.23809523809145886, "Bleu_2": 0.1639564589433648, "Bleu_3": 0.07609843785660979, "Bleu_4": 9.257505818304278e-06, "METEOR": 0.18096007310096246, "ROUGE_L": 0.22485518694049497, "CIDEr": 2.478567393493852e-18, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a street with nine people walking on it. The street is surrounded by buildings, and there are cars parked on the sidewalk. There are no sidewalks or sky in the image. In the background, there is a tree and a sign for Darcell XV Female Impersonators.\n\nTwo people are walking on the street. The cars are parked on the sidewalk."}, "522941": {"image_id": 522941, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1714285714251079, "Bleu_3": 0.08491317075202565, "Bleu_4": 1.068333456439781e-05, "METEOR": 0.22333626277091312, "ROUGE_L": 0.22732919254658387, "CIDEr": 1.1009475775276842e-10, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2777777777777778, "f": 0.22222222222222224, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows an elephant standing in a field. The elephant has a chain. \n\nThere are eight people gathered around the elephant. \n\nThe people in the background are wearing black shirts. They appear to be preparing to go to the beach and are watching a man holding a red bag."}, "511662": {"image_id": 511662, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.07205793047605258, "Bleu_4": 9.44575929237223e-06, "METEOR": 0.23321027217488682, "ROUGE_L": 0.2582869586256957, "CIDEr": 4.0890195360692096e-08, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.3157894736842105, "f": 0.2553191489361702, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.8333333333333334, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a cruise ship in the foreground, with palm trees and a beach in the background. The ship is surrounded by colorful umbrellas and chairs on the sand. The sky is clear and blue, with a few clouds in the distance.\n\nThere is no sand in the image."}, "377371": {"image_id": 377371, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.18898223649928916, "Bleu_3": 0.10165319124498205, "Bleu_4": 1.3357103091702778e-05, "METEOR": 0.28767646417310216, "ROUGE_L": 0.31213450292397665, "CIDEr": 0.0003502295577634815, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a cutting board with sliced nuts on it. A knife is also on the cutting board. The background features a green and white striped tablecloth.\n\nThere is no banana peel in the image."}, "170813": {"image_id": 170813, "Bleu_1": 0.14678899082434138, "Bleu_2": 0.1042749182664756, "Bleu_3": 0.04666507621909328, "Bleu_4": 5.564389447248332e-06, "METEOR": 0.16008724510929015, "ROUGE_L": 0.12003935716628403, "CIDEr": 7.222626689748467e-58, "SPICE": {"All": {"pr": 0.3125, "re": 0.22727272727272727, "f": 0.2631578947368421, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows five people in a park. One person is walking on the grass, another person is playing baseball in the field, and two people are walking on the grass wearing red shirts. One person is squatting down to use a laptop. The park also has two stone benches. One person is sitting on a bench, looking at a dog in the field, and another person is sitting on a bench, looking at a person in a red shirt. The person sitting on the bench is wearing a brown jacket. There is also a tree in the park.\n\nThe overall scene shows a person sitting under a tree."}, "347210": {"image_id": 347210, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.2385593618010997, "Bleu_3": 0.1417058058944265, "Bleu_4": 1.643518441152205e-05, "METEOR": 0.26210465074195505, "ROUGE_L": 0.3028368794326241, "CIDEr": 3.6330937393272154e-07, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.10526315789473684, "f": 0.09523809523809525, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a park with a bench in the middle of the grass. The bench is made of wood. The park is surrounded by three trees. There are no people in sight. The sky is clear and there are no clouds."}, "175494": {"image_id": 175494, "Bleu_1": 0.25806451612070763, "Bleu_2": 0.1854955582979839, "Bleu_3": 0.10586596094056361, "Bleu_4": 1.434755010621989e-05, "METEOR": 0.2493645737101873, "ROUGE_L": 0.2869238005644403, "CIDEr": 0.001694412833207546, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a dog sleeping on a bed. The dog is wearing a blanket. The bed has a blanket and a pillow. The wall has a cartoon character on it."}, "265879": {"image_id": 265879, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.134717557601255, "Bleu_3": 0.08654263680347211, "Bleu_4": 0.05859113621853524, "METEOR": 0.25549371559328926, "ROUGE_L": 0.22431183021643206, "CIDEr": 1.2464064957989586e-13, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.13333333333333333, "f": 0.18181818181818182, "fn": 39.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3125, "f": 0.38461538461538464, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of four people sitting at a table outside. The people are eating. The people are wearing yellow shirts. Some of the people are smiling. A pizza is on the table. A bottle of wine is on the table. A plate of food is on the table. The people are sitting at a table."}, "433998": {"image_id": 433998, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.142442462319253, "Bleu_3": 0.07725775597136249, "Bleu_4": 1.0176289493198208e-05, "METEOR": 0.17265130555013075, "ROUGE_L": 0.2662758792716388, "CIDEr": 0.03013030644046135, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.16, "f": 0.1379310344827586, "fn": 21.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress. There is a catcher catching the ball. The field is covered in grass. There is a scoreboard displaying the score of the game. However, there are no players, no pitcher, no game, and no team in the image."}, "286711": {"image_id": 286711, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.11065666703226194, "Bleu_3": 0.06342171440889113, "Bleu_4": 8.583294598130882e-06, "METEOR": 0.16831573944463699, "ROUGE_L": 0.1937738246505718, "CIDEr": 6.263759462512404e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1875, "f": 0.17142857142857143, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a baseball game in progress. The players are wearing red and white uniforms. The umpire is wearing a black shirt. The players are wearing pants. The crowd is seated in the stands.\n\nThere is no game or path in the scene. The field is made of grass."}, "552744": {"image_id": 552744, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.21602468994265056, "Bleu_3": 0.15617933312069163, "Bleu_4": 0.11224444648384589, "METEOR": 0.23875541219322532, "ROUGE_L": 0.2501464557703574, "CIDEr": 1.0649914654391635e-09, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.17391304347826086, "f": 0.2352941176470588, "fn": 19.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image is of three women standing in front of a wall with stuffed animals hanging from it. The women are wearing white shirts. They have long brown hair. They are each holding a stuffed animal, and one of them is holding a teddy bear. The wall behind them is black."}, "447279": {"image_id": 447279, "Bleu_1": 0.3199999999936, "Bleu_2": 0.19794866371815806, "Bleu_3": 0.11775100856355505, "Bleu_4": 1.3652085900555668e-05, "METEOR": 0.23512381742682278, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.461117452450951e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of twelve people standing on the sidewalk at the intersection. They are wearing yellow vests and helmets. \n\nThere are no horses in the scene.\n\nThere is no streetlight in the scene.\n\nThere is no horse in the scene.\n\nThere is no sidewalk in the scene."}, "409217": {"image_id": 409217, "Bleu_1": 0.5555555555246915, "Bleu_2": 0.47828670262560663, "Bleu_3": 0.35004667909434545, "Bleu_4": 0.27499775951549793, "METEOR": 0.30049568866310816, "ROUGE_L": 0.4518518518518518, "CIDEr": 0.5892049246041229, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.20689655172413793, "f": 0.2608695652173913, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a plate of food with steak, broccoli, and beans on it. The surface is white."}, "28114": {"image_id": 28114, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.191273013914278, "Bleu_3": 0.097892089462343, "Bleu_4": 1.2534724690400046e-05, "METEOR": 0.21389465084393477, "ROUGE_L": 0.22021660649819497, "CIDEr": 7.370787893816356e-07, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a bus driving down the street. The bus is orange and has the words \"Van\" written on the side. There are people walking on the sidewalk and biking on the sidewalk. There are no buildings in the scene."}, "33994": {"image_id": 33994, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.14892084929058885, "Bleu_3": 9.041973946001247e-07, "Bleu_4": 2.2469734403051963e-09, "METEOR": 0.16788830923941483, "ROUGE_L": 0.21708185053380782, "CIDEr": 0.0004605431637497449, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows an arrangement of flowers on a table. There are two yellow flowers in the arrangement. One of the flowers has a long stem. The table is made of plastic."}, "278509": {"image_id": 278509, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.19507682662422146, "Bleu_3": 0.13956004780907147, "Bleu_4": 0.10730806580090091, "METEOR": 0.2602433992906156, "ROUGE_L": 0.2889039242219215, "CIDEr": 3.3400800183185646e-07, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.1111111111111111, "f": 0.10714285714285715, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image is of a motorcycle parked on the side of a road. The motorcycle is black. The seat is black. The handlebars are black. The tires are black. The road is empty and there are no other vehicles or pedestrians in the image."}, "544975": {"image_id": 544975, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.22794037622152502, "Bleu_3": 0.11198166808362255, "Bleu_4": 1.4053502464380188e-05, "METEOR": 0.2950991045777429, "ROUGE_L": 0.2601279317697228, "CIDEr": 0.00010871845683850555, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a giraffe standing next to a zebra in a zoo. The giraffe is looking at a tree. The giraffe has a long neck. The zebra is looking at a rock. The zebra has a short body."}, "158806": {"image_id": 158806, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.14361061402438519, "Bleu_3": 0.08825729402465829, "Bleu_4": 1.0389626923458908e-05, "METEOR": 0.214754952563734, "ROUGE_L": 0.21942446043165464, "CIDEr": 4.2636280866583407e-17, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.23529411764705882, "f": 0.2222222222222222, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a dog sitting on the ground next to a person who is holding a plate with a piece of toast on it. The dog is looking up at the person with its mouth open. The person is wearing a blue shirt. The person is holding a blue bowl in his hand. The dog is eating from the blue bowl."}, "267321": {"image_id": 267321, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.29214466689738716, "Bleu_3": 0.19231133960538557, "Bleu_4": 0.14198555312627809, "METEOR": 0.23480328453086355, "ROUGE_L": 0.40939597315436244, "CIDEr": 0.01244067724033782, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.08333333333333333, "f": 0.07407407407407407, "fn": 22.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a living room with a couch, a chair, and a window. The walls and the ceiling are white. The room is well lit.\n\nThere is no coffee table, door, plant, or vase in the scene."}, "137188": {"image_id": 137188, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.19062587708942288, "Bleu_3": 0.11180557358247464, "Bleu_4": 0.07235275065135853, "METEOR": 0.19817155854336843, "ROUGE_L": 0.30198019801980197, "CIDEr": 1.0810407033990913e-11, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.25, "f": 0.22727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on a table in front of a window. The cat is looking at a stuffed animal on the table. There is also another stuffed animal on the table. The window provides a view of the outside.\n\nThe cat is a grey and white cat with a fluffy coat."}, "132702": {"image_id": 132702, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.22312917498915605, "Bleu_3": 0.17685746807651279, "Bleu_4": 0.13333925991412676, "METEOR": 0.22656268554418602, "ROUGE_L": 0.24636510500807754, "CIDEr": 1.0748448325784747e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2631578947368421, "f": 0.29411764705882354, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows three pieces of broccoli on a white tablecloth. The broccoli is arranged on the plate in a neat, symmetrical pattern. The plate is not covered with a napkin. The background is a light brown color."}, "151075": {"image_id": 151075, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.2613286875248416, "Bleu_3": 0.12053222932010679, "Bleu_4": 1.4651479869824228e-05, "METEOR": 0.3132289501092905, "ROUGE_L": 0.2713120830244626, "CIDEr": 7.892693808668864e-07, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.24, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a black wetsuit and is holding onto a surfboard with one hand while riding the wave with the other. The wave is large and white."}, "516372": {"image_id": 516372, "Bleu_1": 0.16049382715851243, "Bleu_2": 0.11850405004131419, "Bleu_3": 0.08925511121875405, "Bleu_4": 0.05494790907707286, "METEOR": 0.17845234656338088, "ROUGE_L": 0.15581098339719027, "CIDEr": 6.432541857040129e-31, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.20833333333333334, "f": 0.23255813953488372, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows three cars in a parking lot. There is a parked car in front of the car. The car is maroon. A tree is in front of the car. The car is black. A dog is in front of the car. The car is red and white.\n\nThere is a fire hydrant located in the middle of the road. The fire hydrant is red.\n\nThere is no truck, hood, box, or spout in the scene.\n\nThe roof is black."}, "397958": {"image_id": 397958, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.3270349700741, "Bleu_3": 0.27168347305382384, "Bleu_4": 0.2255391761236893, "METEOR": 0.2707341282079223, "ROUGE_L": 0.391653290529695, "CIDEr": 0.000789703718865327, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.30434782608695654, "f": 0.27999999999999997, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.7142857142857143, "f": 0.4761904761904762, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a black and white cow standing in a field with a fence in the background. The cow has a white patch on its forehead. The cow is looking at the camera."}, "154004": {"image_id": 154004, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.17654696589776867, "Bleu_3": 0.12008331555545111, "Bleu_4": 1.3444449848718374e-05, "METEOR": 0.22176720234870725, "ROUGE_L": 0.2476798143851508, "CIDEr": 1.421216125233757e-13, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of 11 people sitting on the beach. They are wearing swimsuits and some of them are holding surfboards. \n\nThe beach is sandy. There are no palm trees in the scene. The overall atmosphere of the scene is relaxed and enjoyable, as the people sit on the sand and enjoy the beach."}, "179599": {"image_id": 179599, "Bleu_1": 0.44999999998875007, "Bleu_2": 0.3038218101174071, "Bleu_3": 0.1938765058105794, "Bleu_4": 2.106655186698942e-05, "METEOR": 0.2714996302791192, "ROUGE_L": 0.3561301084236864, "CIDEr": 1.1701586970189008e-05, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.2222222222222222, "f": 0.1702127659574468, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a baseball player in a blue jersey and white pants standing on a mound, ready to throw a ball. The background is a green field with a fence.\n\nThere is no glove or ball in the scene."}, "282553": {"image_id": 282553, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.32444284224487613, "Bleu_3": 0.18016397830290895, "Bleu_4": 2.4218026051569858e-05, "METEOR": 0.17748845649236025, "ROUGE_L": 0.34040178571428575, "CIDEr": 0.12867574238946708, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows two people in a field. The people are walking on the sidewalk. They are wearing casual clothing."}, "53529": {"image_id": 53529, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.27450794146236435, "Bleu_3": 0.1871273763607665, "Bleu_4": 0.1306343434446391, "METEOR": 0.31575272905922785, "ROUGE_L": 0.3883101851851851, "CIDEr": 6.8244699374078635e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a dog sitting in the back of a truck with a green hat on its head. The truck is decorated with green and white streamers and balloons. The dog is wearing a green collar. The driver is wearing a black shirt. The shamrock is green."}, "13168": {"image_id": 13168, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.15249857032909853, "Bleu_3": 8.211593041013025e-07, "Bleu_4": 1.9170109753044323e-09, "METEOR": 0.24572398638701057, "ROUGE_L": 0.17134831460674158, "CIDEr": 1.6620249737262242e-07, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.29411764705882354, "f": 0.27777777777777773, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a train on the tracks. The train is silver and has windows on the sides. There are people standing on the platform. The sky is dark and there are streetlights on the platform.\n\nThe train is moving at a slow pace."}, "528738": {"image_id": 528738, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.16001422411453173, "Bleu_3": 0.1124643536531252, "Bleu_4": 1.4198555312627806e-05, "METEOR": 0.18745788454622517, "ROUGE_L": 0.2793893129770992, "CIDEr": 4.9058744375693605e-06, "SPICE": {"All": {"pr": 0.3125, "re": 0.1724137931034483, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a table with a bunch of vegetables on it. There is a carrot, two potatoes, and two onions on the table. There are also five lemons on the table. The table is made of marble."}, "368193": {"image_id": 368193, "Bleu_1": 0.11999999999760003, "Bleu_2": 0.04948716592953954, "Bleu_3": 3.708924358389366e-07, "Bleu_4": 1.0207315006261665e-09, "METEOR": 0.12557203287675472, "ROUGE_L": 0.1586475942782835, "CIDEr": 6.907380714583853e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 30.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two people riding horses down the street. The horses are standing still. The people are wearing cowboy hats and riding boots. One person is on the horses. The street is lined with houses and there are no trees in the scene. The sky is clear and blue."}, "538064": {"image_id": 538064, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.14062009564344036, "Bleu_3": 0.0880168037197584, "Bleu_4": 0.05881058251701122, "METEOR": 0.2193559139291418, "ROUGE_L": 0.25738396624472576, "CIDEr": 2.2351510396389224e-15, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3, "f": 0.2926829268292683, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two statues made of bronze and concrete. One statue depicts a man in a suit and hat holding a child in his arms. The statues are located on a pedestal in the middle of a city street. There are two buildings and three cars in the background. The city street is located in front of the statues."}, "265636": {"image_id": 265636, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.16165520152449506, "Bleu_3": 0.10932423750469307, "Bleu_4": 1.352917115464091e-05, "METEOR": 0.22611327980742016, "ROUGE_L": 0.18236173393124064, "CIDEr": 2.1491758765852913e-07, "SPICE": {"All": {"pr": 0.5, "re": 0.1935483870967742, "f": 0.27906976744186046, "fn": 25.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a stuffed animal sitting on a couch next to a birthday card. The card has the words \"happy birthday\" written on it. The stuffed animal is wearing a bow tie.\n\nThe background of the image is a red and"}, "577796": {"image_id": 577796, "Bleu_1": 0.18644067796294173, "Bleu_2": 0.13887752404723028, "Bleu_3": 0.06968345758419357, "Bleu_4": 8.816582219575545e-06, "METEOR": 0.12451722447239726, "ROUGE_L": 0.13840045377197957, "CIDEr": 6.749997531373453e-16, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bathroom with six urinals on the wall. The urinals are made of porcelain, ceramic, plastic, or stainless steel. They have a spherical or oblong shape with a hole in the center. They are mounted on the wall with metal brackets. Some of the urinals have a small mirror or a TV screen on the side."}, "554046": {"image_id": 554046, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.15785101684950267, "Bleu_3": 0.10672028316489314, "Bleu_4": 1.3202927206769876e-05, "METEOR": 0.23588041926476574, "ROUGE_L": 0.2616154395997141, "CIDEr": 8.856760749279147e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows four sheep standing in a snowy field. They are wearing coats and appear to be enjoying the snow. The fence in the background is made of wire. \n\nThere is no gate or shed in the scene.\n\nThe sky is cloudy."}, "316534": {"image_id": 316534, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.13957263155725563, "Bleu_3": 0.07118725684669193, "Bleu_4": 9.083071358441841e-06, "METEOR": 0.17348941868386927, "ROUGE_L": 0.20460644007155634, "CIDEr": 1.6366807159488364e-13, "SPICE": {"All": {"pr": 0.3, "re": 0.14285714285714285, "f": 0.19354838709677416, "fn": 36.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.29411764705882354, "f": 0.3448275862068966, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of six cows grazing on a grassy hillside next to a body of water. The cows are brown and black with white spots on their faces. They are not standing in a line. The cows are looking at the water. In the background, there are palm trees and a blue sky."}, "158950": {"image_id": 158950, "Bleu_1": 0.16883116882897622, "Bleu_2": 0.11545032042537927, "Bleu_3": 0.05622243796728913, "Bleu_4": 7.000423685163775e-06, "METEOR": 0.18571078837531493, "ROUGE_L": 0.18986216096042685, "CIDEr": 7.367363768245422e-28, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.0967741935483871, "f": 0.1111111111111111, "fn": 28.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a train traveling along a track in the middle of a field. The train is blue and yellow. The track is located in the middle of a field. There are trees and bushes on either side of the track. A tree is above the track. The train is moving smoothly along the Sydney train track. The train has a number on the side. The sky is cloudy and there are clouds above the sky."}, "524822": {"image_id": 524822, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.17377018855424126, "Bleu_3": 0.13508428197080266, "Bleu_4": 0.08465318538300615, "METEOR": 0.25359056662790164, "ROUGE_L": 0.3285457809694794, "CIDEr": 1.5332734416590637e-10, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.2916666666666667, "f": 0.27450980392156865, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a living room with four couches. The couches are white and beige. There is a white fireplace with a mirror above it. The room has a large window that is well lit. There are white curtains on the window. A flat screen TV is mounted on the wall."}, "248111": {"image_id": 248111, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.11952367853238388, "Bleu_4": 1.3594021798767565e-05, "METEOR": 0.18231363980747387, "ROUGE_L": 0.24811156304474144, "CIDEr": 1.0426104298987834e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.18518518518518517, "f": 0.20833333333333334, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a kitchen with white cabinets and a white refrigerator. There is a stove and a sink in the kitchen. The floor is made of hardwood.\n\nThe walls are painted white and there are no windows in the room. The ceiling is made of white plaster. The room is spacious and well-lit."}, "409964": {"image_id": 409964, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1504179432467115, "Bleu_4": 0.09604167742854731, "METEOR": 0.33804479790093495, "ROUGE_L": 0.29756097560975614, "CIDEr": 1.914375447384938e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a tennis court. He is wearing a white shirt and blue and white shorts, and has a tennis racket in his hand. The court is made of grass and there are trees in the background."}, "337987": {"image_id": 337987, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.1998225376133843, "Bleu_4": 0.1716075518039193, "METEOR": 0.261607620226656, "ROUGE_L": 0.3059013163786155, "CIDEr": 2.5695474257819596e-09, "SPICE": {"All": {"pr": 0.0851063829787234, "re": 0.16, "f": 0.11111111111111112, "fn": 21.0, "numImages": 1.0, "fp": 43.0, "tp": 4.0}, "Relation": {"pr": 0.0625, "re": 0.1, "f": 0.07692307692307693, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.3, "f": 0.22222222222222224, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image shows a bird perched on a branch of a tree. The bird's body is brown and black. The bird has a black stripe on its head. The bird has a long, curved beak. The bird's eyes are open. The bird is perched on the branch."}, "544104": {"image_id": 544104, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.1363861813953473, "Bleu_3": 6.694472319171738e-07, "Bleu_4": 1.4892060909898447e-09, "METEOR": 0.19173186828796712, "ROUGE_L": 0.24448897795591185, "CIDEr": 1.087570666277202e-17, "SPICE": {"All": {"pr": 0.47058823529411764, "re": 0.34782608695652173, "f": 0.39999999999999997, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 8.0}, "Relation": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a harbor with several boats docked at the pier. The boats are small and colorful. Some of the boats are having sails up. The water is calm and clear. There is no pier in the scene. The sail is up on one of the boats. There is a building on the shore. There is no shore or stone in the scene."}, "121210": {"image_id": 121210, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.19518886688953246, "Bleu_3": 0.11432028587212996, "Bleu_4": 1.3147705731634356e-05, "METEOR": 0.20141853976929686, "ROUGE_L": 0.27036011080332406, "CIDEr": 2.4298239749292776e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1, "f": 0.13953488372093023, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a plate of food with a stew made with beef and carrots. The carrots are orange in color. The dish is served with a side of green beans and a sprig of parsley on top. The plate is placed on a white tablecloth. There is a knife on the tablecloth."}, "46551": {"image_id": 46551, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.16658955971162087, "Bleu_3": 0.10724350864958367, "Bleu_4": 1.2939428392854091e-05, "METEOR": 0.14049107706538985, "ROUGE_L": 0.24416277518345564, "CIDEr": 3.7253595851821743e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of five people standing in a room. The people are all wearing black shirts and jeans. One of the people is holding a camera. The room has a wooden ceiling and is made of brick. \n\nThere is no television in the room."}, "535588": {"image_id": 535588, "Bleu_1": 0.340909090901343, "Bleu_2": 0.26711994597152616, "Bleu_3": 1.193221624352811e-06, "Bleu_4": 2.537142570239067e-09, "METEOR": 0.23477960507231574, "ROUGE_L": 0.2733674775928297, "CIDEr": 1.2458278445450726e-05, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This image shows a bus parked on the side of the road. The bus has a bike rack on the back. There is a person standing next to the bus, looking at a bike. The sky and trees are not visible in the image."}, "173997": {"image_id": 173997, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.19069251784483274, "Bleu_3": 0.11914512632603338, "Bleu_4": 1.416592339557592e-05, "METEOR": 0.22519969332912584, "ROUGE_L": 0.24646464646464644, "CIDEr": 5.760750017486403e-08, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.375, "f": 0.25531914893617014, "fn": 10.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two people sitting on a bench in a park. They are wearing red jackets. The bench is made of wood and has a small table on it. There are no trees in the scene, but there is a bush in the background."}, "320396": {"image_id": 320396, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.13857638305004102, "Bleu_3": 8.110083286556016e-07, "Bleu_4": 1.9758409157987315e-09, "METEOR": 0.184414376931888, "ROUGE_L": 0.3172362555720654, "CIDEr": 1.0877115925326746e-05, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a man playing frisbee on a beach with a group of seagulls in the background. The man is wearing a white shirt and white pants, and he is holding a frisbee in his right hand."}, "221282": {"image_id": 221282, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.14907119849725053, "Bleu_3": 0.10794709443366063, "Bleu_4": 0.08339977535654645, "METEOR": 0.2284507079237209, "ROUGE_L": 0.29500268672756585, "CIDEr": 1.940684484503955e-11, "SPICE": {"All": {"pr": 0.28, "re": 0.21212121212121213, "f": 0.2413793103448276, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three women in a room. One of the women is putting a pizza on a wooden table and cutting it with a knife. The other two women are also preparing food, cutting a cake with a knife. The room is filled with the smell of pizza. The women are wearing white shirts."}, "25143": {"image_id": 25143, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.23262966005988533, "Bleu_3": 0.1688078155277358, "Bleu_4": 0.12160144681459327, "METEOR": 0.22224135140193094, "ROUGE_L": 0.30367143746110764, "CIDEr": 1.318128416904533e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.25, "f": 0.22857142857142856, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of four people playing frisbee in a park. They are all wearing green shirts and white pants. One person is throwing a frisbee while the others are running to catch it. The grass is green and there are trees in the background."}, "52835": {"image_id": 52835, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.14679516868082104, "Bleu_3": 7.408254355300373e-07, "Bleu_4": 1.6721917553985766e-09, "METEOR": 0.2379732741820181, "ROUGE_L": 0.20666290231507625, "CIDEr": 3.2523859887763814e-12, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.09090909090909091, "f": 0.11538461538461539, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a lunch box with various food items inside, including a carrot, an orange, and peas. The lunch box is made of plastic. The lid is also made of plastic. The food items, including carrots, orange, peas, meatballs, and a yogurt, are arranged in a row on a tray inside the lunch box."}, "300962": {"image_id": 300962, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.23204774044025306, "Bleu_3": 0.17829685970436746, "Bleu_4": 0.1464157017197837, "METEOR": 0.32883603780479664, "ROUGE_L": 0.32250755287009064, "CIDEr": 1.5645785272941169e-06, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2413793103448276, "f": 0.2545454545454545, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two baseball players swinging a bat at a ball on a baseball field. The players are wearing jerseys and pants. The jersey is black and white. The pants are white. The ball is flying through the air."}, "332532": {"image_id": 332532, "Bleu_1": 0.14999999999812502, "Bleu_2": 0.07547319081304477, "Bleu_3": 4.17987800561266e-07, "Bleu_4": 9.868474509236863e-10, "METEOR": 0.14550975013263595, "ROUGE_L": 0.157487091222031, "CIDEr": 2.2094832508344238e-30, "SPICE": {"All": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a bathroom with four toilets, two sinks, and a trash can. The walls are orange and the floor is made of tile.\n\nThe toilets are made of porcelain and do not have lids. The sinks are made of porcelain as well, with one being white and the other being pink. There is a spray bottle on one of the sinks and a toothbrush on the other.\n\nPlease note that there is no trash can in the scene."}, "528261": {"image_id": 528261, "Bleu_1": 0.16666666666269844, "Bleu_2": 0.11043152607218519, "Bleu_3": 6.730418227629333e-07, "Bleu_4": 1.6721120911708975e-09, "METEOR": 0.15702469353636672, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.1059518246686756e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.46153846153846156, "f": 0.4444444444444445, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image features a giraffe grazing on the grass. The giraffe is looking at the grass. The giraffe is not wearing a giraffe hat. The fenced in area is made of wood. The grass is green. There are trees in the area."}, "297046": {"image_id": 297046, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 0.09041487870756197, "Bleu_4": 1.0972040044962827e-05, "METEOR": 0.20096297100432395, "ROUGE_L": 0.14896214896214896, "CIDEr": 1.2143448782693857e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a train traveling down the tracks. The train is orange and has a red and black paint job. There are cars parked on the side of the road. There are buildings in the background. The sky is cloudy. There are trees in the background.\n\nThe train is traveling down the tracks."}, "130839": {"image_id": 130839, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.3099340466837252, "Bleu_3": 0.15265988694268132, "Bleu_4": 1.9233147636007186e-05, "METEOR": 0.3394189632574917, "ROUGE_L": 0.4353256021409455, "CIDEr": 0.004807355778304376, "SPICE": {"All": {"pr": 0.125, "re": 0.10714285714285714, "f": 0.11538461538461538, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man carrying a suitcase on the sidewalk. The man is wearing a black suit and is carrying two suitcases. The man's hair is gray."}, "451120": {"image_id": 451120, "Bleu_1": 0.4594594594470417, "Bleu_2": 0.29889687073377524, "Bleu_3": 0.23369436051191625, "Bleu_4": 0.18318788922526721, "METEOR": 0.2871329185201889, "ROUGE_L": 0.332295719844358, "CIDEr": 3.185710919573918e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.12903225806451613, "f": 0.15999999999999998, "fn": 27.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a woman standing at a table with two jars of food on it. She is wearing a blue sweater and has a smile on her face. There are no other people in the scene."}, "378134": {"image_id": 378134, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.4074406768151364, "Bleu_3": 0.3406380512769036, "Bleu_4": 0.27748702734311687, "METEOR": 0.29296764693040483, "ROUGE_L": 0.39144385026737966, "CIDEr": 0.10519415676519167, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.09375, "f": 0.12244897959183672, "fn": 29.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of four people playing frisbee on a grassy field. The players are wearing shirts. The sky is blue."}, "458953": {"image_id": 458953, "Bleu_1": 0.1382978723389543, "Bleu_2": 1.2194563936860548e-09, "Bleu_3": 2.5284143175886606e-12, "Bleu_4": 1.154451872824181e-13, "METEOR": 0.1264824481112238, "ROUGE_L": 0.15652492668621698, "CIDEr": 6.24068338722864e-40, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.23529411764705882, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of two people in a field. The people are flying a kite. They are wearing a blue shirt. The sky is filled with kites. The kites are in various colors and shapes. Some of the kites have a string of plastic bags attached to them, while others have a string of lights, beads, or a person attached to them. The kites include swans, hearts, octagons, and kites with a red cross on them. There is also a kite shaped like a cactus and a kite shaped like a lizard."}, "159451": {"image_id": 159451, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.20225995873532804, "Bleu_3": 0.1558829769381012, "Bleu_4": 0.12100696391488384, "METEOR": 0.2380238023002039, "ROUGE_L": 0.23775055679287305, "CIDEr": 1.1312907020321572e-13, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2222222222222222, "f": 0.24489795918367346, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a yellow tractor parked on a dirt road in front of a large building. The tractor has a large hood on the front. There is no bucket in the scene. The tractor is parked next to a large pile of dirt. There are no other vehicles or people in the image."}, "294258": {"image_id": 294258, "Bleu_1": 0.5517241379120095, "Bleu_2": 0.3713906763410685, "Bleu_3": 1.7222627547611908e-06, "Bleu_4": 3.7439601738468776e-09, "METEOR": 0.28590284774693225, "ROUGE_L": 0.46018440905280805, "CIDEr": 0.04715556820481018, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.07407407407407407, "f": 0.08695652173913043, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man wearing a black suit and a brown tie standing in front of a building. The man is also wearing a white and gray shirt."}, "544695": {"image_id": 544695, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.16064386577523138, "Bleu_3": 9.618560885253057e-07, "Bleu_4": 2.374340857937043e-09, "METEOR": 0.2972458642007234, "ROUGE_L": 0.3266107442441549, "CIDEr": 0.0037966408024792254, "SPICE": {"All": {"pr": 0.25, "re": 0.2608695652173913, "f": 0.2553191489361702, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two women playing tennis on a court. The women are holding tennis rackets. They are both wearing tennis shoes and white clothing. The background is a black field."}, "623": {"image_id": 623, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.17390208590454106, "Bleu_3": 1.0026809779444285e-06, "Bleu_4": 2.4281336212346506e-09, "METEOR": 0.2510107243568299, "ROUGE_L": 0.4080267558528428, "CIDEr": 0.001179765800628696, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.13636363636363635, "f": 0.10909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a woman sitting on a teddy bear. The woman is wearing a purple shirt. The teddy bear is wearing a pink dress and has its arms around the woman."}, "236690": {"image_id": 236690, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.1566749772899432, "Bleu_3": 0.10891354481885915, "Bleu_4": 0.0693049753220061, "METEOR": 0.2219026293351666, "ROUGE_L": 0.20344635908838243, "CIDEr": 5.356504517264252e-15, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image is of a seagull flying over the ocean. The bird has white wings with black patterns and a black and red beak. The sky is blue and there are waves in the background. The seagull is flying high in the air and appears to be in a state of flight. The image is taken from a distance."}, "382088": {"image_id": 382088, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.2114602732248218, "Bleu_3": 0.16474763643642418, "Bleu_4": 0.13618477462329975, "METEOR": 0.2840023135360377, "ROUGE_L": 0.31077147016011636, "CIDEr": 4.852684567773161e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13333333333333333, "f": 0.163265306122449, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a white horse standing in a field. The horse has a white mane and tail. The horse is looking directly at the camera. There is a fence in the background.\n\nThere is no sky or trees in the scene."}, "504711": {"image_id": 504711, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.28867513458592853, "Bleu_3": 0.23776195046624574, "Bleu_4": 0.19147265797760177, "METEOR": 0.3811393314201573, "ROUGE_L": 0.4852824184566428, "CIDEr": 0.0032621257037576392, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07692307692307693, "f": 0.0851063829787234, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a cake with chocolate icing on top. A piece of chocolate cake is on a plate. The fork is holding a piece of cake. A person is holding the fork."}, "495348": {"image_id": 495348, "Bleu_1": 0.3846153846005918, "Bleu_2": 3.922322702609806e-09, "Bleu_3": 8.622339795765927e-12, "Bleu_4": 4.085892078969877e-13, "METEOR": 0.14026456966171424, "ROUGE_L": 0.24158415841584158, "CIDEr": 0.015672145477635454, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.20833333333333334, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of five zebras standing and grazing in a grassy field. The zebras are in their natural habitat, which is the savannas."}, "326217": {"image_id": 326217, "Bleu_1": 0.27272727272314046, "Bleu_2": 0.17137861409677843, "Bleu_3": 0.09718243089729395, "Bleu_4": 1.0986406937328196e-05, "METEOR": 0.18807328570442106, "ROUGE_L": 0.2506849315068493, "CIDEr": 2.799171695224823e-17, "SPICE": {"All": {"pr": 0.16, "re": 0.125, "f": 0.14035087719298245, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of four people in a boat on a river. They are wearing hats and traditional Thai clothing. The people are carrying baskets of fruit and vegetables. The man is wearing a red shirt. The woman is wearing a hat. The boat is being pulled by a man and a woman in traditional Thai clothing. There are other boats in the background."}, "59752": {"image_id": 59752, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.08444006618162872, "Bleu_3": 6.062462295166369e-07, "Bleu_4": 1.6373682487936863e-09, "METEOR": 0.22444251983056926, "ROUGE_L": 0.21441124780316342, "CIDEr": 7.245325893280417e-05, "SPICE": {"All": {"pr": 0.16, "re": 0.23529411764705882, "f": 0.19047619047619052, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a river with two boats on it. There are two houses on the other side of the river. The sky is blue. There are trees on the banks of the river."}, "437393": {"image_id": 437393, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.2480694691721357, "Bleu_3": 0.1864122047986733, "Bleu_4": 0.11502846551482096, "METEOR": 0.22782302105360103, "ROUGE_L": 0.2764350453172206, "CIDEr": 1.7932907571204084e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a white horse with blue and pink accents on its mane and tail. The horse has a blue bow on its head and a pink rose on its neck. The horse is standing on a white surface."}, "279209": {"image_id": 279209, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.12262786789482262, "Bleu_3": 6.49040635782644e-07, "Bleu_4": 1.5000491055541283e-09, "METEOR": 0.18990161701721997, "ROUGE_L": 0.2255678816693079, "CIDEr": 3.4015140310252145e-13, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person skiing down a snowy mountain trail. The person is wearing a black and blue ski suit and carrying skis. The trees on either side of the trail are covered in white snow. The sky is clear and the color of the sky is white.\n\nThe image is taken in the winter season."}, "202228": {"image_id": 202228, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.23262966005988533, "Bleu_3": 0.1688078155277358, "Bleu_4": 0.12160144681459327, "METEOR": 0.28286815021472944, "ROUGE_L": 0.31063017186505404, "CIDEr": 2.3648715924773136e-08, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.12903225806451613, "f": 0.13333333333333333, "fn": 27.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a man taking a selfie in front of a mirror. The man is wearing a red jacket and black pants, and he has a black hat on his head. The mirror is white. The room is empty except for the mirror and the man."}, "193661": {"image_id": 193661, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.2129856878358862, "Bleu_3": 0.16553898215115095, "Bleu_4": 0.13299435569869233, "METEOR": 0.25889965749168997, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.004629599190867918, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.24, "f": 0.1935483870967742, "fn": 19.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a living room with a fireplace, hardwood floors, and yellow walls. There is a door on one side of the room. A rocking chair is in the living room."}, "457060": {"image_id": 457060, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.22037727300834692, "Bleu_3": 0.1292360563774017, "Bleu_4": 1.4882455879058205e-05, "METEOR": 0.23863382104148495, "ROUGE_L": 0.2217912980244819, "CIDEr": 5.325773343239857e-07, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15789473684210525, "f": 0.18181818181818182, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows two giraffes standing in a fenced in area. One of the giraffes is looking at the camera and the other giraffe is also looking at the camera. The fenced in area is surrounded by a metal fence. There is a tree in the background."}, "390215": {"image_id": 390215, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.22140372137841335, "Bleu_3": 0.1452390111187727, "Bleu_4": 1.773054311768373e-05, "METEOR": 0.3364090811420464, "ROUGE_L": 0.41567291311754684, "CIDEr": 0.00045631822932724187, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.25, "f": 0.2941176470588235, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.625, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a plate of food with two chickens, broccoli, and herbs. The chicken is roasted and seasoned with herbs and spices. The broccoli is steamed. The food is served on the plate."}, "579635": {"image_id": 579635, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.1587768372028858, "Bleu_3": 0.09141555868773478, "Bleu_4": 1.2430185040655493e-05, "METEOR": 0.18210136239435273, "ROUGE_L": 0.19757085020242915, "CIDEr": 0.00016459238575665473, "SPICE": {"All": {"pr": 0.25, "re": 0.11428571428571428, "f": 0.1568627450980392, "fn": 31.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.25, "f": 0.34782608695652173, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows two surfers riding waves on surfboards in the ocean. The surfers are wearing wetsuits. One of the surfers is wearing a black and white shirt. The waves are breaking on the shore."}, "251920": {"image_id": 251920, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.11314714295768938, "Bleu_3": 7.084810326519695e-07, "Bleu_4": 1.7853738103300445e-09, "METEOR": 0.12204116735498086, "ROUGE_L": 0.2672090112640801, "CIDEr": 0.0003617156780912775, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.18518518518518517, "f": 0.18181818181818182, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows six pizzas on a black and white checkered plate. The pizzas are topped with various ingredients such as cheese, pepperoni, and vegetables. There is a bottle of wine on the counter next to the pizzas."}, "271117": {"image_id": 271117, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.17864740024886272, "Bleu_3": 8.852756586932276e-07, "Bleu_4": 1.9815533245784103e-09, "METEOR": 0.2588656096980491, "ROUGE_L": 0.27371794871794874, "CIDEr": 1.5778826255274362e-08, "SPICE": {"All": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image is of a small room with a desk, bookshelf, and a lamp. On the desk, there is a blue vase, a clock, a remote control, and a pen. On the bookshelf, there is a laptop. The walls are yellow. There is no window in the room."}, "11051": {"image_id": 11051, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.16958686225644692, "ROUGE_L": 0.25221500295333726, "CIDEr": 2.0666352421050896e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 40.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.5, "f": 0.15384615384615385, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.23529411764705882, "re": 0.4, "f": 0.29629629629629634, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image shows a woman in a black dress and a man in a tuxedo standing next to each other. The woman is holding a flower. The man is also holding a flower. They are both smiling and not looking at each other. The background is a white wall."}, "170605": {"image_id": 170605, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.08401680504001675, "Bleu_3": 5.242181839106549e-07, "Bleu_4": 1.3162056532389086e-09, "METEOR": 0.08687782805429864, "ROUGE_L": 0.15288220551378445, "CIDEr": 9.100738613255086e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "There are no people in this image. There are two snowmobiles in the middle of a snowy field. The sun is shining down on them. There are no trees or buildings in the background. The snowmobiles are parked on the ground. There are no other vehicles or people in the scene."}, "84123": {"image_id": 84123, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.19340379080858328, "Bleu_3": 0.12533108165793935, "Bleu_4": 0.07700112744244865, "METEOR": 0.19953403993057783, "ROUGE_L": 0.2197632527020072, "CIDEr": 1.2012917990111755e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1282051282051282, "f": 0.18518518518518517, "fn": 34.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.25, "f": 0.34782608695652173, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a street with cars parked on both sides. There are signs on the street indicating the direction of traffic. The signs indicate \"West ocean beaches turn right 1 block\" and \"capital blvd and the museum\". The sky is cloudy and there is no sunlight. The image is taken from a low angle, looking down the street."}, "505899": {"image_id": 505899, "Bleu_1": 0.29999999999500004, "Bleu_2": 0.24701609087363371, "Bleu_3": 0.16144607667342067, "Bleu_4": 0.1102324364630613, "METEOR": 0.2733093872286343, "ROUGE_L": 0.26236559139784943, "CIDEr": 3.274334546244337e-15, "SPICE": {"All": {"pr": 0.05, "re": 0.02631578947368421, "f": 0.034482758620689655, "fn": 37.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.07142857142857142, "f": 0.08, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a table with a cup of coffee and a plate of donuts on it. The donuts are covered in glaze and sprinkles. There is a knife on the table. \n\nThe cup of coffee contains a latte. Two donuts are on the plate. One of the donuts is heart-shaped. \n\nThe background is a wooden floor with no carpet."}, "256814": {"image_id": 256814, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.17807996398101744, "Bleu_3": 0.15571015753072553, "Bleu_4": 0.12892052266756399, "METEOR": 0.263088282008854, "ROUGE_L": 0.29985955056179775, "CIDEr": 7.345268886075674e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows two men in the scene. The first man is holding a donut in his hand and eating it. The second man is holding a cell phone and taking a selfie. There is no car, driver, passenger, or tree in the image."}, "419680": {"image_id": 419680, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 7.063108368194853e-07, "Bleu_4": 1.7019021213324188e-09, "METEOR": 0.16468574659350607, "ROUGE_L": 0.2350674373795761, "CIDEr": 3.0056664392774526e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.27586206896551724, "f": 0.2318840579710145, "fn": 21.0, "numImages": 1.0, "fp": 32.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}}, "caption": "The image shows a building on the left and a sign on the right. The building has a large window on the top floor and a small window on the bottom floor. The sign has the words \"no parking\" written on it in green letters."}, "519555": {"image_id": 519555, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.22522130822577494, "Bleu_3": 0.15122694444080373, "Bleu_4": 0.09470104449999896, "METEOR": 0.2558319135902014, "ROUGE_L": 0.2827814569536423, "CIDEr": 2.9242714866017206e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.5, "f": 0.23529411764705882, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a stop sign in the middle of a field. The sign is made of metal and has a red and white background with the word stop written in black letters. The sign is surrounded by tall grass and trees. The sky is cloudy."}, "354929": {"image_id": 354929, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.2681074537606562, "Bleu_3": 0.15070679262303924, "Bleu_4": 1.699822823471084e-05, "METEOR": 0.28071877391432154, "ROUGE_L": 0.35835509138381205, "CIDEr": 6.4561893760605e-06, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of seven people riding bikes down a street at night. They are wearing helmets and some of them are holding lights on their bikes. The street is lit up by streetlights and there are no buildings in the scene."}, "17379": {"image_id": 17379, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.08217664461402949, "Bleu_4": 1.0264051022519406e-05, "METEOR": 0.22685722630468597, "ROUGE_L": 0.27036011080332406, "CIDEr": 6.582289274284729e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 9.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image is of a bathroom with a large mirror on the wall. The mirror is framed in a tile. A television is mounted on the mirror. There are two sinks in the bathroom. The sink on the left has a faucet and a drain. The sink on the right has a mirror."}, "13965": {"image_id": 13965, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.12757664411350078, "Bleu_4": 0.10032055246769755, "METEOR": 0.22121093713059076, "ROUGE_L": 0.23341836734693874, "CIDEr": 4.877135855527582e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15, "f": 0.15789473684210525, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows two cars parked on the side of a street. There is a green trolley car among them. The trolley car has a sign on the side that reads \"San Francisco muni\". There are no other cars or people in the scene."}, "422836": {"image_id": 422836, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.18216065373578985, "Bleu_3": 0.13846277984327005, "Bleu_4": 0.10202539004220176, "METEOR": 0.31601948370947325, "ROUGE_L": 0.30049261083743845, "CIDEr": 3.0773683695384214e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.12121212121212122, "f": 0.10666666666666667, "fn": 29.0, "numImages": 1.0, "fp": 38.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.2857142857142857, "f": 0.2758620689655172, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a man and a woman walking down a street. The man is carrying a suitcase and the woman is carrying a suitcase. There is a building on the left side of the street and a cafe on the right side. There are no trees or cars in the scene."}, "513292": {"image_id": 513292, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.20314980006762443, "Bleu_3": 0.10667221025972526, "Bleu_4": 1.3848731186391142e-05, "METEOR": 0.29332566870458554, "ROUGE_L": 0.2839851024208566, "CIDEr": 0.000149117440834526, "SPICE": {"All": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a boy walking on a sidewalk. The boy is holding a black and white skateboard. He is wearing blue shorts and a red shirt. The background does not include any houses or trees."}, "202444": {"image_id": 202444, "Bleu_1": 0.1585365853639203, "Bleu_2": 0.07662718436544834, "Bleu_3": 0.041868935208292386, "Bleu_4": 5.520929029024112e-06, "METEOR": 0.13816533480189283, "ROUGE_L": 0.13045337895637296, "CIDEr": 1.4673993155281728e-30, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of three people sitting on the ground, doing skateboarding, and standing on a wall. They are in a park where a skateboard ramp is located. The ramp is made of concrete and does not have a railing on the side.\n\nThe people are wearing different clothes. The woman is wearing a white shirt and blue jeans. The man is also wearing a white shirt and blue jeans.\n\nOverall, the image depicts people skateboarding at a skate park."}, "268541": {"image_id": 268541, "Bleu_1": 0.15068493150478515, "Bleu_2": 0.13724291033724306, "Bleu_3": 0.10987456395283174, "Bleu_4": 0.09330681415524934, "METEOR": 0.2226457147263411, "ROUGE_L": 0.21972084646555606, "CIDEr": 9.2797457909747e-24, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.3125, "f": 0.2564102564102564, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a man wearing a suit and tie, standing in front of a white wall. The man is holding a cup in his hand. The cup is in the man's hand. The man is also wearing a scarf on his neck. There is a black and white photo on the wall. The photo appears to be of a man in a suit and tie, holding a cup in his hand."}, "377999": {"image_id": 377999, "Bleu_1": 0.31666666666138893, "Bleu_2": 0.2197841776473887, "Bleu_3": 0.09408526625258933, "Bleu_4": 1.099442446212156e-05, "METEOR": 0.24585743006803548, "ROUGE_L": 0.3043912175648702, "CIDEr": 3.917563693777874e-14, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.14814814814814814, "f": 0.12903225806451613, "fn": 23.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.2727272727272727, "f": 0.2222222222222222, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a man standing on the shore of a dock, looking out at a sailboat on the water. The man is riding a bike and is also looking at a dog. The dock is made of wood. The sky is clear and blue, with a few clouds scattered across it. The water is calm and reflects the sky."}, "272694": {"image_id": 272694, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.269724531227751, "Bleu_3": 0.20323395413067125, "Bleu_4": 0.13536681105262507, "METEOR": 0.23977749317260735, "ROUGE_L": 0.3500382555470543, "CIDEr": 0.04350040689715056, "SPICE": {"All": {"pr": 0.28125, "re": 0.28125, "f": 0.28125, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a banana and a cup on a table. The banana is ripe. The cup is filled with coffee. The Starbucks logo is on the cup."}, "137844": {"image_id": 137844, "Bleu_1": 0.15384615384446323, "Bleu_2": 0.11694106923964503, "Bleu_3": 0.06748253210304485, "Bleu_4": 7.68728282190772e-06, "METEOR": 0.16362777352867358, "ROUGE_L": 0.18270310745039314, "CIDEr": 2.550137259309118e-40, "SPICE": {"All": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows four people in a skate park. One person is sitting on a bench, while another person is riding a skateboard and performing a trick. The person performing the trick is wearing a red hat and a black shirt with green pants. Another person is also performing a skateboard trick and wearing a hat, but with a helmet on their head. This person is wearing a black shirt and navy blue pants. The skate park is surrounded by a fence, and there are rocks and trees in the background."}, "374829": {"image_id": 374829, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.24442576475815658, "Bleu_3": 0.14916736567829222, "Bleu_4": 1.7548433487930022e-05, "METEOR": 0.26114058971607773, "ROUGE_L": 0.30421772584781986, "CIDEr": 0.0009400158089545016, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.11538461538461539, "f": 0.12499999999999997, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a baseball player holding a bat in the field. The umpires are preparing to call a baseball game.\n\nThere is no batter's box, ball, crowd, stands, home plate, obstacles, or game in the image."}, "21465": {"image_id": 21465, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.11429089766174176, "Bleu_3": 6.350643060633274e-07, "Bleu_4": 1.5044258140708105e-09, "METEOR": 0.14317172418421106, "ROUGE_L": 0.14796846573681016, "CIDEr": 4.412603969487496e-12, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3333333333333333, "f": 0.2962962962962963, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a picture of a room with a table and chairs in it. There are several items on the table, including a vase, a lamp, and a book. The walls are brown. There are two windows in the room. The floor is made of wood. There are no rugs in the room."}, "281929": {"image_id": 281929, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.17504208247906033, "Bleu_3": 0.1322380251708152, "Bleu_4": 0.10747234966422095, "METEOR": 0.25701641540826736, "ROUGE_L": 0.3038184836745988, "CIDEr": 2.1737518577283387e-12, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2222222222222222, "f": 0.24489795918367346, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The man in the image is wearing a brown suit and tie, and is standing next to a bicycle. The man is holding onto the handlebars of the bicycle with both hands. The bicycle has a black frame and white tires. \n\nIn the background, there is a house with a brown roof and white walls."}, "464814": {"image_id": 464814, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1413162504531272, "Bleu_4": 0.11350940547325802, "METEOR": 0.30324140524650006, "ROUGE_L": 0.34936998854524626, "CIDEr": 3.4582031510471304e-12, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.1875, "f": 0.22641509433962265, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a living room with a couch, a television, and a chair on the furniture. The walls are light purple. There are windows in the room. The floor is made of hardwood. There is a rug on the furniture.\n\nThe living room is well lit and there is no clutter or mess."}, "213538": {"image_id": 213538, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.18726241522375653, "Bleu_3": 0.10715656750302463, "Bleu_4": 1.217494725595168e-05, "METEOR": 0.19605450639839006, "ROUGE_L": 0.19192448872574724, "CIDEr": 4.915291399997054e-12, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.06060606060606061, "f": 0.07272727272727272, "fn": 31.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows two desks with a computer, keyboard, and two mice on them. Two computer monitors are on the first desk, and a laptop computer is on the second desk. A red curtain is hanging behind the desks. A chair and a computer monitor are in the background. There is no bookshelf, wall, or window in the scene."}, "461573": {"image_id": 461573, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.0800071120572659, "Bleu_3": 5.623217682656264e-07, "Bleu_4": 1.5013144369944e-09, "METEOR": 0.17653800946530832, "ROUGE_L": 0.23940345368916802, "CIDEr": 4.207319689502659e-06, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.1724137931034483, "f": 0.18867924528301888, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three benches made of metal. The benches have a rusty and worn appearance. They are sitting on the sidewalk. \n\nThere are no trees in the scene.\n\nThere is one leaf which is brown in color."}, "360629": {"image_id": 360629, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.12626174790809142, "Bleu_3": 0.08982012142922803, "Bleu_4": 0.06407123783458783, "METEOR": 0.1620685781405619, "ROUGE_L": 0.2121001390820584, "CIDEr": 1.9699104659171308e-07, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.23529411764705882, "f": 0.16666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is of a lunch box with a variety of food inside, including meth, broccoli, and noodles. The lunch box is red. There is no sushi or rice in the image. There are vegetables in the lunch box. There is no lid in the image."}, "114745": {"image_id": 114745, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.10583300875240854, "Bleu_4": 1.356590733316526e-05, "METEOR": 0.2700480430961708, "ROUGE_L": 0.3259541984732824, "CIDEr": 7.3449809271765606e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man riding a skateboard down a ramp. The ramp is surrounded by a fence. The man is wearing a red shirt and is balancing on the skateboard. The man's arms are not outstretched."}, "548878": {"image_id": 548878, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.12521758066643465, "Bleu_3": 7.318524682825048e-07, "Bleu_4": 1.7805390573409366e-09, "METEOR": 0.16167113205672787, "ROUGE_L": 0.21631205673758863, "CIDEr": 6.96372168540181e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13333333333333333, "f": 0.14814814814814814, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person wearing a snowboarding helmet and goggles jumping off a snowboard ramp. The person is wearing a black and red snowboarding suit. The person is jumping off a ramp. The background is a city skyline with tall buildings."}, "385985": {"image_id": 385985, "Bleu_1": 0.2105263157872576, "Bleu_2": 0.1252097903560739, "Bleu_3": 0.06959978124844443, "Bleu_4": 7.780525835368834e-06, "METEOR": 0.14314615832490232, "ROUGE_L": 0.18833619210977703, "CIDEr": 4.303507686179527e-36, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21052631578947367, "f": 0.2580645161290323, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows three people sitting on the ground. They are all looking at their cell phones. The person on the left is wearing black pants and a white shirt. The person on the right is wearing black pants and a black shirt. The person on the left is holding a cell phone, and the other person is looking at a cell phone. The person on the left is looking at a video game controller. The shirt of the person on the left is white. The shirt of the person on the right is white."}, "289714": {"image_id": 289714, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.15541746803663614, "Bleu_3": 0.10316340294864779, "Bleu_4": 0.0710848629767716, "METEOR": 0.1499747761451571, "ROUGE_L": 0.19614147909967844, "CIDEr": 9.650848626663743e-09, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.15625, "f": 0.16666666666666666, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image is of a kitchen with green and yellow walls. There is a stove in the corner of the room. A glass of wine is on the stove. There is a sink in the room. A yellow and red striped chair is in the room."}, "230226": {"image_id": 230226, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.06388765649870325, "Bleu_3": 4.397416072405079e-07, "Bleu_4": 1.1597748989748829e-09, "METEOR": 0.11422796809213447, "ROUGE_L": 0.15155279503105593, "CIDEr": 2.2388699245021646e-11, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.26666666666666666, "f": 0.18181818181818182, "fn": 11.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a clear plastic container with a handle on top. Brushes are next to the container. The container is sitting on top of a white toilet. There is a toilet paper holder next to the toilet. There is a sink and a towel rack next to the sink."}, "319534": {"image_id": 319534, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.1412673303879691, "Bleu_3": 0.0731427188861825, "Bleu_4": 9.405585246221825e-06, "METEOR": 0.22704020497090904, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.3751757642788952e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.13793103448275862, "f": 0.18604651162790697, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a woman standing in front of a bus with other people on board. The bus is white and green. The woman is wearing a white shirt and has her hands on her hips. The woman's hands are on the window. She is swaying back and forth with her hips."}, "427476": {"image_id": 427476, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.27439773622258, "Bleu_3": 0.22074337048067055, "Bleu_4": 0.17302961463690114, "METEOR": 0.2859988496671015, "ROUGE_L": 0.314974182444062, "CIDEr": 6.733484185522695e-10, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.043478260869565216, "f": 0.043478260869565216, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a young girl standing in a bathroom with a toilet and sink. The walls are painted white. There are two windows in the background. The floor is made of wood. The girl is wearing a white shirt and jeans. She has her hair tied up in a hat."}, "101223": {"image_id": 101223, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.32566947362944193, "Bleu_3": 0.2173224313183697, "Bleu_4": 0.1360028792323118, "METEOR": 0.3171980760584427, "ROUGE_L": 0.4245939675174013, "CIDEr": 0.002220448940222227, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.2, "f": 0.14814814814814817, "fn": 16.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a view of the mountains from an airplane window. The mountains are not covered in snow. There are no clouds in the sky. There is no runway in the scene."}, "123570": {"image_id": 123570, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.1880253582691385, "Bleu_3": 0.12601611262969112, "Bleu_4": 0.07876236038722048, "METEOR": 0.24919572226997985, "ROUGE_L": 0.2363032650802435, "CIDEr": 2.5732675323022615e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14814814814814814, "f": 0.16326530612244897, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman standing on the sidewalk in front of a store at night. She is holding an umbrella over her head. The woman is looking down at the ground. The store has a large window, but there is no sign on it. The woman is wearing a black coat and black boots."}, "368581": {"image_id": 368581, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.20643070595483948, "Bleu_3": 0.14008951523375043, "Bleu_4": 1.7398984878177722e-05, "METEOR": 0.17154633719460996, "ROUGE_L": 0.29864316687648623, "CIDEr": 0.007907480543038943, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a lunchbox with a sandwich, fruit, and vegetables inside. The sandwich is made of bread. The background of the lunchbox is green. There are no other objects in the image."}, "446984": {"image_id": 446984, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2660221937781222, "Bleu_3": 0.19885251001833604, "Bleu_4": 0.13749681484639564, "METEOR": 0.30234229831103143, "ROUGE_L": 0.35765472312703583, "CIDEr": 1.3357699723338906e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of nine people on bicycles. They are wearing yellow vests and helmets. They are standing in front of a large, yellow bike. They are all smiling and looking at a giant pair of scissors. There is a person sitting on a bike."}, "514668": {"image_id": 514668, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.17807996398101744, "Bleu_3": 0.13133103318069508, "Bleu_4": 0.10252671801486268, "METEOR": 0.2379893923626486, "ROUGE_L": 0.3342465753424657, "CIDEr": 1.2828510977292782e-07, "SPICE": {"All": {"pr": 0.24242424242424243, "re": 0.25, "f": 0.24615384615384617, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 8.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.08333333333333333, "f": 0.07692307692307691, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5384615384615384, "f": 0.5185185185185186, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The image shows two cats sitting in the car. One cat is staring at the sun and wearing a red collar, while the other cat is looking out the window at the mountains. The car is not parked on the side of the road."}, "532129": {"image_id": 532129, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.2718301411002404, "Bleu_3": 0.2017363863769417, "Bleu_4": 0.1333045094068889, "METEOR": 0.23391905598532517, "ROUGE_L": 0.3489037178265014, "CIDEr": 0.006654066167804734, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13333333333333333, "f": 0.1379310344827586, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a pizza on a plate with cheese on top. A glass of water is also on the table next to the pizza. The plate is silver."}, "200168": {"image_id": 200168, "Bleu_1": 0.19999999999500007, "Bleu_2": 0.12403473458606787, "Bleu_3": 7.397773249928141e-07, "Bleu_4": 1.8187597339048352e-09, "METEOR": 0.15297120762259392, "ROUGE_L": 0.23680124223602486, "CIDEr": 5.201279396271159e-06, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.32, "f": 0.29629629629629634, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a person doing skiing on a snowy slope. The person is wearing a helmet and goggles, and is skiing down the slope. The trees in the background are covered in snow. The sky is clear and blue."}, "470801": {"image_id": 470801, "Bleu_1": 0.222222222217284, "Bleu_2": 0.1421338109005459, "Bleu_3": 0.07773956660946078, "Bleu_4": 1.028417039620613e-05, "METEOR": 0.16090571179887173, "ROUGE_L": 0.28073635765943455, "CIDEr": 1.7817701393986587e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.2857142857142857, "f": 0.2926829268292683, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a woman holding two kites. One of the kites has a red and white striped tail and a blue and white striped body. The woman is standing in front of a blue sky with no clouds. She is wearing a black shirt."}, "138713": {"image_id": 138713, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.07269451760681338, "Bleu_4": 9.458362067955946e-06, "METEOR": 0.17612975074100776, "ROUGE_L": 0.18654434250764526, "CIDEr": 3.85731134925581e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2, "f": 0.23076923076923075, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.06666666666666667, "f": 0.08, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of four people playing frisbee. They are all wearing purple shirts and white shorts. One person is throwing the frisbee while the others are running to catch it. The sky is blue and there are trees in the background.\n\nThere is no park in the scene."}, "195917": {"image_id": 195917, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.17817416126992966, "Bleu_3": 0.09773951426230146, "Bleu_4": 1.2969527289736299e-05, "METEOR": 0.28932762908511767, "ROUGE_L": 0.33888888888888885, "CIDEr": 0.00017447559357411792, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10526315789473684, "f": 0.12121212121212122, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a man wearing a black shirt standing in front of a window. A tree can be seen outside the window. The man is holding a toothbrush and appears to be brushing his teeth."}, "145391": {"image_id": 145391, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2640100002346085, "Bleu_3": 0.17975728622846687, "Bleu_4": 0.11350052389324858, "METEOR": 0.21312140515385408, "ROUGE_L": 0.3172362555720654, "CIDEr": 0.011750702956332957, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.0967741935483871, "f": 0.11538461538461538, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a roll of tape with a pair of scissors on top of it. The tape is wrapped around the roll of tape and has a label that says \"scotch tape\". The scissors are not open."}, "459303": {"image_id": 459303, "Bleu_1": 0.1641791044751615, "Bleu_2": 0.0863868425568369, "Bleu_3": 4.860272450059243e-07, "Bleu_4": 1.1573120305459365e-09, "METEOR": 0.13623494548434692, "ROUGE_L": 0.17985257985257982, "CIDEr": 2.310257715937222e-19, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.04, "f": 0.05128205128205128, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a train traveling down the tracks. The train is black and yellow and has a number on the side. \n\nThere are five people standing on the train platform. Some of the people are taking a selfie, some are watching a man in a black jacket, and one person is holding a bag. \n\nThe sky is not clear. There are no trees in the scene."}, "497334": {"image_id": 497334, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.25440640194528097, "Bleu_3": 1.2159559913078582e-06, "Bleu_4": 2.677141840521775e-09, "METEOR": 0.26695440531934334, "ROUGE_L": 0.3531114327062228, "CIDEr": 3.4580501311001775e-05, "SPICE": {"All": {"pr": 0.1875, "re": 0.08108108108108109, "f": 0.11320754716981132, "fn": 34.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a bed with a book on it. The book has a red cover with white and black patterns on it. The bed is made with a white sheet. There is a pillow on the bed."}, "173138": {"image_id": 173138, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.17720317768650332, "Bleu_3": 0.08936417387415972, "Bleu_4": 1.1350251107826057e-05, "METEOR": 0.19165636765589517, "ROUGE_L": 0.28968792401628224, "CIDEr": 1.0223428341615668e-08, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.28125, "f": 0.3333333333333333, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7777777777777778, "re": 0.5384615384615384, "f": 0.6363636363636364, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}}, "caption": "The image shows a person standing on the beach, looking out at the ocean. The person is wearing a black wetsuit and holding a surfboard. The person is surfing and looking at a wave. The beach is sandy and there are no rocks in the water."}, "404984": {"image_id": 404984, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.21821789022984422, "Bleu_3": 0.14096477244685904, "Bleu_4": 0.09598524129527268, "METEOR": 0.1953993814761851, "ROUGE_L": 0.32947530864197533, "CIDEr": 6.832743782336835e-05, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.3181818181818182, "f": 0.2916666666666667, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a living room with two couches, a television, and a rug. The walls are light brown. The floor is made of wood. There are two windows on the left side of the room."}, "427965": {"image_id": 427965, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.14748360054137324, "Bleu_3": 0.10400644242125906, "Bleu_4": 0.0666540383687628, "METEOR": 0.2293740016520144, "ROUGE_L": 0.22521097046413502, "CIDEr": 7.948927476033154e-16, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a living room with two couches, a chair, and a television on the wall. There is a window without curtains. The room is decorated with a lamp, a vase, and a bookshelf. \n\nThere is no coffee table or wall in the scene. \n\nThere is a rug on the floor. \n\nThere is a dog in the living room."}, "445834": {"image_id": 445834, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1371021242743437, "Bleu_3": 0.06991578304852385, "Bleu_4": 8.919345345892188e-06, "METEOR": 0.1934220855302955, "ROUGE_L": 0.23682750970604544, "CIDEr": 7.845414116654396e-14, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2, "f": 0.17857142857142855, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of four people standing in front of a bus. They are all wearing blue uniforms. The people are talking to each other. \n\nThe bus is parked in front of a building. There is a large window on the side of the building. A sign is also on the side of the building."}, "386958": {"image_id": 386958, "Bleu_1": 0.1403508771905202, "Bleu_2": 0.07079923253922572, "Bleu_3": 4.5001964233160024e-07, "Bleu_4": 1.1397908406297794e-09, "METEOR": 0.21501939202144565, "ROUGE_L": 0.20178630499503802, "CIDEr": 1.2505978131991771e-12, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.11538461538461539, "f": 0.10909090909090909, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a fire hydrant on the side of a road. The hydrant is made of metal and has a rusty metal cap on top. Gravel and dirt surround the fire hydrant. The hydrant is seen from a low angle, looking down from a car. There is a yellow line on the side of the hydrant."}, "306135": {"image_id": 306135, "Bleu_1": 0.2463768115906322, "Bleu_2": 0.14744195615274458, "Bleu_3": 0.06871567050137709, "Bleu_4": 8.373477496690829e-06, "METEOR": 0.17016340777354283, "ROUGE_L": 0.2284185891006352, "CIDEr": 3.890214293825515e-20, "SPICE": {"All": {"pr": 0.09375, "re": 0.09375, "f": 0.09375, "fn": 29.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man riding a skateboard. He is walking down a set of stairs in front of a building with columns and arches. The man is wearing a red shirt and blue pants. He does not have a backpack on his back. \n\nThere are people walking on the sidewalk in front of the building. \n\nThere is a statue of John Edward Mckinley in front of the building."}, "335839": {"image_id": 335839, "Bleu_1": 0.404255319140335, "Bleu_2": 0.3247428357002883, "Bleu_3": 0.21085094168690133, "Bleu_4": 2.1484165518058135e-05, "METEOR": 0.345223385924396, "ROUGE_L": 0.30367143746110764, "CIDEr": 2.7045589732344185e-07, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.07692307692307693, "f": 0.07407407407407408, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a man standing on the sidewalk in front of a brick building with graffiti on the walls. The man is wearing a black and red jacket, black pants, and a purple hat. There is a fire hydrant on the sidewalk next to the man."}, "190313": {"image_id": 190313, "Bleu_1": 0.24999999999652778, "Bleu_2": 0.19680547341248847, "Bleu_3": 0.14917951303445823, "Bleu_4": 0.10960993743594462, "METEOR": 0.2561024184293327, "ROUGE_L": 0.22975517890772126, "CIDEr": 1.2927506814096215e-21, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows three women sitting on a bench outside a store. \n\nThe first woman is sitting on the bench, holding a bag. She is wearing black pants and a black shirt. \n\nThe second woman is talking on the phone, holding a cell phone. \n\nThe third woman is drinking a drink, holding a cup of coffee. \n\nThe store has a large window with a sign that reads \"a woman in a wheelchair\"."}, "85328": {"image_id": 85328, "Bleu_1": 0.13186813186668278, "Bleu_2": 0.07655590023424934, "Bleu_3": 4.0382119502052855e-07, "Bleu_4": 9.300818387435611e-10, "METEOR": 0.12418895067177362, "ROUGE_L": 0.12069647803719825, "CIDEr": 2.4617573155633437e-40, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a train on the tracks. People are boarding the train on the platform. The train is green and yellow. The train is not moving slowly. The train has black wheels. The train has a white roof.\n\nThere are buildings in the background. People are walking on the sidewalk. People are riding a skateboard. People are riding skateboards. People are gathered together. People are walking down the street. A man is putting on a hat.\n\nThe train's doors are not open.\n\nOverall, a train is on the tracks."}, "104002": {"image_id": 104002, "Bleu_1": 0.34615384614053263, "Bleu_2": 0.2631174057817865, "Bleu_3": 0.1423516936043401, "Bleu_4": 1.8818717370172825e-05, "METEOR": 0.28139724286034834, "ROUGE_L": 0.36761751707513063, "CIDEr": 0.01404769720940752, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.07692307692307693, "f": 0.08, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of nine cows standing in a field. The cows are grazing in the field. There is a fence in the background."}, "37389": {"image_id": 37389, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.15097578581028312, "Bleu_3": 0.10625604957093672, "Bleu_4": 0.0680327838576014, "METEOR": 0.23300959123040266, "ROUGE_L": 0.23735408560311286, "CIDEr": 1.0110134789639395e-15, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is of a clock tower in the middle of a city. The clock tower is made of stone and brick. There is a clock face on the front of the clock tower, with numbers and hands. The clock is ticking away. \n\nThere are buildings around the clock tower. There are no people or sidewalk in the scene."}, "383594": {"image_id": 383594, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.15404159684489246, "Bleu_3": 0.07423624735269675, "Bleu_4": 9.20435358425019e-06, "METEOR": 0.2084362948187783, "ROUGE_L": 0.2764350453172206, "CIDEr": 8.987293880168346e-14, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows three plates on a table with a red and white checkered tablecloth. On the first plate, there is a sandwich and pickles. On the second plate, there is a burger and fries. On the third plate, there is the mystery of the St. John's burger 1. There is also a jar of pickles on the side."}, "319696": {"image_id": 319696, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.33282011772208075, "Bleu_3": 0.20977124924927762, "Bleu_4": 2.5169669586788924e-05, "METEOR": 0.3393127021249914, "ROUGE_L": 0.4552238805970149, "CIDEr": 0.017173023516187273, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.28, "f": 0.27450980392156865, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a red microwave oven sitting on a countertop in a kitchen. The countertop is made of stone. A glass is on the counter."}, "318911": {"image_id": 318911, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.15891043153801604, "Bleu_3": 0.07810454645155356, "Bleu_4": 9.783773730343155e-06, "METEOR": 0.24758576534898757, "ROUGE_L": 0.27555053642010163, "CIDEr": 9.32644391474603e-13, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.3888888888888889, "f": 0.3111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.8333333333333334, "f": 0.45454545454545453, "fn": 1.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a flock of twelve sheep grazing in a green field. The sheep are of different colors, including white, black, and brown. Some of the sheep are standing behind a fence, while others are eating grass or laying down. Some of the sheep are looking at each other, and some are huddled together."}, "455506": {"image_id": 455506, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.22976150005156148, "Bleu_3": 0.17412114136874438, "Bleu_4": 0.12115660853589846, "METEOR": 0.29730776765873823, "ROUGE_L": 0.330722891566265, "CIDEr": 5.85855459082682e-11, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2916666666666667, "f": 0.30434782608695654, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a dog playing with a frisbee. The dog is running with the frisbee in its mouth. The dog is wearing a collar. The dog is standing on grass with its front paws on the ground and its back paws in the air. The dog is looking at the frisbee."}, "444631": {"image_id": 444631, "Bleu_1": 0.13157894736668976, "Bleu_2": 0.07254762501004024, "Bleu_3": 0.04143222213380237, "Bleu_4": 5.586926459461732e-06, "METEOR": 0.16778337979274285, "ROUGE_L": 0.13714028776978418, "CIDEr": 3.8390676424595855e-28, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.1724137931034483, "f": 0.17857142857142858, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two people standing on the beach. Person 1 is holding a surfboard and wearing a black wetsuit. Person 2 is holding a sled. The person is wearing a white shirt and a black jacket. The person is smoking in the smoky city of Brooklyn 0.\n\nThe beach is sandy and there are rocks scattered around. There is no driftwood in the scene. The sky is cloudy and there are waves in the distance.\n\n"}, "497014": {"image_id": 497014, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.18216065373578985, "Bleu_3": 0.10989798119082404, "Bleu_4": 1.2829013611550496e-05, "METEOR": 0.2105818435932357, "ROUGE_L": 0.23669623059866962, "CIDEr": 6.893626613193736e-10, "SPICE": {"All": {"pr": 0.09375, "re": 0.14285714285714285, "f": 0.11320754716981132, "fn": 18.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image features a dog standing on the grass in front of a metal fence. The dog is catching a frisbee. The dog has a blue frisbee hanging out of its mouth. The dog is wearing a collar and tag on its neck.\n\nThere are no trees or gates in the scene."}, "502749": {"image_id": 502749, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.21764287502183505, "Bleu_3": 0.13806135595106658, "Bleu_4": 1.983544145310677e-05, "METEOR": 0.194331983805668, "ROUGE_L": 0.37014563106796117, "CIDEr": 0.08951649231879802, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a kitchen with white cabinets and gray countertops. There are red and white wreaths hanging from the ceiling."}, "230593": {"image_id": 230593, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.17739371879401636, "Bleu_3": 0.14342204728356284, "Bleu_4": 0.09837489905425255, "METEOR": 0.20440713561153998, "ROUGE_L": 0.18208955223880596, "CIDEr": 1.4765280989808493e-19, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.34615384615384615, "f": 0.36734693877551017, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a group of geese walking on a path in a park. The geese are brown and white. The geese are walking on the sidewalk. The geese have black and white heads and necks. There is no line or beak in the scene. There is no tree in the scene. There is a bench in the distance. There is no fountain in the scene."}, "364636": {"image_id": 364636, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.09589266029382536, "Bleu_3": 6.899287365489461e-07, "Bleu_4": 1.867506984265124e-09, "METEOR": 0.12788632326820604, "ROUGE_L": 0.21981981981981977, "CIDEr": 0.0014656031547063534, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.28, "f": 0.27450980392156865, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a brown dog standing on the ground. The dog is walking. The dog's ears are perked up. The background includes a fence and a picnic table."}, "288313": {"image_id": 288313, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.3162277660039253, "Bleu_3": 0.20563674453180716, "Bleu_4": 0.14100024578167505, "METEOR": 0.3486878878921707, "ROUGE_L": 0.41733181299885974, "CIDEr": 0.02653771658465716, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.19047619047619047, "f": 0.21052631578947367, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a table set with a plate of food. The tablecloth is black. There is a glass of orange juice on the table."}, "384503": {"image_id": 384503, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.055743561356123544, "Bleu_3": 3.769818805157754e-07, "Bleu_4": 9.846267797162314e-10, "METEOR": 0.09470855558355064, "ROUGE_L": 0.13646532438478748, "CIDEr": 1.0377000751313617e-16, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.21052631578947367, "f": 0.15999999999999998, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a green train traveling down a track. The train does not have a yellow stripe on the side. There is a green bow on the front of the train. There are trees on either side of the track and a small stone building in the distance. The sky is cloudy.\n\nThere is no rain in the image."}, "190156": {"image_id": 190156, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.22760466886504876, "Bleu_3": 0.15115540850568024, "Bleu_4": 0.11193401922301613, "METEOR": 0.25218717747063785, "ROUGE_L": 0.26571250777846916, "CIDEr": 1.2348094772637677e-07, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.047619047619047616, "f": 0.05, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a black and white cat sitting on a table with a cup of coffee on it. The cat is not looking up at the camera. There is also a laptop on the desk. The background is a messy office with scattered papers and books."}, "174123": {"image_id": 174123, "Bleu_1": 0.3666666666605556, "Bleu_2": 0.24929278500044508, "Bleu_3": 0.17497948870763677, "Bleu_4": 0.11709251720607591, "METEOR": 0.26221258816918463, "ROUGE_L": 0.2553064275037369, "CIDEr": 1.0504896133534354e-11, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2413793103448276, "f": 0.27450980392156865, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows two people sitting at a table. One person is holding a cigarette and a pair of scissors in their hand, while the other person is holding a knife. \n\nOn the table, there is a pizza with cheese, tomato sauce, and various toppings including pepperoni, mushrooms, onions, and olives. \n\nThere is no tablecloth or napkin in the scene."}, "557239": {"image_id": 557239, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.29777500018082764, "Bleu_3": 0.14864064036690816, "Bleu_4": 1.885210451287141e-05, "METEOR": 0.36401947547775465, "ROUGE_L": 0.3871260199456029, "CIDEr": 0.008637436567821403, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a cat sitting in a white toilet bowl. The cat's eyes are green and its nose is orange. The cat is laying in the toilet."}, "184474": {"image_id": 184474, "Bleu_1": 0.13207547169562125, "Bleu_2": 0.08729111496323051, "Bleu_3": 0.053062776235949925, "Bleu_4": 7.3934982643400135e-06, "METEOR": 0.19745601079535782, "ROUGE_L": 0.15127092374457532, "CIDEr": 5.873582598933084e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.13793103448275862, "f": 0.17777777777777778, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a bench sitting on top of a hill. The bench is made of wood and does not have a backrest. It is located in a grassy area with no other objects nearby. The hill is surrounded by green grass and trees. The sky is blue with clouds in the distance."}, "335099": {"image_id": 335099, "Bleu_1": 0.24615384615005917, "Bleu_2": 0.08770580192934307, "Bleu_3": 4.961032050004957e-07, "Bleu_4": 1.1846255688500039e-09, "METEOR": 0.1558974358974359, "ROUGE_L": 0.21128154379020286, "CIDEr": 7.038385029389497e-15, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.21052631578947367, "f": 0.1702127659574468, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two dogs sitting on a fence. One dog is looking at the window and wearing a collar, while the other dog is looking at itself in the mirror and wearing a hat. The fence is made of iron and the gate is not open. There is a building in the background. The sky is cloudy and there are trees in the foreground."}, "431306": {"image_id": 431306, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.18677184190511298, "Bleu_3": 0.14921454814781854, "Bleu_4": 0.12486557620089443, "METEOR": 0.2629601790507407, "ROUGE_L": 0.2636887608069164, "CIDEr": 3.59756213747914e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.23529411764705882, "f": 0.23529411764705882, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image is of a bathroom with four sinks and two mirrors on the wall. The mirrors are made of glass and have white frames. The sinks are made of white porcelain and have faucets on them. The floor is made of white tiles."}, "125815": {"image_id": 125815, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.2545139051836993, "Bleu_3": 0.17382577992832773, "Bleu_4": 1.954384523264165e-05, "METEOR": 0.23178724583378418, "ROUGE_L": 0.3590875643855777, "CIDEr": 0.00010061434445666898, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a train on the tracks at a train station. The train is red. It is pulling into the station. There are people standing on a platform. There is a car parked nearby.\n\nThe sky is blue."}, "521106": {"image_id": 521106, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.20084043275925678, "Bleu_3": 0.12059375557298453, "Bleu_4": 1.4050458184787668e-05, "METEOR": 0.2168172313603854, "ROUGE_L": 0.23461538461538461, "CIDEr": 1.2991392457267087e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10526315789473684, "f": 0.12903225806451615, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a tennis player hitting a ball with a racket on a tennis court. The player is wearing a yellow shirt and black shorts. The player is about to hit the ball in the net. The player is running towards the ball. The sky is blue."}, "508672": {"image_id": 508672, "Bleu_1": 0.4666666666355556, "Bleu_2": 0.44721359546907896, "Bleu_3": 0.4252903702525085, "Bleu_4": 0.4001601601624029, "METEOR": 0.4395803347849714, "ROUGE_L": 0.6440422322775264, "CIDEr": 0.9613508694443473, "SPICE": {"All": {"pr": 0.375, "re": 0.3157894736842105, "f": 0.34285714285714286, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.8, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a bicycle parked next to a flooded road. The bicycle is red."}, "221737": {"image_id": 221737, "Bleu_1": 0.15094339622356714, "Bleu_2": 0.12047318414543882, "Bleu_3": 0.0828730900622893, "Bleu_4": 0.05808548879280544, "METEOR": 0.17648686051393592, "ROUGE_L": 0.2334609075997813, "CIDEr": 1.1880152171055286e-10, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.30434782608695654, "f": 0.28571428571428575, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a road with a sign on it that says \"a bridge over the river tay\". There is a bridge over the road. A sign is on the bridge. The sign says \"a road sign\". The road is lined with two trees and there are no cars or people in sight."}, "345580": {"image_id": 345580, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.21302148074284213, "Bleu_3": 0.190152024801609, "Bleu_4": 0.1593376966491881, "METEOR": 0.2752743482470477, "ROUGE_L": 0.305254378648874, "CIDEr": 0.0002201731100268618, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.058823529411764705, "f": 0.08333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image shows a zebra standing in a field with a fence in the background. The zebra is black and white. It has a long mane and tail. The zebra is standing in the dirt."}, "46440": {"image_id": 46440, "Bleu_1": 0.19354838709053074, "Bleu_2": 0.16064386577523138, "Bleu_3": 0.12118627329025787, "Bleu_4": 0.0892895357439945, "METEOR": 0.22697778266309085, "ROUGE_L": 0.22202001819836215, "CIDEr": 0.0014446480371397138, "SPICE": {"All": {"pr": 0.15, "re": 0.2, "f": 0.17142857142857143, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three men playing basketball in a gym. They are wearing blue jerseys and black and orange jerseys. They are also wearing white shorts. The men are playing basketball."}, "270066": {"image_id": 270066, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.15115540850568024, "Bleu_4": 0.11193401922301613, "METEOR": 0.26772844284232955, "ROUGE_L": 0.2848565710473649, "CIDEr": 2.0498059757087122e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a white motorcycle parked in front of a building with a green roof. The motorcycle has a black seat and a black handlebar. The building has a green roof and a white wall. There is a sign on the wall that reads, \"Bicyclists Ireland\"."}, "419867": {"image_id": 419867, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.19462473603439093, "Bleu_3": 0.10690830888031075, "Bleu_4": 1.420621166464532e-05, "METEOR": 0.24955728777559832, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.00032466336720519853, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.30434782608695654, "f": 0.25925925925925924, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a grocery store with bananas stocked on the shelves. The store is filled with various products, including bananas, cereal, and milk. \n\nThere are two people shopping in the grocery store."}, "194724": {"image_id": 194724, "Bleu_1": 0.2173913043446755, "Bleu_2": 0.0979325933415155, "Bleu_3": 0.052311025728262815, "Bleu_4": 6.824313083275742e-06, "METEOR": 0.12902584677418438, "ROUGE_L": 0.19156572454015255, "CIDEr": 1.3944936614312853e-17, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a table with two pizzas on it. One of the pizzas has olives, onions, peppers, mushrooms, olives, pepperoni, and sausage as toppings, while the other pizza has olives, mushrooms, onions, and peppers as toppings. There are also two glasses of soda on the table. One glass contains a squirt of cola, while the other glass contains cola.\n\nThe background of the image is a red and"}, "236426": {"image_id": 236426, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.27327631272580527, "Bleu_3": 0.16068567361899208, "Bleu_4": 1.855520928853527e-05, "METEOR": 0.2412352056653395, "ROUGE_L": 0.3155483298847177, "CIDEr": 6.802943245482737e-05, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a tennis player in action on a court. The player is wearing a white shirt and white shorts, and is holding a tennis racket. The player is using his left hand to hit the ball."}, "499826": {"image_id": 499826, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2526455763146363, "Bleu_3": 0.1907268589329514, "Bleu_4": 0.11143093224787655, "METEOR": 0.2443205307393732, "ROUGE_L": 0.3191330343796711, "CIDEr": 9.489443912132826e-07, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.1111111111111111, "f": 0.11428571428571428, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a woman standing on the sidewalk next to a group of elephants. The woman is wearing a pink shirt and jeans. The woman does not have a camera around her neck. The elephants are walking down the street. The trunks are swaying back and forth."}, "514904": {"image_id": 514904, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.18405922400671818, "Bleu_3": 0.13425456010359604, "Bleu_4": 0.0968531189851532, "METEOR": 0.24163986079776373, "ROUGE_L": 0.2335886214442013, "CIDEr": 1.8363736705226427e-14, "SPICE": {"All": {"pr": 0.125, "re": 0.15789473684210525, "f": 0.13953488372093023, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a woman holding a hot dog in her hand. She is wearing a brown sweater. The woman's shirt is brown. She is wearing black sunglasses on her face.\n\nShe is standing on the sidewalk in front of a building.\n\nThere is no awning in the scene.\n\nThere is a bicycle parked on the sidewalk."}, "359864": {"image_id": 359864, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.245934688411173, "Bleu_3": 0.18219922530638885, "Bleu_4": 2.13702889855126e-05, "METEOR": 0.2983610198365396, "ROUGE_L": 0.4080267558528428, "CIDEr": 0.0013936775348466334, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a man wearing a red shirt and sunglasses standing on a boat. The man is looking at the boat and appears to be steering it. The boat is white."}, "247333": {"image_id": 247333, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.24152294576370853, "Bleu_3": 0.19725789782932507, "Bleu_4": 0.15794492758974024, "METEOR": 0.26672746636034156, "ROUGE_L": 0.3650265957446809, "CIDEr": 2.6273538039996993e-05, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a plate of food on a table. There is a bottle of ketchup on the side of the table. \n\nOn the plate, there is a slice of ham, a slice of cheese, and three slices of tomato."}, "54277": {"image_id": 54277, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1373143068093302, "Bleu_3": 0.07085740383081722, "Bleu_4": 9.094693994314411e-06, "METEOR": 0.20451788802530382, "ROUGE_L": 0.24110671936758893, "CIDEr": 2.938350158200801e-12, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.23529411764705882, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person snowboarding in a large indoor skiing area. The person is wearing a blue jacket and blue pants, and has a helmet on their head. There are several other people in the background, also on snowboards. The walls of the building are made of concrete. The person is in the snow."}, "80172": {"image_id": 80172, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.36890203261675947, "Bleu_3": 0.28306767771581115, "Bleu_4": 0.2365011243903772, "METEOR": 0.32043170514330677, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.004272687326041976, "SPICE": {"All": {"pr": 0.25, "re": 0.06896551724137931, "f": 0.1081081081081081, "fn": 27.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a boy brushing his teeth with a toothbrush while sitting on the toilet. The boy is wearing a blue shirt. The toilet has a toilet seat cover on it."}, "376959": {"image_id": 376959, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.3478041718090821, "Bleu_3": 0.2892232419191526, "Bleu_4": 0.22366895391201558, "METEOR": 0.3132820504280915, "ROUGE_L": 0.43296529968454256, "CIDEr": 0.007808101709431229, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.20689655172413793, "f": 0.21052631578947367, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a girl sitting at a table with a pencil and paper in front of her. The girl is wearing a green dress. There is a window in the background."}, "47055": {"image_id": 47055, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.17720317768650332, "Bleu_3": 0.08936417387415972, "Bleu_4": 1.1350251107826057e-05, "METEOR": 0.16566992036874975, "ROUGE_L": 0.2447178389943835, "CIDEr": 6.529908604693394e-07, "SPICE": {"All": {"pr": 0.125, "re": 0.13333333333333333, "f": 0.12903225806451615, "fn": 26.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a bedroom with a bed, nightstand, and lamp. The walls are gray. The floor is made of wood. There are blinds on one side of the room. A white vase with a flower is on the nightstand. A mattress is on the bed."}, "154816": {"image_id": 154816, "Bleu_1": 0.16883116882897622, "Bleu_2": 0.09426479189433258, "Bleu_3": 0.049114823488072175, "Bleu_4": 6.3255968680318e-06, "METEOR": 0.18086477497667924, "ROUGE_L": 0.2039281236941078, "CIDEr": 2.7788917075928134e-26, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows two baseball players in the process of playing baseball. One player is swinging a bat, while the other player is preparing to throw the ball. The players are wearing uniforms, with one wearing a red and white uniform and the other wearing a blue uniform. Both players are wearing helmets, with one wearing a black helmet and the other wearing a red helmet. The player wearing the red helmet is also wearing black gloves."}, "155179": {"image_id": 155179, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.07293249574741174, "Bleu_3": 4.871859700370513e-07, "Bleu_4": 1.2660998324356512e-09, "METEOR": 0.10455429397790354, "ROUGE_L": 0.23036253776435048, "CIDEr": 2.833781729519879e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.10256410256410256, "f": 0.11594202898550725, "fn": 35.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.1875, "f": 0.20689655172413793, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a round loaf of bread with a hole in the middle. The bread is made of white flour. It has a golden brown crust. There are no visible toppings or fillings on the bread. The image is taken from a white background with good lighting."}, "328374": {"image_id": 328374, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.14082179293641955, "Bleu_3": 0.08711096565049779, "Bleu_4": 1.0288252588030562e-05, "METEOR": 0.16604723081397618, "ROUGE_L": 0.19912948857453752, "CIDEr": 2.763828558427959e-15, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.36363636363636365, "f": 0.32653061224489793, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of ten people doing various activities in the snow. Some of them are skiing, some are sledding, and others are riding a skateboard. Some people are preparing to ski, while others are playing in the snow. Some are riding on a sled, while others are riding down a snowy hill. There is no snowman in the scene."}, "264919": {"image_id": 264919, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.1442707907155283, "Bleu_3": 7.733595213406049e-07, "Bleu_4": 1.8006234777217801e-09, "METEOR": 0.19460244956020536, "ROUGE_L": 0.23297262889879056, "CIDEr": 5.965261437092537e-07, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a man wearing a shirt. He is holding a cell phone and looking at it. The balloons are tied to a man wearing a shirt with balloons on his head. There are two poles in the scene. \n\nThere are four people in the background."}, "48185": {"image_id": 48185, "Bleu_1": 0.2758620689560048, "Bleu_2": 0.19851666678721847, "Bleu_3": 0.113434038700165, "Bleu_4": 1.539267887805166e-05, "METEOR": 0.19799778736676704, "ROUGE_L": 0.3489037178265014, "CIDEr": 0.0027606408922972656, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14285714285714285, "f": 0.16, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a bathroom with four mirrors, two sinks, and a floor made of tile. The bathroom has a large window with curtains, providing a view of the outdoors."}, "43376": {"image_id": 43376, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.20498001541675429, "Bleu_3": 0.13655670620412985, "Bleu_4": 1.679566795121378e-05, "METEOR": 0.2153752063108099, "ROUGE_L": 0.32972972972972975, "CIDEr": 0.0001642292310909075, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.20689655172413793, "f": 0.24000000000000002, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a giraffe standing on a fence in a zoo. The giraffe is looking in the trees. The giraffe is not wearing a harness. There is no ground or bush in the scene."}, "204994": {"image_id": 204994, "Bleu_1": 0.14545454545190087, "Bleu_2": 0.05189992960981586, "Bleu_3": 3.704127177650188e-07, "Bleu_4": 9.942911665844388e-10, "METEOR": 0.13574650643617497, "ROUGE_L": 0.14672279013830425, "CIDEr": 1.9306253482830468e-13, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man standing on a wooden bench next to two giraffes. The man is wearing a blue shirt and does not have a beard. The giraffes are standing on the ground. One of the giraffes has a hump on its back and a long neck. There are no spots on the giraffes."}, "309264": {"image_id": 309264, "Bleu_1": 0.1904761904716554, "Bleu_2": 0.06815981765745711, "Bleu_3": 4.879016455216701e-07, "Bleu_4": 1.3136602547196461e-09, "METEOR": 0.13991598229576727, "ROUGE_L": 0.1701534170153417, "CIDEr": 5.912244975384241e-07, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2727272727272727, "f": 0.23529411764705882, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a large, open space with three birds in cages. The pigeons of San Francisco's San Francisco Zoo are in the cages. The spooky story of the San Francisco Zoo is also in the cages. The walls are white."}, "356028": {"image_id": 356028, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.1769023808359136, "Bleu_3": 0.09543806343349583, "Bleu_4": 1.2553771013542623e-05, "METEOR": 0.21108406469403532, "ROUGE_L": 0.2793893129770992, "CIDEr": 2.3368948223979168e-05, "SPICE": {"All": {"pr": 0.15625, "re": 0.21739130434782608, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a room with six beds in it. The walls are made of wood. There are windows on one side of the room. The floor is made of wood. There are no chairs in the room."}, "544794": {"image_id": 544794, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.16087993330478273, "Bleu_3": 0.11658508041316994, "Bleu_4": 1.3479442271323005e-05, "METEOR": 0.2225295194568932, "ROUGE_L": 0.2501464557703574, "CIDEr": 8.371119194889676e-10, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.12, "f": 0.10169491525423728, "fn": 22.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows three plates with slices of pizza on them. One slice of pizza has mushrooms and sausage on it, while the other slice has mushrooms and onions on it. There are also two slices of pepperoni on the plates. The plates are on a table with a white tablecloth."}, "264619": {"image_id": 264619, "Bleu_1": 0.15384615384220912, "Bleu_2": 0.06362847629592486, "Bleu_3": 4.783000660880887e-07, "Bleu_4": 1.3203823351935062e-09, "METEOR": 0.0967520143622909, "ROUGE_L": 0.16769759450171823, "CIDEr": 1.7152241278042885e-05, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "There are no people in this image. There are two beaches in the image. There are no kitesurfers in the image. There is a wave in the image. There is no shore, surfer, rocks, or shells in the image."}, "322222": {"image_id": 322222, "Bleu_1": 0.3387096774138918, "Bleu_2": 0.2471412435971578, "Bleu_3": 0.1720163532744382, "Bleu_4": 0.09637497966338594, "METEOR": 0.25321026492119386, "ROUGE_L": 0.2929562433297759, "CIDEr": 3.961489186071501e-15, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.17857142857142858, "f": 0.18181818181818182, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two men playing tennis on a court. The first man is wearing a white shirt and white shorts, and he is holding a tennis racket. The second man is also holding a tennis racket. The woman in the background is also playing tennis. She is wearing a green shirt and blue shorts. \n\nTennis is being played on the court."}, "359791": {"image_id": 359791, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.11429089766174176, "Bleu_3": 0.06350643060633274, "Bleu_4": 8.460008059351496e-06, "METEOR": 0.14719226064005514, "ROUGE_L": 0.15127092374457532, "CIDEr": 6.101302979590623e-12, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.18181818181818182, "f": 0.20512820512820512, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on a boat. The boat is white and has a large open area on the top for people to stand on. There are several orange chairs lined up along the sides of the boat.\n\nThere is no body of water or water in the scene."}, "404635": {"image_id": 404635, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.15508644003992356, "Bleu_3": 0.08115433313646976, "Bleu_4": 1.0498339569158865e-05, "METEOR": 0.23675482780452423, "ROUGE_L": 0.34945894334818584, "CIDEr": 5.326614764513407e-07, "SPICE": {"All": {"pr": 0.375, "re": 0.20689655172413793, "f": 0.26666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.3333333333333333, "f": 0.43478260869565216, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a group of nine elephants standing in a green field. They are not facing the same direction. The elephants are of the wild. All the elephants do not have tusks. Any of the elephants do not have tusks.\n\nThe background is a blue sky.\n\n"}, "364343": {"image_id": 364343, "Bleu_1": 0.19512195121475318, "Bleu_2": 0.15617376188474938, "Bleu_3": 0.123336304131798, "Bleu_4": 0.09968499639428786, "METEOR": 0.22837112728082712, "ROUGE_L": 0.3083032490974729, "CIDEr": 1.0464600679616659e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.16, "f": 0.21621621621621623, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a plate with a crepe topped with fruit. The plate is placed on a tablecloth, which is red and white. There is no glass or juice in the image. There are no chairs or tables in the scene."}, "1573": {"image_id": 1573, "Bleu_1": 0.6249999999609376, "Bleu_2": 0.40824829043749705, "Bleu_3": 2.2833557018287965e-06, "Bleu_4": 5.501034141799257e-09, "METEOR": 0.2395363287458249, "ROUGE_L": 0.4212707182320442, "CIDEr": 0.39755392472943973, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is of a kitchen with a stove and a refrigerator. The walls are white."}, "174898": {"image_id": 174898, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.2544697557892895, "Bleu_3": 0.2257961883817142, "Bleu_4": 0.19904996166719055, "METEOR": 0.336292301824273, "ROUGE_L": 0.36624416277518346, "CIDEr": 2.0004770948443152e-08, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.14705882352941177, "f": 0.15384615384615385, "fn": 29.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3076923076923077, "f": 0.27586206896551724, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a black motorcycle parked on the side of a road in front of a row of trees. The motorcycle has a black seat and a black engine. The trees are bare and the sun is not visible in the image. The road is paved."}, "527580": {"image_id": 527580, "Bleu_1": 0.21333333333048887, "Bleu_2": 0.1315191898425204, "Bleu_3": 0.07796418233164683, "Bleu_4": 9.007167150773798e-06, "METEOR": 0.13903012169431217, "ROUGE_L": 0.2207478890229192, "CIDEr": 2.9884758869808667e-22, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.14285714285714285, "f": 0.1379310344827586, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.36363636363636365, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a train on the beach. There are people sitting on the sand and umbrellas set up. There is a building in the background, along with a palm tree and a mountain. The sky is cloudy with white clouds.\n\nThe train is an old-style train. People are reading, sitting on a bench, walking down the street, sitting on a bench, and playing music at a restaurant.\n\nThere is no seat in the scene."}, "522020": {"image_id": 522020, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.16903085094265752, "Bleu_3": 0.1383044222251921, "Bleu_4": 0.09995754509692037, "METEOR": 0.21246025704475005, "ROUGE_L": 0.21229698375870068, "CIDEr": 3.0871960619730833e-13, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a white cat sitting in the grass. The cat has a long tail. The cat is looking at the camera.\n\nIn the background, there is a house with a window on the left side and a door on the right side. The sky is blue and there are some clouds in the background."}, "142890": {"image_id": 142890, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.36115755924124826, "Bleu_3": 0.26511346924327256, "Bleu_4": 0.17470942956955962, "METEOR": 0.3280031459417711, "ROUGE_L": 0.4687156970362239, "CIDEr": 0.16148068866687781, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.21052631578947367, "f": 0.14035087719298245, "fn": 15.0, "numImages": 1.0, "fp": 34.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image features a black cat sitting on the keyboard of a computer. The cat is looking at the screen of the computer."}, "503238": {"image_id": 503238, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.23121228231834207, "Bleu_3": 0.1455615162588986, "Bleu_4": 0.08818452583937933, "METEOR": 0.2783544591796534, "ROUGE_L": 0.25507765830346474, "CIDEr": 2.1929779468370753e-11, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a bus driving down the street. The bus is orange and green. It is a city bus. The number 10 is on the front of the bus. The bus is stopped at a red light. There is a person not walking on the sidewalk. There are tall buildings in the background."}, "522430": {"image_id": 522430, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.13805054457255134, "Bleu_4": 1.5820356672588363e-05, "METEOR": 0.2160085731558387, "ROUGE_L": 0.24646464646464644, "CIDEr": 4.6093713402037194e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows three cows standing in a field. The cows are brown and white. Some of the cows are looking at each other, while others are looking at the camera.\n\nThe sun is setting in the background, casting a warm glow over the scene."}, "155897": {"image_id": 155897, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.13241452366608922, "Bleu_3": 0.08505022398980135, "Bleu_4": 0.05757177103686273, "METEOR": 0.2007724886409033, "ROUGE_L": 0.17300056721497448, "CIDEr": 6.291134166815287e-16, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.18181818181818182, "f": 0.24242424242424246, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a woman sitting on a bench. She is holding a sandwich in her hand. The sandwich is made of a toasted sandwich and a toasted sourdough bread with a slice of cheese. The woman is wearing a blue shirt and shorts, and has a green hat on her head.\n\nThere are five people in the background."}, "214494": {"image_id": 214494, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.1791244302026115, "Bleu_3": 0.10008904723903041, "Bleu_4": 1.3410639647907158e-05, "METEOR": 0.2332058589271297, "ROUGE_L": 0.3061224489795918, "CIDEr": 0.00016522147879371391, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.23076923076923078, "f": 0.2790697674418605, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a chocolate cake on a black plate. The knife is cutting into the cake. The hand is holding the knife. The background is dark and there are no other visible details."}, "223093": {"image_id": 223093, "Bleu_1": 0.24657534246237567, "Bleu_2": 0.1755617207917742, "Bleu_3": 0.13758914964323737, "Bleu_4": 0.09287976947396767, "METEOR": 0.2344578529212116, "ROUGE_L": 0.27027027027027023, "CIDEr": 9.119245750003573e-24, "SPICE": {"All": {"pr": 0.2, "re": 0.24, "f": 0.2181818181818182, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a building with a clock tower on top. The building has a clock on top. The clock tower has a clock on it and is surrounded by a brick wall. There are no trees or other towers in the scene.\n\nThe building appears to be old and has a lot of character. The clock tower is tall and imposing. The sky is blue and there are clouds in the background."}, "422706": {"image_id": 422706, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.11964664509646934, "Bleu_4": 0.07944348368460985, "METEOR": 0.19247412623524657, "ROUGE_L": 0.2887573964497041, "CIDEr": 4.705366481990578e-07, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}}, "caption": "The image shows two people standing on the deck of a cruise ship, looking out at the ocean. The people are wearing life jackets. The ship is equipped with safety equipment.\n\nThe image is taken from a distance and shows the ship's size and shape."}, "4011": {"image_id": 4011, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.15328483486852826, "Bleu_3": 0.09489031659247031, "Bleu_4": 1.1215483008811741e-05, "METEOR": 0.2601879525379661, "ROUGE_L": 0.3202099737532808, "CIDEr": 1.574163040510374e-11, "SPICE": {"All": {"pr": 0.15625, "re": 0.23809523809523808, "f": 0.18867924528301888, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features a woman wearing a black apron and holding a cake that appears to be a dog. The cake is made of white fondant and has a realistic dog face on it. The woman is smiling and appears to be proud of her creation. The background is a kitchen with white cabinets and a countertop."}, "188824": {"image_id": 188824, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.3533898220409052, "Bleu_3": 0.28105750237816374, "Bleu_4": 0.2345692236121739, "METEOR": 0.4027014559252755, "ROUGE_L": 0.4122706925305012, "CIDEr": 1.3334649245636657e-07, "SPICE": {"All": {"pr": 0.08, "re": 0.1111111111111111, "f": 0.09302325581395349, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on a couch next to a television. The cat is looking at a remote control. The couch is covered in a blanket. There is not a pillow on the couch. The television is on and shows a cartoon playing on it."}, "247206": {"image_id": 247206, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.3123475237694987, "Bleu_3": 0.21548837176462715, "Bleu_4": 2.265280468988654e-05, "METEOR": 0.28561691131231837, "ROUGE_L": 0.35234657039711187, "CIDEr": 3.1605891553290507e-06, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.5, "f": 0.3783783783783784, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is of a man lying on the floor with a cat on his chest. The cat is looking at a toy. The man is holding a tv remote. The background is a wall with a window in the background."}, "430047": {"image_id": 430047, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.22758963106159172, "Bleu_3": 0.15466509142797644, "Bleu_4": 1.7331983335639942e-05, "METEOR": 0.19265923097106571, "ROUGE_L": 0.26036585365853654, "CIDEr": 1.5356988204820845e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image is a room with a television on the wall. There is a couch against the wall. The room is well lit and has a window with curtains. There is a smudge on the window. A tv remote control is on the curtains."}, "244240": {"image_id": 244240, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.18312996850378505, "Bleu_3": 0.1198104621384325, "Bleu_4": 1.4585628855619904e-05, "METEOR": 0.18353745063617327, "ROUGE_L": 0.29897773421089485, "CIDEr": 8.186720824594467e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.0967741935483871, "f": 0.125, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a toilet in a bathroom. The toilet is white and has a seat and a lid. The sink is made of concrete and does not have a faucet. \n\nThere is no shower head or hose in the scene."}, "49810": {"image_id": 49810, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.12327121291697288, "Bleu_3": 0.06436001859611394, "Bleu_4": 8.306443472505375e-06, "METEOR": 0.2326214848408924, "ROUGE_L": 0.20344635908838243, "CIDEr": 2.5088048006859355e-14, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.4375, "f": 0.3684210526315789, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows two cats sitting on wooden decks. One cat is looking at its reflection in a mirror, while the other cat is looking at the cat in the mirror. The cat's reflection is in the mirror. The cats have white coats with orange patches on their ears. The background includes a building and a wooden deck."}, "85914": {"image_id": 85914, "Bleu_1": 0.5652173912797732, "Bleu_2": 0.32057261019905153, "Bleu_3": 0.21390511802337533, "Bleu_4": 0.14873335791141465, "METEOR": 0.2760148306064475, "ROUGE_L": 0.5021035302725444, "CIDEr": 0.26144155293915144, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.30434782608695654, "f": 0.3333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a plate of food with a variety of vegetables, including potatoes and broccoli. The plate is on a brown tablecloth."}, "442942": {"image_id": 442942, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.11764652669092619, "Bleu_4": 0.07713382612340196, "METEOR": 0.27446302153337915, "ROUGE_L": 0.236281471917366, "CIDEr": 2.0688888276537927e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.17142857142857143, "f": 0.21818181818181817, "fn": 29.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows two trains on a track in the middle of a field. The trains have red and blue awnings on top and on the sides. \n\nThere are eleven people standing on the train and in the field. \n\nThe overall scene depicts a small train in a park."}, "162543": {"image_id": 162543, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.1469436716703117, "Bleu_3": 8.356671880332698e-07, "Bleu_4": 2.0065472339680166e-09, "METEOR": 0.14323157948729218, "ROUGE_L": 0.22246535375638216, "CIDEr": 4.507600084366434e-06, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of five elephants standing in a field. The elephants are not wearing collars. The elephants are not standing in a line. There is a tree in the background and a building in the distance."}, "157352": {"image_id": 157352, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.0953462589224164, "Bleu_3": 0.05957256316301672, "Bleu_4": 8.423108446301198e-06, "METEOR": 0.17147336461861243, "ROUGE_L": 0.2053872053872054, "CIDEr": 2.822378451140496e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of four people skateboarding on a ramp. They are all wearing skateboarding gear, including helmets, pads, and shoes. The ramp is made of concrete and has a smooth surface. The sky is blue and there are trees in the background."}, "262810": {"image_id": 262810, "Bleu_1": 0.1940298507433727, "Bleu_2": 0.093912398915264, "Bleu_3": 5.138592405596748e-07, "Bleu_4": 1.20666894144117e-09, "METEOR": 0.16371077762619374, "ROUGE_L": 0.16523702031602708, "CIDEr": 4.536278117455888e-18, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.09523809523809523, "f": 0.09302325581395349, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a wedding reception in a large room. There are two tables set up with a cake on each. The tables are decorated with white tablecloths. \n\nThe bride and groom are standing at the head table, hugging the cake. \n\nThere are two guests taking pictures and seated at a table. \n\nThere are five candles placed on the tables. \n\nThere is no picture in the scene."}, "498807": {"image_id": 498807, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.15160238526733089, "Bleu_4": 0.11561678083377591, "METEOR": 0.19202800483309568, "ROUGE_L": 0.2663755458515284, "CIDEr": 2.69423856799335e-07, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09523809523809523, "f": 0.08333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a woman surfing on a pink surfboard in the ocean. She is wearing a black wetsuit, and her hair is blowing in the wind. The waves are crashing against the shore. There are no other surfers in the scene."}, "563605": {"image_id": 563605, "Bleu_1": 0.22222222221604945, "Bleu_2": 0.11268723396062734, "Bleu_3": 7.2015089840826e-07, "Bleu_4": 1.8341681390713041e-09, "METEOR": 0.13310797111704464, "ROUGE_L": 0.2420634920634921, "CIDEr": 8.547339671368862e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16, "f": 0.15094339622641512, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows four people standing in front of a building with umbrellas. They are all wearing brown and black outfits. The building is white. People are walking on the sidewalk in front of the building."}, "162503": {"image_id": 162503, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.29475317236707566, "Bleu_3": 0.2571188308244214, "Bleu_4": 0.2181901282642112, "METEOR": 0.2901606875963262, "ROUGE_L": 0.28018372703412076, "CIDEr": 3.727122341640673e-09, "SPICE": {"All": {"pr": 0.1875, "re": 0.21428571428571427, "f": 0.19999999999999998, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a bird perched on a branch in a forest. The bird is gray and white. The bird is perched on a branch. The eyes are the size of a small owl.\n\nThere is no other information about the forest, trees, or underbrush in the scene."}, "62089": {"image_id": 62089, "Bleu_1": 0.2205882352908737, "Bleu_2": 0.17213731578711086, "Bleu_3": 0.11043560738159444, "Bleu_4": 1.1997852097306463e-05, "METEOR": 0.23966120300297072, "ROUGE_L": 0.2538309114927345, "CIDEr": 9.771145237621424e-18, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.038461538461538464, "f": 0.04, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a boy wearing a helmet and knee pads, standing on a skateboard ramp in a parking lot. The boy is wearing a gray shirt with blue stripes and black pants. The ramp is made of concrete and there is a railing.\n\nNote: The refined passage is not consistent with the supplementary information provided. Please provide the correct supplementary information for a more accurate refined passage."}, "340737": {"image_id": 340737, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.1591372845179993, "Bleu_3": 0.09788738062229653, "Bleu_4": 0.0648598683911502, "METEOR": 0.20293712448738924, "ROUGE_L": 0.21229698375870068, "CIDEr": 3.0561433898365064e-13, "SPICE": {"All": {"pr": 0.28125, "re": 0.5625, "f": 0.375, "fn": 7.0, "numImages": 1.0, "fp": 23.0, "tp": 9.0}, "Relation": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.8333333333333334, "f": 0.5263157894736842, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image is of a bathroom with a bathtub, sink, and toilet. The walls are yellow. The floor is made of tile. There is a window on the left side of the room and a door on the right side. The room is well lit. The room does not have a large mirror on the wall."}, "423744": {"image_id": 423744, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.14862901964760822, "Bleu_4": 1.714477581871228e-05, "METEOR": 0.2679443478034987, "ROUGE_L": 0.3165307635285397, "CIDEr": 2.5321020726294345e-05, "SPICE": {"All": {"pr": 0.32142857142857145, "re": 0.4090909090909091, "f": 0.36000000000000004, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Attribute": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "This is a computer workstation with a laptop and a monitor on top of it. The laptop is open and the monitor is turned on. The workbench is made of wood. There is a small table on top of the workbench."}, "343903": {"image_id": 343903, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.25425669045977695, "Bleu_3": 0.1818494973816351, "Bleu_4": 0.10938852244325235, "METEOR": 0.271440312167526, "ROUGE_L": 0.42996283480712544, "CIDEr": 4.79069811157915e-05, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.14285714285714285, "f": 0.16129032258064516, "fn": 30.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.26666666666666666, "f": 0.2962962962962963, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a plate with a blueberry pancake on it, sitting on top of a pink and white checkered tablecloth. There is a glass of milk next to the plate. The background is a colorful, patterned tablecloth.\n\nThe image is taken in a kitchen."}, "117786": {"image_id": 117786, "Bleu_1": 0.15555555555382716, "Bleu_2": 0.09348302602403925, "Bleu_3": 0.04630852524978634, "Bleu_4": 5.812539266623835e-06, "METEOR": 0.1381328499842941, "ROUGE_L": 0.16093773556460125, "CIDEr": 5.480718051867301e-35, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows two men standing on a sidewalk in front of a large building with a large dome on top. The building has a white stone facade. \n\nThe first man is playing with a frisbee and is holding a stick. There is a statue in front of him. The second man is also playing with a frisbee and is holding a frisbee. \n\nThe first man is wearing a white shirt and the second man is wearing blue and purple pants. \n\nThere is a bird on top of the building."}, "3693": {"image_id": 3693, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.120873444601629, "Bleu_3": 0.06467791518167731, "Bleu_4": 8.452750341737085e-06, "METEOR": 0.1928705507372585, "ROUGE_L": 0.2426136363636364, "CIDEr": 6.59360157394245e-14, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.25, "f": 0.2162162162162162, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of six people standing in front of a graffiti wall. The people are wearing black and white clothing. The wall has various colors and designs on it, including blue, green, and red. There are also some words written on the wall. The people are holding a cell phone with their hands."}, "187852": {"image_id": 187852, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.10583300875240854, "Bleu_4": 1.356590733316526e-05, "METEOR": 0.18560785215343426, "ROUGE_L": 0.28147659854976925, "CIDEr": 0.0005633733354414392, "SPICE": {"All": {"pr": 0.28, "re": 0.35, "f": 0.3111111111111111, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of ten people standing in front of a building. The people are wearing sunglasses. Some of the people are holding cameras. The man's shirt is blue. The woman's shirt is blue."}, "414078": {"image_id": 414078, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.2641352718914714, "Bleu_3": 0.1895147329784242, "Bleu_4": 0.13582344277251354, "METEOR": 0.2697133341335261, "ROUGE_L": 0.3238221632382216, "CIDEr": 2.0704569607598043e-06, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a black and brown cat lying on a bed. The cat is looking up at a clock. The cat is wearing a collar with a tag on it. The bed has a blue sheet and a blue blanket on it."}, "121716": {"image_id": 121716, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 7.502652544655378e-07, "Bleu_4": 1.7134131896259546e-09, "METEOR": 0.17041462771758162, "ROUGE_L": 0.18373493975903615, "CIDEr": 4.4816577867036683e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.08823529411764706, "f": 0.12244897959183675, "fn": 31.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a person doing skiing down a snowy slope. The person is wearing a black jacket, tan pants, and black ski boots. They are holding onto two skis and are jumping off a snowy slope. The sky is blue and there are no other people or objects in the scene."}, "327794": {"image_id": 327794, "Bleu_1": 0.5714285714013606, "Bleu_2": 0.1690308509374531, "Bleu_3": 1.1456697640101971e-06, "Bleu_4": 3.023266712930042e-09, "METEOR": 0.22661942087532902, "ROUGE_L": 0.287396937573616, "CIDEr": 0.09305007670766124, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16666666666666666, "f": 0.1923076923076923, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a pan of vegetables cooking. The vegetables are carrots, onions, and mushrooms. There is no pot in the image."}, "143370": {"image_id": 143370, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.19518001458420758, "Bleu_3": 0.14979742339353158, "Bleu_4": 0.11946956198208007, "METEOR": 0.30899114150956664, "ROUGE_L": 0.35942760942760943, "CIDEr": 0.004581040298741045, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.13157894736842105, "f": 0.13888888888888887, "fn": 33.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.11764705882352941, "f": 0.13793103448275862, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image is of a bathroom with a toilet, sink, and mirror. The walls are green. The floor is made of tile. There is a window on one side of the room. The toilet is white."}, "354202": {"image_id": 354202, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.1772810520820019, "Bleu_3": 0.125237643155067, "Bleu_4": 0.08040382322087453, "METEOR": 0.31554532701301, "ROUGE_L": 0.27128335451080055, "CIDEr": 1.2083675442693513e-10, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2692307692307692, "f": 0.27999999999999997, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two giraffes standing on a fence in a zoo. The giraffes are brown and white. They have long necks and legs. One of the giraffes is looking directly at the camera, while the other is looking away. The fence is made of wood and has a gate."}, "189193": {"image_id": 189193, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.20447945297237122, "Bleu_3": 1.01487632009003e-06, "Bleu_4": 2.2753263050582995e-09, "METEOR": 0.236524163696248, "ROUGE_L": 0.3028368794326241, "CIDEr": 3.0102073167130366e-07, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a woman standing on a skateboard in the middle of a parking lot. She is wearing a black hat and a green sweater. \n\nThere is no backpack or car in the scene.\n\nThe woman is standing on the skateboard."}, "561967": {"image_id": 561967, "Bleu_1": 0.1917808219151811, "Bleu_2": 0.12641888766864096, "Bleu_3": 6.083056640180659e-07, "Bleu_4": 1.3391119486480954e-09, "METEOR": 0.16264384270970553, "ROUGE_L": 0.1675057208237986, "CIDEr": 4.029737187019357e-24, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10526315789473684, "f": 0.12903225806451615, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a train traveling along a track. The train has a yellow and green color scheme and is pulling a cargo car. There are no other trains in the scene. There are no buildings in the scene. A large tree is in the foreground, and a large field is in the background. The sky is cloudy and there is no snow on the ground.\n\nThe train is traveling along the track."}, "404071": {"image_id": 404071, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.23783535599888, "Bleu_3": 0.17393278705640788, "Bleu_4": 0.12581466580364023, "METEOR": 0.2418160035688142, "ROUGE_L": 0.28754208754208754, "CIDEr": 7.747401304708541e-08, "SPICE": {"All": {"pr": 0.08, "re": 0.1111111111111111, "f": 0.09302325581395349, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a train traveling along a track in the countryside. The train is blue and yellow. There are trees and bushes on either side of the track. A bridge is visible in the distance. The sky is clear and there are no clouds."}, "251572": {"image_id": 251572, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.2399494896298897, "Bleu_3": 0.17578342897796143, "Bleu_4": 0.12022370616851272, "METEOR": 0.3268299611580362, "ROUGE_L": 0.33757609297177643, "CIDEr": 2.0134460258652597e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.15, "f": 0.17142857142857143, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a woman laying down on a couch with a puppy in her lap. The woman is wearing a gray sweater and has wavy hair. The puppy is brown and white and is wearing a sweater. \n\nThere is no ponytail, dog, or collar in the scene. The background does not have a wall."}, "436791": {"image_id": 436791, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.24840690229653717, "Bleu_3": 0.1876852661328498, "Bleu_4": 0.1565757368190075, "METEOR": 0.3329202956072946, "ROUGE_L": 0.33701657458563533, "CIDEr": 2.471879908804282e-13, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man wearing a black jacket. He is holding a cell phone to his ear and talking on the phone. The man is walking down the street, looking at the ground. The man's hair is short and he does not have a beard. The sky is blue and there are trees in the background."}, "319257": {"image_id": 319257, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.3849001794457496, "Bleu_3": 0.2576012965819263, "Bleu_4": 0.1923018800711164, "METEOR": 0.28786118991929216, "ROUGE_L": 0.33394160583941607, "CIDEr": 0.01805487430563197, "SPICE": {"All": {"pr": 0.35, "re": 0.28, "f": 0.3111111111111111, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on a window sill. The cat is wearing a collar. The cat is sitting on a cactus. The cat is laying down."}, "279437": {"image_id": 279437, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.2506402059074552, "Bleu_3": 0.14897587976109594, "Bleu_4": 1.7289663387197205e-05, "METEOR": 0.26407869489949976, "ROUGE_L": 0.3650265957446809, "CIDEr": 2.318183116162424e-05, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.1, "f": 0.12903225806451613, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a bedroom with a bed, a window in front of the bed, and floral wallpaper on the walls. The bed has a brown comforter and brown pillows. There is a blue and white vase on the nightstand."}, "175718": {"image_id": 175718, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2383656473040621, "Bleu_3": 1.2237946382258258e-06, "Bleu_4": 2.7957677823832457e-09, "METEOR": 0.25493113992246846, "ROUGE_L": 0.34297188755020075, "CIDEr": 0.0007855217530599249, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.3076923076923077, "f": 0.3018867924528302, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6, "f": 0.631578947368421, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a pizza on a cutting board. A beer bottle is next to the pizza. The label on the beer bottle reads \"St. Helena\". There are three mugs in the scene."}, "126671": {"image_id": 126671, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.17339191115885713, "Bleu_3": 0.12608269096032357, "Bleu_4": 0.09769805815563083, "METEOR": 0.236147830816228, "ROUGE_L": 0.317915309446254, "CIDEr": 1.9994577291550566e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.08, "f": 0.11428571428571428, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image is of a bathroom with a toilet, a wall, and a floor. The walls are beige. The floor is made of tile. The toilet is on the left side of the room. There is a window with red and white striped curtains in the room."}, "281424": {"image_id": 281424, "Bleu_1": 0.19512195121475318, "Bleu_2": 0.1396860591504661, "Bleu_3": 0.11449528240744465, "Bleu_4": 0.09427624888340959, "METEOR": 0.1816496362907301, "ROUGE_L": 0.23229246001523232, "CIDEr": 6.324518122051224e-07, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a cat sleeping in a suitcase. The cat is lying on its side with its paws tucked under its body. The suitcase is open. There is a small table next to the suitcase with a lamp on it."}, "136": {"image_id": 136, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.10206207261435839, "Bleu_3": 5.517966071795556e-07, "Bleu_4": 1.2882549225122457e-09, "METEOR": 0.1573720512239915, "ROUGE_L": 0.21785714285714283, "CIDEr": 1.3310774283465753e-18, "SPICE": {"All": {"pr": 0.12, "re": 0.12, "f": 0.12, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two giraffes standing in a large enclosure. The giraffes are looking at a sign and a ladder respectively. The enclosure is made of glass. The door is not open. There are two people in the enclosure. The people are looking at a reflection in the window and a cell phone respectively.\n\nThere are no other giraffes or people in the scene."}, "71929": {"image_id": 71929, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.150830541720198, "Bleu_4": 0.12936981168128564, "METEOR": 0.21263514366653594, "ROUGE_L": 0.25176886792452824, "CIDEr": 3.804319573889901e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.125, "f": 0.1509433962264151, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a plate of food on a table. The plate contains shrimp, rice, and vegetables. There is also a glass on the table. The background is a blue sky with white clouds.\n\nThe image is taken from a boat in the ocean. The sun is shining brightly in the sky."}, "69293": {"image_id": 69293, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.12819595791702068, "Bleu_4": 0.08519041837055405, "METEOR": 0.23656511577920766, "ROUGE_L": 0.3732154996600952, "CIDEr": 6.885684775183793e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a toilet, sink, and mirror. The floor is made of tile and the walls are made of wood. There is a shower in the bathroom. The toilet is made of porcelain and has a seat and lid."}, "90040": {"image_id": 90040, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.11375929179665137, "Bleu_3": 0.06415924230513619, "Bleu_4": 8.612596688347549e-06, "METEOR": 0.19502055888886394, "ROUGE_L": 0.21441124780316342, "CIDEr": 1.26190784778915e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.20833333333333334, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a river with boats docked on the shore. There are no buildings in the scene. The person is standing on the shore. The sky is cloudy. There are trees in the background.\n\nThe image is taken from a low angle, looking down at the river and the boats."}, "409646": {"image_id": 409646, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.3086066999129581, "Bleu_3": 0.22232392576237683, "Bleu_4": 2.57486610153163e-05, "METEOR": 0.23926208473390184, "ROUGE_L": 0.4452554744525547, "CIDEr": 0.015246045479906475, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.18181818181818182, "f": 0.21621621621621623, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a black bear walking on the road. The bear is standing on the road. The background is a green field with trees in the distance."}, "296383": {"image_id": 296383, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.49761335150383107, "Bleu_3": 0.2964968937577693, "Bleu_4": 3.468941568808112e-05, "METEOR": 0.246763736046767, "ROUGE_L": 0.48248587570621465, "CIDEr": 0.3523603245380048, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.08, "f": 0.07407407407407408, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a cell phone with a green light emitting from the screen. The phone is on a wooden floor."}, "566672": {"image_id": 566672, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.21666028366574688, "Bleu_3": 0.15756477111639683, "Bleu_4": 1.8284257592918543e-05, "METEOR": 0.19351922349904163, "ROUGE_L": 0.26483357452966716, "CIDEr": 3.409610617716638e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10344827586206896, "f": 0.1276595744680851, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a baseball player swinging a bat on a baseball field. The player is wearing a white jersey and white pants. The player is holding a bat and swinging it. The umpire is a baseball umpire."}, "202865": {"image_id": 202865, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.22696949467458388, "Bleu_3": 0.1338131642598596, "Bleu_4": 1.5454743722279543e-05, "METEOR": 0.2031991578126718, "ROUGE_L": 0.24177566389219182, "CIDEr": 1.86837211086706e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.13793103448275862, "f": 0.17391304347826086, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a hand holding a doughnut with a bite taken out of it. The doughnut is covered in powdered sugar and has a glaze on top. The hand holding the doughnut is wearing a white glove. The background is a green grassy area."}, "226805": {"image_id": 226805, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.1601281538019776, "Bleu_3": 8.004271223291966e-07, "Bleu_4": 1.7986320469414935e-09, "METEOR": 0.2299047939200427, "ROUGE_L": 0.2921655833048238, "CIDEr": 7.423933382330748e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.10714285714285714, "f": 0.13333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a large, open living room with high ceilings and large windows. There are two couches and two chairs arranged around the room. There are five tables in the room, including a round table with a white top. The walls are painted brown. There are no paintings on the walls."}, "235221": {"image_id": 235221, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.23763541030969576, "Bleu_3": 0.15121069009849425, "Bleu_4": 0.09212480089236008, "METEOR": 0.2391551440787168, "ROUGE_L": 0.33608815426997246, "CIDEr": 2.2176456315300318e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.36363636363636365, "f": 0.25806451612903225, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a lightning storm in the background, with a clock tower in the foreground. The clock tower has a red light on top of it. There is a building in the background, which is red in color. The sky is dark and stormy, with lightning bolts striking the ground."}, "499402": {"image_id": 499402, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.18971331171167066, "Bleu_3": 9.574966238312988e-07, "Bleu_4": 2.1644020701535495e-09, "METEOR": 0.22154113628190245, "ROUGE_L": 0.26852531181217903, "CIDEr": 8.588755600952048e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.15625, "f": 0.18867924528301888, "fn": 27.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows an airplane flying over a mountain range. The airplane has a wing, but there is no specific information about it. The southwest logo is on the tail. The mountain range consists of snowy mountains. The sky is clear and blue."}, "539557": {"image_id": 539557, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1596564940032875, "Bleu_3": 0.0804252399656011, "Bleu_4": 1.0203142794069551e-05, "METEOR": 0.18743138124005432, "ROUGE_L": 0.22889305816135083, "CIDEr": 1.7776291119460707e-11, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.23529411764705882, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is of a ship with a white and purple hull. The mast of the ship is white. There are several birds flying overhead, including a seagull, a sandhill crane, a bird, a purple bird, and a bald eagle. The sky is purple. In the background, there is a lighthouse."}, "109976": {"image_id": 109976, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.20203050890627616, "Bleu_3": 0.13760021235336062, "Bleu_4": 0.10316499681152426, "METEOR": 0.23777311812816218, "ROUGE_L": 0.23303196230739842, "CIDEr": 1.2552037643724417e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a kitchen with white cabinets and a white refrigerator. There is a stove and oven in the kitchen. The floor is made of tile. There is a microwave on the counter. The walls are painted white.\n\nThe image does not show any windows in the room."}, "210448": {"image_id": 210448, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.1886616557167528, "Bleu_3": 0.13489621379916564, "Bleu_4": 0.09633599896665924, "METEOR": 0.21116827165197824, "ROUGE_L": 0.25738396624472576, "CIDEr": 8.076632339014169e-16, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of six zebras standing in a fenced enclosure. The zebras are standing in the dirt. Rocks and dirt are surrounding the zebras. The zebras are not in good health.\n\nThere is a fence made of wood. The gate is not open.\n\nThere is a tree in the background. There are no bushes in the scene."}, "32724": {"image_id": 32724, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.2142857142812956, "Bleu_3": 0.1431099878823661, "Bleu_4": 1.5887772073282784e-05, "METEOR": 0.26057030289199723, "ROUGE_L": 0.27354260089686094, "CIDEr": 5.056842385551814e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.14814814814814814, "f": 0.1951219512195122, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of four giraffes running across a grassy plain. They are running in a line, with their long necks and legs stretched out in front of them. The giraffes are brown with white spots. The sky is blue and there are mountains in the distance."}, "277689": {"image_id": 277689, "Bleu_1": 0.29032258064047867, "Bleu_2": 0.0975642000715291, "Bleu_3": 0.05413480481885138, "Bleu_4": 7.20102682183652e-06, "METEOR": 0.20822926850894874, "ROUGE_L": 0.2295390404515522, "CIDEr": 1.538871993560999e-13, "SPICE": {"All": {"pr": 0.15, "re": 0.12, "f": 0.1333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two wedding cakes with white tablecloths on a table. On the first cake, there is a red rose. On the second cake, there is a red and white striped hat. There are also red strawberries on top of the cakes. The background is a blue sky with palm trees in the distance.\n\nThere is no champagne in the image."}, "167818": {"image_id": 167818, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2006088294094673, "Bleu_3": 0.10105205741245245, "Bleu_4": 1.283698314434347e-05, "METEOR": 0.25197071017541683, "ROUGE_L": 0.25120109814687713, "CIDEr": 3.335763907829779e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a desk with a computer, keyboard, mouse, and other computer accessories on it. There is a window behind the desk, and a balcony can be seen from the window. The room is well lit and has a white wall."}, "445135": {"image_id": 445135, "Bleu_1": 0.4081632652977926, "Bleu_2": 0.33248190579716647, "Bleu_3": 0.25439704998014057, "Bleu_4": 0.19451790929447138, "METEOR": 0.3499768359320724, "ROUGE_L": 0.3984757757212847, "CIDEr": 4.110900437283835e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 10.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a tennis court with a net in the background. The man is wearing a black shirt and white shorts, and is holding a tennis racket in his right hand. The court is made of green grass. The man is playing tennis."}, "3145": {"image_id": 3145, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.1311863860222524, "Bleu_4": 0.08156879226605328, "METEOR": 0.22830988088033277, "ROUGE_L": 0.27949599083619703, "CIDEr": 4.864054110108183e-11, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.2727272727272727, "f": 0.2903225806451613, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a living room with a couch, two coffee tables, and two chairs. The walls are painted green. There is a ceiling fan in the center of the room. The room is spacious and well-lit, with a window on the left side. The curtains are open. The floor is made of hardwood."}, "319127": {"image_id": 319127, "Bleu_1": 0.30952380951644, "Bleu_2": 0.22988155309362565, "Bleu_3": 0.17418178962825515, "Bleu_4": 1.9186064914358115e-05, "METEOR": 0.25751790200289515, "ROUGE_L": 0.27354260089686094, "CIDEr": 1.8497145216358818e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a snowy scene with two trees in the foreground. The trees are bare. There is a park bench in the foreground. The sky is cloudy and there is snow on the ground.\n\nThe image is in black and white."}, "380906": {"image_id": 380906, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.16695677422191285, "Bleu_3": 8.865761273541133e-07, "Bleu_4": 2.0559894081168643e-09, "METEOR": 0.17620253164556962, "ROUGE_L": 0.2469635627530364, "CIDEr": 3.0648521323885053e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bench on the beach. The bench is made of wood. There is a purple ribbon tied around the bench. The beach is covered in sand. There are rocks in the distance. The ocean is visible in the background."}, "524850": {"image_id": 524850, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.12032689292712466, "Bleu_4": 1.4538040525271512e-05, "METEOR": 0.19380672132050217, "ROUGE_L": 0.2469635627530364, "CIDEr": 2.4643685468712823e-06, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows an airplane with a large engine on the front and a wing on the side. There are people standing around the airplane. The people are standing on the tarmac. There are no other airplanes or buildings in the scene."}, "85926": {"image_id": 85926, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.1643989873008524, "Bleu_3": 0.09174380408476636, "Bleu_4": 1.2276168154895987e-05, "METEOR": 0.1801765791260437, "ROUGE_L": 0.23735408560311286, "CIDEr": 7.705531073307921e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2727272727272727, "f": 0.2790697674418604, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a brown bear walking in the grass. The bear is accompanied by her cubs. The cubs are walking in the grass and looking at the camera. The cubs are also looking at a fox."}, "102355": {"image_id": 102355, "Bleu_1": 0.19999999999764706, "Bleu_2": 0.11952286093202484, "Bleu_3": 0.07008385048178956, "Bleu_4": 8.049335006153916e-06, "METEOR": 0.167945583876302, "ROUGE_L": 0.17183098591549295, "CIDEr": 2.5810038699800035e-32, "SPICE": {"All": {"pr": 0.2, "re": 0.08695652173913043, "f": 0.12121212121212122, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows two horses pulling a cart on a road. The horse is pulling the cart. The house with a red roof is in front of the horse. \n\nThere are five people in the scene. Some of the people are walking a horse, some are sitting on a motorcycle, some are sitting on a bench, and some are riding on a horse.\n\nThere are two trees in the background. There is no fence in the scene.\n\nThe sky is blue and there are clouds."}, "47112": {"image_id": 47112, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.16205747826449043, "Bleu_3": 0.10689725778450594, "Bleu_4": 0.07343660663748419, "METEOR": 0.21026458312615967, "ROUGE_L": 0.27637540453074433, "CIDEr": 4.654978395175791e-07, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14285714285714285, "f": 0.14545454545454545, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two tables. On the first table, there is a pizza with mushrooms, olives, and pepperoni. On the second table, there is a glass of wine. There are two glasses on the table. \n\nThe tablecloth is blue. On the right is the glass."}, "215709": {"image_id": 215709, "Bleu_1": 0.1481481481454047, "Bleu_2": 0.10574021142710928, "Bleu_3": 0.08640378216299735, "Bleu_4": 0.07091931299479709, "METEOR": 0.16158558299865017, "ROUGE_L": 0.1862026862026862, "CIDEr": 5.837112666511855e-13, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.20833333333333334, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a sink, toilet, and shower. The walls are made of wood. There are tiles on the floor, and a rug is on the floor. There is a wooden door and a window without curtains. There are plants on the windowsill, and a sand dollar is on the windowsill."}, "512982": {"image_id": 512982, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.21350420506538995, "Bleu_3": 0.12216804360518721, "Bleu_4": 1.660219092499284e-05, "METEOR": 0.17879785831666342, "ROUGE_L": 0.2357487922705314, "CIDEr": 0.008833431221578182, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a sink made of granite. The faucet is located on the sink. There is no toilet or shower in the image."}, "344633": {"image_id": 344633, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.11420804814152181, "Bleu_3": 6.667764421629133e-07, "Bleu_4": 1.6203844679821425e-09, "METEOR": 0.22780709877245064, "ROUGE_L": 0.2121001390820584, "CIDEr": 3.144903257873645e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.15384615384615385, "f": 0.13793103448275862, "fn": 22.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image shows five horses running. Two people are riding horses. The person riding is wearing a helmet and boots. The person riding is wearing a helmet and a purple shirt. One of the horses is licking a person. There is no corral in the scene."}, "555942": {"image_id": 555942, "Bleu_1": 0.11504424778659254, "Bleu_2": 0.07166522112572077, "Bleu_3": 0.03590029113836696, "Bleu_4": 4.528718295221434e-06, "METEOR": 0.14677252031511132, "ROUGE_L": 0.11543556424651484, "CIDEr": 6.963821454447688e-66, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16666666666666666, "f": 0.1702127659574468, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows three motorcycles parked on the sidewalk next to a row of parked cars. \n\nThe motorcycles have different colors. One is orange and white, one is green with a sidecar, and the other is green with a green paint job. \n\nThe motorcycles have different seat colors. One has a black seat, one has a brown seat, and the other also has a brown seat. \n\nThe motorcycles also have different gas tank colors. One has a green and black gas tank. \n\nOne of the motorcycles has a green front fender. \n\nThere is no rear mentioned in the supplementary information.\n\nThe motorcycles are parked on the sidewalk next to the row of cars."}, "471567": {"image_id": 471567, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.20080483221924839, "Bleu_3": 1.1035932143410068e-06, "Bleu_4": 2.6091993798285682e-09, "METEOR": 0.2023354944308462, "ROUGE_L": 0.2970779220779221, "CIDEr": 0.0011515030579685682, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.35294117647058826, "f": 0.27272727272727276, "fn": 11.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8333333333333334, "f": 0.625, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a giraffe looking at the camera. The giraffe has a long neck and its fur is brown and white. The background does not include a wooden fence or trees."}, "24260": {"image_id": 24260, "Bleu_1": 0.23880597014568944, "Bleu_2": 0.10418645221255786, "Bleu_3": 0.05506847470461123, "Bleu_4": 7.147140047139338e-06, "METEOR": 0.14743818382736532, "ROUGE_L": 0.17734276577187713, "CIDEr": 7.226028958013397e-13, "SPICE": {"All": {"pr": 0.046511627906976744, "re": 0.10526315789473684, "f": 0.06451612903225806, "fn": 17.0, "numImages": 1.0, "fp": 41.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.043478260869565216, "re": 0.16666666666666666, "f": 0.06896551724137931, "fn": 5.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.1, "re": 1.0, "f": 0.18181818181818182, "fn": 0.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Object": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows two horses in a field. The horses are brown and white with long manes and tails. The horse on the left is jumping over a fence made of wood. The horse on the right is standing in the dirt. The horse on the left does not have a white stripe on its back. The horse on the right is not on the right side."}, "106508": {"image_id": 106508, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.11470786693325052, "Bleu_3": 0.06207850355375181, "Bleu_4": 8.158446869155907e-06, "METEOR": 0.19049660851081635, "ROUGE_L": 0.19709208400646203, "CIDEr": 4.099606578247098e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.75, "f": 0.5714285714285714, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a bus stop with a bus and a police officer standing on the sidewalk. The bus stop has a sign that says \"the sands of time\". The officer is wearing a yellow and orange vest. \n\nThere are no trees or buildings in the background.\n\nThe image is taken from a bird's-eye view."}, "311082": {"image_id": 311082, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.21103178185560523, "Bleu_3": 0.1534163882016816, "Bleu_4": 0.11901061222895773, "METEOR": 0.23803575824446976, "ROUGE_L": 0.2669584245076586, "CIDEr": 8.518923664539953e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.07142857142857142, "f": 0.08695652173913043, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows three elephants standing in a field with trees in the background. The elephants are standing next to each other and appear to be interacting with each other. The elephants are grey in color and have tusks."}, "312167": {"image_id": 312167, "Bleu_1": 0.305555555547068, "Bleu_2": 0.1321374945249591, "Bleu_3": 8.00800630132788e-07, "Bleu_4": 1.9861626911872047e-09, "METEOR": 0.17997342550265727, "ROUGE_L": 0.2420634920634921, "CIDEr": 2.5367320717282094e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a still life of three vases with pink flowers in them. The vases are sitting on a table. The vases are made of glass and have a cylinder shape. The flowers are pink."}, "324937": {"image_id": 324937, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.134717557601255, "Bleu_3": 0.06868893635096675, "Bleu_4": 8.761418413475316e-06, "METEOR": 0.18348137682280366, "ROUGE_L": 0.23041225987481118, "CIDEr": 2.472910685224007e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.2692307692307692, "f": 0.2592592592592593, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a white and black dog lying on a couch. The dog is looking up at the camera with its tongue hanging out of its mouth. The couch is covered in a brown fabric. There is a pillow on the couch. The room is dimly lit and there are no books or lamp in the scene."}, "65415": {"image_id": 65415, "Bleu_1": 0.16393442622682078, "Bleu_2": 0.09053574604102199, "Bleu_3": 0.05179200443176847, "Bleu_4": 6.995842782527095e-06, "METEOR": 0.1556208853647395, "ROUGE_L": 0.16822945394373964, "CIDEr": 5.343557788372501e-17, "SPICE": {"All": {"pr": 0.25, "re": 0.19047619047619047, "f": 0.2162162162162162, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a woman in a red jacket and black pants standing on skis in the snow. She is holding a pair of skis. The woman is also wearing goggles on her face.\n\nThere are two signs in the scene. One sign reads \"3\" and the other sign reads \"no parking\".\n\nThe woman is standing on skis in the snow."}, "201925": {"image_id": 201925, "Bleu_1": 0.6153846153372783, "Bleu_2": 0.3922322702449393, "Bleu_3": 0.3035577449570705, "Bleu_4": 0.2299751911087547, "METEOR": 0.20996468660321999, "ROUGE_L": 0.4834874504623514, "CIDEr": 0.9220424187976324, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a cake in a black pan. The cake is brown."}, "273132": {"image_id": 273132, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.13109795466387256, "Bleu_3": 0.08305329348874976, "Bleu_4": 0.05582190347406638, "METEOR": 0.19178339261480074, "ROUGE_L": 0.19162303664921465, "CIDEr": 2.142076173878407e-16, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a black and white photograph of two women sitting on a bench in a park. Both women are wearing hats and jackets. One woman has a tennis ball in her hand, while the other woman has a tennis racket in her hand.\n\nThe bench is made of metal. There is no cigarette, wood, metal, frame, or tree in the scene."}, "475238": {"image_id": 475238, "Bleu_1": 0.36842105261218844, "Bleu_2": 0.20232565954468354, "Bleu_3": 1.340348304748383e-06, "Bleu_4": 3.502541230863007e-09, "METEOR": 0.15053384858542995, "ROUGE_L": 0.2398427260812582, "CIDEr": 0.05776202986151617, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows two trains traveling down the tracks on a sunny day. A building is in the background."}, "130527": {"image_id": 130527, "Bleu_1": 0.30769230768047345, "Bleu_2": 0.2218800784813872, "Bleu_3": 0.12705988559832868, "Bleu_4": 1.7281219479288692e-05, "METEOR": 0.17801353864186042, "ROUGE_L": 0.2890995260663507, "CIDEr": 0.019165273320548574, "SPICE": {"All": {"pr": 0.24, "re": 0.35294117647058826, "f": 0.28571428571428564, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a green field with three cows grazing in it. The cows are doing a spooky story about a farm in San Diego 0."}, "337563": {"image_id": 337563, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.16751484856166823, "Bleu_3": 0.12144417015554987, "Bleu_4": 0.07899380722443533, "METEOR": 0.24658060442232388, "ROUGE_L": 0.24190350297422336, "CIDEr": 6.413513703509485e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.2857142857142857, "f": 0.3243243243243243, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6, "f": 0.631578947368421, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a woman sitting on a bed with her daughter sitting next to her. The woman is peeping a banana and holding a banana. The daughter is eating a banana and holding a toy banana. The room is dimly lit and there are curtains on the windows."}, "135356": {"image_id": 135356, "Bleu_1": 0.1739130434744802, "Bleu_2": 0.13900960936832768, "Bleu_3": 0.07601144519394981, "Bleu_4": 1.005291773011835e-05, "METEOR": 0.19844980372525303, "ROUGE_L": 0.2873485868102288, "CIDEr": 8.771191272091134e-09, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.4117647058823529, "f": 0.3043478260869565, "fn": 10.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.6666666666666666, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.26666666666666666, "re": 0.6666666666666666, "f": 0.3809523809523809, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a man standing in a kitchen. He is holding a sink faucet in his hand. The man is wearing a plaid shirt and black jeans. \n\nThe kitchen has a stainless steel refrigerator, a stove, and a dishwasher. There is a window on the"}, "290078": {"image_id": 290078, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.2578553115592693, "Bleu_3": 0.19333988033524058, "Bleu_4": 0.11257396315370245, "METEOR": 0.257062888828634, "ROUGE_L": 0.3043912175648702, "CIDEr": 4.09841705308962e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.16, "f": 0.17777777777777778, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a toilet sitting on the sidewalk in front of a building. The toilet is white. There is a small hole located on the side of the building. The building is a two-story brick structure with a red door and two windows on the top floor."}, "578314": {"image_id": 578314, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.2148344622063902, "Bleu_3": 0.1344264611354716, "Bleu_4": 0.09001463882336909, "METEOR": 0.20187333021332485, "ROUGE_L": 0.2621776504297994, "CIDEr": 2.8249823658737343e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a toilet in a bathroom. The toilet is white and has a seat and a lid. The bathroom also features a sink and a mirror, but the supplementary information does not provide any specific information about them."}, "174893": {"image_id": 174893, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.16001422411453173, "Bleu_3": 0.1124643536531252, "Bleu_4": 0.07984434410291594, "METEOR": 0.29958376015337485, "ROUGE_L": 0.2793893129770992, "CIDEr": 2.521068539687746e-05, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.2631578947368421, "f": 0.17543859649122803, "fn": 14.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a girl sitting at a table. She is cutting up paper using a pair of scissors. The table is made of wood. The girl is wearing a brown and white shirt and has brown hair."}, "539310": {"image_id": 539310, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.23121228231834207, "Bleu_3": 0.12715969702116897, "Bleu_4": 1.416999083410326e-05, "METEOR": 0.23377715223680873, "ROUGE_L": 0.24710648148148148, "CIDEr": 4.735579675563628e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.13636363636363635, "f": 0.19999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a view of a street with seven cars parked on both sides of the street. There is a building in the background. The sky is cloudy. There are trees in the foreground. A traffic light can be seen in the foreground. The image is taken from the perspective of a person."}, "49740": {"image_id": 49740, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2253202848508038, "Bleu_3": 0.1617359060141058, "Bleu_4": 0.11645895136943694, "METEOR": 0.29294522031312004, "ROUGE_L": 0.375770020533881, "CIDEr": 0.02207447933096305, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a baseball player swinging a bat at a ball. The player is wearing a white uniform with the number 13 on the back."}, "274549": {"image_id": 274549, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.2276604231967495, "Bleu_3": 0.10994365150211913, "Bleu_4": 1.3675138027356721e-05, "METEOR": 0.22870210473936425, "ROUGE_L": 0.26425992779783397, "CIDEr": 2.3117069586742766e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14814814814814814, "f": 0.15999999999999998, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person doing skiing on a snowy slope. The person is wearing an orange jacket, black pants, and black ski boots. They are holding ski poles in their hands. The person also has a backpack on their back."}, "537211": {"image_id": 537211, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.2156655464019184, "Bleu_3": 0.1879985501619886, "Bleu_4": 0.15956399774259794, "METEOR": 0.3861151689271558, "ROUGE_L": 0.41780821917808225, "CIDEr": 2.3573699690604163e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2631578947368421, "f": 0.2040816326530612, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man sitting on a dock made of wood. The man is eating a hot dog. He is wearing a gray shirt and brown pants. \n\nIn the background, there are five buildings and a body of water. The sky is clear."}, "533743": {"image_id": 533743, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.14527180078437643, "Bleu_3": 0.09211555193837166, "Bleu_4": 0.0619698937576483, "METEOR": 0.2250653175282161, "ROUGE_L": 0.2717149220489977, "CIDEr": 9.247991144214875e-14, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2777777777777778, "f": 0.24390243902439024, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two men in a living room. One of the men is playing a video game and wearing a hat on his head. The other man is also playing a video game and wearing a hat on his head. The man's shirt is black. There is a couch in front of a television."}, "81812": {"image_id": 81812, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.26006316586278166, "Bleu_3": 0.19734449042138133, "Bleu_4": 0.13750203938570613, "METEOR": 0.22347118691102946, "ROUGE_L": 0.28968792401628224, "CIDEr": 5.1871879333614985e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of five people sitting at a table in a restaurant. The people are enjoying their meals. Some of the people are drinking wine. The table is set with brown tablecloths and paper napkins. There are bottles of wine on the table."}, "59743": {"image_id": 59743, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.3638034375324306, "Bleu_3": 0.26034991751675446, "Bleu_4": 3.350704079297443e-05, "METEOR": 0.3026890878504301, "ROUGE_L": 0.5133239831697054, "CIDEr": 0.3305209314424915, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.12, "f": 0.13636363636363635, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three people holding surfboards and wearing wetsuits. They are not standing in the water."}, "356131": {"image_id": 356131, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.23452078798159529, "Bleu_3": 1.3372469554821615e-06, "Bleu_4": 3.2288884622985093e-09, "METEOR": 0.25883432431227393, "ROUGE_L": 0.2961165048543689, "CIDEr": 0.13527030940959067, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14814814814814814, "f": 0.14285714285714285, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a boat sailing on calm blue water. The boat is brown and has white sails. There are two people in the boat."}, "311310": {"image_id": 311310, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.12993504870706918, "Bleu_3": 0.06787131897112117, "Bleu_4": 8.763866421088602e-06, "METEOR": 0.13044925124792014, "ROUGE_L": 0.23036253776435048, "CIDEr": 5.362179184789547e-13, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of ten people playing with kites in a park. The kites are made of colorful fabric and have tails that are streaming behind them. The people are standing on the grass and looking up at the kites. There are no trees in the scene. The sky is clear with no clouds."}, "165257": {"image_id": 165257, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.15240998561606448, "Bleu_3": 0.08343000781860355, "Bleu_4": 1.104652199055032e-05, "METEOR": 0.22968432163479635, "ROUGE_L": 0.2952973720608575, "CIDEr": 7.00758741330628e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 24.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a kitchen with wooden floors and cabinets. There is a sink in the corner. The countertops are made of granite. The refrigerator is on the wall. The walls are painted a light color. There are no windows in the room."}, "202658": {"image_id": 202658, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.23186944787247984, "Bleu_3": 0.177175406364313, "Bleu_4": 0.11871704289685217, "METEOR": 0.2330095912304027, "ROUGE_L": 0.41673783091374894, "CIDEr": 0.00215668385362435, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.26666666666666666, "f": 0.19047619047619047, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 1.0, "f": 0.5714285714285715, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a toilet with a pink seat and a white tank. The toilet is in a small room with a concrete floor. There is a door made of wood."}, "50926": {"image_id": 50926, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.21320071635169824, "Bleu_3": 0.16246400358068253, "Bleu_4": 0.12541438165489327, "METEOR": 0.24725582982674743, "ROUGE_L": 0.2872277810476751, "CIDEr": 2.395505747682343e-13, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three people standing in a field. The people are playing frisbee. \n\nThere are two buildings in the background, a barn and a house. \n\nThe people are standing in the grass. There is a man and a woman in the field. \n\nThere is a multicolored kite being held by one of the people."}, "514797": {"image_id": 514797, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.17204158993311794, "Bleu_3": 8.898958910772614e-07, "Bleu_4": 2.036143756474482e-09, "METEOR": 0.2136613108042816, "ROUGE_L": 0.2924657534246575, "CIDEr": 2.6845140870065373e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.125, "f": 0.16326530612244897, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows three people standing on a pier, looking up at a kite flying in the sky. The people are flying a kite and looking at a kite. The design of the kite is a triangular shape. A man is holding the kite."}, "258021": {"image_id": 258021, "Bleu_1": 0.1296296296272291, "Bleu_2": 0.08565936145673987, "Bleu_3": 0.05206135179390746, "Bleu_4": 7.252605189423233e-06, "METEOR": 0.09244674651068518, "ROUGE_L": 0.17468499427262313, "CIDEr": 4.927944748197273e-13, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.10526315789473684, "f": 0.08695652173913043, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man walking with a chain on the sidewalk in front of a building. The man's shirt is blue, and his pants are also blue.\n\nThere is no helmet or bicycle in the scene.\n\nThe building has a large window on the top floor. There are trees in the background."}, "203085": {"image_id": 203085, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.1880253582691385, "Bleu_3": 0.11008521423530734, "Bleu_4": 0.07116982665493311, "METEOR": 0.22766826607822704, "ROUGE_L": 0.2658241638522715, "CIDEr": 4.2037665689214726e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.13636363636363635, "f": 0.1764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a man sitting at a desk in a small room. He is wearing a gray shirt and blue pants. There is a computer monitor on the desk in front of him. \n\nThe room is cluttered with various items such as a chair, but there is no lamp or bookshelf in the scene."}, "441442": {"image_id": 441442, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.12909944487067912, "Bleu_3": 7.291106321801015e-07, "Bleu_4": 1.7429412599383862e-09, "METEOR": 0.1543026706231454, "ROUGE_L": 0.25258799171842644, "CIDEr": 2.605250246750571e-08, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.125, "f": 0.11428571428571428, "fn": 28.0, "numImages": 1.0, "fp": 34.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.3333333333333333, "f": 0.27586206896551724, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image shows a horse and a rider in a field. The horse is brown and has a saddle on its back. The rider is wearing a helmet and boots. In the background, there is a white fence. The horse is walking in the grass."}, "494759": {"image_id": 494759, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2166823008689824, "Bleu_3": 0.18190756402244534, "Bleu_4": 0.13341346641164198, "METEOR": 0.2678542958031059, "ROUGE_L": 0.3934677997337975, "CIDEr": 1.5457809370358467e-06, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two people standing on a beach. They are looking at a dragon kite in the sky. The kite is made of plastic and has a tail. The sky is cloudy and there are some clouds in the background."}, "336937": {"image_id": 336937, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 0.06880010617668034, "Bleu_4": 9.172809483333237e-06, "METEOR": 0.15947486344412276, "ROUGE_L": 0.23091482649842268, "CIDEr": 2.4106112546952177e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This image features a total of 18 sinks in rows. The sinks are white. Each sink has a faucet on the top and a drain on the bottom. Some sinks are facing each other because they are arranged in a row, while others are facing away from each other."}, "157155": {"image_id": 157155, "Bleu_1": 0.16049382715851243, "Bleu_2": 0.07757911135330817, "Bleu_3": 0.04239235108710623, "Bleu_4": 5.590388331019876e-06, "METEOR": 0.13806347962465618, "ROUGE_L": 0.2170818505338078, "CIDEr": 1.3367502463596464e-27, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of four people standing on the sidewalk in front of a building. The people are wearing jeans and hoodies. They are also wearing hats on their heads. They are also wearing black jackets on their bodies. \n\nThere is a horse in front of the building. The horse is wearing a brown blanket. \n\nThere is also a carriage in the scene. The carriage is decorated with a flag. \n\nThe overall scene depicts people standing on the street."}, "243600": {"image_id": 243600, "Bleu_1": 0.24999999999632352, "Bleu_2": 0.22855810195353252, "Bleu_3": 0.19241131387726443, "Bleu_4": 0.15299847984741405, "METEOR": 0.2455609015673183, "ROUGE_L": 0.3147279549718574, "CIDEr": 1.6454943042671645e-19, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2222222222222222, "f": 0.24489795918367346, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a black and white photograph of a library with bookshelves and tables. There are several people sitting at tables. The people are reading books in a library. The people are sitting at a table in front of a bookshelf. The windows are located in the library.\n\nThe image is taken from a book or magazine.\n\nThere are no other objects or elements mentioned in the passage."}, "542147": {"image_id": 542147, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.11624763874063387, "Bleu_3": 0.07281710555786126, "Bleu_4": 1.0322985794503843e-05, "METEOR": 0.13412831096532862, "ROUGE_L": 0.23735408560311286, "CIDEr": 4.64924290426904e-06, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows three buildings. The buildings are not under construction. There is a lot in front of the buildings. There is a scaffolding on one of the buildings. A large helipad is visible on the roof."}, "277227": {"image_id": 277227, "Bleu_1": 0.17741935483584811, "Bleu_2": 0.07626944360167771, "Bleu_3": 0.0459391866706192, "Bleu_4": 6.366847879468056e-06, "METEOR": 0.1523587810178689, "ROUGE_L": 0.15968586387434555, "CIDEr": 8.479459094987241e-18, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows three boats docked in the water. The boats have different colors and patterns. One boat is blue and white, with a blue stripe on the side. Some of the other boats have blue and white stripes, while others have different colors. The pier, made of wood, is visible in the scene. However, there is no railing on the pier."}, "323552": {"image_id": 323552, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.18535150310271878, "Bleu_3": 0.11783047902946191, "Bleu_4": 1.4133420106715872e-05, "METEOR": 0.26861755418463396, "ROUGE_L": 0.2787206266318538, "CIDEr": 2.4508138097662437e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a woman sitting on the floor next to a suitcase. She is wearing a blue shirt and brown pants. She has a backpack on her back and is holding a small bag in her hand. The airport is in the background."}, "319607": {"image_id": 319607, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.23611253443469188, "Bleu_3": 1.117015925187725e-06, "Bleu_4": 2.4449972325028082e-09, "METEOR": 0.18054410000057963, "ROUGE_L": 0.287396937573616, "CIDEr": 4.8282511063262615e-05, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.10526315789473684, "f": 0.0975609756097561, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a street with a red light at the corner. There are people walking on the sidewalk. The bicycles are parked on the sidewalk. The building on the left has a large window. There is no sign in the image."}, "581702": {"image_id": 581702, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.21381869073854032, "Bleu_3": 0.13906381417319807, "Bleu_4": 0.10184169067891133, "METEOR": 0.26867289371043207, "ROUGE_L": 0.32383921799949444, "CIDEr": 1.7153087880409742e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a bird perched on a rock in a garden. The bird has a red head and a black and white body. The bird is looking down at something on the ground. The background is a rocky terrain with some greenery.\n\nThe bird is perched on a rock in a garden."}, "328818": {"image_id": 328818, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.26311740578544657, "Bleu_3": 0.20884713485024017, "Bleu_4": 0.14896301681366347, "METEOR": 0.2493466982721539, "ROUGE_L": 0.34078212290502796, "CIDEr": 1.8014465152615055e-05, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.21428571428571427, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image features a woman sitting on a wooden bench next to a bike rack. The woman is wearing a pink shirt and blue jeans. She is holding a bike helmet in her hand, preparing to put on her shoes."}, "55981": {"image_id": 55981, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.12227087188800603, "Bleu_3": 7.144207399267894e-07, "Bleu_4": 1.7376029391733272e-09, "METEOR": 0.18319971465592738, "ROUGE_L": 0.23720025923525598, "CIDEr": 4.493986176285492e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.06666666666666667, "f": 0.10526315789473685, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a girl standing in front of a staircase. She is holding a suitcase. The girl is wearing a brown sweater and pink jeans. The staircase and railing are not visible in the image. There is no carpet on the floor."}, "385918": {"image_id": 385918, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.24397501823025944, "Bleu_3": 0.15184969791598188, "Bleu_4": 1.8048119765282307e-05, "METEOR": 0.21311967621938657, "ROUGE_L": 0.29901960784313725, "CIDEr": 0.00015865949306991434, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of five people playing frisbee on a green field. They are wearing black and white shirts and black pants. One person is catching a frisbee.\n\nThere are trees in the background."}, "86625": {"image_id": 86625, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.0799063530041829, "Bleu_4": 1.0207315006261666e-05, "METEOR": 0.21889935411825062, "ROUGE_L": 0.26228501228501233, "CIDEr": 1.766997468337715e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a man looking at a refrigerator. The man is wearing a black hoodie and has a surprised expression on his face. The refrigerator has a white door and a white handle. There is no carton of eggs on the counter. The counter does not have a top."}, "87429": {"image_id": 87429, "Bleu_1": 0.30232558138831805, "Bleu_2": 2.6829513838535914e-09, "Bleu_3": 5.599474224723303e-12, "Bleu_4": 2.5739223415532196e-13, "METEOR": 0.1486580212961967, "ROUGE_L": 0.22662538699690402, "CIDEr": 1.7771257675186703e-06, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two buildings with several cars parked in front of them. The buildings are made of brick. A traffic light is in front of building 1. A bus is in front of building 2. There are three windows on each floor."}, "330091": {"image_id": 330091, "Bleu_1": 0.33928571427965565, "Bleu_2": 0.19238759578427378, "Bleu_3": 8.81698546800201e-07, "Bleu_4": 1.8963614854638516e-09, "METEOR": 0.24318434939285477, "ROUGE_L": 0.257867543447628, "CIDEr": 2.788234184421395e-08, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.2857142857142857, "f": 0.3137254901960784, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.46153846153846156, "f": 0.46153846153846156, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows two people engaging in winter sports. One person is skiing down a snowy slope on a snowboard. The other person is playing with a sled. The person skiing down is wearing a red and black jacket, black pants, and purple and blue ski goggles.\n\nThere are no trees or mountains in the scene."}, "491851": {"image_id": 491851, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.2271847336913753, "Bleu_3": 1.2118627329025794e-06, "Bleu_4": 2.8235830417003965e-09, "METEOR": 0.24545399207469448, "ROUGE_L": 0.3266107442441549, "CIDEr": 0.0032072718282526655, "SPICE": {"All": {"pr": 0.08, "re": 0.1111111111111111, "f": 0.09302325581395349, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a desk with a computer, keyboard, mouse, and speakers. There is also a lamp on the desk. The walls are blue. There is a window in the room."}, "203661": {"image_id": 203661, "Bleu_1": 0.17241379310047567, "Bleu_2": 0.12297974198368156, "Bleu_3": 0.10260764179972841, "Bleu_4": 0.07916835232880483, "METEOR": 0.17284611714749254, "ROUGE_L": 0.20885642547363614, "CIDEr": 5.225331230532448e-15, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.27586206896551724, "f": 0.29090909090909095, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a kitchen with a wooden table and chairs. The chairs are made of plastic and wood/metal. There is a stove and an oven on the countertop. A bowl is on the countertop. A bowl of fruit is on the countertop besides the stove and oven. There are three sinks. The floor is made of wood."}, "150875": {"image_id": 150875, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.1587768372028858, "Bleu_3": 0.09141555868773478, "Bleu_4": 1.2430185040655493e-05, "METEOR": 0.1828566150101621, "ROUGE_L": 0.20980223559759242, "CIDEr": 2.067842204192185e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1111111111111111, "f": 0.13636363636363638, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is a photograph of a bench in a park. The bench is made of concrete. There is a plaque on the bench. Bushes are around the bench. There is a flower near the bench."}, "99707": {"image_id": 99707, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.20203050890627616, "Bleu_3": 0.15144863020774949, "Bleu_4": 0.11085800359033553, "METEOR": 0.2775996516602301, "ROUGE_L": 0.3059013163786155, "CIDEr": 2.8610648157833887e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.12903225806451613, "f": 0.16666666666666666, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a person wearing a purple jacket and skiing gear standing next to a sign that reads \"superstar\". The person is holding ski poles and has a smile. The background is a snowy mountain with trees and a blue sky.\n\nThere is no snowboard in the image."}, "124647": {"image_id": 124647, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.05870362244443319, "Bleu_3": 3.9718152379234885e-07, "Bleu_4": 1.0378709071282543e-09, "METEOR": 0.1411921409693798, "ROUGE_L": 0.14244016345592528, "CIDEr": 1.0203188374635474e-13, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.23809523809523808, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows two boys skateboarding on a sidewalk. The boys are wearing helmets and different colored shirts and pants. One boy is wearing a plaid shirt and doing skateboarding, while the other boy is wearing green pants and also doing skateboarding. \n\nThere are no scarves in the scene.\n\nThere are no other people in the scene."}, "62167": {"image_id": 62167, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.07457725404314713, "Bleu_4": 9.591924934151242e-06, "METEOR": 0.19983619101884262, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.9284228583870746e-11, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.2, "f": 0.13636363636363635, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man standing on a grassy field. The man is wearing an orange shirt and gray pants. He is holding a frisbee and is about to throw it. There is a dog around the man, but it is not a labrador retriever. The man is also holding a leash."}, "300221": {"image_id": 300221, "Bleu_1": 0.18181818181542703, "Bleu_2": 0.052888588533987035, "Bleu_3": 3.522475598614246e-07, "Bleu_4": 9.126428539580221e-10, "METEOR": 0.14605181304990952, "ROUGE_L": 0.1490713587487781, "CIDEr": 3.2098421585236985e-20, "SPICE": {"All": {"pr": 0.3, "re": 0.14285714285714285, "f": 0.19354838709677416, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a crate filled with vegetables arranged in it. The crate is placed on a wooden table. There are no vegetables or fruits mentioned in the supplementary information, so there are no carrots, lettuce, apples, oranges, or grapes in the image. However, there is a beet in the image. In the background, there is a building and a vegetable stand in front of it."}, "109537": {"image_id": 109537, "Bleu_1": 0.1874999999941407, "Bleu_2": 2.45934688411173e-09, "Bleu_3": 5.863713930556269e-12, "Bleu_4": 2.8875537785495686e-13, "METEOR": 0.07736163447846403, "ROUGE_L": 0.15775862068965518, "CIDEr": 4.1565212463520355e-05, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.038461538461538464, "f": 0.03636363636363637, "fn": 25.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.06666666666666667, "re": 0.1111111111111111, "f": 0.08333333333333334, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}}, "caption": "The image shows two surfers riding waves on surfboards. The surfers are wearing wetsuits and helmets, and are standing on the boards with their arms outstretched. The waves are large and white."}, "382715": {"image_id": 382715, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.12909944487067912, "Bleu_3": 7.291106321801015e-07, "Bleu_4": 1.7429412599383862e-09, "METEOR": 0.21020484519905885, "ROUGE_L": 0.24646464646464644, "CIDEr": 3.787005617526678e-08, "SPICE": {"All": {"pr": 0.06060606060606061, "re": 0.1, "f": 0.07547169811320756, "fn": 18.0, "numImages": 1.0, "fp": 31.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a person on a skateboard riding down the sidewalk on a sunny day. The person is wearing a black jacket, black pants, and black sneakers. The sidewalk is made of concrete. There are cars parked on the street. The sky is blue."}, "52596": {"image_id": 52596, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.167705098309884, "Bleu_3": 0.12132137515823341, "Bleu_4": 0.08711893742893871, "METEOR": 0.26143556949559504, "ROUGE_L": 0.18778860954335555, "CIDEr": 8.868321357070537e-19, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.16666666666666666, "f": 0.1509433962264151, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a girl holding a piece of pizza. The girl is eating the pizza. She is standing in front of a group of people, but there are no people in the scene. There are no blankets or picnic tables either. The sky is blue and there are trees in the background. The girl is wearing a purple shirt and has a small smile."}, "500718": {"image_id": 500718, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.23611253443469188, "Bleu_3": 0.1407351877211811, "Bleu_4": 0.09194664155137737, "METEOR": 0.18392923954917648, "ROUGE_L": 0.2881241565452092, "CIDEr": 1.2375378148708949e-06, "SPICE": {"All": {"pr": 0.03333333333333333, "re": 0.045454545454545456, "f": 0.03846153846153846, "fn": 21.0, "numImages": 1.0, "fp": 29.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a group of three airplanes parked on the tarmac. The airplanes are painted in different colors and have different designs on their tails. Some of the airplanes have engines on the wings, while others have them on the tails."}, "182240": {"image_id": 182240, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.07587175464144183, "Bleu_4": 9.619833423045096e-06, "METEOR": 0.17247710645775305, "ROUGE_L": 0.1783625730994152, "CIDEr": 1.901799204592881e-12, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2777777777777778, "f": 0.2272727272727273, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of four zebras standing in a field. They are all facing the same direction and appear to be grazing. The ground is dry and cracked, with some small rocks and bushes visible in the scene. The sky is clear and blue, with a few white clouds scattered across it."}, "525083": {"image_id": 525083, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.15849534045439814, "Bleu_3": 0.08295835031586613, "Bleu_4": 1.0734404745305494e-05, "METEOR": 0.20046464504543499, "ROUGE_L": 0.2447178389943835, "CIDEr": 2.6321265912867746e-09, "SPICE": {"All": {"pr": 0.1875, "re": 0.13043478260869565, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a kitchen with wooden floors, white cabinets, and a black stove. There is a dining table and two chairs in the center of the room. The dining table is surrounded by a brown chair. \n\nThere is no window or door in the scene."}, "56821": {"image_id": 56821, "Bleu_1": 0.18604651162358038, "Bleu_2": 0.06655583256240599, "Bleu_3": 4.7628049328452643e-07, "Bleu_4": 1.2819825042675062e-09, "METEOR": 0.18888389004969802, "ROUGE_L": 0.1619110816191108, "CIDEr": 2.0148021111619492e-07, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.25925925925925924, "f": 0.30434782608695654, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image does not show a street. There are two buildings on either side. There are two cars parked on the side of the road. There are four people walking on the sidewalk. The sky is blue. The buildings are made of brick."}, "256367": {"image_id": 256367, "Bleu_1": 0.34782608694139894, "Bleu_2": 0.25147784537359036, "Bleu_3": 1.444087101444629e-06, "Bleu_4": 3.5029790723971512e-09, "METEOR": 0.22616016196907573, "ROUGE_L": 0.39144385026737966, "CIDEr": 0.03375062753486494, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.06896551724137931, "f": 0.07272727272727274, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a train traveling on a railroad track. The train is blue and yellow. The train is traveling on the track."}, "42667": {"image_id": 42667, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.19069251784483274, "Bleu_3": 0.11914512632603338, "Bleu_4": 1.416592339557592e-05, "METEOR": 0.24555067280035786, "ROUGE_L": 0.24887800897592818, "CIDEr": 4.2978580370014924e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a girl sitting on a suitcase. She is looking up at the camera with a smile on her face. She is wearing a green shirt and holding a toy. The background is a dark brown wall with a window in the background."}, "388453": {"image_id": 388453, "Bleu_1": 0.1481481481454047, "Bleu_2": 0.09157370929741424, "Bleu_3": 5.44309719688458e-07, "Bleu_4": 1.3334969390389797e-09, "METEOR": 0.10914583539811629, "ROUGE_L": 0.17115600448933782, "CIDEr": 1.3434386270975376e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.25, "f": 0.22727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a person sitting in a chair in a room. There is a chandelier hanging from the ceiling. \n\nThere are no other people in the scene. There are no tables, chairs, walls, or colors in the scene. There is a window in the room. \n\nAbout 20 people are standing in the room."}, "38118": {"image_id": 38118, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.2708012801434743, "Bleu_3": 0.18543905063492347, "Bleu_4": 0.13048038401891202, "METEOR": 0.2958378284525617, "ROUGE_L": 0.321390937829294, "CIDEr": 0.019901808066586826, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.18518518518518517, "f": 0.20408163265306123, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a person doing skiing on a snowy slope. The person is wearing a red jacket and black pants. The sky is blue."}, "305319": {"image_id": 305319, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.2211119802467678, "ROUGE_L": 0.28018372703412076, "CIDEr": 1.9470871808044286e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 30.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.35714285714285715, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is holding a surfboard and is wearing a black wetsuit. The wave is large and white, with a lot of foam on top. The sky is blue and there are clouds in the background."}, "410484": {"image_id": 410484, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.19674775072873346, "Bleu_3": 0.11010503638215556, "Bleu_4": 1.4776306152176404e-05, "METEOR": 0.18117527138002118, "ROUGE_L": 0.3032311516155758, "CIDEr": 0.01607753177969801, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.1111111111111111, "f": 0.11320754716981132, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two brides and a groom cutting a cake. The cake is blue and white. A star is on top of the cake. The bride is wearing a dress."}, "454252": {"image_id": 454252, "Bleu_1": 0.1710526315766967, "Bleu_2": 0.12635233389327966, "Bleu_3": 0.08650051448193542, "Bleu_4": 9.703609318360453e-06, "METEOR": 0.20736047343604827, "ROUGE_L": 0.21891822609587283, "CIDEr": 9.016192359179273e-26, "SPICE": {"All": {"pr": 0.125, "re": 0.2727272727272727, "f": 0.17142857142857143, "fn": 8.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of nine people standing in front of a barrel of wine. A wine glass is in front of the people. The people are holding glasses. The people are holding wine glasses. The barrel is made of wood stock video footage.\n\nThe room is dimly lit and has a cozy atmosphere. The people are enjoying themselves, sipping wine and engaging in conversation. The overall scene gives off a warm and inviting vibe."}, "245153": {"image_id": 245153, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.22821773228679554, "Bleu_3": 0.1497806431282426, "Bleu_4": 1.829411709689116e-05, "METEOR": 0.2114598888517891, "ROUGE_L": 0.2654482158398608, "CIDEr": 0.00032331904336608814, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.26666666666666666, "f": 0.2105263157894737, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two puffins sitting on top of a grassy hill overlooking a lake. The puffins are sitting on grassy cliffs. The sky is cloudy. There are no trees in the scene."}, "528980": {"image_id": 528980, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.18837162993777626, "Bleu_3": 1.0695743954365786e-06, "Bleu_4": 2.5710986510668226e-09, "METEOR": 0.22430221913521173, "ROUGE_L": 0.2775250227479527, "CIDEr": 0.0015606923559192136, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.16129032258064516, "f": 0.15384615384615385, "fn": 26.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image does not contain a red and white umbrella or a street corner. It shows a city with several buildings in the background. There are cars parked on the street."}, "402118": {"image_id": 402118, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.15569978882944752, "Bleu_3": 0.11112381532950555, "Bleu_4": 0.0716728249212735, "METEOR": 0.2178559299563987, "ROUGE_L": 0.24110671936758893, "CIDEr": 8.949655225298291e-13, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a person doing a trick on a snowboard. The person is wearing a white snowboarding suit and a white helmet. The person is snowboarding down a hill and jumping off a ramp, flying through the air. The background is a mountain range with trees and snow. The sky is clear and blue."}, "303893": {"image_id": 303893, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.18731716231147263, "Bleu_3": 0.09824666233063457, "Bleu_4": 1.2739803480291042e-05, "METEOR": 0.17059630786511626, "ROUGE_L": 0.2347959969207082, "CIDEr": 3.267598132761537e-05, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.29411764705882354, "f": 0.27777777777777773, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two children sitting on the ground in a park. One of the children is holding a bowl filled with a sandwich. The other child is holding a spoon. Both children are wearing blue and white shirts."}, "491836": {"image_id": 491836, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.21573723181113055, "Bleu_3": 0.1593617613384745, "Bleu_4": 0.11580903993958114, "METEOR": 0.23464474625658097, "ROUGE_L": 0.31282051282051276, "CIDEr": 1.814629549609117e-09, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.21212121212121213, "f": 0.29166666666666663, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.07142857142857142, "f": 0.11111111111111112, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a body of water with a small boat in the distance. The sky is clear and blue, with some clouds in the distance. There are trees on the shore and a small island in the distance. The water is calm and there are no waves."}, "456816": {"image_id": 456816, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.19577417125493551, "Bleu_3": 0.12421105892331817, "Bleu_4": 1.4888606314394972e-05, "METEOR": 0.20581816676006842, "ROUGE_L": 0.2543786488740617, "CIDEr": 8.057021482303887e-07, "SPICE": {"All": {"pr": 0.3125, "re": 0.23809523809523808, "f": 0.27027027027027023, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a plate with a doughnut on it. The doughnut is covered in powdered sugar and does not have a hole in the middle. There is a fork on the plate. The background is a wooden table without a tablecloth."}, "495825": {"image_id": 495825, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.15182109665359528, "Bleu_3": 0.07942711818418766, "Bleu_4": 1.0272436745896128e-05, "METEOR": 0.14732613912179587, "ROUGE_L": 0.23565121412803533, "CIDEr": 2.515472218115419e-07, "SPICE": {"All": {"pr": 0.3125, "re": 0.1724137931034483, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a cow grazing in a green field with mountains in the background. The sky is a bright blue with fluffy white clouds. The grass is tall and green. There are no trees in the field. The fence is made of wooden posts and barbed wire."}, "174740": {"image_id": 174740, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.18257418583143972, "Bleu_3": 0.11080794149542911, "Bleu_4": 1.2975313384213989e-05, "METEOR": 0.19481660515649737, "ROUGE_L": 0.21441124780316342, "CIDEr": 2.5769382140556187e-09, "SPICE": {"All": {"pr": 0.0625, "re": 0.03333333333333333, "f": 0.04347826086956522, "fn": 29.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows three boxes with two doughnuts inside, sitting on top of a wooden table. A bottle of soda is next to one of the boxes. The table is made of wood and has a rough texture. The doughnuts are covered in powdered sugar and appear to be freshly baked."}, "507037": {"image_id": 507037, "Bleu_1": 0.382352941165225, "Bleu_2": 0.28478969316957436, "Bleu_3": 0.19664063617763064, "Bleu_4": 2.2254330294642257e-05, "METEOR": 0.3462417212367826, "ROUGE_L": 0.41567291311754684, "CIDEr": 0.000447345683350891, "SPICE": {"All": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of 17 people standing outside a building. Some of the people are holding bicycles. The building appears to be a church with a large cross on top of it."}, "57323": {"image_id": 57323, "Bleu_1": 0.16091954022803542, "Bleu_2": 0.1297706322725313, "Bleu_3": 0.09254038506430413, "Bleu_4": 0.05542154840062338, "METEOR": 0.19510450984010475, "ROUGE_L": 0.1708683473389356, "CIDEr": 6.107986939549555e-38, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of three people riding motorcycles on a street. The people are wearing helmets and riding motorcycles. Some of the people are riding a green motorcycle, while others are riding a red motorcycle. \n\nThere are five motorcycles in total. The motorcycles are on the street. \n\nThere are cars parked on the side of the road, and there are also people walking on the sidewalk. The overall atmosphere of the scene is lively and energetic, as the people ride their motorcycles down the street."}, "516038": {"image_id": 516038, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.27263927062982823, "Bleu_3": 0.15489911707162277, "Bleu_4": 0.09880309634326721, "METEOR": 0.2623310425946789, "ROUGE_L": 0.31077147016011636, "CIDEr": 4.326793916857971e-07, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1, "f": 0.11538461538461538, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a baseball game in progress on a green field. There is a player batting, while two catchers are crouching down to catch the ball. The catcher is currently catching a ball. The other players are standing on the field."}, "433915": {"image_id": 433915, "Bleu_1": 0.1525423728787705, "Bleu_2": 0.08882636283768905, "Bleu_3": 5.172926420747347e-07, "Bleu_4": 1.2538778168305696e-09, "METEOR": 0.18502162250216306, "ROUGE_L": 0.18836850231600616, "CIDEr": 2.4261688324395376e-14, "SPICE": {"All": {"pr": 0.1, "re": 0.17647058823529413, "f": 0.12765957446808512, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image is a television screen showing a man and a woman in suits standing in front of a white wall. The man is wearing a suit and a blue tie. The woman is wearing a blue dress. They are both looking directly at the camera.\n\nThe image is in black and white and appears to be a still."}, "17899": {"image_id": 17899, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2608202654732723, "Bleu_3": 0.16314309133869306, "Bleu_4": 1.7528189410229203e-05, "METEOR": 0.20074779007263285, "ROUGE_L": 0.2576946288473144, "CIDEr": 1.2865934385461033e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.12903225806451613, "f": 0.17777777777777778, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a woman in a pink apron standing at a table with a tray of baked goods in front of her. She is using a rolling pin to roll out dough on a surface. There are several other baked goods on the table, including cookies and muffins."}, "298252": {"image_id": 298252, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.26846242207825327, "Bleu_3": 0.2175486149850356, "Bleu_4": 0.17361123498626596, "METEOR": 0.2701792730439055, "ROUGE_L": 0.23735408560311286, "CIDEr": 4.97403436313246e-05, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.38461538461538464, "f": 0.24390243902439027, "fn": 8.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a variety of donuts on display in the bakery. The donuts include glazed, frosted, snickerdoodle, sourdough, and more. They are arranged on trays in the display case.\n\nThe image is taken in a bakery."}, "222370": {"image_id": 222370, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.1184508853673932, "Bleu_3": 0.06683330244266764, "Bleu_4": 8.975429359940367e-06, "METEOR": 0.21305823880957153, "ROUGE_L": 0.19690122659780504, "CIDEr": 9.127390515841735e-11, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.34782608695652173, "f": 0.34782608695652173, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a group of three people riding skateboards, walking down the street, and riding a motorcycle. The street is like a narrow street, with buildings on either side. The buildings are made of concrete. The people are wearing turbans.\n\nThere are no cars parked on the street."}, "374448": {"image_id": 374448, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.12666009927244304, "Bleu_3": 7.944072943886587e-07, "Bleu_4": 2.0053583652894944e-09, "METEOR": 0.1697998247118594, "ROUGE_L": 0.2633093525179856, "CIDEr": 0.00028695463780347216, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.15151515151515152, "f": 0.1694915254237288, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a room with a high ceiling made of wood. There are two tables and six chairs set up in the room. The room is decorated with gold vases on the ceiling."}, "181278": {"image_id": 181278, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.07229440390503974, "Bleu_3": 5.074381600450152e-07, "Bleu_4": 1.3529171154640911e-09, "METEOR": 0.1469395496214688, "ROUGE_L": 0.17304964539007092, "CIDEr": 1.06243833073208e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of four boys playing baseball on a field. They are wearing blue and white uniforms with the number 1 on the back. One of the boys is throwing a ball. \n\nThere is no tree in the scene."}, "373789": {"image_id": 373789, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.38056219754078957, "Bleu_3": 0.2745265912099932, "Bleu_4": 0.19785857229739154, "METEOR": 0.26406985843666203, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.0730901229616038, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2857142857142857, "f": 0.2580645161290323, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a plate with two pieces of bread on it. The plate is on a countertop in a kitchen. The toast has a slice of bread on it."}, "251124": {"image_id": 251124, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.18233123936852927, "Bleu_3": 8.974042296560842e-07, "Bleu_4": 2.0018796078270936e-09, "METEOR": 0.22177852070896092, "ROUGE_L": 0.29901960784313725, "CIDEr": 6.966347632684005e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bicycle parked on a bench in front of a city skyline at night. The skyline is made up of buildings with lights on them. The bicycle is black and does not have a red light on the front. The bench is made of wood."}, "162249": {"image_id": 162249, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.1276351315918384, "Bleu_3": 0.08398516678948022, "Bleu_4": 0.0575510831581648, "METEOR": 0.22138852470696657, "ROUGE_L": 0.23448654585392636, "CIDEr": 1.316180394558128e-13, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is a bathroom with a large tub in the center of the room. There is a sink and toilet in the corner of the room. The walls are not visible in the image. There are two windows on either side of the room. The floor is made of hardwood. There is no rug in the image."}, "551908": {"image_id": 551908, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.253320198544886, "Bleu_3": 0.15888145887773164, "Bleu_4": 0.10665089166023431, "METEOR": 0.2879747361590602, "ROUGE_L": 0.4138599466925127, "CIDEr": 0.0035157791704473786, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a plate of food with a piece of fish, potatoes, and broccoli. The fish is white. The color of the broccoli is green. The potatoes are not visible in the image."}, "366367": {"image_id": 366367, "Bleu_1": 0.517241379292509, "Bleu_2": 0.42980119128085426, "Bleu_3": 0.36315316639954087, "Bleu_4": 0.29298071682481264, "METEOR": 0.31223466190521665, "ROUGE_L": 0.40705433746425174, "CIDEr": 0.012994135522986422, "SPICE": {"All": {"pr": 0.125, "re": 0.06896551724137931, "f": 0.08888888888888889, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a young girl standing in front of a wall. She is holding a cell phone and looking at it. The girl is wearing a pink sweater."}, "231343": {"image_id": 231343, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.2504897164290992, "Bleu_3": 0.1856883150846676, "Bleu_4": 0.14143550190666943, "METEOR": 0.2583414693961532, "ROUGE_L": 0.26116207951070336, "CIDEr": 4.709111347837919e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.4166666666666667, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and wearing a gray uniform. The field is made of grass. The sky is clear.\n\nThere are no other players in the scene.\n\nThere are spectators in the stands.\n\nThere are no trees in the scene."}, "236290": {"image_id": 236290, "Bleu_1": 0.15151515151285586, "Bleu_2": 0.09656090991557924, "Bleu_3": 0.052618796224205545, "Bleu_4": 6.9345860869222e-06, "METEOR": 0.14285503185035014, "ROUGE_L": 0.15450861195542046, "CIDEr": 1.4114385198888426e-20, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.13793103448275862, "f": 0.13793103448275862, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two men standing on a staircase. One man is holding a suitcase and looking at it, while the other man is holding a cigarette and looking at a woman. The staircase is made of metal and has a railing on either side. The man holding the suitcase is wearing a black and white suit, while the other man is not wearing a suit."}, "189095": {"image_id": 189095, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1520747661648476, "Bleu_3": 0.08010026144994811, "Bleu_4": 1.0395904495718301e-05, "METEOR": 0.18237333387746016, "ROUGE_L": 0.22775357809583074, "CIDEr": 5.051812045825696e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two bears standing on a rock in a clearing surrounded by trees and rocks. The bears are brown in color. One bear is licking the other bear's ear. The bears are standing in a zoo. There are no other animals in the image."}, "426546": {"image_id": 426546, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.22312917498915605, "Bleu_3": 0.14037186543654434, "Bleu_4": 0.09428509488367463, "METEOR": 0.22968562605931478, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.0003709012675667721, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a plate of food with two sandwiches, fries, and a side of coleslaw. The sandwiches are made with meat and cheese. The fries are crispy and golden. The coleslaw is a creamy, tangy side dish."}, "114119": {"image_id": 114119, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.17875929966553875, "Bleu_3": 8.344331191885145e-07, "Bleu_4": 1.8111115905593795e-09, "METEOR": 0.22304694185109136, "ROUGE_L": 0.24018449769377878, "CIDEr": 9.423672489782092e-14, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.14285714285714285, "f": 0.15789473684210528, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two cats sleeping on a shelf. One cat is lying on its side, while the other cat is not. There is a clock on the wall behind the cats. A small white box is next to the clock. The numbers 10 and 2 are visible on the clock. The cats' eyes are not open."}, "290828": {"image_id": 290828, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.21997067252504504, "Bleu_3": 0.14775633223339277, "Bleu_4": 0.10269754859549582, "METEOR": 0.19832916139960843, "ROUGE_L": 0.3078734858681023, "CIDEr": 0.0020040004320372733, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.29411764705882354, "f": 0.27777777777777773, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing on a fence. The giraffe is eating a tree. There are people standing on a balcony. The people are looking at a reflection in the glass."}, "64103": {"image_id": 64103, "Bleu_1": 0.1694915254208561, "Bleu_2": 0.12087736925536453, "Bleu_3": 0.08003532503880463, "Bleu_4": 9.781698624583785e-06, "METEOR": 0.22794388207272753, "ROUGE_L": 0.17300056721497448, "CIDEr": 1.2259173265741428e-16, "SPICE": {"All": {"pr": 0.24, "re": 0.25, "f": 0.24489795918367346, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows two birds swimming in the water. One bird is looking at a fish, while the other bird is looking at the other bird. The birds have long beaks. The water is calm and there are no other objects in the image. The birds are black and white. The sky is blue and there are no clouds."}, "194756": {"image_id": 194756, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.1663895814060149, "Bleu_3": 8.77316169724088e-07, "Bleu_4": 2.026992316985924e-09, "METEOR": 0.18921039877558996, "ROUGE_L": 0.2902787219578518, "CIDEr": 3.153335415088584e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a boat with a blue hull and white sides, tied up on the side of a river. People are walking on the sidewalk.\n\nThe boat is tied up on the side of the river. People are walking on the sidewalk."}, "412879": {"image_id": 412879, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.19999999999603923, "Bleu_3": 0.11775100856360317, "Bleu_4": 0.07636830779166373, "METEOR": 0.2618723571076195, "ROUGE_L": 0.26116207951070336, "CIDEr": 1.6831321882148826e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a woman playing tennis on a tennis court. She is playing with a racket and there is no ball in the scene. The woman is wearing a black top and black pants. Her hair is styled long and straight. The background is a green field with no trees."}, "51741": {"image_id": 51741, "Bleu_1": 0.517241379292509, "Bleu_2": 0.3329225712021714, "Bleu_3": 1.601182759775103e-06, "Bleu_4": 3.544764127114608e-09, "METEOR": 0.2809655679943166, "ROUGE_L": 0.3935483870967742, "CIDEr": 0.01740538593956148, "SPICE": {"All": {"pr": 0.24, "re": 0.46153846153846156, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a toilet, sink, and wood walls. The floor is made of tile. There is a window on the left side of the room."}, "111448": {"image_id": 111448, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.13245323570415993, "Bleu_3": 6.832623415157836e-07, "Bleu_4": 1.5589858513434585e-09, "METEOR": 0.16587674771125546, "ROUGE_L": 0.18973561430793154, "CIDEr": 4.2467953989179496e-13, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a horse with two jockeys on a racetrack. The horse is wearing a jockey's hat. The jockey is riding the horse. The jockey is wearing a black and white striped shirt and black pants. There are people in the background watching the race.\n\nThere is no racetrack, blanket, or saddle in the scene."}, "255279": {"image_id": 255279, "Bleu_1": 0.17543859648815024, "Bleu_2": 0.1371021242743437, "Bleu_3": 0.06991578304852385, "Bleu_4": 8.919345345892188e-06, "METEOR": 0.1984754885673611, "ROUGE_L": 0.24413950829045164, "CIDEr": 5.5784110549188145e-14, "SPICE": {"All": {"pr": 0.1875, "re": 0.1, "f": 0.13043478260869568, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a black motorcycle parked on the side of a road. There is a black helmet on the handlebars of the motorcycle. The rider is wearing a black helmet and a green and black jacket. \n\nThere is a car parked in the background. The image is taken in a residential area with trees and houses."}, "243626": {"image_id": 243626, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.21060588478687045, "Bleu_3": 1.139217330716798e-06, "Bleu_4": 2.6721168024330813e-09, "METEOR": 0.21182337414216276, "ROUGE_L": 0.2970779220779221, "CIDEr": 0.0031587520534924465, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.22727272727272727, "f": 0.25, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a plate of food with a piece of meat, beans, and slices. The meat is well done. The orange slices are grilled. The plate is on a green tablecloth."}, "171255": {"image_id": 171255, "Bleu_1": 0.4054054053944486, "Bleu_2": 0.2599376224478953, "Bleu_3": 0.15687969824156975, "Bleu_4": 0.10322985794503843, "METEOR": 0.2321147655754191, "ROUGE_L": 0.2848249027237354, "CIDEr": 0.00022864890996974455, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a person standing on the beach, looking out at the ocean. There are four horses standing on the beach. The beach is lined with palm trees and there is a beach umbrella set up."}, "41119": {"image_id": 41119, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.269724531227751, "Bleu_3": 0.1409145534273607, "Bleu_4": 1.8290765605004157e-05, "METEOR": 0.21433151184317437, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.014408184407047947, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.2, "f": 0.15789473684210528, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a traffic light hanging from a pole in the middle of a street. The traffic light is green. It is safe to cross the street."}}}