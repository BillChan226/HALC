{"overall": {"Bleu_1": 0.263935665512607, "Bleu_2": 0.1764102204317475, "Bleu_3": 0.11280850592372751, "Bleu_4": 0.07166432026103316, "METEOR": 0.21538223753130473, "ROUGE_L": 0.26963918933421366, "CIDEr": 0.00657375535256146, "SPICE": 0.1938710980064905}, "imgToEval": {"244575": {"image_id": 244575, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.20134681655868997, "Bleu_3": 0.13231746201962133, "Bleu_4": 0.09085380956494306, "METEOR": 0.2005209975506014, "ROUGE_L": 0.28089025326170375, "CIDEr": 4.441257073910053e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.19047619047619047, "f": 0.1951219512195122, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows two horses standing in the woods. The horses are brown. They do not have long manes or long tails. The horses are surrounded by trees. The trees in the clearing are tall and green."}, "464737": {"image_id": 464737, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.19802950859148932, "Bleu_3": 0.14639174990113343, "Bleu_4": 0.08945166560686846, "METEOR": 0.22823806376493364, "ROUGE_L": 0.26293103448275856, "CIDEr": 9.566547866348515e-10, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2608695652173913, "f": 0.28571428571428575, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two zebras standing in a grassy field. The zebras are black and white with white stripes on their backs. In the background, there is an ostrich which is black and white. The image is taken from a bird's eye view.\n\nThere are no other animals in the scene."}, "284379": {"image_id": 284379, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.12521758066643465, "Bleu_3": 7.318524682825048e-07, "Bleu_4": 1.7805390573409366e-09, "METEOR": 0.16875463442569488, "ROUGE_L": 0.21631205673758863, "CIDEr": 1.0480318139023645e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23076923076923078, "f": 0.2033898305084746, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.46153846153846156, "f": 0.4444444444444445, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a boy riding a surfboard in the ocean. The boy is wearing a black shirt and is laying on the surfboard. He is also wearing a life jacket for safety.\n\nThere are no waves or shore in the scene."}, "252940": {"image_id": 252940, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.10024266962117512, "Bleu_4": 1.230060008283069e-05, "METEOR": 0.2333215890630258, "ROUGE_L": 0.34837235865219873, "CIDEr": 7.306248874553433e-05, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.043478260869565216, "f": 0.0425531914893617, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a man and a woman standing under an umbrella in a park. The man is wearing a suit. The woman is wearing a black dress. They are both holding an umbrella. They are looking at each other.\n\nThere is no tree in the scene."}, "101068": {"image_id": 101068, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.17149858513911254, "Bleu_3": 0.08435451529716312, "Bleu_4": 1.057477026987749e-05, "METEOR": 0.2620514054561517, "ROUGE_L": 0.29204069419509276, "CIDEr": 4.855274516566139e-11, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.2222222222222222, "f": 0.3, "fn": 21.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.8333333333333334, "re": 0.45454545454545453, "f": 0.5882352941176471, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows two men in baseball uniforms. They are both holding a baseball bat. One of the men is hitting a baseball, while the other is playing baseball. They are standing on the ground and throwing water on it. \n\nThere is no baseball field or other players in the scene."}, "455261": {"image_id": 455261, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.14062009564344036, "Bleu_3": 0.06985898340781152, "Bleu_4": 8.794233288972274e-06, "METEOR": 0.23036867333407293, "ROUGE_L": 0.2667916276163699, "CIDEr": 2.579084346160465e-14, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13043478260869565, "f": 0.15, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows two people riding different vehicles. One person is riding a bike and the other person is riding a motorcycle. The person riding the bike is wearing a red shirt and the person riding the motorcycle is wearing a helmet. The image does not show a road or handlebars. There are trees on either side of the scene."}, "107964": {"image_id": 107964, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.12903971808302675, "Bleu_3": 0.09045267833662955, "Bleu_4": 0.06404023311330644, "METEOR": 0.1553886431403833, "ROUGE_L": 0.20346897931954633, "CIDEr": 2.178985846965522e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a skateboarder performing a trick on a halfpipe. The skateboarder is jumping off a ramp. The skateboarder is wearing a black shirt and jeans. The halfpipe is made of concrete. The surface of the halfpipe is smooth.\n\nThere is no sunset in the image."}, "292363": {"image_id": 292363, "Bleu_1": 0.382352941165225, "Bleu_2": 0.34038878891983904, "Bleu_3": 0.2937420934441515, "Bleu_4": 0.23913834187492314, "METEOR": 0.33486228494904574, "ROUGE_L": 0.4537190082644628, "CIDEr": 0.0005660074883611068, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.18518518518518517, "f": 0.20408163265306123, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a slice of pizza on a plate with a fork on the side. The pizza is topped with cheese and onions. The plate is on a table with a blue tablecloth."}, "233848": {"image_id": 233848, "Bleu_1": 0.1690140845046618, "Bleu_2": 0.08510852345318905, "Bleu_3": 0.047173598575917894, "Bleu_4": 6.268260360115882e-06, "METEOR": 0.15770239606982692, "ROUGE_L": 0.2355789860847177, "CIDEr": 4.580407684789604e-18, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.20833333333333334, "f": 0.24390243902439027, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a small town with several buildings, including a church, a school, a post office, and a general store. The buildings are made of wood. There are also several houses in the town, including old log houses and old wooden buildings. The town is surrounded by a fence and there is a small flagpole in the center. The sky is cloudy and there are some trees in the background."}, "480179": {"image_id": 480179, "Bleu_1": 0.25806451612070763, "Bleu_2": 0.13116516715248897, "Bleu_3": 0.0840258688823375, "Bleu_4": 1.2064803451993357e-05, "METEOR": 0.1491181053176097, "ROUGE_L": 0.25269262634631323, "CIDEr": 0.0027751900895045794, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.1111111111111111, "f": 0.10810810810810811, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a pile of suitcases on the sidewalk. The suitcases are made of metal and have a rusty appearance. Some of the suitcases are open, while others are closed."}, "499727": {"image_id": 499727, "Bleu_1": 0.3999999999800001, "Bleu_2": 0.2051956704065011, "Bleu_3": 0.13274595419765597, "Bleu_4": 1.925988722733138e-05, "METEOR": 0.17741740034857673, "ROUGE_L": 0.34040178571428575, "CIDEr": 0.09986927298726826, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.05555555555555555, "f": 0.05405405405405406, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a person flying a kite in the sky. The kite is flying. The sky is not clear."}, "226220": {"image_id": 226220, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.20797761524680117, "Bleu_3": 0.1908516373600709, "Bleu_4": 0.17246689923059094, "METEOR": 0.3173237505559564, "ROUGE_L": 0.3033149171270718, "CIDEr": 2.4891431329317075e-14, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.11538461538461539, "f": 0.12244897959183673, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a cat sleeping on the arm of a couch in a living room. The cat is lying on its side with its head resting on the arm of the couch. The cat's eyes are closed and its paws are not tucked under its body. The room is well lit with natural light coming in."}, "375211": {"image_id": 375211, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.12508887309711966, "Bleu_3": 7.574924114606953e-07, "Bleu_4": 1.8772266184831244e-09, "METEOR": 0.14084507042253522, "ROUGE_L": 0.23282442748091606, "CIDEr": 4.5297258744716776e-06, "SPICE": {"All": {"pr": 0.08, "re": 0.1111111111111111, "f": 0.09302325581395349, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bowl of red sauce. The sauce is made with tomato sauce, garlic, and olive oil. There is no spoon in the image. The bowl is made of ceramic and does not have a handle."}, "534669": {"image_id": 534669, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.08681823924888467, "Bleu_4": 1.1239895308238822e-05, "METEOR": 0.21559638307219128, "ROUGE_L": 0.25702247191011235, "CIDEr": 5.455163020531161e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a large airplane parked on the tarmac at an airport. The plane has a white and blue paint job with red and white stripes on the tail. It is parked next to a large building with a sign that reads \"m5\"."}, "568425": {"image_id": 568425, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.14882336590863374, "Bleu_3": 0.11746087033063704, "Bleu_4": 0.07978199887125366, "METEOR": 0.19939184129149123, "ROUGE_L": 0.2576376179079263, "CIDEr": 1.0120190627256833e-07, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a stop sign on the side of the road. The sign has a red and white background. The words \"stop\" are written in black letters. The sign is surrounded by a blue background. There is a house in the background."}, "146541": {"image_id": 146541, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.16695677422191285, "Bleu_3": 8.865761273541133e-07, "Bleu_4": 2.0559894081168643e-09, "METEOR": 0.1556568826170604, "ROUGE_L": 0.25957446808510637, "CIDEr": 1.1452108469895594e-06, "SPICE": {"All": {"pr": 0.10256410256410256, "re": 0.17391304347826086, "f": 0.12903225806451615, "fn": 19.0, "numImages": 1.0, "fp": 35.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.2727272727272727, "f": 0.21428571428571427, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image shows a zebra lying on the ground in the shade of a tree. The zebra has a long mane and stripes on its back. The zebra is not looking up at the sky. The image is taken in a zoo."}, "240323": {"image_id": 240323, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.2442581240031167, "ROUGE_L": 0.3057644110275689, "CIDEr": 1.4104266725858414e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.16666666666666666, "f": 0.13043478260869565, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a plate with a slice of turkey, carrots, and an orange on it. The plate is on a table with a white background. The turkey is sliced in half. There are carrot sticks on the side of the plate. The orange is sliced in half."}, "343954": {"image_id": 343954, "Bleu_1": 0.18309859154671693, "Bleu_2": 0.13531392816118423, "Bleu_3": 0.10200746806736341, "Bleu_4": 0.0628560011180448, "METEOR": 0.2445029993716317, "ROUGE_L": 0.2719572001783326, "CIDEr": 9.660501686085551e-22, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.28125, "f": 0.2432432432432432, "fn": 23.0, "numImages": 1.0, "fp": 33.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6153846153846154, "f": 0.4848484848484849, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}}, "caption": "The image shows a group of four people standing on a hillside, looking up at a kite flying in the sky. The people are flying a kite. The people are looking at a kite. The people are looking up at a kite. The people are flying a kite. The people are dressed in casual clothing. The kite is made of blue and pink fabric. The tail of the kite is wagging."}, "359203": {"image_id": 359203, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.191273013914278, "Bleu_3": 0.097892089462343, "Bleu_4": 1.2534724690400046e-05, "METEOR": 0.2633611214281405, "ROUGE_L": 0.26703633445206476, "CIDEr": 5.138775085602795e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.2608695652173913, "f": 0.21818181818181817, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a bench made of wood in front of a stone building. The building appears to be a church and has a lot of windows. The bench is old and has a lot of wear and tear on it."}, "496541": {"image_id": 496541, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.16816819849581244, "Bleu_3": 0.08270007684490462, "Bleu_4": 1.0365265119381272e-05, "METEOR": 0.223223937677983, "ROUGE_L": 0.25722891566265055, "CIDEr": 2.1118260534885936e-11, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a sheep and two lambs standing in a barn. The sheep is brown and white, with a black and white face. The lambs are black and white, with white faces. The barn is made of wood and has a wooden roof. There are bales of hay in the background."}, "499835": {"image_id": 499835, "Bleu_1": 0.2075471698074048, "Bleu_2": 1.9978217455490674e-09, "Bleu_3": 4.2774121488863e-12, "Bleu_4": 1.9890391110390992e-13, "METEOR": 0.12290502793296088, "ROUGE_L": 0.11097634930260766, "CIDEr": 2.0123829983199017e-12, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.2222222222222222, "f": 0.14457831325301204, "fn": 21.0, "numImages": 1.0, "fp": 50.0, "tp": 6.0}, "Relation": {"pr": 0.038461538461538464, "re": 0.09090909090909091, "f": 0.05405405405405406, "fn": 10.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.45454545454545453, "f": 0.3703703703703703, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a black truck parked on the side of a road during the night. The truck has a logo on its side. There are buildings in the background, but they are not visible due to the darkness.\n\nThe image is taken at night, and there are no streetlights in the scene."}, "258388": {"image_id": 258388, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.0902516670662263, "Bleu_3": 5.290733975849901e-07, "Bleu_4": 1.2868813412039973e-09, "METEOR": 0.1096240734843126, "ROUGE_L": 0.1812778603268945, "CIDEr": 3.117030026302146e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.13793103448275862, "f": 0.15384615384615385, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows three people standing in a room. Two of the people are holding skateboards. One person is holding a lighter. \n\nThe room has exposed brick walls and a high ceiling. There is a skateboard ramp in the background, and a box can be seen as well.\n\nThere is no warehouse or garage in the scene."}, "772": {"image_id": 772, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.21573723181113055, "Bleu_3": 0.10039161882933353, "Bleu_4": 1.2245315087875368e-05, "METEOR": 0.22514641702118246, "ROUGE_L": 0.20497311827956988, "CIDEr": 5.346891386033324e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.22727272727272727, "f": 0.17543859649122806, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two sheep standing in a field. The sheep have white and brown patches on their wool. They are standing on grass and looking at a fence. The fence is orange and made of orange ropes. There is a sign on the fence that says \"Sheep\"."}, "563702": {"image_id": 563702, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.17230672835218738, "Bleu_3": 0.09292535942640182, "Bleu_4": 1.2218701690392882e-05, "METEOR": 0.1694447024133051, "ROUGE_L": 0.14489311163895485, "CIDEr": 3.927117021678778e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features four fire trucks parked on the side of the road. There are several firefighters standing around the trucks. The firefighters are wearing black uniforms and coats. \n\nThere are no other trucks or pants in the scene.\n\n"}, "346275": {"image_id": 346275, "Bleu_1": 0.30952380951644, "Bleu_2": 0.12287685874511865, "Bleu_3": 7.227033533137168e-07, "Bleu_4": 1.7638185291549245e-09, "METEOR": 0.22544204862116804, "ROUGE_L": 0.20580296896086367, "CIDEr": 4.022082522832858e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.11538461538461539, "f": 0.14634146341463417, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a person jumping off a black skateboard on a ramp. The person is wearing a white shirt and jeans. The ramp is made of concrete and has a ledge on the side. There are two trees in the scene."}, "302222": {"image_id": 302222, "Bleu_1": 0.333333333325926, "Bleu_2": 0.23028309323074364, "Bleu_3": 0.17023095994636145, "Bleu_4": 0.10410380146216557, "METEOR": 0.260585885192444, "ROUGE_L": 0.28073635765943455, "CIDEr": 1.1524432554011647e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.17857142857142858, "f": 0.20833333333333331, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of six people sitting on a bench in a public space. The people are wearing hats and sunglasses. The benches are made of wood and have umbrellas on top of them. \n\nThere are no trees or buildings in the scene."}, "334327": {"image_id": 334327, "Bleu_1": 0.382352941165225, "Bleu_2": 0.3229211588918931, "Bleu_3": 0.2535153985740639, "Bleu_4": 0.19927056304614166, "METEOR": 0.2820321521053163, "ROUGE_L": 0.3426966292134831, "CIDEr": 0.0004741403099536896, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.15625, "f": 0.1639344262295082, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two tennis players hitting a tennis ball with a racket on a tennis court. The players are wearing a red shirt and blue shorts. The ball is flying through the air."}, "21711": {"image_id": 21711, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.13398285197459078, "Bleu_4": 0.08598520764469421, "METEOR": 0.21822707955593285, "ROUGE_L": 0.2781758957654723, "CIDEr": 7.831613513041963e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of two people riding motorcycles on a road. The people are wearing helmets and riding gear. One person is holding a frisbee and the other person is holding a snowboard. \n\nIn the background, there are trees and a car in the distance."}, "146155": {"image_id": 146155, "Bleu_1": 0.0937499999992676, "Bleu_2": 0.047059185384992805, "Bleu_3": 0.025999964501225555, "Bleu_4": 3.443515665144235e-06, "METEOR": 0.12863342094969313, "ROUGE_L": 0.10449977158519871, "CIDEr": 1.0658550493515237e-81, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2916666666666667, "f": 0.27999999999999997, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows three people standing at a bar in a restaurant. They are all holding glasses of wine. The people are wearing casual clothing. The bar has a wooden counter. There is a man in a suit behind the counter. \n\nThere are 31 bottles behind the counter.\n\nThere are 39 glasses of wine on the counter.\n\nThere are 31 bottles behind the counter.\n\nThere are 3 people standing at the bar. They are all drinking. \n\nThere are 2 pieces of clothing on the counter.\n\nThere are 39 glasses of wine on the counter.\n\nThere are 31 bottles behind the counter.\n\nThere are 3 people standing at the bar. They are all drinking. \n\nThere are 2 pieces of clothing on the counter.\n\nThere are 39 glasses of wine"}, "507187": {"image_id": 507187, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.1463850109381557, "Bleu_3": 0.08573762202818366, "Bleu_4": 1.1755743200566939e-05, "METEOR": 0.19891736687686679, "ROUGE_L": 0.2420634920634921, "CIDEr": 1.3409788403734502e-05, "SPICE": {"All": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of seven people standing around a green motorcycle. The motorcycle is green and white. The motorcycle has a white seat and a silver engine. The people are looking at the motorcycle."}, "328352": {"image_id": 328352, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.14401064146758893, "Bleu_3": 0.0939614522123186, "Bleu_4": 0.06414506805775248, "METEOR": 0.19724889670639265, "ROUGE_L": 0.2760180995475113, "CIDEr": 1.9007900929204606e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.10714285714285714, "f": 0.15, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person sitting on a bench in front of a body of water. The person is dressed in a green shirt. They are looking out at a train station. There is a boat in the water. In the background, there is a mountain. The sky is clear and blue."}, "92488": {"image_id": 92488, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1923483450237976, "Bleu_3": 0.0958611289126843, "Bleu_4": 1.2106983211839111e-05, "METEOR": 0.19757111170058184, "ROUGE_L": 0.20890410958904113, "CIDEr": 3.195515788909516e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.13043478260869565, "f": 0.1764705882352941, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.21428571428571427, "f": 0.3157894736842105, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows two buildings on either side of a street. The buildings are made of glass and stone. The first building has a tall and skinny design, while the second building features a large clock. In the distance, there is a clock tower."}, "256657": {"image_id": 256657, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.20100756304815393, "Bleu_3": 0.13175185157163616, "Bleu_4": 0.08143605172498537, "METEOR": 0.29365965255385224, "ROUGE_L": 0.3099943534726144, "CIDEr": 7.311703705591833e-12, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.5384615384615384, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.8333333333333334, "f": 0.5882352941176471, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a dog playing fetch with a frisbee on a grassy field. The dog is running towards the camera with the frisbee in its mouth. The field is surrounded by trees and a fence. The sky is clear and blue, with some clouds in the distance. The grass is green and well maintained."}, "560993": {"image_id": 560993, "Bleu_1": 0.333333333325926, "Bleu_2": 0.2611164839276783, "Bleu_3": 0.1851058047231149, "Bleu_4": 0.13182877145591065, "METEOR": 0.24472571211684746, "ROUGE_L": 0.2840984697272122, "CIDEr": 2.3245528011059872e-07, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.11538461538461539, "f": 0.0967741935483871, "fn": 23.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2727272727272727, "f": 0.23076923076923075, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a man sitting at a desk in front of a television. The man is playing a video game. The television is playing a video game. The man is wearing a black shirt and black pants. There is a book on the desk."}, "212384": {"image_id": 212384, "Bleu_1": 0.305555555547068, "Bleu_2": 0.2288688541020835, "Bleu_3": 0.1455151315767242, "Bleu_4": 1.7480450956950112e-05, "METEOR": 0.2385077002682506, "ROUGE_L": 0.33888888888888885, "CIDEr": 7.139938537254304e-05, "SPICE": {"All": {"pr": 0.15, "re": 0.10714285714285714, "f": 0.125, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image is a cake with a zebra and a giraffe on it. The cake is brown and black in color. The zebra and giraffe are made of fondant and are brown and black in color."}, "48332": {"image_id": 48332, "Bleu_1": 0.1739130434744802, "Bleu_2": 0.10767638040926633, "Bleu_3": 0.08077421359130516, "Bleu_4": 0.05916807499632182, "METEOR": 0.19489683971824123, "ROUGE_L": 0.2447178389943835, "CIDEr": 1.2879812117598749e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows two people standing around a table with two cakes on it. The cakes have ribbons, one with a blue and white ribbon and the other with a red, white, and blue ribbon. The people are wearing military uniforms and are cutting a cake."}, "443313": {"image_id": 443313, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.10654502541910188, "Bleu_4": 0.06978423773350045, "METEOR": 0.22585818313719697, "ROUGE_L": 0.32275132275132273, "CIDEr": 1.539189803631228e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.21739130434782608, "f": 0.17241379310344826, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a blue tennis court with a crowd of people watching from the stands. The man is wearing white clothing and has a white racket in his hand. The crowd is made up of people of different ages and races, all of whom are wearing casual clothing."}, "262476": {"image_id": 262476, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.21442250696028836, "Bleu_3": 0.17015105805045752, "Bleu_4": 0.11622111816247423, "METEOR": 0.16908660602560197, "ROUGE_L": 0.2350674373795761, "CIDEr": 0.00196103481871963, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.14285714285714285, "f": 0.12244897959183672, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows three people standing in a kitchen. They are drinking beer. The people are all wearing casual clothing.\n\nThe image is well lit and the colors are vibrant."}, "312213": {"image_id": 312213, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.11009637651061581, "Bleu_3": 0.061153792306271486, "Bleu_4": 8.143605172498537e-06, "METEOR": 0.18095852573176416, "ROUGE_L": 0.24110671936758893, "CIDEr": 7.630058182410543e-13, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on top of a laptop computer. The cat is looking at the screen with its eyes. The laptop has a keyboard and a mouse on it. The cat is not wearing a collar or a tag. The background is a light gray wall with a window in the background."}, "444366": {"image_id": 444366, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.11764652669092619, "Bleu_4": 0.09172809483333236, "METEOR": 0.20696313345857872, "ROUGE_L": 0.27566171723692706, "CIDEr": 9.338070876108197e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.125, "f": 0.14634146341463414, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a chair made of wicker. The chair is placed in front of a window with a view of the sky. There is a sheaf of dried grass on the floor next to the chair. The room is well lit by natural light coming through the window."}, "13061": {"image_id": 13061, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.1462544848210594, "Bleu_3": 0.08743583640208556, "Bleu_4": 1.2117880855538534e-05, "METEOR": 0.1833086916526158, "ROUGE_L": 0.25206611570247933, "CIDEr": 0.0001363086681490486, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.13793103448275862, "f": 0.16, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two remote controls on a wooden table. The remote controls are silver and black and silver in color. The remote controls have blue buttons. \n\nThere is no television in the image."}, "414501": {"image_id": 414501, "Bleu_1": 0.382352941165225, "Bleu_2": 0.28478969316957436, "Bleu_3": 0.17178141833809604, "Bleu_4": 2.010905744323401e-05, "METEOR": 0.22768493648997362, "ROUGE_L": 0.28549141965678626, "CIDEr": 0.002224322281799276, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a store with various electronics on display. A Microsoft mouse is on display in the store. The store is well lit. The people are looking at the store and a TV."}, "209346": {"image_id": 209346, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.19490257306060377, "Bleu_3": 0.15207942549613881, "Bleu_4": 0.09025762053874582, "METEOR": 0.3154813083752228, "ROUGE_L": 0.3465909090909091, "CIDEr": 1.935348398522979e-13, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.02702702702702703, "f": 0.031746031746031744, "fn": 36.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.07692307692307693, "f": 0.07692307692307693, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a woman standing in front of a large red suitcase. She is wearing a white dress. The woman is holding a red suitcase. The woman is holding a red briefcase. The suitcase is on the ground in front of her. There is a window in the background with a view of the city."}, "190014": {"image_id": 190014, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.16987257791700947, "Bleu_4": 1.9631974133116808e-05, "METEOR": 0.27438966898016415, "ROUGE_L": 0.37654320987654316, "CIDEr": 0.00011027217325065681, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.09090909090909091, "f": 0.09302325581395349, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person standing on top of a snow covered mountain. They are wearing a black jacket and white pants. They are holding a snowboard in their hand. The mountain is covered with snow."}, "364853": {"image_id": 364853, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.18731716231302323, "Bleu_3": 0.10846113596924095, "Bleu_4": 1.2398158141354333e-05, "METEOR": 0.200311498633788, "ROUGE_L": 0.2392156862745098, "CIDEr": 3.2264079668720795e-14, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11764705882352941, "f": 0.12903225806451615, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a man grilling hot dogs on a barbecue grill. The man is wearing a blue shirt and is using a spatula to flip the hot dogs. \n\nThere are three hot dogs on the grill. \n\nThere is no grill or metal handle in the scene. \n\nThe man is grilling the hot dogs on the grill."}, "453485": {"image_id": 453485, "Bleu_1": 0.18644067796294173, "Bleu_2": 0.13887752404723028, "Bleu_3": 0.08779565503978201, "Bleu_4": 1.0484742305525719e-05, "METEOR": 0.2005209975506014, "ROUGE_L": 0.2010326266066132, "CIDEr": 1.2025676772254896e-15, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.19047619047619047, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a woman in a kitchen preparing tea in a teapot. The woman is wearing a white apron and has a smile on her face. The kitchen is well lit and has a stove and a sink. There is no refrigerator in the scene. The walls are painted white and there is a window in the kitchen."}, "47648": {"image_id": 47648, "Bleu_1": 0.517241379292509, "Bleu_2": 0.3039153369167485, "Bleu_3": 0.15067706657715282, "Bleu_4": 1.9045484732020414e-05, "METEOR": 0.267855084921969, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.0040633907505760805, "SPICE": {"All": {"pr": 0.3, "re": 0.3157894736842105, "f": 0.3076923076923077, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image is a bowl of vegetables, including broccoli and carrots. There are slices of lemon in the bowl. The bowl is on a table with a white tablecloth."}, "204650": {"image_id": 204650, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1978218215826409, "Bleu_3": 0.1311863860222524, "Bleu_4": 1.4505210378846464e-05, "METEOR": 0.21707608222020283, "ROUGE_L": 0.2961165048543689, "CIDEr": 4.598992023416491e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a plane on the runway. The plane is gray. The plane has a large propeller on the front. There are people walking on the snow. The people are doing various activities, including riding a skateboard. One person is wearing a red jacket. There is a large red stripe on the plane."}, "362696": {"image_id": 362696, "Bleu_1": 0.2608695652136106, "Bleu_2": 0.1238760208504916, "Bleu_3": 0.06118334685342003, "Bleu_4": 7.675186525526234e-06, "METEOR": 0.1853939677963474, "ROUGE_L": 0.20304327151688062, "CIDEr": 1.4155786714887002e-20, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a street sign with a no parking sign on it. The sign is mounted on a pole. The street sign says \"Park Ave\". The no parking sign says \"No parking from 8am to 8pm except Sunday\" and \"No left turn\".\n\nThere are buildings on either side of the street. The buildings have windows and a door.\n\nThe overall scene shows the sign mounted on a pole."}, "477741": {"image_id": 477741, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1501878522938693, "Bleu_3": 0.11793851048655062, "Bleu_4": 0.08828781887837776, "METEOR": 0.2557920484773773, "ROUGE_L": 0.295638126009693, "CIDEr": 5.755685592983976e-13, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2777777777777778, "f": 0.2777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a building with graffiti on the walls. There is a stop sign on the side of the building. The building appears to be a former cleaners and has been abandoned for some time. The graffiti on the walls is colorful and appears to be from different artists. The stop sign is in good condition."}, "413616": {"image_id": 413616, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.26111648392551057, "Bleu_3": 0.1300475859230407, "Bleu_4": 1.6454943953709725e-05, "METEOR": 0.3317944957759866, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.0003591209788659891, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a dog playing with a frisbee. The dog is jumping up to catch the frisbee in the air. The dog is a black and white terrier with a red collar."}, "146126": {"image_id": 146126, "Bleu_1": 0.16346153845996672, "Bleu_2": 0.1053994145821447, "Bleu_3": 0.06016843845305722, "Bleu_4": 6.81469168357646e-06, "METEOR": 0.1605523629848494, "ROUGE_L": 0.15773919468045808, "CIDEr": 1.2536464145942071e-45, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.3333333333333333, "f": 0.3111111111111111, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows two tables. On the first table, there is a box of noodles. The table is used for a noodle dish. On the second table, there is a remote control, a can of soda, and a packet of chips. The table is used for a snack. \n\nThere is no television in the image. \n\nThere is no bag of food in the image. \n\nThere is a bowl of noodles in the image. \n\nThere is a packet of french fries and a drink in the image. \n\nThere is no cup or coffee in the image. \n\nThere is no wall or window in the image."}, "325331": {"image_id": 325331, "Bleu_1": 0.111111111108642, "Bleu_2": 0.08703882797589277, "Bleu_3": 0.07063108368194848, "Bleu_4": 0.05381887058082684, "METEOR": 0.17772173586646683, "ROUGE_L": 0.20052596975673898, "CIDEr": 1.5956770616623778e-08, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.07407407407407407, "f": 0.0909090909090909, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows two cats sleeping on top of two keyboards. The cats are brown and black. They are lying on their backs with their paws tucked under their bodies. The cats' eyes are not open. The cats' paws are pressed down on the keyboards."}, "4286": {"image_id": 4286, "Bleu_1": 0.27272727272314046, "Bleu_2": 0.19432508268642176, "Bleu_3": 0.12096683960340891, "Bleu_4": 1.294686481721265e-05, "METEOR": 0.22574387790181658, "ROUGE_L": 0.23992133726647003, "CIDEr": 4.96026236849415e-19, "SPICE": {"All": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.6, "f": 0.3157894736842105, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in a field of tall grass. The giraffe is wearing a collar and has a long neck. The man in the image is standing next to the giraffe and looking at it. The background is a dense forest with tall trees. The greenery in the scene is lush and green.\n\nThere are no other objects or animals in the image."}, "515303": {"image_id": 515303, "Bleu_1": 0.13636363636157026, "Bleu_2": 0.045802861240735154, "Bleu_3": 3.200381473995332e-07, "Bleu_4": 8.493098745181432e-10, "METEOR": 0.14196756453652687, "ROUGE_L": 0.14523809523809522, "CIDEr": 1.913527522108222e-18, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1875, "f": 0.15789473684210525, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of four people standing in front of a green carriage. The carriage has black wheels and a red and white canopy. \n\nOne of the men is wearing a white shirt and black pants. The woman is wearing a green shirt. \n\nIn front of the people, there is a frisbee and a bike. The frisbee is also in front of the people."}, "422677": {"image_id": 422677, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.14815943949377966, "Bleu_3": 0.08256538592718124, "Bleu_4": 1.1031958317495015e-05, "METEOR": 0.1825523860712436, "ROUGE_L": 0.2588767859668977, "CIDEr": 5.293200280842762e-07, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08695652173913043, "f": 0.08695652173913043, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man in a white shirt and khaki pants standing on a skateboard in front of a brick wall. The man is holding onto the skateboard with his left hand and has his right hand in his pocket."}, "169436": {"image_id": 169436, "Bleu_1": 0.27692307691881657, "Bleu_2": 0.1973380543410219, "Bleu_3": 0.1073256951360139, "Bleu_4": 0.06682359867549831, "METEOR": 0.19705060202364122, "ROUGE_L": 0.21318022965551672, "CIDEr": 6.304100126403312e-19, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.13043478260869565, "f": 0.16666666666666669, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a baseball player wearing a gray uniform and a black helmet, standing on the field with his glove raised. The baseball player is wearing a catcher's mitt. The player is catching a ball. The player is holding a baseball bat. The player has a smile. The player is also wearing a blue chest protector. The background is a green grass field."}, "369386": {"image_id": 369386, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2738612787456488, "Bleu_3": 0.12543706648990202, "Bleu_4": 1.5197389197190652e-05, "METEOR": 0.2469638896257273, "ROUGE_L": 0.28416149068322977, "CIDEr": 5.463296021700647e-06, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.5294117647058824, "f": 0.4736842105263158, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a toilet with a white seat and a toilet paper holder on the wall. There is also a window on the wall with a sign. The toilet is in a room with a sink and a mirror."}, "343004": {"image_id": 343004, "Bleu_1": 0.1692307692281657, "Bleu_2": 0.11498327637419221, "Bleu_3": 0.07487202886266836, "Bleu_4": 9.070720371351856e-06, "METEOR": 0.222819667415662, "ROUGE_L": 0.2190867111339148, "CIDEr": 1.671057706355544e-18, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.26666666666666666, "f": 0.163265306122449, "fn": 11.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.3333333333333333, "f": 0.14285714285714288, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 1.0, "f": 0.2857142857142857, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two people sitting on a couch. One person is wearing a purple shirt and has a purple pillow on their lap. The other person has a purple pillow on their lap and a cat sitting on it. There is a yellow banana on the couch. The banana does not have a brown spot on it. The background is a light brown color."}, "10693": {"image_id": 10693, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.3216337604400496, "Bleu_3": 0.19714987047942706, "Bleu_4": 2.3299898818396168e-05, "METEOR": 0.3612468248693682, "ROUGE_L": 0.4817374136229022, "CIDEr": 0.01670506490784009, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a woman standing in the rain holding an umbrella. She is wearing a black jacket. The umbrella is white. The car is parked in the rain."}, "210458": {"image_id": 210458, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.1313579154832357, "Bleu_3": 0.07061638347858736, "Bleu_4": 9.254837436221288e-06, "METEOR": 0.20019664142417762, "ROUGE_L": 0.22889305816135083, "CIDEr": 1.4038892167335648e-11, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08695652173913043, "f": 0.08695652173913043, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a zebra standing in the middle of a fenced area. The zebra is wearing a striped coat and does not have a tag on its neck. The fence and gate are not present in the image. There are no trees, but there is a bush in the background."}, "397135": {"image_id": 397135, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.253320198544886, "Bleu_3": 0.1818738688549909, "Bleu_4": 0.11802861352029913, "METEOR": 0.20326368596694702, "ROUGE_L": 0.3216168717047452, "CIDEr": 0.0003966395482386173, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.19230769230769232, "f": 0.20833333333333331, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of four people riding horses on a beach. The horses are pulling a cart with a person sitting in it. The people are wearing hats. The sky is clear."}, "176793": {"image_id": 176793, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2963744891737883, "Bleu_3": 0.2469382016149895, "Bleu_4": 0.21692718598330413, "METEOR": 0.3024343705254508, "ROUGE_L": 0.4155942467827404, "CIDEr": 0.0002638074233714323, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.25, "f": 0.2692307692307692, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a woman sitting on a motorcycle in front of a restaurant. She is wearing a white shirt, blue pants, and a red skirt. The restaurant has a sign that reads \"Harley Davidson Lincoln Rd\"."}, "347179": {"image_id": 347179, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.23783535599888, "Bleu_3": 0.13805054457255136, "Bleu_4": 1.5820356672588363e-05, "METEOR": 0.274348364036863, "ROUGE_L": 0.38006230529595014, "CIDEr": 6.925151621856617e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a group of five people standing in a field, looking at a flock of sheep. The people are wearing hats. The sheep are standing in a field of grass. The sky is cloudy and there are trees in the background."}, "43734": {"image_id": 43734, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.14819171472405493, "Bleu_3": 0.09641854808598062, "Bleu_4": 1.1689882104179119e-05, "METEOR": 0.17310158838874887, "ROUGE_L": 0.2238532110091743, "CIDEr": 8.540106077157782e-10, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows three black dogs standing in the water. One of the dogs is wearing a hat and a sweater, another is wearing a hat, and the third is wearing a hoodie. The dogs are standing in the waves. In the background, there are two rocks and a sand castle."}, "334074": {"image_id": 334074, "Bleu_1": 0.38095238093424044, "Bleu_2": 0.276026223723469, "Bleu_3": 0.22913395280203924, "Bleu_4": 0.1912081757405872, "METEOR": 0.23909439306643115, "ROUGE_L": 0.33116178067318125, "CIDEr": 0.19755690218151742, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2222222222222222, "f": 0.21818181818181817, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two zebras standing in the shade. The zebras are black and white with distinctive stripes on their backs."}, "473057": {"image_id": 473057, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.21550898337204086, "Bleu_3": 0.16574618012457856, "Bleu_4": 0.13815135310163001, "METEOR": 0.3201673570917464, "ROUGE_L": 0.30254184748915064, "CIDEr": 1.2781937406779763e-10, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.3684210526315789, "f": 0.3684210526315789, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image is a room with a bed, desk, and two chairs. There is a window with curtains and a door with a coat on it. The room has white walls and there is no rug in the room. The image is well lit and there are no other objects in the room."}, "350444": {"image_id": 350444, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.26130213377863615, "Bleu_3": 0.21166601750481703, "Bleu_4": 0.15257340614283252, "METEOR": 0.2541199223191204, "ROUGE_L": 0.28728414442700156, "CIDEr": 1.4625964758642444e-05, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of five boys playing soccer on a field. They are wearing blue and black jerseys and blue shorts. The boys are kicking a soccer ball. \n\nThere are no other people in the scene."}, "96549": {"image_id": 96549, "Bleu_1": 0.14999999999750005, "Bleu_2": 0.05042194840811363, "Bleu_3": 3.525903467255478e-07, "Bleu_4": 9.364489338402021e-10, "METEOR": 0.15029547209705513, "ROUGE_L": 0.16721491228070173, "CIDEr": 5.110424584562184e-15, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.10714285714285714, "f": 0.17142857142857143, "fn": 25.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a large airplane taking off from a runway at night. The plane has a white and blue body. The tail is blue and white, and the wings are white. The runway is illuminated with lights on either side. The sky is dark and there are no clouds in sight. The airplane is taking off from the runway."}, "119233": {"image_id": 119233, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.15289415742853263, "Bleu_3": 0.09531019071827618, "Bleu_4": 1.1305389682845626e-05, "METEOR": 0.240142390811287, "ROUGE_L": 0.2717149220489977, "CIDEr": 5.502898376996684e-13, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.07692307692307693, "f": 0.0975609756097561, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two cats in a room. One cat is lying on a desk, sleeping peacefully. The other cat is lying on a laptop, using it as a cozy spot. The laptop is open on the desk. \n\nThere are no other office supplies in the scene, such as a keyboard, printer, scanner, stapler, or plant."}, "1083": {"image_id": 1083, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.23445316701614308, "Bleu_3": 0.20924430771501362, "Bleu_4": 0.1609068706614158, "METEOR": 0.27781347766854564, "ROUGE_L": 0.3076368876080692, "CIDEr": 4.256494002397208e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows three cows walking in a green field. The cows are black and white. Some of the cows are walking in the grass, while others are standing in the grass. The field is surrounded by trees and a hill in the background."}, "265725": {"image_id": 265725, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.11531640100118269, "Bleu_3": 0.0661213089813225, "Bleu_4": 8.952677771744006e-06, "METEOR": 0.23738421537632853, "ROUGE_L": 0.2401574803149606, "CIDEr": 6.610277868449724e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16, "f": 0.16326530612244897, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two baseball players in black and white uniforms, each holding a bat and ready to hit the ball. The players are standing on the field. The field is green. \n\nThere is no ball in the image.\n\nThere is no umpire or spectators in the stands."}, "432150": {"image_id": 432150, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.19264477878804065, "Bleu_3": 0.12611911632771927, "Bleu_4": 1.53642039728234e-05, "METEOR": 0.25337996652578504, "ROUGE_L": 0.32570556826849734, "CIDEr": 8.345809664745404e-06, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.23076923076923078, "f": 0.26666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a kitchen with white cabinets, a stove, and a refrigerator. There is a table in the corner of the room. The floor is made of hardwood. The walls are white. There are windows in the room."}, "5503": {"image_id": 5503, "Bleu_1": 0.1538461538431953, "Bleu_2": 0.0776735637365534, "Bleu_3": 4.941500225511973e-07, "Bleu_4": 1.2526942807511536e-09, "METEOR": 0.11308517215842992, "ROUGE_L": 0.18373493975903615, "CIDEr": 5.929059664222341e-12, "SPICE": {"All": {"pr": 0.125, "re": 0.10526315789473684, "f": 0.11428571428571428, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a toilet with a seat and a handle on the side. The toilet is in a bathroom with a sink and a showerhead on the wall. There is a door on the right side. The floor is made of tile. A sock is on the side of the toilet."}, "261906": {"image_id": 261906, "Bleu_1": 0.16216216215777943, "Bleu_2": 0.11624763874063385, "Bleu_3": 0.09174380408476634, "Bleu_4": 0.06903396668483773, "METEOR": 0.1362848012111917, "ROUGE_L": 0.2247605011053795, "CIDEr": 2.6803606920832338e-05, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.12903225806451613, "f": 0.16666666666666666, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a stork standing on a fence in a green area. The stork is white and black. The stork has a long beak and long legs. There are no trees or pond in the scene."}, "112110": {"image_id": 112110, "Bleu_1": 0.15873015872763924, "Bleu_2": 0.12393943320197576, "Bleu_3": 0.09107590114587596, "Bleu_4": 0.0595682436395783, "METEOR": 0.1436158858373293, "ROUGE_L": 0.19056544829740704, "CIDEr": 2.104918440980263e-17, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a person standing on a sidewalk. The person is carrying a skateboard on his back. He is wearing a pair of grey and white sneakers and blue jeans. He is holding a small object with his hands. The shirt is blue and white. The background is a dark blue sky with some clouds.\n\nThere is no pocket in the scene."}, "243849": {"image_id": 243849, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.14540168172223333, "Bleu_3": 0.10022433611412393, "Bleu_4": 0.07039372171321473, "METEOR": 0.2444156157612191, "ROUGE_L": 0.285427807486631, "CIDEr": 8.594617620844139e-08, "SPICE": {"All": {"pr": 0.08, "re": 0.1, "f": 0.08888888888888889, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bacon cheeseburger with a fried egg on top. The burger is on a white plate with a red and white checkered tablecloth. There is no glass or juice in the scene. The background is a white wall with a window."}, "299100": {"image_id": 299100, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.13343067301000014, "Bleu_4": 0.08344354329350989, "METEOR": 0.2577115144769182, "ROUGE_L": 0.3315217391304348, "CIDEr": 1.7404081782417592e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.19047619047619047, "f": 0.1951219512195122, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a hot dog on a plate with a glass of water next to it. The hot dog is topped with vegetables and sauce. The glass of water contains ice cubes and a lemon. The table is made of wood and has a blue and white checkered pattern on it."}, "159790": {"image_id": 159790, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.0919600979722263, "Bleu_3": 0.05861154731966137, "Bleu_4": 8.37127147128765e-06, "METEOR": 0.2057897519129198, "ROUGE_L": 0.2636887608069164, "CIDEr": 5.445106372016146e-07, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2222222222222222, "f": 0.20689655172413793, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of twelve people doing skateboarding. Some of the people are riding a skateboard and performing tricks. \n\nThe people are wearing t-shirts and jeans. \n\nThere is no ramp or metal in the scene. \n\nThere is no design on the ramp."}, "371322": {"image_id": 371322, "Bleu_1": 0.4374999999726563, "Bleu_2": 0.1707825127549637, "Bleu_3": 1.2771823872371912e-06, "Bleu_4": 3.5579828676919253e-09, "METEOR": 0.12176814289313653, "ROUGE_L": 0.21082949308755758, "CIDEr": 0.0786106906095465, "SPICE": {"All": {"pr": 0.15, "re": 0.25, "f": 0.18749999999999997, "fn": 9.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.75, "f": 0.375, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person wearing a wetsuit and standing on a surfboard in the river."}, "240960": {"image_id": 240960, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.24174688919636403, "Bleu_3": 1.429652860731961e-06, "Bleu_4": 3.5215555865744205e-09, "METEOR": 0.22568984669916656, "ROUGE_L": 0.43482688391038704, "CIDEr": 0.16554984110440846, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a pizza on a table. The pizza has red sauce on top. There is no cheese in the image."}, "421401": {"image_id": 421401, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.16652655174285833, "Bleu_3": 9.436646347668319e-07, "Bleu_4": 2.2637359354087977e-09, "METEOR": 0.20722406503464766, "ROUGE_L": 0.2543786488740617, "CIDEr": 7.37323597169539e-05, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2631578947368421, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is of a vase with red flowers in it. The vase is made of clay and has a spiral design on it. The flowers are red. The vase is sitting on the table."}, "305159": {"image_id": 305159, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.16888013236325736, "Bleu_3": 9.623559024864637e-07, "Bleu_4": 2.3155883840431146e-09, "METEOR": 0.18812477247247344, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.0002228143845953458, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a train car with an open door and two windows on the side. The train car is painted in white and has a metal surface. The walls are made of glass."}, "379767": {"image_id": 379767, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.2531848417613592, "Bleu_3": 1.368711126224722e-06, "Bleu_4": 3.2150004481526583e-09, "METEOR": 0.27886710239651413, "ROUGE_L": 0.34173669467787116, "CIDEr": 0.04893363275274129, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.23809523809523808, "f": 0.21276595744680848, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a plate of food with rice, broccoli, and chicken on it. There are two glasses of wine on the table. The tablecloth is brown."}, "485509": {"image_id": 485509, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1923483450237976, "Bleu_3": 0.0958611289126843, "Bleu_4": 1.2106983211839111e-05, "METEOR": 0.16418540806682544, "ROUGE_L": 0.2911694510739857, "CIDEr": 1.3065132655464153e-05, "SPICE": {"All": {"pr": 0.16, "re": 0.25, "f": 0.19512195121951217, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person doing skiing on a snowy slope. The person is wearing a black ski suit. The slope is covered with trees and there are mountains in the background.\n\nThe image is taken from a high angle, looking down the slope."}, "57222": {"image_id": 57222, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.12592155012443357, "Bleu_3": 0.07227425284747027, "Bleu_4": 9.795841373567018e-06, "METEOR": 0.14052625424817225, "ROUGE_L": 0.17134831460674158, "CIDEr": 1.0670989042629064e-08, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.02857142857142857, "f": 0.04, "fn": 34.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows two stuffed animals sitting on the ground. One of the stuffed animals is wearing a pink hat and the other is wearing a pink hat. The stuffed animals are both wearing pink clothing.\n\nThere is no other clothing in the scene."}, "523637": {"image_id": 523637, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.16282722783536435, "Bleu_4": 0.1176927314512938, "METEOR": 0.25790508177892996, "ROUGE_L": 0.3202099737532808, "CIDEr": 2.424721715306566e-09, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.07692307692307693, "f": 0.08888888888888889, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of four people sitting on a couch in a well-lit living room. They are looking at a laptop and appear to be working on something. The people are wearing casual clothing, with some wearing blue shirts and others wearing black or white shirts."}, "221433": {"image_id": 221433, "Bleu_1": 0.27272727271487607, "Bleu_2": 0.11396057645433466, "Bleu_3": 8.65950551279142e-07, "Bleu_4": 2.4178614975561836e-09, "METEOR": 0.1098581883280149, "ROUGE_L": 0.19344608879492597, "CIDEr": 0.033477683379390014, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows 16 people surfing in the water. Some of the people are wearing wetsuits. The surfboard is in the water."}, "246124": {"image_id": 246124, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.22821773228679554, "Bleu_3": 0.11888097523312292, "Bleu_4": 1.538345748700747e-05, "METEOR": 0.18231666489401735, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.000325164102864041, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.07407407407407407, "f": 0.1111111111111111, "fn": 25.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows three people standing on a stone bridge. They are wearing suits and one of them is holding a kite. The landscape is hilly and green, with trees and buildings visible."}, "193863": {"image_id": 193863, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.20159019488753482, "Bleu_3": 0.14716669660616322, "Bleu_4": 0.11759665505639212, "METEOR": 0.2843151515812485, "ROUGE_L": 0.2959369314736203, "CIDEr": 5.5189746753248903e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman playing tennis on a tennis court with a net in the background. The woman is wearing a black shirt and black shorts, and has a racket in her hand. The court is made of concrete. There is a fence around the court. There are trees in the background."}, "242411": {"image_id": 242411, "Bleu_1": 0.16666666666481483, "Bleu_2": 0.10599978799945162, "Bleu_3": 0.05035498145932652, "Bleu_4": 6.1894494042587606e-06, "METEOR": 0.16852231222718517, "ROUGE_L": 0.16137566137566137, "CIDEr": 2.7362760250536347e-38, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.08695652173913043, "f": 0.09999999999999999, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a building with a car parked on the side of the road. There are four people on the street. The people are drinking a soda, holding a hat, walking down the street, and doing a look at the people of San Diego 0. There is a window on the building.\n\nThe image is taken from a high angle, looking down on the street. The buildings are white and have large windows. There is no street, road, or sidewalk in the scene. The sky is clear and blue."}, "538198": {"image_id": 538198, "Bleu_1": 0.255813953482423, "Bleu_2": 0.2064840403341673, "Bleu_3": 0.14611791249268313, "Bleu_4": 0.11175580607022101, "METEOR": 0.22597322647882284, "ROUGE_L": 0.23446508648302372, "CIDEr": 2.3058586962924435e-06, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a white and brown truck parked in a parking lot. The truck has a hood ornament and a brown hood. It is parked next to a car with a tan roof. There are several other cars parked in the lot."}, "177065": {"image_id": 177065, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.10060545457057822, "Bleu_3": 6.491530627040081e-07, "Bleu_4": 1.6602928882351336e-09, "METEOR": 0.20606597107371988, "ROUGE_L": 0.3519835136527563, "CIDEr": 0.0020774742585378822, "SPICE": {"All": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of four people playing tennis on a court. They are all wearing tennis shoes and some are holding rackets. The court is made of blue and white. There is a tree in the background."}, "271248": {"image_id": 271248, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.25503068521918915, "Bleu_3": 0.18666445436887244, "Bleu_4": 0.1495582520742981, "METEOR": 0.27918585077766334, "ROUGE_L": 0.2531120331950207, "CIDEr": 1.486745123976426e-06, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two buses parked on the side of the road. One bus is blue and orange, while the other is white. There are three people standing on the street. The people are looking at a bus and a red truck."}, "569452": {"image_id": 569452, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.11262765836415223, "Bleu_3": 0.06709347299490492, "Bleu_4": 9.26433478217715e-06, "METEOR": 0.12281667479689165, "ROUGE_L": 0.2038770053475936, "CIDEr": 2.2603489878597034e-07, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person skateboarding down a sidewalk in a park. The person is wearing a white shirt and brown pants, and has a black skateboard. There are trees and grass in the background.\n\nThe person is performing a trick on the skateboard."}, "152340": {"image_id": 152340, "Bleu_1": 0.10156249999920657, "Bleu_2": 0.06926924531407447, "Bleu_3": 0.053406008363167286, "Bleu_4": 0.03951141519394344, "METEOR": 0.12638168306451605, "ROUGE_L": 0.135706340378198, "CIDEr": 8.277817404846748e-83, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11538461538461539, "f": 0.12765957446808512, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two tables with plates of food on them. On the first table, there is a plate with a donut on it. On the second table, there is a plate with a sandwich on it. The tables have white tablecloths on them. \n\nThere are four glasses with drinks and desserts in them. The first glass contains a drink, the second glass contains a dessert, the third glass contains orange juice, and the fourth glass contains a drink.\n\nThere are three plates of food and three glasses of juice in total.\n\nThere is no pitcher in the image. There are no people in the image. There is no tablecloth on the table. There are no walls in the image.\n\nThe image shows a room with brown walls."}, "383420": {"image_id": 383420, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.211554354135948, "Bleu_3": 0.16128911947121186, "Bleu_4": 0.11889099988798969, "METEOR": 0.24312739841590134, "ROUGE_L": 0.21055226824457596, "CIDEr": 8.886484204234034e-19, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a remote control sitting on a table. The remote control has the words \"TV\" written on it. The design of the remote control resembles a TV. The remote control is made of plastic. There is a screen on the front of the remote control. The remote control is connected to a television set. \n\nThere is no other information provided about the television set."}, "531135": {"image_id": 531135, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.191273013914278, "Bleu_3": 0.12333630413179801, "Bleu_4": 1.4906383786424012e-05, "METEOR": 0.21357903903994824, "ROUGE_L": 0.2260934025203855, "CIDEr": 1.1728128674800574e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a baseball game happening on a field with a large crowd watching. The players are wearing baseball uniforms. The field is green. There are no stands or infield in the scene. The crowd is watching from the bleachers."}, "356490": {"image_id": 356490, "Bleu_1": 0.15686274509496353, "Bleu_2": 0.11202240672002234, "Bleu_3": 6.350451047474111e-07, "Bleu_4": 1.5198233764127822e-09, "METEOR": 0.18724238118374534, "ROUGE_L": 0.18654434250764526, "CIDEr": 5.495887177201919e-11, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.25, "f": 0.1935483870967742, "fn": 9.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two people swimming in the ocean. The people are laying on surfboards and wearing black wetsuits. They are holding the surfboards with their arms. The water and waves are not visible in the image. The shore is visible in the background. The sky is blue with no clouds."}, "289633": {"image_id": 289633, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.2574643252642948, "Bleu_3": 0.20450823775460866, "Bleu_4": 0.12994297068155328, "METEOR": 0.24399110979905048, "ROUGE_L": 0.3836477987421384, "CIDEr": 0.00019172402038939874, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.06896551724137931, "f": 0.0784313725490196, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man with a beard holding a toothbrush in his mouth. The man is wearing a blue shirt and khaki pants. The background does not include a sink or toilet."}, "184791": {"image_id": 184791, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.134717557601255, "Bleu_3": 6.868893635096677e-07, "Bleu_4": 1.5580249967419038e-09, "METEOR": 0.1689647508849368, "ROUGE_L": 0.2538376179027187, "CIDEr": 2.7068063223263973e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.15384615384615385, "f": 0.17777777777777778, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a vase made of metal. The vase has a paisley pattern. A bowl of oranges is on the table.\n\nThere are four fruits in the image. The fruit includes oranges and apricots.\n\nThere is no lemon or apple in the image.\n\nThere is no ceramic in the image.\n\nThere is no frame in the image."}, "271032": {"image_id": 271032, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.25197631533031906, "Bleu_3": 0.16966490952037497, "Bleu_4": 2.1023693682472793e-05, "METEOR": 0.19571072904785486, "ROUGE_L": 0.3086003372681282, "CIDEr": 0.03084211346021122, "SPICE": {"All": {"pr": 0.5, "re": 0.16, "f": 0.24242424242424243, "fn": 21.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a seagull perched on a rocky outcropping overlooking the ocean. The seagull is standing on a rock. The seagull is looking out over the water."}, "183757": {"image_id": 183757, "Bleu_1": 0.1382978723389543, "Bleu_2": 0.10202704186985226, "Bleu_3": 0.06975703388703519, "Bleu_4": 0.05226225627322785, "METEOR": 0.17186693894234348, "ROUGE_L": 0.1754133716750539, "CIDEr": 3.232789247220365e-41, "SPICE": {"All": {"pr": 0.28, "re": 0.4117647058823529, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two boats parked on the side of a river. On the deck of the boats, there are two dogs and a cat. The dogs are laying down and looking at the boats. The cat is sitting on one of the boats and looking at the dogs.\n\nThere are no trees in the scene, but there is grass on the banks of the river. There is no window in the boats. The overall view of the image is from a side angle, and the camera position is not shown in the image."}, "579593": {"image_id": 579593, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.18490006540142992, "Bleu_3": 1.1099703391050027e-06, "Bleu_4": 2.7474558341074007e-09, "METEOR": 0.18575731074885066, "ROUGE_L": 0.2442442442442442, "CIDEr": 0.004708664408221477, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16129032258064516, "f": 0.16393442622950818, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.25, "f": 0.23076923076923075, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in the middle of a clearing surrounded by tall trees. The giraffe is looking at a tree. The trees are brown."}, "416765": {"image_id": 416765, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.26794565081604904, "Bleu_3": 0.19624108648339778, "Bleu_4": 0.11954791984833718, "METEOR": 0.26072861132764147, "ROUGE_L": 0.3685800604229607, "CIDEr": 6.767343439344391e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3157894736842105, "f": 0.3243243243243243, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of seven cows standing in a field. The cows are black and white. They are grazing in the field. \n\nThere is a small stream running through the field. \n\nThere is no grass in the scene."}, "307209": {"image_id": 307209, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.23260756692519305, "Bleu_3": 0.18319839662297754, "Bleu_4": 0.13004139996985578, "METEOR": 0.3034629732434813, "ROUGE_L": 0.33107191316146534, "CIDEr": 6.914966268107524e-08, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.14285714285714285, "f": 0.12000000000000001, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a bear standing on a log in the water. The bear is playing in the water and looking at the log. The bear is brown and is looking up at the camera with its mouth open. There are no trees in the scene."}, "463013": {"image_id": 463013, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.18070977621815823, "Bleu_3": 0.12430963509343393, "Bleu_4": 0.09362537959803303, "METEOR": 0.18082336184583084, "ROUGE_L": 0.26681246582832147, "CIDEr": 2.1307026161573808e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.11764705882352941, "f": 0.14814814814814817, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a baseball game in progress. The players are wearing a baseball uniform and are standing on the field. The umpire is standing behind home plate, ready to call the next pitch. The sun is shining down on the field, casting a warm glow.\n\nThe crowd is watching from the stands."}, "173204": {"image_id": 173204, "Bleu_1": 0.09090909090860477, "Bleu_2": 0.04943473238874875, "Bleu_3": 2.3639096970515023e-07, "Bleu_4": 5.176291267356358e-10, "METEOR": 0.09222420272676435, "ROUGE_L": 0.07269116186693148, "CIDEr": 2.852120558477019e-191, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.12121212121212122, "f": 0.11940298507462688, "fn": 29.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of 29 people skiing down a snowy hill. They are wearing skiing gear and have their skis on their feet. The people are doing skiing. The people are taking pictures. The people are walking on the sidewalk. The people are riding a bike. The people are walking on the ice. The people are doing a ski race. The people are walking around. The people are standing in a crowd. The people are playing a game. The people are playing soccer. The people are watching a game. The people are praying. The people are taking pictures. The people are doing skiing. The people are standing behind a fence. The people are holding umbrellas. The people are playing a game. The people are playing a game. The people are playing soccer. The people are holding a red and white flag. A group of people are standing in a line are the people doing. The people are walking. The people are holding up signs. The people are walking in a crowd. The people are playing in the water. The people are standing on a street."}, "9262": {"image_id": 9262, "Bleu_1": 0.14473684210335874, "Bleu_2": 0.07608859102426038, "Bleu_3": 0.04276965904789536, "Bleu_4": 5.721647867042853e-06, "METEOR": 0.11998829360049933, "ROUGE_L": 0.1569468267581475, "CIDEr": 1.074060497394215e-23, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.35, "f": 0.3333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a table with a drink on it. There are six teddy bears on the table. A jar of honey is on the table. A teddy bear is nearby the table.\n\nThere is no sandwich or fruit in the image.\n\nThere is no stuffed animal or rabbit in the image.\n\nThere is a table and a chair in the scene. There is no desk nearby.\n\nThe scene is not in a hospital waiting room."}, "365822": {"image_id": 365822, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.16163173752903065, "Bleu_3": 0.13682045713838573, "Bleu_4": 0.1196425813532057, "METEOR": 0.2841876378094491, "ROUGE_L": 0.2959369314736203, "CIDEr": 3.5035716784520696e-11, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.22727272727272727, "f": 0.2857142857142857, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a kitchen with white cabinets and a stove. There is a table in the center of the room, and a chair is placed next to it. A cat is on the table.\n\nThe image is taken from the perspective of someone standing in the kitchen looking out the window. The"}, "531111": {"image_id": 531111, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.19611613513518975, "Bleu_3": 0.168776595292194, "Bleu_4": 0.14628063653430673, "METEOR": 0.3324938153854294, "ROUGE_L": 0.27811550151975684, "CIDEr": 5.209847441455112e-20, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08333333333333333, "f": 0.0851063829787234, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a black and white checkered floor. There are three sinks in the bathroom, all of which are white. A mirror is above each sink. There is a white toilet in the bathroom. \n\nThe room is well lit with natural light. There is no shower in the bathroom. There is a window with curtains on the left side of the room."}, "402798": {"image_id": 402798, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.21666028366574688, "Bleu_3": 0.1376455059779305, "Bleu_4": 0.09290830058656584, "METEOR": 0.2680310728782588, "ROUGE_L": 0.3351648351648352, "CIDEr": 9.42686940493082e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.23529411764705882, "f": 0.2162162162162162, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows an airplane on the tarmac. The airplane is red and white. The airplane has a tail and wings. The airplane is parked on the tarmac. There are no other airplanes or buildings in the scene."}, "578092": {"image_id": 578092, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 6.980462899277689e-07, "Bleu_4": 1.6401693914301652e-09, "METEOR": 0.16365414006156812, "ROUGE_L": 0.2130384167636787, "CIDEr": 1.2563048868010628e-10, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2916666666666667, "f": 0.32558139534883723, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a street with a house on the left side and a car parked on the right side. The house has a blue door and a red roof. The car has a silver hood and a silver body. There are no other cars or people in the image."}, "208135": {"image_id": 208135, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.11722658350807154, "Bleu_3": 6.89076821568532e-07, "Bleu_4": 1.6807563750229034e-09, "METEOR": 0.25748244206497695, "ROUGE_L": 0.2197406340057637, "CIDEr": 2.1216726503477987e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.17857142857142858, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person doing skiing on a snowy mountain slope. The person is wearing blue clothing and a purple helmet. They are holding skis and appear to be in good physical condition. The image is taken from a high angle, looking down."}, "99428": {"image_id": 99428, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.13334123550086785, "Bleu_4": 1.6132673522067715e-05, "METEOR": 0.23288047684994345, "ROUGE_L": 0.28728414442700156, "CIDEr": 2.7118435642995194e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a stack of two laptops on a table. The screen of the laptops is black. The laptops are different sizes and shapes. \n\nThere is no cell phone, digital camera, cable, or speaker in the scene."}, "455464": {"image_id": 455464, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.2956263824122027, "Bleu_3": 0.21962282645720926, "Bleu_4": 0.1604087710934087, "METEOR": 0.38220480914432287, "ROUGE_L": 0.3951417004048583, "CIDEr": 0.00018569491543515468, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.15151515151515152, "f": 0.19999999999999998, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man standing in a building. The man is talking on a cell phone and holding a cell phone. He is wearing a blue shirt. The man does not have a beard."}, "341645": {"image_id": 341645, "Bleu_1": 0.15789473684002772, "Bleu_2": 0.07947194142284998, "Bleu_3": 4.402830589076255e-07, "Bleu_4": 1.0398441821242354e-09, "METEOR": 0.13821249519635348, "ROUGE_L": 0.125, "CIDEr": 1.6061000214810355e-24, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two men standing on the sidewalk. One of the men is holding a skateboard. The men are wearing a brown and white shirt and black and brown and black pants respectively. The street is lined with trees and a building. \n\nThe image is taken from inside a car, looking out the window. The car is parked on the side of the road. There are eight cars parked on the side of the road."}, "200058": {"image_id": 200058, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.19062587708942288, "Bleu_3": 0.14086619565212993, "Bleu_4": 0.10232224124615, "METEOR": 0.17982354664975736, "ROUGE_L": 0.22344322344322343, "CIDEr": 9.606244702647437e-12, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08, "f": 0.0909090909090909, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a woman standing on a snowboard in the middle of a snowy field. She is wearing a black jacket and purple and black pants, and has a helmet on her head. There are two trees in the background, and a mountain range in the distance. The sky is clear and blue."}, "132328": {"image_id": 132328, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.24643202903867023, "Bleu_3": 0.1486189512948787, "Bleu_4": 1.7377208785097002e-05, "METEOR": 0.21172296297120113, "ROUGE_L": 0.3299526707234618, "CIDEr": 3.956405407925124e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.18518518518518517, "f": 0.2127659574468085, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of ten people flying kites in a field. The people are playing frisbee and riding bikes. Some of the people are sitting on the grass. The kites are made of plastic, paper, and cloth."}, "235131": {"image_id": 235131, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.12577443714450187, "Bleu_3": 6.485133546264769e-07, "Bleu_4": 1.4790078495203335e-09, "METEOR": 0.1139415225290562, "ROUGE_L": 0.1639784946236559, "CIDEr": 5.985871468243849e-15, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a building with a large glass facade and a spacious courtyard in front of it. The building is a museum or art gallery. In front of the courtyard, there is a boat dock. \n\nThere are two people walking down the street and looking at a blurry image of a person. \n\nThere is no exhibit in the scene."}, "403078": {"image_id": 403078, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.23124864502453574, "Bleu_3": 0.14951317712512502, "Bleu_4": 0.10189882571893968, "METEOR": 0.21069646527509603, "ROUGE_L": 0.24478330658105937, "CIDEr": 0.0002059732607646753, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13043478260869565, "f": 0.14634146341463414, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a riverbank, wearing wetsuits. They are holding surfboards. The water is calm. There is a tree in the background.\n\nThe man is wearing a wetsuit."}, "249325": {"image_id": 249325, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.23354968324320796, "Bleu_3": 0.207075816858827, "Bleu_4": 0.17052957615550848, "METEOR": 0.26077542007533355, "ROUGE_L": 0.3286195286195286, "CIDEr": 8.823073849846699e-07, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.16666666666666666, "f": 0.22727272727272724, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a man sitting on a bench reading a newspaper. The man is wearing a black jacket and a pair of blue sunglasses. The man is wearing glasses on his face. \n\nThere are no pigeons in the scene.\n\nLeaves are on the ground."}, "110626": {"image_id": 110626, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.10484363678213088, "Bleu_4": 0.08324415466849458, "METEOR": 0.22009824425759658, "ROUGE_L": 0.25553560742070613, "CIDEr": 2.824521249187676e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.14814814814814814, "f": 0.18604651162790697, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a stop sign on the side of the road. The sign is red and white, and the letters are white. The road is empty and there are no cars or other vehicles visible in the image. The sky is blue and there is a field in the background."}, "1852": {"image_id": 1852, "Bleu_1": 0.38095238093424044, "Bleu_2": 0.30860669990912093, "Bleu_3": 0.24682706829042084, "Bleu_4": 0.17001078097529507, "METEOR": 0.22188239803102885, "ROUGE_L": 0.35924617196702, "CIDEr": 0.18071466893764287, "SPICE": {"All": {"pr": 0.25, "re": 0.13513513513513514, "f": 0.1754385964912281, "fn": 32.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.0625, "f": 0.08695652173913043, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a pair of scissors on a table. The scissors is open. There is no rose in the image."}, "175024": {"image_id": 175024, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 0.06980462899277687, "Bleu_4": 9.223350291134877e-06, "METEOR": 0.22049336626908833, "ROUGE_L": 0.2901307966706302, "CIDEr": 5.721043169250703e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man riding a black motorcycle on a road. The man is wearing a black helmet and gloves. There is a pink teddy bear on the back of the motorcycle. The road is straight and there are trees on both sides of it. The sky is blue."}, "557114": {"image_id": 557114, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.2129856878358862, "Bleu_3": 0.16553898215115095, "Bleu_4": 0.13299435569869233, "METEOR": 0.24036248091360485, "ROUGE_L": 0.2970779220779221, "CIDEr": 0.0009635829697685042, "SPICE": {"All": {"pr": 0.2, "re": 0.11538461538461539, "f": 0.14634146341463417, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two zebras standing in front of a wooden fence. The zebras are wearing striped coats. The fence is made of wooden planks. The trees in the background are green."}, "34471": {"image_id": 34471, "Bleu_1": 0.23809523809145886, "Bleu_2": 0.1752768273470684, "Bleu_3": 0.13604932523069987, "Bleu_4": 0.08048862002738134, "METEOR": 0.260598761237758, "ROUGE_L": 0.27354260089686094, "CIDEr": 1.0733158079983593e-16, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.06451612903225806, "f": 0.07407407407407407, "fn": 29.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a living room with two couches, a television, and a remote control. There are two men standing in the living room. One man is holding a wii remote and looking at it, while the other man is also holding a wii remote and looking at a video game. The room is well lit. There are no windows in the room."}, "182874": {"image_id": 182874, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.19676758717389048, "Bleu_3": 0.15120391375656378, "Bleu_4": 0.1259205465036305, "METEOR": 0.2873702398139028, "ROUGE_L": 0.26961325966850824, "CIDEr": 1.1294002811274748e-14, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.36363636363636365, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a street with several buses and cars driving down the road. There are no trees in the scene. There are pedestrians walking on the sidewalk.\n\nThe sky is blue and there are no clouds in sight. The image is taken from a bird's eye view, giving a comprehensive view of the busy street scene."}, "300008": {"image_id": 300008, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.14265877597821283, "Bleu_3": 0.0767587966534404, "Bleu_4": 1.0068921364324644e-05, "METEOR": 0.16967901696031032, "ROUGE_L": 0.22775357809583074, "CIDEr": 6.8466512165628125e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.19230769230769232, "f": 0.20408163265306123, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two cows lying on the beach. The cows are brown and do not have a white patch on their foreheads. The people are standing on the beach and looking at the cows. The sky is blue and there are palm trees in the background."}, "12014": {"image_id": 12014, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2738612787456488, "Bleu_3": 0.21449436651941792, "Bleu_4": 0.1519738919719065, "METEOR": 0.3255433015205257, "ROUGE_L": 0.3588235294117647, "CIDEr": 0.00020853979760186652, "SPICE": {"All": {"pr": 0.1875, "re": 0.1111111111111111, "f": 0.13953488372093023, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a red double decker bus driving down a city street. The bus is parked on the street. There are people standing on the sidewalk. The sky is cloudy. There are buildings on either side of the street."}, "557907": {"image_id": 557907, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.26874192493724514, "Bleu_3": 0.20326259477011585, "Bleu_4": 0.1414126547200183, "METEOR": 0.27778281731343374, "ROUGE_L": 0.25902335456475584, "CIDEr": 2.196381187227862e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.10714285714285714, "f": 0.11999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two sheep grazing in a green field. The sheep are white and black. They have long, curly horns. They are standing in a grassy field with a tree in the background. The sky is blue and there are clouds in the distance."}, "278463": {"image_id": 278463, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.12032689292712466, "Bleu_4": 1.4538040525271512e-05, "METEOR": 0.17787314825245096, "ROUGE_L": 0.2839851024208566, "CIDEr": 6.833933264337425e-06, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.38095238095238093, "f": 0.3636363636363636, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.8333333333333334, "f": 0.5882352941176471, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a desk with a laptop on it. There are books and papers on the desk, as well as a cup of coffee on the side. The room is not brightly lit. Additionally, there is a cat on the laptop."}, "303534": {"image_id": 303534, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.1039255192663279, "Bleu_4": 0.06990644027657904, "METEOR": 0.16156926967175284, "ROUGE_L": 0.1937738246505718, "CIDEr": 2.7241978834996924e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a bedroom with a bed, a desk, and three windows. Curtains are on the windows. The walls are painted blue. The floor is covered in carpet. There is no rug on the bed. The room is well lit and there are no other objects in the room."}, "257187": {"image_id": 257187, "Bleu_1": 0.1627906976706328, "Bleu_2": 0.08804509063049047, "Bleu_3": 5.739518732336318e-07, "Bleu_4": 1.4744892493104462e-09, "METEOR": 0.15519102629242904, "ROUGE_L": 0.19766688269604665, "CIDEr": 3.116082312399584e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.17647058823529413, "f": 0.1818181818181818, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a woman holding up a bottle and smiling at the camera. She is wearing a blue shirt and blue pants. She has a purple and blue scarf around her neck. The background is a wooden bar with a large mirror."}, "268838": {"image_id": 268838, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.11009637651095512, "Bleu_3": 0.057427779714340516, "Bleu_4": 7.404681486168968e-06, "METEOR": 0.15488805877997106, "ROUGE_L": 0.21631205673758866, "CIDEr": 5.934219319883549e-21, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.19230769230769232, "f": 0.18181818181818185, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a group of nine sheep grazing in a field surrounded by trees. The sheep are grazing in the grass. Some of the sheep are laying down on a yellow background. One sheep is standing in a yellow field. The sheep are grazing on grass. The overall scene is peaceful and serene, with the tall green trees and yellow grass creating a beautiful backdrop."}, "1563": {"image_id": 1563, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2497770842103635, "Bleu_3": 0.1801740136201905, "Bleu_4": 0.13937542038551926, "METEOR": 0.2416077316030289, "ROUGE_L": 0.3604135893648449, "CIDEr": 0.0006140941542627909, "SPICE": {"All": {"pr": 0.07272727272727272, "re": 0.17391304347826086, "f": 0.10256410256410256, "fn": 19.0, "numImages": 1.0, "fp": 51.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 23.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.19047619047619047, "re": 0.36363636363636365, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}}, "caption": "The image shows a woman standing in front of a ski race course. She is wearing a black and white ski suit and holding a pair of skis. The course is marked with flags."}, "320642": {"image_id": 320642, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.1301889109786357, "Bleu_3": 6.636004394087886e-07, "Bleu_4": 1.5047393726752762e-09, "METEOR": 0.22070545094535393, "ROUGE_L": 0.21998969603297272, "CIDEr": 6.230378246027762e-15, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows three women standing in front of a building with a sign that reads \"a fan\". The women are wearing black and white dresses. One of the women is holding a white video game controller. The building is a brick building. \n\nThere are no shoes in the scene.\n\nThe women are not holding any objects in their hands."}, "152771": {"image_id": 152771, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.23473823892604287, "Bleu_3": 0.16621191224307574, "Bleu_4": 0.11823053204528565, "METEOR": 0.2673977751778921, "ROUGE_L": 0.29647630619684084, "CIDEr": 6.565492122604845e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a parking lot with two cars parked in it. There are trees in the background. A white bicycle is parked in the middle of the lot.\n\nThe parking lot is paved with asphalt. There are no other vehicles or people in the image. The sky is clear."}, "450464": {"image_id": 450464, "Bleu_1": 0.1756756756733017, "Bleu_2": 0.16993585042882822, "Bleu_3": 0.13400764983889937, "Bleu_4": 0.07630141745313276, "METEOR": 0.21589589243946913, "ROUGE_L": 0.23916358091918974, "CIDEr": 9.29775297793932e-24, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.22727272727272727, "f": 0.17543859649122806, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a train on the tracks in front of a building with a dome on top. There are people walking on the sidewalk and cars driving on the street. The sky is cloudy. \n\nThe train is a silver subway car. The building has a clock tower on top. A boat is in front of building 1. A bus is in front of building 2. There is a large building in the background."}, "533517": {"image_id": 533517, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.276533159369469, "Bleu_3": 0.19085369914763303, "Bleu_4": 0.12140538257408166, "METEOR": 0.26822145222474675, "ROUGE_L": 0.31470335339638866, "CIDEr": 0.00017603812818986128, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.17857142857142858, "f": 0.1923076923076923, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a table with a vase of blue and orange flowers on it. There are two chairs at the table. The room is dimly lit. There are three people sitting at the table."}, "151877": {"image_id": 151877, "Bleu_1": 0.333333333325926, "Bleu_2": 0.24618298195313262, "Bleu_3": 0.11211985653837897, "Bleu_4": 1.3534729403222225e-05, "METEOR": 0.19392174014621172, "ROUGE_L": 0.24063116370808676, "CIDEr": 1.5868193879085063e-07, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.10714285714285714, "f": 0.14285714285714285, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a truck parked on the side of a street. The truck is brown and has a cement mixer on its side. There are four people walking on the street. One person is sitting on a rock. A building is in the background."}, "262587": {"image_id": 262587, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.1649780043937838, "Bleu_3": 9.680778403513374e-07, "Bleu_4": 2.3650112439037722e-09, "METEOR": 0.272954092584186, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.0005087165052962884, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.3333333333333333, "f": 0.25641025641025644, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.8, "f": 0.5000000000000001, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person surfing on a green wave in the ocean. The person is wearing a black wetsuit and holding onto a surfboard with one hand while riding the wave."}, "542537": {"image_id": 542537, "Bleu_1": 0.4374999999863282, "Bleu_2": 0.31430927853687557, "Bleu_3": 0.23616618459629019, "Bleu_4": 0.1736086198146104, "METEOR": 0.3326373916101292, "ROUGE_L": 0.49512987012987014, "CIDEr": 0.006173859241150912, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man in a blue shirt and black pants holding a frisbee in his right hand and his left hand in the air. There are people in the background."}, "70258": {"image_id": 70258, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.2836543144559696, "Bleu_3": 0.22568026465562344, "Bleu_4": 0.17081922403555683, "METEOR": 0.3809851738318816, "ROUGE_L": 0.4701348747591522, "CIDEr": 0.0075615398740375254, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.07692307692307693, "f": 0.06666666666666667, "fn": 24.0, "numImages": 1.0, "fp": 32.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of five children playing with a ball in a courtyard. The children are wearing blue shirts and white pants. There are trees in the background."}, "396542": {"image_id": 396542, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.14922200399597868, "Bleu_3": 0.08442829210502145, "Bleu_4": 1.1370783164998655e-05, "METEOR": 0.19573660278876834, "ROUGE_L": 0.2683677958644963, "CIDEr": 3.0981421631087087e-05, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.15151515151515152, "f": 0.14925373134328357, "fn": 28.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4166666666666667, "f": 0.3703703703703704, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a person skiing down a snowy slope. The person is wearing black ski boots and a red backpack. The person is skiing down a snowy slope. The tree is on the slope. The slope is steep."}, "37325": {"image_id": 37325, "Bleu_1": 0.14583333333029516, "Bleu_2": 0.07877609890445154, "Bleu_3": 5.128736296145103e-07, "Bleu_4": 1.3158447399136021e-09, "METEOR": 0.1244723922015489, "ROUGE_L": 0.21942446043165467, "CIDEr": 5.844581236193935e-10, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.17857142857142858, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows two skateboarders performing tricks on a halfpipe. The skateboarders are wearing a white shirt and black pants. \n\nThe halfpipe is made of plastic and has a curved bottom. The halfpipe does not have a flat top. \n\nOverall, the skateboarders are performing tricks on a ramp."}, "21645": {"image_id": 21645, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1010152544531381, "Bleu_3": 6.010242872773113e-07, "Bleu_4": 1.4739391640949855e-09, "METEOR": 0.23154728611948525, "ROUGE_L": 0.26940063091482647, "CIDEr": 1.0164241645265446e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1, "f": 0.11538461538461538, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a room painted in beige. There is a large window on the left side of the room, through which a brown couch can be seen. The room also has two couches and a glass table in the center. The fireplace is located in the living room."}, "434479": {"image_id": 434479, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2014440620697061, "Bleu_3": 0.09733867301596093, "Bleu_4": 1.2101715869638743e-05, "METEOR": 0.17018485832798602, "ROUGE_L": 0.20691994572591585, "CIDEr": 1.7958711447797318e-08, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.09375, "f": 0.09836065573770493, "fn": 29.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a table with two slices of pizza on it. One slice of pizza is topped with pineapple and nuts, while the other slice is topped with mushrooms. The pizza is made of pineapples, nuts, and mushrooms. The table is in a restaurant setting."}, "104563": {"image_id": 104563, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.1516196087106396, "Bleu_3": 9.363773583417624e-07, "Bleu_4": 2.34826571218133e-09, "METEOR": 0.19782395991940213, "ROUGE_L": 0.29383429672447015, "CIDEr": 0.0008508394142218166, "SPICE": {"All": {"pr": 0.24, "re": 0.42857142857142855, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man skateboarding on a sidewalk. The man is wearing a yellow shirt and a pair of sneakers. He is holding the skateboard with his arms outstretched."}, "203864": {"image_id": 203864, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.3894440481690285, "Bleu_3": 0.27045469197936195, "Bleu_4": 0.17316703460096747, "METEOR": 0.3365141584364032, "ROUGE_L": 0.4499473129610117, "CIDEr": 0.035726323803671134, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08695652173913043, "f": 0.07999999999999999, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two people playing tennis on a tennis court. They are wearing tennis shoes and holding rackets. The court is made of grass."}, "463601": {"image_id": 463601, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.2550510152998425, "Bleu_3": 0.17690444644743003, "Bleu_4": 0.10474049059633278, "METEOR": 0.2419916734497909, "ROUGE_L": 0.3059013163786155, "CIDEr": 1.4451927507163323e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.125, "f": 0.12903225806451615, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man and a child standing on the beach, holding a kite. The man is wearing a blue shirt and blue shorts, and the child is wearing a blue shirt and blue shorts. They are both standing in the sand. The ocean is in the background."}, "355263": {"image_id": 355263, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.22893427324353557, "Bleu_3": 0.18218943070472146, "Bleu_4": 0.15604229933011285, "METEOR": 0.27275755218555997, "ROUGE_L": 0.28367380833748546, "CIDEr": 4.331437542520912e-12, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.25, "f": 0.22727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows three stuffed animals hanging from a metal beam on the side of a building. The animals are all different colors and have different expressions on their faces. One of the animals is wearing a hat and has a big smile on its face. The other animals are looking at each other."}, "573223": {"image_id": 573223, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.1646773939157558, "Bleu_3": 0.11194045746119324, "Bleu_4": 0.08375853894095579, "METEOR": 0.24419687377550212, "ROUGE_L": 0.26236559139784943, "CIDEr": 2.133283230435614e-15, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.3333333333333333, "f": 0.28, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a young girl standing in front of a toilet in a bathroom. She is wearing a blue and white dress with a snowflake pattern. Her hair is tied back in a bun. The toilet is white and has a lid. There is a sink to the left of the toilet. The girl is not wearing a ponytail."}, "52007": {"image_id": 52007, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.21381869073854032, "Bleu_3": 0.1844476240478094, "Bleu_4": 0.14968466016581375, "METEOR": 0.2389486147139826, "ROUGE_L": 0.3124644280022766, "CIDEr": 2.2931096104511438e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.08, "f": 0.10810810810810811, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a bus parked at a bus stop. There are people standing at the bus stop. The bus is a yellow double-decker bus. There is a sign at the bus stop that reads \"Lytham 11 st arms\". The sky is cloudy and there are trees and a building in the background."}, "403943": {"image_id": 403943, "Bleu_1": 0.49999999998437505, "Bleu_2": 0.3810003809884732, "Bleu_3": 0.2684910740226452, "Bleu_4": 0.19114167548168476, "METEOR": 0.3359102994134228, "ROUGE_L": 0.4691162109375, "CIDEr": 0.023351452335998432, "SPICE": {"All": {"pr": 0.15, "re": 0.10714285714285714, "f": 0.125, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man standing on the beach holding an umbrella. The man is wearing a blue shirt and black shorts. The umbrella has a striped pattern. The beach is sandy."}, "303250": {"image_id": 303250, "Bleu_1": 0.1555555555520988, "Bleu_2": 0.08408749651636235, "Bleu_3": 0.05478539491981273, "Bleu_4": 7.910178336294183e-06, "METEOR": 0.22341503374920643, "ROUGE_L": 0.17268223637650387, "CIDEr": 2.929035833823674e-09, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.17647058823529413, "f": 0.17647058823529413, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a brown bear and its cub in the water. The bear is yelling at another bear. The bear is looking at a fish. The cub is playing with its mother. The cub is looking at the mother bear. The water is clear."}, "397211": {"image_id": 397211, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.11043152607211947, "Bleu_3": 6.787458389845651e-07, "Bleu_4": 1.6936921942132095e-09, "METEOR": 0.11900826446280993, "ROUGE_L": 0.13937547600913938, "CIDEr": 3.077681625258404e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.26666666666666666, "f": 0.2285714285714286, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two people doing skateboarding on a ramp in a park. The people are wearing a white shirt and a black shirt. The ramp is made of wood and concrete. \n\nThere are no trees or buildings in the scene."}, "2239": {"image_id": 2239, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.14104731216518007, "Bleu_4": 0.08936355593064986, "METEOR": 0.2687082425191655, "ROUGE_L": 0.28259430840502975, "CIDEr": 1.4118207007595888e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2, "f": 0.17647058823529413, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a girl standing on a tennis court. She is holding a tennis racket. The girl is wearing a white tennis shirt. The grass on the tennis court is green. There is a net on the court.\n\nThere are no tennis balls in the scene."}, "566314": {"image_id": 566314, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.16222142112789117, "Bleu_3": 0.09854348184583721, "Bleu_4": 1.1537786210260598e-05, "METEOR": 0.2325644509452919, "ROUGE_L": 0.17805020431990656, "CIDEr": 4.5652486854454374e-14, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.20689655172413793, "f": 0.24000000000000002, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is a stained glass window in a church. The window is made up of many different colors, including blue and yellow. The stained glass window is in the middle of the room. A tiled wall surrounds the stained glass window.\n\nThere is a clock on the wall. The clock is made of wood and metal."}, "291537": {"image_id": 291537, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.2782433374469758, "Bleu_3": 0.13872365303731862, "Bleu_4": 1.757208840962666e-05, "METEOR": 0.28517591762526895, "ROUGE_L": 0.2775250227479527, "CIDEr": 0.0014345643343213975, "SPICE": {"All": {"pr": 0.2, "re": 0.3125, "f": 0.24390243902439027, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.5, "f": 0.2, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a person snowboarding down a mountain slope. The person is wearing a red jacket, black pants, and is holding onto a snowboard. The person is turning left direction."}, "262605": {"image_id": 262605, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 0.0858725358973738, "Bleu_4": 1.0831815605763862e-05, "METEOR": 0.2344362508885582, "ROUGE_L": 0.34560906515580736, "CIDEr": 4.0575313685811503e-08, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.35294117647058826, "f": 0.33333333333333337, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a woman standing in a dimly lit room. She is wearing a black dress and holding a hat in her hand. A chandelier is hanging from the ceiling.\n\nThe woman is looking at her reflection in the mirror, but there is no mirror in the scene."}, "118778": {"image_id": 118778, "Bleu_1": 0.1388888888850309, "Bleu_2": 1.9920476821678646e-09, "Bleu_3": 4.886975713115077e-12, "Bleu_4": 2.438662222082535e-13, "METEOR": 0.1776278322292962, "ROUGE_L": 0.154040404040404, "CIDEr": 2.9606948598096185e-05, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16666666666666666, "f": 0.14814814814814814, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows three trains on the tracks. There are cargo containers on the side of the trains. A building is in the background. There is no greenery in the scene.\n\nThe trains are moving slowly."}, "121673": {"image_id": 121673, "Bleu_1": 0.4848484848337925, "Bleu_2": 0.3015113445684842, "Bleu_3": 1.4313588920408447e-06, "Bleu_4": 3.1443515193397556e-09, "METEOR": 0.22408264382537152, "ROUGE_L": 0.3632574065803186, "CIDEr": 0.00788243719347119, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a person surfing on a surfboard in the ocean. The person is wearing a red shirt and black pants. The person is holding onto the surfboard. The wave is white."}, "91670": {"image_id": 91670, "Bleu_1": 0.17777777777382722, "Bleu_2": 2.0100756304732486e-09, "Bleu_3": 4.546237434540884e-12, "Bleu_4": 2.1748372490549038e-13, "METEOR": 0.11748251748251748, "ROUGE_L": 0.168391994478951, "CIDEr": 7.297697614686504e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17391304347826086, "f": 0.1568627450980392, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a convenience store on the street. There are cars driving down the street. There are two people walking. The people are eating kfc.\n\nThere is no pizza parlor or restaurant on the street. There is no road or sidewalk in the scene."}, "162829": {"image_id": 162829, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.1229880092500526, "Bleu_3": 0.07710286831404463, "Bleu_4": 1.0939951744794564e-05, "METEOR": 0.17718183497732704, "ROUGE_L": 0.20980223559759242, "CIDEr": 8.160000469242027e-05, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.15, "f": 0.125, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two people sitting at a table outside under a canopy of trees. The people are talking at the table. They are dressed in a blue shirt and a green and white attire."}, "360101": {"image_id": 360101, "Bleu_1": 0.2857142857040817, "Bleu_2": 0.2300218531057509, "Bleu_3": 0.15966079269551264, "Bleu_4": 0.11295714543526911, "METEOR": 0.23895027480264644, "ROUGE_L": 0.3651237031125299, "CIDEr": 0.006589774380584083, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.1111111111111111, "f": 0.11320754716981132, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a plate with two sandwiches on it. The sandwiches are made with bread, tomato, and cheese. The plate is on the table in the kitchen."}, "580410": {"image_id": 580410, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2680359137985001, "Bleu_3": 0.1916881510700032, "Bleu_4": 0.15407030704019273, "METEOR": 0.29541567964424525, "ROUGE_L": 0.370923161967938, "CIDEr": 1.8398404025444397e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.23529411764705882, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a living room with a white couch, a bookshelf, and a window on the left side of the room. The curtains are not open. The floor is made of wood. There is a rug in the center of the room. The walls are white and decorated with a large bookcase."}, "97427": {"image_id": 97427, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.2537081316938597, "Bleu_3": 0.13197861940352346, "Bleu_4": 1.7081922403555685e-05, "METEOR": 0.2766841956352166, "ROUGE_L": 0.40065681444991785, "CIDEr": 0.0030528793748467106, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.24, "f": 0.24999999999999994, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a kitchen with white appliances, a wooden table, and a window with black curtains. There is a stove in the kitchen. The floor is made of tile."}, "437898": {"image_id": 437898, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.2994247357980183, "Bleu_3": 0.14739150029843637, "Bleu_4": 1.8557240176540272e-05, "METEOR": 0.30504948967121387, "ROUGE_L": 0.3846846846846847, "CIDEr": 0.002148162853981109, "SPICE": {"All": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a kitchen with white appliances, wooden cabinets, and a white refrigerator. There are two sinks and a stove in the kitchen. The floor is made of hardwood."}, "149550": {"image_id": 149550, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2236067977443172, "Bleu_3": 0.15804080050769032, "Bleu_4": 0.12086038782206311, "METEOR": 0.24103675627470983, "ROUGE_L": 0.33152173913043476, "CIDEr": 3.0666858668956475e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is of a bathroom with a sink, toilet, and shower. The sink is made of white porcelain and has a faucet on the right side. The toilet is made of plastic. The seat is located in the bathroom."}, "516422": {"image_id": 516422, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2062842492474154, "Bleu_3": 0.12276317177262669, "Bleu_4": 1.4239605151902859e-05, "METEOR": 0.2680059088867807, "ROUGE_L": 0.31551724137931036, "CIDEr": 1.1243672115806002e-06, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.20588235294117646, "f": 0.28571428571428564, "fn": 27.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.7142857142857143, "re": 0.38461538461538464, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a couple sitting on a wooden bench in a park. They are reading a newspaper. The woman is wearing a white shirt and blue pants, while the man is wearing a blue shirt and white pants.\n\nThere is no dog or leash in the scene."}, "543065": {"image_id": 543065, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.27958605584655793, "Bleu_3": 0.25004624490867694, "Bleu_4": 0.21487698226476146, "METEOR": 0.346375835920219, "ROUGE_L": 0.417548226509023, "CIDEr": 3.848516213063517e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.14814814814814814, "f": 0.17777777777777776, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a table with a pizza on it. The man is wearing glasses and a black shirt. There are two chairs at the table. \n\nThere are three other people in the background of the image. \n\nThe table has a green tablecloth."}, "432085": {"image_id": 432085, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.13576884665825373, "Bleu_3": 6.710529771769306e-07, "Bleu_4": 1.4980620179980724e-09, "METEOR": 0.18490226893041392, "ROUGE_L": 0.2804597701149425, "CIDEr": 5.502225868353224e-12, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2, "f": 0.24489795918367346, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a desk with a plate of food in front of him. The man is wearing a blue shirt and blue pants. The desk has a plate of food on it. The plate of food contains a tortilla and a menu at a San Diego restaurant. \n\nThere is no computer, lamp, window, or view in the scene."}, "117869": {"image_id": 117869, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.29777500018082764, "Bleu_3": 0.18727547166812117, "Bleu_4": 0.1260716212138501, "METEOR": 0.2647756928063827, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.005524733195697181, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.045454545454545456, "f": 0.04166666666666667, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a giraffe standing on a rock, looking at a tree. The giraffe has brown and white fur. The background is a landscape with trees and rocks."}, "413538": {"image_id": 413538, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.07059312079859056, "Bleu_3": 4.953516746581623e-07, "Bleu_4": 1.3202927206769879e-09, "METEOR": 0.16577925202771818, "ROUGE_L": 0.17003484320557494, "CIDEr": 6.674381050235701e-08, "SPICE": {"All": {"pr": 0.375, "re": 0.2608695652173913, "f": 0.30769230769230765, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of two people standing around a grill on the grass. There are several sausages on the grill. One person is holding a plate of sausages. The people are wearing casual clothing. There are several trees in the background."}, "71667": {"image_id": 71667, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.27735009810559197, "Bleu_3": 0.20080646033179486, "Bleu_4": 0.14464063790346657, "METEOR": 0.2968415548184202, "ROUGE_L": 0.44614361702127664, "CIDEr": 0.00011407663359840448, "SPICE": {"All": {"pr": 0.09375, "re": 0.12, "f": 0.10526315789473684, "fn": 22.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a black and white photograph of a city street. The photograph depicts a street with a clock. On either side of the street, there is a store and a car. The photograph also shows a large department store."}, "162763": {"image_id": 162763, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.08664587414929849, "Bleu_3": 5.986080831486464e-07, "Bleu_4": 1.5848464939717996e-09, "METEOR": 0.15444015444015446, "ROUGE_L": 0.23088569265707795, "CIDEr": 8.564916688791359e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.13793103448275862, "f": 0.17777777777777778, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a photograph of two bicycles that are parked in a garage. The frames of the bicycles are black. The tires of the bicycles are black. There are no tools or bicycle parts on the floor."}, "334170": {"image_id": 334170, "Bleu_1": 0.333333333325926, "Bleu_2": 0.19462473603600663, "Bleu_3": 9.586112891273503e-07, "Bleu_4": 2.1400286214116864e-09, "METEOR": 0.2544954274996606, "ROUGE_L": 0.27941368930768223, "CIDEr": 4.284182401897594e-08, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.75, "f": 0.7058823529411765, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "This is a bathroom with a white sink, toilet, and shower. The walls are painted a warm beige color. The floor is made of white tiles. There is a window on the left side of the room. The bathroom is well lit and has a"}, "193407": {"image_id": 193407, "Bleu_1": 0.30952380951644, "Bleu_2": 0.26066118020872475, "Bleu_3": 0.18940185937628337, "Bleu_4": 0.11488730100868014, "METEOR": 0.24254699484561348, "ROUGE_L": 0.3043912175648702, "CIDEr": 1.2960457811952994e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.25, "f": 0.20689655172413793, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a person standing in the snow. The person is holding an umbrella and wearing a black coat and black boots. The person is not standing in the middle of a snowy sidewalk. There are two buildings in the background."}, "553931": {"image_id": 553931, "Bleu_1": 0.24615384615005917, "Bleu_2": 0.186052101880928, "Bleu_3": 0.14005529698464508, "Bleu_4": 0.10737595646409503, "METEOR": 0.26928703613842786, "ROUGE_L": 0.2497258571533007, "CIDEr": 7.633579818658712e-19, "SPICE": {"All": {"pr": 0.3125, "re": 0.3125, "f": 0.3125, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a display case filled with various types of donuts. The donuts are arranged on shelves in rows, with some of them being stacked on top of each other. The display case has a glass front and is surrounded by a wooden frame. The donuts are arranged in rows on the shelves. \n\nThere are a total of 38 donuts in the display case."}, "186927": {"image_id": 186927, "Bleu_1": 0.2592592592496571, "Bleu_2": 0.14121975761738967, "Bleu_3": 9.274353348178416e-07, "Bleu_4": 2.4010981784314084e-09, "METEOR": 0.15265017667844524, "ROUGE_L": 0.2668416447944007, "CIDEr": 0.015191245849643372, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.2962962962962963, "f": 0.3018867924528302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.46153846153846156, "f": 0.46153846153846156, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a bedroom with a television on the floor. There is no shelf in the room. There is no food or bag in the scene."}, "353510": {"image_id": 353510, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.15939996379066856, "Bleu_3": 0.1108246975736063, "Bleu_4": 0.07053208849722335, "METEOR": 0.2221532079993335, "ROUGE_L": 0.22834224598930483, "CIDEr": 1.8183862617467775e-14, "SPICE": {"All": {"pr": 0.16, "re": 0.25, "f": 0.19512195121951217, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man and a woman standing in a kitchen. The man is wearing a blue shirt and the woman is wearing a purple shirt. They are both holding a cup of coffee and looking at something on the countertop. The kitchen has wooden cabinets and a white countertop. There is a window in the kitchen."}, "202810": {"image_id": 202810, "Bleu_1": 0.3055555555513117, "Bleu_2": 0.18554997976613252, "Bleu_3": 0.1253029391234537, "Bleu_4": 0.08689927831588563, "METEOR": 0.22935194462833527, "ROUGE_L": 0.26068376068376065, "CIDEr": 8.629063658263858e-15, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.30434782608695654, "f": 0.2978723404255319, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.7777777777777778, "f": 0.7000000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image shows a street with several buildings on either side. The buildings are made of brick and have a mix of victorian, neo-classical, and neo-gothic architecture. There are four buildings in total. \n\nThere are nine cars parked on the side of the road. \n\nThere is no snow in the image.\n\nThe sky is clear and blue.\n\nThe image is taken from a high angle, looking down at the street and buildings."}, "133279": {"image_id": 133279, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.11009637651016171, "Bleu_3": 6.55680898648204e-07, "Bleu_4": 1.60955965059484e-09, "METEOR": 0.262213906254367, "ROUGE_L": 0.1616964877402253, "CIDEr": 9.127599319054123e-08, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a parking lot with several cars parked in it. There are also two airplanes in the background. The sky is clear and there are no clouds in sight. The ground is dry and there are no cacti or dirt in the scene."}, "169169": {"image_id": 169169, "Bleu_1": 0.4142857142797959, "Bleu_2": 0.3194845745443804, "Bleu_3": 0.22899550325817125, "Bleu_4": 0.15227612920542194, "METEOR": 0.2772752655538565, "ROUGE_L": 0.32269441015693884, "CIDEr": 3.2955935902723083e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.13333333333333333, "f": 0.16, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of four people standing in front of a building with a green sign that reads \"Spring Kitchen\". The building has a large window and a door on the front. There are two trees in the area. \n\nThe people are walking down the street and some are eating a sandwich. Two people are standing in front of the building. The people are standing on the sidewalk."}, "143503": {"image_id": 143503, "Bleu_1": 0.13513513513148287, "Bleu_2": 0.08664587414929846, "Bleu_3": 5.986080831486463e-07, "Bleu_4": 1.5848464939717994e-09, "METEOR": 0.09217151430726447, "ROUGE_L": 0.1465172137710168, "CIDEr": 3.8154449257665866e-07, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.30434782608695654, "f": 0.28571428571428575, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a horse standing on the sidewalk. The rider is wearing a helmet on their head. The horse is wearing a yellow vest. The building in the background is white and has a clock tower."}, "551454": {"image_id": 551454, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.17140166589755992, "Bleu_3": 0.11496733018745972, "Bleu_4": 0.07185584827225176, "METEOR": 0.24903283908280444, "ROUGE_L": 0.29516129032258065, "CIDEr": 4.0544455992029966e-16, "SPICE": {"All": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 10.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a clock tower made of stone in the middle of a city. There is a clock face on the front of the clock tower. A statue is also present on the front of the clock tower. A street is in front of the clock tower, where people are walking. There are buildings and trees in the background."}, "304044": {"image_id": 304044, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.07289725414308927, "Bleu_3": 4.942991774103207e-07, "Bleu_4": 1.2945692944860819e-09, "METEOR": 0.11678046955503268, "ROUGE_L": 0.15906127770534548, "CIDEr": 5.7678353351632886e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a street with cars parked on both sides. There are six lights at the intersection, with different colors including pink, orange, and red. There is a crosswalk where a dna strand is located.\n\nThe image is taken from the perspective of a driver."}, "536741": {"image_id": 536741, "Bleu_1": 0.5151515151359045, "Bleu_2": 0.358870281271592, "Bleu_3": 0.23185235792594905, "Bleu_4": 2.5387990321036462e-05, "METEOR": 0.2959917887938467, "ROUGE_L": 0.46362649294245384, "CIDEr": 0.08932102778227541, "SPICE": {"All": {"pr": 0.5, "re": 0.32142857142857145, "f": 0.391304347826087, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 9.0}, "Relation": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.46153846153846156, "f": 0.5217391304347826, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The man in the image is wearing a suit and tie, and holding a bottle of wine. He is standing in front of a red curtain. There is a table in the room."}, "505144": {"image_id": 505144, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.27263927062982823, "Bleu_3": 0.2102304460871048, "Bleu_4": 0.1635068194930436, "METEOR": 0.24801196386291485, "ROUGE_L": 0.31612067369979635, "CIDEr": 2.284738546391438e-05, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.25806451612903225, "f": 0.30769230769230765, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.42857142857142855, "f": 0.5217391304347826, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a person standing next to a suitcase with a tag on it. The person is standing on a skateboard. The suitcase has a tag on it with the words `Heavy duty luggage` and `Lax avg 183` written on it."}, "15883": {"image_id": 15883, "Bleu_1": 0.153846153843787, "Bleu_2": 0.06933752452707859, "Bleu_3": 4.241622738100331e-07, "Bleu_4": 1.0532976288458041e-09, "METEOR": 0.13633732712620247, "ROUGE_L": 0.15091538842157345, "CIDEr": 2.0460584630898706e-19, "SPICE": {"All": {"pr": 0.16, "re": 0.4, "f": 0.22857142857142856, "fn": 6.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people preparing food. One person is cutting up a loaf of bread with a knife. Another person is cutting up a piece of bread. The people are holding a knife. There is a person cutting up a hot dog. The people are holding a plate of food. There are two knives and two pieces of bread on the table."}, "478857": {"image_id": 478857, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.07269451760681338, "Bleu_4": 9.458362067955946e-06, "METEOR": 0.1589890693813113, "ROUGE_L": 0.21441124780316342, "CIDEr": 2.098301509351887e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a road with four cars parked on the side. There is a tree and a house in the background. The sky is clear and blue.\n\nThe image is taken from a bird's eye view, looking down on the street. The camera is positioned at a slight angle."}, "36252": {"image_id": 36252, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.19388959544940748, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.0014909847694832485, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three people wearing wetsuits and standing on their surfboards, waiting for a wave. They are standing on a beach and the ocean is in the background."}, "145747": {"image_id": 145747, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.18474632789942436, "Bleu_3": 0.1305684807849958, "Bleu_4": 0.09973167972643766, "METEOR": 0.20768817213109644, "ROUGE_L": 0.2401574803149606, "CIDEr": 1.3546301352007073e-09, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.17391304347826086, "f": 0.19999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows three boats on a lake surrounded by trees. The boats are white and have blue and red stripes. The sky is cloudy and there is a cloud in the distance. The water is calm and there are no waves. The trees are orange and yellow."}, "119677": {"image_id": 119677, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.2978416985811777, "Bleu_3": 0.2454369336781793, "Bleu_4": 0.17869522053917206, "METEOR": 0.24369661679088744, "ROUGE_L": 0.36810344827586206, "CIDEr": 0.003222298769259684, "SPICE": {"All": {"pr": 0.24, "re": 0.35294117647058826, "f": 0.28571428571428564, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a piece of cheesecake on a gray plate. The cheesecake is square-shaped and yellow. There is a fork placed on the side of the plate. The plate is gray."}, "145101": {"image_id": 145101, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.11740724488886634, "Bleu_3": 6.304863686903069e-07, "Bleu_4": 1.4677711128532439e-09, "METEOR": 0.17205082039412922, "ROUGE_L": 0.20926243567753, "CIDEr": 8.551019381653378e-15, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3157894736842105, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a room with two couches, a television, and two lamps. There is a window on the left side of the room with blinds. The floor is made of hardwood and the walls are painted white. The ceiling is made of wood and has a fan in it. There is a door in the room."}, "27476": {"image_id": 27476, "Bleu_1": 0.1710526315766967, "Bleu_2": 0.11697953037157091, "Bleu_3": 0.05697215874989177, "Bleu_4": 7.094410133732758e-06, "METEOR": 0.19340408619616004, "ROUGE_L": 0.1919964028776978, "CIDEr": 9.173318638396827e-23, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.3181818181818182, "f": 0.27450980392156865, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two women walking on the street. One woman is talking on the phone and wearing a short skirt. A smile is on her face. The other woman is holding a cell phone and wearing a white shirt. A smile is on her face. Both women are walking in the direction of the camera. The woman wearing the plaid shirt and shorts is also wearing sunglasses. There are two cars parked on the street."}, "463534": {"image_id": 463534, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.14254579382569355, "Bleu_3": 7.358334830308166e-07, "Bleu_4": 1.6801271827773928e-09, "METEOR": 0.2514734868505423, "ROUGE_L": 0.27774615822424586, "CIDEr": 8.6762965180251e-11, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08333333333333333, "f": 0.07843137254901962, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man lying on the bed. The man is sleeping. He is wearing a black shirt. The man is also wearing pajama pants. On his chest, there is a dog with a green collar. The bed is covered in a green and white striped blanket. There are two pillows nearby."}, "195086": {"image_id": 195086, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.16658955971162087, "Bleu_3": 8.511922922355495e-07, "Bleu_4": 1.9348958476953622e-09, "METEOR": 0.148432773866291, "ROUGE_L": 0.2598904443091905, "CIDEr": 1.130988781779571e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13333333333333333, "f": 0.1379310344827586, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a girl wearing pink pants. She is standing on a blue yoga mat and bending over to play with a laptop. The girl is stretching her arms up towards the ceiling. She is wearing a blue headband. There is no scarf in the image."}, "143359": {"image_id": 143359, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.23488808779791684, "Bleu_3": 0.1253683714769749, "Bleu_4": 1.6436148153953708e-05, "METEOR": 0.19199960414164033, "ROUGE_L": 0.31937172774869105, "CIDEr": 0.0017711078908281227, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.28125, "f": 0.3103448275862069, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 0.42857142857142855, "f": 0.4444444444444445, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a skateboarder performing a trick in a park. The skateboarder is wearing a black shirt and blue pants. The skateboarder is doing a trick on a ledge."}, "13383": {"image_id": 13383, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.20982172726164103, "Bleu_3": 0.16176672459792843, "Bleu_4": 0.12561880675318737, "METEOR": 0.26619361970284394, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.0676955839610985e-12, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.3125, "f": 0.2564102564102564, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 1.0, "f": 0.4615384615384615, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows three cats sleeping on a table. The cats are lying on their sides with their paws tucked under their bodies. One of the cats has a laptop tucked under its body. There is a cup of coffee on the table. The table also has a keyboard and a mouse on it."}, "392915": {"image_id": 392915, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.13497638119624783, "Bleu_3": 0.07896560106821801, "Bleu_4": 1.081441008019292e-05, "METEOR": 0.21064137671243852, "ROUGE_L": 0.24148851939825808, "CIDEr": 1.1586291150610478e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.1111111111111111, "f": 0.08333333333333334, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a kitchen with white cabinets and green countertops. There are stainless steel sinks in the kitchen. The floor is made of ceramic tiles. The refrigerator is located in the kitchen. There are plants in the kitchen."}, "286544": {"image_id": 286544, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.07926525909642891, "Bleu_4": 9.990095999341766e-06, "METEOR": 0.2162621995433249, "ROUGE_L": 0.28554710356933877, "CIDEr": 1.0562295700748345e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of 11 people walking down a sidewalk. Some of the people are riding skateboards, some are walking, and one person is riding a bike. A woman is on the sidewalk and a man in a wheelchair is also on the sidewalk. The people are walking on the sidewalk."}, "59108": {"image_id": 59108, "Bleu_1": 0.12820512820348456, "Bleu_2": 0.0999500374674876, "Bleu_3": 0.06406105824399991, "Bleu_4": 7.69449754857725e-06, "METEOR": 0.1341786594304057, "ROUGE_L": 0.1341248900615655, "CIDEr": 3.0068107920340746e-28, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.15789473684210525, "f": 0.125, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows four fire hydrants on the sidewalk. The fire hydrants are red. Fire hydrant 1 has a chain attached to it and is surrounded by a concrete wall. Fire hydrant 2 has a key attached to it and is surrounded by a concrete wall. Fire hydrant 3 has a chain attached to it and is surrounded by a concrete wall. Fire hydrant 4 has a key attached to it and is surrounded by a concrete wall."}, "318596": {"image_id": 318596, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.07923964199176128, "Bleu_4": 1.0198056661125237e-05, "METEOR": 0.1696322105292183, "ROUGE_L": 0.25221500295333726, "CIDEr": 5.701965994467932e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.3333333333333333, "f": 0.27027027027027023, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 1.0, "f": 0.625, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a street sign with the words dunmore ct written on it. The street sign is green. The sign is on the side of the road. There is a palm tree in the background.\n\nThere are no other words, signs, buildings, metal, or rust in the image."}, "346112": {"image_id": 346112, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.1975021321326405, "Bleu_3": 0.1719936178314516, "Bleu_4": 0.14582974563221107, "METEOR": 0.23334311515157755, "ROUGE_L": 0.2459677419354839, "CIDEr": 2.1776109097438176e-09, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.11764705882352941, "f": 0.10526315789473684, "fn": 30.0, "numImages": 1.0, "fp": 38.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.2, "f": 0.18750000000000003, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image features a gray and white cat lying on a white bed. The cat is looking at a window. The cat has a white patch on its nose. The cat is lying on its side. The background is a white bed with a white blanket on it."}, "572861": {"image_id": 572861, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 9.566001321761773e-07, "Bleu_4": 2.2206095448570952e-09, "METEOR": 0.1802754649722118, "ROUGE_L": 0.2683677958644963, "CIDEr": 1.693200616343062e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a horse and a carriage in front of a building with a sign that reads \"The Stables\". The horse is brown and white. The carriage is brown and white. The canopy on the carriage is brown."}, "348905": {"image_id": 348905, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.10256784899095028, "Bleu_3": 0.056935422350642036, "Bleu_4": 7.576871174126601e-06, "METEOR": 0.20631998083318007, "ROUGE_L": 0.169538632573652, "CIDEr": 2.0774043483592842e-14, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows four people riding jet skis in the water. The people are wearing life jackets and holding onto handlebars attached to the jet skis.\n\nThe water is calm and there are no other boats or people in the area. The sky is clear and there are no clouds. The sun is shining brightly, creating a pleasant atmosphere."}, "355881": {"image_id": 355881, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.18463723646331667, "Bleu_3": 1.0321883735007984e-06, "Bleu_4": 2.4605880386243325e-09, "METEOR": 0.16515166473603085, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.00339556854542731, "SPICE": {"All": {"pr": 0.3125, "re": 0.23809523809523808, "f": 0.27027027027027023, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a bowl filled with a variety of food. The food includes carrots, oranges, cucumbers, and a frog. The bowl is made of plastic and has a floral pattern on it."}, "402909": {"image_id": 402909, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 0.0916687886758685, "Bleu_4": 1.2360545409858299e-05, "METEOR": 0.20344679458563794, "ROUGE_L": 0.19934640522875818, "CIDEr": 0.0004931273335829696, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a train station with a platform and tracks leading to the tracks. There are no buildings or clock tower in the scene. The sky is cloudy and there is snow on the ground."}, "421286": {"image_id": 421286, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.20218927553934637, "Bleu_3": 0.14650674739543, "Bleu_4": 0.08861366029132581, "METEOR": 0.2702872533648275, "ROUGE_L": 0.2814302191464821, "CIDEr": 2.949024296095734e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.20833333333333334, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a plate with a slice of pizza on it. The pizza has mozzarella cheese on top. There are two forks next to the plate. \n\nThere is no glass or water in the image.\n\nThe plate with pizza and the forks are on a table. The table does not have a tablecloth."}, "559956": {"image_id": 559956, "Bleu_1": 0.17241379310047567, "Bleu_2": 0.09525969852473676, "Bleu_3": 0.05451844491105066, "Bleu_4": 7.3674453364292815e-06, "METEOR": 0.12130722241717219, "ROUGE_L": 0.17192784667418262, "CIDEr": 2.613986542612561e-15, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of three people standing around a flock of four sheep in a barn. The people are standing around a llama, sheep, and a cow. The people are wearing t-shirts and hats. The sheep are wearing blue collars and a sweater. The sheep are standing in a pen. The barn is a tan structure."}, "275661": {"image_id": 275661, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.20603150145092247, "Bleu_3": 0.09598617210562842, "Bleu_4": 1.1712026325597718e-05, "METEOR": 0.23889598635046164, "ROUGE_L": 0.2594167679222357, "CIDEr": 2.2798137859874522e-09, "SPICE": {"All": {"pr": 0.15, "re": 0.1, "f": 0.12, "fn": 27.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a room with a wooden floor. There is a desk with a computer, a lamp, and a book on it. In the corner, there is a chair. There is a window in the room, and a curtain is hanging from it. The room has a white ceiling."}, "318063": {"image_id": 318063, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.3708990934959662, "Bleu_3": 0.2513158137004015, "Bleu_4": 0.15873761851572363, "METEOR": 0.27893108596856986, "ROUGE_L": 0.28773584905660377, "CIDEr": 0.01672443707626471, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 6.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 1.0, "f": 0.5714285714285715, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a surfer riding a surfboard on a wave. The surfer is wearing a red shirt and has his arms outstretched as he rides the wave."}, "118739": {"image_id": 118739, "Bleu_1": 0.39999999999, "Bleu_2": 0.17541160385696436, "Bleu_3": 0.09320610239933667, "Bleu_4": 1.2162779391303559e-05, "METEOR": 0.19282641418180466, "ROUGE_L": 0.22426470588235295, "CIDEr": 5.450794841338567e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.17857142857142858, "f": 0.19607843137254902, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two pizzas with red sauce on a white plate. One of the slices of pizza has red sauce, while the other slice has white sauce. The plate is white and a slice of pizza is on it."}, "80666": {"image_id": 80666, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.2800560168001635, "Bleu_3": 0.2660114633660819, "Bleu_4": 0.248958090454748, "METEOR": 0.3698988128927296, "ROUGE_L": 0.39563679245283023, "CIDEr": 1.2093895230983925e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14814814814814814, "f": 0.1509433962264151, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a white and brown cat sitting on a bench in front of a building with a brown roof. The cat is looking up at the camera. The building has a large window on the top floor with a view of the street. There is a tree in the background."}, "44767": {"image_id": 44767, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.10562592656622659, "Bleu_4": 1.2211216504829663e-05, "METEOR": 0.2473714666489629, "ROUGE_L": 0.26940063091482647, "CIDEr": 3.12106955804372e-10, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.3333333333333333, "f": 0.41379310344827586, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a plate with fish, carrots, and a fork on it. The fish is white and has a flaky texture. The carrots are orange. The fork is on the side of the plate. The plate is white and has a pattern of lines on it.\n\nThere are no onions or parsley in the scene."}, "31092": {"image_id": 31092, "Bleu_1": 0.1971830985887721, "Bleu_2": 0.11867816581770188, "Bleu_3": 0.07418353401049213, "Bleu_4": 0.049499796200475656, "METEOR": 0.19076382982987525, "ROUGE_L": 0.21756576014266607, "CIDEr": 7.574819418371991e-22, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3076923076923077, "f": 0.2580645161290323, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows three people riding bicycles on the sidewalk. The person is walking on the sidewalk. A skateboard is on the person's back. The person is riding a bike. A backpack is on the person's back. The helmet the person is wearing is black. The bicycles are black and red. A basket is on the front of the bicycles. The sidewalk is made of concrete and has cracks."}, "6589": {"image_id": 6589, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.1506556909135452, "Bleu_4": 0.11042240379731003, "METEOR": 0.28714184123257314, "ROUGE_L": 0.3059013163786155, "CIDEr": 7.322400154323197e-10, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.16666666666666666, "f": 0.22727272727272724, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on a couch with a green and blue tie around its neck. The cat is looking at a pillow. The couch is covered in a leopard print. The fabric is a tan color. The head of the cat is visible in the image."}, "207937": {"image_id": 207937, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.1727334068323749, "Bleu_3": 0.11183162941545124, "Bleu_4": 1.2206421209808795e-05, "METEOR": 0.16145598125828947, "ROUGE_L": 0.17888563049853376, "CIDEr": 1.3515390769744274e-17, "SPICE": {"All": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.06666666666666667, "re": 0.16666666666666666, "f": 0.09523809523809522, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two people standing in front of a building. The building has white walls and a red roof. There is a green fence in front of the building. The people are wearing red raincoats and standing under an umbrella. The people are not standing in the rain. The image is taken from a low angle, looking up at the people. The lighting is natural."}, "378454": {"image_id": 378454, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.1415984650784514, "Bleu_3": 7.14361653643535e-07, "Bleu_4": 1.6119076650872648e-09, "METEOR": 0.2169468242341508, "ROUGE_L": 0.2255678816693079, "CIDEr": 1.204689663261679e-12, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a person playing frisbee. The person is jumping off a pier into the ocean. The person is wearing a maroon shirt and maroon shorts, and holding a green ball. The beach is sandy and there are no palm trees in the scene. The sky is blue and there are some clouds in the background."}, "252495": {"image_id": 252495, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 0.16670955566718626, "Bleu_4": 1.9213241481614443e-05, "METEOR": 0.22714653527317463, "ROUGE_L": 0.2930344275420336, "CIDEr": 2.033227425212887e-05, "SPICE": {"All": {"pr": 0.15, "re": 0.1875, "f": 0.16666666666666663, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two people on surfboards in the water. The people are sailing on a sailboard and surfing on a surfboard. \n\nThere are no wetsuits or sunglasses in the scene.\n\nThere are trees in the background."}, "368280": {"image_id": 368280, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.1184508853673932, "Bleu_3": 0.06683330244266764, "Bleu_4": 8.975429359940367e-06, "METEOR": 0.19394653707331017, "ROUGE_L": 0.23091482649842268, "CIDEr": 3.78297751776968e-10, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.1, "f": 0.10256410256410256, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of six boys playing soccer on a grass field. They are wearing blue and green jerseys, and black shorts. One of the boys is kicking the soccer ball with his left foot. The other boys are watching him and trying to get the ball."}, "557323": {"image_id": 557323, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.17188791273498485, "Bleu_3": 0.13985853457714958, "Bleu_4": 0.11987062245553716, "METEOR": 0.2599744888767657, "ROUGE_L": 0.3265524625267667, "CIDEr": 3.5835078805342845e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a soccer player in a green uniform playing soccer on a field. The player is kicking the ball with his right foot.\n\nThe image is taken from a high angle, looking down on the field. The sun is shining brightly, casting long shadows on the grass. The crowd is cheering in the background."}, "120021": {"image_id": 120021, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.23186944787247984, "Bleu_3": 0.15477697383157918, "Bleu_4": 1.9076129215280465e-05, "METEOR": 0.28427551008786955, "ROUGE_L": 0.3125533731853117, "CIDEr": 0.003190488451125048, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.15151515151515152, "f": 0.1754385964912281, "fn": 28.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.3125, "f": 0.3333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a black motorcycle parked on a red concrete floor. The motorcycle has a sleek, modern design with a silver body and a red seat. The tires are black."}, "534038": {"image_id": 534038, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.24253562502909157, "Bleu_3": 0.17667460065234128, "Bleu_4": 0.11548887884654896, "METEOR": 0.2549019291901266, "ROUGE_L": 0.3426966292134831, "CIDEr": 0.0018679567059609028, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.2, "f": 0.1568627450980392, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.3333333333333333, "f": 0.16666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows three people walking on the beach. The people are wearing hats and carrying bags. The sky is cloudy and the water is not calm. There is a boat in the distance."}, "146240": {"image_id": 146240, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.15524265447385155, "Bleu_4": 0.12637915277901166, "METEOR": 0.26001232858527057, "ROUGE_L": 0.37958929682638454, "CIDEr": 2.6175325145861604e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.12, "f": 0.12244897959183673, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a skateboarder performing a trick on a skateboard. The skateboarder is wearing a black shirt and black pants, and has a black hat on his head. The skateboard has white wheels with black rims and brown wheels. The background is a concrete skate park."}, "145325": {"image_id": 145325, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2138186907385403, "Bleu_3": 0.13906381417319805, "Bleu_4": 0.08563831261527419, "METEOR": 0.2101867950474824, "ROUGE_L": 0.24007646463510626, "CIDEr": 2.734999177595785e-07, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a desk with a computer, keyboard, mouse, and headset on it. A chair is in front of the desk. The walls are white. There are no windows in the room. The floor is made of carpet.\n\nThe room is well lit and there are no other objects in the scene."}, "81251": {"image_id": 81251, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.21072097723733796, "Bleu_3": 0.09955605444507262, "Bleu_4": 1.2237355827839207e-05, "METEOR": 0.29254143452441084, "ROUGE_L": 0.3712720632988436, "CIDEr": 1.9036873333936026e-08, "SPICE": {"All": {"pr": 0.5, "re": 0.21739130434782608, "f": 0.30303030303030304, "fn": 18.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a pizza with tomatoes, arugula, and parmesan cheese on top. The pizza is served on a white plate. There is a glass of wine next to the pizza. The pizza is placed on a table. The background is a white wall with a window."}, "376531": {"image_id": 376531, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.2239692918128555, "ROUGE_L": 0.3489037178265014, "CIDEr": 0.0008459626306355611, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2, "f": 0.17647058823529413, "fn": 24.0, "numImages": 1.0, "fp": 32.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.125, "f": 0.09090909090909091, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a young boy playing with a frisbee in a grassy area. The boy is wearing blue pants. In the background, there is a fence and trees."}, "360328": {"image_id": 360328, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.2800560167972403, "Bleu_3": 0.21402603671717593, "Bleu_4": 0.15858679875652748, "METEOR": 0.3303419640652648, "ROUGE_L": 0.47581903276131043, "CIDEr": 0.0006022152335356718, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a woman wearing a white shirt and holding a phone. She is standing in a kitchen with a refrigerator in the background. The woman appears to be talking on the phone."}, "283785": {"image_id": 283785, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.09046835805554347, "Bleu_3": 0.05091751995938635, "Bleu_4": 6.820527635997505e-06, "METEOR": 0.17612975074100776, "ROUGE_L": 0.14878048780487807, "CIDEr": 6.029958947598764e-17, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of 19 people standing in front of a bookshelf. The people are wearing yellow and orange costumes. Some of the people are holding books. There are several children in the group, including one who is laying on the floor. The adults are all standing and looking at the children.\n\nThere are no other costumes or books in the scene."}, "181786": {"image_id": 181786, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2613777310992162, "Bleu_3": 0.15745859536234952, "Bleu_4": 1.840793408002193e-05, "METEOR": 0.2797981229005299, "ROUGE_L": 0.3017312448474856, "CIDEr": 1.4506587886178143e-05, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.23809523809523808, "f": 0.23255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person skiing down a snowy slope. The person is wearing a yellow jacket and black pants, and has skis on their feet. The sky is cloudy and there is snow on the ground."}, "310622": {"image_id": 310622, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.19957280121567952, "Bleu_3": 1.0342687475822788e-06, "Bleu_4": 2.371144604551199e-09, "METEOR": 0.21614589620431982, "ROUGE_L": 0.28728414442700156, "CIDEr": 1.0034736398952666e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a street with five signs on the sidewalk. The signs are blue and white. One of the signs says \"west 23rd street\" and another says \"korea way\". There are also four buildings in the background."}, "110231": {"image_id": 110231, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.10433283794475069, "Bleu_3": 0.05976183926619196, "Bleu_4": 8.083053722298239e-06, "METEOR": 0.18443113772455094, "ROUGE_L": 0.15472415979708307, "CIDEr": 1.9150265008904232e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.09523809523809523, "f": 0.1081081081081081, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a person doing skiing on a snowy slope. The person is wearing a black and white ski suit, red ski boots, and a red and blue ski helmet. The person is holding onto a pair of skis and appears to be in good shape.\n\nThe background is a mountain landscape."}, "578849": {"image_id": 578849, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.152387863548989, "Bleu_3": 7.693256188802166e-07, "Bleu_4": 1.7371612974592085e-09, "METEOR": 0.19909032141758803, "ROUGE_L": 0.18100890207715134, "CIDEr": 4.168668579814745e-12, "SPICE": {"All": {"pr": 0.18333333333333332, "re": 0.4230769230769231, "f": 0.25581395348837205, "fn": 15.0, "numImages": 1.0, "fp": 49.0, "tp": 11.0}, "Relation": {"pr": 0.03225806451612903, "re": 0.125, "f": 0.05128205128205128, "fn": 7.0, "numImages": 1.0, "fp": 30.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38095238095238093, "re": 0.6666666666666666, "f": 0.4848484848484849, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}}, "caption": "The image shows a person doing skiing on a ski slope. The person is wearing a red and white suit, a white and blue helmet, and red goggles. They are holding a pair of skis, and also have a pair of poles in their hands. The background is a snowy mountain with trees."}, "146887": {"image_id": 146887, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 0.13300573168298876, "Bleu_4": 0.08367437134425945, "METEOR": 0.26421398772259075, "ROUGE_L": 0.33577981651376143, "CIDEr": 3.689312695226762e-10, "SPICE": {"All": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.75, "f": 0.7058823529411765, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows three green parrots perched on a tree branch. They are looking up at the sky and appear to be in a state of contemplation.\n\nThe sky is blue and cloudless, with a few white clouds scattered across it. There are no other trees or branches in the scene."}, "215914": {"image_id": 215914, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.07284313590699668, "Bleu_3": 4.799308605281424e-07, "Bleu_4": 1.2383960073346406e-09, "METEOR": 0.12650073206442167, "ROUGE_L": 0.21759809750297268, "CIDEr": 1.051688499016746e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a building with a sign that reads \"vs outdoor\". A skateboarder is in front of the building. There are no people in the image. There is winter clothing in the scene. There are no skis, but there is a snowboard. There are two snowballs on the ground."}, "544655": {"image_id": 544655, "Bleu_1": 0.10666666666524446, "Bleu_2": 0.07593263965918066, "Bleu_3": 0.042905343013108964, "Bleu_4": 5.755067339780465e-06, "METEOR": 0.13442637387858491, "ROUGE_L": 0.1386994088221919, "CIDEr": 1.2523757602564287e-25, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.3448275862068966, "f": 0.3508771929824561, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 10.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6153846153846154, "re": 0.6666666666666666, "f": 0.64, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}}, "caption": "The image shows a girl wearing a gray hoodie. The girl is smiling. \n\nThere are four people in the image. Some of the people are holding a bag of food. Some of the people are holding a cell phone. Some of the people are holding umbrellas. Some of the people are talking on their cell phones.\n\nThere is no sidewalk, sunglasses, or phone in the scene.\n\nThere are no bags or dogs in the scene."}, "34372": {"image_id": 34372, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.15617376188474938, "Bleu_3": 0.08551661700652094, "Bleu_4": 1.1326402344943274e-05, "METEOR": 0.2354286878800954, "ROUGE_L": 0.3083032490974729, "CIDEr": 1.9478867772836197e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.06896551724137931, "f": 0.08163265306122448, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.13333333333333333, "f": 0.14814814814814814, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of two people playing basketball in a gymnasium. They are wearing blue shirts and black shorts, and one of them is holding a basketball. The floor is made of wood. There are hoops on the wall."}, "447522": {"image_id": 447522, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.18677184190511298, "Bleu_3": 0.11843166534940335, "Bleu_4": 1.4187468588457954e-05, "METEOR": 0.25972893640152644, "ROUGE_L": 0.24583557227297154, "CIDEr": 1.795336781400024e-07, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a plate of food with broccoli, carrots, and rice on top. The food is arranged in a pattern of alternating colors, with the broccoli and carrots on the bottom and the rice on top. The plate is on a blue tablecloth."}, "451951": {"image_id": 451951, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.25819888973988653, "Bleu_3": 1.2516318556030132e-06, "Bleu_4": 2.7763804075211575e-09, "METEOR": 0.1999547422419037, "ROUGE_L": 0.24918300653594777, "CIDEr": 5.6815779613755135e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.13793103448275862, "f": 0.18604651162790697, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a man riding a skateboard on a bridge. The man is wearing a black shirt and waving his arms in the air. The sky is cloudy and there are clouds in the background."}, "324634": {"image_id": 324634, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.17283511575720037, "Bleu_3": 9.396955198772326e-07, "Bleu_4": 2.206598690629072e-09, "METEOR": 0.19415066191639338, "ROUGE_L": 0.2793893129770992, "CIDEr": 8.26908632256287e-06, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two people standing in a white room. One person is holding a cell phone and the other person is looking at a cell phone. Both people are dressed in black clothing and wearing black hats."}, "445658": {"image_id": 445658, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.25928148941334883, "Bleu_3": 0.12676801653440603, "Bleu_4": 1.5884362032463997e-05, "METEOR": 0.23536536050298526, "ROUGE_L": 0.3359559402045633, "CIDEr": 0.0010022209602549383, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a kitchen with wooden cabinets and a black stove. There is a white refrigerator and a microwave on the counter. The floor is made of wood.\n\nThere is no sink in the kitchen."}, "381257": {"image_id": 381257, "Bleu_1": 0.255813953482423, "Bleu_2": 0.17451086522195614, "Bleu_3": 0.1141029906527568, "Bleu_4": 0.07806525322093243, "METEOR": 0.2251641504482342, "ROUGE_L": 0.2902787219578518, "CIDEr": 2.6725828786479126e-07, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2222222222222222, "f": 0.2142857142857143, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a desk with a computer, mouse, and keyboard on it. There is also a pencil and paper on the desk. The wall is brown. There is no window or lamp in the scene. The overall mood is calm and peaceful."}, "65394": {"image_id": 65394, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.22086305214437038, "Bleu_3": 0.1540881120701569, "Bleu_4": 0.11703565707209887, "METEOR": 0.30215718404277325, "ROUGE_L": 0.37731958762886597, "CIDEr": 4.952463571349582e-06, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man wearing a yellow life jacket and a dog on a kayak in the water. The man is standing on a dock. The dog is sitting on the kayak. \n\nThere are no trees or buildings in the scene."}, "255135": {"image_id": 255135, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.11215443081631235, "Bleu_3": 0.07850304593348241, "Bleu_4": 0.05549736159877403, "METEOR": 0.2112092365510139, "ROUGE_L": 0.21048999309868874, "CIDEr": 2.043966029817154e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.13793103448275862, "f": 0.17777777777777778, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a stop sign on the side of a road. The sign is made of metal and has a red and white background. The sign is in good condition and is easy to read. The road is paved and there are no other cars or pedestrians in sight. The sky is clear."}, "293315": {"image_id": 293315, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.14757569038041785, "Bleu_3": 0.10527395965365241, "Bleu_4": 0.06786565520908983, "METEOR": 0.24853198894843387, "ROUGE_L": 0.23908174692049275, "CIDEr": 7.915867211579365e-11, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows three women sitting on a bench overlooking a valley. The women are wearing casual clothing. One of the women is wearing a blue sweater, another is wearing a red vest, and the third is wearing a scarf. They are looking out at the view. The grass is green and there are trees in the background."}, "491481": {"image_id": 491481, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.26111648392551057, "Bleu_3": 0.20643767470015953, "Bleu_4": 0.15562125170838512, "METEOR": 0.23934538224021235, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.0004457072507293737, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a giraffe standing on a grassy field. The giraffe is brown and white, with a long neck. The giraffe is looking at a tree. The background includes a green bush."}, "50431": {"image_id": 50431, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.29351975427062216, "Bleu_3": 1.5311620018090081e-06, "Bleu_4": 3.534548116230228e-09, "METEOR": 0.23641050155203275, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.036080203076465374, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.19230769230769232, "f": 0.1851851851851852, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows two horses pulling a white carriage on a street in a city. The carriage is white. The horses have white manes and tails."}, "87889": {"image_id": 87889, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.23312620205015375, "Bleu_3": 1.3518230023460688e-06, "Bleu_4": 3.293328483675269e-09, "METEOR": 0.2709308540600028, "ROUGE_L": 0.4256379585326954, "CIDEr": 0.08690956858924259, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows two people skiing down a snowy slope. They are wearing skis and carrying ski poles. The slope is covered with snow."}, "499716": {"image_id": 499716, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.09288407280072536, "Bleu_3": 5.60482607100497e-07, "Bleu_4": 1.3839209880654026e-09, "METEOR": 0.11231907763202931, "ROUGE_L": 0.14923547400611623, "CIDEr": 3.747946002568838e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows three zebras standing in a pen. One zebra is standing in a zoo. Another zebra is eating grass. The zebras are black and white. The pen is surrounded by a fence. There are no trees or grass in the scene. The zebras have distinctive stripes on their back."}, "400887": {"image_id": 400887, "Bleu_1": 0.18518518518289895, "Bleu_2": 0.10758287072664732, "Bleu_3": 0.07603148512316708, "Bleu_4": 0.048721590197703994, "METEOR": 0.17750994433840556, "ROUGE_L": 0.17169280257338157, "CIDEr": 3.1591948068525453e-28, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.3103448275862069, "f": 0.3103448275862069, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a group of five people walking horses on a street. The people are wearing hats and the horses are wearing saddles. A man and a woman walking horses can be seen on the street. The people are wearing plaid shirts and blue and pink. The people are also wearing a white shirt and blue pants. The people are playing frisbee and a dog can be seen with them. The horses are wearing a hat and a white collar."}, "26185": {"image_id": 26185, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.14361061402438519, "Bleu_3": 7.004986068930467e-07, "Bleu_4": 1.5536115957337455e-09, "METEOR": 0.23080028973210706, "ROUGE_L": 0.24621594349142278, "CIDEr": 2.2039995720744704e-16, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person standing on a cliff overlooking the ocean. The person is carrying a surfboard and wearing a wetsuit. The person is standing on a sandy beach. The person is holding a surfboard. The person is wearing a black jacket. The sky is cloudy and there is a strong wind blowing. The waves are crashing against the rocks below."}, "385770": {"image_id": 385770, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.327326835338012, "Bleu_3": 0.22425727432945428, "Bleu_4": 0.15821285887535239, "METEOR": 0.23959916130686862, "ROUGE_L": 0.48248587570621465, "CIDEr": 0.20064834439013196, "SPICE": {"All": {"pr": 0.2, "re": 0.23809523809523808, "f": 0.21739130434782608, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a living room with a couch, a television, and a floor made of hardwood. The walls are beige."}, "446260": {"image_id": 446260, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.44158804329836093, "Bleu_3": 0.2940871238449009, "Bleu_4": 0.18439593265247142, "METEOR": 0.33325790373650616, "ROUGE_L": 0.5142255005268704, "CIDEr": 0.07210489667226695, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man wearing a white shirt with a black and yellow striped tie. The man is standing in front of a car."}, "353409": {"image_id": 353409, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.17654696589776867, "Bleu_3": 0.10490243861000662, "Bleu_4": 1.2148431820734e-05, "METEOR": 0.23207350385507441, "ROUGE_L": 0.2426136363636364, "CIDEr": 1.108042718262809e-13, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16, "f": 0.2105263157894737, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a group of 27 people riding motorcycles on a road. They are all wearing helmets. Some of the people are carrying bags or other items. There are 9 cars parked along the side of the road. People are walking on the sidewalk. There are 2 trees in the background. The sky is clear."}, "536653": {"image_id": 536653, "Bleu_1": 0.18309859154671693, "Bleu_2": 0.13531392816118423, "Bleu_3": 0.09267993542393647, "Bleu_4": 0.05849410006417951, "METEOR": 0.19554559273577476, "ROUGE_L": 0.22478120681713498, "CIDEr": 2.643172144205903e-22, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features three women. The first woman is wearing a white dress and holding a tennis racket. The second woman is wearing a white shirt and holding a tennis racket. The third woman is wearing a black dress and holding a tennis racket. The first and second women are playing tennis on a tennis court. The third woman is sitting in the stands.\n\nThe crowd in the background is cheering."}, "450217": {"image_id": 450217, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.11941628680174102, "Bleu_3": 7.638223859874093e-07, "Bleu_4": 1.947169971344997e-09, "METEOR": 0.15373533070676557, "ROUGE_L": 0.20783645655877342, "CIDEr": 1.9681716197325604e-05, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.20833333333333334, "f": 0.23255813953488372, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a mother elephant and her baby taking a bath in a body of water. The mother elephant is swimming with her head above the water. The baby elephant is also swimming."}, "548219": {"image_id": 548219, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.26340122154667245, "Bleu_3": 0.22099054784871044, "Bleu_4": 0.1647014484209147, "METEOR": 0.3659900596654728, "ROUGE_L": 0.35765472312703583, "CIDEr": 5.770380304360099e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a black and white cat sitting on top of a red suitcase. The cat is looking out of the open suitcase. The cat is also hiding inside the suitcase.\n\nThe image is taken from a low angle, looking up at the cat. The lighting"}, "266117": {"image_id": 266117, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.18463723646331667, "Bleu_3": 0.13004758592304067, "Bleu_4": 0.0925329498886205, "METEOR": 0.22263559899475346, "ROUGE_L": 0.2497952497952498, "CIDEr": 0.00048333537286639617, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a black couch in a living room. The room has a window on the left side, through which a white wall can be seen. The floor is made of wood."}, "67881": {"image_id": 67881, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.12508887309711966, "Bleu_3": 7.574924114606953e-07, "Bleu_4": 1.8772266184831244e-09, "METEOR": 0.12820821219723913, "ROUGE_L": 0.21785714285714286, "CIDEr": 9.81099722022956e-05, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows three people playing baseball on a field. The players are wearing baseball uniforms and helmets, and one player is holding a bat. The field is made of dirt. There are no trees in the scene."}, "253177": {"image_id": 253177, "Bleu_1": 0.253731343279795, "Bleu_2": 0.12400668194996362, "Bleu_3": 0.06184799226301171, "Bleu_4": 7.797389177628595e-06, "METEOR": 0.17418761351397105, "ROUGE_L": 0.1679669573198715, "CIDEr": 8.55400859006111e-19, "SPICE": {"All": {"pr": 0.16, "re": 0.13793103448275862, "f": 0.14814814814814817, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image is a painting of two horses on a wall. The first horse is depicted with a brown coat and brown mane. The second horse is depicted as a cat in a tree, with a gray coat and gray mane. The painting is framed in three frames. The frames have pink mattes. The wall is painted orange. There is no trim or window in the scene."}, "196462": {"image_id": 196462, "Bleu_1": 0.14285714285612247, "Bleu_2": 0.1063261093095519, "Bleu_3": 0.07891944146263902, "Bleu_4": 0.06154926317940149, "METEOR": 0.1750115031650292, "ROUGE_L": 0.1396236012207528, "CIDEr": 9.71543488620889e-99, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.5, "f": 0.2, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows three plates on a table. Each plate has a different arrangement of food. \n\nPlate 1 has bread on the side, and a bowl of scrambled eggs, bread, and salad on it. \n\nPlate 2 also has bread on the side, and a bowl of eggs and toast on it. \n\nPlate 3 has a salad on the side, and a bowl of salad, bread, and an egg on it. \n\nThere is a glass with water in it, and a squirt of water on the side. The glass does not have a straw. \n\nThere are two slices of toast, one with a slice of cheese on top, and the other with a bowl of eggs on top. \n\nThere is also a bowl of salad and a fork on the table. \n\nThere is no other food or drink in the scene."}, "373424": {"image_id": 373424, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.19543398998956504, "Bleu_3": 0.15461557958393143, "Bleu_4": 0.10492161811761927, "METEOR": 0.24592720663335563, "ROUGE_L": 0.35091083413231067, "CIDEr": 1.1826093022541696e-13, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.18518518518518517, "f": 0.18518518518518517, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman sitting on a couch in front of a window with a view of snow-covered trees. The woman is wearing a blue sweater and black pants. A cat is sitting on the woman's lap. The cat on the woman's lap is orange and sitting on a blanket, while the other cat is gray and sitting on a box."}, "183217": {"image_id": 183217, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.12393943320197576, "Bleu_3": 0.07956212804929154, "Bleu_4": 0.05382598430424235, "METEOR": 0.17611828910576627, "ROUGE_L": 0.19273301737756712, "CIDEr": 1.7896294914492455e-17, "SPICE": {"All": {"pr": 0.1875, "re": 0.24, "f": 0.21052631578947367, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a box filled with various types of donuts. There are a total of twelve donuts in the box. The donuts include glazed, chocolate frosted, frosted, frosted with chocolate, frosted with coconut, frosted with coconut, frosted with coconut, frosted with coconut, frosted with coconut, frosted with coconut, frosted with coconut, and frosted with hearts. \n\nThe box is sitting on a table."}, "464622": {"image_id": 464622, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1824897193978171, "Bleu_3": 0.09045267833662957, "Bleu_4": 1.1388142795948563e-05, "METEOR": 0.22219931481440455, "ROUGE_L": 0.24416277518345564, "CIDEr": 7.507943968262116e-10, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.06060606060606061, "f": 0.08, "fn": 31.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows two tables with mason jars filled with oranges on them. The mason jars are labeled with the date and time. Oranges are inside the mason jars.\n\nThere are no other objects on the tables. The overall appearance of the image is clean and organized."}, "175737": {"image_id": 175737, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.10043712727569683, "Bleu_4": 1.2182355083925507e-05, "METEOR": 0.2183332699684469, "ROUGE_L": 0.19690122659780504, "CIDEr": 2.298932551411795e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 1.0, "f": 0.6, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two motorcycles parked on the side of a dirt road. The motorcycles are black and silver. The stripes on the motorcycles are black. \n\nThere is no desert in the scene. There are rocks on the side of the road. There are no bushes in the scene."}, "372756": {"image_id": 372756, "Bleu_1": 0.16666666666388893, "Bleu_2": 0.09205746178828507, "Bleu_3": 5.267000178020353e-07, "Bleu_4": 1.265329944373763e-09, "METEOR": 0.16587904088534428, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.915382698788e-15, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.20833333333333334, "f": 0.2, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a bird perched on a mirror. The bird has yellow and white feathers. It is sitting on a table. The mirror has a black frame and a round shape. The bird's reflection is visible in the mirror. The bird is looking directly at the camera with its beak open. The bird has a long, curly tail."}, "308316": {"image_id": 308316, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.12281268769488378, "Bleu_3": 0.06706647632268699, "Bleu_4": 8.857886206727456e-06, "METEOR": 0.1823409196371279, "ROUGE_L": 0.1920654911838791, "CIDEr": 3.4924552866799683e-12, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.07142857142857142, "f": 0.07017543859649124, "fn": 26.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image is of two aircraft flying in the sky. The pattern of the aircraft is a black and yellow pattern. A propeller is on the front of the aircraft. A green field is in the background.\n\nThere are no trees or buildings in the scene. The sky is clear and blue."}, "168416": {"image_id": 168416, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.20412414522676303, "Bleu_3": 0.10311813598199678, "Bleu_4": 1.312051431427763e-05, "METEOR": 0.20713379183769892, "ROUGE_L": 0.3139705882352941, "CIDEr": 3.6915481870476526e-05, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2777777777777778, "f": 0.20408163265306123, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a bird feeder hanging from a tree in a forest. The feeder is made of plastic. There is a bird on top of the feeder. The bird has green plumage. The feeder is surrounded by green leaves."}, "348496": {"image_id": 348496, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.15404159684489246, "Bleu_3": 0.10706719584566135, "Bleu_4": 0.0810085961909493, "METEOR": 0.1798419231147503, "ROUGE_L": 0.22521097046413502, "CIDEr": 2.5936160954172957e-14, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.09523809523809523, "f": 0.10256410256410256, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a river with boats and people on the water. There are buildings on the shore and a bridge in the background. The sky is blue and there are trees on the shore.\n\nThe image is taken from a high vantage point, looking down on the river and the people on it. The boats are on the water."}, "333677": {"image_id": 333677, "Bleu_1": 0.2666666666622222, "Bleu_2": 0.16467739391575578, "Bleu_3": 0.11194045746119323, "Bleu_4": 0.07043225514233839, "METEOR": 0.24814008416744182, "ROUGE_L": 0.28955696202531644, "CIDEr": 1.7754147982376075e-14, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16, "f": 0.14545454545454545, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a bedroom with a bed, a dresser, and two windows. The walls are painted white. The floor is made of wood.\n\nThere is a dog in the bedroom. The dog is laying on the bed.\n\nThere is no dresser in the room.\n\nThe bed is made up with a blue and white striped blanket and a pillow."}, "224364": {"image_id": 224364, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 7.990635300418294e-07, "Bleu_4": 1.8151458107416433e-09, "METEOR": 0.18929018772686282, "ROUGE_L": 0.18944099378881987, "CIDEr": 5.183215828967407e-10, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows four giraffes standing in a grassy area. They are all facing the same direction and appear to be looking at something in the distance. The giraffes are standing in a zoo and a forest. Some of the giraffes are eating leaves and branches. The grass is green."}, "551820": {"image_id": 551820, "Bleu_1": 0.21428571428265308, "Bleu_2": 0.1576220812455521, "Bleu_3": 0.12224517754579907, "Bleu_4": 0.08593351966030348, "METEOR": 0.22720636823314114, "ROUGE_L": 0.2647058823529412, "CIDEr": 2.5572655914440473e-23, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.18181818181818182, "f": 0.2285714285714286, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of five people playing tennis on a court. They are wearing black, blue, and white shirts, and holding tennis rackets. Some of the people are wearing white tennis shoes.\n\nThere are twelve spectators watching the game. Some of the spectators are watching the tennis match, while others are watching a skateboarder or a basketball game.\n\nThe overall scene depicts people playing tennis in a gym."}, "152962": {"image_id": 152962, "Bleu_1": 0.2023809523785431, "Bleu_2": 0.14813818733468606, "Bleu_3": 0.06444265131960462, "Bleu_4": 7.581563822621311e-06, "METEOR": 0.20768246174883714, "ROUGE_L": 0.1983739837398374, "CIDEr": 3.0709326240914737e-33, "SPICE": {"All": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of four people standing on a tennis court. The people are talking to each other. Some of them are wearing blue and white shirts, while others are wearing a black shirt. The man is holding a tennis racket. He is wearing a white shirt and black pants. The people are also wearing various colors of pants, including grey, Nike shorts, and shorts. The overall atmosphere of the scene is lively and engaging.\n\nThe image is in black and white."}, "32779": {"image_id": 32779, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.2659080117331791, "Bleu_3": 0.14871044110244871, "Bleu_4": 1.672799052297512e-05, "METEOR": 0.24692275808315067, "ROUGE_L": 0.34078212290502796, "CIDEr": 1.581480380821412e-06, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.2, "f": 0.16949152542372883, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a bedroom with two beds, a bathroom with a bathtub, and a living room with a bed. The walls are painted yellow and the floor is made of tile. There is a window in the living room that lets in natural light."}, "97767": {"image_id": 97767, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.24913643955277223, "Bleu_3": 0.2069786209646836, "Bleu_4": 0.16008869878752136, "METEOR": 0.3011173305476258, "ROUGE_L": 0.39757914338919925, "CIDEr": 0.025385222172936144, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a yellow fire hydrant on the sidewalk in front of a building. There is no hose or sign in the image. The building is made of brick."}, "349485": {"image_id": 349485, "Bleu_1": 0.12280701754170516, "Bleu_2": 0.08111071056394559, "Bleu_3": 0.062078503553751795, "Bleu_4": 0.04587831823896188, "METEOR": 0.19949899660457693, "ROUGE_L": 0.17805020431990656, "CIDEr": 3.928581732227617e-13, "SPICE": {"All": {"pr": 0.32, "re": 0.32, "f": 0.32, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a grocery store with various vegetables on display. Green peppers are on display in the grocery store. There are no fruits or shelves in the scene. There are bananas on the shelves. There are no oranges or other fruits in the scene. There is no refrigerator or meat or dairy products in the scene."}, "53635": {"image_id": 53635, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.1348279544430054, "Bleu_4": 1.6508456672891575e-05, "METEOR": 0.2787394690420027, "ROUGE_L": 0.33888888888888885, "CIDEr": 9.532395482128646e-05, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.09523809523809523, "f": 0.11764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a man riding a skateboard in a skate park. The man is skateboarding and holding the skateboard. He is wearing a blue t-shirt and blue jeans. The skate park is surrounded by trees."}, "87409": {"image_id": 87409, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.17039568890752202, "Bleu_3": 0.13243488460776973, "Bleu_4": 0.09867571387532262, "METEOR": 0.2120944508170559, "ROUGE_L": 0.26293103448275856, "CIDEr": 6.805266390902317e-11, "SPICE": {"All": {"pr": 0.375, "re": 0.2, "f": 0.26086956521739135, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows three people on a surfboard in the middle of a body of water. They are wearing black wetsuits and are holding on to the surfboard with their arms outstretched.\n\nThe water is calm and there are no waves in sight. The sky is clear and there are no clouds."}, "572095": {"image_id": 572095, "Bleu_1": 0.21428571428265308, "Bleu_2": 0.12461119656801366, "Bleu_3": 6.112258877289958e-07, "Bleu_4": 1.3587282474070894e-09, "METEOR": 0.1857347428755963, "ROUGE_L": 0.2006578947368421, "CIDEr": 5.874025978914452e-22, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2857142857142857, "f": 0.34285714285714286, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a line of six motorcycles parked on the side of a street. The motorcycles have different colors and styles, with some having chrome and others having black and silver. \n\nThere are six people standing next to the motorcycles. They are looking at the bikes and engaging in various activities, such as walking, shopping, and riding bikes. \n\nThe scene is also populated with a building and a tree."}, "251801": {"image_id": 251801, "Bleu_1": 0.1641791044751615, "Bleu_2": 0.11152493418469049, "Bleu_3": 0.07260282675752167, "Bleu_4": 0.04945043929983204, "METEOR": 0.14132238521370577, "ROUGE_L": 0.18309154577288642, "CIDEr": 1.0309271157573245e-20, "SPICE": {"All": {"pr": 0.16, "re": 0.12121212121212122, "f": 0.1379310344827586, "fn": 29.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a table with a variety of desserts on it. There are three desserts in total. The desserts include a variety of chocolate cake, a steamed cake, and a pineapple cake. \n\nThe table is set up with a green tablecloth. There are four plates and two cups on the table. \n\nThere is no cake on the table. The desserts are arranged in a creative way."}, "432017": {"image_id": 432017, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.19963735236767363, "Bleu_3": 1.2190465996349817e-06, "Bleu_4": 3.04761713618387e-09, "METEOR": 0.20660862232067295, "ROUGE_L": 0.2955426356589147, "CIDEr": 0.05907385275688412, "SPICE": {"All": {"pr": 0.1, "re": 0.09523809523809523, "f": 0.0975609756097561, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a clock tower made of metal. The clock tower has a clock face with Roman numerals. The clock face is large."}, "139605": {"image_id": 139605, "Bleu_1": 0.382352941165225, "Bleu_2": 0.24069122088509454, "Bleu_3": 0.12187749155325173, "Bleu_4": 1.5545410934818913e-05, "METEOR": 0.21567728227784694, "ROUGE_L": 0.25979557069846676, "CIDEr": 0.00023647191950804764, "SPICE": {"All": {"pr": 0.1875, "re": 0.125, "f": 0.15, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a boat sailing in the ocean near a lighthouse. The lighthouse has a white roof. The boat has a white hull and a blue sail. The water is calm and clear."}, "137395": {"image_id": 137395, "Bleu_1": 0.2413793103365042, "Bleu_2": 0.13130643285511392, "Bleu_3": 8.611313773805956e-07, "Bleu_4": 2.226172038512766e-09, "METEOR": 0.1665075544864047, "ROUGE_L": 0.22001803426510366, "CIDEr": 0.0025849830187043045, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two people playing baseball in a cage. The players are wearing helmets and using bats. However, there is no mention of gloves in the supplementary information."}, "309279": {"image_id": 309279, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.10256784899095028, "Bleu_3": 0.056935422350642036, "Bleu_4": 7.576871174126601e-06, "METEOR": 0.1766103673660142, "ROUGE_L": 0.249616368286445, "CIDEr": 2.9698348344240336e-12, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.20833333333333334, "f": 0.1754385964912281, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows three cakes on three plates. A slice of lemon is on top of the first cake, a slice of cake is on top of the second cake, and a slice of orange is on top of the third cake. There are two forks on the plates, one of which has a bite taken out of it."}, "33221": {"image_id": 33221, "Bleu_1": 0.1382978723389543, "Bleu_2": 0.11568779133908723, "Bleu_3": 0.06626320063815033, "Bleu_4": 7.519586489247982e-06, "METEOR": 0.1704739740829529, "ROUGE_L": 0.18007380073800736, "CIDEr": 8.24455123199224e-32, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.23529411764705882, "f": 0.22857142857142856, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a group of six people standing on a beach. The people are holding suitcases, a bag and a frisbee, a frisbee, a kite, and a skateboard. The people are wearing black vests, blue vests, and yellow and white vests. The people are also wearing black and white hats, blue hats, and yellow hats. One person is holding a large ball, another person is holding a slingshot, and the third person is holding a sledgehammer. In the background, there is a palm tree.\n\nThe overall scene shows people standing on the beach."}, "272925": {"image_id": 272925, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 6.880010617668035e-07, "Bleu_4": 1.631181823642126e-09, "METEOR": 0.17308071260614372, "ROUGE_L": 0.2576946288473144, "CIDEr": 1.3268056143712388e-09, "SPICE": {"All": {"pr": 0.375, "re": 0.20689655172413793, "f": 0.26666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a sidewalk covered in confetti. There are no people, streets, umbrellas, or sky in the scene. However, there is a fire hydrant on the corner.\n\nThe image is taken from a low angle, looking down at the scene. The confetti is scattered all over the sidewalk."}, "231471": {"image_id": 231471, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.16064386577523138, "Bleu_3": 9.618560885253057e-07, "Bleu_4": 2.374340857937043e-09, "METEOR": 0.18542072279394023, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.0011390439286398954, "SPICE": {"All": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of twelve ducks swimming in a river next to a park bench. The park bench is made of wood. The ducks are swimming in the water."}, "152795": {"image_id": 152795, "Bleu_1": 0.3199999999872001, "Bleu_2": 0.2309401076664203, "Bleu_3": 0.1323600626202131, "Bleu_4": 1.801822694784617e-05, "METEOR": 0.227046622757572, "ROUGE_L": 0.26725082146768897, "CIDEr": 0.02198206591636004, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.14814814814814814, "f": 0.1818181818181818, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a bunch of bananas hanging from a metal railing. The bananas are green and ripe. The bananas are hanging from the railing."}, "489046": {"image_id": 489046, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.17739371879401636, "Bleu_3": 0.13496531382971108, "Bleu_4": 0.07903718961099786, "METEOR": 0.2516294423386595, "ROUGE_L": 0.23851417399804498, "CIDEr": 1.770497098394568e-19, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16666666666666666, "f": 0.15686274509803924, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a bird perched on a branch of a tree growing in a body of water. The bird has a brown and green plumage. The bird's beak is long and curved, resembling the shape of a kingfisher's beak. The tree has green leaves. The water is clear and calm. The sky is blue and there are no other objects in the image."}, "215808": {"image_id": 215808, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.19806961801469586, "Bleu_4": 0.16302913592071108, "METEOR": 0.3396649503006859, "ROUGE_L": 0.35765472312703583, "CIDEr": 4.0108228583750044e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1111111111111111, "f": 0.10909090909090909, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a slice of carrot cake on a plate with a fork on the side. The cake is decorated with peanut butter frosting and has a scoop of peanut butter on top. There is a glass of milk on the table next to the plate."}, "197716": {"image_id": 197716, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.20140768086634514, "Bleu_4": 0.16153316780581992, "METEOR": 0.296195391657294, "ROUGE_L": 0.400437636761488, "CIDEr": 8.687465531039368e-06, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.25, "f": 0.27027027027027023, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.75, "f": 0.8571428571428571, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a blue and orange bus driving down a street with houses on either side. The bus has a number on the side. The grass is green and there are trees on the side of the road."}, "330204": {"image_id": 330204, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.23783535599888, "Bleu_3": 0.18736341508412688, "Bleu_4": 0.15820356672588365, "METEOR": 0.3439643258962121, "ROUGE_L": 0.32084155161078237, "CIDEr": 8.666690783560517e-07, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.32, "f": 0.2388059701492537, "fn": 17.0, "numImages": 1.0, "fp": 34.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.06666666666666667, "re": 0.14285714285714285, "f": 0.09090909090909091, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5454545454545454, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "The image shows a bus parked in front of a building. The bus is green and yellow. The sign on the side of the bus reads \"cleveland bus\". There are three people standing in front of the bus. The people are looking at the bus."}, "150703": {"image_id": 150703, "Bleu_1": 0.2238805970115839, "Bleu_2": 0.1426631751581299, "Bleu_3": 0.0855552773277329, "Bleu_4": 0.05592939339701023, "METEOR": 0.17818584850801047, "ROUGE_L": 0.22771815212319177, "CIDEr": 2.3028410295253094e-18, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.23529411764705882, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a hot dog and a drink on a table. The hot dog is wrapped in a bun. It has ketchup and mustard on it. The hot dog is also topped with tomato, pickles, and onions. The hot dog is wrapped in a paper bag.\n\nThe table is made of wood. It has a white tablecloth on it. There is no napkin in the scene."}, "497928": {"image_id": 497928, "Bleu_1": 0.5714285714081633, "Bleu_2": 0.35634832253693677, "Bleu_3": 0.16966490952037497, "Bleu_4": 2.1023693682472793e-05, "METEOR": 0.20275427523946904, "ROUGE_L": 0.2901077996195307, "CIDEr": 0.05349686164091669, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.19047619047619047, "f": 0.1568627450980392, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a living room with a white couch, a television on the wall, and a window. The room is well lit and has a comfortable atmosphere."}, "91334": {"image_id": 91334, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.18871982178961313, "Bleu_3": 0.15817245013940903, "Bleu_4": 0.1281637706389262, "METEOR": 0.26883183373049124, "ROUGE_L": 0.32555036691127415, "CIDEr": 2.7567166481769015e-09, "SPICE": {"All": {"pr": 0.1, "re": 0.15789473684210525, "f": 0.12244897959183673, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.3333333333333333, "f": 0.23076923076923078, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image shows a cat drinking water from a bowl. The cat's head is tilting back and forth as it drinks. The bowl is made of plastic and does not have a handle. There is water in the bowl. \n\nThe cat is sitting on a table."}, "191053": {"image_id": 191053, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.16189403144554257, "Bleu_3": 0.09559755986510447, "Bleu_4": 1.3174544410426687e-05, "METEOR": 0.25506424732204286, "ROUGE_L": 0.2713523131672598, "CIDEr": 0.0013255420188777128, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15, "f": 0.15789473684210525, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a boy sitting on the floor in a living room. The boy is posing for a picture. He is wearing a white shirt and a blue and yellow tie."}, "300323": {"image_id": 300323, "Bleu_1": 0.42553191488456316, "Bleu_2": 0.35987457985098253, "Bleu_3": 0.2844853707281499, "Bleu_4": 0.19904996166719055, "METEOR": 0.28641983070721216, "ROUGE_L": 0.34163036714374606, "CIDEr": 2.8605487626343146e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a woman standing in a living room. The woman is holding a wii remote in her hand. She is wearing a white shirt and tan pants. There is no television in the scene. There is no furniture, couch, or coffee table in the background."}, "66423": {"image_id": 66423, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.1402573746613369, "Bleu_3": 0.08736613667841296, "Bleu_4": 1.0355005892559527e-05, "METEOR": 0.22686158090770076, "ROUGE_L": 0.27546412443552437, "CIDEr": 2.58245291260715e-15, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15, "f": 0.13953488372093023, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of six people standing on surfboards in the ocean. The people are wearing wetsuits and holding surfboards. Some of the people are wearing blue shirts. The people are standing in the ocean and on the shore. \n\nThere are five surfboards in the image. \n\nIn the background, there is a volcano. Waves are breaking on the shore."}, "223122": {"image_id": 223122, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.22190634114281918, "Bleu_3": 0.11667896745206957, "Bleu_4": 1.5169250360908672e-05, "METEOR": 0.31097609530941395, "ROUGE_L": 0.3836477987421384, "CIDEr": 0.0001870660479136436, "SPICE": {"All": {"pr": 0.25, "re": 0.17142857142857143, "f": 0.2033898305084746, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a small bathroom with a toilet, sink, and shower. The walls are white. The room does not have a window. There is no floor, tile, or rug in the scene."}, "390718": {"image_id": 390718, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.1819804470697048, "Bleu_3": 0.1070438934390262, "Bleu_4": 1.2333957720218137e-05, "METEOR": 0.23962688225031042, "ROUGE_L": 0.26940063091482647, "CIDEr": 5.166052544946266e-12, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.22727272727272727, "f": 0.29411764705882354, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a group of two men playing baseball in a park. They are wearing baseball uniforms and one of them is holding a bat. The field is like a baseball field. There is a tree in the background.\n\nThere are no gloves in the scene.\n\nThere is no sky or cloud in the scene."}, "46508": {"image_id": 46508, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.15422177271257892, "Bleu_3": 0.11932216243528104, "Bleu_4": 0.09541186197242199, "METEOR": 0.21428171754272543, "ROUGE_L": 0.25702247191011235, "CIDEr": 2.507611399696253e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21052631578947367, "f": 0.186046511627907, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man riding an elephant. The man is wearing a brown jacket. The elephant is wearing a saddle. There is a tree in the background.\n\nThere is no bicycle or helmet in the image. There is no grass in the scene.\n\n"}, "526576": {"image_id": 526576, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.2793721183009322, "Bleu_3": 0.21548837176462718, "Bleu_4": 0.18015112494343735, "METEOR": 0.34436175510256534, "ROUGE_L": 0.3617494440326167, "CIDEr": 5.114584032508901e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man standing in front of a wall. The man is wearing a blue and white shirt and black pants. He is holding his mouth with his right hand and standing in a crouch. His legs are bent."}, "581717": {"image_id": 581717, "Bleu_1": 0.222222222217284, "Bleu_2": 0.1740776559517855, "Bleu_3": 0.11211985653837894, "Bleu_4": 0.0761113766870077, "METEOR": 0.21794700803243328, "ROUGE_L": 0.25258799171842644, "CIDEr": 1.430603896370283e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.17647058823529413, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a cat peeking out of a suitcase. The cat is looking up at the camera. The suitcase is open. There is a collar on the cat's neck. The suitcase contains a pile of clothes. The background is a dark brown color."}, "307683": {"image_id": 307683, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.19973386548003494, "Bleu_3": 0.12015039217497778, "Bleu_4": 1.4011697930921418e-05, "METEOR": 0.23512381742682278, "ROUGE_L": 0.2635802469135803, "CIDEr": 3.4487104693483294e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person sitting on a blanket. In front of the person, there is a plate with a sandwich, an apple, and a glass on it.\n\nThere is no green field or trees in the scene. The person is not wearing a blue shirt or jeans."}, "580757": {"image_id": 580757, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.23924685418403427, "Bleu_3": 0.20519598703738454, "Bleu_4": 0.16977287863592969, "METEOR": 0.23802490524920686, "ROUGE_L": 0.3099943534726144, "CIDEr": 1.8542002559006812e-12, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.25, "f": 0.2926829268292683, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a fire hydrant painted in red, white, and blue colors. The fire hydrant is decorated with a patriotic design, including a red, white, and blue striped pattern on the body. On top of the fire hydrant, there is a blue star. The flag on top is a red, white, and blue strip."}, "230995": {"image_id": 230995, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.2444257647581566, "Bleu_3": 0.18793910397544641, "Bleu_4": 0.13955755488666227, "METEOR": 0.23206221236411764, "ROUGE_L": 0.3259541984732824, "CIDEr": 2.357095793664409e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.17647058823529413, "f": 0.1935483870967742, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a woman sitting on the sidewalk with an umbrella over her head. She is wearing a blue shirt and gray pants. The umbrella has a striped pattern. The woman is not looking at her phone."}, "242779": {"image_id": 242779, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.07926525909642891, "Bleu_4": 9.990095999341766e-06, "METEOR": 0.20157807091755506, "ROUGE_L": 0.2943699731903485, "CIDEr": 1.0012448903529936e-09, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.20833333333333334, "f": 0.1923076923076923, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress. There is no baseball game in the image. The players are standing on the field. The player is wearing a white uniform. The umpire is standing behind home plate. There is no home plate in the image. The scoreboard shows the score of the game."}, "70815": {"image_id": 70815, "Bleu_1": 0.22499999999437506, "Bleu_2": 0.13155870289272328, "Bleu_3": 7.693994231890818e-07, "Bleu_4": 1.873110771279216e-09, "METEOR": 0.15469984029990955, "ROUGE_L": 0.23680124223602486, "CIDEr": 1.001817375009338e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21428571428571427, "f": 0.1875, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a dog standing on the sidewalk. The dog is wearing a harness. There are two bicycles in the scene. A styrofoam cup is next to one of the bicycles. A person is also present in the scene."}, "477688": {"image_id": 477688, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.09829463743443755, "Bleu_3": 6.033032403124956e-07, "Bleu_4": 1.5032618275449672e-09, "METEOR": 0.19401849144236338, "ROUGE_L": 0.23135271807838179, "CIDEr": 1.4044318125778737e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.21739130434782608, "f": 0.23809523809523808, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a police officer standing in front of a line of motorcycles. The police officer is wearing a black and yellow helmet and is holding the motorcycles with their arms. The motorcycles are black and white, with the words \"BMW\" written on the side."}, "411841": {"image_id": 411841, "Bleu_1": 0.36538461537758876, "Bleu_2": 0.26766404732330973, "Bleu_3": 0.20485839967523833, "Bleu_4": 0.15146825617022444, "METEOR": 0.2384622337708957, "ROUGE_L": 0.26293103448275856, "CIDEr": 1.1436770663213674e-11, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.23076923076923078, "f": 0.19047619047619047, "fn": 20.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5555555555555556, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a building with a red and white plane parked in front of it. The building is a terminal of Makati Airport. The sign on the building reads \"Naha Airport\". The letters on the sign are blue. The plane has a red and white tail and white and red wings."}, "153150": {"image_id": 153150, "Bleu_1": 0.6666666666349207, "Bleu_2": 0.4472135954781297, "Bleu_3": 0.3160816010076583, "Bleu_4": 0.20465920654800618, "METEOR": 0.3932249165105456, "ROUGE_L": 0.6623235613463625, "CIDEr": 0.413916260936587, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a dog lying on a bed. The dog is wearing a blue collar with an orange bow tie."}, "284860": {"image_id": 284860, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.09600307214592775, "Bleu_3": 5.326151009485259e-07, "Bleu_4": 1.2597149807623247e-09, "METEOR": 0.1499808530883995, "ROUGE_L": 0.22067183462532297, "CIDEr": 6.245972350765036e-17, "SPICE": {"All": {"pr": 0.125, "re": 0.19047619047619047, "f": 0.1509433962264151, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.36363636363636365, "f": 0.2962962962962963, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a street with a black light at the corner. There is a building on the right side of the street, which is brown. A post box is on the left side of the street. The street is empty and there are no cars or people in the image.\n\nThe image is taken from a low angle, looking down the street."}, "145061": {"image_id": 145061, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.24911189772076184, "Bleu_3": 0.15936176133847452, "Bleu_4": 0.09738340653916805, "METEOR": 0.26408279904944154, "ROUGE_L": 0.27371794871794874, "CIDEr": 1.0402638799518705e-08, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.18181818181818182, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a street with a bus stop on the corner. There is a car parked on the side of the road. A stop sign is on the corner of the street. There are no pedestrians or sky in the image. There are trees in the background."}, "535591": {"image_id": 535591, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.20159019488753482, "Bleu_3": 0.14716669660616322, "Bleu_4": 0.08935413502510754, "METEOR": 0.2513173020122495, "ROUGE_L": 0.27774615822424586, "CIDEr": 1.1179358561512741e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.21052631578947367, "f": 0.2222222222222222, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a train station with a train on the tracks. There are mountains in the background. The sky is clear and blue.\n\nThe train station has a small platform, but there are no benches or signs. There is a building with a door and a garbage can in front of it."}, "443537": {"image_id": 443537, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.21103178185560523, "Bleu_3": 0.13402155970338947, "Bleu_4": 1.6080715766744762e-05, "METEOR": 0.24818625172831302, "ROUGE_L": 0.22846441947565538, "CIDEr": 3.9426162073856856e-05, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.16666666666666666, "f": 0.1276595744680851, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two black cats lying on a bed. The cats are laying on the dog. The dog is black and white. The bed is covered in a blanket. \n\nThere is no lamp or nightstand in the scene."}, "306426": {"image_id": 306426, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.10714285714064781, "Bleu_3": 6.250904486134178e-07, "Bleu_4": 1.5179857311603866e-09, "METEOR": 0.1806210432291751, "ROUGE_L": 0.236281471917366, "CIDEr": 4.355374747528328e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.24242424242424243, "f": 0.2807017543859649, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.4, "re": 0.13333333333333333, "f": 0.2, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.4, "f": 0.48, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a woman wearing a blue shirt and white pants kneeling on a table, cutting a long, thin piece of dough with a knife. The woman is surrounded by other women in white aprons and hats, all of whom are working on various tasks in the kitchen."}, "346972": {"image_id": 346972, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.22086305214437038, "Bleu_3": 0.16959591199172672, "Bleu_4": 0.1391796360991585, "METEOR": 0.2500634653376763, "ROUGE_L": 0.3292847503373819, "CIDEr": 2.579738838447772e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a woman standing in the kitchen. She is washing dishes and cleaning the sink. The woman is holding a sponge. She is wearing a brown shirt and blue jeans. Her hair is short and tied back in a ponytail."}, "359659": {"image_id": 359659, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 8.081987454730765e-07, "Bleu_4": 1.8117138691105226e-09, "METEOR": 0.22004938265474921, "ROUGE_L": 0.18373493975903615, "CIDEr": 2.0149470491676363e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.8, "re": 0.4444444444444444, "f": 0.5714285714285714, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a toilet, sink, and mirror. The walls are tan and the floor is made of wood. There is a window on the left side of the room. There are two doors, both on the left side. The room is well lit and has a clean appearance."}, "332407": {"image_id": 332407, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.1462544848210594, "Bleu_3": 0.11016225079815198, "Bleu_4": 0.08103715339000786, "METEOR": 0.17825573393252964, "ROUGE_L": 0.2674656533177433, "CIDEr": 0.002334816306473111, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of three people playing baseball on a field. The people are wearing a baseball uniform. The adults are holding a baseball bat. The children are wearing a baseball glove."}, "310442": {"image_id": 310442, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.19847906537590718, "Bleu_3": 0.130644640808071, "Bleu_4": 0.08092223395268255, "METEOR": 0.2751388472266807, "ROUGE_L": 0.31642651296829977, "CIDEr": 8.225276017334945e-12, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.22727272727272727, "f": 0.25641025641025644, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a woman riding a bicycle on a sidewalk. She is wearing a white shirt with a black cat on it. Additionally, there is a black cat sitting on her head. The woman is smiling and appears to be enjoying the ride. The background consists of a residential area with trees and houses."}, "339344": {"image_id": 339344, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.23063280200236536, "Bleu_3": 0.16661525806434221, "Bleu_4": 0.13251445746056092, "METEOR": 0.26854384542183596, "ROUGE_L": 0.29901960784313725, "CIDEr": 8.594518381838623e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a school bus driving down a street in a residential area. The bus is yellow. A bus is parked on the side of the road. There are trees and houses visible in the background. The sky is blue and there are clouds in the distance."}, "395997": {"image_id": 395997, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.13819269959596528, "Bleu_3": 0.09740171167974562, "Bleu_4": 1.1094110391125546e-05, "METEOR": 0.23224768510355895, "ROUGE_L": 0.18673469387755104, "CIDEr": 1.0930591185472937e-17, "SPICE": {"All": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 4.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a dog sitting in the back seat of a car. The car is driving down the street. A bus is passing by the car. The dog is looking out the window. \n\nThere are no other cars in the scene.\n\nThere is no golden retriever in the scene.\n\nThere are no trees in the scene.\n\nThere are no buildings in the scene."}, "288633": {"image_id": 288633, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.07808688094237472, "Bleu_3": 5.387209294115685e-07, "Bleu_4": 1.4242196946570861e-09, "METEOR": 0.2095620204767752, "ROUGE_L": 0.1717100633356791, "CIDEr": 7.108527021069023e-07, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.8333333333333334, "f": 0.5263157894736842, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows two streets with a horse-drawn carriage on one of them. The streets are lined with trees. There are two people walking on the sidewalk. One of the buildings is a large red brick building with a clock tower."}, "248334": {"image_id": 248334, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.2078097333810539, "Bleu_3": 1.0528746809095736e-06, "Bleu_4": 2.386200247223795e-09, "METEOR": 0.20254543972678116, "ROUGE_L": 0.2347959969207082, "CIDEr": 3.949945699918347e-05, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.24242424242424243, "f": 0.3076923076923077, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7777777777777778, "re": 0.5, "f": 0.6086956521739131, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}}, "caption": "The image shows a boat floating on a river. The boat is filled with children, who are riding it. The river is surrounded by lush green vegetation. The sun is shining brightly overhead. The water is calm and clear."}, "228541": {"image_id": 228541, "Bleu_1": 0.21212121211799817, "Bleu_2": 0.1399300524541518, "Bleu_3": 0.09718243089729395, "Bleu_4": 0.06178110636217584, "METEOR": 0.2579729738827192, "ROUGE_L": 0.17888563049853376, "CIDEr": 2.912538536924879e-19, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "There are no people in this image. There are two buildings in the scene. A bus stop is in front of each building, and there are no cars parked in front of the buildings. A yellow fire hydrant is visible in the foreground.\n\nThere are no windows or cars in the scene. The sky is clear and blue, with a few clouds visible in the distance."}, "351667": {"image_id": 351667, "Bleu_1": 0.13725490195809306, "Bleu_2": 1.6568337391262165e-09, "Bleu_3": 3.826372616523305e-12, "Bleu_4": 1.8483326514023874e-13, "METEOR": 0.06700167504187604, "ROUGE_L": 0.11708253358925143, "CIDEr": 3.432862375340731e-09, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3, "f": 0.3243243243243243, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows four pizzas in a baking dish. One pizza has tomato slices on top and the other has cheese and meat on top. The pizzas are in a baking dish. There is no lid on top of the baking dish. The dish is on a countertop in a kitchen."}, "243950": {"image_id": 243950, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.23948888444560104, "Bleu_3": 0.11573276595218217, "Bleu_4": 1.4405111503153814e-05, "METEOR": 0.208691121786025, "ROUGE_L": 0.3299526707234618, "CIDEr": 0.00035452707935568857, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a woman wearing a white tennis outfit playing a tennis match on a grass court. She is holding a tennis racket in her left hand. The crowd is watching her. The sky is clear and sunny."}, "120070": {"image_id": 120070, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.12253577034561024, "Bleu_3": 7.541989245962001e-07, "Bleu_4": 1.884710726818381e-09, "METEOR": 0.15163103891231333, "ROUGE_L": 0.1798084008843036, "CIDEr": 1.720286098313602e-05, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3333333333333333, "f": 0.2962962962962963, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows two men sitting at desks in a room. The men are typing on laptops. The laptops are in front of the men. The room is not brightly lit. The men's shirts are gray."}, "539196": {"image_id": 539196, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.10846522890718009, "Bleu_3": 6.215293828145829e-07, "Bleu_4": 1.4954983534640539e-09, "METEOR": 0.1965667612118209, "ROUGE_L": 0.24002248454187747, "CIDEr": 1.2954557346993036e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two white horses standing in a stable. The horses are looking over the fence. One horse is wearing a halter and the other horse is wearing a saddle. The stable is made of wood and has a wooden roof. The horses' heads are sticking out of the door."}, "163451": {"image_id": 163451, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1457945082861785, "Bleu_3": 0.07846510342081583, "Bleu_4": 1.029533066265393e-05, "METEOR": 0.17218243526955834, "ROUGE_L": 0.16158940397350993, "CIDEr": 3.3156975872509686e-08, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.04, "f": 0.0392156862745098, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows three people sitting on the ground. One of the people is holding a baby in her arms. The people are wearing casual clothes. The baby is wearing a red dress and is holding a cell phone. The people are looking at the baby."}, "401808": {"image_id": 401808, "Bleu_1": 0.3199999999936, "Bleu_2": 0.21380899352561972, "Bleu_3": 0.14189834119414174, "Bleu_4": 0.08829955693848539, "METEOR": 0.2588328744534295, "ROUGE_L": 0.26228501228501233, "CIDEr": 8.757246832283839e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14285714285714285, "f": 0.1568627450980392, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man standing on a beach with his dog. The man is wearing a black shirt and blue jeans. The dog's collar is black. The beach is covered in rocks and there are mountains in the background. The sky is clear and there are no clouds."}, "325357": {"image_id": 325357, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.25661967682415326, "Bleu_3": 0.2163825246281965, "Bleu_4": 0.1807114773547797, "METEOR": 0.3050545622639891, "ROUGE_L": 0.3617494440326167, "CIDEr": 8.846733690597439e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a metal pot sitting on a brick hearth in front of a brick wall. The pot is made of metal and does not have a handle. The hearth is made of brick. The wall is made of brick."}, "104980": {"image_id": 104980, "Bleu_1": 0.2394366197149375, "Bleu_2": 0.16542123536561942, "Bleu_3": 0.09256663465643017, "Bleu_4": 1.039234672667418e-05, "METEOR": 0.22454659697222917, "ROUGE_L": 0.20343020485945684, "CIDEr": 6.746646891307066e-22, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man standing in front of a bar. The man is looking at his cell phone. The man is wearing a white shirt and black pants. The man does not have a tattoo on his left arm.\n\nBehind the man, there are two people. The people are drinking beer. The people are wearing t-shirts. The people are drinking from a bottle. \n\nThere is no glasses in the scene."}, "467593": {"image_id": 467593, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.2717786532439402, "Bleu_3": 0.13356407584880067, "Bleu_4": 1.6787535109825208e-05, "METEOR": 0.24729345240382528, "ROUGE_L": 0.3288409703504044, "CIDEr": 0.0002901371081876165, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.08333333333333333, "f": 0.0851063829787234, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a peacock with bright green, blue, and purple feathers. The peacock is looking out of a cage. The peacock's eyes are blue. The peacock is standing behind a fence."}, "301236": {"image_id": 301236, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2138186907385403, "Bleu_3": 0.13906381417319805, "Bleu_4": 0.08563831261527419, "METEOR": 0.1558216761391356, "ROUGE_L": 0.29781924704350654, "CIDEr": 0.0005639302011330533, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.14814814814814814, "f": 0.1951219512195122, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows two zebras standing in front of a car window. The zebras are wearing striped coats and do not have tags on their necks. The car window is open and there is a reflection of a zebra in the glass. The background is a brown field with trees in the distance."}, "313783": {"image_id": 313783, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.16582725333093248, "Bleu_3": 0.09713972135124138, "Bleu_4": 0.06278192634850849, "METEOR": 0.24891004816155748, "ROUGE_L": 0.24621594349142278, "CIDEr": 2.021195842981301e-16, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a plate with a grilled chicken patty, carrots and mashed potatoes on it. The plate is on a white plate. There is a fork on the side of the plate.\n\nThere is no grilled chicken patty, carrots, or mashed potatoes in the image. There is no knife in the image. There is no wall or window in the image."}, "437347": {"image_id": 437347, "Bleu_1": 0.1388888888876029, "Bleu_2": 0.08056137408638922, "Bleu_3": 3.941388892285078e-07, "Bleu_4": 8.738555351333771e-10, "METEOR": 0.09480438558914871, "ROUGE_L": 0.0985142118863049, "CIDEr": 1.383002008120531e-56, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.18518518518518517, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows three people in a street in front of two buildings. \n\nThe first person is throwing a baseball and is about to hit a ball. They are wearing a white shirt and black pants. \n\nThe second person is catching a frisbee and is holding a skateboard. They are wearing a black and white striped shirt and black pants. \n\nThe third person is riding a bike and is holding a phone. They are wearing a black and white striped shirt and black pants. \n\nThe buildings are made of red brick and have windows on the upper floors. \n\nThere are no baseball bats or balls in the image."}, "210990": {"image_id": 210990, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.19374606456772306, "Bleu_3": 0.1289662020068933, "Bleu_4": 1.5848464939717993e-05, "METEOR": 0.16613044982421926, "ROUGE_L": 0.23088569265707795, "CIDEr": 2.8006268694293546e-05, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.16129032258064516, "f": 0.16666666666666669, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two people skiing down a snowy mountain slope. Both people are wearing blue ski suits and have backpacks on their backs. The mountain is covered in snow and there are rocks in the background."}, "244468": {"image_id": 244468, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.13245323570415993, "Bleu_3": 0.06832623415157835, "Bleu_4": 8.766821695974853e-06, "METEOR": 0.20224095408467327, "ROUGE_L": 0.20670958996950187, "CIDEr": 4.867745748773063e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a small kitten sitting on a wooden fence. The kitten is looking at the camera and a tree. Its ears are positioned on the side of its head, and they are pinned back. The kitten's tail is curled. The barn is red and has a wooden door with a window on the side."}, "379161": {"image_id": 379161, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.16097271743377828, "Bleu_3": 0.10901632019691793, "Bleu_4": 0.06845507269089697, "METEOR": 0.21459825166907928, "ROUGE_L": 0.2323177366702938, "CIDEr": 4.0306130119579963e-17, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a vase with a bunch of red berries in it. The vase is sitting on a table. The table has a white tablecloth on it and there are two chairs in front of it. In front of the window, there is a green plant. The window provides a blurry view of the city. The room has a wooden floor."}, "446136": {"image_id": 446136, "Bleu_1": 0.4772727272618802, "Bleu_2": 0.3649553246634688, "Bleu_3": 0.2810451226260416, "Bleu_4": 0.21572529583166192, "METEOR": 0.3146564279850917, "ROUGE_L": 0.4066666666666667, "CIDEr": 1.500587474289266e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.23529411764705882, "f": 0.1702127659574468, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.8, "f": 0.4444444444444444, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of five people sitting around a table with plates of food in front of them. The people are eating dinner, a meal, and a pizza. The table is covered in a tablecloth and there are candles on the table."}, "193021": {"image_id": 193021, "Bleu_1": 0.6428571428341837, "Bleu_2": 0.40824829044901273, "Bleu_3": 0.2679161449086303, "Bleu_4": 2.96151653589967e-05, "METEOR": 0.37469401821284387, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.062145019308331204, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a kitchen with wooden floors, brown cabinets, and a dining table with three chairs in the center of the room. There is a chandelier hanging."}, "350099": {"image_id": 350099, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1457945082861785, "Bleu_3": 0.07846510342081583, "Bleu_4": 1.029533066265393e-05, "METEOR": 0.16424820046163835, "ROUGE_L": 0.2367399741267788, "CIDEr": 1.5062811823636726e-08, "SPICE": {"All": {"pr": 0.375, "re": 0.2, "f": 0.26086956521739135, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a person standing on a skateboard in the middle of a field. The person is wearing a black suit and holding onto the skateboard. The sky is cloudy and there are trees in the background.\n\nThe image is taken from a low angle."}, "285433": {"image_id": 285433, "Bleu_1": 0.1666666666650327, "Bleu_2": 0.11489699792315322, "Bleu_3": 0.05091813102370373, "Bleu_4": 6.042901872865776e-06, "METEOR": 0.1855009793801862, "ROUGE_L": 0.1697981906750174, "CIDEr": 1.152093367513285e-51, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.17857142857142858, "f": 0.20408163265306123, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a toilet, sink, and mirror. The walls are white and the floor is made of tile. There is a window in the bathroom.\n\nThe toilet is made of white porcelain and has a seat. The sink is a bathroom sink.\n\nThere is no mirror in the scene.\n\nThere is no wall in the scene.\n\nThere is no tile in the scene.\n\nThere is no window in the scene.\n\nThere is no bowl in the scene.\n\nThere are two seats in the scene.\n\nThere is no lid in the scene.\n\nThere is no bathroom in the scene."}, "471842": {"image_id": 471842, "Bleu_1": 0.2666666666622222, "Bleu_2": 0.22297424542449404, "Bleu_3": 0.15079275220630997, "Bleu_4": 0.1047307312517398, "METEOR": 0.29037669423849577, "ROUGE_L": 0.28416149068322977, "CIDEr": 5.791424273522752e-15, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15384615384615385, "f": 0.14814814814814817, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a plate of food with a piece of cake on it. The cake is topped with blueberries and has blue and white frosting on it. There is a fork placed on top of the cake. The cake is placed on a table. \n\nThere are two glasses on the table, but there is no wine in the glasses."}, "24734": {"image_id": 24734, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.3077935056097516, "Bleu_3": 0.17394640853977758, "Bleu_4": 2.358844810525448e-05, "METEOR": 0.21185566859067445, "ROUGE_L": 0.4477768456375839, "CIDEr": 0.23469982249622762, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.27586206896551724, "f": 0.27586206896551724, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a pizza with black olives as the toppings. The pizza is on a plate on a table."}, "270222": {"image_id": 270222, "Bleu_1": 0.2153846153813018, "Bleu_2": 0.08204126541296468, "Bleu_3": 4.745056453593857e-07, "Bleu_4": 1.1457321911034339e-09, "METEOR": 0.15609756097560978, "ROUGE_L": 0.18174595292481877, "CIDEr": 1.6791058688655823e-18, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.13513513513513514, "f": 0.15151515151515152, "fn": 32.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.26666666666666666, "f": 0.28571428571428575, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a clock tower with a large clock face on the front. The clock face has numbers and hands. There are three other clocks located on the sides of the tower. The clock tower is made of stone and has a steeple. There are several windows on the sides of the tower. The clock face on the tower has a lot of figurines."}, "330265": {"image_id": 330265, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.11805626721734597, "Bleu_3": 7.03675938605906e-07, "Bleu_4": 1.7288741230850778e-09, "METEOR": 0.1903572837223, "ROUGE_L": 0.2109266943291839, "CIDEr": 7.529713489397558e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a bathroom with a toilet, sink, and mirror. The toilet is white and has a lid. The sink is made of granite and has a faucet. A faucet is attached to the sink. The mirror is made of glass."}, "498511": {"image_id": 498511, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.1730297489554192, "Bleu_4": 0.12387535527350019, "METEOR": 0.2618589118158686, "ROUGE_L": 0.34945894334818584, "CIDEr": 9.656860483701705e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a horse grazing in a green field surrounded by mountains in the background. The horse is brown. The horse is grazing in the field. The horse is looking at a tree. The sky is blue and cloudy.\n\nThe image is taken from a distance."}, "163296": {"image_id": 163296, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.11303027047441294, "Bleu_3": 6.83559800121601e-07, "Bleu_4": 1.6916722834125866e-09, "METEOR": 0.2373987054791865, "ROUGE_L": 0.2952973720608575, "CIDEr": 6.934248125353046e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a green, leafy plant with small, white flowers on the ends of the leaves. The leaves are curled and the flowers are clustered together. The plant is growing in a garden. The image is taken in the spring season."}, "251856": {"image_id": 251856, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.16817499303272468, "Bleu_3": 0.08696639352820397, "Bleu_4": 1.118668148397708e-05, "METEOR": 0.20606412633021515, "ROUGE_L": 0.26804770872567485, "CIDEr": 1.4082747410891872e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.29411764705882354, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is lying on a surfboard and paddling with their hands to stay on the wave. The wave is white. The person is wearing a helmet to protect themselves from a fall."}, "245173": {"image_id": 245173, "Bleu_1": 0.189189189184076, "Bleu_2": 0.10252078086873165, "Bleu_3": 6.696562432589319e-07, "Bleu_4": 1.7239283526069037e-09, "METEOR": 0.2187315316061613, "ROUGE_L": 0.20115416323165708, "CIDEr": 6.193113147944723e-06, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.17857142857142858, "f": 0.17857142857142858, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two churches with clock towers. The churches have large, stone facades and pointed roofs. The clock tower has a clock face with hands pointing to the time. The churches are surrounded by a square."}, "469300": {"image_id": 469300, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.19782182158264086, "Bleu_3": 0.1311863860222524, "Bleu_4": 0.08156879226605328, "METEOR": 0.259284977337301, "ROUGE_L": 0.24970760233918127, "CIDEr": 1.428188155891063e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.25, "f": 0.20408163265306123, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6, "f": 0.7499999999999999, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man standing behind the bar with wine glasses in front of him. The man is holding a bottle of wine. There are several people sitting at tables nearby, sipping wine from their glasses. The bar is made of wood. The walls are beige. There are 2 windows in the scene."}, "547293": {"image_id": 547293, "Bleu_1": 0.1666666666631945, "Bleu_2": 0.10314212462370771, "Bleu_3": 0.061381585886313365, "Bleu_4": 8.466919880736143e-06, "METEOR": 0.09011377496803413, "ROUGE_L": 0.14950980392156862, "CIDEr": 1.656628531602859e-09, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.038461538461538464, "f": 0.04166666666666667, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a plane parked on the tarmac. The plane has a white body with blue and white stripes on the wings and tail. The plane has a large bumper on the front and a small bumper on the back. The plane also has a tail fin."}, "274593": {"image_id": 274593, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.11764652669092619, "Bleu_4": 0.09172809483333236, "METEOR": 0.1918064373538805, "ROUGE_L": 0.2894768062640882, "CIDEr": 1.0877426200610726e-08, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a red fire hydrant on the sidewalk in front of a building. The hydrant has a sign on it that reads \"Brussels Centre\". There are no other objects in the image. The image is taken from a bird's eye view, looking down on the hydrant."}, "231879": {"image_id": 231879, "Bleu_1": 0.16071428571141586, "Bleu_2": 0.09362816758816678, "Bleu_3": 0.05455146638784257, "Bleu_4": 7.439364783947175e-06, "METEOR": 0.15016311028939944, "ROUGE_L": 0.19406150583244963, "CIDEr": 7.517179616852756e-11, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2631578947368421, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows four people standing in front of a table with a cake on it. The people are wearing blue and white clothing. They are looking at the cake and holding a cake. The cake has white frosting and does not have a number on it.\n\nThere are no other details mentioned in the passage."}, "291257": {"image_id": 291257, "Bleu_1": 0.2608695652136106, "Bleu_2": 0.20542514084166144, "Bleu_3": 0.10799926335682423, "Bleu_4": 1.1753835574999517e-05, "METEOR": 0.23910214228089025, "ROUGE_L": 0.2329037976409627, "CIDEr": 6.183153273461831e-18, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.10714285714285714, "f": 0.11999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a woman sleeping in bed. The woman is wearing a white nightgown. She looks like she is old. Her hair is tied back with a hair band. \n\nThere are two cats in the scene. One cat is sleeping and sitting on a blanket on the bed. The other cat is also sleeping and sitting on a couch.\n\nThere is no lap or book in the scene."}, "326854": {"image_id": 326854, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.20314980006762443, "Bleu_3": 1.066722102597253e-06, "Bleu_4": 2.462691352392326e-09, "METEOR": 0.23929209117723885, "ROUGE_L": 0.29652777777777783, "CIDEr": 0.0005317283907497069, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2631578947368421, "f": 0.29411764705882354, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a well-lit room with windows and overhead lighting. There is a desk with a computer on it. There is also a bookshelf with a box on it. The floor is made of wood."}, "394449": {"image_id": 394449, "Bleu_1": 0.2089552238774783, "Bleu_2": 0.13782572126827164, "Bleu_3": 0.08361016149301816, "Bleu_4": 9.775732365864505e-06, "METEOR": 0.17287205848489487, "ROUGE_L": 0.18309154577288642, "CIDEr": 5.018754218819101e-19, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.1724137931034483, "f": 0.21276595744680854, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a train station with a platform and three people standing on it. A train can be seen on the platform. There is a tree growing on the platform. The roof of the station is made of metal. There are windows on the sides of the station.\n\nThe train station is surrounded by buildings and there are no other specific details mentioned in the passage."}, "113294": {"image_id": 113294, "Bleu_1": 0.21126760563082722, "Bleu_2": 0.13456839120296812, "Bleu_3": 0.06402442350632395, "Bleu_4": 7.881920122766104e-06, "METEOR": 0.16388849630192562, "ROUGE_L": 0.19453302961275623, "CIDEr": 5.651660817185823e-22, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two men in the scene. One man is walking on the rocks, looking at a dog, wearing shorts, and holding a fishing pole. The other man is pulling a boat, looking at a boat, wearing a hat, and holding a rope. The boat is close to the man.\n\nThere is no body of water in the scene.\n\nThere are no other objects or elements mentioned in the passage."}, "8771": {"image_id": 8771, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.17472060423831776, "Bleu_3": 0.12672598113117825, "Bleu_4": 1.4665135417043072e-05, "METEOR": 0.23798964604049033, "ROUGE_L": 0.2848565710473649, "CIDEr": 2.1282717107749862e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man sitting on a snowboard in the snow. He is wearing a blue jacket and blue pants. The snowboard has a head logo. The man is holding the snowboard with both hands and looking at it. There is no mountain in the scene."}, "252388": {"image_id": 252388, "Bleu_1": 0.3913043478090738, "Bleu_2": 0.23099715104243387, "Bleu_3": 0.13645768027438204, "Bleu_4": 1.8879521772493907e-05, "METEOR": 0.30711576016051595, "ROUGE_L": 0.3769309989701339, "CIDEr": 0.06201954237364153, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3157894736842105, "f": 0.2926829268292683, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a child sitting in a bathtub, using a toothbrush to brush their teeth. The child is wearing a blue shirt."}, "325114": {"image_id": 325114, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.10024266962117512, "Bleu_4": 1.230060008283069e-05, "METEOR": 0.22303437767443876, "ROUGE_L": 0.29064919594997013, "CIDEr": 5.664164134307208e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is of a bathroom with a toilet, a red table, and a red vase. The toilet is on the left side of the room and the table is on the right side. The table has a bowl of salad on it. The walls are white."}, "181739": {"image_id": 181739, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.18535150310271878, "Bleu_3": 0.11783047902946191, "Bleu_4": 1.4133420106715872e-05, "METEOR": 0.3237864998950116, "ROUGE_L": 0.32620320855614976, "CIDEr": 8.147292532466353e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13636363636363635, "f": 0.13636363636363635, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two gray cats sitting on a wooden desk in front of a computer monitor. The cats are looking at the computer monitor. The desk has a paper and two pens on it. There is no window or outside in the scene."}, "185360": {"image_id": 185360, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.14555562743244904, "Bleu_3": 0.07148419034913474, "Bleu_4": 8.94723384105085e-06, "METEOR": 0.24303825898487394, "ROUGE_L": 0.22956989247311832, "CIDEr": 2.952599916694346e-15, "SPICE": {"All": {"pr": 0.24, "re": 0.23076923076923078, "f": 0.23529411764705882, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a car parked on the side of a road. The condition of the car is damaged. The car is covered in mud and has a cracked windshield. \n\nThere is a cow standing in the field next to the car. The cow is brown and does not have a large horn on its head.\n\nThe sky is cloudy."}, "53450": {"image_id": 53450, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.24447927302426964, "Bleu_3": 0.1287583353288884, "Bleu_4": 1.67683594049909e-05, "METEOR": 0.2875390960042861, "ROUGE_L": 0.4128595600676818, "CIDEr": 0.004726215462042086, "SPICE": {"All": {"pr": 0.04, "re": 0.05, "f": 0.044444444444444446, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a blue bus parked on the sidewalk. The bus has the words \"San Diego\" written on the side. There are palm trees in front of the building."}, "565087": {"image_id": 565087, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.30860669990912093, "Bleu_3": 1.7114033061407743e-06, "Bleu_4": 4.085038450534026e-09, "METEOR": 0.1675144701786306, "ROUGE_L": 0.3034825870646766, "CIDEr": 0.059035868591669885, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.14285714285714285, "f": 0.17777777777777778, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows three people in the water at the beach. Some of the people are surfing and others are swimming."}, "54164": {"image_id": 54164, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.32703497007409993, "Bleu_3": 0.14951317712512505, "Bleu_4": 1.8120458368313506e-05, "METEOR": 0.30848677017400083, "ROUGE_L": 0.29544720697449145, "CIDEr": 0.00027969588576134556, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2, "f": 0.20408163265306126, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a black wetsuit and holding onto a surfboard with one hand while riding the wave with the other."}, "286774": {"image_id": 286774, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.18463723646331667, "Bleu_3": 0.1032188373500798, "Bleu_4": 1.3836903383875294e-05, "METEOR": 0.1701819038783994, "ROUGE_L": 0.2654482158398608, "CIDEr": 0.00010299123907350058, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.15625, "f": 0.20408163265306123, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is of a desk with two computers, a keyboard, and a mouse. The desk is made of wood. There is a chair in front of the desk, which has a cushion."}, "398031": {"image_id": 398031, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 0.12358624423715978, "Bleu_4": 1.5349982032732275e-05, "METEOR": 0.27147757689050855, "ROUGE_L": 0.36401007823896037, "CIDEr": 0.002229035917884085, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.17857142857142858, "f": 0.2, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.38461538461538464, "f": 0.3703703703703704, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a person standing on a beach flying a kite. The person is wearing a blue shirt and brown pants. The weather is like a clear blue sky. There are two rocks in the foreground."}, "108541": {"image_id": 108541, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 0.09808593569034826, "Bleu_4": 1.2472080427479296e-05, "METEOR": 0.19935077589114628, "ROUGE_L": 0.22197962154294032, "CIDEr": 3.573071143871377e-07, "SPICE": {"All": {"pr": 0.15625, "re": 0.20833333333333334, "f": 0.17857142857142858, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a highway with a sign that reads \"pay toll / mile\". A truck is driving on the road. The sky is cloudy. Trees are on either side of the road.\n\nThere is no other information available about the image."}, "40341": {"image_id": 40341, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.21718612137747484, "Bleu_3": 0.1536645171290916, "Bleu_4": 0.10921823440887, "METEOR": 0.27372864103658795, "ROUGE_L": 0.27949599083619703, "CIDEr": 7.938256117207475e-12, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.25925925925925924, "f": 0.25925925925925924, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5454545454545454, "f": 0.4799999999999999, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a man standing in the snow. The man is holding skis. He is wearing a black jacket and black pants. A pair of skis is in front of the man.\n\nThere are six cars parked on the street.\n\nThe sky is cloudy and there are no other people in the image."}, "16897": {"image_id": 16897, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.16329931618231128, "Bleu_3": 0.10286498078416037, "Bleu_4": 0.06900655593284068, "METEOR": 0.16411459279003365, "ROUGE_L": 0.28113837999769564, "CIDEr": 3.091213413982505e-06, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.3333333333333333, "f": 0.2978723404255319, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of six people sitting at a table in a conference room. They are using laptops and tablets to work on a project. Some of the people are wearing a blue shirt, a white shirt, a suit, a shirt and pants, a shirt, and a plaid shirt."}, "351017": {"image_id": 351017, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.2047650389408227, "Bleu_3": 0.16912968543226087, "Bleu_4": 0.1475756952410161, "METEOR": 0.21224186317617408, "ROUGE_L": 0.3028368794326241, "CIDEr": 1.8372091589906297e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two people sitting at a table in a restaurant. The people are drinking wine and writing on a piece of paper. They are wearing glasses. The table has bottles of wine on it. \n\nThe people are sitting at a table. They are writing on a piece of paper with their hands."}, "230593": {"image_id": 230593, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.17739371879401636, "Bleu_3": 0.14342204728356284, "Bleu_4": 0.09837489905425255, "METEOR": 0.20440713561153998, "ROUGE_L": 0.18208955223880596, "CIDEr": 1.6912163281304655e-19, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09523809523809523, "f": 0.08888888888888889, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of geese walking on a path in a park. The geese are brown and white. The geese are walking on the sidewalk. The geese have black and white heads and necks. There is no line or beak in the scene. There is no tree in the scene. There is a bench in the distance. There is no fountain in the scene."}, "129416": {"image_id": 129416, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.24671758189216153, "Bleu_3": 0.20247259909783916, "Bleu_4": 0.1551271783858721, "METEOR": 0.2900414311819392, "ROUGE_L": 0.3393077873918418, "CIDEr": 1.292333861343404e-07, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of nine cows grazing in a field next to a river. The cows are black, brown, black and white, and tan. The field is covered in tall, green grass. There are trees in the background. The sky is clear and blue."}, "80328": {"image_id": 80328, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.18463723646331667, "Bleu_3": 0.1032188373500798, "Bleu_4": 1.3836903383875294e-05, "METEOR": 0.2046115663103649, "ROUGE_L": 0.3015323776569451, "CIDEr": 0.00027242975675093517, "SPICE": {"All": {"pr": 0.28, "re": 0.2692307692307692, "f": 0.27450980392156865, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a herd of five zebras grazing in a grassy field. The zebras are standing and eating grass. Their stripes are visible. In the background, there is a rhinoceros and giraffes."}, "488476": {"image_id": 488476, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.2602575457946004, "Bleu_3": 0.17119495568587, "Bleu_4": 2.095920888284441e-05, "METEOR": 0.17932372009495023, "ROUGE_L": 0.26991150442477874, "CIDEr": 0.0025789183297556997, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image is a window display with several white ceramic rabbits on the shelves. The rabbits are arranged in a row. However, there are no rabbits in the image."}, "40051": {"image_id": 40051, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.13363062095380426, "Bleu_3": 0.06915221111259608, "Bleu_4": 8.887622216194529e-06, "METEOR": 0.2855535623749454, "ROUGE_L": 0.20795454545454545, "CIDEr": 5.495466132181146e-14, "SPICE": {"All": {"pr": 0.15, "re": 0.12, "f": 0.1333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a toilet, sink, and stove. The walls are painted blue and the floor is made of tile. There is a window on the left side of the room and a door on the right.\n\nThe toilet is white and there is a seat on it. The seat is also white."}, "51403": {"image_id": 51403, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.15534712747310678, "Bleu_3": 7.8441426562788e-07, "Bleu_4": 1.7715772413454909e-09, "METEOR": 0.22510344827586204, "ROUGE_L": 0.22048192771084338, "CIDEr": 4.118167839878016e-10, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.17391304347826086, "f": 0.12307692307692307, "fn": 19.0, "numImages": 1.0, "fp": 38.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image shows two dogs sitting in front of chairs. One dog is sitting on a chair and the other is sitting on a wooden table. The dogs are black and brown. They both have collars on their faces and bodies. The wall is white and the floor is made of wood."}, "109907": {"image_id": 109907, "Bleu_1": 0.17142857142612247, "Bleu_2": 0.13187609467725983, "Bleu_3": 0.06347573633863028, "Bleu_4": 7.860263587069598e-06, "METEOR": 0.1759392381567225, "ROUGE_L": 0.2236480293308891, "CIDEr": 4.4635411267484686e-21, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5714285714285714, "re": 0.8, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a dog standing in the water. The dog's head is tilting back. The dog is wearing a collar on its neck. The dog is not pooping in the water. There is no sock hanging out of the dog's mouth. \n\nIn the background, there are trees and grass on the shore. There is no bird on the shore. The sky is cloudy with a few clouds."}, "366683": {"image_id": 366683, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.12399138853119372, "Bleu_3": 0.0839337382802947, "Bleu_4": 1.0376714806170423e-05, "METEOR": 0.2039887000506682, "ROUGE_L": 0.2445589919816724, "CIDEr": 5.240572381292547e-12, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.3333333333333333, "f": 0.36734693877551017, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.375, "re": 0.2, "f": 0.26086956521739135, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8571428571428571, "f": 0.631578947368421, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a table with a cup of coffee, a sandwich, and a passport on it. The table is made of wood. The cup is made of paper. The lid is white. The sandwich is made of bread and has a variety of toppings.\n\nThere is no color or coffee in the scene."}, "315868": {"image_id": 315868, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.1832114449629405, "Bleu_3": 0.12801525895981317, "Bleu_4": 1.3508625657141918e-05, "METEOR": 0.2237983775214409, "ROUGE_L": 0.21631205673758866, "CIDEr": 7.485567007251258e-20, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.09090909090909091, "f": 0.10256410256410256, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two motorcycles parked on the sidewalk. One motorcycle is blue and white, with a chrome rim. The other motorcycle is blue and has a slick tire. The motorcycles are parked on the sidewalk in front of a building.\n\nThere is no Harley Davidson in the scene.\n\nThere is a black seat on one of the motorcycles.\n\nThere is no handlebar in the scene."}, "316007": {"image_id": 316007, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.11303027047441294, "Bleu_3": 0.06835598001216008, "Bleu_4": 9.512972336420179e-06, "METEOR": 0.21522916519157756, "ROUGE_L": 0.24110671936758896, "CIDEr": 2.5441624095919096e-06, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.28, "f": 0.2692307692307692, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows two people in the snow, both holding a snowboard. They are both wearing blue jackets and black pants. The sky is blue and there are trees in the background.\n\nThe image is in focus and the lighting is good."}, "430048": {"image_id": 430048, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.11677484162160401, "Bleu_3": 0.0681935615181132, "Bleu_4": 9.321701825196602e-06, "METEOR": 0.1634921953600315, "ROUGE_L": 0.1643097643097643, "CIDEr": 2.6933452383463745e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.2857142857142857, "f": 0.2608695652173913, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a building with a large window on the side. There is no awning or door on the building. A car is parked in front of the building. The sidewalk is made of concrete. There is no brick or tree in the scene."}, "478742": {"image_id": 478742, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.1591372845179993, "Bleu_3": 0.13285361520174627, "Bleu_4": 0.10733500452789224, "METEOR": 0.18550278136789342, "ROUGE_L": 0.2401574803149606, "CIDEr": 1.0475046353908882e-13, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.10714285714285714, "f": 0.11111111111111112, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a sink and a floor made of tile. There is a window on the wall that looks out onto the St. Louis River. The room is well lit and does not have a large mirror on the wall.\n\nThere is no toilet, shower, wall, ocean, or mirror in the scene."}, "321742": {"image_id": 321742, "Bleu_1": 0.18749999999707034, "Bleu_2": 0.13363062095410766, "Bleu_3": 0.08320512800135492, "Bleu_4": 9.857802458394728e-06, "METEOR": 0.19400398006993783, "ROUGE_L": 0.25363825363825365, "CIDEr": 2.9853698753534277e-19, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.20833333333333334, "f": 0.2, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of six motorcycles parked in a parking lot. The motorcycles are black and have different colors and designs. Some are green and black, some are blue, and some are just black. They are parked next to each other and appear to be in good condition. There are no people in the image. The background is a concrete parking lot."}, "293072": {"image_id": 293072, "Bleu_1": 0.2238805970115839, "Bleu_2": 0.16473324516198606, "Bleu_3": 0.11864143223075768, "Bleu_4": 0.08499429795978983, "METEOR": 0.21032012063612743, "ROUGE_L": 0.21233217304823468, "CIDEr": 1.0591613585768868e-17, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.038461538461538464, "f": 0.05128205128205129, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows two children sitting at a table with a cake in front of them. The children are wearing a blue and white shirt. They are holding a cake and blowing out candles on a birthday cake. \n\nThere are no party hats in the scene.\n\nThere is one balloon in the scene.\n\nThere is one adult cutting the cake.\n\nThere is no tablecloth in the scene."}, "287331": {"image_id": 287331, "Bleu_1": 0.5999999999760001, "Bleu_2": 0.5244044240636627, "Bleu_3": 0.4573320257282276, "Bleu_4": 0.4018887540149296, "METEOR": 0.3987346638029704, "ROUGE_L": 0.5142255005268704, "CIDEr": 0.10769387985087298, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.26666666666666666, "f": 0.3137254901960784, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a dog jumping up to catch a frisbee in the air. The dog is wearing a green collar and a green leash."}, "306667": {"image_id": 306667, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.17821457732346996, "Bleu_3": 0.14154335182136238, "Bleu_4": 0.11152102388989424, "METEOR": 0.16827902507119882, "ROUGE_L": 0.20631341600901915, "CIDEr": 1.7155720098333674e-14, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.38461538461538464, "f": 0.27777777777777773, "fn": 8.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of ten people standing on a soccer field. The people are talking to each other. Some of the people are standing on a field. Some of the people are playing soccer. The people are standing in front of a mural. The people are taking a picture. A soccer goal is in the background."}, "160855": {"image_id": 160855, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.27197188373746883, "Bleu_3": 0.16017393233919006, "Bleu_4": 1.8510871554059165e-05, "METEOR": 0.24000368010257137, "ROUGE_L": 0.3531114327062228, "CIDEr": 4.791214083049089e-05, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2916666666666667, "f": 0.27999999999999997, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5454545454545454, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a group of thirteen people flying kites in a park. The kites are made of plastic. The tails are attached to the kites. The people are playing frisbee in the park. The sky is blue."}, "499622": {"image_id": 499622, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.20948264539468747, "Bleu_3": 0.16833306223397848, "Bleu_4": 0.12066503367952006, "METEOR": 0.29133827897678644, "ROUGE_L": 0.28696236559139787, "CIDEr": 1.1361474630756117e-09, "SPICE": {"All": {"pr": 0.32, "re": 0.36363636363636365, "f": 0.3404255319148936, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.75, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a police officer riding a white motorcycle on the sidewalk. The police officer is wearing a helmet and has a serious expression on his face. The officer is riding the motorcycle on the road on the right side. There is a tree in the background."}, "124796": {"image_id": 124796, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.10412270358781489, "Bleu_4": 1.2197379410072965e-05, "METEOR": 0.23516044899560642, "ROUGE_L": 0.25507765830346474, "CIDEr": 3.1441421396812914e-12, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person standing in the water, holding a yellow ball. The person is wearing a striped shirt and shorts, and has a look of concentration on their face. The background is a beach with waves.\n\nThe person is not standing in the water. The person's face looks like a boy."}, "399666": {"image_id": 399666, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.09337611011479056, "Bleu_4": 1.1534197288455865e-05, "METEOR": 0.2127646600488962, "ROUGE_L": 0.3036168565424179, "CIDEr": 5.66066508761137e-07, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09523809523809523, "f": 0.08333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a person jumping over a sandy beach with a surfboard in the background. The person is wearing a red shirt and blue shorts, and is holding a frisbee. The sky is blue and there are waves in the background. The image is in black and white."}, "359965": {"image_id": 359965, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.15585730003579046, "Bleu_3": 0.10950337957304693, "Bleu_4": 0.07771324020536689, "METEOR": 0.1699534264509773, "ROUGE_L": 0.2347959969207082, "CIDEr": 4.7274741922644734e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.06666666666666667, "f": 0.09523809523809522, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a toilet with a seat and a handle on the side. The toilet is in a bathroom. There is a remote control on the side of the toilet and on the wall next to the toilet."}, "320425": {"image_id": 320425, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.28867513458920707, "Bleu_3": 0.2268030705273307, "Bleu_4": 0.16348126556331607, "METEOR": 0.3066396932872695, "ROUGE_L": 0.2921655833048238, "CIDEr": 2.1142007911383673e-10, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2, "f": 0.1851851851851852, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.06666666666666667, "re": 0.1111111111111111, "f": 0.08333333333333334, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of nine giraffes standing in a field. The giraffes are drinking water, eating from trees, standing in a dirt area, standing on the ground, and eating grass. Some of the giraffes are standing next to each other. The sky is blue. There are trees in the background."}, "352286": {"image_id": 352286, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.19374606456772306, "Bleu_3": 0.1023605423670429, "Bleu_4": 1.332691735508304e-05, "METEOR": 0.20658277600506972, "ROUGE_L": 0.33862014274385416, "CIDEr": 3.2690530437279163e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17647058823529413, "f": 0.15789473684210528, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a room with a red couch, a television, and a lamp. The couch is red. The lamp is hanging from the ceiling and has a red shade. The room also has a coffee table."}, "79472": {"image_id": 79472, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.19999999999603923, "Bleu_3": 0.11775100856360317, "Bleu_4": 0.07636830779166373, "METEOR": 0.2272936467771461, "ROUGE_L": 0.22889305816135083, "CIDEr": 3.07772372305351e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a desk with a computer, printer, and other office supplies. The desk is made of wood. There is a lamp on the desk. The room has a window with curtains and a view of the backyard.\n\nThe image is taken in a home office with a wooden desk."}, "450500": {"image_id": 450500, "Bleu_1": 0.11864406779459928, "Bleu_2": 0.04522817015681362, "Bleu_3": 3.2984840854782555e-07, "Bleu_4": 8.947233841048187e-10, "METEOR": 0.08252612727197357, "ROUGE_L": 0.15993707393812268, "CIDEr": 5.686648800130352e-15, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two people standing on the sidewalk. They are wearing black clothing and are talking on the phone.\n\nIn the background, there are two buildings. One building is red and the other is white. There is a sign on one of the buildings that reads \"for lease\".\n\nThe overall scene shows the people standing on the sidewalk."}, "16574": {"image_id": 16574, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.18103344785369693, "Bleu_3": 0.09977029015284858, "Bleu_4": 1.3272826941145857e-05, "METEOR": 0.20109066817060506, "ROUGE_L": 0.32670237184391737, "CIDEr": 0.00013511565179463264, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15789473684210525, "f": 0.14634146341463414, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a group of six people dressed in medieval costumes standing on a snowy field. They are not holding swords or shields, and there is no battle. The field is covered in snow."}, "370677": {"image_id": 370677, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.12094486170917773, "Bleu_3": 0.08599680891572581, "Bleu_4": 0.061313855169743685, "METEOR": 0.16985646130363824, "ROUGE_L": 0.2293233082706767, "CIDEr": 4.827329616616192e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows three women standing in front of a bakery. The women are wearing red, yellow, and blue uniforms. They have their hair tied back, either with hair bands or hair clips. \n\nThere are 27 bread on the shelves.\n\nThere are no other items in the scene."}, "416739": {"image_id": 416739, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.1384332440755414, "Bleu_3": 7.824806388361054e-07, "Bleu_4": 1.8721431301108676e-09, "METEOR": 0.2316007690710307, "ROUGE_L": 0.2531120331950207, "CIDEr": 9.846947295426602e-07, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.041666666666666664, "f": 0.04651162790697675, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a bedroom with a white bed, a wooden dresser, and a window with a view of the outside. The walls are painted green and the floor is made of metal. The room is dimly lit by the small window."}, "136218": {"image_id": 136218, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.27588029391667884, "Bleu_3": 0.22153776670485226, "Bleu_4": 0.18046993571957456, "METEOR": 0.2908929369166519, "ROUGE_L": 0.35012755102040816, "CIDEr": 9.140365435724648e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.07407407407407407, "f": 0.08888888888888888, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a city skyline with two buildings and a large airplane flying overhead. The buildings are tall and made of glass and steel. The airplane belongs to Southwest airlines. The sky is clear and blue. There are no people in the image."}, "528516": {"image_id": 528516, "Bleu_1": 0.24999999998958336, "Bleu_2": 0.10425720702409896, "Bleu_3": 7.905508875568159e-07, "Bleu_4": 2.2023814945605373e-09, "METEOR": 0.16736620246225367, "ROUGE_L": 0.264069264069264, "CIDEr": 0.019820200012421463, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2777777777777778, "f": 0.22222222222222224, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a pan with vegetables cooking in it. The vegetables include carrots, and green beans. The vegetables are cooking in the pan."}, "340884": {"image_id": 340884, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.15007505629280368, "Bleu_3": 0.08633422507036763, "Bleu_4": 1.1729176379484152e-05, "METEOR": 0.2871697332108684, "ROUGE_L": 0.3017312448474856, "CIDEr": 1.2293370786676091e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows an elephant standing in the dirt next to a small pond. The elephant is brown. The elephant is walking. The elephant is looking at a rock. The elephant has large ears, which are asymmetrical."}, "411241": {"image_id": 411241, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.17504208247906033, "Bleu_3": 0.12014621934667156, "Bleu_4": 0.07599442723762243, "METEOR": 0.21015598122553153, "ROUGE_L": 0.2324442025040827, "CIDEr": 3.373337125753485e-11, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.09090909090909091, "f": 0.07692307692307691, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man sitting on the couch with two laptops on his lap. The man is wearing a blue shirt and black pants. There is a blanket on the couch next to him. The room is dimly lit, but there is no lamp. There is a table with a remote control on it."}, "76454": {"image_id": 76454, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 0.16670955566718626, "Bleu_4": 0.10804399675973254, "METEOR": 0.289664209603289, "ROUGE_L": 0.38418474457662705, "CIDEr": 0.00016073183520856767, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.38095238095238093, "f": 0.41025641025641024, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.6363636363636364, "f": 0.6666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image shows a giraffe standing on a fence in front of a city skyline. The giraffe is looking towards a tree. The giraffe's head is tilted downward. The skyline is made up of tall buildings."}, "227599": {"image_id": 227599, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.24019223070154896, "Bleu_3": 0.1824447771213173, "Bleu_4": 0.1346032804565933, "METEOR": 0.29121070951902334, "ROUGE_L": 0.3588235294117647, "CIDEr": 6.362693417350435e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of six people standing on the beach with surfboards. They are all wearing swimsuits and sunglasses. The man in the center is holding a surfboard and a cigarette. The other people are standing around them."}, "233528": {"image_id": 233528, "Bleu_1": 0.19230769230522685, "Bleu_2": 0.14135069854621995, "Bleu_3": 0.09239203372584673, "Bleu_4": 0.05694565324910067, "METEOR": 0.19911796737792017, "ROUGE_L": 0.21125541125541128, "CIDEr": 9.234545558247223e-23, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.11428571428571428, "f": 0.13559322033898305, "fn": 31.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.25, "f": 0.2962962962962963, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a desk with a laptop, a computer, a keyboard, a mouse, and a mouse on it. There is also a chair for the computer. The computer is used for various tasks. There are papers and a book on the desk. The walls are painted white. The floor is made of wood.\n\nThere are windows on one side of the room. The room is well lit by natural light.\n\nThere are no shelves in the room."}, "69668": {"image_id": 69668, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.2102800206225174, "Bleu_3": 0.1555438048979653, "Bleu_4": 0.0951042841299709, "METEOR": 0.29329390664418525, "ROUGE_L": 0.3078864353312303, "CIDEr": 9.857949163731581e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.12903225806451613, "f": 0.1509433962264151, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man wearing a yellow shirt and black pants standing in front of an oven. The man is working on the oven. The man has a smirk on his face. The glass door of the oven is not open.\n\nThere is no apron in the scene."}, "446651": {"image_id": 446651, "Bleu_1": 0.20312499999682618, "Bleu_2": 0.1269686250438429, "Bleu_3": 6.38264046466008e-07, "Bleu_4": 1.436871157329033e-09, "METEOR": 0.18232734967829792, "ROUGE_L": 0.2476798143851508, "CIDEr": 6.825076019868846e-17, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man and a woman riding on a motorcycle. The man is wearing a helmet on his head. The woman is wearing a grey dress and a helmet on her head. The woman is also wearing a grey jacket.\n\nThe man and the woman are riding on a black motorcycle. They are both smiling and appear to be enjoying the ride."}, "127068": {"image_id": 127068, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.18389242811841477, "Bleu_3": 0.11540775810613964, "Bleu_4": 0.07732307904453359, "METEOR": 0.21630324317992097, "ROUGE_L": 0.2873485868102288, "CIDEr": 1.031484992981384e-08, "SPICE": {"All": {"pr": 0.4, "re": 0.375, "f": 0.38709677419354843, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a man standing next to a surfboard on the beach. The surfboard has a logo on it. The man is wearing a white shirt. The sky is blue and there are palm trees in the background.\n\nThere are no shorts in the scene."}, "390292": {"image_id": 390292, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 0.12358624423715978, "Bleu_4": 1.5349982032732275e-05, "METEOR": 0.18033570192865508, "ROUGE_L": 0.2697126013264554, "CIDEr": 0.0001609419287901314, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a woman using her cell phone. She is looking at her cell phone and wearing a white shirt. The background is a red wall with a red curtain and a window with a reflection."}, "579158": {"image_id": 579158, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.24902912254001588, "Bleu_3": 0.18221836147003703, "Bleu_4": 0.11089937663359, "METEOR": 0.25412754347801914, "ROUGE_L": 0.29756097560975614, "CIDEr": 3.5688417944070264e-07, "SPICE": {"All": {"pr": 0.375, "re": 0.2222222222222222, "f": 0.27906976744186046, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a blue and red airplane on the tarmac. The airplane is not ready to take off. The landing gear is not extended. The airplanes are parked on the tarmac. The sky is clear and there are no clouds in sight."}, "396051": {"image_id": 396051, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2067245576408771, "Bleu_3": 0.11956793017371352, "Bleu_4": 1.6336470130381284e-05, "METEOR": 0.22228444363698413, "ROUGE_L": 0.3306233062330623, "CIDEr": 0.019698877200888414, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image does not contain an airport terminal. There are three planes parked on the tarmac. The sky is cloudy. There is a fence surrounding the area."}, "149252": {"image_id": 149252, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1740776559517855, "Bleu_3": 0.0889895891077732, "Bleu_4": 1.1381305436598616e-05, "METEOR": 0.18199994237394124, "ROUGE_L": 0.28073635765943455, "CIDEr": 6.273366176581944e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows two zebras standing in a field with trees in the background. The zebras are standing close together and looking at each other. They have black and white stripes.\n\nThe image is taken in a dry, arid environment with a clear blue sky."}, "405365": {"image_id": 405365, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.28284271246306963, "Bleu_3": 1.5151444882660885e-06, "Bleu_4": 3.545968452787769e-09, "METEOR": 0.20151688866566855, "ROUGE_L": 0.2987267384916748, "CIDEr": 0.02955854966048229, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.4090909090909091, "f": 0.36734693877551017, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 9.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.7777777777777778, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image shows four people doing skiing on a snow-covered slope. They are wearing ski gear and standing on skis. The sky is not clear."}, "314757": {"image_id": 314757, "Bleu_1": 0.2089552238774783, "Bleu_2": 0.09745750213072185, "Bleu_3": 0.05267110122508168, "Bleu_4": 6.912486646967604e-06, "METEOR": 0.15422429708673505, "ROUGE_L": 0.14987714987714987, "CIDEr": 9.838071197969709e-17, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a living room with three couches. One of the couches has a laptop on it. There is no coffee table or television in the room. \n\nThere are four people in the room. Some of the people are holding a wii remote and others are holding a laptop. \n\nThe walls of the room are brown. There are no windows on either side of the room."}, "245301": {"image_id": 245301, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.1701377556473561, "Bleu_4": 0.126885537703041, "METEOR": 0.22401636827845803, "ROUGE_L": 0.23229246001523232, "CIDEr": 1.1206834497298804e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.15384615384615385, "f": 0.1951219512195122, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a woman riding a horse on a grassy field. The woman is wearing a red coat and boots. The horse is wearing a saddle and bridle. The background is a cloudy sky with some trees in the distance."}, "215650": {"image_id": 215650, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.134717557601255, "Bleu_3": 0.08654263680347211, "Bleu_4": 1.0419141114820697e-05, "METEOR": 0.15764426061026518, "ROUGE_L": 0.14039125431530494, "CIDEr": 6.376138914243825e-16, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.35294117647058826, "f": 0.31578947368421056, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a black and white photograph of a city street in the rain. There are several cars parked on the side of the road. People are walking in the water. People are also playing a game.\n\nThere are several buildings visible in the background.\n\nThe image is taken from a high angle, looking down on the street."}, "475856": {"image_id": 475856, "Bleu_1": 0.339622641503026, "Bleu_2": 0.24244760629354595, "Bleu_3": 0.151215262126857, "Bleu_4": 1.6216391434171577e-05, "METEOR": 0.2782709123073923, "ROUGE_L": 0.3402119353039598, "CIDEr": 4.6118305182960905e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.14285714285714285, "f": 0.19354838709677416, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The man in the image is wearing a suit and tie. He is standing in front of a door and holding a pen. The man is holding his hand up with his other hand.\n\nThe floor is made of wood. There is no briefcase or rug in the scene.\n\nThe walls are white."}, "387776": {"image_id": 387776, "Bleu_1": 0.333333333325926, "Bleu_2": 0.12309149097656634, "Bleu_3": 0.07063108368194851, "Bleu_4": 9.57049894254339e-06, "METEOR": 0.1853618384378707, "ROUGE_L": 0.2435129740518962, "CIDEr": 1.817909421703033e-08, "SPICE": {"All": {"pr": 0.030303030303030304, "re": 0.043478260869565216, "f": 0.03571428571428572, "fn": 22.0, "numImages": 1.0, "fp": 32.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.0625, "re": 0.1111111111111111, "f": 0.08, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}}, "caption": "The image shows a person doing snowboarding on a snowy slope. The person is wearing a red snowboarding suit and is jumping off a ramp. The snowy slope is not covered in trees and there is no mountain in the background. The sky is blue."}, "332877": {"image_id": 332877, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.12198750911664548, "Bleu_3": 6.214597592719476e-07, "Bleu_4": 1.4084041646300657e-09, "METEOR": 0.1425361621555262, "ROUGE_L": 0.15561224489795916, "CIDEr": 9.956002977235886e-19, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.14285714285714285, "f": 0.11428571428571427, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.5, "f": 0.26666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a busy street with many motorcycles and cars driving down the street. There are no trees or sidewalks in the scene.\n\nThere are a total of 14 people in the scene. Some of the people are riding motorcycles, while others are taking selfies or riding on skateboards.\n\nThe overall scene is bustling with activity, with many motorcycles driving down the street."}, "325385": {"image_id": 325385, "Bleu_1": 0.19999999999789472, "Bleu_2": 0.12203940765572971, "Bleu_3": 0.0684198960022268, "Bleu_4": 0.043195633776281085, "METEOR": 0.17863416780434618, "ROUGE_L": 0.17842778793418648, "CIDEr": 4.860242129030841e-41, "SPICE": {"All": {"pr": 0.3, "re": 0.2, "f": 0.24, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows an office space with two desks and one chair. There are computers on the desks. A computer and a laptop are on one of the desks. A printer, a monitor, and a screen are also on the desks.\n\nThe office space is surrounded by walls, which are painted red. There are no windows on the walls, but there is a large screen on the wall. The ceiling is also visible, and it features a large red wall.\n\nThe image is taken from a bird's eye view, showing the entire office space."}, "535997": {"image_id": 535997, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 7.733118331435389e-07, "Bleu_4": 1.7439076818628815e-09, "METEOR": 0.1708561549647522, "ROUGE_L": 0.25341246290801184, "CIDEr": 4.109189174259013e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a church with a tall steeple and a clock tower. The church is made of stone. The roof of the church is a triangle. The clock tower is made of metal and has a clock face on it. The sky is dark blue.\n\nThere are no stars in the sky."}, "445038": {"image_id": 445038, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.3038218101131809, "Bleu_3": 0.24871131730975723, "Bleu_4": 0.191248131481018, "METEOR": 0.26921401902323566, "ROUGE_L": 0.36237623762376237, "CIDEr": 0.02776932462441284, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.038461538461538464, "f": 0.0425531914893617, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a plane flying in the sky. The plane is flying in the air. The plane is on a runway. The sky is cloudy."}, "558784": {"image_id": 558784, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.27588029391667884, "Bleu_3": 0.1935310651946666, "Bleu_4": 0.1371274973469818, "METEOR": 0.2734926459121228, "ROUGE_L": 0.3342465753424657, "CIDEr": 2.96944161752494e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a picture of a man standing on a grassy field. The man is holding a frisbee. He is wearing a hat on his head. In the background, there is a pond and trees. There is also a dirt path surrounding the pond."}, "301221": {"image_id": 301221, "Bleu_1": 0.31034482758085613, "Bleu_2": 0.22136353557062677, "Bleu_3": 0.12050860098552074, "Bleu_4": 1.3355890848514968e-05, "METEOR": 0.1931828121560923, "ROUGE_L": 0.27001770607908715, "CIDEr": 1.2466737053883162e-11, "SPICE": {"All": {"pr": 0.3, "re": 0.2608695652173913, "f": 0.27906976744186046, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a person sitting at a table with a pizza in front of them. The pizza has eggs, bacon, and spinach on it. There are also cups on the table. There are knives as well. \n\nThe person is sitting at a table. A pizza with eggs and spinach is on the table besides cups of coffee."}, "355956": {"image_id": 355956, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.14185186364132965, "Bleu_3": 0.08020507112003895, "Bleu_4": 1.0794573108750781e-05, "METEOR": 0.1364077108735766, "ROUGE_L": 0.23713878450174936, "CIDEr": 0.0004160415875410743, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.3076923076923077, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "There are no people in this image. There is no baseball being played. There is a field in the image. There is a player wearing a baseball uniform standing on the field. There is no grass or trees in the scene."}, "482970": {"image_id": 482970, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.22312917498915605, "Bleu_3": 0.1905139322076228, "Bleu_4": 0.15603008975011737, "METEOR": 0.26439410408060077, "ROUGE_L": 0.3584470094438615, "CIDEr": 3.1771557324283957e-05, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2, "f": 0.19607843137254902, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a laptop sitting on a desk in a room. The laptop is next to a mouse. There is a lamp on the desk. The laptop has a screen that is displaying a message in English."}, "301765": {"image_id": 301765, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.13794014695833945, "Bleu_3": 0.07680285411963501, "Bleu_4": 1.0252671801486271e-05, "METEOR": 0.17843640907045769, "ROUGE_L": 0.214185393258427, "CIDEr": 6.543981069953888e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.20833333333333334, "f": 0.22727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two street signs with the words \"Prince st\" and \"Grafton street\" written on them. The street signs are attached to a pole and are surrounded by trees. There are no other buildings in the scene. The sky is clear and blue."}, "511662": {"image_id": 511662, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.07205793047605258, "Bleu_4": 9.44575929237223e-06, "METEOR": 0.23321027217488682, "ROUGE_L": 0.2582869586256957, "CIDEr": 4.222308309878165e-08, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.225, "f": 0.2857142857142857, "fn": 31.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 19.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6153846153846154, "re": 0.6666666666666666, "f": 0.64, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}}, "caption": "The image shows a cruise ship in the foreground, with palm trees and a beach in the background. The ship is surrounded by colorful umbrellas and chairs on the sand. The sky is clear and blue, with a few clouds in the distance.\n\nThere is no sand in the image."}, "461722": {"image_id": 461722, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.12430587656291647, "Bleu_4": 0.10467398290586188, "METEOR": 0.24191288505516742, "ROUGE_L": 0.26116207951070336, "CIDEr": 3.0307092078292235e-10, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.3888888888888889, "f": 0.3111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a young girl sitting at a table with a plate of food in front of her. She is wearing a green and white shirt and has long blonde hair. The background is a kitchen with a countertop in front of the girl. There are cabinets in the kitchen."}, "406253": {"image_id": 406253, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2555622163811263, "Bleu_3": 0.1973292455171, "Bleu_4": 0.15745849216150845, "METEOR": 0.31190644935680667, "ROUGE_L": 0.2993223771321754, "CIDEr": 1.0368459990426308e-09, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.19230769230769232, "f": 0.18181818181818185, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of three motorcycles parked on the side of a city street. The motorcycles are blue and green. They are parked on the sidewalk. There are also two cars parked on the street. People are walking down the sidewalk. The buildings in the scene create a bustling city atmosphere."}, "463174": {"image_id": 463174, "Bleu_1": 0.4054054053944486, "Bleu_2": 0.18380365551841535, "Bleu_3": 9.882801705785478e-07, "Bleu_4": 2.3082897967275263e-09, "METEOR": 0.26632900034414375, "ROUGE_L": 0.2514427040395713, "CIDEr": 2.2020392140758588e-05, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white shirt and pink and white leggings. She has a tennis racket in her hand and is swinging it to hit the ball."}, "287320": {"image_id": 287320, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.24174688920325796, "Bleu_3": 0.1293558303633546, "Bleu_4": 0.07994117708696576, "METEOR": 0.26483525145423725, "ROUGE_L": 0.2663755458515284, "CIDEr": 4.939254650980647e-13, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.20833333333333334, "f": 0.18867924528301888, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.38461538461538464, "f": 0.3225806451612903, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "The image shows a bathroom with a toilet, sink, and mirror. The walls are painted white. The floor is made of tile. There is a wooden vanity with a mirror on it. A scrubbing brush is on the sink. A towel is on the mirror. The toilet has a white lid. The seat has a button."}, "135266": {"image_id": 135266, "Bleu_1": 0.130952380950822, "Bleu_2": 0.05617365093189097, "Bleu_3": 3.3761143663916305e-07, "Bleu_4": 8.302169728134882e-10, "METEOR": 0.08551068883610452, "ROUGE_L": 0.14454976303317535, "CIDEr": 1.7030247580663937e-31, "SPICE": {"All": {"pr": 0.24, "re": 0.17647058823529413, "f": 0.20338983050847456, "fn": 28.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows three people in the scene. One of the people is holding a sandwich and another person is eating a sandwich. Another person is holding a bottle of wine and another person is drinking a beer. The people are wearing a blue shirt and a black hat. One of the people is wearing a black jacket.\n\nThere is no boat or plate in the scene.\n\nThere is no food or water in the scene.\n\nThere is no life jacket in the scene."}, "187901": {"image_id": 187901, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.08111147935548949, "Bleu_4": 1.0064933408714859e-05, "METEOR": 0.27010574008039373, "ROUGE_L": 0.2513243084167157, "CIDEr": 2.3164048342653563e-13, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a clock tower with a large clock face on the front. The clock face has Roman numerals and there are two clock faces on either side of the main clock. The tower is made of brick and has a steeple on top. The sky is blue. There are trees in the scene."}, "135872": {"image_id": 135872, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.15541746803663614, "Bleu_3": 8.188084718265141e-07, "Bleu_4": 1.8902516755213052e-09, "METEOR": 0.26952216444119725, "ROUGE_L": 0.2794502617801047, "CIDEr": 1.0034600032262796e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a computer room with a desk, chair, and computer. A computer monitor, a keyboard, and a mouse is on the desk. The room is painted in gray. The floor is made of carpet. There is a window with a view of a tree outside."}, "97610": {"image_id": 97610, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.19778287446532944, "Bleu_3": 0.12952938033879158, "Bleu_4": 1.5785531341013118e-05, "METEOR": 0.23435520436830778, "ROUGE_L": 0.2793893129770992, "CIDEr": 4.3289929681098215e-06, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.23809523809523808, "f": 0.20833333333333334, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows two elephants walking along a sidewalk. The elephants are wearing tusks and have grey colors. They do not have spots or stripes. The elephants are in a wildlife sanctuary. The background is a concrete wall."}, "568132": {"image_id": 568132, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.08701138391057636, "Bleu_4": 1.1125382292156776e-05, "METEOR": 0.2508919563174654, "ROUGE_L": 0.2827814569536423, "CIDEr": 8.138374755513606e-09, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.32, "f": 0.30769230769230765, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a boy holding a baseball. The boy is wearing a baseball uniform, which consists of a red shirt, black pants, and a red hat. Trees can be seen in the background. Another boy throwing a baseball can also be seen in the image."}, "404209": {"image_id": 404209, "Bleu_1": 0.5483870967565037, "Bleu_2": 0.382408889972753, "Bleu_3": 0.3116040335517178, "Bleu_4": 0.25640576940987764, "METEOR": 0.28126498067805294, "ROUGE_L": 0.40636565507031824, "CIDEr": 0.042728041437750136, "SPICE": {"All": {"pr": 0.2, "re": 0.15625, "f": 0.17543859649122806, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.07692307692307693, "f": 0.07692307692307693, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.26666666666666666, "f": 0.30769230769230765, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a cup of coffee and a slice of cake on a plate. The cup is filled with coffee. The plate also has a piece of cake on it."}, "74967": {"image_id": 74967, "Bleu_1": 0.17460317460040317, "Bleu_2": 0.10613538967648731, "Bleu_3": 5.694604069888632e-07, "Bleu_4": 1.324524018391331e-09, "METEOR": 0.10654712503149447, "ROUGE_L": 0.1891472868217054, "CIDEr": 4.600963384860901e-18, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows three people in a hospital room. One person is holding scissors. Another person is holding a knife. \n\nThere is a baby in the bassinet. The baby is lying on a pink blanket. The baby is also lying on the table. A pink blanket is over the baby.\n\nThere are no other people, rooms, scrubs, masks, or walls in the scene."}, "200365": {"image_id": 200365, "Bleu_1": 0.42857142856268227, "Bleu_2": 0.2988071523274369, "Bleu_3": 0.21177988488347993, "Bleu_4": 0.1425547103183908, "METEOR": 0.2992893687117399, "ROUGE_L": 0.3165829145728643, "CIDEr": 0.0015045356059775234, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.2916666666666667, "f": 0.3333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a bicycle parked next to a table with a plate of hot dogs and a drink on it. The table is located in front of a car. The bicycle is on the sidewalk. There is no building or trees in the scene. The sky is cloudy."}, "357941": {"image_id": 357941, "Bleu_1": 0.30952380951644, "Bleu_2": 0.26066118020872475, "Bleu_3": 0.20402696809840276, "Bleu_4": 0.15987473728172072, "METEOR": 0.2614607462604101, "ROUGE_L": 0.35384296664594983, "CIDEr": 1.4184172488798257e-05, "SPICE": {"All": {"pr": 0.09375, "re": 0.0967741935483871, "f": 0.09523809523809523, "fn": 28.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.0625, "f": 0.08, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a black cat sitting on top of a red blanket in front of a television. The cat's eyes are green. The television is playing a movie with a man's face on it. The room is dimly lit."}, "222467": {"image_id": 222467, "Bleu_1": 0.17543859648815024, "Bleu_2": 0.055971707853964936, "Bleu_3": 3.847613819595434e-07, "Bleu_4": 1.0134332918214462e-09, "METEOR": 0.16778626838837307, "ROUGE_L": 0.13669467787114845, "CIDEr": 1.424186110470589e-13, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2608695652173913, "f": 0.28571428571428575, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows two cats sitting on a television. The cats are looking directly at the camera with their eyes wide open. The television set is in the background, with a blank screen showing. The room is dimly lit, with only a few light sources coming from the windows. The cats' fur is visible in the image."}, "375566": {"image_id": 375566, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.2885415814310566, "Bleu_3": 0.2230754874693259, "Bleu_4": 0.14987638789540042, "METEOR": 0.305034680656719, "ROUGE_L": 0.2781758957654723, "CIDEr": 1.4518197593573185e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 30.0, "numImages": 1.0, "fp": 30.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.07692307692307693, "f": 0.07692307692307693, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4375, "f": 0.4666666666666667, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The image shows a woman walking down a street. She is holding a yellow umbrella over her head. She is wearing a pink shirt and pants. \n\nThere are three trees lining the street. There are no cars in the scene.\n\nThere is no hat in the scene."}, "312204": {"image_id": 312204, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.245934688411173, "Bleu_3": 0.1591656839177488, "Bleu_4": 0.10858943671066813, "METEOR": 0.2905975130173843, "ROUGE_L": 0.42068965517241375, "CIDEr": 0.0007325636833490242, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.13793103448275862, "f": 0.14285714285714285, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows an elephant standing in a grassy field. The elephant is grey and is walking in the grass. It has a long, curved tusk. There are trees in the background."}, "417606": {"image_id": 417606, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 0.08556026937263805, "Bleu_4": 1.0861779420621467e-05, "METEOR": 0.2080796560715251, "ROUGE_L": 0.23036253776435048, "CIDEr": 1.8866213628174286e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a stop sign on the side of a road in a wooded area. The sign is white with black letters and has a red background. The road and the surrounding area are lined with trees. There are no other signs or objects in the image."}, "508731": {"image_id": 508731, "Bleu_1": 0.22222222221604945, "Bleu_2": 0.13801311186458243, "Bleu_3": 8.243669901955128e-07, "Bleu_4": 2.029840717200597e-09, "METEOR": 0.14475716746727546, "ROUGE_L": 0.14950980392156862, "CIDEr": 0.00014443272381909193, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.14285714285714285, "f": 0.15789473684210528, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows three elephants standing in a field. There is a tree in the background. The elephants are wearing collars and appear to be in a controlled environment. The image is in black and white."}, "382411": {"image_id": 382411, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.265684465654326, "Bleu_3": 0.16233648076075052, "Bleu_4": 0.10752875081056673, "METEOR": 0.3285830167859238, "ROUGE_L": 0.3839496459480724, "CIDEr": 0.00025936375218554863, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and has a tennis racket in his hand. The man is swinging his racket to hit a tennis ball."}, "57107": {"image_id": 57107, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.1469436716703117, "Bleu_3": 0.08356671880332696, "Bleu_4": 1.1283644306066042e-05, "METEOR": 0.14927176938197673, "ROUGE_L": 0.1931908155186065, "CIDEr": 1.299125491946828e-06, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2777777777777778, "f": 0.21739130434782608, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows three giraffes standing in a field. The giraffes are wearing a giraffe's coat. They are all in good health. The giraffes are standing in a line, with their heads and necks bending down to eat."}, "59015": {"image_id": 59015, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.20314980006762443, "Bleu_3": 0.10667221025972526, "Bleu_4": 1.3848731186391142e-05, "METEOR": 0.1497436602606581, "ROUGE_L": 0.23371647509578544, "CIDEr": 0.0095125817042047, "SPICE": {"All": {"pr": 0.1875, "re": 0.08333333333333333, "f": 0.11538461538461539, "fn": 33.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three people standing on a boat in the middle of a river. The boat is surrounded by trees and there are other boats in the background. The people are not wearing life jackets."}, "117328": {"image_id": 117328, "Bleu_1": 0.1935483870936525, "Bleu_2": 0.0975642000715291, "Bleu_3": 5.413480481885139e-07, "Bleu_4": 1.2805437728409903e-09, "METEOR": 0.13559822979037758, "ROUGE_L": 0.19162303664921465, "CIDEr": 1.89178016746888e-15, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23529411764705882, "f": 0.20512820512820512, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a dog standing in a field with its paws on the ground. The dog is playing with a frisbee. The dog is standing on leaves. A splint is on the dog's left paw. The dog is licking its paw. The dog's fur is black and white. The dog is wearing a white shoe on its left paw."}, "28982": {"image_id": 28982, "Bleu_1": 0.222222222217284, "Bleu_2": 0.10050378152366245, "Bleu_3": 6.170193490770501e-07, "Bleu_4": 1.5378421667838189e-09, "METEOR": 0.17450152625006235, "ROUGE_L": 0.24063116370808676, "CIDEr": 3.865063932476356e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2631578947368421, "f": 0.23809523809523808, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two red stop signs with white letters on them. The signs are mounted on a pole in the middle of a parking lot. There are no cars in the lot. The signs are in good condition and appear to be well maintained."}, "200252": {"image_id": 200252, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.13525044519677484, "Bleu_3": 7.769700289594421e-07, "Bleu_4": 1.8743785288733243e-09, "METEOR": 0.27235329629123356, "ROUGE_L": 0.25120109814687713, "CIDEr": 1.4387424528701294e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.17647058823529413, "f": 0.18750000000000003, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a bedroom with two beds, a desk, and a closet. There are two pairs of shoes on the floor next to the bed. One pair is green and the other is white. The shoes appear to be sneakers."}, "133750": {"image_id": 133750, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.24349237676800983, "Bleu_3": 0.14133524661187286, "Bleu_4": 1.938341802255266e-05, "METEOR": 0.16196784187188332, "ROUGE_L": 0.27141268075639596, "CIDEr": 0.03656668921981202, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.05555555555555555, "f": 0.06349206349206349, "fn": 34.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.13333333333333333, "f": 0.14285714285714288, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows two zebras standing in a pen. The pen is surrounded by a fence. The zebras are standing on the ground."}, "172686": {"image_id": 172686, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.08268590713763764, "Bleu_4": 1.0646588104479637e-05, "METEOR": 0.19437300093670512, "ROUGE_L": 0.24069446271208733, "CIDEr": 1.4423989166441407e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.29411764705882354, "f": 0.24390243902439027, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a bowl of oranges on a wooden table. There are nine oranges in the bowl. The oranges are an orange color. Some of the oranges are sliced and some are whole. The oranges are arranged in a pattern of alternating sliced and whole oranges."}, "295765": {"image_id": 295765, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.17217163877715416, "Bleu_3": 0.10191897915864952, "Bleu_4": 0.06623699576007691, "METEOR": 0.2808277683318067, "ROUGE_L": 0.23591160220994478, "CIDEr": 5.625245944443478e-15, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2916666666666667, "f": 0.3111111111111111, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a plane flying in the sky. The body of the plane is white and red. The plane is flying with blue and white propellers. The plane is in good condition.\n\nThe sky is clear and blue, with a few clouds scattered in the distance. The plane is flying towards the left side of the image."}, "154867": {"image_id": 154867, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.15849534045439814, "Bleu_3": 0.08295835031586613, "Bleu_4": 1.0734404745305494e-05, "METEOR": 0.10109991583840755, "ROUGE_L": 0.23135271807838179, "CIDEr": 2.0921207761851184e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.21052631578947367, "f": 0.2222222222222222, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image does not contain a metal plate, rocky outcropping, body of water, or grass. However, there is a hole and rocks in the image. The image is taken from a low angle, looking down. The sky is blue and there are clouds in the distance."}, "233868": {"image_id": 233868, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.23791547571099586, "Bleu_3": 0.16329291590653727, "Bleu_4": 0.12650662740677643, "METEOR": 0.27979392602083436, "ROUGE_L": 0.3210526315789473, "CIDEr": 3.41950779441721e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man playing a video game. He is standing in front of a television, holding a controller in his hand. The television is showing a video game. The man is wearing a yellow shirt and gray pants. He has a look of concentration on his face. The room is well lit."}, "466239": {"image_id": 466239, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.16001422411453173, "Bleu_3": 8.926301664894732e-07, "Bleu_4": 2.1231792381840073e-09, "METEOR": 0.17037686465796814, "ROUGE_L": 0.3155483298847177, "CIDEr": 1.533698950080297e-05, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.0967741935483871, "f": 0.13636363636363635, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.23076923076923078, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a train crossing a bridge over a body of water. The train is silver and red. The bridge is made of steel. There is not a large concrete abutment at either end of the bridge."}, "361830": {"image_id": 361830, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.14815943949377966, "Bleu_3": 0.08256538592718124, "Bleu_4": 1.1031958317495015e-05, "METEOR": 0.23325830407640205, "ROUGE_L": 0.22021660649819497, "CIDEr": 1.5540440305081693e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a stop sign with grass growing around it. The sign is red and white with the words stop written in black letters. The background is a blue sky with no clouds. There are no cars in the scene."}, "102348": {"image_id": 102348, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.24866794885861784, "Bleu_3": 0.19153683966557564, "Bleu_4": 0.1487998309407241, "METEOR": 0.3426885538776898, "ROUGE_L": 0.28968792401628224, "CIDEr": 3.378380385744639e-08, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.1724137931034483, "f": 0.23809523809523808, "fn": 24.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a fire hydrant covered in snow. The fire hydrant is made of orange metal. There is no handle on top of the fire hydrant. A tree is next to the fire hydrant. The sky is cloudy and there is snow on the ground."}, "524621": {"image_id": 524621, "Bleu_1": 0.17460317460040317, "Bleu_2": 0.10613538967648731, "Bleu_3": 0.056946040698886306, "Bleu_4": 7.4483459174862765e-06, "METEOR": 0.17718926115229894, "ROUGE_L": 0.16061084781463927, "CIDEr": 1.1601995219841946e-17, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.16, "f": 0.21621621621621623, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows two giraffes standing in a clearing surrounded by trees. They are both looking at different directions. One giraffe is looking at a zebra, while the other giraffe is looking at a tree. The giraffes are standing in the bush. The sky is blue with some clouds in the background. The giraffes are both brown with white spots on their backs."}, "323729": {"image_id": 323729, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.11998523349247527, "Bleu_3": 0.07054895444072659, "Bleu_4": 9.679500319009214e-06, "METEOR": 0.1683726110470419, "ROUGE_L": 0.24286662242866625, "CIDEr": 9.987605114275885e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2, "f": 0.1923076923076923, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a living room with two couches. There is no coffee table or chair in the room. There is a door on the left side and the floor is made of wood. There is no rug in the center of the room."}, "505461": {"image_id": 505461, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.1448065155642414, "Bleu_4": 0.11318741601733968, "METEOR": 0.2053074283909101, "ROUGE_L": 0.30587392550143266, "CIDEr": 3.614529620957593e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16, "f": 0.15094339622641512, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This image shows two boats docked at a pier on a cloudy day. The boats are white and blue. The pier is made of wood and has a railing. There are people boarding a boat and looking at another boat."}, "113945": {"image_id": 113945, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.33476703169424327, "Bleu_3": 0.20248080783197475, "Bleu_4": 2.3770841794998468e-05, "METEOR": 0.282354927341732, "ROUGE_L": 0.3373271889400921, "CIDEr": 0.012740718271244797, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.26666666666666666, "f": 0.2051282051282051, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a red heart-shaped cake with two bears standing on top of it. The bears are wearing wedding rings. The cake is placed on a white pedestal."}, "185598": {"image_id": 185598, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2132007163490489, "Bleu_3": 0.11360703054848365, "Bleu_4": 1.486872032585981e-05, "METEOR": 0.24495880103709, "ROUGE_L": 0.39967239967239965, "CIDEr": 0.0005866696950929924, "SPICE": {"All": {"pr": 0.35, "re": 0.30434782608695654, "f": 0.3255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a woman surfing on a wave in the ocean. She is wearing a wetsuit and standing on a surfboard. The woman is smiling and appears to be enjoying the ride."}, "344364": {"image_id": 344364, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.10690449676280989, "Bleu_3": 6.197980942284417e-07, "Bleu_4": 1.5002485403888437e-09, "METEOR": 0.2282741442140286, "ROUGE_L": 0.22732919254658387, "CIDEr": 1.8356786725168855e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and blue shorts, and has a tennis racket in his hand.\n\nThe court is made of blue and white tiles. There are two lines on the court that mark the boundaries of the game."}, "331317": {"image_id": 331317, "Bleu_1": 0.17741935483584811, "Bleu_2": 0.07626944360167771, "Bleu_3": 4.593918667061921e-07, "Bleu_4": 1.1322034490908017e-09, "METEOR": 0.1579236959011153, "ROUGE_L": 0.15673175745118192, "CIDEr": 6.007055445985283e-15, "SPICE": {"All": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features two clocks. Clock 1 has a gold frame and a gold face. It has Roman numerals and is surrounded by a large window. Clock 2 also has a gold frame and a gold face. It has Roman numerals and is surrounded by a gold frame. The image is taken in a large, dimly lit room with a high ceiling."}, "412286": {"image_id": 412286, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.22794037622152502, "Bleu_3": 0.17775981771709612, "Bleu_4": 0.14708889510753856, "METEOR": 0.2971282343088496, "ROUGE_L": 0.3804573804573804, "CIDEr": 4.0425583000907336e-05, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a tennis court. He is wearing a white shirt and black shorts, and has a tennis racket in his hand. The sky is blue and there are clouds in the sky."}, "77394": {"image_id": 77394, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.15585730003579046, "Bleu_3": 8.691288996416392e-07, "Bleu_4": 2.0665100326125144e-09, "METEOR": 0.11100553844260386, "ROUGE_L": 0.24746450304259635, "CIDEr": 3.7909255289370256e-05, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.058823529411764705, "f": 0.043478260869565216, "fn": 16.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a living room with a couch, a table, and a chandelier hanging from the ceiling. A wreath is hanging from the chandelier. The room is decorated in a festive manner, with a Christmas tree and ornaments."}, "519569": {"image_id": 519569, "Bleu_1": 0.4444444444279836, "Bleu_2": 0.22645540682037069, "Bleu_3": 0.12705988559852477, "Bleu_4": 1.7098323692086587e-05, "METEOR": 0.20986779963406982, "ROUGE_L": 0.30530530530530536, "CIDEr": 0.011942992817923246, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.3333333333333333, "f": 0.16216216216216214, "fn": 6.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a kitchen with white cabinets and beige countertops. There is a large island with two stools on either side. The floor is made of hardwood."}, "127496": {"image_id": 127496, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.30678599553005403, "Bleu_3": 0.20453114927632365, "Bleu_4": 0.12787395553128056, "METEOR": 0.2986852637922913, "ROUGE_L": 0.43194335169158143, "CIDEr": 0.0010389220681925853, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3684210526315789, "f": 0.3414634146341463, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a white toilet, a white sink, and a white bathtub. The walls are painted white. The window is located in the bathroom. The floor is made of white tiles."}, "164555": {"image_id": 164555, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.18389242811841477, "Bleu_3": 0.09159919831148879, "Bleu_4": 1.1562497200951536e-05, "METEOR": 0.1864634099941412, "ROUGE_L": 0.24830393487109906, "CIDEr": 3.6001795802735805e-09, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.1111111111111111, "f": 0.10810810810810811, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This image shows a beach with a large body of water in the background. There are six baskets on the sand. Some people are flying a kite in the sky.\n\nThe sky is blue and there are some clouds in the distance. The beach is sandy."}, "572477": {"image_id": 572477, "Bleu_1": 0.255813953482423, "Bleu_2": 0.17451086522195614, "Bleu_3": 0.1306153185181404, "Bleu_4": 0.0863934042964332, "METEOR": 0.2692735418927057, "ROUGE_L": 0.29756097560975614, "CIDEr": 1.3577745720426758e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2857142857142857, "f": 0.2790697674418604, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6666666666666666, "f": 0.5454545454545455, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a man playing tennis on a tennis court. He is wearing a black shirt and jeans, and has a tennis racket in his hand. The court is made of asphalt. There is a tree and a fence in the background."}, "40037": {"image_id": 40037, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.20207633640188252, "Bleu_3": 0.12981395520520816, "Bleu_4": 1.4122135180868542e-05, "METEOR": 0.2890985574825629, "ROUGE_L": 0.2643553629469122, "CIDEr": 2.4907928456804206e-14, "SPICE": {"All": {"pr": 0.1875, "re": 0.15789473684210525, "f": 0.17142857142857143, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows two buildings. The first building has a clock tower on top and a gray roof. There are three windows on the sides of the building. The second building has a dome on top and is made of stone. There is a large parking lot surrounding the buildings, and a bus is parked in the lot."}, "504487": {"image_id": 504487, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.4242640686946045, "Bleu_3": 0.3151627539628544, "Bleu_4": 0.1942206909793554, "METEOR": 0.25318987003645993, "ROUGE_L": 0.38566912539515275, "CIDEr": 0.028709479914725652, "SPICE": {"All": {"pr": 0.15, "re": 0.14285714285714285, "f": 0.14634146341463414, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of eight giraffes standing in a fenced area. The giraffes are standing on the ground and looking at a tree."}, "547047": {"image_id": 547047, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.3459163477621225, "Bleu_3": 0.2123296873626401, "Bleu_4": 2.5130737266766878e-05, "METEOR": 0.2698899129823179, "ROUGE_L": 0.4149659863945578, "CIDEr": 0.3109531272043141, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.20833333333333334, "f": 0.2702702702702703, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a sign that reads, \"Attention dog owners, please pick up after your dogs.\" The sign is located in the middle of a dirt lot."}, "501835": {"image_id": 501835, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.1462544848210594, "Bleu_3": 0.08743583640208556, "Bleu_4": 1.2117880855538534e-05, "METEOR": 0.2016395608178774, "ROUGE_L": 0.21441124780316342, "CIDEr": 0.00021046414220244806, "SPICE": {"All": {"pr": 0.2, "re": 0.15, "f": 0.17142857142857143, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows three horses pulling a carriage down a gravel road through a forest. The carriage is decorated with a black and white striped blanket. The trees in the forest have green leaves."}, "92248": {"image_id": 92248, "Bleu_1": 0.4634146341350387, "Bleu_2": 0.32290601214250725, "Bleu_3": 0.23732995298936232, "Bleu_4": 0.16286434412424713, "METEOR": 0.25542060826288593, "ROUGE_L": 0.42182308037718896, "CIDEr": 0.0001306224961901556, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.23529411764705882, "f": 0.1702127659574468, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a building with a clock tower on top. The building has a stone facade and columns. There is a statue of a dragon on top of the building. The other statue is a lion. The sky is blue."}, "105465": {"image_id": 105465, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.3692744729208134, "Bleu_3": 0.30100671894004044, "Bleu_4": 0.2314734800629201, "METEOR": 0.2574101126181039, "ROUGE_L": 0.3489702517162472, "CIDEr": 0.09578851938043931, "SPICE": {"All": {"pr": 0.0625, "re": 0.037037037037037035, "f": 0.046511627906976744, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows an airplane with purple and blue seats and purple and blue windows. There are no people in the image."}, "506942": {"image_id": 506942, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1371021242743437, "Bleu_3": 6.991578304852386e-07, "Bleu_4": 1.586108817962657e-09, "METEOR": 0.1861494838320412, "ROUGE_L": 0.20504201680672268, "CIDEr": 6.700768715453982e-15, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of seven people sitting on the beach. The people are playing beach volleyball, playing frisbee, playing volleyball on the beach, and walking on the beach. \n\nThere are two beach chairs under the umbrella. \n\nIn the background, there is a beach volleyball net. \n\nThe overall scene shows chairs and umbrellas on the sand."}, "115455": {"image_id": 115455, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.1379656129587101, "Bleu_4": 0.10990311827438792, "METEOR": 0.1974109888374136, "ROUGE_L": 0.3155949741315595, "CIDEr": 6.791010329383421e-06, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman sitting on the ground. She is holding a basket in her lap. The woman is wearing a black skirt. The background is a green forest.\n\nThere are no trees or bushes in the scene."}, "129135": {"image_id": 129135, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.26967994497923586, "Bleu_3": 0.20373530018127356, "Bleu_4": 0.15677171297743656, "METEOR": 0.32327850225123844, "ROUGE_L": 0.3134232498394348, "CIDEr": 4.6889544899744824e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.11538461538461539, "f": 0.14285714285714285, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a train parked at a train station. The train is yellow and blue. The train has two windows. \n\nThe platform has a bench, and the passengers are sitting on it, looking at the train. \n\nThere are no other people in the scene."}, "26908": {"image_id": 26908, "Bleu_1": 0.30952380951644, "Bleu_2": 0.2128289624210096, "Bleu_3": 0.1503283554093226, "Bleu_4": 0.09660831957637359, "METEOR": 0.23888642966227597, "ROUGE_L": 0.34359283846308586, "CIDEr": 2.135764325630217e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08, "f": 0.10256410256410256, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a dog lying on the ground. The dog is chewing on a bone. The road is empty and there are no vehicles or people in sight. The grass is green. The dog is black and has a white patch."}, "367329": {"image_id": 367329, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.08696565534534605, "Bleu_3": 6.119658713574004e-07, "Bleu_4": 1.6359043508197515e-09, "METEOR": 0.16417910447761194, "ROUGE_L": 0.20350291909924936, "CIDEr": 5.2759924248750803e-05, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.17391304347826086, "f": 0.15384615384615385, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows three zebras standing in a fenced in area. The zebras are wearing stripes and appear to be not healthy. The fence is made of black metal and does not have a gate."}, "521601": {"image_id": 521601, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.2717786532439402, "Bleu_3": 0.16828019067165936, "Bleu_4": 0.11226501349146902, "METEOR": 0.2667760269183328, "ROUGE_L": 0.3396976929196499, "CIDEr": 0.0006507259364505762, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09523809523809523, "f": 0.12121212121212123, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a cup with a yellow handle. The cup is sitting on a table. There is a brown lid on the cup, and there is a small hole in the lid."}, "344094": {"image_id": 344094, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.11420804814152181, "Bleu_3": 6.667764421629133e-07, "Bleu_4": 1.6203844679821425e-09, "METEOR": 0.16522598244174153, "ROUGE_L": 0.1927939317319848, "CIDEr": 1.3522269164856077e-08, "SPICE": {"All": {"pr": 0.030303030303030304, "re": 0.043478260869565216, "f": 0.03571428571428572, "fn": 22.0, "numImages": 1.0, "fp": 32.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.06666666666666667, "re": 0.09090909090909091, "f": 0.07692307692307691, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}}, "caption": "The image features a plant with fern-like leaves. The plant is sitting in a white vase on a wooden table. The stem of the plant is a few inches tall. There is a small white flower on the table. The wall in the background is white."}, "396209": {"image_id": 396209, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.09415544714235627, "Bleu_3": 5.776228382887613e-07, "Bleu_4": 1.4385671494946425e-09, "METEOR": 0.18352491852224864, "ROUGE_L": 0.23461538461538461, "CIDEr": 3.490906183934632e-10, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.09523809523809523, "f": 0.09302325581395349, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a narrow street with buildings on either side. The buildings are made of stone and have balconies with ivy growing on them. There is a table and a chair on either side of the street. A motorcycle is on the sidewalk. The sky is white."}, "529798": {"image_id": 529798, "Bleu_1": 0.15094339622356714, "Bleu_2": 0.07619393177449452, "Bleu_3": 4.846447707252929e-07, "Bleu_4": 1.2283585334482279e-09, "METEOR": 0.194108476482543, "ROUGE_L": 0.18100890207715134, "CIDEr": 1.2523287259573015e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13793103448275862, "f": 0.1951219512195122, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a flock of seven sheep grazing on a rocky hillside. The sheep are walking and grazing on grass and rocks. They come in various colors, including white, black, brown. \n\nThere are no people in the scene.\n\nIn the background, there is a lake with a white flag on the shore."}, "62985": {"image_id": 62985, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 6.880010617668035e-07, "Bleu_4": 1.631181823642126e-09, "METEOR": 0.1305181510593934, "ROUGE_L": 0.2208811104405552, "CIDEr": 1.2497794286102186e-09, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2692307692307692, "f": 0.2916666666666667, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two people skiing down two snowy mountain slopes. One person is holding a snowboard and the other person is holding a ski pole. The person wearing a green jacket is skiing down the slope. The sky is cloudy. There are no other mountains in the scene."}, "517674": {"image_id": 517674, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.09486600651870754, "Bleu_4": 0.06428216024395343, "METEOR": 0.2146491672923291, "ROUGE_L": 0.27774615822424586, "CIDEr": 1.6791020584782906e-11, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16666666666666666, "f": 0.19512195121951217, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a street with cars driving down it. There are buildings on either side of the street. There is a traffic light at the intersection. The sky is cloudy and there is no sun.\n\nThe image is taken at night, as evidenced by the streetlights on the side of the road."}, "575691": {"image_id": 575691, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.12354612406992554, "Bleu_3": 0.06973999503999065, "Bleu_4": 9.370187147557456e-06, "METEOR": 0.12909062792437728, "ROUGE_L": 0.16277518345563707, "CIDEr": 5.099552546283399e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two women standing next to two giraffes in a zoo. The women are wearing red and white striped shirts. The giraffes are eating grass and reaching up to the women. One of the women's face is being reached up to by a giraffe."}, "267690": {"image_id": 267690, "Bleu_1": 0.3214285714170919, "Bleu_2": 0.10910894511402736, "Bleu_3": 7.707540024261883e-07, "Bleu_4": 2.0687206009477373e-09, "METEOR": 0.15832365445561072, "ROUGE_L": 0.20890410958904107, "CIDEr": 0.0018927528861954956, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09523809523809523, "f": 0.0909090909090909, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows three boys wearing suits and hats standing on a sidewalk in front of a building. The boys are all smiling and looking at the camera."}, "119641": {"image_id": 119641, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.221323371633511, "Bleu_3": 0.1422990097780613, "Bleu_4": 1.549383431134387e-05, "METEOR": 0.2402947386668385, "ROUGE_L": 0.2959369314736203, "CIDEr": 1.3182544019927805e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of four people riding on the backs of six elephants through a river. The elephants are riding in the water. The elephants are wearing a hat. The people are wearing a white shirt and a hat.\n\nThe river is surrounded by trees. A hill is in the background."}}}