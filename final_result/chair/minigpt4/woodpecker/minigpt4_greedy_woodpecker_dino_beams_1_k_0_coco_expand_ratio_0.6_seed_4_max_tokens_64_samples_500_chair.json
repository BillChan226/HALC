{"overall": {"Bleu_1": 0.26337576014287445, "Bleu_2": 0.1707519820942303, "Bleu_3": 0.10424086497795013, "Bleu_4": 0.06350510980012494, "METEOR": 0.20976761856388534, "ROUGE_L": 0.26250091597112857, "CIDEr": 0.010594588653899542, "SPICE": 0.18025182992664476}, "imgToEval": {"504142": {"image_id": 504142, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.21997067252481586, "Bleu_3": 1.1860705496446933e-06, "Bleu_4": 2.7783911310133035e-09, "METEOR": 0.13455483437248605, "ROUGE_L": 0.2944489139179405, "CIDEr": 0.0021675433110282328, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.1724137931034483, "f": 0.21276595744680854, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a dog sleeping on a couch with a blanket over its head. The dog is wearing a collar.\n\nThere are no pillows, lamp, or table in the scene."}, "49115": {"image_id": 49115, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.12038585308312308, "Bleu_3": 0.06906098117642889, "Bleu_4": 9.355294087801786e-06, "METEOR": 0.2100829682679496, "ROUGE_L": 0.2719745222929936, "CIDEr": 5.44730701876093e-08, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.03333333333333333, "f": 0.03389830508474576, "fn": 29.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a giraffe standing on a rock in a park. The giraffe is brown with spots on its back and neck. It has a long neck, head, legs, and feet. The giraffe is looking at a tree. There is no path in the scene."}, "328284": {"image_id": 328284, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.07930515857033198, "Bleu_3": 4.945382002622933e-07, "Bleu_4": 1.240958731067451e-09, "METEOR": 0.14434095415540013, "ROUGE_L": 0.1821983273596177, "CIDEr": 2.060990887265252e-13, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.0967741935483871, "f": 0.13636363636363635, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two women skiing on a ski trail covered in snow. Both women are wearing jackets and pants. They are holding ski poles as they ski. The trees in the background are covered in snow. A stream is running through the middle of the image. There is no backpack in the scene."}, "434662": {"image_id": 434662, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.10714285714064781, "Bleu_3": 6.250904486134178e-07, "Bleu_4": 1.5179857311603866e-09, "METEOR": 0.13693693693693695, "ROUGE_L": 0.15752098127824402, "CIDEr": 5.456506433638073e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person wearing a helmet and goggles, standing on a snowy road. The person is holding a ski pole in their left hand. The person is wearing a blue jacket and black pants. The person is standing on a snow slope and is holding a snowboard."}, "307166": {"image_id": 307166, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.1791244302026115, "Bleu_3": 0.12610429748037671, "Bleu_4": 1.5948028086028776e-05, "METEOR": 0.17001390575674358, "ROUGE_L": 0.25979557069846676, "CIDEr": 0.0006400850229678953, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.11764705882352941, "f": 0.09756097560975609, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a table with two pizzas on it. There are also drinks on the table. The table is not in a kitchen or dining area.\n\nThe image is in black and white."}, "386352": {"image_id": 386352, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.2909938476144488, "Bleu_3": 0.22433762449235847, "Bleu_4": 0.1670454254892528, "METEOR": 0.27032754035295337, "ROUGE_L": 0.3798932384341636, "CIDEr": 0.0011016323286525361, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a woman playing tennis. She is wearing a blue shirt and has a tennis racket in her hand. There are several people watching a tennis match in the background."}, "74059": {"image_id": 74059, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.10562592656622659, "Bleu_4": 1.2211216504829663e-05, "METEOR": 0.23267073848048334, "ROUGE_L": 0.2663755458515284, "CIDEr": 6.106487197442802e-13, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.11538461538461539, "f": 0.13953488372093026, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a tall, stone tower with a clock face on the front. The clock face has Roman numerals and hands. The tower is surrounded by a stone wall and there is a gate on the left side. The sky is blue and there are clouds in the background.\n\nThe image is taken at sunset."}, "466882": {"image_id": 466882, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.06657795516001168, "Bleu_3": 4.584595505702186e-07, "Bleu_4": 1.2096859591117995e-09, "METEOR": 0.1901433823752287, "ROUGE_L": 0.154040404040404, "CIDEr": 6.622264633083221e-10, "SPICE": {"All": {"pr": 0.3125, "re": 0.17857142857142858, "f": 0.22727272727272727, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features two players playing tennis on two tennis courts. The players are wearing white shirts and black shorts, and they are holding rackets. The court is made of blue and white tiles, and there are lines on the court to mark the boundaries of the game."}, "264124": {"image_id": 264124, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.26794565081604904, "Bleu_3": 0.21139430216468957, "Bleu_4": 0.16636035584894698, "METEOR": 0.2514045637119328, "ROUGE_L": 0.3139705882352941, "CIDEr": 1.1995235232205703e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 10.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a man wearing a black shirt and sporting a beard. He is talking on a cell phone and holding it to his ear. The man is smiling.\n\nIn the background, there is a building and a tree."}, "92205": {"image_id": 92205, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.30543850923258115, "Bleu_3": 0.2430215251256089, "Bleu_4": 0.1971526664520057, "METEOR": 0.31016957900327363, "ROUGE_L": 0.3768016472203157, "CIDEr": 0.00015150981152450252, "SPICE": {"All": {"pr": 0.125, "re": 0.2777777777777778, "f": 0.1724137931034483, "fn": 13.0, "numImages": 1.0, "fp": 35.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.5555555555555556, "f": 0.3703703703703704, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "The image shows a man standing on the side of a road holding a stop sign. The road is empty and there are no other cars or pedestrians in sight. The man is wearing a yellow vest and a hard hat."}, "34071": {"image_id": 34071, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.12725695259184966, "Bleu_3": 0.0759254028064691, "Bleu_4": 1.0500614219604798e-05, "METEOR": 0.13792427279181624, "ROUGE_L": 0.17341862117981524, "CIDEr": 8.558599312736003e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "There is no car in this image. There is no road or mirror either. However, there is a sun setting in the background. The image captures a scene at night with the headlights of a car illuminating the surroundings."}, "555066": {"image_id": 555066, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.2014440620697061, "Bleu_3": 0.17687610721625666, "Bleu_4": 0.15926753768166318, "METEOR": 0.26668148173074085, "ROUGE_L": 0.30160692212608153, "CIDEr": 1.028286814478797e-07, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.19230769230769232, "f": 0.1694915254237288, "fn": 21.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two cars parked on the side of the road. There are no buildings, streets, or sidewalks in the scene. There is one person standing in front of a wall. The sky is visible in the background. There are no trees in the scene."}, "448786": {"image_id": 448786, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.11964664509646934, "Bleu_4": 0.07944348368460985, "METEOR": 0.2177327082765591, "ROUGE_L": 0.24238410596026488, "CIDEr": 6.638906764793928e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 28.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.4666666666666667, "f": 0.5185185185185186, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image shows a bullet train with a sleek and modern design. The train has a white and blue body, with a blue stripe running along the side. It has a maximum speed of 320 km/h. The train also features a large window on the front."}, "324308": {"image_id": 324308, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.10281451514171928, "Bleu_3": 6.313737539096188e-07, "Bleu_4": 1.5740514693995106e-09, "METEOR": 0.18357006466301987, "ROUGE_L": 0.17134831460674158, "CIDEr": 4.439399072497325e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a banana plant growing on a fence. The plant has green leaves and green bananas hanging from it. The fence is made of wood and does not have a gate. \n\nThe sky is blue and there are clouds in the background."}, "42837": {"image_id": 42837, "Bleu_1": 0.378378378368152, "Bleu_2": 0.2712444903948123, "Bleu_3": 0.1847530799391623, "Bleu_4": 0.13878148650215147, "METEOR": 0.2682403474819696, "ROUGE_L": 0.2697126013264554, "CIDEr": 0.00015143044264121907, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1, "f": 0.11320754716981132, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a wetsuit and is standing on the board with his feet on the ground. The wave is crashing down on the surfer."}, "314690": {"image_id": 314690, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.22522130822577494, "Bleu_3": 0.1664467895387212, "Bleu_4": 0.13392750150279648, "METEOR": 0.21356574677644966, "ROUGE_L": 0.2794502617801047, "CIDEr": 3.3889262698667213e-07, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.19230769230769232, "f": 0.17543859649122806, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a living room with a couch, a television, and a wall with a poster on it. The walls are green. The floor is made of hardwood and there is a rug on it. \n\nThere is no coffee table or window in the scene."}, "263780": {"image_id": 263780, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.14907119849663567, "Bleu_3": 0.08024900879514213, "Bleu_4": 1.0532159683631698e-05, "METEOR": 0.16451364292091378, "ROUGE_L": 0.2053872053872054, "CIDEr": 2.4006267616450157e-08, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.23333333333333334, "f": 0.2592592592592593, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two elephants standing on a dirt area. The elephants are brown and do not have a white patch on their backs. They are walking and appear to be looking at different things - one at a pond and the other at a tree."}, "256035": {"image_id": 256035, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.083971912273837, "Bleu_3": 5.703763329560112e-07, "Bleu_4": 1.4964792230382814e-09, "METEOR": 0.20463007593252225, "ROUGE_L": 0.2937534397358283, "CIDEr": 1.09184306494977e-05, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.06896551724137931, "f": 0.07017543859649124, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a person wearing a black ski suit, black gloves, and a black helmet. The person is holding ski poles and is ready to ski down the snowy slope. The person is standing on yellow and red skis."}, "413900": {"image_id": 413900, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.17817416126992966, "Bleu_3": 0.12314407142557375, "Bleu_4": 0.08673245635138281, "METEOR": 0.2593796529265844, "ROUGE_L": 0.29047619047619044, "CIDEr": 9.313593158787315e-05, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2222222222222222, "f": 0.27272727272727276, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows two people playing a video game. They are standing near a screen and looking at a cell phone. The people are wearing shirts, pants, and hoodies. There are no plants in the scene."}, "357978": {"image_id": 357978, "Bleu_1": 0.1710526315766967, "Bleu_2": 0.04775669329345939, "Bleu_3": 3.1352987234103033e-07, "Bleu_4": 8.060806187610442e-10, "METEOR": 0.13285269815593043, "ROUGE_L": 0.1776206322795341, "CIDEr": 3.142543945414611e-25, "SPICE": {"All": {"pr": 0.10638297872340426, "re": 0.17857142857142858, "f": 0.13333333333333333, "fn": 23.0, "numImages": 1.0, "fp": 42.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.10526315789473684, "re": 0.2, "f": 0.13793103448275862, "fn": 8.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Size": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.2727272727272727, "f": 0.21428571428571427, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image shows two women standing in front of a white wall. One of the women is wearing a red and white striped shirt and the other is wearing a white shirt. Both women are holding a Wii remote and have smiles on their faces, indicating that they are playing a game. \n\nThere is no cane in the image.\n\nThere are no other people in the room.\n\nThere is not a person sitting on a couch."}, "521874": {"image_id": 521874, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.0953462589231035, "Bleu_3": 5.2176600559778e-07, "Bleu_4": 1.2253825679269957e-09, "METEOR": 0.18473274622109814, "ROUGE_L": 0.21243781094527364, "CIDEr": 3.390396669576206e-19, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.23076923076923078, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a train traveling along a track. The train is blue and red. The train is traveling north. The train is facing the viewer. The body of the train is blue and red. The roof of the train is blue. The wheels of the train are red. \n\nNext to the track, there is a building with a green roof. The building has white walls."}, "49517": {"image_id": 49517, "Bleu_1": 0.14285714285568515, "Bleu_2": 0.08581241314761598, "Bleu_3": 0.05353276360517659, "Bleu_4": 6.3391911396802805e-06, "METEOR": 0.14944272082339483, "ROUGE_L": 0.1309200171698383, "CIDEr": 1.3285900314537434e-46, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.3157894736842105, "f": 0.19047619047619047, "fn": 13.0, "numImages": 1.0, "fp": 38.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2857142857142857, "f": 0.16, "fn": 5.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a kitchen with two stoves. On the first stove, there is a pot of potatoes. On the second stove, there is a pot of soup. There is no sink or refrigerator in the scene. \n\nThere is one pot and two pans on the stove. There is no bowl in the scene. \n\nThere is one bowl of food on the counter. There are two cabinets above the counter. Above the first cabinet, there is a microwave. Above the second cabinet, there is a clock. \n\nThe walls are painted white. There are no windows in the scene."}, "67616": {"image_id": 67616, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.2219805449057966, "Bleu_3": 0.16484624050415608, "Bleu_4": 0.1329604526834031, "METEOR": 0.20926192303382543, "ROUGE_L": 0.2662758792716388, "CIDEr": 2.956241098230623e-07, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1875, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a street with a building on either side. There is a car parked on the side of the street. People are walking on the sidewalk.\n\nThere are no other buildings, brick, or windows in the scene.\n\nThere is a tree in the area.\n\n"}, "154071": {"image_id": 154071, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.17264741623354635, "Bleu_3": 0.08056537575108588, "Bleu_4": 9.830244525527297e-06, "METEOR": 0.18461140660286868, "ROUGE_L": 0.17300056721497448, "CIDEr": 1.908107381339576e-14, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.21428571428571427, "f": 0.1643835616438356, "fn": 22.0, "numImages": 1.0, "fp": 39.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3157894736842105, "re": 0.6, "f": 0.41379310344827586, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}}, "caption": "The image shows a baseball game in progress on a field with a large crowd of people watching. The players are wearing white and maroon uniforms with a swoosh on the back. The umpire is a baseball umpire, ready to throw out the batter. The game is taking place on a field with a home plate in the center."}, "351133": {"image_id": 351133, "Bleu_1": 0.4444444444279836, "Bleu_2": 0.3698001308028598, "Bleu_3": 0.2541197711970494, "Bleu_4": 0.1617059615981109, "METEOR": 0.3001065939407281, "ROUGE_L": 0.4608120868744097, "CIDEr": 0.031015471292442642, "SPICE": {"All": {"pr": 0.2, "re": 0.2916666666666667, "f": 0.23728813559322035, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.45454545454545453, "f": 0.3846153846153846, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a woman standing in a bathroom. The woman is brushing her teeth and holding a toothbrush. The bathroom features a mirror on the wall."}, "270165": {"image_id": 270165, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.22131333406452386, "Bleu_3": 0.14519947954201504, "Bleu_4": 1.59753113202508e-05, "METEOR": 0.250302174151971, "ROUGE_L": 0.34574898785425096, "CIDEr": 1.153602401510618e-08, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.34782608695652173, "f": 0.3636363636363636, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a red cow with a pink hat on its head standing in front of a building. The cow is wearing a pink hat and has a red nose. The building has a red and white striped awning. There is no sidewalk, door, or tree in the scene."}, "200250": {"image_id": 200250, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.06270761041513984, "Bleu_3": 4.1255718841224776e-07, "Bleu_4": 1.062973521947745e-09, "METEOR": 0.11922503725782413, "ROUGE_L": 0.1321776814734561, "CIDEr": 2.2313639126665636e-13, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman walking down the street. There are two billboards on the side of the street. The first billboard has the words \"Get out of the un\" written underneath the picture. The second billboard has the words \"The u s of america\" written underneath the picture. The woman is wearing a white jacket and jeans."}, "302990": {"image_id": 302990, "Bleu_1": 0.18181818181267223, "Bleu_2": 0.1305582419627553, "Bleu_3": 0.10321883735007978, "Bleu_4": 0.07781062585419259, "METEOR": 0.16834471682383081, "ROUGE_L": 0.2497952497952498, "CIDEr": 0.0005049691586640056, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.11764705882352941, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image shows two surfers riding a wave on surfboards. The surfers are wearing black wetsuits. They have their arms outstretched as they ride the wave. The wave is breaking and is white."}, "147425": {"image_id": 147425, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.2619684159899703, "Bleu_3": 0.1859900515820873, "Bleu_4": 2.1344051626100504e-05, "METEOR": 0.2163408096848368, "ROUGE_L": 0.3061224489795918, "CIDEr": 0.00021628084924901075, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a cat sitting on a black suitcase. The cat is brown and black. The suitcase is black and has a handle on top. The cat is looking up at the camera."}, "152245": {"image_id": 152245, "Bleu_1": 0.20930232557896158, "Bleu_2": 0.12154950351770238, "Bleu_3": 0.08893970704162234, "Bleu_4": 0.0710121336097626, "METEOR": 0.17602576861368197, "ROUGE_L": 0.20685757347400152, "CIDEr": 1.3339885152460162e-32, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of eight people standing in a line at an airport. The people are looking at a laptop, talking to each other, talking on the phone, smiling, eating a sandwich, and pushing a cart. They are putting their luggage on the conveyor belt. The people are wearing a white shirt, a blue jacket, a black shirt, a blue shirt, and blue jeans. A flight information screen is displayed on the screen.\n\nThere are no suitcases or a security checkpoint in the scene."}, "191689": {"image_id": 191689, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.11009637651016171, "Bleu_3": 6.55680898648204e-07, "Bleu_4": 1.60955965059484e-09, "METEOR": 0.19684245112002124, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.058757545528996e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two brown bears standing on a rocky outcropping in a forest. The bears are looking at the camera. One bear is standing on a fence and the other bear is standing on grass. The background is a mix of trees and rocks."}, "51484": {"image_id": 51484, "Bleu_1": 0.2692307692204142, "Bleu_2": 0.207549808656966, "Bleu_3": 0.15311620018090075, "Bleu_4": 0.11177222546745082, "METEOR": 0.2865643386349552, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.0134689319275496, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.20833333333333334, "f": 0.21739130434782608, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows two couples walking on the beach. They are holding surfboards. They are looking at the ocean. The beach is lined with palm trees."}, "66181": {"image_id": 66181, "Bleu_1": 0.1710526315766967, "Bleu_2": 0.08271701918575548, "Bleu_3": 4.5218832366238747e-07, "Bleu_4": 1.0608617546960753e-09, "METEOR": 0.13418243751091777, "ROUGE_L": 0.16194690265486725, "CIDEr": 3.3966503860253545e-26, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.15, "f": 0.10909090909090909, "fn": 17.0, "numImages": 1.0, "fp": 32.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.11764705882352941, "re": 0.25, "f": 0.15999999999999998, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}}, "caption": "The image shows two frames in the scene. The first frame is black and contains two pictures of a baby. The second frame is made of light wood and contains a drawing of a cat.\n\nThere is a vase on the table with a bunch of green leaves in it. A wall is behind the table, and there is a painting on the wall.\n\nThe image also features a baby in a black and white photo."}, "289263": {"image_id": 289263, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.22696949467552002, "Bleu_3": 0.1428653103202315, "Bleu_4": 1.5388427959471035e-05, "METEOR": 0.23163585912064324, "ROUGE_L": 0.24610951008645532, "CIDEr": 1.8655048025048697e-12, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.3684210526315789, "f": 0.3684210526315789, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a woman standing on the beach. She is holding a surfboard and wearing a bikini. Her hair is tied back with a hair band. The waves are crashing against the shore in the background. The sky is blue and there are clouds in the distance. The woman is smiling and looks happy."}, "536426": {"image_id": 536426, "Bleu_1": 0.1690140845046618, "Bleu_2": 0.09827485785206054, "Bleu_3": 0.05192126352208002, "Bleu_4": 6.735684107821933e-06, "METEOR": 0.2057409445116468, "ROUGE_L": 0.2285714285714286, "CIDEr": 1.6752464566827456e-22, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.08695652173913043, "f": 0.0784313725490196, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a pink traffic cone on the side of the road. In front of the road, there are two houses. A tree is in front of the houses. The roof of the first house is black and the front door is blue. The roof of the second house is blue and the front door is also blue. There is a fire hydrant located on the side of the road."}, "377814": {"image_id": 377814, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.152387863548989, "Bleu_3": 0.0969289541450585, "Bleu_4": 0.06532774148415076, "METEOR": 0.17838115185516576, "ROUGE_L": 0.25707405177603854, "CIDEr": 9.79888248994007e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.17391304347826086, "f": 0.19999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a box of six donuts. The donuts are of different flavors and toppings. The flavors include chocolate, vanilla, cinnamon, and strawberry. The donuts are arranged in rows on a tray inside the box. The box is made of paper and does not have a clear plastic window on the top."}, "411754": {"image_id": 411754, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.21223817998318867, "Bleu_3": 0.13704703969756082, "Bleu_4": 0.09327870647149639, "METEOR": 0.24415056052488227, "ROUGE_L": 0.2930344275420336, "CIDEr": 1.868348366059227e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.10714285714285714, "f": 0.15, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man in a red shirt sitting on a bench, looking at his phone. He is also wearing jeans and has a beard. There are other people in the background. The walls are white."}, "340034": {"image_id": 340034, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.2540002539920509, "Bleu_3": 0.16447507755428037, "Bleu_4": 0.11227564716536803, "METEOR": 0.22254756581106117, "ROUGE_L": 0.31448702526207256, "CIDEr": 0.003651712894459482, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.18181818181818182, "f": 0.14545454545454545, "fn": 18.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5714285714285714, "f": 0.34782608695652173, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a boy sitting on a toilet, looking at a phone. The boy is wearing a black shirt. The bathroom is dimly lit, with a window in the background."}, "193050": {"image_id": 193050, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.11180339887325601, "Bleu_3": 0.05832523373035536, "Bleu_4": 7.521326530167089e-06, "METEOR": 0.21311766695862272, "ROUGE_L": 0.2190867111339148, "CIDEr": 6.859275771646859e-19, "SPICE": {"All": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a group of six sheep grazing in a green field. The sheep are grazing on grass, some are laying down, and some are eating grass. They are standing in the grass, looking at each other. A tarp is hanging behind the sheep. The fence in the background is made of wood, and there is barbed wire on it. The sky is blue."}, "217269": {"image_id": 217269, "Bleu_1": 0.1486486486466399, "Bleu_2": 0.11939003311422937, "Bleu_3": 0.058282013830438524, "Bleu_4": 7.266684840308887e-06, "METEOR": 0.2027108849585472, "ROUGE_L": 0.19533394327538886, "CIDEr": 8.64610638604447e-23, "SPICE": {"All": {"pr": 0.15, "re": 0.0967741935483871, "f": 0.11764705882352941, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a computer on a desk. There is a computer monitor on the desk, displaying a picture of a cat. A keyboard and a mouse are also on the desk. Another laptop is on a separate desk, and there is a laptop on the desk as well. \n\nThere are two chairs in front of the desk. The room has white walls and windows on both sides. The floor is made of wood."}, "437290": {"image_id": 437290, "Bleu_1": 0.15789473684002772, "Bleu_2": 0.11239029738831462, "Bleu_3": 0.0698905790873741, "Bleu_4": 8.269576405221184e-06, "METEOR": 0.19025249696479535, "ROUGE_L": 0.22303473491773307, "CIDEr": 4.39118883651935e-25, "SPICE": {"All": {"pr": 0.3125, "re": 0.2631578947368421, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of 18 people standing in a room. The people are wearing cosplay costumes. Some of the people are playing games, talking on the phone, or talking to each other. Some are playing video games or playing with a Wii. Some are holding a frisbee or a ball. Some are standing in a line. \n\nThere are no costumes or props in the scene.\n\nThere is no table or screen in the scene."}, "282928": {"image_id": 282928, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.15289415742853263, "Bleu_3": 0.10910293277568511, "Bleu_4": 0.07035716820731766, "METEOR": 0.17946453530673964, "ROUGE_L": 0.23775055679287305, "CIDEr": 4.594067094875858e-13, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.07407407407407407, "f": 0.0909090909090909, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a man holding a sandwich in his hand. The sandwich appears to be a sandwich, not a hamburger, and there is no lettuce, tomato, or cheese on top. The man is wearing a blue shirt and blue jeans, not a white shirt. The background is a blue sky, but there are no clouds."}, "188084": {"image_id": 188084, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.24880667575704968, "Bleu_3": 1.2210919836895118e-06, "Bleu_4": 2.725415993494921e-09, "METEOR": 0.2582051186308048, "ROUGE_L": 0.358612580834803, "CIDEr": 0.00019394232783172813, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a sandwich with a cup of coffee on the side. The sandwich has a filling of meat and vegetables. The drink is a coffee. The table has a gray tablecloth and a napkin."}, "552320": {"image_id": 552320, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.18478728706739583, "Bleu_3": 9.566649380940492e-07, "Bleu_4": 2.19090725664289e-09, "METEOR": 0.1956772889018037, "ROUGE_L": 0.29306794783802337, "CIDEr": 1.0945528561574627e-05, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16666666666666666, "f": 0.19607843137254902, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two men standing in a kitchen. One man is holding a pizza in his hands, while the other man is holding a samsung galaxy s3. The pizza is topped with pepperoni, sausage, mushrooms, onions, peppers, olives, and pepperoncini."}, "530313": {"image_id": 530313, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.13819269959596528, "Bleu_3": 0.08508823255530318, "Bleu_4": 1.0024660377689843e-05, "METEOR": 0.1516964233576751, "ROUGE_L": 0.1881167763157895, "CIDEr": 8.849954414164535e-18, "SPICE": {"All": {"pr": 0.1, "re": 0.09523809523809523, "f": 0.0975609756097561, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of 16 people sitting in a room. They are wearing suits and ties. Some of the people are sitting in a crowd, while others are sitting in a row. They are engaged in various activities, such as eating, holding a frisbee, or talking on the phone. The room is well lit and there are no windows in the scene."}, "242060": {"image_id": 242060, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1666666666629209, "Bleu_3": 0.12467616434942133, "Bleu_4": 0.0980127897842689, "METEOR": 0.19264253315757743, "ROUGE_L": 0.25258799171842644, "CIDEr": 2.1299619011282512e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.23076923076923078, "f": 0.21428571428571427, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows two plates of cinnamon rolls on a wooden table. There is a teapot and cups on the side of the wooden table. There are no lemons in the image. There are herbs on the table. There is no rug on the floor."}, "391214": {"image_id": 391214, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.19264477878804065, "Bleu_3": 1.001008089659607e-06, "Bleu_4": 2.2974843685195705e-09, "METEOR": 0.1941369036068685, "ROUGE_L": 0.2669584245076586, "CIDEr": 6.024649847325288e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13793103448275862, "f": 0.14035087719298248, "fn": 25.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on the ocean. The surfer is riding a surfboard and is wearing a wetsuit. The surfer also has a surfboard under their arm. The wave is white. The sky is gray."}, "482367": {"image_id": 482367, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.15075567228616532, "Bleu_3": 0.07494071883573872, "Bleu_4": 9.439944120577903e-06, "METEOR": 0.1842967468394623, "ROUGE_L": 0.23036253776435048, "CIDEr": 3.96691958936909e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of nine people sitting on chairs in front of a tennis court. They are all wearing tennis shoes and holding tennis rackets. One of the people is holding a tennis ball in his hand. The image is in black and white.\n\nThere are no other objects or people in the scene."}, "402334": {"image_id": 402334, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 9.3195323389309e-07, "Bleu_4": 2.0594083122093235e-09, "METEOR": 0.21037720227398155, "ROUGE_L": 0.20497311827956988, "CIDEr": 2.667857905917634e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a building with a steeple on top. The building appears to be a church. There is a clock on top of the building. The building has a large stained glass window on the front. The sky is blue and there are clouds in the background."}, "469398": {"image_id": 469398, "Bleu_1": 0.22499999999437506, "Bleu_2": 0.18605210187910182, "Bleu_3": 0.13980915359900498, "Bleu_4": 0.09270459775952086, "METEOR": 0.33363826488184156, "ROUGE_L": 0.34078212290502796, "CIDEr": 1.8605635162586835e-05, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16, "f": 0.1568627450980392, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man holding a baby in his arms while looking at a cell phone. The man is looking at a picture of a woman. The baby is lying in a onesie.\n\nThe background is a hospital room."}, "316648": {"image_id": 316648, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 0.11558994996382839, "Bleu_4": 1.4598906514772134e-05, "METEOR": 0.264875556345835, "ROUGE_L": 0.3017312448474856, "CIDEr": 1.2971531967096926e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.7142857142857143, "f": 0.4761904761904762, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a group of five people walking down a street in a city. The people are wearing sunglasses and carrying bags. The street is lined with cars and buses. There are signs on the buildings."}, "254004": {"image_id": 254004, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.16888013236325736, "Bleu_3": 0.12124924590332728, "Bleu_4": 0.08708008839347464, "METEOR": 0.2672277829495527, "ROUGE_L": 0.3216168717047452, "CIDEr": 0.0001794632548388835, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14285714285714285, "f": 0.1568627450980392, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows three people loading luggage onto a truck. The truck is parked on the side of a runway. There are other vehicles in the background.\n\nThe image is in black and white."}, "399369": {"image_id": 399369, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.1630820182599269, "Bleu_3": 8.330762903217117e-07, "Bleu_4": 1.893260841337042e-09, "METEOR": 0.21402887559299089, "ROUGE_L": 0.2675438596491228, "CIDEr": 1.279191403934598e-09, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.22580645161290322, "f": 0.2641509433962264, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a person playing frisbee on a sandy beach. The person is wearing black and white striped pants. They are running towards the camera with their arms outstretched, holding a frisbee in their hand. The sky is blue and there is no camera in the scene."}, "206838": {"image_id": 206838, "Bleu_1": 0.2424242424168963, "Bleu_2": 0.19462473603439093, "Bleu_3": 0.16970636198074643, "Bleu_4": 0.14868720325859808, "METEOR": 0.2738479577816627, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.0006751404566804891, "SPICE": {"All": {"pr": 0.2, "re": 0.11428571428571428, "f": 0.14545454545454545, "fn": 31.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows three women riding horses in the water. The women are wearing bikinis and sunglasses. The horses are brown and white. The image is taken from the perspective of the horses."}, "146672": {"image_id": 146672, "Bleu_1": 0.17499999999781252, "Bleu_2": 0.08152036322346691, "Bleu_3": 0.05543991235453547, "Bleu_4": 0.03856951874733331, "METEOR": 0.1610042533364704, "ROUGE_L": 0.15321500334896182, "CIDEr": 1.4344252775856983e-29, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows four clocks positioned throughout the scene. Each clock has different features, such as a clock face, Roman numerals, and small alarm clocks. The clocks are accompanied by various objects, including silver and gold dollars, glasses of champagne and wine, and a vase with flowers. \n\nA wine glass and a champagne flute are positioned on either side of one of the clocks. The hands of the clocks are pointing to different positions, indicating the time or specific objects."}, "431256": {"image_id": 431256, "Bleu_1": 0.13207547169686723, "Bleu_2": 0.08687444855179041, "Bleu_3": 0.041710967234465525, "Bleu_4": 5.152030073474367e-06, "METEOR": 0.1488396388088827, "ROUGE_L": 0.12217919615435974, "CIDEr": 2.25110787098563e-56, "SPICE": {"All": {"pr": 0.2, "re": 0.11538461538461539, "f": 0.14634146341463417, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows five people on snowboards. One person is doing a snowboard trick and wearing a white helmet. Another person is walking down the street and wearing a green helmet. One person is riding a bike and wearing a black helmet. Another person is riding a train and wearing a black helmet. The last person is also riding a bike and wearing a black helmet.\n\nThere is snow on the ground. The person is jumping over a ramp made of wood. The ramp has a white surface. The person is wearing a black jacket and white pants.\n\nThere is no mountain range in the background."}, "506454": {"image_id": 506454, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.08289171213388852, "Bleu_3": 5.469206357223955e-07, "Bleu_4": 1.4133420106715874e-09, "METEOR": 0.22347877572697905, "ROUGE_L": 0.22317073170731705, "CIDEr": 3.656125445523379e-05, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.32142857142857145, "f": 0.36000000000000004, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a bench made of wood in the middle of a grassy area. The bench is surrounded by three trees. The grass is green and there are no other plants in the image. The sky is blue and there are no clouds."}, "212384": {"image_id": 212384, "Bleu_1": 0.305555555547068, "Bleu_2": 0.2288688541020835, "Bleu_3": 0.1455151315767242, "Bleu_4": 1.7480450956950112e-05, "METEOR": 0.2385077002682506, "ROUGE_L": 0.33888888888888885, "CIDEr": 8.354264280440785e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is a cake with a zebra and a giraffe on it. The cake is brown and black in color. The zebra and giraffe are made of fondant and are brown and black in color."}, "181969": {"image_id": 181969, "Bleu_1": 0.38461538458579886, "Bleu_2": 0.17902871849551308, "Bleu_3": 1.4282938742524094e-06, "Bleu_4": 4.131551590743584e-09, "METEOR": 0.15914232935250605, "ROUGE_L": 0.2985318107667211, "CIDEr": 0.24816830190705597, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2, "f": 0.1951219512195122, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a brown dog sleeping. The dog is wearing a sweater."}, "450889": {"image_id": 450889, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.15939996379066856, "Bleu_3": 0.12197836292293228, "Bleu_4": 0.09974743613527262, "METEOR": 0.25984598437656053, "ROUGE_L": 0.2862356621480709, "CIDEr": 2.551960552827272e-13, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a fireplace. The man is holding a remote control in his hand. He is wearing a blue and white shirt and black pants. The man does not have a beard. \n\nThe fireplace has a television on top of it. There are also books and other objects on the mantel."}, "84073": {"image_id": 84073, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.1189176779999305, "Bleu_3": 6.437822382780047e-07, "Bleu_4": 1.5050585905794507e-09, "METEOR": 0.1655311370650433, "ROUGE_L": 0.20666290231507625, "CIDEr": 8.551204050970909e-13, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.09090909090909091, "f": 0.07692307692307691, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a refrigerator with a handle on the door. The handle is made of wood and has a black knob on it. The refrigerator is white. A beer tap is on the door of the refrigerator. A small hole is on the refrigerator. The refrigerator does not have a window on the top."}, "293207": {"image_id": 293207, "Bleu_1": 0.5151515151359045, "Bleu_2": 0.28371186834087453, "Bleu_3": 0.17317070955163646, "Bleu_4": 0.1147031946085795, "METEOR": 0.19540469689979606, "ROUGE_L": 0.3690260133091349, "CIDEr": 0.05602756005916287, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13636363636363635, "f": 0.16666666666666663, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of four people playing a game of frisbee on a grassy field. They are wearing green shirts and white pants, and one of them is holding a frisbee."}, "431691": {"image_id": 431691, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.1663895814060149, "Bleu_3": 0.08773161697240878, "Bleu_4": 1.139861545684521e-05, "METEOR": 0.19630260083109266, "ROUGE_L": 0.21801286633309508, "CIDEr": 1.2897302223745385e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man and a woman standing outside. The man is holding a donut. He is wearing a grey hoodie. The woman is holding a cell phone. She is wearing a scarf. The man and the woman are eating a donut."}, "218470": {"image_id": 218470, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.1462544848210594, "Bleu_3": 0.08743583640208556, "Bleu_4": 1.2117880855538534e-05, "METEOR": 0.15907486757660416, "ROUGE_L": 0.28549141965678626, "CIDEr": 0.0006364850312406509, "SPICE": {"All": {"pr": 0.1, "re": 0.12, "f": 0.1090909090909091, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a street light on the corner of a street. The street light is mounted on a pole. The canopy is black. There is no ladder, car, or pedestrian in the scene."}, "9050": {"image_id": 9050, "Bleu_1": 0.3913043478090738, "Bleu_2": 0.2982160396695685, "Bleu_3": 1.6178846977139845e-06, "Bleu_4": 3.8146366462203816e-09, "METEOR": 0.22691536954608804, "ROUGE_L": 0.40939597315436244, "CIDEr": 0.09904237444387912, "SPICE": {"All": {"pr": 0.0625, "re": 0.03333333333333333, "f": 0.04347826086956522, "fn": 29.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a table set with a plate of meat and vegetables. The tablecloth and chairs are not visible in the image."}, "390769": {"image_id": 390769, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.2385593618010997, "Bleu_3": 0.16221265425984788, "Bleu_4": 0.10228157247107707, "METEOR": 0.26072861132764147, "ROUGE_L": 0.3028368794326241, "CIDEr": 1.0698115121915099e-06, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.22580645161290322, "f": 0.28, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a woman standing on the sidewalk. She is talking on the phone and looking at her phone. She is wearing a black shirt and jeans. The building behind her has a door.\n\nThere is no awning in the scene."}, "175718": {"image_id": 175718, "Bleu_1": 0.382352941165225, "Bleu_2": 0.28478969316957436, "Bleu_3": 0.13634300208924155, "Bleu_4": 1.690963431814651e-05, "METEOR": 0.29483418016608465, "ROUGE_L": 0.36371379897785344, "CIDEr": 0.0005339174909500162, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.16129032258064516, "f": 0.1818181818181818, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.0625, "f": 0.09090909090909091, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a pizza on a cutting board. A bottle of beer is next to the pizza. The label on the beer bottle reads St. Helena. There are three mugs in the scene."}, "288430": {"image_id": 288430, "Bleu_1": 0.16363636363338846, "Bleu_2": 0.1100963765106158, "Bleu_3": 0.061153792306271486, "Bleu_4": 8.143605172498537e-06, "METEOR": 0.15236671834842921, "ROUGE_L": 0.2127164942461932, "CIDEr": 1.4233134259015715e-13, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of five people standing on the beach. The people are holding a frisbee, a kite, a green ball, and a green hat. A kite is on the beach. The kites are made of plastic and have tails attached to them. The hats are protecting from the dangers of sun exposure."}, "568150": {"image_id": 568150, "Bleu_1": 0.48888888887802473, "Bleu_2": 0.34960294938219333, "Bleu_3": 0.17847219784831794, "Bleu_4": 1.918075095046497e-05, "METEOR": 0.23705248227495104, "ROUGE_L": 0.321390937829294, "CIDEr": 3.875077115224039e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.35, "f": 0.2916666666666667, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.5, "f": 0.2, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a bathroom with a toilet, sink, and shower. The walls are white and the floor is made of tile. There is a window on the left side of the room that lets in natural light. The toilet is located in the bathroom."}, "200109": {"image_id": 200109, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.264906471406127, "Bleu_3": 0.1785260332980217, "Bleu_4": 0.11212450567445467, "METEOR": 0.27927065955815356, "ROUGE_L": 0.3655430711610487, "CIDEr": 0.0001840635006233857, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15, "f": 0.13953488372093023, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a person holding a cell phone with a pizza on it. The person is sitting in a chair. The pizza has cheese and pepperoni on it. A text message is on the person's cell phone."}, "292617": {"image_id": 292617, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.18478728706739583, "Bleu_3": 0.12053222932010677, "Bleu_4": 0.08239132605996681, "METEOR": 0.2986325381373535, "ROUGE_L": 0.3165307635285397, "CIDEr": 1.5030141567135561e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a living room with three couches, a television, and furniture. The room has a couch on the left side. There is a window with closed curtains. The walls are painted white and the floor is made of hardwood."}, "467990": {"image_id": 467990, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1836795895878896, "Bleu_3": 0.09697058721479536, "Bleu_4": 1.2615497851146056e-05, "METEOR": 0.2718860113523348, "ROUGE_L": 0.2683677958644963, "CIDEr": 7.873028757352252e-06, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a train traveling on the tracks. The train is yellow and silver. The train is passing by. The train is waiting for passengers on the platform. The train is traveling in the direction of London Euston."}, "443713": {"image_id": 443713, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.13093073413895012, "Bleu_3": 7.094917059707092e-07, "Bleu_4": 1.660297934705131e-09, "METEOR": 0.23878691537242483, "ROUGE_L": 0.2776332899869961, "CIDEr": 2.1296382610338163e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.35294117647058826, "f": 0.2926829268292683, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of 17 people skateboarding on a street. They are wearing t-shirts. One person is doing a skateboard trick. The others are also skateboarding. Some people are standing behind a fence, while others are watching a skateboard competition. There are also five skateboards in the image."}, "365129": {"image_id": 365129, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.2833670695091401, "Bleu_3": 0.16312067495063523, "Bleu_4": 0.10478669242368933, "METEOR": 0.30445053926412774, "ROUGE_L": 0.3034825870646766, "CIDEr": 5.12127780778999e-05, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a body of water with boats in the foreground and a sunset in the background. The water is calm and there are no waves. The boats are small and white. A mountain is in the background."}, "462904": {"image_id": 462904, "Bleu_1": 0.382352941165225, "Bleu_2": 0.3044529883214349, "Bleu_3": 0.205590915082101, "Bleu_4": 0.1538756906228928, "METEOR": 0.25698470904138776, "ROUGE_L": 0.36003372681281615, "CIDEr": 0.00041370707416496174, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13793103448275862, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a horse standing in front of a fence. The horse is black and is wearing a saddle. \n\nThere are no tables or chairs in the scene, and there is no awning."}, "3466": {"image_id": 3466, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.08301945902134701, "Bleu_3": 0.05004173624553015, "Bleu_4": 6.9406610695910465e-06, "METEOR": 0.16299628277539072, "ROUGE_L": 0.17805020431990656, "CIDEr": 3.767002365757689e-14, "SPICE": {"All": {"pr": 0.07317073170731707, "re": 0.16666666666666666, "f": 0.1016949152542373, "fn": 15.0, "numImages": 1.0, "fp": 38.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image is of two people standing in front of two toilets. The first person is wearing orange boots and the second person is not wearing any boots. The toilets have red tiles and the first toilet has a rusty pipe. The second toilet has a brown ring. There is no sink or faucet in the image."}, "134760": {"image_id": 134760, "Bleu_1": 0.1948051948026649, "Bleu_2": 0.11320835321145165, "Bleu_3": 5.549219378046449e-07, "Bleu_4": 1.232724395456291e-09, "METEOR": 0.17857477202024516, "ROUGE_L": 0.16017505470459517, "CIDEr": 3.773043885659228e-27, "SPICE": {"All": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of seven people skiing down a snowy slope. The people are doing skiing. One person is doing snowboarding. Another person is riding a snowmobile. One person is riding on a bike.\n\nThere are four ski in the image. The people are skiing down a ski slope.\n\nThere is no slope or ski lift in the image. The trees are covered in snow. The sky is cloudy and there is a light snowfall."}, "364705": {"image_id": 364705, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.21213203434730224, "Bleu_3": 0.12507242179545755, "Bleu_4": 1.7268932788606005e-05, "METEOR": 0.1571983057845188, "ROUGE_L": 0.2571127502634352, "CIDEr": 0.013613575612551738, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of four stuffed animals sitting on a blue carpet. They are all wearing pink bows. The animals have white fur."}, "191296": {"image_id": 191296, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.14982983544985165, "Bleu_3": 7.76220525547567e-07, "Bleu_4": 1.7760875805722272e-09, "METEOR": 0.15728063085505825, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.2919648924648929e-11, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.24, "f": 0.24999999999999994, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a pipe lying on the ground in a field. The pipe has a small hole in the side and is in a rusted condition. The field is green. \n\nThere is no tall grass, dirt, debris, or wildflowers in the scene. The hole is located in the middle."}, "457817": {"image_id": 457817, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 0.14979742339481708, "Bleu_4": 0.12039217537167975, "METEOR": 0.255013241659951, "ROUGE_L": 0.27319257837492, "CIDEr": 2.0107602463843823e-11, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.23809523809523808, "f": 0.21276595744680848, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a tennis player playing tennis on a tennis court. The player is wearing a white shirt and green shorts, and holding a red racket. The player is hitting the ball in the back of his leg. The background of the image is a blue and white tennis court."}, "531995": {"image_id": 531995, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.22228757208608238, "Bleu_3": 0.1714752440578388, "Bleu_4": 0.12039217537167975, "METEOR": 0.26439587103176826, "ROUGE_L": 0.3216168717047452, "CIDEr": 2.0055471135105766e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a black and white cat sitting on the floor. The cat is wearing a boot and has a boot in its mouth. A black boot is next to the cat. The cat is enjoying a boot. There are five toys on the floor. The room is dimly lit."}, "276673": {"image_id": 276673, "Bleu_1": 0.3333333333274854, "Bleu_2": 0.20412414522831843, "Bleu_3": 0.09116091793051664, "Bleu_4": 1.0883236761897338e-05, "METEOR": 0.22275626337369597, "ROUGE_L": 0.2627894453419494, "CIDEr": 1.952077430072298e-09, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09523809523809523, "f": 0.08333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a baseball game in progress on a field with a fence surrounding it. There are two players on the field. One player is holding a bat and the other player is catching a baseball. \n\nThere is no ball in the image. The crowd is watching from the stands. The sky is clear and blue."}, "112800": {"image_id": 112800, "Bleu_1": 0.15533980582373455, "Bleu_2": 0.11037895715277549, "Bleu_3": 0.062253016230965214, "Bleu_4": 7.008422879870452e-06, "METEOR": 0.16523660521902023, "ROUGE_L": 0.14729216971369438, "CIDEr": 2.19711309084538e-44, "SPICE": {"All": {"pr": 0.15625, "re": 0.17857142857142858, "f": 0.16666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a small plane flying over the water. The plane is white and green. It has a propeller on the back. The tail of the plane is green and white. \n\nIn the foreground, there is a boat. The boat is red, blue, white and orange. A tug boat is in the foreground. It has a large flag on top. A large oar is on top of the boat. A white and red truck is in the foreground. The boat is white and orange. A scuba tank is on top of the boat.\n\nThere are no trees or islands in the scene."}, "390685": {"image_id": 390685, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.07883330048480665, "Bleu_3": 4.749674066907792e-07, "Bleu_4": 1.170925172060759e-09, "METEOR": 0.21897926450356137, "ROUGE_L": 0.21857084357084358, "CIDEr": 5.284854960179638e-15, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2727272727272727, "f": 0.24489795918367346, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two stop signs on the side of the road. The stop signs are red and white. One of the stop signs has the words \"stop\" written on it, while the other has \"stop\" and \"go\" written on it. \n\nThere is no road, car, or person in the image. The background features a blue sky and distant trees."}, "195002": {"image_id": 195002, "Bleu_1": 0.15999999999786668, "Bleu_2": 0.10397504898061158, "Bleu_3": 0.06665843824471619, "Bleu_4": 8.008629943499997e-06, "METEOR": 0.2295280533486033, "ROUGE_L": 0.21834451901566, "CIDEr": 9.866607649047998e-26, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.13793103448275862, "f": 0.18181818181818182, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a young girl sitting at a table. There is a plate of doughnuts in front of the girl. She is wearing a princess dress and has a crown on her head. \n\nThere are no other people in the scene. \n\nThe walls of the room are painted with a mural of the princesses. \n\nThere is no camera in the scene. \n\nThere is no design on the walls. \n\nA donut is on the table."}, "104626": {"image_id": 104626, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.24019223070154896, "Bleu_3": 0.11493300756926315, "Bleu_4": 1.4232564071963268e-05, "METEOR": 0.2540917075359139, "ROUGE_L": 0.2764350453172206, "CIDEr": 1.634868649243203e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.1724137931034483, "f": 0.1851851851851852, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a blue truck parked on the side of a road. The truck has a canvas top and is parked next to a tent. There is no person in the scene. There is no park in the scene."}, "291370": {"image_id": 291370, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.0961565816414218, "Bleu_3": 6.356506717327843e-07, "Bleu_4": 1.6458750873229306e-09, "METEOR": 0.14711500788775694, "ROUGE_L": 0.27191679049034173, "CIDEr": 2.2932631447222428e-05, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2222222222222222, "f": 0.22857142857142856, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of nine people standing in front of two buildings. Some of the people are wearing hats and holding flowers. A black horse is in the background. The building appears to be a restaurant."}, "434804": {"image_id": 434804, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.08902660440381881, "Bleu_4": 1.1128852820974656e-05, "METEOR": 0.20638421560275058, "ROUGE_L": 0.236281471917366, "CIDEr": 1.023443742980612e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21428571428571427, "f": 0.1875, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of four giraffes standing in a fenced enclosure. The giraffes are wearing a metal fence. They appear to be healthy. \n\nThere is a building in the background. The building has a roof and windows. \n\nThe overall scene shows giraffes standing in a fenced enclosure."}, "143": {"image_id": 143, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2993592018235193, "Bleu_3": 0.19546454494909793, "Bleu_4": 0.12086038782189067, "METEOR": 0.2641333140087545, "ROUGE_L": 0.30421772584781986, "CIDEr": 2.1777296961640816e-05, "SPICE": {"All": {"pr": 0.15625, "re": 0.23809523809523808, "f": 0.18867924528301888, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of seven birds perched on a tree branch. The birds are sitting on the branch, facing the same direction and looking at something in the distance. They have a brown and white plumage."}, "249219": {"image_id": 249219, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.2721655269656347, "Bleu_3": 0.18096117443269358, "Bleu_4": 0.12535343643128788, "METEOR": 0.264875556345835, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.010965400553768725, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15789473684210525, "f": 0.15789473684210525, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a purple and white bus driving down a street lined with houses. The destination sign on the front of the bus reads \"sbs transit\"."}, "19716": {"image_id": 19716, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.1906925178456823, "Bleu_3": 0.12641490045451217, "Bleu_4": 0.07857415746443172, "METEOR": 0.3134885925607597, "ROUGE_L": 0.3396436525612472, "CIDEr": 2.282240814361958e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man wearing a black suit and tie. He is standing in front of a large window. The building behind him is an office complex, which appears to be a shopping mall. The ceiling of the building is like a glass roof. The man is posing for a picture. He has slicked hair."}, "517973": {"image_id": 517973, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.2162249910430379, "Bleu_3": 0.17319011026093825, "Bleu_4": 0.14071433641463527, "METEOR": 0.27390997305411796, "ROUGE_L": 0.36467391304347824, "CIDEr": 6.193997202394388e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2608695652173913, "f": 0.2727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a white Volkswagen Beetle parked in a parking lot. There are no other cars nearby the Volkswagen Beetle. The car has a surfboard on top of it. The sky is clear and blue. There are no trees in the scene.\n\nThe image is taken from a low angle, looking up at the car."}, "23019": {"image_id": 23019, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.07293249574741174, "Bleu_3": 4.871859700370513e-07, "Bleu_4": 1.2660998324356512e-09, "METEOR": 0.2074521289342637, "ROUGE_L": 0.1601049868766404, "CIDEr": 7.232160274175859e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.20689655172413793, "f": 0.21818181818181817, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a city skyline at night with nine buildings made of glass. The image is taken from a high angle, looking down at the city. There are cars and buildings on the street, and many lights can be seen. \n\nThere is one pedestrian on the street."}, "177213": {"image_id": 177213, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.18392019594445258, "Bleu_3": 9.304003187271436e-07, "Bleu_4": 2.1052633193896277e-09, "METEOR": 0.24180907808566118, "ROUGE_L": 0.2809210526315789, "CIDEr": 4.971258124307102e-06, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.13333333333333333, "f": 0.14285714285714288, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a plate of pizza with cheese and basil on top. The pizza is on the table. There are two glasses of beer on the table. The color of the beer is yellow. The background is a white wall with no window."}, "514773": {"image_id": 514773, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.20291986247433838, "Bleu_3": 9.436646347757244e-07, "Bleu_4": 2.0455163268987793e-09, "METEOR": 0.1985490013826504, "ROUGE_L": 0.21903052064631956, "CIDEr": 2.0989874456582165e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.75, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image is of a room with a desk, two chairs, and a computer in it. There is a leopard print blanket in the room. The walls are blue. There are no windows on the left side of the room. There are no windows on the right side of the room."}, "259253": {"image_id": 259253, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.20304239863369572, "Bleu_3": 0.12521356825154964, "Bleu_4": 1.4792534123479756e-05, "METEOR": 0.20541136705727908, "ROUGE_L": 0.3228733459357278, "CIDEr": 4.841989179952998e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of eight sheep standing in a field. The sheep are white and black, white, gray, white, white, white and black, white, and white respectively.\n\nThere is a tree in the background. The tree is green.\n\nThe sky is blue."}, "85340": {"image_id": 85340, "Bleu_1": 0.26984126983698664, "Bleu_2": 0.17454497936008803, "Bleu_3": 0.12594520169547688, "Bleu_4": 0.09033497027796634, "METEOR": 0.23551438849829467, "ROUGE_L": 0.24314897857498752, "CIDEr": 2.1638007344484304e-14, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows four people sitting at a table in a restaurant. They are posing for a picture. One of the people is holding a hot dog. Another person is holding a cup. The background of the image includes a bar and other tables.\n\nThe image is in color and the lighting is good. The people in the image are wearing casual clothes."}, "94025": {"image_id": 94025, "Bleu_1": 0.1249999999980469, "Bleu_2": 0.07715167497983091, "Bleu_3": 0.04578954656590653, "Bleu_4": 6.298574903813265e-06, "METEOR": 0.15351195584901195, "ROUGE_L": 0.15561224489795916, "CIDEr": 3.849303587957631e-18, "SPICE": {"All": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a stop sign on the side of a dirt road. The sign is rusted and has a few scratches on it. There is a wooden fence on the side of the road. There are no other signs or trees in the scene. In the distance, there is a mountain range. The sky is clear and there are no clouds in sight."}, "21746": {"image_id": 21746, "Bleu_1": 0.255813953482423, "Bleu_2": 0.11037036210960939, "Bleu_3": 6.672783373035958e-07, "Bleu_4": 1.6508791085804972e-09, "METEOR": 0.2618041232540356, "ROUGE_L": 0.25505226480836235, "CIDEr": 1.83984218741593e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.25, "f": 0.24489795918367346, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white shirt and shorts, and has a racket in her hand.\n\nThere is no concrete or net in the scene.\n\nThere is no game or sidelines in the scene."}, "338291": {"image_id": 338291, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.12399138853119372, "Bleu_3": 6.66182522208817e-07, "Bleu_4": 1.5516807838487133e-09, "METEOR": 0.19360972584123837, "ROUGE_L": 0.1821983273596177, "CIDEr": 6.559885968289085e-13, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man standing in front of a building with a snowboard on his back. He is wearing a blue jacket and blue pants. Some of the people in the background are wearing a black jacket and holding a red hat. The building is not a ski resort. The building is snow-covered."}, "10142": {"image_id": 10142, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.11447636746877136, "Bleu_3": 7.587583354772992e-07, "Bleu_4": 1.970053892727639e-09, "METEOR": 0.19988257075200305, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.0009441217026060698, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2, "f": 0.1923076923076923, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man wearing a blue jacket and black pants standing on a snowy trail with skis on his feet. He is holding ski poles and appears to be skiing."}, "327433": {"image_id": 327433, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.11207313002177546, "Bleu_3": 6.584408628047618e-07, "Bleu_4": 1.6051679053027854e-09, "METEOR": 0.20396721562475717, "ROUGE_L": 0.2019867549668874, "CIDEr": 5.726213523059185e-09, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.10526315789473684, "f": 0.0975609756097561, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows two zebras grazing in the grass in the foreground. A giraffe is standing in the background. The sky is clear and blue, with a few clouds scattered across it. The landscape is flat and open, with no trees or other vegetation in sight."}, "177935": {"image_id": 177935, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.07450111597138893, "Bleu_3": 4.977802722253634e-07, "Bleu_4": 1.2939428392854094e-09, "METEOR": 0.1715242881072027, "ROUGE_L": 0.20847573479152426, "CIDEr": 1.4596489759637387e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.09090909090909091, "f": 0.11538461538461539, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a kitchen with white appliances. There is a stove, an oven, and a refrigerator. The walls are painted yellow. There are wooden cabinets and granite countertops. The floor is made of hardwood.\n\nThe image is well lit and shows a clean and organized kitchen."}, "100354": {"image_id": 100354, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.12778110819056318, "Bleu_3": 6.841022856919291e-07, "Bleu_4": 1.5907366237766522e-09, "METEOR": 0.1828740802208622, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.3995555457036384e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows three goats and a baby. The mother goat is standing on dirt and has a long coat. The baby goat is also standing on dirt and has a short coat. The mother goat is nursing her baby. The relationship between the mother goat and the baby is mother and child."}, "377326": {"image_id": 377326, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.28171808489925787, "Bleu_3": 0.2092148242246677, "Bleu_4": 0.1383436845588797, "METEOR": 0.23462357719196542, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.008060175138560262, "SPICE": {"All": {"pr": 0.24, "re": 0.24, "f": 0.24, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows three cows standing next to a pond. The cows are brown and white. They have stub tails. The cows are drinking water from the pond."}, "300471": {"image_id": 300471, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.14254579382569355, "Bleu_3": 0.07358334830308164, "Bleu_4": 9.448049464513672e-06, "METEOR": 0.18414492281287517, "ROUGE_L": 0.2334609075997813, "CIDEr": 4.1641729051760055e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.29411764705882354, "f": 0.3125, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two cats sitting on blue chairs in front of a blue building. The cats are wearing blue collars. One of the cats has a blue ribbon tied around its neck.\n\nThe building has a blue door and windows with blue shutters. There are blue tables and chairs outside the building."}, "512729": {"image_id": 512729, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.1921765286905374, "Bleu_3": 0.1060098772537733, "Bleu_4": 1.4116578094797889e-05, "METEOR": 0.21882770870337476, "ROUGE_L": 0.30886075949367087, "CIDEr": 0.0017312324524029568, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.23529411764705882, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a bowl of broccoli. A piece of broccoli is on top of the bowl. Broccoli and sauce is in the bowl. The dish is served with a side of rice."}, "14151": {"image_id": 14151, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.22190634114281918, "Bleu_3": 0.11667896745206957, "Bleu_4": 1.5169250360908672e-05, "METEOR": 0.16137564835383372, "ROUGE_L": 0.33177933177933183, "CIDEr": 0.0008988666334560818, "SPICE": {"All": {"pr": 0.25, "re": 0.3157894736842105, "f": 0.27906976744186046, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person jumping off a snowboard on a white slope. The person is wearing a red suit and a helmet. In the background, there are two trees in the distance."}, "323726": {"image_id": 323726, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1360198059227937, "Bleu_3": 0.07435849582310866, "Bleu_4": 9.831839444823975e-06, "METEOR": 0.1658220072515439, "ROUGE_L": 0.1941438574156588, "CIDEr": 6.854270494872513e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a baseball player swinging a bat at a ball. The player is wearing an orange jersey with the number ten on the back. The player is swinging at a baseball. The player is running towards first base. The crowd is cheering in the background."}, "270351": {"image_id": 270351, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.10540925533701173, "Bleu_3": 5.940557542491763e-07, "Bleu_4": 1.416999083410831e-09, "METEOR": 0.19299188196958256, "ROUGE_L": 0.21095100864553315, "CIDEr": 1.799111513248914e-13, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.11428571428571428, "f": 0.12903225806451613, "fn": 31.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows three pigeons perched on a ledge of a building. The building is painted a light pink color. There is a window on the side of the building. The pigeons are all facing the same direction and appear to be looking at something in the distance. There is no birdhouse in the scene."}, "290113": {"image_id": 290113, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.10540925533701173, "Bleu_3": 0.07484633495897125, "Bleu_4": 9.476043991914697e-06, "METEOR": 0.15695938341333918, "ROUGE_L": 0.13871517907902217, "CIDEr": 1.2355364398001295e-12, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.25, "f": 0.2033898305084746, "fn": 18.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows two people doing snowboarding and skiing on a snowy slope. The people are wearing ski gear and holding ski poles. One person is doing snowboarding and the other is doing skiing. The skiers are using skis.\n\nThere are no trees in the scene.\n\nThe snow is deep and the sky is cloudy."}, "535312": {"image_id": 535312, "Bleu_1": 0.48648648647333825, "Bleu_2": 0.28474739871794696, "Bleu_3": 0.16670955566718626, "Bleu_4": 1.9213241481614443e-05, "METEOR": 0.19102442531422398, "ROUGE_L": 0.3174721189591078, "CIDEr": 0.05811306861256453, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a collage of images showing a living room, kitchen, and bedroom. In the living room, there is a couch, a TV, a table, and four chairs. \n\nThere is no kitchen or bedroom in the image."}, "478282": {"image_id": 478282, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.18802535826836297, "Bleu_3": 9.368170754206349e-07, "Bleu_4": 2.103433449500824e-09, "METEOR": 0.1458423867122573, "ROUGE_L": 0.3134232498394348, "CIDEr": 8.328733118146971e-07, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.3076923076923077, "f": 0.2807017543859649, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a vase with flowers on top of a mantle. The mantle is made of wood. There is a decorative design on the mantle. The flowers are inside the vase. The vase is made of glass and has a decorative design on it."}, "64796": {"image_id": 64796, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.19658927486887504, "Bleu_3": 0.12066064806249903, "Bleu_4": 0.07994791209466426, "METEOR": 0.19047660357996682, "ROUGE_L": 0.24238410596026488, "CIDEr": 8.470833567236304e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.17647058823529413, "f": 0.15, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a plant with red flowers on a stand. The plant is sitting on a stool. It is a red roses plant. The leaves are green. The stand is made of marble. The background is a white wall with a window in the distance."}, "525297": {"image_id": 525297, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.38674623406228154, "Bleu_3": 0.22872522208884816, "Bleu_4": 0.14942825781451607, "METEOR": 0.25328175720031015, "ROUGE_L": 0.43884892086330934, "CIDEr": 0.06136334374317564, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.06818181818181818, "f": 0.09836065573770492, "fn": 41.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.16666666666666666, "f": 0.23076923076923078, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person holding a smartphone with a video of cows on the screen. The person is wearing a white shirt. The background is white."}, "158414": {"image_id": 158414, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2908872369299581, "Bleu_3": 0.1521993147229894, "Bleu_4": 1.9786891108517274e-05, "METEOR": 0.20462577608020818, "ROUGE_L": 0.38193202146690514, "CIDEr": 0.037412005667173884, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10714285714285714, "f": 0.1276595744680851, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a bus with a sign that reads \"welcome aboard.\" The bus is parked in front of a building. The bus is delivering medicine."}, "170346": {"image_id": 170346, "Bleu_1": 0.4117647058581315, "Bleu_2": 0.27785946509625026, "Bleu_3": 1.7265786931171227e-06, "Bleu_4": 4.378826865576807e-09, "METEOR": 0.1463451453917498, "ROUGE_L": 0.3257676902536716, "CIDEr": 0.13870879586369408, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.12, "f": 0.16666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows three sheep standing on a rocky hillside. The sheep are white with white horns."}, "328315": {"image_id": 328315, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.15450054281980155, "Bleu_3": 0.10224344881149082, "Bleu_4": 0.07543938388216609, "METEOR": 0.20939240351831706, "ROUGE_L": 0.25452016689847007, "CIDEr": 7.238221415093239e-20, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.10714285714285714, "f": 0.16216216216216214, "fn": 25.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.25, "f": 0.375, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a desk with a computer, a printer, and other office supplies on it. There is a lamp on the desk. Behind the lamp, there is a blue light. Behind the second lamp, there is a clock. Behind the third lamp, there is a computer monitor. There is a bookshelf behind the desk. Behind the bookshelf, there is a computer monitor. The walls are brown in color."}, "113246": {"image_id": 113246, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.21144903759104486, "Bleu_3": 0.14639700334655723, "Bleu_4": 0.08651713582465577, "METEOR": 0.21791963566388456, "ROUGE_L": 0.23043712898003238, "CIDEr": 1.4228217870574935e-14, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16, "f": 0.16326530612244897, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows three people sitting on two couches in a living room. The people are wearing casual clothing. Some of them are looking at a television, while others are playing a video game using a wii controller. The room is well lit, with no windows in the background.\n\nThere is no laptop or coffee table in the scene."}, "1290": {"image_id": 1290, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.12541522083027962, "Bleu_3": 6.548937148826446e-07, "Bleu_4": 1.5032715711819957e-09, "METEOR": 0.21245818963457702, "ROUGE_L": 0.20631341600901915, "CIDEr": 2.1223452260437487e-14, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.3684210526315789, "f": 0.3684210526315789, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows two women in the kitchen. One woman is holding a cake with candles on it. She is wearing a red dress. The other woman is holding a baby. She is also wearing a red dress. The baby is sitting in a high chair and wearing a onesie. The baby has a finger in its mouth."}, "292365": {"image_id": 292365, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.22631728213415836, "Bleu_3": 0.15794190135774153, "Bleu_4": 0.10090835403909652, "METEOR": 0.2223867291929269, "ROUGE_L": 0.26703633445206476, "CIDEr": 9.406009561097558e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.06666666666666667, "f": 0.10256410256410256, "fn": 28.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on a toilet seat, looking up. The cat is wearing a collar and its fur is striped. The cat is looking at the toilet. In the background, there is a white toilet in the bathroom."}, "246746": {"image_id": 246746, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1940285000252239, "Bleu_3": 0.16642889932012636, "Bleu_4": 0.13999942250312572, "METEOR": 0.2917892738425711, "ROUGE_L": 0.3433395872420263, "CIDEr": 2.4189420118419012e-11, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.21052631578947367, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a woman riding a brown horse in a grassy field. The woman is wearing a white shirt and boots. The horse is wearing a saddle and bridle. The background is a blue sky with white clouds.\n\nThe image is of a woman riding a horse in a field."}, "328464": {"image_id": 328464, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.1384332440755414, "Bleu_3": 0.07824806388361051, "Bleu_4": 1.0527834487325538e-05, "METEOR": 0.10014585077890367, "ROUGE_L": 0.19626769626769625, "CIDEr": 9.894620324259853e-07, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15789473684210525, "f": 0.13043478260869565, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a sailboat on a frozen lake. The sailboat is white. The lake is covered in snow. There are trees in the background. The sky is cloudy and there is a sun in the top right corner of the image."}, "420852": {"image_id": 420852, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.16351748503705, "Bleu_3": 0.09418739954830285, "Bleu_4": 1.2813098990443002e-05, "METEOR": 0.1573574921405782, "ROUGE_L": 0.18512898330804248, "CIDEr": 0.0003216227807072862, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.18518518518518517, "f": 0.1639344262295082, "fn": 22.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a building with a power line and a telephone pole in the background. The sky is blue. There are no clouds in the sky. There is no street in the image."}, "97646": {"image_id": 97646, "Bleu_1": 0.20731707316820344, "Bleu_2": 0.12392263810334311, "Bleu_3": 0.0576860016211417, "Bleu_4": 7.020952834770627e-06, "METEOR": 0.19546584635184674, "ROUGE_L": 0.1798652064026959, "CIDEr": 1.5391552754422207e-32, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.07692307692307693, "f": 0.10810810810810811, "fn": 24.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows two men in a forest. One man is walking with a skateboard on a path. The other man is riding a bike on a trail. The men are walking over a bridge made of wood. The bridge does not have a railing on either side. The man's pants are blue. The man is carrying a backpack.\n\nThere is no stream in the scene. There are no wooden planks in the scene. There are no railings in the scene."}, "545796": {"image_id": 545796, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.16866980207552001, "Bleu_3": 0.1164842984773604, "Bleu_4": 0.08197539731849457, "METEOR": 0.22552701092168295, "ROUGE_L": 0.24636510500807754, "CIDEr": 3.3190184099832097e-06, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.058823529411764705, "f": 0.04651162790697675, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a child brushing his teeth. The child is wearing a white onesie. The child does not have a bow in her hair. The background consists of a white wall with a window in the background."}, "332407": {"image_id": 332407, "Bleu_1": 0.2424242424168963, "Bleu_2": 0.08703882797517024, "Bleu_3": 6.252035830567377e-07, "Bleu_4": 1.6894127988830863e-09, "METEOR": 0.14356405799619498, "ROUGE_L": 0.19411296738265713, "CIDEr": 0.0013685498700061111, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of three people playing baseball on a field. The people are wearing a baseball uniform. The adults are holding baseball bats and the children are holding baseball gloves."}, "204448": {"image_id": 204448, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.1405803892726323, "Bleu_3": 9.799638670146946e-07, "Bleu_4": 2.619087743276261e-09, "METEOR": 0.16972108412096465, "ROUGE_L": 0.2423038728897716, "CIDEr": 0.057270370592216305, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image does not contain a stove. There is a refrigerator and a sink in the kitchen. The floor is made of tile."}, "480842": {"image_id": 480842, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.06567895774161787, "Bleu_3": 4.448553400606041e-07, "Bleu_4": 1.163734197858576e-09, "METEOR": 0.13922179112856892, "ROUGE_L": 0.15259537210756724, "CIDEr": 4.460811914407952e-12, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows four giraffes standing in a field of tall grass. The giraffes are looking at the camera, with their long necks stretched out in front of them. Their fur is brown and white, and they have brown and white spots. The background is a green field with tall grass."}, "224155": {"image_id": 224155, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.24343224777560685, "Bleu_3": 0.14969266991794247, "Bleu_4": 1.5936742847175135e-05, "METEOR": 0.3123464352149447, "ROUGE_L": 0.35158501440922196, "CIDEr": 8.119339330542055e-13, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.043478260869565216, "f": 0.04761904761904762, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man wearing a green shirt and having a beard. He is holding a cell phone and taking a selfie. The background features a sink with a green towel in front of it.\n\nThere is no toilet or shower in the scene. The man is standing in front of the bathroom mirror."}, "303647": {"image_id": 303647, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.22447181760045806, "Bleu_3": 0.13495529486165445, "Bleu_4": 0.08853753948319075, "METEOR": 0.235488350477097, "ROUGE_L": 0.3642999336429994, "CIDEr": 1.5822821008295753e-06, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.35714285714285715, "f": 0.24390243902439024, "fn": 9.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a pizza on a pan. The pizza has mushrooms and basil on it. There is a pizza pan on the counter. There is a pot of water next to the pizza pan. The kitchen has a stove and an oven."}, "448868": {"image_id": 448868, "Bleu_1": 0.1126760563364412, "Bleu_2": 0.04012054271368288, "Bleu_3": 2.857337247009912e-07, "Bleu_4": 7.65321472971464e-10, "METEOR": 0.1151113720785749, "ROUGE_L": 0.13990825688073394, "CIDEr": 1.552317529844115e-22, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11538461538461539, "f": 0.11320754716981132, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows five trucks parked on the side of the road. A trailer is attached to one of the trucks, and a tank is attached to another. A hose is attached to one of the trucks, and a large tank is attached to another.\n\nThere are three buildings in the background, including a tall building and a large building.\n\nThe sky is cloudy and there is snow on the ground."}, "360705": {"image_id": 360705, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.15839698776796265, "Bleu_3": 0.07436832510266554, "Bleu_4": 9.099199516464643e-06, "METEOR": 0.17650788528165245, "ROUGE_L": 0.16061084781463927, "CIDEr": 6.954685595849668e-17, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.03571428571428571, "f": 0.05405405405405406, "fn": 27.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a green field with a cow laying down in the grass. In the background, there is a row of trees with leaves turning red in the fall. The sky is blue with a few clouds.\n\nThe image is taken from a bird's eye view, looking down on the field and trees. There are not many clouds in the sky."}, "122678": {"image_id": 122678, "Bleu_1": 0.3393321990846875, "Bleu_2": 0.21816008132871334, "Bleu_3": 0.1511436058305072, "Bleu_4": 0.11467908044619834, "METEOR": 0.3276028768620102, "ROUGE_L": 0.37621145374449333, "CIDEr": 0.0046066554285278, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.20689655172413793, "f": 0.2142857142857143, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a woman in a white uniform standing in front of a wall. She is holding a pen and looking at a map. The woman has a serious expression."}, "253843": {"image_id": 253843, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.1397957424660571, "Bleu_4": 0.10224344084785833, "METEOR": 0.2920113808389717, "ROUGE_L": 0.2507339988256019, "CIDEr": 7.622657957369066e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a man and a woman standing in a dirt field. The man is wearing a black and white striped shirt and the woman is wearing a white shirt. In the background, there is a horse which is brown and white. The horse does not have a saddle on its back."}, "301421": {"image_id": 301421, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.0953462589231035, "Bleu_3": 0.052176600559777984, "Bleu_4": 6.890832571132198e-06, "METEOR": 0.19295576888926122, "ROUGE_L": 0.21631205673758866, "CIDEr": 4.577527595906418e-20, "SPICE": {"All": {"pr": 0.4, "re": 0.5263157894736842, "f": 0.45454545454545453, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6428571428571429, "re": 0.9, "f": 0.75, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 9.0}}, "caption": "The image shows a desk with a black and silver computer, speakers, and a lamp on it. The desk is made of glass. The computer is a black laptop with a mouse and a keyboard on either side. The speakers are black and silver, and there are various items on them, including a cat, a small speaker, a laptop, a remote control, and a blue light."}, "248965": {"image_id": 248965, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.18971331171167066, "Bleu_3": 0.12063701515683257, "Bleu_4": 0.08139457119702034, "METEOR": 0.2584367139385691, "ROUGE_L": 0.23720025923525598, "CIDEr": 1.1815224367745592e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person standing on a sandy beach and holding a kite. The kite is made of colorful fabric and has a long tail. The person is wearing a pink shirt and black pants. In the background, there are no trees."}, "274134": {"image_id": 274134, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.15887222732309736, "Bleu_3": 7.371996827596484e-07, "Bleu_4": 1.5943766755738508e-09, "METEOR": 0.21312140515385414, "ROUGE_L": 0.2266604737575476, "CIDEr": 1.4849278701096216e-16, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a room with a wooden table and a chair in the center. There is a bookshelf on the wall with books on it. The room has a window with a view of a garden.\n\nOn the table, there is a book. The room is dimly lit with two lamps, one of which is a small lamp. \n\nThe bookshelf is made of wood."}, "527193": {"image_id": 527193, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.12592155012443357, "Bleu_3": 7.22742528474703e-07, "Bleu_4": 1.7419743018621623e-09, "METEOR": 0.14326470151047482, "ROUGE_L": 0.19677419354838707, "CIDEr": 4.199088379365696e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of three elephants playing with each other in a field. One of the elephants is holding a tire, while the others are playing with the tire. The elephants are standing in a line, with the fence in the background."}, "277383": {"image_id": 277383, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.07808688094237472, "Bleu_3": 5.387209294115685e-07, "Bleu_4": 1.4242196946570861e-09, "METEOR": 0.14901116756128524, "ROUGE_L": 0.18583396801218582, "CIDEr": 3.503790262528068e-05, "SPICE": {"All": {"pr": 0.15, "re": 0.11538461538461539, "f": 0.13043478260869565, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of four people playing frisbee on a grass field. The players are wearing red and white jerseys, and black shorts. The spectators are watching the game.\n\nThe image is taken from a bird's-eye view."}, "417015": {"image_id": 417015, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.059110575176554124, "Bleu_3": 4.065453602348427e-07, "Bleu_4": 1.0713693373996204e-09, "METEOR": 0.1797752808988764, "ROUGE_L": 0.17468499427262313, "CIDEr": 1.295926746053905e-11, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two pink flowers sitting on two tables. The flowers are pink. One flower is sitting on a vase, and the other flower is sitting on a small vase. The flowers are sitting on top of the vases. \n\nThere is no mirror in the scene.\n\nThere are no books in the scene."}, "349525": {"image_id": 349525, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2065984676302324, "Bleu_3": 0.10305360646835118, "Bleu_4": 1.3027212489554092e-05, "METEOR": 0.22794369224948766, "ROUGE_L": 0.31423052157115255, "CIDEr": 1.9060787238022062e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a kitchen with an oven and a woman sitting on a chair at a table. The woman is playing a game. The room does not have a stove or a refrigerator. There is no man in the scene."}, "567254": {"image_id": 567254, "Bleu_1": 0.19540229884832871, "Bleu_2": 0.1167592331430088, "Bleu_3": 5.43318526321958e-07, "Bleu_4": 1.1754957520351712e-09, "METEOR": 0.14560576819556115, "ROUGE_L": 0.16561942440462338, "CIDEr": 1.114602037696989e-30, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.16129032258064516, "f": 0.1694915254237288, "fn": 26.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows two girls sitting on the floor. One of the girls is brushing her hair and looking at a toothbrush. The other girl is also brushing her hair, but she is looking at a television. Both girls have a curious expression on their faces. \n\nThe girls have long, curly blonde hair. One of the girls is wearing a white t-shirt. There are no shorts in the scene. \n\nThere is no television in the scene. \n\nThe room is decorated with a blue and white striped pattern."}, "19783": {"image_id": 19783, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.07347183583515587, "Bleu_3": 5.26437340454787e-07, "Bleu_4": 1.4188431559098949e-09, "METEOR": 0.16249821495271252, "ROUGE_L": 0.1931908155186065, "CIDEr": 1.1168211055699612e-05, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3157894736842105, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man standing near the water. The man is throwing a frisbee and looking at a kite. He is wearing a white shirt and has a frisbee in his hand. \n\nThere are three seagulls flying overhead."}, "562292": {"image_id": 562292, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.10241831129827411, "Bleu_3": 5.47257534072173e-07, "Bleu_4": 1.270014485739853e-09, "METEOR": 0.13755640372012976, "ROUGE_L": 0.1490713587487781, "CIDEr": 2.7331313428234633e-20, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.13333333333333333, "f": 0.14285714285714288, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two women sitting on two benches in a park. One woman is wearing black and white striped leggings, and the other woman is wearing black leggings. The woman with the black and white striped leggings is wearing a white top. The woman with the black leggings is wearing a blue sweater. Both women are carrying handbags, and one of the handbags is black."}, "538819": {"image_id": 538819, "Bleu_1": 0.18181818181542703, "Bleu_2": 0.052888588533987035, "Bleu_3": 3.522475598614246e-07, "Bleu_4": 9.126428539580221e-10, "METEOR": 0.10699292890191912, "ROUGE_L": 0.15737874097007223, "CIDEr": 6.047230771733005e-21, "SPICE": {"All": {"pr": 0.25, "re": 0.23529411764705882, "f": 0.24242424242424243, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a plate with two slices of bread. One slice of bread is topped with meth, peppers, onions, and cheese, while the other slice of bread is topped with sausage, peppers, and cheese. The bread is not toasted, but the other slice is toasted. The toppings include cheese, pepperoni, and tomato slices. The pepperoni is like a red meat that's sliced and fried."}, "521259": {"image_id": 521259, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.14819171472405493, "Bleu_3": 0.07652745233046604, "Bleu_4": 9.829979956142771e-06, "METEOR": 0.16150812291428113, "ROUGE_L": 0.19074421513445905, "CIDEr": 8.337302738164889e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of children playing with a skateboard. The children are wearing a white shirt. The children are kicking a soccer ball. They are playing on a field in front of a school building. There is no soccer jersey, cleat, ball, foot, grass, or tree in the image."}, "470779": {"image_id": 470779, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.15017092450871714, "Bleu_4": 0.10788334129141647, "METEOR": 0.21520192428097862, "ROUGE_L": 0.3249482095294466, "CIDEr": 3.797834963731173e-10, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.11764705882352941, "f": 0.14035087719298242, "fn": 30.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.2857142857142857, "f": 0.32, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of five people posing for a picture on a snowy slope. They are all wearing ski gear and holding their skis. The woman in the center is wearing a black jacket and black pants, while the man on the left is wearing a blue jacket and black pants."}, "92053": {"image_id": 92053, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.11455372707190037, "Bleu_4": 0.07602453795872412, "METEOR": 0.24862538081301258, "ROUGE_L": 0.3057644110275689, "CIDEr": 3.5227011419153205e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a table with three plates of food on it. The plates have different types of food on them, including sausages, burgers, and sandwiches. There are also two beers on the table. The table is in a dimly lit room. A fireplace is in the background."}, "361687": {"image_id": 361687, "Bleu_1": 0.11290322580463061, "Bleu_2": 0.06084196831372127, "Bleu_3": 3.951406897304247e-07, "Bleu_4": 1.0112320187709208e-09, "METEOR": 0.12830522472472386, "ROUGE_L": 0.15388496468213927, "CIDEr": 3.114634768671756e-17, "SPICE": {"All": {"pr": 0.125, "re": 0.18181818181818182, "f": 0.14814814814814814, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows three babies lying on two beds in a nursery. The babies are sleeping. One baby is wearing a zebra print blanket, another baby is wearing a zebra print sock, and the third baby is wearing a zebra print hat. The babies have their hands clasped together. The background is a white wall.\n\nThere is no window in the scene."}, "386879": {"image_id": 386879, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2608202654732723, "Bleu_3": 0.16314309133869306, "Bleu_4": 0.09856825261135735, "METEOR": 0.2401691038101078, "ROUGE_L": 0.3010487353485503, "CIDEr": 1.3907960527311146e-09, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.2, "f": 0.1639344262295082, "fn": 20.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5555555555555556, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a woman in a red tennis dress holding a tennis racket. She is standing in a grassy area with a tree in the background. The woman is playing tennis and appears to be enjoying the game. The image is in focus and the colors are vibrant."}, "461855": {"image_id": 461855, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.16256402218685123, "Bleu_3": 0.10796339325484196, "Bleu_4": 1.3236142380428904e-05, "METEOR": 0.1590636276616265, "ROUGE_L": 0.20890410958904113, "CIDEr": 1.4827631650091157e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.15151515151515152, "f": 0.18518518518518517, "fn": 28.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a girl sitting on a couch. She is wearing a white dress and has a stuffed animal in her lap. The background is dark and the lighting is dim.\n\nThe image is in black and white and has a vintage look."}, "315610": {"image_id": 315610, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.19795764159279172, "Bleu_3": 0.15662032595896783, "Bleu_4": 0.11133996756281149, "METEOR": 0.31018709240512143, "ROUGE_L": 0.3124644280022766, "CIDEr": 2.851236149653505e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a ferris wheel with planes flying in the sky. The ferris wheel has a large wheel with seats inside and a large wheel with seats outside. The planes are flying in the sky above the ferris wheel. The sky is cloudy and there are no other clouds in the background."}, "419560": {"image_id": 419560, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.19374606456772306, "Bleu_3": 0.1023605423670429, "Bleu_4": 1.332691735508304e-05, "METEOR": 0.20850036051373208, "ROUGE_L": 0.3418734987990392, "CIDEr": 6.787869571172611e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two giraffes standing in a field surrounded by tall trees. The giraffes are looking in different directions. They are brown with white spots on their backs and necks. The trees are tall and green."}, "136271": {"image_id": 136271, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.13957263155327546, "Bleu_3": 9.91265929396143e-07, "Bleu_4": 2.6758036036849715e-09, "METEOR": 0.1264822134387352, "ROUGE_L": 0.305, "CIDEr": 0.04457554497785156, "SPICE": {"All": {"pr": 0.12, "re": 0.12, "f": 0.12, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image does not contain any fruit. There is a metal stand in the image. The stand is in a grocery store."}, "174633": {"image_id": 174633, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 0.10556671919572966, "Bleu_4": 0.06999971125159092, "METEOR": 0.21748668261748955, "ROUGE_L": 0.23047858942065497, "CIDEr": 6.196674099147768e-11, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.0625, "f": 0.06779661016949153, "fn": 30.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man holding a child on skis. They are skiing down a snowy slope. The man is wearing a black jacket and the child is wearing a blue jacket. They are both holding hands and smiling at each other. In the background, there is a mountain covered with snow."}, "122120": {"image_id": 122120, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.14118624159718107, "Bleu_3": 7.863217694465758e-07, "Bleu_4": 1.867175871883868e-09, "METEOR": 0.19410484361472824, "ROUGE_L": 0.2902787219578518, "CIDEr": 9.572546917958235e-08, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}}, "caption": "The image shows a man skateboarding on a concrete halfpipe. The man is wearing a red shirt and blue pants. He is holding onto a skateboard and wearing a helmet and knee pads. The man is performing a skateboard trick on the halfpipe."}, "34015": {"image_id": 34015, "Bleu_1": 0.42222222221283956, "Bleu_2": 0.2938769068160246, "Bleu_3": 0.15896352576278594, "Bleu_4": 1.7585745850829684e-05, "METEOR": 0.2774480620707058, "ROUGE_L": 0.32972972972972975, "CIDEr": 1.6641025163214173e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man in a red shirt and blue pants standing on a tennis court. He is holding a tennis racket in his right hand and left hand. The man is looking at a tennis ball. The man is walking towards the net."}, "369460": {"image_id": 369460, "Bleu_1": 0.2058823529381488, "Bleu_2": 0.15678956443155245, "Bleu_3": 0.13074162363865652, "Bleu_4": 0.10829217195264998, "METEOR": 0.2799821401727978, "ROUGE_L": 0.26650485436893206, "CIDEr": 2.56843995606065e-19, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10714285714285714, "f": 0.1276595744680851, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a woman walking on the sidewalk. She is talking on the phone and looking at her phone. She is wearing black pants and a black shirt. The woman's hair is long and curly, and it is brown. She is not wearing sunglasses. There is a building behind the woman. In the building, there is a window with a reflection of the woman in it."}, "240049": {"image_id": 240049, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.19738550848437394, "Bleu_3": 0.12935583036335457, "Bleu_4": 0.07994117708696576, "METEOR": 0.23937941135986257, "ROUGE_L": 0.25957446808510637, "CIDEr": 1.1785526481720409e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1875, "f": 0.17142857142857143, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a woman holding a baby while standing next to two giraffes in a zoo enclosure. The woman is wearing a black jacket and jeans. The baby is wearing a pink jacket. The woman is standing behind the fence. The giraffes are eating grass and one of them is looking at a little girl."}, "168686": {"image_id": 168686, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 0.09808593569034826, "Bleu_4": 1.2472080427479296e-05, "METEOR": 0.19430581801342886, "ROUGE_L": 0.2531120331950207, "CIDEr": 7.523509359388033e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13043478260869565, "f": 0.18750000000000003, "fn": 20.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a display of fresh fruits and vegetables in a green basket on a kitchen counter. The fruits include blueberries, strawberries, and oranges. The vegetables include broccoli, carrots, and lettuce. The display is arranged in a neat and organized manner."}, "195172": {"image_id": 195172, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.1603567451442148, "Bleu_3": 0.12892319893629803, "Bleu_4": 0.10814442950655956, "METEOR": 0.27537612718892646, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.1302439500629513e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.20833333333333334, "f": 0.20408163265306126, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing in a field of tall grass. The giraffe is brown with white spots on its back and legs. It has a long neck and long legs. The giraffe is looking at a tree. The background is a green field with trees in the distance."}, "124798": {"image_id": 124798, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.18946618668147105, "Bleu_3": 9.812054324169895e-07, "Bleu_4": 2.2478613857685046e-09, "METEOR": 0.18537585359794317, "ROUGE_L": 0.2908719346049046, "CIDEr": 5.65900807962663e-06, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.13043478260869565, "f": 0.10714285714285714, "fn": 20.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bus driving down the road. There are several cars parked on the side of the road. There is a person riding the bus. \n\nThere are two buildings in the scene. \n\nThe sky is clear and blue."}, "279809": {"image_id": 279809, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.09550351820629131, "Bleu_4": 1.2224986162514046e-05, "METEOR": 0.2665615605530883, "ROUGE_L": 0.27354260089686094, "CIDEr": 1.1013710640320562e-07, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06896551724137931, "f": 0.09090909090909091, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two cats sitting on a windowsill. The cats are black and brown. They are looking at a window. The window is open and there is a view of the snowy landscape outside. The cats are not enjoying the snow."}, "170898": {"image_id": 170898, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.096550680463639, "Bleu_3": 5.437019551875556e-07, "Bleu_4": 1.2958417172416301e-09, "METEOR": 0.1558826878332539, "ROUGE_L": 0.2006578947368421, "CIDEr": 3.0191086587550885e-16, "SPICE": {"All": {"pr": 0.1, "re": 0.13043478260869565, "f": 0.11320754716981132, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two dogs lying on a bed. The dogs are sleeping. One of the dogs is a greyhound. The bed is covered with a floral patterned blanket. There are two pillows on the bed, both of which are green. One of the dogs is resting its head on a white pillow. The dog is wearing an orange collar."}, "274411": {"image_id": 274411, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.16816819849581244, "Bleu_3": 0.1041955676448189, "Bleu_4": 0.06931670557096503, "METEOR": 0.1984735960030748, "ROUGE_L": 0.25176886792452824, "CIDEr": 7.221567441593827e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a woman playing tennis on a tennis court. She is wearing a blue and white dress and has a tennis racket in her hand. The net is in the background. There are no other players in the scene. The sky is blue and there are trees in the background."}, "449379": {"image_id": 449379, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.12635334149896824, "Bleu_3": 0.06789968544843664, "Bleu_4": 8.89525332437836e-06, "METEOR": 0.18363576909599424, "ROUGE_L": 0.18908865468071917, "CIDEr": 4.205739001068126e-12, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a bedroom with a red bedspread. There are three cats in the image. One cat is sleeping on top of the bedspread. The cats are on a bed. The position of the cat on the left is lying down. The position of the cat on the right is lying down."}, "475660": {"image_id": 475660, "Bleu_1": 0.24999999999652778, "Bleu_2": 0.18764665625757584, "Bleu_3": 0.12624510186187463, "Bleu_4": 0.07348498842874635, "METEOR": 0.2342126130491, "ROUGE_L": 0.308080808080808, "CIDEr": 9.366105217356996e-17, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of eight people standing on the steps of the capitol building in Washington, DC. They are dressed in suits and ties and are holding microphones. The building is visible in the background, with a large dome on top. \n\nThere are a total of eleven people in the scene. Some of the people are playing music, holding a trumpet or a guitar, and dressed in jeans and t-shirts "}, "125535": {"image_id": 125535, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.22792115290866924, "Bleu_3": 0.13746108160529513, "Bleu_4": 1.9228544752192987e-05, "METEOR": 0.2229007414057846, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.059461371466834306, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}}, "caption": "The image shows a pelican perched on a tree branch. The pelican is brown and white. The pelican's beak is open."}, "353898": {"image_id": 353898, "Bleu_1": 0.7999999999466668, "Bleu_2": 0.6324555319900065, "Bleu_3": 0.49742263460378094, "Bleu_4": 0.3784481137309595, "METEOR": 0.41945002311298496, "ROUGE_L": 0.698140200286123, "CIDEr": 0.9668535079613516, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man sitting on a bench in a park surrounded by pigeons"}, "177539": {"image_id": 177539, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.12903971808302675, "Bleu_3": 7.17923383724535e-07, "Bleu_4": 1.7029245450294905e-09, "METEOR": 0.20590514749615296, "ROUGE_L": 0.23843648208469054, "CIDEr": 5.688508467484719e-09, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2777777777777778, "f": 0.25641025641025644, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person standing on the beach holding a surfboard. The person is wearing a black and white striped shirt and black shorts. The surfboard has a white stripe. The sky is blue. There are no palm trees in the background. The beach is sandy."}, "467791": {"image_id": 467791, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.11704480209465776, "Bleu_4": 1.3816591886120847e-05, "METEOR": 0.24472571211684746, "ROUGE_L": 0.24416277518345564, "CIDEr": 1.2239768627618826e-07, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.18181818181818182, "f": 0.20512820512820512, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a baseball game in progress on a field. There are several players on the field, including a pitcher and a catcher. The pitcher is throwing the ball to the catcher. The catcher is holding a bat. The other players are standing on the field."}, "197918": {"image_id": 197918, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.16695677422191285, "Bleu_3": 8.865761273541133e-07, "Bleu_4": 2.0559894081168643e-09, "METEOR": 0.18675943437182146, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.6466974129650348e-07, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.15384615384615385, "f": 0.14035087719298245, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two children playing with stuffed animals in a toy store. The children are standing in front of a shelf filled with toys, including stuffed animals, dolls, and toy cars. One of the children is holding a stuffed panda bear."}, "153524": {"image_id": 153524, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.10457151389178666, "Bleu_4": 0.06847928396795629, "METEOR": 0.19496408455252565, "ROUGE_L": 0.21542083578575633, "CIDEr": 2.229097102238432e-13, "SPICE": {"All": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is a computer desk with two computers on it. The computers are connected to a monitor and a keyboard. There is a lamp on the desk. A window is in the background.\n\nThe room is empty except for the computers and lamp. The window is open and there is a view of the outside."}, "449428": {"image_id": 449428, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.20683507599183215, "Bleu_3": 0.110162250798152, "Bleu_4": 1.4410670132161684e-05, "METEOR": 0.1968845187363288, "ROUGE_L": 0.29373996789727125, "CIDEr": 0.0002273128441891038, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.05, "f": 0.04545454545454545, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a herd of three cows grazing in a field. The cows are standing in a line, with their heads down and their tails hanging behind them. They are not wearing collars."}, "231140": {"image_id": 231140, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.16854996561062321, "Bleu_3": 0.0971326448056359, "Bleu_4": 1.3220369604551863e-05, "METEOR": 0.21677374661152943, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.00038291773593884847, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a house with a black roof and a black door. Zebras are grazing and eating grass in front of the house. The house has a large garden with a lake."}, "540449": {"image_id": 540449, "Bleu_1": 0.34782608694139894, "Bleu_2": 0.3079962013899118, "Bleu_3": 0.23841352750186381, "Bleu_4": 0.19186606564204423, "METEOR": 0.27758043313646036, "ROUGE_L": 0.4687156970362239, "CIDEr": 0.12442279592652387, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.06060606060606061, "f": 0.07692307692307693, "fn": 31.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a dog sitting in the car. The dog is wearing a collar. The car is parked in a parking lot."}, "182755": {"image_id": 182755, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.16087993330478273, "Bleu_3": 0.11658508041316994, "Bleu_4": 0.07580047429682589, "METEOR": 0.19469851072270586, "ROUGE_L": 0.2238532110091743, "CIDEr": 7.351554439268139e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08695652173913043, "f": 0.0851063829787234, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a desk with a computer, keyboard, mouse, and two monitors. The desk is made of wood. There is a lamp on the desk. The floor is also made of wood.\n\nThere is no window or outside in the scene. There is no room or walls in the scene."}, "159170": {"image_id": 159170, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.1195228609300719, "Bleu_3": 7.489871169676584e-07, "Bleu_4": 1.8889796346301667e-09, "METEOR": 0.21707671035032783, "ROUGE_L": 0.25673400673400676, "CIDEr": 3.160461663901536e-05, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a cat lying on a couch. The cat's paws are stretched out in front of it. The cat's eyes are closed and it appears to be sleeping. The cat is orange."}, "408480": {"image_id": 408480, "Bleu_1": 0.22222222221604945, "Bleu_2": 0.11268723396062734, "Bleu_3": 7.2015089840826e-07, "Bleu_4": 1.8341681390713041e-09, "METEOR": 0.2029321932066674, "ROUGE_L": 0.27477477477477474, "CIDEr": 2.4080094237772e-06, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.3181818181818182, "f": 0.2692307692307693, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a red lighthouse on the waterfront. There is a ship in the background. A tall building is also visible in the background.\n\nThe sky is blue and there are trees in the foreground."}, "538242": {"image_id": 538242, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.06185895741189865, "Bleu_3": 4.3341351003500945e-07, "Bleu_4": 1.1534197288455865e-09, "METEOR": 0.1536555976370042, "ROUGE_L": 0.18815545959284388, "CIDEr": 1.0893159361666056e-09, "SPICE": {"All": {"pr": 0.19444444444444445, "re": 0.23333333333333334, "f": 0.21212121212121213, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2631578947368421, "re": 0.35714285714285715, "f": 0.30303030303030304, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}}, "caption": "The image shows two people standing in front of a motorcycle in a parking lot. The people are wearing military uniforms and helmets. The motorcycle is not parked and does not have a sidecar attached. There are no trees in the scene, but there are buildings in the distance."}, "552153": {"image_id": 552153, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.24597601850010517, "Bleu_3": 0.19428705359227444, "Bleu_4": 0.14631973332482512, "METEOR": 0.2880991551800113, "ROUGE_L": 0.3951417004048583, "CIDEr": 9.413832961497332e-05, "SPICE": {"All": {"pr": 0.1875, "re": 0.1111111111111111, "f": 0.13953488372093023, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a small plane flying over a body of water. The plane is white and green. There are no other boats or people in the image. In the background, there is a mountain."}, "63617": {"image_id": 63617, "Bleu_1": 0.340909090901343, "Bleu_2": 0.23557764908855597, "Bleu_3": 0.15826323683329635, "Bleu_4": 1.7633522188639767e-05, "METEOR": 0.23306571479769378, "ROUGE_L": 0.29735376044568246, "CIDEr": 1.869035723625445e-07, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.047619047619047616, "f": 0.04, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a young boy playing catch with his father on a wooden deck. The boy is wearing a baseball glove and holding a baseball in his hand. The father is standing behind him. The background is a clear sky with no clouds."}, "366529": {"image_id": 366529, "Bleu_1": 0.4324324324207451, "Bleu_2": 0.28997255745928074, "Bleu_3": 0.13393124865178632, "Bleu_4": 1.6303907740006476e-05, "METEOR": 0.18796918589217726, "ROUGE_L": 0.2627422828427854, "CIDEr": 9.948565601830499e-05, "SPICE": {"All": {"pr": 0.1, "re": 0.15789473684210525, "f": 0.12244897959183673, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.6, "f": 0.3157894736842105, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a wedding photo of a bride and groom. The bride is wearing a veil. The groom is wearing a white suit. They are posing for a picture. They are standing in front of a waterfall."}, "282841": {"image_id": 282841, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.19518001458420758, "Bleu_3": 1.038637323785807e-06, "Bleu_4": 2.413901023217176e-09, "METEOR": 0.19070113186303977, "ROUGE_L": 0.2420634920634921, "CIDEr": 2.740737326350958e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a wall with a mirror hanging on it. There are leather straps hanging from the wall, and a pair of scissors on the table.\n\nThere is no window or room in the image."}, "169679": {"image_id": 169679, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.12464639250022254, "Bleu_3": 0.08121828408966404, "Bleu_4": 9.846267797162313e-06, "METEOR": 0.13631611243576108, "ROUGE_L": 0.1639784946236559, "CIDEr": 1.2398785281867306e-15, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows four people standing on a snowy slope. They are wearing ski gear and holding skis. The woman on the left is wearing a blue jacket and blue pants, while the man in the middle is wearing a blue jacket and blue pants. The woman on the right is wearing a white and blue jacket and brown pants."}, "427034": {"image_id": 427034, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.12198750911664548, "Bleu_3": 6.214597592719476e-07, "Bleu_4": 1.4084041646300657e-09, "METEOR": 0.19927543566499392, "ROUGE_L": 0.20792754187767823, "CIDEr": 4.528635145648732e-16, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a small black and tan dog sitting on top of a laptop. The dog is looking up at the camera with its tongue hanging out of its mouth. The laptop has two screens, one showing a picture of a cat and the other showing a man holding a pizza. The dog is also wearing a collar with a sock on it."}, "381527": {"image_id": 381527, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.21997067252481586, "Bleu_3": 0.14943552521577302, "Bleu_4": 1.8580221322976227e-05, "METEOR": 0.28418088604234204, "ROUGE_L": 0.3885350318471337, "CIDEr": 0.0032094202800736363, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.047619047619047616, "f": 0.0425531914893617, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a skateboarder performing a trick on the side of a skate park. The skateboarder is wearing black pants and a white shirt. The skateboarder's helmet is white."}, "81661": {"image_id": 81661, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.18700983288178252, "Bleu_3": 8.400251538923964e-07, "Bleu_4": 1.7879782017146963e-09, "METEOR": 0.20979279842227558, "ROUGE_L": 0.24676731922271183, "CIDEr": 2.179895318331944e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a laptop computer with a mouse on it. A cell phone is next to the laptop. The laptop has a red screen. The keyboard is red. The mouse is on the keyboard. The keyboard is red. \n\nThere are two desks in the scene. On the desks, there is a laptop, a can, a remote control, and a cord."}, "501368": {"image_id": 501368, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.21470745394187096, "Bleu_3": 0.14432865208179946, "Bleu_4": 0.09040892145530917, "METEOR": 0.2192582055184445, "ROUGE_L": 0.28018372703412076, "CIDEr": 8.596313492462434e-09, "SPICE": {"All": {"pr": 0.375, "re": 0.1935483870967742, "f": 0.25531914893617014, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a woman standing in a bathroom. The woman is brushing her hair and looking at a mirror. She is wearing a towel around her neck. The towel is yellow. \n\nThere is no light or wall in the scene. There is no window in the scene."}, "51119": {"image_id": 51119, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.3098662125759413, "Bleu_3": 0.22014152945079551, "Bleu_4": 0.15713284450350143, "METEOR": 0.20531025057704794, "ROUGE_L": 0.3441466854724965, "CIDEr": 4.711969339912159e-05, "SPICE": {"All": {"pr": 0.1, "re": 0.06896551724137931, "f": 0.08163265306122448, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a burnt out bus that has been involved in an accident. The bus is on the side of the road. There are several people repairing the bus. Bits of metal are scattered around the bus."}, "502006": {"image_id": 502006, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.19438820598718592, "Bleu_3": 0.1007038404331726, "Bleu_4": 1.2978033761735104e-05, "METEOR": 0.22398992500931827, "ROUGE_L": 0.22846441947565538, "CIDEr": 5.473120930039079e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 33.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.3125, "f": 0.39999999999999997, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a brown bear walking through a grassy field. The bear is standing on its hind legs and looking at something in the distance. The cubs are hiding in the grass and standing next to a tree."}, "213457": {"image_id": 213457, "Bleu_1": 0.33333333331944454, "Bleu_2": 0.12038585308064416, "Bleu_3": 8.701138390872275e-07, "Bleu_4": 2.366612932459347e-09, "METEOR": 0.16015434242729853, "ROUGE_L": 0.264069264069264, "CIDEr": 0.018249807799636076, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.047619047619047616, "f": 0.04545454545454545, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a person skiing on a snowy slope. The person is wearing a black and yellow ski suit and a black helmet."}, "138549": {"image_id": 138549, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.22677868380095453, "Bleu_3": 0.14758022201791693, "Bleu_4": 1.6171364085849802e-05, "METEOR": 0.2799029712855335, "ROUGE_L": 0.27128335451080055, "CIDEr": 1.4455338785690951e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16666666666666666, "f": 0.14814814814814814, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a table with a plate of food on it. The plate contains a sandwich and an orange slice. There is also a glass on the table, as well as a book. The background is a wooden floor, and there is no tablecloth or window in the scene."}, "579303": {"image_id": 579303, "Bleu_1": 0.1538461538441815, "Bleu_2": 0.08939803125238129, "Bleu_3": 0.04720059128142643, "Bleu_4": 6.119208672953316e-06, "METEOR": 0.16354226263730468, "ROUGE_L": 0.1907953529937444, "CIDEr": 4.661041359475605e-29, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13333333333333333, "f": 0.16666666666666669, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows two plates with sandwiches on them. The first plate has a cup of coffee next to it. The second plate has a cup of coffee next to it. The first sandwich has a tomato on top of it and is served with a side of salad. The second sandwich has laundry and tomato on top of it and is served with a glass of water. The table does not have a tablecloth or a vase."}, "351744": {"image_id": 351744, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.11945967146768073, "Bleu_3": 6.978002390453578e-07, "Bleu_4": 1.6966894961903369e-09, "METEOR": 0.20819573956166262, "ROUGE_L": 0.25318206972883234, "CIDEr": 7.205252176140391e-08, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08695652173913043, "f": 0.0909090909090909, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a train on the tracks. A container car is attached to the back of the train. The train is traveling through a tunnel. The tracks lead to the train station. There is a tree and a building visible in the background."}, "521605": {"image_id": 521605, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.23452078798159529, "Bleu_3": 1.3372469554821615e-06, "Bleu_4": 3.2288884622985093e-09, "METEOR": 0.2439317943265231, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.01876351493643535, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.26666666666666666, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a plate of food with bacon, eggs, and broccoli on it. The overall appearance of the dish is quite appetizing and inviting."}, "494439": {"image_id": 494439, "Bleu_1": 0.1449275362297837, "Bleu_2": 0.0799616276247328, "Bleu_3": 0.045697890166528324, "Bleu_4": 6.166462975308838e-06, "METEOR": 0.19358204816378846, "ROUGE_L": 0.15151515151515152, "CIDEr": 2.9153646643935952e-22, "SPICE": {"All": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 27.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a train on the tracks in front of a building. The train is blue and white. The wheels of the train are white. There is not a number on the side of the train. The train has a red and white stripe on the side. The building is made of brick. The building has a red roof.\n\nThere are no people or platforms in the scene."}, "209753": {"image_id": 209753, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.2449489742734669, "Bleu_3": 0.16982634150412063, "Bleu_4": 1.787283644212795e-05, "METEOR": 0.26314128432047396, "ROUGE_L": 0.2966050186680559, "CIDEr": 1.9559252981766783e-08, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.13333333333333333, "f": 0.11764705882352941, "fn": 26.0, "numImages": 1.0, "fp": 34.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a woman wearing a black dress and holding a phone in her hand. She is standing in front of a window with a view of a tree outside. There is a TV in the background. The woman is looking at her phone with a smile on her face."}, "435709": {"image_id": 435709, "Bleu_1": 0.1904761904716554, "Bleu_2": 0.11805626721734595, "Bleu_3": 7.03675938605906e-07, "Bleu_4": 1.7288741230850776e-09, "METEOR": 0.10639807973203237, "ROUGE_L": 0.21631205673758863, "CIDEr": 7.889074523566528e-08, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.2, "f": 0.14545454545454545, "fn": 16.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5714285714285714, "f": 0.36363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image does not contain a street. There are three buildings in the image. There are six cars in the image. The cars are not parked on the side of the road.\n\nThe image does not contain a road or any person."}, "38029": {"image_id": 38029, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.183339699400327, "Bleu_3": 0.10061584140131913, "Bleu_4": 1.3357103091691184e-05, "METEOR": 0.29713604077257133, "ROUGE_L": 0.3108544250042466, "CIDEr": 8.13784453059564e-05, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.27586206896551724, "f": 0.2857142857142857, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.46153846153846156, "f": 0.4444444444444445, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a red fire truck driving down the street with people walking on the sidewalk. The truck has a large red fire hydrant on the back. There are people standing on the sidewalk."}, "434494": {"image_id": 434494, "Bleu_1": 0.2153846153813018, "Bleu_2": 0.10047961905700466, "Bleu_3": 5.431733704148491e-07, "Bleu_4": 1.267961100712804e-09, "METEOR": 0.10375987937615178, "ROUGE_L": 0.15091538842157345, "CIDEr": 1.3118851225131117e-17, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.26666666666666666, "f": 0.1951219512195122, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.8, "f": 0.4210526315789473, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows two people standing on two different roads. One person is standing on a tarmac road, wearing a striped vest and holding a kite. The other person is standing on a sidewalk, wearing a yellow vest and holding a skateboard.\n\nThere is no construction site in the image.\n\nThere is no hard hat, safety vest, shovel, tar, dirt, or gravel in the image."}, "171062": {"image_id": 171062, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.26599758829439873, "Bleu_3": 0.20266503317508344, "Bleu_4": 0.13508250818356246, "METEOR": 0.25726899138929965, "ROUGE_L": 0.3190005810575247, "CIDEr": 5.236173729027713e-11, "SPICE": {"All": {"pr": 0.24, "re": 0.1875, "f": 0.21052631578947367, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on a wooden table in a dimly lit room. The cat is looking at a television in front of it. The television is showing a video game with a character running through a forest. The cat's ears are twitching. There are no lamps on the table."}, "238866": {"image_id": 238866, "Bleu_1": 0.3715190997867868, "Bleu_2": 0.23168286400471463, "Bleu_3": 2.103416377214603e-06, "Bleu_4": 6.701444468735928e-09, "METEOR": 0.10751149317046566, "ROUGE_L": 0.22803738317757008, "CIDEr": 0.3575992545124089, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "There are no doughnuts in this image."}, "428454": {"image_id": 428454, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.1252448582145496, "Bleu_3": 6.840816017013768e-07, "Bleu_4": 1.6070175637240875e-09, "METEOR": 0.18238723580470495, "ROUGE_L": 0.26704190118824267, "CIDEr": 1.5306326827900766e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1111111111111111, "f": 0.10256410256410256, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person snowboarding on a snowy slope. The person is wearing a green jacket and holding a snowboard. The person is also flying two kites. The sky is clear and blue, with a few clouds in the distance. There is no snow on the ground and no tracks."}, "200945": {"image_id": 200945, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.253320198544886, "Bleu_3": 0.12610429748037674, "Bleu_4": 1.594802808602878e-05, "METEOR": 0.27129311433316655, "ROUGE_L": 0.36371379897785344, "CIDEr": 0.0008563737234310316, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a hot dog on a bun made of white bread. There is ketchup and mustard on top of the hot dog. A pickle is also on top of the hot dog."}, "391139": {"image_id": 391139, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.25928148941334883, "Bleu_3": 0.21677025908174807, "Bleu_4": 0.18889796346285267, "METEOR": 0.30807958096491195, "ROUGE_L": 0.36715391229578676, "CIDEr": 0.0002675946255806677, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a dog sitting on a wooden bench in front of a pumpkin patch. The dog is wearing a red collar on its forehead. The pumpkins in the patch are orange and yellow."}, "440093": {"image_id": 440093, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.11497181007363187, "Bleu_4": 1.3481992110749651e-05, "METEOR": 0.23498829639751304, "ROUGE_L": 0.26940063091482647, "CIDEr": 4.677561390258342e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a person doing a skateboard trick. The person is riding on a skateboard. The person is wearing a black shirt and black pants. The person is also wearing a blue helmet. The skateboard has four wheels. The background is a concrete skate park with no trees."}, "555356": {"image_id": 555356, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.19374606456772306, "Bleu_3": 0.1289662020068933, "Bleu_4": 0.08912246776433805, "METEOR": 0.1704928139746245, "ROUGE_L": 0.27858121479677267, "CIDEr": 2.1475007393720124e-05, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.17857142857142858, "f": 0.16129032258064516, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a microwave oven on a countertop. There is no sink or faucet in the scene. There is a piece of aluminum foil on top of the microwave oven. The countertop is made of granite."}, "561270": {"image_id": 561270, "Bleu_1": 0.31666666666138893, "Bleu_2": 0.19383142538727718, "Bleu_3": 0.10901429746174544, "Bleu_4": 0.0690468517493109, "METEOR": 0.2571730337511249, "ROUGE_L": 0.27477477477477474, "CIDEr": 5.503034817474153e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15, "f": 0.14634146341463414, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 1.0, "f": 0.2857142857142857, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows three boats docked at a pier on a body of water. One of the boats is red and has a white hull. Another boat is a sailboat and is also docked at the pier, with a white and red color scheme. The water is calm and peaceful. The sky is cloudy, with some clouds in the distance."}, "351557": {"image_id": 351557, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1543033499589101, "Bleu_3": 0.07971700074705254, "Bleu_4": 1.0244098719420824e-05, "METEOR": 0.22239791195941241, "ROUGE_L": 0.22679390259015986, "CIDEr": 6.044794490288437e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of ten people standing in front of two buildings. Two people are standing in front of the building. The people are wearing different colored shirts and blue pants. Some of the people are holding a dog, a cell phone, a kite, or a flag."}, "123131": {"image_id": 123131, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.13608276348545723, "Bleu_3": 0.08874014256039511, "Bleu_4": 0.060546529641682174, "METEOR": 0.21416979234678923, "ROUGE_L": 0.17951736315479697, "CIDEr": 9.469606771794661e-14, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.10344827586206896, "f": 0.10526315789473684, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of two trucks parked in a lot. The first truck is black and the second truck is yellow. The first truck has a large grille on the front and a large bumper on the back. The second truck is pulling a black trailer, which has a large sign on the back."}, "326248": {"image_id": 326248, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 0.08411954328528157, "Bleu_4": 1.0608359163741716e-05, "METEOR": 0.19353151759319712, "ROUGE_L": 0.26521739130434785, "CIDEr": 2.7261564094348257e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a tennis match in progress on a court. There are no players on the court. The opponent is holding a tennis racket. \n\nThere are 20 people on the sidelines. Some of them are spectators, while others are coaches. \n\nThere are no stands or sideline in the scene."}, "531852": {"image_id": 531852, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.14129296641606834, "Bleu_3": 0.12124793605097663, "Bleu_4": 0.10670385044190443, "METEOR": 0.2617368144225027, "ROUGE_L": 0.26961325966850824, "CIDEr": 8.815530387370495e-15, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21052631578947367, "f": 0.21621621621621623, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two men standing in a living room. One of the men is holding a video game controller and the other is holding a remote control. The room is decorated with a couch, a television, a table, and a man. The men are wearing casual clothing and appear to be in their mid to late 20s."}, "205720": {"image_id": 205720, "Bleu_1": 0.42499999998937504, "Bleu_2": 0.3131723536201055, "Bleu_3": 0.19783425727091494, "Bleu_4": 0.12027509029435071, "METEOR": 0.32686072590219467, "ROUGE_L": 0.39610389610389607, "CIDEr": 8.372747762833832e-05, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}}, "caption": "The image shows a man standing on a boat. The man is talking on the phone and looking at a phone. He is wearing a red shirt and does not have a beard. The boat is docked in the water."}, "69223": {"image_id": 69223, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.15075567228549366, "Bleu_3": 8.08524074577027e-07, "Bleu_4": 1.883464306778211e-09, "METEOR": 0.23053715909480113, "ROUGE_L": 0.21048999309868874, "CIDEr": 4.453356240546241e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bathroom with a large bathtub, a sink, and a toilet. The walls are made of marble. The floor is made of tile. There is a door on one side of the room. A bathroom is on one side of the room."}, "233311": {"image_id": 233311, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.22086305214437035, "Bleu_3": 0.13460836455258657, "Bleu_4": 0.08892786873706292, "METEOR": 0.26585093146812533, "ROUGE_L": 0.31077147016011636, "CIDEr": 1.1641190050920443e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a table with a stuffed monkey on it. The table is not empty. There is a bowl filled with oranges. The monkey is holding a toy in its hand. The color of the cloth on the table is blue."}, "460294": {"image_id": 460294, "Bleu_1": 0.1707317073149911, "Bleu_2": 0.12985526884080165, "Bleu_3": 0.09447053726408963, "Bleu_4": 0.06797089915290365, "METEOR": 0.19459995657600695, "ROUGE_L": 0.17457072771872448, "CIDEr": 2.540739046166546e-29, "SPICE": {"All": {"pr": 0.16, "re": 0.13333333333333333, "f": 0.14545454545454545, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of three people standing under umbrellas in a parking lot. The people are wearing a white coat and a black and white shirt. Some of the people are holding umbrellas. A woman with an umbrella can be seen in the parking lot.\n\nIn the background, there are two buildings. The buildings are made of brick. The windows are located on the top floor. \n\nThere are cars parked in the lot. There is no lot in the scene.\n\n"}, "107907": {"image_id": 107907, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 6.290089214849726e-07, "Bleu_4": 1.5012173807660588e-09, "METEOR": 0.16560934891485812, "ROUGE_L": 0.21131639722863746, "CIDEr": 6.890080218365701e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.22727272727272727, "f": 0.23809523809523808, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.45454545454545453, "f": 0.5882352941176471, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows a room with two paintings on the wall. One of the paintings is a large abstract piece, while the other is a framed piece of art. There is a table in the room, and on the table, there is a vase. The vase has a floral design on it."}, "463084": {"image_id": 463084, "Bleu_1": 0.2857142857097506, "Bleu_2": 0.23515854049712342, "Bleu_3": 0.20131589315307905, "Bleu_4": 0.16900849975556387, "METEOR": 0.2719935193254761, "ROUGE_L": 0.23204945316214928, "CIDEr": 8.715351851556376e-15, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15, "f": 0.13043478260869565, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a bus stop on a street with a building in the background. A bus can be seen at the bus stop. A sign can be seen at the bus stop, which says \"wanadoo by all together\". The weather is cloudy and there are some trees in the background. There are also some cars parked on the side of the road."}, "279621": {"image_id": 279621, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.12032689292712466, "Bleu_4": 0.08175340974652183, "METEOR": 0.2153109209765505, "ROUGE_L": 0.2531120331950207, "CIDEr": 1.0249592035002823e-06, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1111111111111111, "f": 0.0975609756097561, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a train traveling along a track next to a river. The train is pulling cars. The track is surrounded by a tree and a hill in the background. The sky is clear and there are no clouds in sight."}, "199438": {"image_id": 199438, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.1772810520820019, "Bleu_3": 0.125237643155067, "Bleu_4": 1.4298046332209055e-05, "METEOR": 0.2480715371828652, "ROUGE_L": 0.2901307966706302, "CIDEr": 5.586751531271903e-09, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.038461538461538464, "f": 0.04, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man and a woman paddling a canoe on a lake. The man is paddling the canoe. The woman is looking at a duck. The woman is paddling the canoe. There are ducks on the lake. The sky is blue and there are trees on the shore."}, "160341": {"image_id": 160341, "Bleu_1": 0.1940298507433727, "Bleu_2": 0.13281218822095867, "Bleu_3": 0.09337442078380687, "Bleu_4": 0.059720845430200925, "METEOR": 0.16228598250577186, "ROUGE_L": 0.2061805890873974, "CIDEr": 4.1098663565032966e-19, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.07692307692307693, "f": 0.10256410256410257, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a house located on a ski slope. A ski lift is in front of the house. Snow is on the ground in front of the house. The weather is snowy. There is no ski resort in the image. \n\nThere is a skier and a snowboard on the ground in front of the house. \n\nThe sky is cloudy. There are no trees in the image."}, "571196": {"image_id": 571196, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.191273013914278, "Bleu_3": 0.12333630413179801, "Bleu_4": 1.4906383786424012e-05, "METEOR": 0.19451899550821047, "ROUGE_L": 0.3083032490974729, "CIDEr": 3.673024214982723e-06, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13636363636363635, "f": 0.13636363636363635, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a bed with a book on it. The bed has a floral pattern. A book is next to the bed. There is a nightstand with a book on it. The room has a wooden floor and no walls."}, "370266": {"image_id": 370266, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.3107277331223966, "Bleu_3": 0.2398210671316978, "Bleu_4": 0.15034000394363373, "METEOR": 0.24649263674419603, "ROUGE_L": 0.34078212290502796, "CIDEr": 0.004861106301465147, "SPICE": {"All": {"pr": 0.15625, "re": 0.23809523809523808, "f": 0.18867924528301888, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of seven sheep grazing in a green pasture with a white fence in the background. The sheep are grazing on grass. The fence is white."}, "458487": {"image_id": 458487, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.06520506636831809, "Bleu_3": 4.4890551563344676e-07, "Bleu_4": 1.184204612229436e-09, "METEOR": 0.12267562941722687, "ROUGE_L": 0.18815545959284388, "CIDEr": 7.396798672872642e-10, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.21875, "f": 0.23728813559322032, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.4, "f": 0.42857142857142855, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a baseball game in progress. There is one player on the field, playing baseball. The umpire is a baseball umpire. The crowd is watching the game. Some people in the crowd are waving flags. The field is green. The players are wearing black and white uniforms."}, "521879": {"image_id": 521879, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.11875421719606402, "Bleu_3": 7.186291482531253e-07, "Bleu_4": 1.7796237394908679e-09, "METEOR": 0.15691007231354684, "ROUGE_L": 0.23036253776435048, "CIDEr": 5.8620623799396873e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of five people standing on the sidewalk in front of a horse drawn carriage. The carriage is decorated with flowers. The people are dressed in costumes and hats. Some of the people are holding hats."}, "307784": {"image_id": 307784, "Bleu_1": 0.5384615384477318, "Bleu_2": 0.33669024916197066, "Bleu_3": 0.20947242940424252, "Bleu_4": 0.1264065350516398, "METEOR": 0.28901500721461115, "ROUGE_L": 0.45975773889636606, "CIDEr": 0.19037311465178336, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is of a kitchen with a white sink, a stove, and a refrigerator. There is a wooden cutting board on the counter, and a knife on the cutting board. The walls are brown. The cabinets are beige."}, "154095": {"image_id": 154095, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.20447945297237122, "Bleu_3": 1.01487632009003e-06, "Bleu_4": 2.2753263050582995e-09, "METEOR": 0.16668022622352097, "ROUGE_L": 0.22197962154294032, "CIDEr": 6.861166809263718e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09523809523809523, "f": 0.11428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a bedroom with a bed, a desk, and a television. There is a backpack on the floor next to the bed. The backpack has a blue and orange color scheme. The bed has a blue and white striped blanket."}, "222322": {"image_id": 222322, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2094269541404072, "Bleu_3": 0.10583300875248391, "Bleu_4": 1.3470702101939834e-05, "METEOR": 0.21416979234678923, "ROUGE_L": 0.2771467514766015, "CIDEr": 5.176799906888255e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.13793103448275862, "f": 0.14814814814814817, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a view of the beach from a restaurant. There are 19 umbrellas on the sand. People are sitting at tables on the beach. The water is clear and blue. There is no sand in the scene."}, "227042": {"image_id": 227042, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.13204641200979725, "Bleu_4": 1.5124526410231296e-05, "METEOR": 0.22316026886802032, "ROUGE_L": 0.35568513119533524, "CIDEr": 6.510315231900468e-05, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.21428571428571427, "f": 0.2553191489361702, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of five men playing soccer in a field. They are wearing red and blue jerseys and white shorts. One player is kicking a soccer ball. Another player is trying to block the ball with his hand. The other players are playing soccer."}, "155897": {"image_id": 155897, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.11843515045025206, "Bleu_3": 0.07895363399346553, "Bleu_4": 0.054448019373565, "METEOR": 0.2007724886409033, "ROUGE_L": 0.17300056721497448, "CIDEr": 5.1534380427769905e-16, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21052631578947367, "f": 0.2580645161290323, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a woman sitting on a bench. She is holding a sandwich in her hand. The sandwich is made of a toasted sandwich and a toasted sourdough bread with a slice of cheese. The woman is wearing a blue shirt and shorts. She has a green hat on her head.\n\nThere are five people in the background."}, "33798": {"image_id": 33798, "Bleu_1": 0.3199999999936, "Bleu_2": 0.16162440712508827, "Bleu_3": 0.08164398935369906, "Bleu_4": 1.0373342050823157e-05, "METEOR": 0.2560993607460179, "ROUGE_L": 0.255688622754491, "CIDEr": 4.204744973359137e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.12121212121212122, "f": 0.1568627450980392, "fn": 29.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a living room with two couches, a coffee table, and a television. The room is well lit with natural light coming in from the window, which is not on the left side of the room. The walls are painted white and the floor is made of hardwood."}, "490794": {"image_id": 490794, "Bleu_1": 0.1403508771905202, "Bleu_2": 1.5831189671252371e-09, "Bleu_3": 3.5718082682176773e-12, "Bleu_4": 1.7043848443828508e-13, "METEOR": 0.11214953271028039, "ROUGE_L": 0.17805020431990656, "CIDEr": 2.7825806316202184e-14, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.4444444444444444, "f": 0.4897959183673469, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 12.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.8571428571428571, "re": 0.42857142857142855, "f": 0.5714285714285714, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a street with four cars parked on both sides. There are trees on both sides of the street. A building is in the background. The sky is blue and there are no clouds in the sky.\n\nThe image is taken from a bird's eye view, looking down on the street. The camera is"}, "381925": {"image_id": 381925, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.17807996398101744, "Bleu_3": 0.11472822500028991, "Bleu_4": 0.07790345908043068, "METEOR": 0.2947637596859865, "ROUGE_L": 0.31266017426960535, "CIDEr": 9.581998778499022e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a girl sitting on a bench in front of a stone wall. She is wearing a brown hoodie and has her arms around her knees. The wall is made of large stones. There is no opening or tree in the scene."}, "145312": {"image_id": 145312, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.09124485969890858, "Bleu_3": 5.698161672784481e-07, "Bleu_4": 1.4319831453628615e-09, "METEOR": 0.19038657375234558, "ROUGE_L": 0.23843648208469054, "CIDEr": 2.502010405087565e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2608695652173913, "f": 0.20338983050847456, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a black and white dog standing on the grass. The dog is catching a frisbee. The dog is wearing a purple collar with a purple cloth on it. The dog is standing next to a tree with a purple frisbee hanging down from it."}, "65798": {"image_id": 65798, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.15585730003579046, "Bleu_3": 0.10950337957304693, "Bleu_4": 0.07771324020536689, "METEOR": 0.23068250424592246, "ROUGE_L": 0.2601279317697228, "CIDEr": 5.297865065999812e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.21739130434782608, "f": 0.2564102564102564, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress on a large field. There are several players on the field, including a pitcher and a catcher. The crowd is cheering for the a's. The field is covered in grass."}, "358817": {"image_id": 358817, "Bleu_1": 0.1730769230735947, "Bleu_2": 1.8421903154232562e-09, "Bleu_3": 4.079118561259233e-12, "Bleu_4": 1.929193217195543e-13, "METEOR": 0.11281499319383446, "ROUGE_L": 0.11024096385542169, "CIDEr": 3.417354565686266e-12, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two streets with three houses on either side. There is one car parked on the street. The sky is clear.\n\nThe houses are made of wood and have white trim around the doors. There are no trees or other vegetation in the area. The street is lined with sidewalks."}, "188465": {"image_id": 188465, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.191273013914278, "Bleu_3": 0.097892089462343, "Bleu_4": 1.2534724690400046e-05, "METEOR": 0.2416989451655744, "ROUGE_L": 0.2588767859668977, "CIDEr": 6.263448556908123e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a baseball player about to hit a ball in a stadium. The baseball player is wearing a white uniform and has a bat in his hand. The stadium is filled with a crowd of people watching the game."}, "14285": {"image_id": 14285, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.25761406704390316, "Bleu_3": 0.1585003161501176, "Bleu_4": 1.6883931425975408e-05, "METEOR": 0.2810342297292602, "ROUGE_L": 0.3719512195121952, "CIDEr": 6.941353996633005e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16666666666666666, "f": 0.15686274509803924, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a cat lying on a bed in a room with a television and a desk in the background. The cat is not looking up at the camera. The room has a blue wall with a blue, white, and black mural on it. There is no window in the room."}, "499631": {"image_id": 499631, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.16087993330478273, "Bleu_3": 0.08083557992554675, "Bleu_4": 1.0242161260431777e-05, "METEOR": 0.19313842650217136, "ROUGE_L": 0.22584228063680117, "CIDEr": 3.300962396402301e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image is of a group of ten teddy bears sitting on various objects, including a bench, a wooden step, a snow-covered floor, and a tree. The bears are wearing hats and scarves. \n\nThere is a Christmas tree in the scene, but there are no ornaments, lights, or ribbons on it."}, "67342": {"image_id": 67342, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.13005121774948097, "Bleu_3": 7.38459222349508e-07, "Bleu_4": 1.7703083784398738e-09, "METEOR": 0.2215410442597006, "ROUGE_L": 0.2197406340057637, "CIDEr": 1.2396014833778541e-08, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.1111111111111111, "f": 0.1904761904761905, "fn": 16.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}}, "caption": "The image shows two birds in a green field. The smaller bird is perched on a metal rod and looking at a tree. The larger bird is perching on a metal rod and eating a worm. The smaller bird is also eating a worm."}, "295728": {"image_id": 295728, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.09869275424218699, "Bleu_3": 5.65013632025846e-07, "Bleu_4": 1.358235968559138e-09, "METEOR": 0.1629440242985993, "ROUGE_L": 0.23775055679287305, "CIDEr": 1.9492712803335147e-13, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.19230769230769232, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features three clocks made of metal and brass. The clocks are mounted on the walls and surrounded by frames. Clock 1 is surrounded by a metal frame, clock 2 is surrounded by a wooden frame, and clock 3 is surrounded by a ring. The clocks are located in the lobby of a large building."}, "267951": {"image_id": 267951, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.0956600132176177, "Bleu_4": 1.248740514185277e-05, "METEOR": 0.1432292839647153, "ROUGE_L": 0.216773276474769, "CIDEr": 8.832924082668163e-06, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.17857142857142858, "f": 0.16393442622950818, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5555555555555556, "f": 0.4166666666666667, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows two zebras standing in a pen. The zebras are black and white with stripes on their backs. They are standing next to each other and looking at the camera. The pen is surrounded by a fence."}, "2302": {"image_id": 2302, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.22214157542810112, "Bleu_3": 0.09890764005242271, "Bleu_4": 1.179450934080117e-05, "METEOR": 0.21747561848170918, "ROUGE_L": 0.226906385616863, "CIDEr": 3.700766484040641e-11, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08695652173913043, "f": 0.10526315789473685, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of people riding horses on a dirt path in front of a mountain range. The horses are wearing saddles and the riders are wearing hats. There is a person with a backpack in front of the mountain range.\n\nThere is no snow, rocks, or trees in the scene."}, "146397": {"image_id": 146397, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.09983374884360895, "Bleu_3": 0.06241040020024951, "Bleu_4": 8.829329566836789e-06, "METEOR": 0.15995126025813627, "ROUGE_L": 0.2616154395997141, "CIDEr": 4.2450885647065085e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.15151515151515152, "f": 0.18867924528301888, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of seven men standing on a skateboard ramp. The men are wearing black shirts and jeans. Their arms are outstretched in different directions. The skateboard ramp is made of concrete and has a red line down the middle."}, "122981": {"image_id": 122981, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2823724831943621, "Bleu_3": 0.2268144468215368, "Bleu_4": 0.17199600153045344, "METEOR": 0.25301441597698743, "ROUGE_L": 0.30521801286633315, "CIDEr": 8.980431791423377e-07, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1875, "f": 0.17142857142857143, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a boy wearing a green shirt standing in front of a bus. The bus is white and black. The boy is looking at the bus with a serious expression on his face. There are two men standing next to him."}, "227878": {"image_id": 227878, "Bleu_1": 0.16363636363338846, "Bleu_2": 0.07784989441472377, "Bleu_3": 0.04853779711941007, "Bleu_4": 6.847928396795628e-06, "METEOR": 0.1274070644480393, "ROUGE_L": 0.15633008713480268, "CIDEr": 8.30130897422157e-11, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.15384615384615385, "f": 0.1951219512195122, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a living room with a fish tank on the floor. A betta fish is swimming in the fish tank. The cat is sitting on a chair. The cat is looking at a white chair. The cat has a curious expression on its face. The walls of the room are blue and white."}, "286858": {"image_id": 286858, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.09087496586948689, "Bleu_4": 1.1854610697110774e-05, "METEOR": 0.22401185527389392, "ROUGE_L": 0.2713120830244626, "CIDEr": 4.933126184145066e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.10714285714285714, "f": 0.13636363636363635, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a stuffed animal sitting on a bed. The stuffed animal has a sad expression. The bed is covered in a blanket. There is a lamp next to the bed. The shirt worn by the stuffed animal is blue."}, "459680": {"image_id": 459680, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.2717786532439402, "Bleu_3": 0.13356407584880067, "Bleu_4": 1.6787535109825208e-05, "METEOR": 0.2652101905618491, "ROUGE_L": 0.379530253538653, "CIDEr": 0.0008422843835391951, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2692307692307692, "f": 0.2916666666666667, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a woman holding an umbrella and wearing a pink dress. The woman is standing in front of a building. There is no apron, hat, window, or balcony in the scene."}, "462677": {"image_id": 462677, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 0.09139586978860176, "Bleu_4": 1.1611347030414458e-05, "METEOR": 0.22947139782436202, "ROUGE_L": 0.28894302341318173, "CIDEr": 3.577012115690149e-06, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2571428571428571, "f": 0.3214285714285714, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.46153846153846156, "f": 0.5217391304347826, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a blue mailbox located on the sidewalk next to the road. The mailbox has a sign on it that says \"no parking\". The image is taken from a street. The sky is cloudy and there are no other objects in the scene."}, "90520": {"image_id": 90520, "Bleu_1": 0.30434782607372407, "Bleu_2": 0.20372033840756823, "Bleu_3": 1.254921310539593e-06, "Bleu_4": 3.1528613441074588e-09, "METEOR": 0.18732143608718646, "ROUGE_L": 0.27141268075639596, "CIDEr": 0.01970587757556997, "SPICE": {"All": {"pr": 0.24, "re": 0.24, "f": 0.24, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5454545454545454, "f": 0.4799999999999999, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows two stuffed animals dressed in traditional Japanese clothing. The stuffed animals are dressed in a kimono. The kimono is red."}, "552866": {"image_id": 552866, "Bleu_1": 0.333333333325926, "Bleu_2": 0.19462473603600663, "Bleu_3": 0.12077745418384085, "Bleu_4": 1.4311233929411235e-05, "METEOR": 0.24296461294545682, "ROUGE_L": 0.28073635765943455, "CIDEr": 3.9946510264953874e-08, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06451612903225806, "f": 0.08695652173913043, "fn": 29.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image is a black and white photograph of the Houses of Parliament in London, England. The building is a large, imposing structure with a clock tower in the center. The clock tower is covered in clocks and has a large bell at the top."}, "337083": {"image_id": 337083, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 0.13300573168298876, "Bleu_4": 0.08367437134425945, "METEOR": 0.2634686871302074, "ROUGE_L": 0.2966050186680559, "CIDEr": 7.508222088921624e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a commercial building with a clock tower on top. The building has a green awning over the front door and a sign that reads \"do not enter\". The building is surrounded by trees and has a sidewalk in front of it. A car is parked on the street."}, "304828": {"image_id": 304828, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.15182109665359528, "Bleu_3": 0.10007189813274586, "Bleu_4": 0.06869592482301583, "METEOR": 0.20296355154091433, "ROUGE_L": 0.2616421568627451, "CIDEr": 3.258987884219939e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in a grassy area. The giraffe's legs are not bent. The giraffe's tail is not long. The sun is shining down on the giraffe. A tree is in the background. The image is taken from a bird's eye view."}, "506115": {"image_id": 506115, "Bleu_1": 0.255813953482423, "Bleu_2": 0.17451086522195614, "Bleu_3": 0.1141029906527568, "Bleu_4": 1.388218324422588e-05, "METEOR": 0.25827997510564704, "ROUGE_L": 0.33174711080897346, "CIDEr": 0.0008402283030222756, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.04, "f": 0.041666666666666664, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a group of five people sitting on a bus. They are holding soccer balls in their laps. They are all wearing soccer jerseys. The people are sitting on a bus. \n\nThere is a window on the side of the building."}, "147179": {"image_id": 147179, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.16854996561062321, "Bleu_3": 9.713264480563592e-07, "Bleu_4": 2.3509511060878987e-09, "METEOR": 0.1291906506048808, "ROUGE_L": 0.21235857267188862, "CIDEr": 0.0002352078301945225, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "There are no people in this image. The image shows a living room with a couch. There is no one laying on the couch. There are two pieces of clothing in the room."}, "549718": {"image_id": 549718, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.17238297400489144, "Bleu_4": 0.1324062816098676, "METEOR": 0.27329070696608876, "ROUGE_L": 0.25341246290801184, "CIDEr": 4.351722152498371e-12, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a yellow and blue bus driving down the street. The bus has a large windshield and a small front bumper. The bus is driving on the left side of the road and there are buildings on the right side of the road. There are no other vehicles on the road."}, "160820": {"image_id": 160820, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.20304239863369572, "Bleu_3": 0.09938207498160095, "Bleu_4": 1.2438988916952376e-05, "METEOR": 0.21745328813695744, "ROUGE_L": 0.2924657534246575, "CIDEr": 4.844273309446242e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.23076923076923078, "f": 0.23529411764705882, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of seventeen sheep grazing in a green field. The sheep are white and some have black spots on their backs. The field is surrounded by tall and green trees. \n\nThere are no branches, leaves, or flowers in the scene."}, "517629": {"image_id": 517629, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.16658955971162087, "Bleu_3": 0.12276317177256986, "Bleu_4": 0.09576248453510561, "METEOR": 0.2252018345363229, "ROUGE_L": 0.23404527433175598, "CIDEr": 2.1290322655909555e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a cat sitting in a sink. The cat's fur is white. The sink is made of stainless steel. There is a faucet on the right side of the sink. A white counter is next to the sink. The cat's mouth is open."}, "433277": {"image_id": 433277, "Bleu_1": 0.18749999999707034, "Bleu_2": 0.13363062095410766, "Bleu_3": 0.10483189222810439, "Bleu_4": 0.08675967642623968, "METEOR": 0.2506395705720071, "ROUGE_L": 0.2219334719334719, "CIDEr": 3.4231608871207377e-18, "SPICE": {"All": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a desk with three computer monitors on it. The first two monitors are displaying a picture of a desert, while the third monitor is displaying a desert landscape. There is also a lamp on the desk. The walls are painted brown. There is a window on the left side of the room. A chair is placed in front of the desk."}, "487498": {"image_id": 487498, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.1313579154832357, "Bleu_3": 0.08897106801212075, "Bleu_4": 0.06189082809605832, "METEOR": 0.16108863516894548, "ROUGE_L": 0.1561100447856686, "CIDEr": 5.6236084276639136e-11, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14814814814814814, "f": 0.17391304347826086, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of four people standing under an umbrella in a garden. They are all wearing blue and white striped shirts and black pants. One of the people is holding a cell phone. Another person is holding a laptop. The other two people are also holding cell phones."}, "90640": {"image_id": 90640, "Bleu_1": 0.17142857142612247, "Bleu_2": 0.11145564251346682, "Bleu_3": 0.08183494983780286, "Bleu_4": 0.06359792023009034, "METEOR": 0.19933218079221093, "ROUGE_L": 0.230157660692629, "CIDEr": 6.808363681277791e-20, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of eight elephants walking down the street in the city. The elephants are wearing a hat and a scarf. A person is leading the elephants. The elephants are walking down the street. The elephants are drinking water. The elephants are walking in the water. The elephants are walking in the rain. The elephants are doing a look at the elephants at the San Francisco zoo."}, "470173": {"image_id": 470173, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.19778287446532944, "Bleu_3": 1.0280753730529343e-06, "Bleu_4": 2.3604875051713343e-09, "METEOR": 0.23586462660694624, "ROUGE_L": 0.362555720653789, "CIDEr": 1.1509599155199763e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.10344827586206896, "f": 0.1395348837209302, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a woman standing in front of a statue. The woman is holding a basket. She is wearing a long dress and standing in front of a tree with leaves. The statue is made of bronze."}, "536183": {"image_id": 536183, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 0.07063108368194851, "Bleu_4": 9.57049894254339e-06, "METEOR": 0.16378955200108675, "ROUGE_L": 0.21048999309868874, "CIDEr": 1.4922883626265244e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a pot with vegetables in it. The pot contains beet, broccoli, carrots, and onions. There is no stew in the pot, and there is no lid on the pot. There is no meat, spoon, burner, cutting board, or window in the scene."}, "523597": {"image_id": 523597, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.18299102222839972, "Bleu_4": 0.1358326617524907, "METEOR": 0.2801939777507165, "ROUGE_L": 0.2897862232779097, "CIDEr": 3.2904523189115406e-05, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man riding a motorcycle on a road. The man is wearing a turban on his head and a shirt. He is holding onto the handlebars of the motorcycle. \n\nThere are no trees in the scene."}, "366178": {"image_id": 366178, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2015901948875348, "Bleu_3": 0.09270920944879874, "Bleu_4": 1.1235687646097306e-05, "METEOR": 0.20749926897375576, "ROUGE_L": 0.23894795747062114, "CIDEr": 2.4897006460478484e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.125, "f": 0.12000000000000001, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a road with a yellow sign on the side. The sign has a picture of a person walking on the sidewalk. There are no other cars or people in the image. The sky is cloudy and there is no sunlight. The image is taken from a bird's-eye view."}, "11260": {"image_id": 11260, "Bleu_1": 0.16393442622682078, "Bleu_2": 0.09053574604102199, "Bleu_3": 0.05179200443176847, "Bleu_4": 6.995842782527095e-06, "METEOR": 0.2315907648355557, "ROUGE_L": 0.2729985082048732, "CIDEr": 6.6163572076731575e-15, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a train traveling on a railroad track next to a body of water. The train is silver. The train does not have a number on the side. There are no people or platform in the scene. There is a bridge next to the body of water. The sky is blue and there are no clouds in the sky."}, "92765": {"image_id": 92765, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.11582156166137168, "Bleu_3": 7.006558330325156e-07, "Bleu_4": 1.7345333611892186e-09, "METEOR": 0.20425837483623113, "ROUGE_L": 0.30049261083743845, "CIDEr": 1.0786574363763305e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.3157894736842105, "f": 0.2553191489361702, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a market with a variety of bananas on display. Bananas are also on the table. The people are standing in front of the bananas. Some of the people are talking on the phone. The people are selling food."}, "171936": {"image_id": 171936, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.16012815379904247, "Bleu_3": 1.0084749803102866e-06, "Bleu_4": 2.556795749388759e-09, "METEOR": 0.15029317384795188, "ROUGE_L": 0.19741100323624594, "CIDEr": 0.002592828823256771, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.14285714285714285, "f": 0.12698412698412698, "fn": 24.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.09090909090909091, "f": 0.08, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a stove, sink, and refrigerator. There is a table and four chairs in the kitchen. The floor is made of tile."}, "244401": {"image_id": 244401, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2908872369299581, "Bleu_3": 0.21950939626031343, "Bleu_4": 0.14643937863774928, "METEOR": 0.34885811459081295, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.014528077134865862, "SPICE": {"All": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 28.0, "numImages": 1.0, "fp": 36.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3076923076923077, "f": 0.2580645161290323, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image shows a variety of vegetables arranged on a wooden crate. The vegetables include carrots and tomatoes. The crate is labeled with the words \"CSA\"."}, "534122": {"image_id": 534122, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.19507682662422146, "Bleu_3": 0.09676553259733332, "Bleu_4": 1.2192550254115238e-05, "METEOR": 0.16443017625553374, "ROUGE_L": 0.25702247191011235, "CIDEr": 7.091004060392872e-08, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.3125, "f": 0.2325581395348837, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man standing on the beach, looking out at the ocean. The man is riding a surfboard and looking at a wave. He is standing on a surfboard and wearing blue and white shorts. The man is not wearing a shirt."}, "366099": {"image_id": 366099, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.2915890165723569, "Bleu_3": 0.1977196709641281, "Bleu_4": 0.1157897977621929, "METEOR": 0.2141934440391048, "ROUGE_L": 0.31812255541069095, "CIDEr": 2.396282363900709e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.12903225806451613, "f": 0.16326530612244897, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a pizza with various toppings such as olives and tomatoes on top of a crust. The pizza is placed on a wooden cutting board. \n\nThere are no slices, cheese, or a white tablecloth with a red and white checkered pattern in the image."}, "503135": {"image_id": 503135, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.214984853867146, "Bleu_3": 0.14096477244674038, "Bleu_4": 1.7200673466154932e-05, "METEOR": 0.25280299129375783, "ROUGE_L": 0.2998525315418646, "CIDEr": 0.0003339637382774516, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a police officer riding a motorcycle. The police officer is wearing a helmet. The motorcycle is black and has a blue light on the front. There are people standing on the sidewalk."}, "200807": {"image_id": 200807, "Bleu_1": 0.5897435897284682, "Bleu_2": 0.41317701975515086, "Bleu_3": 0.2642673612635824, "Bleu_4": 0.1504724599649729, "METEOR": 0.28461233564004934, "ROUGE_L": 0.3198501872659176, "CIDEr": 0.0006752552854263807, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a woman standing on a wooden floor. The woman is wearing black and white striped socks. She is also holding a red umbrella and wearing black shoes. The woman is standing in front of a TV."}, "328805": {"image_id": 328805, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.16012815380103265, "Bleu_3": 0.1265001431634541, "Bleu_4": 0.10227637589668918, "METEOR": 0.16351813834424317, "ROUGE_L": 0.2981843575418994, "CIDEr": 9.940692105968234e-05, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.2, "f": 0.16949152542372883, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are beige. The floor is made of tile. There is a door on the left side. The room is well lit. There is no fan on the ceiling."}, "445055": {"image_id": 445055, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.20121090914115636, "Bleu_3": 0.10304662546247204, "Bleu_4": 1.3203823351935061e-05, "METEOR": 0.184606632665633, "ROUGE_L": 0.2601279317697228, "CIDEr": 4.97126831390985e-05, "SPICE": {"All": {"pr": 0.04, "re": 0.05, "f": 0.044444444444444446, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a man and two boys standing on a surfboard in the ocean. The man is holding a surfboard and wearing a wetsuit. The boys are also wearing wetsuits.\n\nThere are no other people in the scene."}, "387223": {"image_id": 387223, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.24494897426831577, "Bleu_3": 0.13766001253722115, "Bleu_4": 1.855667592931768e-05, "METEOR": 0.13214353705467152, "ROUGE_L": 0.28855250709555347, "CIDEr": 0.038877193657562786, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a flock of six sheep grazing on a hillside. The sheep are brown. The river is not frozen. The sky is cloudy."}, "436349": {"image_id": 436349, "Bleu_1": 0.19277108433502685, "Bleu_2": 0.10841740824484335, "Bleu_3": 0.0662085900863061, "Bleu_4": 0.043642865527532056, "METEOR": 0.13621248704813016, "ROUGE_L": 0.17114228456913827, "CIDEr": 1.1391766358542106e-28, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.3181818181818182, "f": 0.3181818181818182, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of six trucks parked on the side of a road. The trucks are painted in various colors and have different designs on them. Some trucks have a statue of liberty on them, while others have a lion on the front. People are seen surrounding the trucks. \n\nThere are four people in the image. Some people are walking in the street, while others are playing a game of chess. \n\nIn the background, there are buildings and a cloudy sky."}, "51335": {"image_id": 51335, "Bleu_1": 0.3387096774138918, "Bleu_2": 0.2686708573917411, "Bleu_3": 0.2034523157050788, "Bleu_4": 0.1545784588126773, "METEOR": 0.3229128424155943, "ROUGE_L": 0.2929562433297759, "CIDEr": 7.699994532855966e-15, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.11538461538461539, "f": 0.13636363636363638, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man sitting at a wooden table with a hot dog in front of him. He is wearing a white shirt and blue pants, and does not have a beard. There are several other people sitting at the table, eating food. The people are eating a donut, a hot dog, a burger, a sandwich, a banana, and a pizza."}, "515531": {"image_id": 515531, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.210720977237338, "Bleu_3": 0.15803538555591157, "Bleu_4": 0.09732010887387402, "METEOR": 0.23848307376331843, "ROUGE_L": 0.2749517063747585, "CIDEr": 4.955772897954881e-08, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.05, "f": 0.04081632653061224, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows two planes flying in front of a full moon. The planes are white and have red tails. The moon is full and appears in the sky. The sky is dark and there are some clouds in the background. The image is taken at night."}, "20371": {"image_id": 20371, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.17890134124348953, "Bleu_3": 0.13868047345555473, "Bleu_4": 0.11110969989555718, "METEOR": 0.24396432821326908, "ROUGE_L": 0.295638126009693, "CIDEr": 8.83343099434617e-06, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09090909090909091, "f": 0.08888888888888888, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a pigeon sitting on a metal ledge. The pigeon has a black and white plumage. Its beak is open. The sky is clear and blue.\n\nThere is no ground or other birds in the scene."}, "180653": {"image_id": 180653, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.22696949467458388, "Bleu_3": 0.10620757885664733, "Bleu_4": 1.2995838594729719e-05, "METEOR": 0.26686843668307053, "ROUGE_L": 0.21585279547062985, "CIDEr": 2.631367807459808e-07, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.20689655172413793, "f": 0.20689655172413793, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two people skiing in the snow. They are wearing ski gear and standing on skis. The man is wearing a black jacket and the woman is wearing a green jacket. They are standing in a snowy forest with trees in the background."}, "373382": {"image_id": 373382, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.13118830932044054, "Bleu_4": 1.7005147775680013e-05, "METEOR": 0.22268892107765464, "ROUGE_L": 0.3726003490401396, "CIDEr": 0.006577885969395052, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.1724137931034483, "f": 0.18867924528301888, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a tennis player serving the ball on a tennis court. The player is wearing white clothing and a green hat. The crowd is watching the tennis match."}, "515642": {"image_id": 515642, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 0.0858725358973738, "Bleu_4": 1.0831815605763862e-05, "METEOR": 0.2823959008182302, "ROUGE_L": 0.26341764342998153, "CIDEr": 1.4080187224835603e-09, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.18181818181818182, "f": 0.20512820512820512, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a remote control sitting on top of a book. The book is open and has a page with writing on it. The remote control has buttons on it and a screen that displays a channel number. The book is on a table next to a toilet."}, "276254": {"image_id": 276254, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 0.09105491676695633, "Bleu_4": 1.1795365411101286e-05, "METEOR": 0.20573334024846995, "ROUGE_L": 0.2469635627530364, "CIDEr": 6.76009780690599e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a view of a small town on the water. There are several boats docked at the shore. The town is on the water. There is a building on the hillside in the background. The sky is clear and blue."}, "332377": {"image_id": 332377, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.07059312079859056, "Bleu_3": 4.953516746581623e-07, "Bleu_4": 1.3202927206769879e-09, "METEOR": 0.14030901519446276, "ROUGE_L": 0.21254355400696864, "CIDEr": 1.523612260345233e-07, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2777777777777778, "f": 0.27027027027027023, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a table with two doughnuts on it. One of the doughnuts is red and the other is blue. There are no cups of coffee on the table. The table is made of wood. The tablecloth on the table is brown."}, "66675": {"image_id": 66675, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 0.08722608547574774, "Bleu_4": 1.0787871557193922e-05, "METEOR": 0.15063150992903496, "ROUGE_L": 0.24653579676674361, "CIDEr": 1.5914288849579875e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a woman and a man standing in a bedroom. The woman is wearing black pants and a black sweater. The man is wearing black pants and a white shirt. They are both holding onto a blanket. The room has a white ceiling.\n\nThere is no wall in the scene."}, "578752": {"image_id": 578752, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.19215378455856627, "Bleu_3": 1.1544156732180946e-06, "Bleu_4": 2.85982660320976e-09, "METEOR": 0.20099097687447257, "ROUGE_L": 0.29158699808795413, "CIDEr": 0.01667678198714462, "SPICE": {"All": {"pr": 0.15, "re": 0.1111111111111111, "f": 0.12765957446808512, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "There is no person in this image. The image shows a beach with calm water. There is no hat, surfboard, sand, or footprints in the scene."}, "411177": {"image_id": 411177, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 0.06923138992163505, "Bleu_4": 9.071482520661878e-06, "METEOR": 0.17519029533763267, "ROUGE_L": 0.22241127856101123, "CIDEr": 3.452230530436454e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.12903225806451613, "f": 0.16326530612244897, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a living room with two couches. The couches are brown and black with brown accents. The walls are painted red. There is a chandelier hanging from the ceiling. \n\nThere is no coffee table, rug, or other furniture in the scene. The materials used for the furniture are not specified."}, "12192": {"image_id": 12192, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.21602468994265056, "Bleu_3": 0.1418983411941997, "Bleu_4": 0.08783602619536428, "METEOR": 0.267405735745862, "ROUGE_L": 0.38065522620904835, "CIDEr": 3.155559105048641e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a boy playing with a tennis racket on the beach. The boy is playing tennis and holding a tennis racket. He is standing in the water. The sky is a deep orange color, with clouds scattered across it. The water is calm and clear, reflecting the beautiful sunset."}, "403657": {"image_id": 403657, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.0953462589224164, "Bleu_3": 5.957256316301674e-07, "Bleu_4": 1.4978640318582358e-09, "METEOR": 0.18983801241476972, "ROUGE_L": 0.1567116249197174, "CIDEr": 2.9015438449600558e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.20833333333333334, "f": 0.21739130434782608, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows five buses driving down the street in front of the Houses of Parliament. One of the buses is red and another one is silver. The buses are traveling in the direction of the camera. There are also two cars on the street."}, "191672": {"image_id": 191672, "Bleu_1": 0.2692307692204142, "Bleu_2": 0.1467598771353111, "Bleu_3": 0.09645716184391705, "Bleu_4": 1.40546132812831e-05, "METEOR": 0.20314164632296206, "ROUGE_L": 0.3131416837782341, "CIDEr": 0.01619010918668811, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two surfers riding a wave on surfboards. The surfers are wearing wetsuits. The wave is breaking and it is like a big wave."}, "461945": {"image_id": 461945, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 0.07063108368194851, "Bleu_4": 9.57049894254339e-06, "METEOR": 0.2333267181037947, "ROUGE_L": 0.2053872053872054, "CIDEr": 3.548322556901355e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.16666666666666666, "f": 0.13953488372093023, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a black shirt and black shorts, and has a tennis racket in his hand.\n\nThere is no grass or trees in the scene.\n\nThe sun is not shining down on the court."}, "502979": {"image_id": 502979, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.10820697408694996, "Bleu_4": 0.07130868363395679, "METEOR": 0.23202182700177626, "ROUGE_L": 0.2482558139534883, "CIDEr": 1.498292130007289e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.35714285714285715, "f": 0.25641025641025644, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person sitting at a table in a restaurant. The person is eating at the restaurant. The person is wearing an apron. The table has a plate of food, a glass of water, and a napkin on it. The tablecloth is white. There are four glasses on the table."}, "43448": {"image_id": 43448, "Bleu_1": 0.5405405405259314, "Bleu_2": 0.4064051736335469, "Bleu_3": 0.26625849179528993, "Bleu_4": 0.1825430784848915, "METEOR": 0.29037958765178384, "ROUGE_L": 0.39557385486361296, "CIDEr": 0.01423231735915722, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.26666666666666666, "f": 0.28571428571428575, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows two elephants standing on a rocky beach with trees in the background. The elephants are brown and have tusks. They are standing next to each other and appear to be looking at a rock."}, "55022": {"image_id": 55022, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.0922138891935132, "Bleu_3": 5.655855085604915e-07, "Bleu_4": 1.4082645504822834e-09, "METEOR": 0.14356620099976258, "ROUGE_L": 0.15752098127824402, "CIDEr": 9.135941521040576e-11, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.14285714285714285, "f": 0.15789473684210528, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows two bicycles parked in front of a store. There is no sign in front of the store. \n\nThe first bicycle is white and the second bicycle is pink. The handlebars of the bicycles are black. The seat is black and the tires are black and white."}, "204661": {"image_id": 204661, "Bleu_1": 0.18333333333027782, "Bleu_2": 0.16723068406837055, "Bleu_3": 0.14249022200723366, "Bleu_4": 0.11936722048418758, "METEOR": 0.29980036802384474, "ROUGE_L": 0.26236559139784943, "CIDEr": 1.9145969832327237e-15, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.21428571428571427, "f": 0.21428571428571427, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a person holding a cell phone in their hand. The phone has a touch screen and a keyboard on the front. There are no other electronic devices on the table. \n\nThere is no laptop or printer in the scene.\n\nThe person is not wearing a white shirt or black pants.\n\nThe background is a dark brown color."}, "259983": {"image_id": 259983, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.15450054281980155, "Bleu_3": 0.10224344881149082, "Bleu_4": 1.1280819074427685e-05, "METEOR": 0.2449154900362987, "ROUGE_L": 0.2329037976409627, "CIDEr": 1.1477526227899117e-19, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.23076923076923078, "f": 0.18749999999999997, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a white kitchen with a stove and oven. The stove has a gas burner on top and a frying pan and pot on top. There is a knob on the side of the stove. The oven has an open door. There are pots and pans on the counter, and a jug of water on the counter. \n\nThere is no dish rack or sink in the kitchen."}, "343561": {"image_id": 343561, "Bleu_1": 0.15909090908729343, "Bleu_2": 0.08602079496655897, "Bleu_3": 5.605992826915985e-07, "Bleu_4": 1.4397710576737564e-09, "METEOR": 0.12817664367837867, "ROUGE_L": 0.1644204851752022, "CIDEr": 2.1574902287231177e-08, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2857142857142857, "f": 0.34285714285714286, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8571428571428571, "re": 0.6, "f": 0.7058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}}, "caption": "The image shows two cyclists riding on a road. The cyclists are doing a race. They are wearing blue and yellow jerseys and blue and white shorts. They are wearing white and black shoes. The cyclists are riding in a peloton on the road."}, "559665": {"image_id": 559665, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.15191090505870355, "Bleu_3": 0.08468336402372788, "Bleu_4": 1.1318741601733969e-05, "METEOR": 0.1963803976271695, "ROUGE_L": 0.22426470588235295, "CIDEr": 2.630488762645482e-06, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a man riding a motorcycle on the side of the road. The man is wearing a helmet on his head. He is also wearing a black leather jacket. \n\nThere are three cars passing by on the road."}, "137003": {"image_id": 137003, "Bleu_1": 0.08974358974243919, "Bleu_2": 0.07633810206807237, "Bleu_3": 0.053526195167715125, "Bleu_4": 0.03781459593307451, "METEOR": 0.16306341150860673, "ROUGE_L": 0.16353887399463807, "CIDEr": 5.680323038588463e-29, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.28, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows two girls in a field. One girl is holding a kite and the other girl is holding a red frisbee. The girl holding the kite is wearing a blue and white striped shirt and blue jeans. The girl holding the frisbee is also wearing blue jeans. The kite is made of plastic and does not have a long tail. The field is green and there are no trees in the scene. The sky is blue."}, "338203": {"image_id": 338203, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.10938412714447902, "Bleu_4": 0.07516571016334685, "METEOR": 0.24755143068310298, "ROUGE_L": 0.25318206972883234, "CIDEr": 3.233308173336107e-07, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.2, "f": 0.18750000000000003, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a bird with brown and black feathers perched on a tree branch. The bird has a beak and sharp talons. The bird is sitting on the tree branch. The tree is tall and thin with many branches. The background is grass."}, "238691": {"image_id": 238691, "Bleu_1": 0.16393442622682078, "Bleu_2": 0.11688114555111409, "Bleu_3": 0.06140621126315898, "Bleu_4": 7.948812054269162e-06, "METEOR": 0.13496533326615207, "ROUGE_L": 0.16495402920497565, "CIDEr": 4.059982621678667e-16, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.125, "f": 0.13793103448275862, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.2857142857142857, "f": 0.2758620689655172, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a group of six people standing in a terminal. Some of the people are sitting on a luggage carousel, while others are walking or talking on the phone. There are no people in a line. The people are carrying luggage, including suitcases. The floor is made of beige tiles. There are no sunglasses or signs in the scene."}, "454610": {"image_id": 454610, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.14564381624761055, "Bleu_3": 7.901421228222159e-07, "Bleu_4": 1.8512564664694888e-09, "METEOR": 0.13509171517259014, "ROUGE_L": 0.168391994478951, "CIDEr": 3.41032654256705e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of two people standing on a boat in a river. The boat is filled with guavas. There are baskets containing fruit, vegetables, and a stuffed animal. The people are wearing blue skirts, blue jeans, and a pair of blue jeans."}, "163057": {"image_id": 163057, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.18171094607444632, "Bleu_3": 0.12476834639035371, "Bleu_4": 0.07894703307415313, "METEOR": 0.1648303350655323, "ROUGE_L": 0.28103661044837513, "CIDEr": 6.215593244825242e-11, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.07407407407407407, "f": 0.07017543859649124, "fn": 25.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of five people playing with kites in a park. The kites are made of plastic and have different shapes and colors. The people are standing on the grass and holding the kites with their hands. There are seven trees in the background and a building in the distance."}, "493623": {"image_id": 493623, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.09875106606632027, "Bleu_3": 5.962685701989571e-07, "Bleu_4": 1.4732563104646528e-09, "METEOR": 0.16869085530985525, "ROUGE_L": 0.1601049868766404, "CIDEr": 1.1161796824101334e-09, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.25, "f": 0.3111111111111111, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows two women standing in front of a white wall. One of the women is holding a brush. They are both wearing white dresses. On the floor, there is a pink flower arrangement and two clear vases. The wall has a white and gray striped pattern."}, "564940": {"image_id": 564940, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.26967994497923586, "Bleu_3": 0.15011345265055326, "Bleu_4": 1.684621689260239e-05, "METEOR": 0.2634898670308504, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.2193190414343696e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.23529411764705882, "f": 0.22857142857142856, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of three stuffed animals sitting on a table. They are all wearing white shirts with the word \"Teddy bears\" written on them.\n\nThe stuffed animals are all different sizes and shapes. They are sitting in a row on the table."}, "423229": {"image_id": 423229, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.10619884880883856, "Bleu_3": 0.05896925524327533, "Bleu_4": 7.850020523433245e-06, "METEOR": 0.14775290167794314, "ROUGE_L": 0.17086834733893558, "CIDEr": 3.961373339455921e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a train traveling down the tracks. There are people on board. The train is not pulling into a station. The train is made of metal. The train has a smoke stack. \n\nThere is a sign that says \"speed limit 10 miles per hour\".\n\nThere is no town, wood, hats, or coats in the scene."}, "412571": {"image_id": 412571, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.09672659665842727, "Bleu_4": 1.1657633846364334e-05, "METEOR": 0.1751465916001113, "ROUGE_L": 0.18780788177339902, "CIDEr": 8.634240878868644e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.16666666666666666, "f": 0.17543859649122806, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a table with a variety of donuts on it. The donuts are arranged in a stack on the table. There is also a cupcake on the table. The table is covered in a white tablecloth. There are candles on the table.\n\nThe donuts are arranged on a three-tier stand."}, "217760": {"image_id": 217760, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.2182178902280546, "Bleu_3": 0.12234957142600307, "Bleu_4": 1.645192939931118e-05, "METEOR": 0.24495880103709, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.008205125451233081, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.20689655172413793, "f": 0.20689655172413793, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image is a black leather case with a zipper on the top and a pair of scissors inside. The scissors are not open. The case is empty."}, "579893": {"image_id": 579893, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.16447838792810768, "Bleu_3": 0.10713507226754848, "Bleu_4": 0.07312765318865694, "METEOR": 0.22178575292115374, "ROUGE_L": 0.27619663648124193, "CIDEr": 7.067734754204817e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"stop\" and \"village\" written on it. The sign is on a tree lined street. The sky is blue and there are clouds in the background.\n\nThe image is taken in the fall season with the leaves changing."}, "5965": {"image_id": 5965, "Bleu_1": 0.19999999999500007, "Bleu_2": 0.12403473458606787, "Bleu_3": 7.397773249928141e-07, "Bleu_4": 1.8187597339048352e-09, "METEOR": 0.1475177304964539, "ROUGE_L": 0.17941176470588235, "CIDEr": 1.4444202279738282e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a motorcycle parked in front of a building with a sign that reads \"United Country All Arizona Realty\" and \"Crown King Customs Made in USA\". The motorcycle is black. The rider is wearing sunglasses and a helmet."}, "107375": {"image_id": 107375, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.15569978882944752, "Bleu_3": 0.09707559423882012, "Bleu_4": 1.1516796881559118e-05, "METEOR": 0.18302796547675307, "ROUGE_L": 0.21095100864553315, "CIDEr": 4.425878367938085e-13, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.14814814814814814, "f": 0.13333333333333333, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.23076923076923078, "f": 0.22222222222222224, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image features a dog standing on a tree stump. The dog is running with a bottle. The dog is wearing a collar. The dog's fur is soft. The dog is standing in the middle of a dirt path surrounded by trees and bushes. The dog's eyes are looking up at the camera."}, "115721": {"image_id": 115721, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.16256402218685123, "Bleu_3": 0.08569060201339629, "Bleu_4": 1.1130224679490435e-05, "METEOR": 0.195856099962485, "ROUGE_L": 0.25702247191011235, "CIDEr": 8.24797311870824e-08, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.21739130434782608, "f": 0.18518518518518517, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a dog lying on a couch with its head resting on its paws. The dog is wearing a red collar and has a tag on its neck. The background is a dark brown color with a pattern of small, white dots."}, "493509": {"image_id": 493509, "Bleu_1": 0.35714285713647964, "Bleu_2": 0.161164592802172, "Bleu_3": 7.835171438538424e-07, "Bleu_4": 1.7356710121002362e-09, "METEOR": 0.16186193092505644, "ROUGE_L": 0.14153132250580044, "CIDEr": 4.0112084999089146e-12, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.10526315789473684, "f": 0.09523809523809525, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows three people wearing yellow safety vests and hard hats standing in front of a building with a large window on the side. They are holding laptops and looking at a laptop computer. The people are looking at a construction site. A construction worker and a woman in a yellow vest are visible outside."}, "507797": {"image_id": 507797, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.18227065413983304, "Bleu_3": 0.14799142306854177, "Bleu_4": 0.09487732070683391, "METEOR": 0.1974109888374136, "ROUGE_L": 0.30521801286633315, "CIDEr": 1.5342323335874575e-07, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.1875, "f": 0.13333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of seven people standing in front of a bus. They are wearing pink shirts and white pants. \n\nThere are no women, purses, or suitcases in the scene. \n\nThe bus is white with a blue stripe down the side."}, "512830": {"image_id": 512830, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 0.0858725358973738, "Bleu_4": 1.0831815605763862e-05, "METEOR": 0.24916197440354756, "ROUGE_L": 0.27566171723692706, "CIDEr": 4.065287923517155e-10, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.19047619047619047, "f": 0.21052631578947367, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a group of 16 people sitting in an airplane. Some of the people are eating, some are sleeping, and others are talking on the phone. One man is looking at the camera. The people are wearing military uniforms. \n\nThere are no other people in the plane."}, "69969": {"image_id": 69969, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.08058229640108601, "Bleu_3": 0.04935848712474826, "Bleu_4": 6.901641753463998e-06, "METEOR": 0.149600585158633, "ROUGE_L": 0.17784256559766765, "CIDEr": 6.105428679826356e-14, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a room with wooden tables and chairs. There are several people sitting at the tables, enjoying their meals. The walls are made of wood and there are windows on one side of the room that let in natural light. The floor is made of wood and there are no rugs in the room."}, "420466": {"image_id": 420466, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.17890134124348953, "Bleu_3": 0.12114855245115345, "Bleu_4": 1.5013144369943999e-05, "METEOR": 0.18141533121257394, "ROUGE_L": 0.2733791455034359, "CIDEr": 9.499635363101138e-06, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.2857142857142857, "f": 0.3137254901960784, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.46153846153846156, "f": 0.5454545454545455, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a giraffe walking on a grassy hillside. The giraffe is a tall animal with spots. It has a long and slender neck and long and skinny legs. The giraffe is walking on the grassy hillside."}, "529850": {"image_id": 529850, "Bleu_1": 0.11881188118694247, "Bleu_2": 0.0844317053667949, "Bleu_3": 0.04160306327562611, "Bleu_4": 5.206399182748102e-06, "METEOR": 0.14196073950097388, "ROUGE_L": 0.16618827535879346, "CIDEr": 2.486671462506154e-49, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man sitting on the floor next to a suitcase. He is petting a black cat that is sitting on the suitcase. The man is wearing a tan shirt and blue pants. The cat is wearing a brown collar. The room has white countertops and a white refrigerator.\n\nThe man is sitting on the floor next to a suitcase. He is petting a black cat that is sitting on the suitcase. The man is wearing a white shirt and black pants. The cat is wearing a red collar. The room has a white countertop and a white refrigerator."}, "397842": {"image_id": 397842, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.09897882079639587, "Bleu_3": 5.769942141601625e-07, "Bleu_4": 1.400025972732928e-09, "METEOR": 0.16585747250445976, "ROUGE_L": 0.21266705403834982, "CIDEr": 4.247615131136533e-12, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.14285714285714285, "f": 0.09090909090909091, "fn": 12.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a dog playing fetch in a backyard. The dog is brown and white with a long, fluffy coat. It is running towards the camera with its tongue hanging out of its mouth. The dog is wearing a collar and tag on its neck. The background is a green grassy field."}, "48555": {"image_id": 48555, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.0986616396109014, "Bleu_4": 1.1893260654292823e-05, "METEOR": 0.22247349772324668, "ROUGE_L": 0.15259537210756724, "CIDEr": 2.8683698633492815e-11, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows four horses doing racing on a beach. The horses are wearing jockeys' hats and jockeys. The sky is cloudy and there are waves crashing on the shore.\n\nThere is no ocean in the scene.\n\nThe image is in black and white and has a vintage feel to it."}, "51938": {"image_id": 51938, "Bleu_1": 0.19444444444174383, "Bleu_2": 0.11701824958159822, "Bleu_3": 0.09214880665352936, "Bleu_4": 0.05803032647083616, "METEOR": 0.13789116771554177, "ROUGE_L": 0.19768518518518519, "CIDEr": 4.1472398136068495e-22, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.05555555555555555, "f": 0.05714285714285714, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows four people skiing down a snowy slope. One person is skiing on a snowboard, while the others are skiing with a pair of skis in their hands. The person wearing a white shirt is skiing down a snowy hill. The person wearing a blue jacket is skiing down a slope. The person wearing blue pants is skiing on a snowy slope and holding a snowboard. The sky is blue."}, "380516": {"image_id": 380516, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.16817499303272468, "Bleu_3": 0.08696639352820397, "Bleu_4": 1.118668148397708e-05, "METEOR": 0.291565444789966, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.40672783861901e-08, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09523809523809523, "f": 0.08888888888888889, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a boy playing tennis on a blue court. He is wearing a white and blue shirt and white shorts, and has a tennis racket in his hand.\n\nThere is a fence surrounding the court.\n\nThere are no other people in the scene."}, "461009": {"image_id": 461009, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.22549380839705863, "Bleu_3": 0.1636579416200959, "Bleu_4": 0.11136317349594806, "METEOR": 0.25998341587474083, "ROUGE_L": 0.28955696202531644, "CIDEr": 9.402187489863815e-16, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.18518518518518517, "f": 0.18181818181818182, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man holding an apple in his hand. The man is wearing a blue shirt. The background is a blurred image of five people. Some of the people are eating, some are playing a game, some are standing in front of a mirror, some are sitting in a room, and a woman is holding a diamond ring."}, "262323": {"image_id": 262323, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.24447927302426964, "Bleu_3": 1.287583353288884e-06, "Bleu_4": 2.981882827002783e-09, "METEOR": 0.24884986070939888, "ROUGE_L": 0.32735357252376573, "CIDEr": 0.015723927297589965, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 15.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a giraffe standing in the grass. The giraffe has spots on its fur. An ostrich is standing next to the giraffe. The zookeeper is holding a giraffe."}, "236049": {"image_id": 236049, "Bleu_1": 0.29999999999500004, "Bleu_2": 0.20168779363245437, "Bleu_3": 0.14103613869021897, "Bleu_4": 0.0996062504508171, "METEOR": 0.21729611739302937, "ROUGE_L": 0.2952973720608575, "CIDEr": 2.882683442714776e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a building with a large window on the side. There is a bird perched in the window, looking out. The building appears to be a stone building, resembling a church. It does not have a lot of damage.\n\nThe bird is flying and looking out of the window. The building is the church of the Holy Sepulchre."}, "373374": {"image_id": 373374, "Bleu_1": 0.222222222217284, "Bleu_2": 0.1421338109005459, "Bleu_3": 0.07773956660946078, "Bleu_4": 1.028417039620613e-05, "METEOR": 0.171637234489378, "ROUGE_L": 0.24063116370808676, "CIDEr": 3.669109093766323e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two plates of food on a table. There is a cup of coffee and a fork on the table as well. However, there is no knife, sandwich, shrimp, lettuce, bun, glass, or juice in the image.\n\nThe background is a green landscape."}, "225603": {"image_id": 225603, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.12183925606190008, "Bleu_3": 7.375490665399666e-07, "Bleu_4": 1.827122068083466e-09, "METEOR": 0.16491862567811938, "ROUGE_L": 0.18277153558052436, "CIDEr": 1.0785118186366446e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.25925925925925924, "f": 0.2545454545454545, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a plate of food with a steak on top and fries on the side. There is a glass of wine on the table. The tablecloth is black. There is no bottle or shelf in the scene."}, "528729": {"image_id": 528729, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 9.566001321761773e-07, "Bleu_4": 2.2206095448570952e-09, "METEOR": 0.17147413755774354, "ROUGE_L": 0.28870858688302903, "CIDEr": 5.015732170753518e-05, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.10526315789473684, "f": 0.07999999999999999, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a man riding a bicycle on the sidewalk. He is wearing a gray shirt and blue pants. The bicycle has an orange frame and black tires. There are cars parked on the street in the background."}, "317070": {"image_id": 317070, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.23204774044025306, "Bleu_3": 0.11231998333584281, "Bleu_4": 1.3989182687371184e-05, "METEOR": 0.25072667124802, "ROUGE_L": 0.27199762187871585, "CIDEr": 2.118364364142036e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person surfing on a surfboard in the ocean. The person is wearing a black wetsuit and holding onto a rope. The sky is cloudy. There are waves in the ocean. The person is in the water."}, "102331": {"image_id": 102331, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.11322770341159263, "Bleu_3": 6.961571161674678e-07, "Bleu_4": 1.737720878510907e-09, "METEOR": 0.1917478344010927, "ROUGE_L": 0.22426470588235295, "CIDEr": 1.815034270907361e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person riding a dirt bike and jumping over a sand dune. The person is wearing a green jersey, black pants, and a helmet on their head. The background depicts a desert landscape with a dirt track."}, "450452": {"image_id": 450452, "Bleu_1": 0.16393442622682078, "Bleu_2": 0.10454167469613528, "Bleu_3": 0.05700447690270919, "Bleu_4": 7.517522301868357e-06, "METEOR": 0.12835992977491772, "ROUGE_L": 0.16180371352785144, "CIDEr": 5.206347824320358e-16, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a clock hanging from a pole on a dilapidated building. The clock has a cracked face and the hands are broken. The building is in a slum condition. There is a window on the building, but it is not broken. There is no graffiti on the building.\n\nThe image is taken in a run-down area of a city."}, "503292": {"image_id": 503292, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.19462473603439093, "Bleu_3": 1.0690830888031079e-06, "Bleu_4": 2.5262613697893535e-09, "METEOR": 0.21248226463757322, "ROUGE_L": 0.24796747967479674, "CIDEr": 0.0005075187721008181, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.16, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a plane taking off from a runway. The plane is a Delta Airlines plane. It is a large jet and has a blue tail and red, white, and blue wings."}, "542248": {"image_id": 542248, "Bleu_1": 0.30508474575754096, "Bleu_2": 0.17765272567537807, "Bleu_3": 0.10345852841494688, "Bleu_4": 1.1858444239827323e-05, "METEOR": 0.2237983775214409, "ROUGE_L": 0.2644576914144151, "CIDEr": 1.0935550293755933e-13, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.09375, "f": 0.12244897959183672, "fn": 29.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a giraffe standing in a field surrounded by tall trees. The giraffe is brown and black with white spots on its back and legs. It is walking and looking at a tree. The giraffe's head is tilted to the left. The trees have branches and leaves. The overall scene is filled with trees and grass."}, "251019": {"image_id": 251019, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.30954614409873055, "Bleu_3": 0.267604614229991, "Bleu_4": 0.22263659306313088, "METEOR": 0.2929490261124995, "ROUGE_L": 0.31077147016011636, "CIDEr": 8.549941140949004e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.13636363636363635, "f": 0.16216216216216214, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man in a red shirt and black shorts playing tennis. He is holding a tennis racket. The man is playing tennis. The ball and the court are not visible in the image. The background consists of gray clouds."}, "48738": {"image_id": 48738, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.09897433185907906, "Bleu_3": 0.058875504281777555, "Bleu_4": 8.117578843784569e-06, "METEOR": 0.1878588442162484, "ROUGE_L": 0.23252858958068615, "CIDEr": 4.231754651638927e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a bighorn sheep standing on a rocky outcropping in the mountains. The sheep has a large horn on its head and is looking directly at the camera. The background is a blue sky with snow-covered mountains in the distance.\n\nThere is no other sheep in the scene."}, "22759": {"image_id": 22759, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 0.10779918441726229, "Bleu_4": 0.07263709682333025, "METEOR": 0.24071313162872832, "ROUGE_L": 0.27371794871794874, "CIDEr": 2.234507194033431e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a cat lying on a bed. A white pillow is under the cat's head. The cat is brown and white. The cat does not have a black spot on its nose. The bed has a paisley pattern. A white wall is in the background."}, "577065": {"image_id": 577065, "Bleu_1": 0.28358208954800623, "Bleu_2": 0.16056210623468745, "Bleu_3": 0.07347240434719365, "Bleu_4": 8.872544691900009e-06, "METEOR": 0.21608260999952242, "ROUGE_L": 0.18309154577288642, "CIDEr": 5.658229637605411e-21, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of four zebras grazing in a grassy field. The zebras are black and white with white stripes on their backs. They are walking in the grass. Some of the zebras are black and white, while others are gray and white. \n\nThere is a fenced area where the zebras are standing. The clearing is surrounded by trees. The sky is blue and cloudy."}, "116461": {"image_id": 116461, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.269724531227751, "Bleu_3": 0.1409145534273607, "Bleu_4": 1.8290765605004157e-05, "METEOR": 0.24816291400036175, "ROUGE_L": 0.43109540636042404, "CIDEr": 0.008221423558905247, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.08, "f": 0.07407407407407408, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.06666666666666667, "re": 0.09090909090909091, "f": 0.07692307692307691, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}}, "caption": "The image shows a pizza with cheese, pepperoni, and mushrooms on top. There is a knife on the side of the plate. The plate is on a table."}, "7214": {"image_id": 7214, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.21997067252504504, "Bleu_3": 1.172742786111253e-06, "Bleu_4": 2.730879756608669e-09, "METEOR": 0.2622853919885064, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.0010736361246824725, "SPICE": {"All": {"pr": 0.4583333333333333, "re": 0.39285714285714285, "f": 0.4230769230769231, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 11.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.9, "re": 0.8181818181818182, "f": 0.8571428571428572, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 9.0}}, "caption": "The image is of a bathroom with a toilet, sink, and mirror. The walls are green. There is a window without blinds. \n\nThere is no rug, floor, or wood in the scene."}, "264336": {"image_id": 264336, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.27602622372916485, "Bleu_3": 0.2237676280726019, "Bleu_4": 0.1786486639029365, "METEOR": 0.37083718651712366, "ROUGE_L": 0.4236111111111111, "CIDEr": 0.00016409386464010146, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.08333333333333333, "f": 0.10169491525423728, "fn": 33.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.1875, "f": 0.2222222222222222, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person riding a bicycle on a path through a park. The person is wearing a red jacket and does not have a backpack on their back. The path is lined with trees."}, "91994": {"image_id": 91994, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.3253956867185506, "Bleu_3": 0.23412971962240928, "Bleu_4": 0.14151579458703112, "METEOR": 0.28143743486290607, "ROUGE_L": 0.3918779396581393, "CIDEr": 0.0002372097379198763, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a desk. He is wearing a black shirt. In front of the man, there is a computer with a black screen. The man is holding a pink pen."}, "222831": {"image_id": 222831, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.1769023808359136, "Bleu_3": 9.543806343349585e-07, "Bleu_4": 2.23241125117263e-09, "METEOR": 0.17455028426622152, "ROUGE_L": 0.30897250361794504, "CIDEr": 4.0749842217237485e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.25, "f": 0.22727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a white shelf with a mug, a book, and a purse on it. There are two vases on the shelf. The vases are white and tan, respectively, and each has a ribbon tied around it."}, "167122": {"image_id": 167122, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 0.12461581769751784, "Bleu_4": 0.07848512144891003, "METEOR": 0.24943585484194541, "ROUGE_L": 0.23961840628507297, "CIDEr": 5.006165837148013e-11, "SPICE": {"All": {"pr": 0.1875, "re": 0.10714285714285714, "f": 0.13636363636363635, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a car parked in front of a building at night. The car's headlights are on. However, the driver is not sitting inside the car. The building has a sign that reads, \"no smoking\". The image is taken at night, and the only light source is from the car's headlights."}, "561699": {"image_id": 561699, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.23401985301353292, "Bleu_3": 0.16587262571559727, "Bleu_4": 0.12707833834389295, "METEOR": 0.25426457893214194, "ROUGE_L": 0.3351648351648352, "CIDEr": 5.719111397336656e-06, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.22727272727272727, "f": 0.25, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a pizza with red sauce and cheese on top of a white plate. The pizza has a brown crust. There is cheese and pepperoni on top of the pizza. The plate is on the table."}, "144932": {"image_id": 144932, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.09415544714235627, "Bleu_3": 5.776228382887613e-07, "Bleu_4": 1.4385671494946425e-09, "METEOR": 0.19665841612457424, "ROUGE_L": 0.22426470588235295, "CIDEr": 4.075161884114594e-09, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.13333333333333333, "f": 0.18750000000000003, "fn": 39.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.3125, "f": 0.39999999999999997, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows two boats in the water. The first boat is a tug boat. There is no person standing on the boat. The second boat is the spooky story of the st johns river 0. There is no person standing on the boat. The water is moving."}, "267321": {"image_id": 267321, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.32566947362944193, "Bleu_3": 0.2173224313183697, "Bleu_4": 0.16173559164392098, "METEOR": 0.23881276008543653, "ROUGE_L": 0.44688644688644685, "CIDEr": 0.08223144305699048, "SPICE": {"All": {"pr": 0.5, "re": 0.13043478260869565, "f": 0.20689655172413793, "fn": 20.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.42857142857142855, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "The image shows a living room with a couch, a chair, and a window on the left side of the room. The walls are white. There is a plant on the coffee table."}, "47837": {"image_id": 47837, "Bleu_1": 0.15909090908910126, "Bleu_2": 0.12828749062323852, "Bleu_3": 0.09147660823248924, "Bleu_4": 0.06514563288703293, "METEOR": 0.20189072353461496, "ROUGE_L": 0.18798151001540836, "CIDEr": 2.3024253843905571e-32, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.14285714285714285, "f": 0.1395348837209302, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of four people sitting at a table. The table is made of wood. The tablecloth is white. The people are wearing casual clothing. The people are eating a meal. \n\nThere is a window behind the people. A wooden wall is visible through the window. A woman holding a plate can be seen from the window.\n\nThere is no deck in the scene.\n\nThere is no person in the scene.\n\nThere is no woods in the scene.\n\nThere is no wood in the scene."}, "119802": {"image_id": 119802, "Bleu_1": 0.22222222221604945, "Bleu_2": 2.5197631533238555e-09, "Bleu_3": 5.7158414685455824e-12, "Bleu_4": 2.7427210913150684e-13, "METEOR": 0.1624340954709201, "ROUGE_L": 0.22897897897897898, "CIDEr": 2.233583157530907e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21052631578947367, "f": 0.21621621621621623, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a pink stuffed animal sitting on the sidewalk next to a streetlight. The animal is pink and has a bow on its head. There are no other cars or people in the image."}, "186624": {"image_id": 186624, "Bleu_1": 0.22535211267288235, "Bleu_2": 0.17021704690637807, "Bleu_3": 0.12804884701264788, "Bleu_4": 0.07454259818939324, "METEOR": 0.27402170963471084, "ROUGE_L": 0.19453302961275623, "CIDEr": 3.293811776596706e-22, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15789473684210525, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a train parked in a room with a metal ceiling. The train is green and black. The train has a rectangular body and a black smoke stack at the front. \n\nThere is no cab in the image. \n\nThere is no person in the image. \n\nThere is a person wearing a hat and holding a bag standing next to the train. \n\nThere are no other people in the image."}, "43345": {"image_id": 43345, "Bleu_1": 0.15909090908729343, "Bleu_2": 0.10535352746832051, "Bleu_3": 6.417259832622543e-07, "Bleu_4": 1.593368598035355e-09, "METEOR": 0.20229520895590794, "ROUGE_L": 0.2197406340057637, "CIDEr": 1.6342346192867873e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2631578947368421, "f": 0.23809523809523808, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a dog sitting on a laptop computer. The dog is brown and white. The dog is looking at the laptop. The laptop has a white screen and a black keyboard. The dog is wearing a collar with a ring on it."}, "260802": {"image_id": 260802, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.14685945835002273, "Bleu_4": 0.11800699061814818, "METEOR": 0.2506980389771165, "ROUGE_L": 0.28773584905660377, "CIDEr": 5.994612157809657e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08695652173913043, "f": 0.0909090909090909, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man playing tennis on a clay court. The man is wearing a blue shirt and white shorts. He is holding a tennis racket and is about to hit the ball with his left hand. The ball is flying through the air and is about to hit the ground."}, "225537": {"image_id": 225537, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.11144846405416943, "Bleu_4": 0.07622713576923955, "METEOR": 0.21709076564040108, "ROUGE_L": 0.24465240641711228, "CIDEr": 5.906576721527527e-08, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2, "f": 0.1886792452830189, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a laptop sitting on a table. The laptop has a screen and a keyboard. The screen is black. The keyboard belongs to the laptop. The mouse is located on the keyboard.\n\nThere is no window, tree, or building in the scene."}, "533548": {"image_id": 533548, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.14793835438670558, "Bleu_4": 0.09209953959056319, "METEOR": 0.3165056675305648, "ROUGE_L": 0.31282051282051276, "CIDEr": 1.1147884071228912e-08, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.3333333333333333, "f": 0.2978723404255319, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a man sitting on a desk in a library. The man is wearing a red jacket and is working on a laptop. There are two laptops on the desks. The man is surrounded by books on the desk. The man is using a laptop computer."}, "120783": {"image_id": 120783, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.17425375883480393, "Bleu_3": 0.09362407257485933, "Bleu_4": 1.228754217003654e-05, "METEOR": 0.23803381546973473, "ROUGE_L": 0.3559445660102115, "CIDEr": 4.2298442290542604e-05, "SPICE": {"All": {"pr": 0.16, "re": 0.13333333333333333, "f": 0.14545454545454545, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a woman holding a bunch of bananas. She is wearing a gray dress and has a tattoo on her arm. The background consists of white walls.\n\nThere is no camera, window, or door in the scene."}, "574823": {"image_id": 574823, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.10158210507506187, "Bleu_4": 0.06733182132555685, "METEOR": 0.2278007330061761, "ROUGE_L": 0.25507765830346474, "CIDEr": 1.677757110365838e-11, "SPICE": {"All": {"pr": 0.3125, "re": 0.23809523809523808, "f": 0.27027027027027023, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows four baseball players standing on the field. The baseball player is holding a baseball glove. The baseball player is holding a bat. The baseball player is wearing a red jersey and black pants. The baseball player is standing on the grass.\n\nThere is no umpire, shirt, or plate in the scene."}, "455301": {"image_id": 455301, "Bleu_1": 0.340909090901343, "Bleu_2": 0.21810252258335, "Bleu_3": 0.1313310331806951, "Bleu_4": 0.08621434964642649, "METEOR": 0.2660271942141532, "ROUGE_L": 0.29756097560975614, "CIDEr": 2.033743761323382e-06, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a girl sitting on a bed, reading a book. The girl is wearing a white dress. The mother is lying next to her baby, holding her baby. The mother is wearing a white dress and has a white sheet over her."}, "463498": {"image_id": 463498, "Bleu_1": 0.1846153846125444, "Bleu_2": 0.15191090506019467, "Bleu_3": 0.1031936251285733, "Bleu_4": 0.06488461462565365, "METEOR": 0.20255189602916793, "ROUGE_L": 0.2497258571533007, "CIDEr": 6.78376734073198e-19, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.21052631578947367, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a living room with two rugs on the floor. There is a couch and three chairs in the corner of the room. There is a fireplace in the corner of the room and a window on the opposite side. The walls are painted a light color. There are no curtains or additional windows in the room. A chair is in the corner."}, "132362": {"image_id": 132362, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.19999999999603923, "Bleu_3": 0.11775100856360317, "Bleu_4": 1.3580418932543062e-05, "METEOR": 0.23024819918170572, "ROUGE_L": 0.2238532110091743, "CIDEr": 4.124210613661802e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.17647058823529413, "f": 0.14285714285714282, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a table set with several bowls of food, including guacamole, salad, and noodles. There is also a bowl of salsa on the table. The table is set with white plates and brown tablecloths. There are glasses of beer on the table. The color of the beer is green."}, "496198": {"image_id": 496198, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.12629784955337583, "Bleu_4": 1.4627961137305314e-05, "METEOR": 0.28306350342063735, "ROUGE_L": 0.2749517063747585, "CIDEr": 3.368605950691947e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two buildings, both with a clock tower on top. The buildings are schools. There are several people standing in front of the building. Some of the people are looking at a fire truck. The windows are located on the second floor of the building."}, "227830": {"image_id": 227830, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.23008949664965453, "Bleu_3": 0.1864588148443747, "Bleu_4": 0.16120161235009695, "METEOR": 0.2740658509012894, "ROUGE_L": 0.29847094801223245, "CIDEr": 1.995641963628004e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a white truck with the words \"Miller lite\" written on the side. The truck is parked in front of a gas station with a sign that reads \"Great taste\" on it. There are several cars parked in the parking lot. \n\nThere is no person outside the gas station."}, "440528": {"image_id": 440528, "Bleu_1": 0.21249999999734373, "Bleu_2": 0.15559196881228998, "Bleu_3": 6.770591057441481e-07, "Bleu_4": 1.4169262827715122e-09, "METEOR": 0.16836795853322672, "ROUGE_L": 0.18279109589041095, "CIDEr": 1.996144041705563e-30, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.16216216216216217, "f": 0.2, "fn": 31.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.058823529411764705, "f": 0.08695652173913045, "fn": 16.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a cake with a swirl of chocolate icing pattern on top. The cake is placed on a plate. There is a fork and a knife on the side of the plate. \n\nThere is a small bowl of fruit on the table next to the cake. \n\nThe cake does not have a red and white striped pattern on top, and there is no sprinkle of powdered sugar. There is no white paper on the side of the plate."}, "163412": {"image_id": 163412, "Bleu_1": 0.1408450704205515, "Bleu_2": 0.07769309688544852, "Bleu_3": 4.439205587190953e-07, "Bleu_4": 1.0650051690058236e-09, "METEOR": 0.14471039383766834, "ROUGE_L": 0.22111463525147262, "CIDEr": 8.046224293114633e-23, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This image shows a group of six people riding on bicycles along a path. The path is next to a body of water, and there is a pier next to the water. \n\nIn the background, there are three trees and two buildings. \n\nThe people are wearing casual clothing, and some of them are riding on a bike, while others are riding on bicycles. One person is even riding on a skateboard."}, "389174": {"image_id": 389174, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2285817953234835, "Bleu_3": 0.1600261774492132, "Bleu_4": 0.09514824286433507, "METEOR": 0.209947997515611, "ROUGE_L": 0.21908296420447745, "CIDEr": 4.1082850564270036e-11, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.26666666666666666, "f": 0.2711864406779661, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a park with a pond in the center, surrounded by trees and benches. There are people sitting on a bench. Some of the people are looking at a game, while others are looking at a dog. The sky is clear and there are no clouds or leaves on the ground."}, "250427": {"image_id": 250427, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.10635890745081387, "Bleu_3": 6.093393760732184e-07, "Bleu_4": 1.465869850942177e-09, "METEOR": 0.13087835686398802, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.8705294144986715e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1935483870967742, "f": 0.22641509433962262, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of six people standing in front of a building. The people are standing in line, walking, walking down the street, playing chess, playing a game, and riding a horse.\n\nThe building is not a theater or concert venue. There is no sign in front of the building."}, "399741": {"image_id": 399741, "Bleu_1": 0.255813953482423, "Bleu_2": 0.17451086522195614, "Bleu_3": 0.1306153185181404, "Bleu_4": 0.0863934042964332, "METEOR": 0.26363748542517595, "ROUGE_L": 0.2902787219578518, "CIDEr": 0.000157119305071429, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.047619047619047616, "f": 0.05, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows two girls sitting on the floor surrounded by toys. They are both wearing red dresses. Each girl has a stuffed animal in her lap and appears to be enjoying it. There are no other toys or presents in the scene."}, "555461": {"image_id": 555461, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.3468729675368036, "Bleu_3": 0.28256219864490845, "Bleu_4": 0.23227909232172794, "METEOR": 0.4304305159149453, "ROUGE_L": 0.5091047040971168, "CIDEr": 0.001704911145835495, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.08695652173913043, "f": 0.0784313725490196, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.3333333333333333, "f": 0.19047619047619044, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The man in the image is sitting at a desk with a laptop in front of him. He is wearing a black hat and a yellow shirt. There is a book on the desk."}, "6593": {"image_id": 6593, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.1769023808359136, "Bleu_3": 0.09543806343349583, "Bleu_4": 1.2553771013542623e-05, "METEOR": 0.19446823413155725, "ROUGE_L": 0.26483357452966716, "CIDEr": 0.002834085332931492, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.3125, "f": 0.18867924528301885, "fn": 11.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5555555555555556, "f": 0.4166666666666667, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows three men playing tennis on a tennis court. The men are wearing white shirts and black shorts. They each have a tennis racket in their hands. The players are wearing white pants and black shirts."}, "536088": {"image_id": 536088, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.12214340376073665, "Bleu_3": 0.06061150641759405, "Bleu_4": 7.621322239858419e-06, "METEOR": 0.17176494572905854, "ROUGE_L": 0.23008015087223005, "CIDEr": 1.083900904316653e-19, "SPICE": {"All": {"pr": 0.25, "re": 0.2692307692307692, "f": 0.2592592592592593, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image features a cake sitting on a table. The cake has a basket on top and is decorated with white and yellow flowers. There is a mirror on the wall behind the cake. \n\nThe cake is in front of a window. Through the window, a tree and a bird cage can be seen. \n\nThere are eight chairs around the table. The room has a view of the outdoors."}, "106849": {"image_id": 106849, "Bleu_1": 0.404255319140335, "Bleu_2": 0.3109175939491187, "Bleu_3": 0.18609431774657123, "Bleu_4": 1.9563054518669536e-05, "METEOR": 0.2820321521053163, "ROUGE_L": 0.317915309446254, "CIDEr": 3.3684721394619447e-09, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.10526315789473684, "f": 0.0930232558139535, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two men standing at a counter in a wine shop. One man is looking at a bottle of wine, while the other man is clapping and looking at a table of beer. There are several bottles of wine on the shelves in the shop."}, "38259": {"image_id": 38259, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1504928025607928, "Bleu_3": 8.272888216792643e-07, "Bleu_4": 1.9519860758481695e-09, "METEOR": 0.1359627411607818, "ROUGE_L": 0.21631205673758863, "CIDEr": 6.312606948867978e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.12903225806451613, "f": 0.14814814814814814, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows an airport with a plane parked on the tarmac. The terminal does not appear in the image. Through the glass wall, a plane can be seen. The sky is blue in color.\n\nThere is no runway in the scene."}, "535602": {"image_id": 535602, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.1475489144223407, "Bleu_3": 7.529519927190925e-07, "Bleu_4": 1.7093577453608883e-09, "METEOR": 0.17491829697760297, "ROUGE_L": 0.28355607205113303, "CIDEr": 1.6621166205081795e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.2777777777777778, "f": 0.2631578947368421, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a cat sitting on a table with a pizza box in front of it. The cat is looking at the pizza box with its head tilted forward. There are several other items on the table, including a laptop and a phone. There is no bag of trash in the scene."}, "448600": {"image_id": 448600, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.26042109924757323, "Bleu_3": 0.1641491303352349, "Bleu_4": 0.09956938190684739, "METEOR": 0.24665793722925478, "ROUGE_L": 0.3028368794326241, "CIDEr": 3.816190783280516e-08, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.20833333333333334, "f": 0.19607843137254902, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a slice of cake on a plate with a fork and knife on the side. The cake has strawberries, chocolate, and whipped cream as toppings. There is a glass on the table. \n\nThere is no milk in the image. A strawberry is on the side."}, "499226": {"image_id": 499226, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.27197188373746883, "Bleu_3": 0.1271301343465568, "Bleu_4": 1.556572553303031e-05, "METEOR": 0.2584089617606696, "ROUGE_L": 0.3584470094438615, "CIDEr": 0.0001981753307340669, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.20833333333333334, "f": 0.18867924528301888, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a cat lying on a couch. The cat is resting its head on a pillow. The cat is sleeping. The couch is covered in a floral print. There are no remote controls in the scene."}, "286303": {"image_id": 286303, "Bleu_1": 0.4999999999583334, "Bleu_2": 0.4264014326740723, "Bleu_3": 0.33130076244167656, "Bleu_4": 0.25211936181920963, "METEOR": 0.3019581342342519, "ROUGE_L": 0.43821839080459773, "CIDEr": 0.9899903123322353, "SPICE": {"All": {"pr": 0.15625, "re": 0.19230769230769232, "f": 0.1724137931034483, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image features a man wearing a tie. The tie is gray."}, "363072": {"image_id": 363072, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.11289809419085711, "Bleu_4": 1.3447816950952107e-05, "METEOR": 0.20692079690979803, "ROUGE_L": 0.20847573479152426, "CIDEr": 1.7045058714245753e-08, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.46153846153846156, "f": 0.5454545454545455, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a subway train traveling on the tracks in front of a tall building. The train is blue and white in color. There are no people, platforms, or sidewalks in the scene. There are two trees in the background. The sky is blue in color."}, "416193": {"image_id": 416193, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 8.681823924888469e-07, "Bleu_4": 1.9987674397634184e-09, "METEOR": 0.26225935317840987, "ROUGE_L": 0.25702247191011235, "CIDEr": 3.324120883982209e-07, "SPICE": {"All": {"pr": 0.20588235294117646, "re": 0.23333333333333334, "f": 0.21874999999999997, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows two zebras grazing on grass in a green field. There is a fig tree in the background.\n\nThe sky is blue and there are clouds in the distance. The grass is green and there are no other animals in the field."}, "390048": {"image_id": 390048, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.16817499303272468, "Bleu_3": 0.10957078983962541, "Bleu_4": 0.07480984787268927, "METEOR": 0.18541288944208453, "ROUGE_L": 0.25258799171842644, "CIDEr": 8.474410162862724e-09, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.0625, "f": 0.06779661016949153, "fn": 30.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two men in a restaurant. One man is sitting at a table with a plate of food in front of him. The other man is standing in front of a table. The man sitting is wearing a blue shirt and black pants."}, "46924": {"image_id": 46924, "Bleu_1": 0.255813953482423, "Bleu_2": 0.13517553494737666, "Bleu_3": 0.07638430164587322, "Bleu_4": 1.0273965107862501e-05, "METEOR": 0.1866922648514738, "ROUGE_L": 0.21801286633309508, "CIDEr": 1.836854148534764e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3333333333333333, "f": 0.2926829268292683, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.8, "f": 0.5333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person holding a small black and silver phone. The phone has a rectangle shape and a black and silver screen on the front. The person's hand is visible in the image, with the phone resting in their palm."}, "26026": {"image_id": 26026, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.06023659207271943, "Bleu_3": 4.143654503114468e-07, "Bleu_4": 1.0921823440882956e-09, "METEOR": 0.1711627906976744, "ROUGE_L": 0.14480712166172105, "CIDEr": 9.07610695174318e-12, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3157894736842105, "f": 0.33333333333333337, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows two people standing around a large, circular enclosure with a circus tent in the background. The people are wearing black shirts. The people are standing around a large elephant. A large metal chair is in the background. A large red and blue striped ring is hanging from the circus tent."}, "382333": {"image_id": 382333, "Bleu_1": 0.382352941165225, "Bleu_2": 0.28478969316957436, "Bleu_3": 0.19664063617763064, "Bleu_4": 2.2254330294642257e-05, "METEOR": 0.26564160548418436, "ROUGE_L": 0.3954619124797406, "CIDEr": 0.0003377087205176896, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13043478260869565, "f": 0.14634146341463414, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a garden with several rows of plants growing in the soil. A vegetable garden is growing in the soil. The garden is surrounded by a fence, which is made of wire."}, "508899": {"image_id": 508899, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.15720795999973383, "Bleu_4": 0.09693770419482768, "METEOR": 0.25964100180808125, "ROUGE_L": 0.23843648208469054, "CIDEr": 7.050202412110858e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.29411764705882354, "f": 0.2380952380952381, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a living room with two couches, a television, and a dog on the floor. The dog is white and black. It is a small rabbit with silky fur. The dog has a black nose and lop ears. The dog is sitting on the floor."}, "20553": {"image_id": 20553, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.11605769149245462, "Bleu_3": 6.54689746724509e-07, "Bleu_4": 1.563155525234599e-09, "METEOR": 0.1335704728800181, "ROUGE_L": 0.20446927374301677, "CIDEr": 7.514585375829918e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a room with a table and a chair in the middle. There is a bottle of beer, a can of coke, and a can of co on the table.\n\nThere is no food or toy in the room.\n\nThere is no field or plant in the scene."}, "65465": {"image_id": 65465, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.11072431282861321, "Bleu_4": 0.08627614350761502, "METEOR": 0.22670873276381417, "ROUGE_L": 0.2688916876574307, "CIDEr": 2.395633419673404e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of three elephants standing in a field. The elephants are all different sizes and colors, with some having spots and others not. They are all standing in a line, with their trunks curled up and their ears flapping in the wind. There are babies with the elephants."}, "320823": {"image_id": 320823, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.24077170616624616, "Bleu_3": 1.0962747416941928e-06, "Bleu_4": 2.3527319061034173e-09, "METEOR": 0.1570997250867262, "ROUGE_L": 0.20691994572591585, "CIDEr": 1.654377284191269e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.13043478260869565, "f": 0.1276595744680851, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a couple sitting at a table with a cake in front of them. The couple is wearing traditional Indian clothing. The cake has candles on it. The background features a brightly colored wall and two windows.\n\nThe couple is sitting on a bench."}, "477087": {"image_id": 477087, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.18227065413983304, "Bleu_3": 0.13445913121019032, "Bleu_4": 0.10499901541586201, "METEOR": 0.2313087054373506, "ROUGE_L": 0.283344392833444, "CIDEr": 1.6741775238194488e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.5, "f": 0.1818181818181818, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.125, "re": 1.0, "f": 0.2222222222222222, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image is a collection of baseball memorabilia, including a baseball bat, glove, and ball. The baseball bat is part of the baseball memorabilia. The glove is made of leather and has a pocket for the ball. The ball is made of leather."}, "71357": {"image_id": 71357, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.1297498240245396, "Bleu_3": 0.08596517673031359, "Bleu_4": 1.0513349070391803e-05, "METEOR": 0.15325394617871815, "ROUGE_L": 0.22008418520745643, "CIDEr": 9.324437896354813e-14, "SPICE": {"All": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.75, "f": 0.75, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a yellow train on the tracks. The train has a large front end with a yellow and black striped nose. The train has a long body with windows on both sides. The train has a small rear end with a yellow and black striped tail. The train is traveling on the tracks."}, "343453": {"image_id": 343453, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.15849534045439814, "Bleu_3": 0.08295835031586613, "Bleu_4": 1.0734404745305494e-05, "METEOR": 0.23016669567845474, "ROUGE_L": 0.2794502617801047, "CIDEr": 2.3818530056255308e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13636363636363635, "f": 0.12244897959183673, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a person standing on a snowy slope, wearing a blue hoodie and holding a pair of skis. The person is posing for a picture. The person is standing on skis. \n\nThere are trees in the background, and a ski lift is also visible."}, "34580": {"image_id": 34580, "Bleu_1": 0.4374999999863282, "Bleu_2": 0.23759548164820116, "Bleu_3": 1.2345775254393491e-06, "Bleu_4": 2.8381756880555377e-09, "METEOR": 0.257695687812592, "ROUGE_L": 0.35, "CIDEr": 0.005276217901352846, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.25, "f": 0.23728813559322032, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "The image shows a red fire hydrant in the grass in front of a parking lot. There are several cars parked in the lot.\n\nThe sky is cloudy and it is raining."}, "151393": {"image_id": 151393, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.11262765836415223, "Bleu_3": 0.06709347299490492, "Bleu_4": 9.26433478217715e-06, "METEOR": 0.16140128431513906, "ROUGE_L": 0.2323514474352463, "CIDEr": 0.00010592419950833226, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.32, "f": 0.2909090909090909, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a stop sign on a pole in the middle of a street. The letters on the stop sign are red. There is a parking sign on the pole. The street is lined with trees. There are no cars in the scene."}, "239351": {"image_id": 239351, "Bleu_1": 0.4318181818083678, "Bleu_2": 0.3006335804242755, "Bleu_3": 0.23459872425289288, "Bleu_4": 0.17531883822094138, "METEOR": 0.28624399222311636, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.0004166165135441025, "SPICE": {"All": {"pr": 0.25, "re": 0.13043478260869565, "f": 0.1714285714285714, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows three couples standing on a dirt road. The couples are holding an umbrella and signs. The sign says \"We're engaged!\" and \"Get married\". The man is wearing a black suit and a tie. The woman is wearing a blue dress."}, "357109": {"image_id": 357109, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.1344109151128908, "Bleu_4": 0.0857082790640443, "METEOR": 0.17338281743097114, "ROUGE_L": 0.20497311827956988, "CIDEr": 3.5187825832906e-09, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.22727272727272727, "f": 0.25641025641025644, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two skateboarders performing tricks on a ramp in front of a crowd of people. The skateboarder's shirt is white and his pants are blue. He is wearing a black and white helmet. The crowd is made up of people of different ages and ethnicities."}, "174888": {"image_id": 174888, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.18971331171167066, "Bleu_3": 0.1380949094291484, "Bleu_4": 0.09007790030550297, "METEOR": 0.27919304844387155, "ROUGE_L": 0.30262225372076546, "CIDEr": 1.94868257980875e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11538461538461539, "f": 0.12765957446808512, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows three men standing outside of a restaurant. One man is holding a plate with a slice of pizza on it. The man is wearing a blue shirt and a hat on his head. The hat is either blue or white."}, "542934": {"image_id": 542934, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2383656473040621, "Bleu_3": 0.12237946382258257, "Bleu_4": 1.5721757596698785e-05, "METEOR": 0.2592355949721438, "ROUGE_L": 0.31266017426960535, "CIDEr": 0.0004079066208749715, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.16666666666666666, "f": 0.12903225806451615, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a kitchen with a wooden table and chairs. There is a stove and oven on the counter. There are pans hanging from the ceiling. The walls of the kitchen are purple."}, "467848": {"image_id": 467848, "Bleu_1": 0.19999999999764706, "Bleu_2": 0.11952286093202484, "Bleu_3": 0.08022598181948269, "Bleu_4": 0.050093666195721406, "METEOR": 0.20028241460683532, "ROUGE_L": 0.20325805257312105, "CIDEr": 3.072064068611483e-30, "SPICE": {"All": {"pr": 0.28, "re": 0.25, "f": 0.2641509433962264, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a truck with a trailer attached to it. A large metal container is attached to the truck. The truck is attached to a trailer. The trailer has a ramp on the back of it. \n\nThere is a tank on the back of the trailer. \n\nThere is a person standing in front of the truck. The person is holding a skateboard.\n\nThere is no hose in the image.\n\nThere is one car in the image.\n\nThe people are standing in the parking lot."}, "413124": {"image_id": 413124, "Bleu_1": 0.3620689655109988, "Bleu_2": 0.23909994568600282, "Bleu_3": 0.15983687245498218, "Bleu_4": 0.11038868410736873, "METEOR": 0.2137955828643786, "ROUGE_L": 0.2544316996871741, "CIDEr": 4.710840999162343e-13, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a boy wearing a baseball uniform and holding a baseball glove. He is standing on a baseball field. The sun is shining down on the boy, casting a shadow on his face. The boy is wearing a green and yellow jersey with the name of the team on it. A fence is in the background."}, "300773": {"image_id": 300773, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.1390096093683277, "Bleu_3": 0.09576841983278785, "Bleu_4": 1.1955001291193745e-05, "METEOR": 0.16300587758254279, "ROUGE_L": 0.16968011126564672, "CIDEr": 3.0660969672867507e-09, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.3333333333333333, "f": 0.28, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows three people standing in front of a building. The people are looking at their cell phones. The building is made of red brick. The roof is red. A red pillar is on the front of the building. The people are wearing red robes."}, "373440": {"image_id": 373440, "Bleu_1": 0.4999999999791667, "Bleu_2": 0.29488391229724037, "Bleu_3": 1.5811017751136311e-06, "Bleu_4": 3.703949407594147e-09, "METEOR": 0.29511653924657333, "ROUGE_L": 0.4186274509803921, "CIDEr": 0.1172382067501822, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.20833333333333334, "f": 0.21739130434782608, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a store with a shelf full of teddy bears. The bears are wearing a white scarf. The sign reads \"travel necessities\"."}, "334321": {"image_id": 334321, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.21666028366574688, "Bleu_3": 0.15756477111639683, "Bleu_4": 0.12227419998955809, "METEOR": 0.2312655711691096, "ROUGE_L": 0.3024079320113314, "CIDEr": 0.00012896189439767626, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.10344827586206896, "f": 0.10714285714285715, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a white dog sitting on a bench in the park. The dog is wearing a red collar. There are no people walking by in the background. There is no sky or trees in the scene."}, "535668": {"image_id": 535668, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.14096477244806874, "Bleu_4": 0.1150278361966755, "METEOR": 0.2529957318366919, "ROUGE_L": 0.26704190118824267, "CIDEr": 2.4757989703212285e-11, "SPICE": {"All": {"pr": 0.1875, "re": 0.16666666666666666, "f": 0.17647058823529413, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a baseball player swinging a bat and hitting a baseball. The player is wearing a white and red uniform and has a baseball helmet on his head. The umpire is standing behind the player and announcing the batter. The player is also wearing a hat on his head."}, "157184": {"image_id": 157184, "Bleu_1": 0.21212121211478424, "Bleu_2": 0.18205477030800182, "Bleu_3": 0.14747595901295485, "Bleu_4": 0.12092555992241515, "METEOR": 0.24250529260531534, "ROUGE_L": 0.3288409703504044, "CIDEr": 0.0002014092064822528, "SPICE": {"All": {"pr": 0.1, "re": 0.08695652173913043, "f": 0.09302325581395349, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a man holding a large knife in his hand. He is standing in front of a white wall made of concrete. The man is wearing a plaid shirt and glasses."}, "64390": {"image_id": 64390, "Bleu_1": 0.5357142856951531, "Bleu_2": 0.28171808489925787, "Bleu_3": 0.1450614571374597, "Bleu_4": 1.8693000799253376e-05, "METEOR": 0.2835818214025529, "ROUGE_L": 0.33394160583941607, "CIDEr": 0.020631516031650247, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09090909090909091, "f": 0.08163265306122448, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a red traffic light at an intersection. The car is parked in the street. The building in the background appears to be a shopping mall."}, "91857": {"image_id": 91857, "Bleu_1": 0.21212121211478424, "Bleu_2": 0.08141736840736051, "Bleu_3": 5.979857148051304e-07, "Bleu_4": 1.6339463528729465e-09, "METEOR": 0.1609351978805805, "ROUGE_L": 0.25738396624472576, "CIDEr": 0.00037068931753354807, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.2727272727272727, "f": 0.3428571428571428, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two giraffes standing in a field. The giraffes are wearing giraffe hats. The necks are long on the giraffes. There is a tree in the background. The tree is green."}, "275202": {"image_id": 275202, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.24253562502930154, "Bleu_3": 1.212492459034356e-06, "Bleu_4": 2.7319439827503006e-09, "METEOR": 0.27113369232232837, "ROUGE_L": 0.34078212290502796, "CIDEr": 0.00024024096106890438, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13636363636363635, "f": 0.13636363636363635, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a table with a pizza on it. There is a glass of red wine on the table and a fork and knife next to the pizza. The table is made of wood."}, "508811": {"image_id": 508811, "Bleu_1": 0.21951219511927422, "Bleu_2": 0.13773231175519954, "Bleu_3": 0.06189571188528847, "Bleu_4": 7.4018222040870865e-06, "METEOR": 0.14196767974510754, "ROUGE_L": 0.19000155738981467, "CIDEr": 1.6368760880129595e-25, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15, "f": 0.13043478260869565, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two tennis players on a tennis court. The tennis players are preparing to hit the ball. They are holding tennis rackets. One of the players is about to hit the ball, while the other player is preparing to hit the ball. \n\nThe players are wearing white and black clothing. One player is wearing a white shirt and black shorts, with red and white shoes. The other player's clothing is not described.\n\nThere is no ball in the image."}, "511111": {"image_id": 511111, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.1506556909135452, "Bleu_4": 0.11042240379731003, "METEOR": 0.26677602691833274, "ROUGE_L": 0.31504196255648803, "CIDEr": 2.5770125710494993e-10, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.19047619047619047, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a glass of orange juice on a countertop next to two blenders. Orange juice is in the blender. A glass is on top of the blender. The countertop is made of granite. The blender has a black handle. There is an orange peel in the blender."}, "70471": {"image_id": 70471, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.24112141107953186, "Bleu_3": 0.1415487039853373, "Bleu_4": 1.6317905930043706e-05, "METEOR": 0.22338269056857002, "ROUGE_L": 0.33993808049535607, "CIDEr": 2.1564080827614396e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.07142857142857142, "f": 0.09523809523809523, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "There is no man in this image. There is a baby wearing a white t-shirt and a onesie, holding a pacifier in its mouth. The baby is sitting on a couch. The background does not show a living room, coffee table, or television."}, "95516": {"image_id": 95516, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.192868005722087, "Bleu_3": 0.13637339509226334, "Bleu_4": 0.08763551144786626, "METEOR": 0.1996231429683798, "ROUGE_L": 0.24830393487109906, "CIDEr": 2.1450091187741196e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.25, "f": 0.23809523809523808, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a truck with logs in the back. The truck is parked in a lot. The license plate on the truck reads \"Texas tx\".\n\nThere are no trees in the background.\n\nThe image is taken in a rural area with a dirt road leading."}, "299946": {"image_id": 299946, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.20952908872569917, "Bleu_3": 0.10402586772234956, "Bleu_4": 1.3119283323578519e-05, "METEOR": 0.18978251802804647, "ROUGE_L": 0.3161850460023325, "CIDEr": 1.2305457890070192e-05, "SPICE": {"All": {"pr": 0.4, "re": 0.24, "f": 0.3, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a woman in a black shirt and black pants standing at a kitchen counter. She is holding a blender and making a smoothie. There is a bowl on the kitchen counter. The woman is standing in the kitchen."}, "356456": {"image_id": 356456, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.08217664461402949, "Bleu_4": 1.0264051022519406e-05, "METEOR": 0.18682896779187994, "ROUGE_L": 0.24811156304474144, "CIDEr": 7.539125813068679e-10, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.3125, "f": 0.2325581395348837, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a train on the tracks in a rural area. The train is an old, red and white locomotive. It is pulling a long, red and white freight car with a large, black tank on top. The train has a large, black smoke stack. The train is traveling through a field."}, "420181": {"image_id": 420181, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.17038855026853147, "Bleu_3": 0.10003706449227341, "Bleu_4": 1.3750902304795609e-05, "METEOR": 0.13767820188501184, "ROUGE_L": 0.2775250227479527, "CIDEr": 0.0005886519628897518, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.16666666666666666, "f": 0.15, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows three people standing in line. One of the people is talking on the phone. The people are standing around a food truck. They are all wearing black jackets."}, "324785": {"image_id": 324785, "Bleu_1": 0.333333333325926, "Bleu_2": 0.19462473603600663, "Bleu_3": 0.09586112891273502, "Bleu_4": 1.203426530909924e-05, "METEOR": 0.13705087220267037, "ROUGE_L": 0.19003115264797507, "CIDEr": 2.0080522422663552e-07, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.16129032258064516, "f": 0.16129032258064516, "fn": 26.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of five boats docked at a pier. The boats are made of wood. Some of the boats have red and white colors, while others have green and white colors.\n\nThere are no lobster traps or wire mesh in the scene."}, "100329": {"image_id": 100329, "Bleu_1": 0.17777777777382722, "Bleu_2": 0.15569978882880534, "Bleu_3": 0.1191451263260334, "Bleu_4": 0.07966084134813135, "METEOR": 0.20882685702124146, "ROUGE_L": 0.2350674373795761, "CIDEr": 8.394597456547913e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a brown bear standing on a rocky outcropping. The bear is eating a fish and has a paw. The bear is standing on its hind legs and has a large, fluffy coat. There is no water, boats, or buildings in the scene."}, "191425": {"image_id": 191425, "Bleu_1": 0.5142857142710204, "Bleu_2": 0.3889222341200232, "Bleu_3": 0.2636881004735942, "Bleu_4": 0.18398732410492732, "METEOR": 0.2763378210046511, "ROUGE_L": 0.3733741392501913, "CIDEr": 0.0004224999581995079, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.3333333333333333, "f": 0.3018867924528302, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.7, "f": 0.608695652173913, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image is a black and white photograph of a sunset over a body of water. The sky is dark and the sun is setting behind a mountain. There is a boat in the water."}, "494620": {"image_id": 494620, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.1942571724677524, "Bleu_3": 0.14357582278478706, "Bleu_4": 0.10431000906543937, "METEOR": 0.28494411190519103, "ROUGE_L": 0.3819009675583381, "CIDEr": 5.202328005463453e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.2222222222222222, "f": 0.2424242424242424, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a man riding a horse. The man is sitting on the back of the horse. He is wearing a hat and a jacket. The horse is wearing a saddle and a bridle. The man and the horse are in front of a building. The sign reads \"the swan's nest\"."}, "359260": {"image_id": 359260, "Bleu_1": 0.1756756756733017, "Bleu_2": 0.12979064964613318, "Bleu_3": 0.08887068416745472, "Bleu_4": 0.05607306627327566, "METEOR": 0.22354034331381167, "ROUGE_L": 0.1916517055655296, "CIDEr": 9.811875346033438e-24, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09090909090909091, "f": 0.08888888888888888, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man sitting on a boat. A boat is next to the man. The man's shirt is blue.\n\nThere is a horse on the beach. \n\nThere are two carts on the beach. A dog is next to the cart. The frame of the cart is made of wood. A horse is pulling the cart.\n\nThe horse's saddle is brown.\n\nThere is no bridle, frame, or sand in the scene."}, "286342": {"image_id": 286342, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.13857638305004102, "Bleu_3": 8.110083286556016e-07, "Bleu_4": 1.9758409157987315e-09, "METEOR": 0.22515285862098355, "ROUGE_L": 0.23940345368916802, "CIDEr": 7.733967839099532e-06, "SPICE": {"All": {"pr": 0.16, "re": 0.18181818181818182, "f": 0.1702127659574468, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a computer keyboard and mouse on a pink carpet. The design of the keyboard is a Microsoft wireless keyboard. The mouse is black and has a Microsoft logo on the top. The carpet is pink."}, "576191": {"image_id": 576191, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.11644450194595923, "Bleu_3": 6.160320779080733e-07, "Bleu_4": 1.423094635444345e-09, "METEOR": 0.18029495982029772, "ROUGE_L": 0.1937738246505718, "CIDEr": 7.056220559771133e-15, "SPICE": {"All": {"pr": 0.15625, "re": 0.19230769230769232, "f": 0.1724137931034483, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a cat sitting on a bench in front of a building. The cat is not looking up at the camera. The bench is made of metal. The seat is made of concrete. The building is made of stone. The building does not have a large window on the top floor. There are no trees in the scene."}, "580908": {"image_id": 580908, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.10555271104180952, "Bleu_4": 1.2644818101757865e-05, "METEOR": 0.2377894683141605, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.1790585382689355e-09, "SPICE": {"All": {"pr": 0.09375, "re": 0.125, "f": 0.10714285714285714, "fn": 21.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of six men in black and white uniforms standing on a baseball field. They are all wearing baseball caps and gloves. Some of them are holding baseball bats. The men are standing in a line, with one man in the front holding a baseball."}, "556420": {"image_id": 556420, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 0.07733118331435387, "Bleu_4": 9.806713568284028e-06, "METEOR": 0.129176458730881, "ROUGE_L": 0.17359134889015368, "CIDEr": 4.066477894574586e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a beach with a hut on the sand. There is a palm tree and a small body of water in the background. The sky is blue and there are clouds in the distance.\n\nThe image is taken from a high angle, looking down on the beach. The sand is white."}, "81251": {"image_id": 81251, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2455273669893519, "Bleu_3": 0.15782934179488486, "Bleu_4": 0.09668023125951691, "METEOR": 0.3434932166859152, "ROUGE_L": 0.4022781774580335, "CIDEr": 1.631544129646393e-08, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.21739130434782608, "f": 0.20408163265306123, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a pizza with tomatoes, arugula, and parmesan cheese on top. The pizza is served on a white plate. There is a glass of wine next to the pizza. The pizza is placed on a wooden table. The background is a white wall with a window."}, "130437": {"image_id": 130437, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.15097027121358048, "Bleu_3": 9.696484046788554e-07, "Bleu_4": 2.4826065965290047e-09, "METEOR": 0.2291143256263745, "ROUGE_L": 0.28478057889822594, "CIDEr": 0.014239000916046013, "SPICE": {"All": {"pr": 0.1590909090909091, "re": 0.21875, "f": 0.18421052631578946, "fn": 25.0, "numImages": 1.0, "fp": 37.0, "tp": 7.0}, "Relation": {"pr": 0.13333333333333333, "re": 0.16666666666666666, "f": 0.14814814814814814, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.4166666666666667, "f": 0.3448275862068966, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a train traveling down the tracks. The train is passing by a building with a tan roof. There are trees visible in the background."}, "359546": {"image_id": 359546, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.15420923384708043, "Bleu_3": 0.1068387297471822, "Bleu_4": 0.07526631223023306, "METEOR": 0.18631441078459057, "ROUGE_L": 0.2260934025203855, "CIDEr": 5.827147266250934e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.10526315789473684, "f": 0.13333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a group of three umbrellas on the beach. The umbrellas are made of straw and have different shapes, including octagon and hat. They are placed on the sand. There is water in the background. The sky is blue."}, "298979": {"image_id": 298979, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.16870903059432618, "Bleu_4": 0.10001000249872885, "METEOR": 0.28885806777983575, "ROUGE_L": 0.3216168717047452, "CIDEr": 4.431765518151741e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.14814814814814814, "f": 0.1951219512195122, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a herd of eight zebras grazing in a grassy field next to a body of water. The zebras are standing in a line, with their heads bending down and their tails swaying back and forth. The water is calm and clear. There are no boats in the scene."}, "413079": {"image_id": 413079, "Bleu_1": 0.19999999999555562, "Bleu_2": 0.11677484162160401, "Bleu_3": 0.0681935615181132, "Bleu_4": 9.321701825196602e-06, "METEOR": 0.21896117295426837, "ROUGE_L": 0.24887800897592818, "CIDEr": 3.5468655556139874e-08, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.25, "f": 0.2909090909090909, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.5, "f": 0.5384615384615384, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image shows a horse jumping over a fence at a horse show. The horse is wearing a saddle and bridle and is jumping over a wooden fence. The rider is wearing a helmet and is holding the reins. The background is a green field."}, "403584": {"image_id": 403584, "Bleu_1": 0.16129032257804374, "Bleu_2": 0.08906352197353938, "Bleu_3": 0.05094280175098147, "Bleu_4": 6.8801691733940225e-06, "METEOR": 0.19186873971653384, "ROUGE_L": 0.1953041622198506, "CIDEr": 4.897539322604715e-16, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15789473684210525, "f": 0.13043478260869565, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows four people standing on the beach. Some of the people are holding surfboards and looking at them. \n\nThe sky is cloudy and there are waves crashing on the shore. The overall atmosphere of the scene is relaxed and peaceful, as the people enjoy their time on the beach. \n\nThere are no other people, wetsuits, or sunglasses in the scene."}, "401004": {"image_id": 401004, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.12712834523041283, "Bleu_3": 0.06730845772977347, "Bleu_4": 8.750873255009596e-06, "METEOR": 0.2039430273934725, "ROUGE_L": 0.22724853645556145, "CIDEr": 4.110926253033678e-11, "SPICE": {"All": {"pr": 0.25, "re": 0.20833333333333334, "f": 0.22727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a room with a wooden floor. In the center of the room, there is a large wooden table with stools around it. On the other side of the room, there is a bar with a counter. The walls are made of brick. There are several windows on the sides of the room."}, "489829": {"image_id": 489829, "Bleu_1": 0.19444444444174383, "Bleu_2": 0.1281870698712216, "Bleu_3": 0.08896869462805923, "Bleu_4": 0.06721607366089649, "METEOR": 0.19849628856021403, "ROUGE_L": 0.17058165548098433, "CIDEr": 1.5547573283054637e-23, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.05555555555555555, "f": 0.05405405405405406, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a man standing in front of a wall of clocks. The clocks are all different shapes and sizes. Some of them are round, some are shaped like a swan, and some are shaped like a ring. Some of the clocks have numbers on them, while others do not. The clocks have different colors, including brown, purple, black, and gold. \n\nThe man is wearing a black shirt and blue pants."}, "177810": {"image_id": 177810, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.14433756729513328, "Bleu_3": 0.118880975234953, "Bleu_4": 0.08615079897682161, "METEOR": 0.22303641806489907, "ROUGE_L": 0.21587462082912032, "CIDEr": 3.8840396436387096e-17, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows five teddy bears sitting on a table next to two Christmas trees. The teddy bears are wearing scarves and hats. Some of the teddy bears are wearing brown scarves and hats, while others are wearing red scarves and hats. \n\nThere are no lights or presents underneath the Christmas trees. \n\nThe background is a white wall with no window in the background."}, "130225": {"image_id": 130225, "Bleu_1": 0.16842105262980608, "Bleu_2": 0.11199104107387153, "Bleu_3": 0.06461071349293435, "Bleu_4": 7.358367022432499e-06, "METEOR": 0.15405195589856768, "ROUGE_L": 0.1603454750281637, "CIDEr": 1.2471155161869668e-41, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.21428571428571427, "f": 0.1935483870967742, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a group of six people flying kites in a field. The people are playing with a frisbee, flying a kite, playing a game of frisbee, walking on the sidewalk, playing a game, and playing a game in the dark. \n\nThere are a total of eight kites in the image. The kites are in various colors, including green, blue, yellow, red, white, black, and purple. Some of the kites have stream.\n\nThere is no other clothing in the scene.\n\nThere is no line in the scene.\n\nThere is no stream in the scene."}, "364010": {"image_id": 364010, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.43033148289628165, "Bleu_3": 0.349618748749835, "Bleu_4": 0.26760322755626287, "METEOR": 0.3157757130578028, "ROUGE_L": 0.5066445182724253, "CIDEr": 0.043984568987515904, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.15625, "f": 0.14492753623188406, "fn": 27.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a dog sitting on a blanket in the back seat of a black sedan. The dog is black and brown. The car has tinted windows."}, "527728": {"image_id": 527728, "Bleu_1": 0.1692307692281657, "Bleu_2": 0.11498327637419221, "Bleu_3": 0.05942596868979659, "Bleu_4": 7.62753624403862e-06, "METEOR": 0.16071895496536434, "ROUGE_L": 0.15649050795279631, "CIDEr": 1.1458990627720125e-19, "SPICE": {"All": {"pr": 0.25, "re": 0.17857142857142858, "f": 0.20833333333333331, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two elephants standing in a small pond. One of the elephants is chewing on a branch and wearing a tusk. The other elephant is in the water and also wearing a tusk. The elephants have their trunks in the water. One of the elephants is wearing a collar with a ring on it.\n\nThere is no giraffe or zebra in the scene."}, "8787": {"image_id": 8787, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.2444257647581566, "Bleu_3": 0.18793910397544641, "Bleu_4": 0.13955755488666227, "METEOR": 0.26054027239965694, "ROUGE_L": 0.3320373250388802, "CIDEr": 2.1012880421481513e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a man holding a camera and standing on the sidewalk. The man is wearing a white and black shirt and blue pants. The camera is a small, black device with a lens on the front."}, "198717": {"image_id": 198717, "Bleu_1": 0.07142857142772109, "Bleu_2": 9.276773134630285e-10, "Bleu_3": 2.1894078615562318e-12, "Bleu_4": 1.0669000860722047e-13, "METEOR": 0.08533979087667905, "ROUGE_L": 0.07331730769230768, "CIDEr": 8.348245367596467e-35, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.35, "f": 0.2745098039215686, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two men in a bedroom. One of the men is holding a plate of food, and the other is holding a cup of coffee. The men are wearing blue pajamas. The room is dimly lit and there are no windows. \n\nThere is a bed made up with a white sheet. A white plate is on the bed. There is also a blanket and two pillows on the bed. \n\nThere is no food, cup, coffee, room, windows, or pajamas in the scene."}, "465223": {"image_id": 465223, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 0.12358624423715978, "Bleu_4": 1.5349982032732275e-05, "METEOR": 0.21903863653434374, "ROUGE_L": 0.2514427040395713, "CIDEr": 0.00021081916124357996, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3333333333333333, "f": 0.2553191489361702, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a tennis match in progress on a court. There are several players on the court, including a woman wearing a white tennis outfit and a man wearing a black shirt. The crowd is cheering."}, "377595": {"image_id": 377595, "Bleu_1": 0.5384615383786985, "Bleu_2": 0.36689969279504947, "Bleu_3": 0.23044502514829485, "Bleu_4": 3.326024950007662e-05, "METEOR": 0.20866083737163685, "ROUGE_L": 0.38461538461538464, "CIDEr": 0.22714800790328915, "SPICE": {"All": {"pr": 0.6111111111111112, "re": 0.44, "f": 0.5116279069767442, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 11.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.8888888888888888, "re": 0.6666666666666666, "f": 0.761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 8.0}}, "caption": "The image shows a large, white, plastic bag sitting on a cutting board."}, "386968": {"image_id": 386968, "Bleu_1": 0.340909090901343, "Bleu_2": 0.2953122116025195, "Bleu_3": 0.20251529907234372, "Bleu_4": 0.14187468588457955, "METEOR": 0.30617962927779263, "ROUGE_L": 0.32620320855614976, "CIDEr": 4.781341250435185e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2222222222222222, "f": 0.22857142857142856, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a woman riding a bicycle on the street. The woman is wearing a brown coat and a brown collar. She is carrying a dog on her lap, which is wearing a jacket. \n\nThe woman is riding the bicycle on the street."}, "405994": {"image_id": 405994, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.13644420572458105, "Bleu_3": 0.07396917719335282, "Bleu_4": 9.738340653916805e-06, "METEOR": 0.16961738383482713, "ROUGE_L": 0.2293233082706767, "CIDEr": 1.081162392694987e-09, "SPICE": {"All": {"pr": 0.02702702702702703, "re": 0.0625, "f": 0.03773584905660377, "fn": 15.0, "numImages": 1.0, "fp": 36.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.0625, "re": 0.16666666666666666, "f": 0.09090909090909091, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}}, "caption": "The image shows a store window with a display of baseball bats. The bats are made of wood and have colorful paint on them. They are arranged in a row on a shelf in the window. The display is in a storefront window of a sporting goods store."}, "134815": {"image_id": 134815, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.22281245492303933, "Bleu_3": 0.14793835438670558, "Bleu_4": 1.6377871492796307e-05, "METEOR": 0.2431236102279514, "ROUGE_L": 0.270595690747782, "CIDEr": 8.828956704239169e-09, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.3333333333333333, "f": 0.3137254901960785, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a kitchen with wooden cabinets and a stove. A gas stove is on the stove. A coffee maker is on the countertops.\n\nThere are no pots or pans in the scene.\n\nThe kitchen has no island.\n\nThere are no walls or windows in the scene."}, "201934": {"image_id": 201934, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.22288685594608834, "Bleu_3": 0.18272474598892796, "Bleu_4": 0.15277191390944114, "METEOR": 0.24584396694120234, "ROUGE_L": 0.2704885580806081, "CIDEr": 1.9961191162008886e-14, "SPICE": {"All": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a white bus parked on the side of the road. There are two people standing on the sidewalk. The people are looking at a reflection in the window. The bus has a bumper sticker on the front that reads \"no guns on school buses\". There is also a car parked along the side of the road."}, "320899": {"image_id": 320899, "Bleu_1": 0.24999999999107145, "Bleu_2": 0.09622504486143743, "Bleu_3": 7.088172837787079e-07, "Bleu_4": 1.9427446513107765e-09, "METEOR": 0.15457427204036006, "ROUGE_L": 0.23828124999999997, "CIDEr": 0.0011485059485297183, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.08, "f": 0.09523809523809526, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a bedroom with two beds. The beds have brown and beige patterned comforters. There are three pillows on the beds, which are brown and beige."}, "406217": {"image_id": 406217, "Bleu_1": 0.3199999999936, "Bleu_2": 0.2555506259948128, "Bleu_3": 0.175896642896203, "Bleu_4": 0.12336052173195815, "METEOR": 0.3102811479803141, "ROUGE_L": 0.26521739130434785, "CIDEr": 5.143079232096935e-10, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2413793103448276, "f": 0.2916666666666667, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a building with a sign on the side that reads \"factory trained technicians\". The building is made of glass and has a large window on the side. The sign is made of wood and has a black background. The letters on the sign are in arial font."}, "130076": {"image_id": 130076, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.23262966005988533, "Bleu_3": 0.15337207891322888, "Bleu_4": 0.09515827466206096, "METEOR": 0.2530910113300174, "ROUGE_L": 0.29186602870813394, "CIDEr": 1.752315841084732e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1875, "f": 0.24000000000000005, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man standing in a living room. He is holding a wii remote in his hand. The man is wearing a striped sweater and a pair of jeans. The room is decorated with a couch and a bookshelf. The fireplace is made of brick."}, "407042": {"image_id": 407042, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.12909944487067912, "Bleu_3": 0.09186218331858677, "Bleu_4": 0.06554510293192194, "METEOR": 0.1918902516015081, "ROUGE_L": 0.2350674373795761, "CIDEr": 2.9219839959271197e-06, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.13333333333333333, "f": 0.09302325581395349, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows four children standing in front of a table with stuffed animals. The children are holding stuffed animals. One of the stuffed animals is a dog.\n\nThere are no other people in the scene.\n\nThere are no tents or tables in the scene."}, "170784": {"image_id": 170784, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.17616606584843764, "Bleu_3": 1.0348931048234187e-06, "Bleu_4": 2.531224579106017e-09, "METEOR": 0.29029727638979574, "ROUGE_L": 0.32972972972972975, "CIDEr": 0.0020068527882644398, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a red bus parked on the street. The bus has a sign on the side that reads \"123 bank\". There are three people walking on the sidewalk."}, "189744": {"image_id": 189744, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.21623201167707057, "Bleu_3": 0.1485964283978739, "Bleu_4": 0.08749017223994217, "METEOR": 0.24383403165474926, "ROUGE_L": 0.2644576914144151, "CIDEr": 1.2899421935771574e-14, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a building with a red brick exterior. The building is a red brick building with a white facade. There is a sign on the front of the building that reads \"domino's pizza\". There are several cars parked in front of the building. The street is lined with trees. The peacock alehouse is in the background."}, "222440": {"image_id": 222440, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.11447636746877136, "Bleu_3": 7.587583354772992e-07, "Bleu_4": 1.970053892727639e-09, "METEOR": 0.11608247085143365, "ROUGE_L": 0.19242902208201892, "CIDEr": 0.00041413117221193664, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows an enclosure with a giraffe, a zebra, and a gira inside. The enclosure is surrounded by a fence. \n\nThere are no people, trees, or other animals in the image."}, "78060": {"image_id": 78060, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1565560727682472, "Bleu_3": 0.0788478660803684, "Bleu_4": 1.0001000249876893e-05, "METEOR": 0.23832967465413546, "ROUGE_L": 0.2544696066746126, "CIDEr": 7.856964402216942e-11, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.12, "f": 0.14285714285714282, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a woman and a child standing on a snow-covered slope. The woman is wearing a black jacket and green pants, while the child is wearing a green snow suit. They are both holding skis and a ski pole. \n\nThere is no mountain range, peak, or tree in the scene."}, "224647": {"image_id": 224647, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.3960590171788445, "Bleu_3": 0.3397451558334295, "Bleu_4": 0.282011638932719, "METEOR": 0.4208749814165901, "ROUGE_L": 0.3954619124797406, "CIDEr": 0.0287438506922947, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a young girl holding a tennis racket and standing on a green field with other children. She is wearing an orange and white dress and white shoes. The sky is blue."}, "301326": {"image_id": 301326, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.11582156166137168, "Bleu_3": 7.006558330325156e-07, "Bleu_4": 1.7345333611892186e-09, "METEOR": 0.17288790060654322, "ROUGE_L": 0.2260934025203855, "CIDEr": 2.005339020566447e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two cats standing on the floor near two fences. The cats are brown and black respectively. The fence is made of metal and has a gate that is not open. The fence is surrounded by plants and trees."}, "128058": {"image_id": 128058, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.1923131632828435, "Bleu_3": 1.0090325449929141e-06, "Bleu_4": 2.32761887046409e-09, "METEOR": 0.29977810288657497, "ROUGE_L": 0.28728414442700156, "CIDEr": 6.875528964297135e-06, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.23333333333333334, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and gray shorts, and has a racket in his hand. The court is made of clay. There are trees in the background."}, "123867": {"image_id": 123867, "Bleu_1": 0.1866666666641778, "Bleu_2": 0.15067416069815426, "Bleu_3": 0.10754863376328312, "Bleu_4": 0.07667045632811215, "METEOR": 0.2029830707795854, "ROUGE_L": 0.19741100323624594, "CIDEr": 6.075717730849257e-24, "SPICE": {"All": {"pr": 0.125, "re": 0.11538461538461539, "f": 0.12000000000000001, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a dog running with a frisbee in a park. The dog is brown and carrying a frisbee. \n\nIn the background, there is a boy playing with a ball. The girl is not present in the scene.\n\nThe dog is a small, fluffy brown dog with a red collar and a leash. The boy is wearing a black hat. The girl is not wearing a pink dress as mentioned in the original passage."}, "331753": {"image_id": 331753, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.11644450194595923, "Bleu_3": 0.061603207790807316, "Bleu_4": 8.0026492316705e-06, "METEOR": 0.19747434606041508, "ROUGE_L": 0.25258799171842644, "CIDEr": 2.8985707739479388e-15, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2222222222222222, "f": 0.24489795918367346, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a row of three toilets with white seats and handles. The handles of the toilets are white and green. The toilets are arranged in a row with the handles facing towards the left. There are a lot of boxes and stacks of toilet paper around the toilets. The toilets are located in a warehouse or storage area."}, "425690": {"image_id": 425690, "Bleu_1": 0.29508196720827734, "Bleu_2": 0.17177950029132097, "Bleu_3": 0.07937740303726576, "Bleu_4": 9.63641879964677e-06, "METEOR": 0.21106652229320277, "ROUGE_L": 0.19794483504597077, "CIDEr": 4.5729208352407177e-17, "SPICE": {"All": {"pr": 0.25, "re": 0.23809523809523808, "f": 0.24390243902439024, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image is a black and white photograph that depicts a city at night. The photograph captures a city at night, with a street illuminated by streetlights. There are no cars or pedestrians in the scene. The buildings on either side of the street are visible, and the sky is dark and cloudy, with a few stars visible in the distance."}, "225658": {"image_id": 225658, "Bleu_1": 0.33333333331944454, "Bleu_2": 0.2407717061612882, "Bleu_3": 0.13812196234991525, "Bleu_4": 1.8820979915064717e-05, "METEOR": 0.2791014653321239, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.049328984606809165, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "There is no man in this image. There is a suit and a tie in the image. There is a hand holding a handgun."}, "331236": {"image_id": 331236, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.25537695921626896, "Bleu_3": 0.14589756469055823, "Bleu_4": 1.9850823738142324e-05, "METEOR": 0.24600931784861912, "ROUGE_L": 0.28273464658169173, "CIDEr": 0.10616063544529832, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.08, "f": 0.09523809523809526, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a blue t-shirt with a blue and orange design on it. There is an orange frisbee next to the t-shirt."}, "47225": {"image_id": 47225, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.4364357804516745, "Bleu_3": 0.3624601243170113, "Bleu_4": 0.22374677076390884, "METEOR": 0.34316188836004774, "ROUGE_L": 0.5590631364562119, "CIDEr": 0.26421561816551886, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of three stuffed animals sitting on a table. There are no bears or tigers in the scene."}, "64300": {"image_id": 64300, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2296698215877162, "Bleu_3": 1.046686633477467e-06, "Bleu_4": 2.2467739515425633e-09, "METEOR": 0.2295295778548837, "ROUGE_L": 0.23461538461538461, "CIDEr": 1.7680629926738325e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a pelican standing on a sandbar in the beach. The pelican is preparing to dive and is looking towards the water. The pelican is spreading out its wings. The pelican is a bird that is a member of the genus pelican. The pelican has wings."}, "59547": {"image_id": 59547, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 0.11726797422183437, "Bleu_4": 0.09868981544258462, "METEOR": 0.22597322647882287, "ROUGE_L": 0.2770478507704785, "CIDEr": 2.13985079558249e-11, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.07142857142857142, "f": 0.0851063829787234, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a woman holding a plate with two cupcakes. The woman is wearing a blue shirt and jeans, and she has a smile on her face. The cupcakes are decorated with colorful frosting and sprinkles. The woman is standing in front of a green plate. \n\nThere is no house in the scene."}, "501538": {"image_id": 501538, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.265684465654326, "Bleu_3": 0.18582888161281605, "Bleu_4": 0.1190001243700155, "METEOR": 0.22405565949746947, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.00015015201071439174, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image features a woman holding a banana in her hand. She is wearing a gray t-shirt with a banana written on it. The background of the image is a blue wall with blue graffiti."}, "318471": {"image_id": 318471, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.22190634114281918, "Bleu_3": 0.11667896745206957, "Bleu_4": 1.5169250360908672e-05, "METEOR": 0.21578922366888215, "ROUGE_L": 0.3015323776569451, "CIDEr": 0.0004437493748505859, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a street sign with the names of two people, one on each side of the sign. The sign is made of metal and has a blue background with white letters."}, "6091": {"image_id": 6091, "Bleu_1": 0.13043478260586014, "Bleu_2": 0.07613869876101455, "Bleu_3": 0.05088456599619497, "Bleu_4": 7.439991547036207e-06, "METEOR": 0.16621848000544118, "ROUGE_L": 0.16158940397350993, "CIDEr": 2.4821916624233986e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "There is no person in this image. There is a stop sign in the image. There is no car in the image. There is no shirt, pants, or hat in the image. There is a road in the image. There is no streetlight in the image."}, "73": {"image_id": 73, "Bleu_1": 0.16666666666269844, "Bleu_2": 0.06375767130479733, "Bleu_3": 4.666611359221816e-07, "Bleu_4": 1.2705304372811575e-09, "METEOR": 0.14050179211469535, "ROUGE_L": 0.1701534170153417, "CIDEr": 1.7290130535162692e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23076923076923078, "f": 0.25531914893617025, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows two motorcycles parked on the side of the road. One motorcycle is silver and the other is black. The motorcycles have black tires, black seats, and silver engines. The motorcycles have number plates on the front, which are black."}, "196715": {"image_id": 196715, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.20597146021314577, "Bleu_3": 0.17023095994636142, "Bleu_4": 0.13700830775392175, "METEOR": 0.24523512656562774, "ROUGE_L": 0.2922655715263518, "CIDEr": 7.452644725802452e-08, "SPICE": {"All": {"pr": 0.09375, "re": 0.125, "f": 0.10714285714285714, "fn": 21.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a white truck parked on a sandy beach. There is a person running on the beach and another person walking on the beach. The truck has a surfboard on the back and a person is standing on the side of the truck."}, "461467": {"image_id": 461467, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 0.09041487870756197, "Bleu_4": 0.06170031538925975, "METEOR": 0.22390739074668325, "ROUGE_L": 0.30198019801980197, "CIDEr": 6.403072635982304e-11, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.16666666666666666, "f": 0.1509433962264151, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two people sitting at a table in a restaurant. They are both wearing glasses and have their hands on the table. The people are eating a pizza, which has mushrooms and onions as toppings. \n\nThere is no wall or window in the scene, and there is no view of the city."}, "398066": {"image_id": 398066, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1457945082861785, "Bleu_3": 0.09885983548206408, "Bleu_4": 1.2243280475333732e-05, "METEOR": 0.18036895583427504, "ROUGE_L": 0.2367399741267788, "CIDEr": 8.582623267791235e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.13793103448275862, "f": 0.1568627450980392, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a baseball game being played on a field. The players are wearing baseball uniforms and are holding a baseball bat. There is a large tree in the background, and a city is also visible in the distance. The field is green and well-maintained."}, "431140": {"image_id": 431140, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.18994132206127556, "Bleu_3": 0.13398285197459078, "Bleu_4": 0.08598520764469421, "METEOR": 0.2550575100879589, "ROUGE_L": 0.33414485696895924, "CIDEr": 5.880318318266621e-08, "SPICE": {"All": {"pr": 0.3125, "re": 0.18518518518518517, "f": 0.2325581395348837, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a bathroom with two toilets, a sink, and a mirror. The walls are painted white and the floor is made of tan tile. There is a door on the right side of the room. The toilets are standard size and the sink is small."}, "67315": {"image_id": 67315, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.19154015512649578, "Bleu_3": 0.1283943344001008, "Bleu_4": 0.09544965216004304, "METEOR": 0.22855881026586297, "ROUGE_L": 0.28367380833748546, "CIDEr": 2.1735908156358004e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.0625, "f": 0.0975609756097561, "fn": 30.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.14285714285714285, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a man wearing a tie standing in front of a window. The man is wearing a black pants and a white shirt. The tie is blue. The background is a white wall with a window.\n\nThere is no suit in the image. The man is not looking down at his hands."}, "261777": {"image_id": 261777, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1630820182599269, "Bleu_3": 0.10496103543446565, "Bleu_4": 1.2660998324356511e-05, "METEOR": 0.25424031312071843, "ROUGE_L": 0.23461538461538461, "CIDEr": 7.698997646658154e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.19230769230769232, "f": 0.2173913043478261, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a person doing a trick on a snowboard. The person is jumping off the snowboard and is in mid-air. The person is wearing a black jacket and blue pants, and has a white and gold helmet on their head. The background is a blue sky."}, "62296": {"image_id": 62296, "Bleu_1": 0.19999999999428575, "Bleu_2": 0.10846522890618356, "Bleu_3": 7.090698915331589e-07, "Bleu_4": 1.8269610522029373e-09, "METEOR": 0.12465636168781395, "ROUGE_L": 0.19757085020242915, "CIDEr": 2.800067917737615e-05, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14285714285714285, "f": 0.16, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a marina with boats docked at the docks. The boats are small in size and are colored blue and white. There are no people standing on the docks. The sky is blue."}, "329088": {"image_id": 329088, "Bleu_1": 0.2187499999931641, "Bleu_2": 0.08400268812636352, "Bleu_3": 6.172887627196749e-07, "Bleu_4": 1.6875893609316949e-09, "METEOR": 0.14405870940799506, "ROUGE_L": 0.2040133779264214, "CIDEr": 0.00037329268847193127, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two people doing skiing on a snowy slope. The people are holding ski poles. One of the skiers is wearing black pants. The skiers have backpacks on their backs."}, "337120": {"image_id": 337120, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.24094636829087762, "Bleu_3": 0.1505903985438184, "Bleu_4": 1.6166107444596474e-05, "METEOR": 0.19145203486568213, "ROUGE_L": 0.28103661044837513, "CIDEr": 2.2383938244246107e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 27.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a building with a clock on the side. A bicycle is parked on the sidewalk in front of the building.\n\nThe building appears to be old and has a lot of character. The clock on the side is old. The sky is blue and there are trees in the background."}, "60240": {"image_id": 60240, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.266556994977913, "Bleu_3": 0.19911893129648386, "Bleu_4": 0.14679869138957788, "METEOR": 0.29841130275013605, "ROUGE_L": 0.2961165048543689, "CIDEr": 0.31269160341546687, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows two people holding a cell phone. One person is wearing a blue jacket. The windows are blue."}, "134657": {"image_id": 134657, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.21915646613065012, "Bleu_3": 0.1526598869426813, "Bleu_4": 0.10815593729213914, "METEOR": 0.2798956100127957, "ROUGE_L": 0.3489037178265014, "CIDEr": 0.0034236646524684233, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a highway with a bridge over it. The sky is clear and blue. There are three cars on the road.\n\nThe bridge is made of steel."}, "166979": {"image_id": 166979, "Bleu_1": 0.16666666666269844, "Bleu_2": 0.11043152607218519, "Bleu_3": 6.730418227629333e-07, "Bleu_4": 1.6721120911708975e-09, "METEOR": 0.15250816170081272, "ROUGE_L": 0.16073781291172595, "CIDEr": 9.160389301275293e-07, "SPICE": {"All": {"pr": 0.15, "re": 0.10714285714285714, "f": 0.125, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows three boats in the water. The boats are red and black, blue and white, and white. There is a building in the background. The San Francisco skyline is also visible in the background. The building is an office building."}, "160437": {"image_id": 160437, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.27735009810173394, "Bleu_3": 1.4743993654832992e-06, "Bleu_4": 3.435812002319317e-09, "METEOR": 0.1823409196371279, "ROUGE_L": 0.3131416837782341, "CIDEr": 0.01307407394273685, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows two zebras lying on the ground in a zoo enclosure. The zebras have stripes on their bodies. The zebras are in the dirt."}, "426815": {"image_id": 426815, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.344350221559779, "Bleu_3": 0.30449755822483004, "Bleu_4": 0.2741229265264104, "METEOR": 0.2882489339789895, "ROUGE_L": 0.5025746652935119, "CIDEr": 0.14613623565933553, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man riding a horse in the water. The horse is brown. The man is wearing a helmet and boots."}, "31749": {"image_id": 31749, "Bleu_1": 0.15068493150478515, "Bleu_2": 0.045747636779081044, "Bleu_3": 3.0890598774534826e-07, "Bleu_4": 8.055550692680164e-10, "METEOR": 0.12573029789967635, "ROUGE_L": 0.13677130044843047, "CIDEr": 3.7726595054560174e-24, "SPICE": {"All": {"pr": 0.2, "re": 0.13043478260869565, "f": 0.15789473684210528, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features two girls. One girl is sitting on a clock and looking at it, while the other girl is reading a book and also looking at a clock. The dress of the first girl is red, and the dress of the second girl is white. The clock on the wall is showing the time half past seven. The girl sitting on the clock is wearing yellow gloves. The floor is brown."}, "54337": {"image_id": 54337, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.07441168295431691, "Bleu_3": 5.130576084588407e-07, "Bleu_4": 1.3555314602460315e-09, "METEOR": 0.16302266640043428, "ROUGE_L": 0.21254355400696864, "CIDEr": 8.593848246944092e-07, "SPICE": {"All": {"pr": 0.21875, "re": 0.2916666666666667, "f": 0.25, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4666666666666667, "re": 0.6363636363636364, "f": 0.5384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}}, "caption": "This is an image of five people sitting around two tables in a room. The people are wearing suits and ties. Some of the people are drinking beer. Some of the people are drinking wine. There are bottles of alcohol on the table."}, "161044": {"image_id": 161044, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 0.11515158022011021, "Bleu_4": 0.07764975754306437, "METEOR": 0.2523432355101962, "ROUGE_L": 0.25902335456475584, "CIDEr": 1.5125490109192108e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.17391304347826086, "f": 0.22857142857142854, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows two planes flying in the sky. One is a small plane with a white stripe on the side, and the other is a larger plane with a white stripe on the side. The small plane is in front of the larger plane."}, "161978": {"image_id": 161978, "Bleu_1": 0.21428571428265308, "Bleu_2": 0.07881104062277605, "Bleu_3": 4.5035508463561064e-07, "Bleu_4": 1.0805568035118135e-09, "METEOR": 0.11539205098074122, "ROUGE_L": 0.17112399476341872, "CIDEr": 2.6870109339645257e-18, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.8, "f": 0.47058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of four people skateboarding on a concrete skate park. The skateboarders are wearing green t-shirts and black pants. They are riding skateboards and performing various tricks on the ramps and rails of the skate park.\n\nThere are a total of thirteen skateboards in the image, scattered throughout the skate park.\n\nThe skateboarders are wearing sneakers.\n\nThere are no other people or objects in the scene."}, "106046": {"image_id": 106046, "Bleu_1": 0.2153846153813018, "Bleu_2": 0.16408253082592936, "Bleu_3": 0.1288006482937251, "Bleu_4": 0.10083723486121435, "METEOR": 0.23644289266231241, "ROUGE_L": 0.27594873083689364, "CIDEr": 1.2460539077779439e-17, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.19047619047619047, "f": 0.1818181818181818, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a girl sitting at a table with a plate of food in front of her. The table is covered with a white tablecloth. There are two chairs on either side of the table. The girl is wearing a brown sweater and has a bow in her hair. \n\nThere are four plates with food on the table. \n\nOne of the plates is missing."}, "138970": {"image_id": 138970, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.09897882079639587, "Bleu_3": 0.057699421416016236, "Bleu_4": 7.872924608075425e-06, "METEOR": 0.18260711076068575, "ROUGE_L": 0.226906385616863, "CIDEr": 4.4693789150951003e-13, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.12, "f": 0.13636363636363635, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows three people standing around a white refrigerator. They are wearing casual clothing, with one person wearing a red shirt, another person wearing a white shirt, and the third person wearing a green shirt. The people are loading the refrigerator into the back of a truck, using ropes to secure it."}, "450037": {"image_id": 450037, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.15811388300441548, "Bleu_3": 0.08697320427224375, "Bleu_4": 1.1547518640761465e-05, "METEOR": 0.2029792058035513, "ROUGE_L": 0.2691176470588235, "CIDEr": 1.4366787977395337e-06, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13043478260869565, "f": 0.11538461538461538, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of four people standing in a field with horses. The people are wearing riding clothes and holding a stick. The horses are wearing a saddle. The field is brown. There are trees in the distance."}, "237869": {"image_id": 237869, "Bleu_1": 0.11428571428408166, "Bleu_2": 0.09968895725441093, "Bleu_3": 0.07596883787328153, "Bleu_4": 8.994104132811597e-06, "METEOR": 0.15335504980317352, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.2495188684765274e-20, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.06451612903225806, "f": 0.07017543859649122, "fn": 29.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image features a clock on a shelf in a train station. The clock is made of plastic. The clock face is a round shape and has numbers and hands. A white circle is on the clock face. The clock is surrounded by a metal frame. There is a small handle on the side of the clock. The clock is located on top of the shelf in the train station."}, "323598": {"image_id": 323598, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.14580296087694455, "Bleu_3": 0.0967137615427347, "Bleu_4": 0.06659271909376246, "METEOR": 0.18277111080225178, "ROUGE_L": 0.26940063091482647, "CIDEr": 3.253742131709791e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.1935483870967742, "f": 0.21818181818181817, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a bathroom with a bathtub, sink, and toilet. The walls are painted white. The floors are made of wood. The room has a skylight and a window with a blind. There is a mirror on the wall opposite the sink. A shower is opposite the sink."}, "261948": {"image_id": 261948, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.20683507599183215, "Bleu_3": 1.1016225079815204e-06, "Bleu_4": 2.5626197980885998e-09, "METEOR": 0.19718161293722022, "ROUGE_L": 0.20573355817875214, "CIDEr": 0.00030243855317450645, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is of a suitcase with a floral pattern on the outside. The suitcase has a green lining and is made of plastic. There is no handle or wooden crate in the scene."}, "438539": {"image_id": 438539, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.1288848155535838, "Bleu_3": 7.399571153427093e-07, "Bleu_4": 1.7839797285693462e-09, "METEOR": 0.17209704774740164, "ROUGE_L": 0.21254355400696864, "CIDEr": 8.177231789012621e-08, "SPICE": {"All": {"pr": 0.10256410256410256, "re": 0.16666666666666666, "f": 0.12698412698412698, "fn": 20.0, "numImages": 1.0, "fp": 35.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "The image shows a group of five people playing frisbee on a grassy field. The people are wearing different colored shirts and pants. Some of the people are holding a frisbee. The people are wearing blue shorts. A frisbee is on the field."}, "204044": {"image_id": 204044, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.17205295744403565, "Bleu_3": 0.08697022430943882, "Bleu_4": 1.105769924492212e-05, "METEOR": 0.25739368799884754, "ROUGE_L": 0.2501708817498291, "CIDEr": 3.155915111149981e-08, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a kitchen with white appliances and wooden cabinets. The appliances are white. The cabinets are made of wood. \n\nThere is a stove, refrigerator, and sink in the kitchen. \n\nThe floor is made of hardwood. \n\nThe kitchen has a window with a view of the street."}, "142454": {"image_id": 142454, "Bleu_1": 0.339622641503026, "Bleu_2": 0.24244760629354595, "Bleu_3": 0.1905192918189981, "Bleu_4": 0.14272236429650256, "METEOR": 0.27123716449221796, "ROUGE_L": 0.38927296209070883, "CIDEr": 2.6037512163496233e-05, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows two cats sitting on a bathroom counter next to a sink. The cats are sitting on the counter and looking at each other. The sink is filled with water. There are towels hanging on the wall. A mirror is hanging on the wall and shows the reflection of a cat."}, "239455": {"image_id": 239455, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.16496470132732644, "Bleu_3": 0.08110929465213233, "Bleu_4": 1.0163901964340892e-05, "METEOR": 0.18381294268628184, "ROUGE_L": 0.24007646463510626, "CIDEr": 1.8841507367344296e-11, "SPICE": {"All": {"pr": 0.15625, "re": 0.25, "f": 0.19230769230769232, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.25, "f": 0.11111111111111112, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of six boats docked at two piers. The boats are red and white. The boats do not have a small cabin on top. The pier is made of wood.\n\nThere is no body of water, cloud, or wood in the scene. There is no sky in the scene."}, "409725": {"image_id": 409725, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.16265001215217242, "Bleu_3": 0.10057999677998902, "Bleu_4": 1.4203609079186458e-05, "METEOR": 0.24391559683939884, "ROUGE_L": 0.37044534412955465, "CIDEr": 0.005847655941508174, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.38461538461538464, "f": 0.2857142857142857, "fn": 8.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a group of 20 people standing on a sidewalk in front of 10 buildings. The people are holding kites and looking up at the sky."}, "299493": {"image_id": 299493, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.11429089766174176, "Bleu_3": 6.350643060633274e-07, "Bleu_4": 1.5044258140708105e-09, "METEOR": 0.20400772699641587, "ROUGE_L": 0.18100890207715134, "CIDEr": 5.680067652469568e-12, "SPICE": {"All": {"pr": 0.375, "re": 0.2, "f": 0.26086956521739135, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows two buses driving down the street. One bus is yellow and the other is yellow and green. The yellow bus is parked on the side of the road. There is a building in the background.\n\nThe yellow bus is a school bus with a white roof and a black stripe."}, "460390": {"image_id": 460390, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.11065666703226194, "Bleu_3": 6.342171440889115e-07, "Bleu_4": 1.5263496054154453e-09, "METEOR": 0.1429552809955083, "ROUGE_L": 0.15501905972045746, "CIDEr": 5.672026383930486e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2608695652173913, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows three people doing skiing on a snowy slope. They are wearing ski gear and have their skis pointed downwards. The people are wearing a black jacket, a green jacket and black pants, and a black hat and a black shirt. The slope is like a steep slope."}, "473002": {"image_id": 473002, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.214201664184383, "Bleu_3": 0.12326123997631014, "Bleu_4": 1.4054311981084246e-05, "METEOR": 0.20959480241362344, "ROUGE_L": 0.23416506717850286, "CIDEr": 2.749508257711965e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a boy riding a skateboard. The boy is wearing a black shirt and jeans. He is standing on a skateboard and holding onto it. \n\nThere are also people walking down the sidewalk. \n\nThere is no sky or cloud in the image. There are no trees in the scene."}, "523470": {"image_id": 523470, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.27174648818404223, "Bleu_3": 0.1454472607016038, "Bleu_4": 1.9124813148101802e-05, "METEOR": 0.25883432431227393, "ROUGE_L": 0.36237623762376237, "CIDEr": 0.04088016843576271, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.0625, "f": 0.07272727272727272, "fn": 30.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a plate with a skewer of beef on top. The skewer contains meat and vegetables. There is a brown tablecloth underneath the plate."}, "85944": {"image_id": 85944, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.15891043153801604, "Bleu_3": 0.09840556216680423, "Bleu_4": 1.1634933331700792e-05, "METEOR": 0.18994683913613386, "ROUGE_L": 0.21095100864553315, "CIDEr": 3.6426474527322964e-13, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of twelve people standing behind the bar in a restaurant. The people are drinking wine, preparing drinks, taking pictures, playing a game, eating, posing for a picture, and eating a sandwich or cake. They are wearing various colored shirts, suits, vests, denim jackets, and glasses. Glasses are on the counter."}, "258523": {"image_id": 258523, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.17213259316161544, "Bleu_3": 0.13076859215453357, "Bleu_4": 0.09630176550491282, "METEOR": 0.22856734096402195, "ROUGE_L": 0.3099943534726144, "CIDEr": 8.213462428550692e-13, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.35294117647058826, "f": 0.26666666666666666, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a black cat lying on top of two toilet seats. The cat is wearing a black collar. The cat's paws are tucked under its body. The toilet seats are made of plastic. The bathroom is tiled with white porcelain. There is a clear glass cover on top of the toilet seats."}}}