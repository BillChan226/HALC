{"overall": {"Bleu_1": 0.2795583784648076, "Bleu_2": 0.18805883601297302, "Bleu_3": 0.11855801794549718, "Bleu_4": 0.07434988880184347, "METEOR": 0.22375129429545842, "ROUGE_L": 0.2852071971024843, "CIDEr": 0.010747223192977846, "SPICE": 0.20917245067433493}, "imgToEval": {"281533": {"image_id": 281533, "Bleu_1": 0.37037037036351167, "Bleu_2": 0.23644230070621639, "Bleu_3": 0.14774838920061847, "Bleu_4": 0.1060491082518161, "METEOR": 0.2690505135943335, "ROUGE_L": 0.29151732377538825, "CIDEr": 6.756539894523076e-11, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a brown dog sitting on the floor in front of a television, intently watching a wildlife show. The dog is captivated by the animals on the screen. \n\nIn the room, there are two potted plants, with one located near the left side of the dog and another near the right side."}, "397773": {"image_id": 397773, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.21997067252504504, "Bleu_3": 1.172742786111253e-06, "Bleu_4": 2.730879756608669e-09, "METEOR": 0.2632739775409384, "ROUGE_L": 0.2713523131672598, "CIDEr": 0.0013052479760898555, "SPICE": {"All": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a pasta dish served on a white plate. The dish includes broccoli, sausage, and cheese. The broccoli is scattered throughout the dish, and the pasta is of different sizes."}, "371250": {"image_id": 371250, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.11926756082899304, "Bleu_3": 7.33805098169319e-07, "Bleu_4": 1.8330256088670778e-09, "METEOR": 0.22537139806948903, "ROUGE_L": 0.26483357452966716, "CIDEr": 4.3275029247523716e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5, "f": 0.588235294117647, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a brown couch with a pineapple design on it, placed in a living room. The couch is positioned in the center of the room. There are four pillows on the couch, including two pineapple-themed pillows."}, "573877": {"image_id": 573877, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.24798277706238742, "Bleu_3": 0.18082975741512392, "Bleu_4": 0.12340063077851947, "METEOR": 0.2789324668503929, "ROUGE_L": 0.35502645502645497, "CIDEr": 3.3649785833485814e-10, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a cat sitting in front of a computer monitor. The cat is looking at a screen, and its attention is focused on the content displayed on the screen. The cat is positioned on the left side of the monitor. The monitor is quite large, occupying a significant portion of the background."}, "181859": {"image_id": 181859, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.3110855084092494, "Bleu_3": 0.2131015066738094, "Bleu_4": 0.16073034971813754, "METEOR": 0.29376635243662735, "ROUGE_L": 0.39246323529411764, "CIDEr": 0.0014622659663530192, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21052631578947367, "f": 0.2580645161290323, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a cat comfortably laying down in a sink. The cat is positioned in the center of the sink, occupying most of the space. The sink is made of stone."}, "119939": {"image_id": 119939, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.22454435656302607, "Bleu_3": 0.1828311173754695, "Bleu_4": 0.15471428129195675, "METEOR": 0.33250990945603626, "ROUGE_L": 0.3108544250042466, "CIDEr": 6.693902747427226e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features two men riding skateboards down a sidewalk. The men are doing skateboarding. They are all wearing white shirts. One of the skateboarders is positioned more towards the left side of the image."}, "385320": {"image_id": 385320, "Bleu_1": 0.370370370356653, "Bleu_2": 0.11935247900206675, "Bleu_3": 8.290377243671376e-07, "Bleu_4": 2.2073840969171685e-09, "METEOR": 0.23054905674584505, "ROUGE_L": 0.2946859903381643, "CIDEr": 0.012926067503279494, "SPICE": {"All": {"pr": 0.4, "re": 0.38095238095238093, "f": 0.3902439024390244, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a toddler brushing her teeth with a blue and white toothbrush. The child is wearing a striped shirt and is standing in a room."}, "490415": {"image_id": 490415, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.24253562502930154, "Bleu_3": 0.19247118049746445, "Bleu_4": 0.12217624912302373, "METEOR": 0.3167965319655202, "ROUGE_L": 0.34078212290502796, "CIDEr": 0.0001848920335269535, "SPICE": {"All": {"pr": 0.125, "re": 0.10344827586206896, "f": 0.11320754716981132, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a man flying a kite in a park. He is skillfully maneuvering the kite in the sky, with the kite visible in the sky. There are no other people in the scene."}, "432293": {"image_id": 432293, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.191273013914278, "Bleu_3": 0.097892089462343, "Bleu_4": 1.2534724690400046e-05, "METEOR": 0.23229141098345968, "ROUGE_L": 0.3083032490974729, "CIDEr": 1.0092225364426057e-06, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08, "f": 0.0909090909090909, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a pizza sitting on a wooden cutting board, which is placed on a dining table. The pizza is covered in shrimp, tomatoes, and parsley. The cutting board is made of wood. The dining table is made of wood."}, "256301": {"image_id": 256301, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.1363861813953473, "Bleu_3": 0.08434506592863017, "Bleu_4": 9.958921354612942e-06, "METEOR": 0.13868628094056956, "ROUGE_L": 0.18011811023622049, "CIDEr": 1.939021116270835e-15, "SPICE": {"All": {"pr": 0.2, "re": 0.1724137931034483, "f": 0.1851851851851852, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a sign with a clock mounted on it. The clock's hands are on the 2:00 and 5:00 positions. The sign is featuring the word \"et\" and is illuminated, making it stand out against the white sky.\n\nThere are five people in the image. Some of the people are working on the sign, while others are working on a red bus."}, "361103": {"image_id": 361103, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.14414999402869194, "Bleu_3": 0.07273528851712342, "Bleu_4": 9.230812022099043e-06, "METEOR": 0.1806152802751418, "ROUGE_L": 0.2663755458515284, "CIDEr": 1.9214515000969814e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a busy city street with people walking. On the street are the people walking. Some of the people are carrying bags, handbags, suitcases, and other items. Two people are visible in the scene. \n\nThe street is lined with various shops, including a bookstore and a warehouse. A bank is also on the street."}, "567562": {"image_id": 567562, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.24462302738989036, "Bleu_3": 0.15744155315169847, "Bleu_4": 0.1147608865295581, "METEOR": 0.31667334940876646, "ROUGE_L": 0.33363719234275296, "CIDEr": 7.785725287064463e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.19047619047619047, "f": 0.22857142857142854, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a woman sitting at a dining table with two children, enjoying a meal together. The woman is eating a meal. The children are playing with a box of cereal and eating. The table is filled with various food items, including a bowl and two cups."}, "448320": {"image_id": 448320, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.2700308624253503, "Bleu_3": 0.19180597090845478, "Bleu_4": 0.14727321823506803, "METEOR": 0.2977039212853259, "ROUGE_L": 0.44963144963144963, "CIDEr": 0.002876424731783245, "SPICE": {"All": {"pr": 0.0625, "re": 0.03571428571428571, "f": 0.045454545454545456, "fn": 27.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a bathroom with a toilet, sink, and two mirrors. The toilet is located in the bathroom. The sink is situated under the toilet. A mirror is placed above the sink."}, "14874": {"image_id": 14874, "Bleu_1": 0.305555555547068, "Bleu_2": 0.2472066162295572, "Bleu_3": 0.2079076274361573, "Bleu_4": 0.16906536464365715, "METEOR": 0.2934041349855059, "ROUGE_L": 0.34885620915032683, "CIDEr": 0.00013072816949767963, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man standing in the snow, holding a snowboard and a pair of skis. He appears to be preparing for a day of skiing. The man is wearing a blue and green jacket."}, "373713": {"image_id": 373713, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.21182963642871727, "Bleu_3": 0.10569715108234483, "Bleu_4": 1.3365863767478914e-05, "METEOR": 0.22415068436744695, "ROUGE_L": 0.27199762187871585, "CIDEr": 3.6928091506621646e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features three people sitting around a table, each with a laptop in front of them. They appear to be engaged in a discussion or presentation, possibly about the topic displayed on the screen, which shows the word \"Stability\"."}, "539326": {"image_id": 539326, "Bleu_1": 0.24999999999218758, "Bleu_2": 0.12700012699615779, "Bleu_3": 0.0813134432663612, "Bleu_4": 1.1668694360293947e-05, "METEOR": 0.25374285224172466, "ROUGE_L": 0.22426470588235295, "CIDEr": 0.0004235466402060762, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.21428571428571427, "f": 0.18181818181818182, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a field covered with grass. There are at least 15 cows grazing on the grass. Some cows are closer to the foreground, while others are further in the background."}, "20059": {"image_id": 20059, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.16300321563702572, "Bleu_3": 0.08452397038337253, "Bleu_4": 1.0885986790308766e-05, "METEOR": 0.23069528747414145, "ROUGE_L": 0.24238410596026488, "CIDEr": 6.294576180797907e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1935483870967742, "f": 0.24489795918367346, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two zebras standing together in a grassy field. They are grazing on the grass. The position of the zebra on the left side is grazing on the grass. The position of the zebra on the right side is also grazing on the grass."}, "530520": {"image_id": 530520, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.23473823892604287, "Bleu_3": 0.17904635481650877, "Bleu_4": 0.13835025436702314, "METEOR": 0.2566047200220614, "ROUGE_L": 0.3100381194409149, "CIDEr": 3.314982774615782e-10, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.20833333333333334, "f": 0.24390243902439027, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts three men sitting on the grass. The young men are wearing jeans. Some of the men are sitting on the grass and using laptops. Others are playing with a remote control car. \n\nThere is a building in the background, and a motorcycle is parked outside the building."}, "117337": {"image_id": 117337, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.15585730003579046, "Bleu_3": 0.12535007820499042, "Bleu_4": 0.10227637589661816, "METEOR": 0.27343548210203333, "ROUGE_L": 0.2741573033707865, "CIDEr": 3.975181049912631e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image is a collage of various photographs featuring a mix of objects and people. There are four oranges scattered throughout the collage. Some of the oranges are placed on the table. There are no apples in the collage."}, "256504": {"image_id": 256504, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.14302403209718587, "Bleu_3": 0.07106368538272442, "Bleu_4": 8.947233841048188e-06, "METEOR": 0.20799879734839405, "ROUGE_L": 0.1994550408719346, "CIDEr": 8.59058782104943e-16, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20689655172413793, "f": 0.2553191489361702, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a bedroom with a bed and a desk. On the bed, there are two laptops. One of the laptops is on the bed. The other laptop is in the bed. A person is sitting in bed, hiding behind a laptop. The person is working on the laptop. The other laptop is left open, possibly for reference."}, "265472": {"image_id": 265472, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.17393131069069204, "Bleu_3": 0.12239317427147997, "Bleu_4": 1.5471428129195674e-05, "METEOR": 0.23428477421191482, "ROUGE_L": 0.31470335339638866, "CIDEr": 0.00010152104038653305, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.1111111111111111, "f": 0.10810810810810811, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a plate of breakfast food, including a serving of bananas and bacon. The bananas are scattered across the plate, with some pieces placed near the bacon. The bacon is cut into strips."}, "441083": {"image_id": 441083, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.2979847747790905, "Bleu_3": 0.20373530018116578, "Bleu_4": 0.11984053756396977, "METEOR": 0.26791371716127677, "ROUGE_L": 0.3512797074954296, "CIDEr": 3.002005199270679e-06, "SPICE": {"All": {"pr": 0.11904761904761904, "re": 0.20833333333333334, "f": 0.15151515151515152, "fn": 19.0, "numImages": 1.0, "fp": 37.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.13333333333333333, "re": 0.3333333333333333, "f": 0.19047619047619044, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.3333333333333333, "f": 0.23076923076923078, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image features a dog sticking its head out of a car window. The dog is enjoying a ride in the car, with its tongue hanging out. The dog's head is visible through the car window. In the background, there are several cars."}, "126958": {"image_id": 126958, "Bleu_1": 0.24590163934023115, "Bleu_2": 0.20244408254138263, "Bleu_3": 0.08856308180849698, "Bleu_4": 1.0461224978467163e-05, "METEOR": 0.17989717054845575, "ROUGE_L": 0.28276065043043186, "CIDEr": 7.488353866017698e-14, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a doorway with a clock mounted on the wall above it. The clock is positioned on the wall. A mirror is mounted on the wall above the doorway. The mirror is positioned towards the top-left corner of the wall. The doorway leads into a room with a blue and orange color scheme, creating a vibrant and lively atmosphere."}, "484075": {"image_id": 484075, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.13192248217215224, "Bleu_4": 0.09941963057042014, "METEOR": 0.2348682612683316, "ROUGE_L": 0.3129988597491448, "CIDEr": 4.4392292030983e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.42105263157894735, "f": 0.3404255319148936, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.7777777777777778, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image features two desks with computer setups. On the first desk, there is a computer, a keyboard, a mouse, a monitor, and a camera. On the second desk, there is a computer, a keyboard, a mouse, a monitor, and a camera. The keyboard is placed closer to the monitor."}, "274528": {"image_id": 274528, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.19154015512649578, "Bleu_3": 0.1283943344001008, "Bleu_4": 0.08026327033859419, "METEOR": 0.20921357772227803, "ROUGE_L": 0.27949599083619703, "CIDEr": 1.1022978919380087e-11, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.10714285714285714, "f": 0.16216216216216214, "fn": 25.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a white truck parked on a street. There is a large advertisement for a bicycle company on the side of the truck, promoting a cycling event. The truck is surrounded by a car and a bus. There are also several people in the scene, some of them standing near the truck."}, "286820": {"image_id": 286820, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.271063930087043, "ROUGE_L": 0.23091482649842268, "CIDEr": 2.0749640937926163e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13333333333333333, "f": 0.16666666666666669, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features two cell phones placed side by side on a green cloth. Both phones are turned on and appear to be identical in size and design. They are positioned close to each other, with one phone slightly to the left and the other slightly to the right."}, "69236": {"image_id": 69236, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 8.681823924888469e-07, "Bleu_4": 1.9987674397634184e-09, "METEOR": 0.16950380017312539, "ROUGE_L": 0.20890410958904113, "CIDEr": 1.0646296337337542e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a bench situated in the middle of a park, surrounded by trees and bushes. The bench is positioned near a sidewalk, providing a comfortable spot for visitors to sit and relax. The park is illuminated at night, with lights scattered throughout."}, "333237": {"image_id": 333237, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.25537695922201126, "Bleu_3": 0.20718294352928657, "Bleu_4": 0.1578260542463968, "METEOR": 0.28873852586040716, "ROUGE_L": 0.2969401947148818, "CIDEr": 1.9497959905560694e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of a bedroom with a bed and two chairs. The bed is situated in the middle of the room. The chair is located near the right side of the bed. The room is not decorated with red flowers."}, "285258": {"image_id": 285258, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.23204774044025306, "Bleu_3": 0.1415143113286697, "Bleu_4": 1.66360355848947e-05, "METEOR": 0.27674437687487885, "ROUGE_L": 0.32250755287009064, "CIDEr": 2.3379209960141154e-06, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.32142857142857145, "f": 0.35294117647058826, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.46153846153846156, "f": 0.4999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a group of four dogs playing together in a grassy field. The dogs are playing and are in different positions, some standing and some running. They are all positioned close to each other, creating a playful scene."}, "574454": {"image_id": 574454, "Bleu_1": 0.340909090901343, "Bleu_2": 0.19909945244613453, "Bleu_3": 9.809125257770397e-07, "Bleu_4": 2.1904167208100756e-09, "METEOR": 0.18608957881961036, "ROUGE_L": 0.2197406340057637, "CIDEr": 3.5085675440035297e-08, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.5263157894736842, "f": 0.46511627906976744, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 10.0}, "Relation": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8571428571428571, "f": 0.75, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image captures a beach scene with people kite surfing. The beach is located in front of a mountain range. There are two people enjoying water activities, such as kite surfing. The scene is lively and vibrant, with the ocean providing a beautiful backdrop."}, "57703": {"image_id": 57703, "Bleu_1": 0.21874999999658204, "Bleu_2": 0.10206207261435839, "Bleu_3": 5.517966071795556e-07, "Bleu_4": 1.2882549225122457e-09, "METEOR": 0.19342888159182628, "ROUGE_L": 0.1840305711987128, "CIDEr": 1.040756460307194e-17, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2, "f": 0.21428571428571427, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image depicts three people walking through a forest. The people are talking to each other. One person is walking a dog, while another person is also walking a dog. The third person is walking a dog. The dogs are dispersed, with two dogs on the left side of the group and one dog in the middle. The people are standing on the trail."}, "70294": {"image_id": 70294, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.15541746803663614, "Bleu_3": 0.08188084718265139, "Bleu_4": 1.0629666321559288e-05, "METEOR": 0.22057053641972432, "ROUGE_L": 0.2447178389943835, "CIDEr": 8.77678281686358e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a blue bus driving down a street. The bus is positioned towards the right side of the scene, and it appears to be a passenger bus. There are no people closer to the bus. There are no people further away from the bus."}, "279769": {"image_id": 279769, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.18837162993777626, "Bleu_3": 1.0695743954365786e-06, "Bleu_4": 2.5710986510668226e-09, "METEOR": 0.19915040016316793, "ROUGE_L": 0.3125533731853117, "CIDEr": 0.0024106409381289182, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.8, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a table with a banana and a piece of paper on it. The banana is placed on the table. The piece of paper is located on the table."}, "541474": {"image_id": 541474, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.2721655269656347, "Bleu_3": 0.14362897932992935, "Bleu_4": 1.8744710838941805e-05, "METEOR": 0.3036237272523218, "ROUGE_L": 0.38006230529595014, "CIDEr": 0.007557883296416431, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2608695652173913, "f": 0.28571428571428575, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image captures a person doing snowboarding on a snow-covered slope. The person is wearing a blue and white jacket. The skier is going down a hill."}, "217561": {"image_id": 217561, "Bleu_1": 0.23529411764359862, "Bleu_2": 0.13251136747635742, "Bleu_3": 0.06431625947989915, "Bleu_4": 7.998568064870978e-06, "METEOR": 0.16000000000000003, "ROUGE_L": 0.20548604427333975, "CIDEr": 4.9847233072109255e-20, "SPICE": {"All": {"pr": 0.2, "re": 0.17857142857142858, "f": 0.1886792452830189, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a dining table set with 11 plates, each with different colors. There are also four forks, a knife, and five spoons on the table. A toothbrush and toothpaste are also present. Additionally, there are 14 cups in the scene. A toothbrush is placed on one of the plates. The overall scene is set on a dining table, with various utensils and items placed on it."}, "303778": {"image_id": 303778, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.1332650098148157, "Bleu_3": 0.06701830194835842, "Bleu_4": 8.487661803821794e-06, "METEOR": 0.24045946477257393, "ROUGE_L": 0.22652519893899206, "CIDEr": 1.3032723564899293e-16, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1111111111111111, "f": 0.10256410256410256, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures two baseball players in the middle of a game, both holding a baseball bat and preparing to run. They are standing on a baseball field. The players are wearing baseball uniforms, with one player wearing a white uniform and the other wearing a white and blue uniform. They are also wearing helmets and baseball caps on their heads."}, "40426": {"image_id": 40426, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 7.901769277795583e-07, "Bleu_4": 1.8299115122529755e-09, "METEOR": 0.18410916628865334, "ROUGE_L": 0.15183571873055382, "CIDEr": 4.620889723003045e-08, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14285714285714285, "f": 0.18604651162790697, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a blender on the kitchen counter. A jar of jam is near the blender. The bowl of fruit is situated on the right side of the counter. There are five fruits in the bowl, including strawberries. There are also seven bottles on the counter."}, "324291": {"image_id": 324291, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.24809883171680105, "Bleu_3": 0.15835772236900064, "Bleu_4": 1.9074322507036495e-05, "METEOR": 0.21610623938351065, "ROUGE_L": 0.3549459684123026, "CIDEr": 0.0024178086235011795, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.18181818181818182, "f": 0.24242424242424246, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a man and a young girl riding a horse together in a grassy field. The man is riding the horse and walking it. The girl is also riding the horse."}, "96241": {"image_id": 96241, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.11582156166137168, "Bleu_3": 7.006558330325156e-07, "Bleu_4": 1.7345333611892186e-09, "METEOR": 0.1281607040559732, "ROUGE_L": 0.17617328519855593, "CIDEr": 1.571967174476204e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2, "f": 0.20689655172413796, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a train on a track. There are four people standing nearby. Two people are standing closer to the train and two others are standing further away. Some individuals are wearing a tie, indicating a formal or semi-formal event."}, "326911": {"image_id": 326911, "Bleu_1": 0.11111111110905351, "Bleu_2": 0.04578685464870713, "Bleu_3": 3.4289363674893317e-07, "Bleu_4": 9.42924728285967e-10, "METEOR": 0.12252504399374455, "ROUGE_L": 0.13974799541809851, "CIDEr": 3.757815940218218e-13, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13636363636363635, "f": 0.1935483870967742, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a cat and a dog walking down a stone path. The cat is positioned behind the bicycle. The dog is carrying a bicycle wheel. The front wheel of the bicycle is the dog's front legs holding, and the rear wheel of the bicycle is the dog's back legs supporting."}, "209222": {"image_id": 209222, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.2628796132330914, "Bleu_3": 0.19047498063033155, "Bleu_4": 0.13720495658436815, "METEOR": 0.29405793394434515, "ROUGE_L": 0.29901960784313725, "CIDEr": 5.998468086758796e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2631578947368421, "f": 0.21739130434782608, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of two men sitting on benches in a park. One of the men is wearing a baseball cap. The men are not enjoying their time outdoors.\n\nThere are no other people in the scene."}, "362293": {"image_id": 362293, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.22676343971299212, "Bleu_3": 0.097196959969432, "Bleu_4": 1.1367077968677194e-05, "METEOR": 0.2483450727158414, "ROUGE_L": 0.23131094257854823, "CIDEr": 2.18488703020969e-12, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.3333333333333333, "f": 0.3125, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a horse-drawn carriage traveling down a street, with a man riding the horse and a carriage driver sitting behind. The horse is positioned in the middle of the street. The carriage is following closely behind the horse.\n\nThere are several cars on the street, including a silver car, a red car, and a blue car."}, "144481": {"image_id": 144481, "Bleu_1": 0.1460674157286959, "Bleu_2": 0.05761695925503423, "Bleu_3": 3.366617724161215e-07, "Bleu_4": 8.161514213978696e-10, "METEOR": 0.11587202683118175, "ROUGE_L": 0.12136888181456426, "CIDEr": 7.106961731923254e-39, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.22727272727272727, "f": 0.27027027027027023, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a museum display with five vases placed on a blue table. The vases showcase intricate designs and craftsmanship. Two of the vases are larger and more prominent, while the other three are smaller. The larger vases are about a foot tall, while the smaller vases are about the size of a litre. The sizes of the vases vary in height, width, and depth, ranging from h x w x d cm to a meter tall. The vases are placed on the table, creating an elegant display."}, "433804": {"image_id": 433804, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.12168393662744252, "Bleu_3": 0.06272467465535159, "Bleu_4": 8.042032245205262e-06, "METEOR": 0.16054548158675247, "ROUGE_L": 0.18466195761856707, "CIDEr": 2.8460896462563126e-16, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15, "f": 0.13953488372093023, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features two boats traveling down a river surrounded by lush green trees. People are on the boats. The boats are moving quickly, leaving a trail of water in their wake. \n\nThere are a total of five people on the boats. They are enjoying the ride and the beautiful scenery. \n\nThere is no specific information about the scenery in the image."}, "142815": {"image_id": 142815, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.0903507902886997, "Bleu_3": 5.540397074769196e-07, "Bleu_4": 1.3792125616624927e-09, "METEOR": 0.19239742198688486, "ROUGE_L": 0.19830949284785435, "CIDEr": 1.8768964285030885e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.2916666666666667, "f": 0.23728813559322035, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.11764705882352941, "re": 0.4, "f": 0.1818181818181818, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features three men sitting on a couch in a room. One man is sitting on the left side of the couch, while the other man is sitting on the right side. Both men are looking at a camera, which is placed on the floor in front of them."}, "85292": {"image_id": 85292, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.11459194182328535, "Bleu_3": 6.280739235613542e-07, "Bleu_4": 1.4774310979864886e-09, "METEOR": 0.21413016433577906, "ROUGE_L": 0.207506520013607, "CIDEr": 6.264005295507145e-13, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.25, "f": 0.19607843137254902, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks. The train is red and yellow. A large trailer is attached to the train. The train is moving through a rural area, surrounded by a field and a forest. It is a freight train carrying cargo.\n\nThere are no other cars or cargo in the scene."}, "500423": {"image_id": 500423, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2065984676302324, "Bleu_3": 0.12983940805705807, "Bleu_4": 1.5492053781230032e-05, "METEOR": 0.20996853122999978, "ROUGE_L": 0.27875095201827876, "CIDEr": 6.084007369480919e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a train parked at a station. The train is orange and white. It is a long city night line train. The train track is located in the middle of the station. The station is located in a city."}, "196280": {"image_id": 196280, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.20447945297237122, "Bleu_3": 0.10148763200900297, "Bleu_4": 1.279510009626945e-05, "METEOR": 0.19063736375658802, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.5089609076555777e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a boy standing in front of a stove, cooking. The boy is wearing a hat. There are no spoons visible in the scene. The photo is captioned with a quote that reads, \"Growing up, Bobby always hated 'leftover night'\"."}, "84752": {"image_id": 84752, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.07347183583515587, "Bleu_3": 5.26437340454787e-07, "Bleu_4": 1.4188431559098949e-09, "METEOR": 0.102269076170012, "ROUGE_L": 0.14489311163895485, "CIDEr": 2.7042979296452325e-07, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14814814814814814, "f": 0.12698412698412698, "fn": 23.0, "numImages": 1.0, "fp": 32.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features an airplane flying over a runway, with its landing gear down. The airplane is red and white. \n\nIn the background, there are seven cars parked along the runway. There are no cars closer to the camera."}, "222317": {"image_id": 222317, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.19659902977179203, "Bleu_4": 0.17743299459788137, "METEOR": 0.3077363127049825, "ROUGE_L": 0.3463722397476341, "CIDEr": 8.968204959565056e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a brown dog lying on a couch in a living room. The dog is resting on a blanket, which covers the couch. The couch is positioned in front of a window, allowing natural light to enter the room.\n\nIn the room, there are no other objects."}, "544421": {"image_id": 544421, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.10675210253269501, "Bleu_3": 7.69610448813251e-07, "Bleu_4": 2.0876149875064654e-09, "METEOR": 0.18958516384844498, "ROUGE_L": 0.2946859903381643, "CIDEr": 0.030399593699165707, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.21052631578947367, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5, "f": 0.6153846153846154, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image features a cake with a waterfall theme. The cake is adorned with brown frosting, and chocolate icing is cascading down the sides of the cake."}, "526827": {"image_id": 526827, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.16302782918400804, "Bleu_3": 0.08654590923115621, "Bleu_4": 1.1282878483696187e-05, "METEOR": 0.20831833822690832, "ROUGE_L": 0.2023888520238885, "CIDEr": 7.358202237159459e-07, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.11764705882352941, "f": 0.1111111111111111, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a pair of scissors with a red handle placed on a table. The scissors are positioned in the middle of the table. The blades of the scissors are not open. \n\nThere are no other pairs of scissors in the scene."}, "527529": {"image_id": 527529, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.10619884880883856, "Bleu_3": 0.05896925524327533, "Bleu_4": 7.850020523433245e-06, "METEOR": 0.17894263267866123, "ROUGE_L": 0.2136602451838879, "CIDEr": 1.2688098395375592e-14, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.3125, "f": 0.39999999999999997, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features a white cat standing on a shelf. The cat is reaching for a piece of paper, which is not present in the scene. The shelf is filled with various books, some of which are located near the cat. A black bag is located near the cat, and a black suitcase is located further away."}, "152785": {"image_id": 152785, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.20568833779665252, "Bleu_3": 0.13058358239001738, "Bleu_4": 1.5662677402020613e-05, "METEOR": 0.26554160125202764, "ROUGE_L": 0.3139705882352941, "CIDEr": 3.679956050561328e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.34782608695652173, "f": 0.37209302325581395, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a herd of seven elephants walking across a grassy plain. The elephants are spread out across the scene, with some closer to the foreground and others further in the background. The herd appears to be moving together."}, "516212": {"image_id": 516212, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.2762575317769765, "Bleu_3": 0.24805772141291282, "Bleu_4": 0.22198616243622446, "METEOR": 0.387594756520846, "ROUGE_L": 0.48265368228849664, "CIDEr": 1.4740230964955422e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.23529411764705882, "f": 0.2162162162162162, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a cat sitting on top of a microwave oven, which is placed on a kitchen counter. The cat appears to be enjoying its elevated position, possibly observing its surroundings or simply relaxing.\n\nThere is no kitchen or other appliances or items in the scene."}, "403378": {"image_id": 403378, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.23055616707626844, "Bleu_3": 0.13738306735708164, "Bleu_4": 1.595639977425073e-05, "METEOR": 0.31310481931803236, "ROUGE_L": 0.3400696864111499, "CIDEr": 1.9710412008622811e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.22727272727272727, "f": 0.27027027027027023, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a woman standing in front of a mirror, looking at her reflection. She is holding a handheld mirror, which is positioned in front of her face. The woman appears to be examining her appearance, possibly checking her makeup or grooming."}, "216051": {"image_id": 216051, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.201619459631519, "Bleu_3": 0.1595958635351509, "Bleu_4": 0.13297818013256768, "METEOR": 0.32075590002757676, "ROUGE_L": 0.3551673944687045, "CIDEr": 8.01272499133708e-07, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.06896551724137931, "f": 0.07017543859649124, "fn": 27.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a woman sitting on a bench, holding a dog. The woman is sitting on a bench. The woman is holding a dog. The woman's shirt is purple. The dog is sitting on the bench. The dog is black."}, "543043": {"image_id": 543043, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.13965509692979164, "Bleu_3": 0.09465173555893981, "Bleu_4": 0.06588602516958998, "METEOR": 0.251352409343359, "ROUGE_L": 0.27371794871794874, "CIDEr": 7.409084855869734e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features two cars parked in front of two houses. The first car is red and the second car is orange. The first house appears to be a bus and the second house appears to be a boat. The cars are parked in front of the bus."}, "392493": {"image_id": 392493, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.14607233344869358, "Bleu_3": 8.399971471326652e-07, "Bleu_4": 2.0285762996808684e-09, "METEOR": 0.18291228888411365, "ROUGE_L": 0.27191679049034173, "CIDEr": 6.040469550374243e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.10344827586206896, "f": 0.15, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a beach with a large group of colorful kites flying high in the sky. The kites are colorful. Some of the kites are closer to the ground, while others are soaring higher, filling the sky."}, "524681": {"image_id": 524681, "Bleu_1": 0.3399999999932, "Bleu_2": 0.2634155559173319, "Bleu_3": 0.17948735747185518, "Bleu_4": 0.1053175950280663, "METEOR": 0.2819538453852823, "ROUGE_L": 0.3335358444714459, "CIDEr": 2.2954998175642018e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image depicts a group of five people enjoying a day at the beach. Some of the people are playing frisbee, while others are playing with a skateboard. One person is standing on the beach. The people are standing on a sandy beach. A kite is soaring in the sky."}, "265816": {"image_id": 265816, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.24447927302426964, "Bleu_3": 0.1287583353288884, "Bleu_4": 1.67683594049909e-05, "METEOR": 0.29044462227387824, "ROUGE_L": 0.3405103668261563, "CIDEr": 0.005475217665339003, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a man wearing a cowboy hat, sitting on a horse-drawn carriage. The horse is positioned in front of the carriage. The man is seated in the carriage."}, "528984": {"image_id": 528984, "Bleu_1": 0.3728813559258834, "Bleu_2": 0.27775504809446055, "Bleu_3": 0.175591310079564, "Bleu_4": 0.11792007764737297, "METEOR": 0.3038807187824112, "ROUGE_L": 0.31478068558791006, "CIDEr": 2.2624144524490544e-12, "SPICE": {"All": {"pr": 0.1794871794871795, "re": 0.2692307692307692, "f": 0.2153846153846154, "fn": 19.0, "numImages": 1.0, "fp": 32.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.45454545454545453, "f": 0.3703703703703703, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image captures a snowy ski slope bustling with activity. There are three people doing skiing. Some of them are skiing down the hill, while others are standing or walking around. A group of people can be seen at the bottom of the slope, possibly preparing to ski or taking a break. There is no slope in the image."}, "565776": {"image_id": 565776, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.20579830216693504, "Bleu_3": 0.13738402941716643, "Bleu_4": 0.08573178735424374, "METEOR": 0.23443909792506773, "ROUGE_L": 0.2893689114781872, "CIDEr": 4.119368490321906e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a kitchen with a stove, refrigerator, and sink. A large island is in the center of the kitchen. The kitchen is well-equipped with various appliances, including a refrigerator, oven, and sink. The refrigerator is located in the kitchen. The oven is situated in the middle of the kitchen."}, "208132": {"image_id": 208132, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1398811515077607, "Bleu_3": 7.219465044848078e-07, "Bleu_4": 1.6481100947130725e-09, "METEOR": 0.2683462093064041, "ROUGE_L": 0.27949599083619703, "CIDEr": 8.666309589008118e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.07407407407407407, "f": 0.09523809523809523, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a dining table with two plates of food. On plate 1, there is a burger. On plate 2, there is a burger, fries, and a bottle of ketchup. The plates are placed on a tablecloth. There are two pickles on the side. A bottle of ketchup is placed on the tablecloth."}, "37017": {"image_id": 37017, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.35948681369506397, "Bleu_3": 0.2527892768122602, "Bleu_4": 0.16279348730958934, "METEOR": 0.1960393012085691, "ROUGE_L": 0.32515991471215355, "CIDEr": 0.013986550214614698, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a dog sitting in a kitchen. The dog is looking at the camera. The kitchen is well-equipped with a refrigerator and an oven."}, "20536": {"image_id": 20536, "Bleu_1": 0.5599999999776001, "Bleu_2": 0.3741657386621158, "Bleu_3": 0.2300435521933498, "Bleu_4": 2.7274191068218678e-05, "METEOR": 0.27482222428200076, "ROUGE_L": 0.4464775846294603, "CIDEr": 0.1052715072976989, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a bathroom with a toilet. The toilet has a ring placed around it. There are three rolls of paper in the bathroom."}, "289264": {"image_id": 289264, "Bleu_1": 0.1296296296272291, "Bleu_2": 0.06994057575388035, "Bleu_3": 4.5479779894921644e-07, "Bleu_4": 1.1653898241136166e-09, "METEOR": 0.1938072993562626, "ROUGE_L": 0.1821983273596177, "CIDEr": 1.9299300902810706e-12, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.29411764705882354, "f": 0.27777777777777773, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a dog standing on the window sill. The dog is wearing a red collar. The dog is looking out the window and observing a view of the outdoors.\n\nThere is no balcony in the scene.\n\nThere is no bird or animal in the scene.\n\nThere is no forest in the scene."}, "18014": {"image_id": 18014, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.24643202903867023, "Bleu_3": 0.11795893981395056, "Bleu_4": 1.4612432574503429e-05, "METEOR": 0.23732328341130698, "ROUGE_L": 0.2897862232779097, "CIDEr": 4.125730715900381e-06, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.043478260869565216, "f": 0.05555555555555555, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features a pizza sitting on a table. The pizza is topped with pepperoni, onions, and mushrooms. The pizza is placed in a box. The toppings include several pieces of broccoli, adding a healthy touch to the meal."}, "381123": {"image_id": 381123, "Bleu_1": 0.14583333333181425, "Bleu_2": 0.1108183276995677, "Bleu_3": 0.08054744593753141, "Bleu_4": 0.04868756932235493, "METEOR": 0.16159016232486156, "ROUGE_L": 0.1537077033837293, "CIDEr": 5.3179332099886996e-42, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a sandy beach with several boats and kayaks scattered along the shore. The boats and kayaks are of various colors and sizes. Some of them are closer to the water's edge, while others are further away. \n\nThere are at least 11 boats and kayaks in the image. The boats and kayaks are scattered along the shore, with some closer to the left side and others closer to the right side. \n\nThe overall atmosphere of the scene is lively and vibrant, with people enjoying their time on the beach and in the water."}, "19608": {"image_id": 19608, "Bleu_1": 0.382352941165225, "Bleu_2": 0.2636640221444497, "Bleu_3": 0.18679174274744473, "Bleu_4": 0.12041423532100866, "METEOR": 0.30703562917722466, "ROUGE_L": 0.4282371294851794, "CIDEr": 0.004999113766712121, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a man riding a bicycle near a pond. The man is riding his bike in the water. The man is wearing a tan shirt. A bird is flying over the water."}, "497348": {"image_id": 497348, "Bleu_1": 0.404255319140335, "Bleu_2": 0.24802643766519644, "Bleu_3": 0.13983132655183445, "Bleu_4": 1.5788475196546116e-05, "METEOR": 0.2946367997526856, "ROUGE_L": 0.35765472312703583, "CIDEr": 3.715132079465149e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.16666666666666666, "f": 0.20689655172413793, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a street with a no-through road sign on a wooden pole. The sign says \"no through road\". The sign is positioned on the left side of the street. There is a car parked on the right side of the street, close to the sign."}, "437594": {"image_id": 437594, "Bleu_1": 0.20312499999682618, "Bleu_2": 0.1269686250438429, "Bleu_3": 0.06382640464660079, "Bleu_4": 8.08012030740199e-06, "METEOR": 0.1427287376281366, "ROUGE_L": 0.1840305711987128, "CIDEr": 1.7708467521750496e-16, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.21052631578947367, "f": 0.163265306122449, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features six people sitting at a desk with two computers in front of them. One computer is placed on the left side of the desk. The people are working on their laptops. The screens of the computers display different content. On one screen, Yahoo is displayed, while on the other screen, a picture of a man in a green shirt is displayed."}, "413404": {"image_id": 413404, "Bleu_1": 0.14634146341106488, "Bleu_2": 1.91273013914278e-09, "Bleu_3": 4.543748293474348e-12, "Bleu_4": 2.2290242827444906e-13, "METEOR": 0.06740667739157097, "ROUGE_L": 0.12560054907343857, "CIDEr": 9.617409895775821e-09, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13043478260869565, "f": 0.1111111111111111, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a man walking in a scene. The man is holding a cell phone. There is a woman close to the man. There is another woman further from the man. The man is positioned in front of the bench."}, "332775": {"image_id": 332775, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.22140372137841335, "Bleu_3": 0.11527627951838042, "Bleu_4": 1.4909550148161668e-05, "METEOR": 0.28290248493600084, "ROUGE_L": 0.36371379897785344, "CIDEr": 0.0001307035976273162, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2413793103448276, "f": 0.28, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.13333333333333333, "f": 0.16666666666666669, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a bed with a cat lying inside a black suitcase. The cat is positioned inside the suitcase. The cat is laying in the suitcase. The suitcase is placed on the bed."}, "530624": {"image_id": 530624, "Bleu_1": 0.34615384614053263, "Bleu_2": 0.23533936215658835, "Bleu_3": 0.13214760629595454, "Bleu_4": 1.779764404504326e-05, "METEOR": 0.17823494851579308, "ROUGE_L": 0.36237623762376237, "CIDEr": 0.014388601008569424, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.23809523809523808, "f": 0.2941176470588235, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image features a brown cat lying on a bed. The cat is partially covered by a blanket. The bed is covered with a floral pattern."}, "139113": {"image_id": 139113, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.16418161448761062, "Bleu_3": 0.10867840345149303, "Bleu_4": 0.0748017008703093, "METEOR": 0.24740346935178245, "ROUGE_L": 0.31853785900783294, "CIDEr": 2.7889689124083603e-06, "SPICE": {"All": {"pr": 0.0625, "re": 0.034482758620689655, "f": 0.044444444444444446, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image captures two men playing soccer on a dirt field. The men are actively playing soccer. One of the men is holding a soccer ball, possibly preparing to kick it or waiting for a pass.\n\nThere are no other players in the scene."}, "192858": {"image_id": 192858, "Bleu_1": 0.29230769230319525, "Bleu_2": 0.17880479256765586, "Bleu_3": 0.10049611017376864, "Bleu_4": 0.06360833339518618, "METEOR": 0.221394736364866, "ROUGE_L": 0.20880195599022, "CIDEr": 4.3552034231013925e-17, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.14285714285714285, "f": 0.21621621621621623, "fn": 24.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features four girls gathered around a dining table, enjoying a meal together. They are seated on chairs, with some of them smiling and laughing. A large pizza is placed on the table. The girls are eating pizza and enjoying it. Some of the girls are not smiling or laughing, while others are smiling and laughing. There are no slices missing from the pizza."}, "482742": {"image_id": 482742, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.14595635698594722, "Bleu_3": 7.28944472052062e-07, "Bleu_4": 1.6365240619904682e-09, "METEOR": 0.1575923392612859, "ROUGE_L": 0.19709208400646203, "CIDEr": 2.4930646408392716e-09, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.18181818181818182, "f": 0.18750000000000003, "fn": 27.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features three men riding bicycles on a street. One of the men is putting a package on his bike. The men are wearing different colored shirts, with one man wearing a blue shirt. The street is lined with trees, creating a pleasant atmosphere for the cyclists. There is a red traffic light at the intersection."}, "398818": {"image_id": 398818, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.15617376188474938, "Bleu_3": 0.1077441858823136, "Bleu_4": 0.07574421758443027, "METEOR": 0.25729282532518954, "ROUGE_L": 0.30434782608695654, "CIDEr": 1.845081549794523e-06, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2, "f": 0.2380952380952381, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a bunch of bananas placed on a countertop. Some of the bananas are not overlapping each other. The bananas are arranged in various positions, creating a visually appealing display. There are at least ten bananas in the scene."}, "305871": {"image_id": 305871, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.23278142562159646, "Bleu_3": 0.1261375218310181, "Bleu_4": 1.666824532264052e-05, "METEOR": 0.2138220014890081, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.0044573482950551885, "SPICE": {"All": {"pr": 0.2, "re": 0.12, "f": 0.15, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a street sign pole with three street signs attached to it. The signs are pointing in different directions. There are no other signs in the scene."}, "443818": {"image_id": 443818, "Bleu_1": 0.15789473683933522, "Bleu_2": 0.1300664954263158, "Bleu_3": 0.09735609536739655, "Bleu_4": 0.06429451441115835, "METEOR": 0.1617141187731994, "ROUGE_L": 0.2136602451838879, "CIDEr": 9.891280606898122e-15, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a dog lying on a dog bed. The dog is brown. The dog is playing with a dog bed. The smaller dog is chewing on the dog bed. The larger dog is looking at the smaller dog. The smaller dog is close to the larger dog. The dog is lying on a dog bed."}, "421109": {"image_id": 421109, "Bleu_1": 0.1538461538431953, "Bleu_2": 0.05492350363704244, "Bleu_3": 3.922071328139402e-07, "Bleu_4": 1.0533861300924754e-09, "METEOR": 0.18984430669759933, "ROUGE_L": 0.21580188679245285, "CIDEr": 1.4193937691295435e-11, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.21052631578947367, "f": 0.2222222222222222, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features three horses in a grassy field. The horses are the main focus of the scene. One horse is brown and walking, while another horse is black and grazing. The third horse is also brown and grazing in the field. The horses' manes and tails are flowing in the wind."}, "416660": {"image_id": 416660, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.21398889174339228, "Bleu_3": 0.15118969592806583, "Bleu_4": 0.09029024038620045, "METEOR": 0.23471023258977694, "ROUGE_L": 0.27006087437742116, "CIDEr": 2.258441401532969e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.38461538461538464, "f": 0.30303030303030304, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of a street scene. The photograph captures two women standing in front of a store, possibly a jewelry store. The women are looking at the window of the store, engaged in conversation. One of the women is holding a baby. Another woman is seen buying a hat."}, "322845": {"image_id": 322845, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.12819595791702068, "Bleu_4": 1.5149236692095784e-05, "METEOR": 0.20749998095317973, "ROUGE_L": 0.30262225372076546, "CIDEr": 1.0960584266576785e-06, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a red stop sign mounted on a pole, positioned next to a rusty building. The stop sign is red and white. The building is rusty in color and made of metal. The backdrop of the building is a blue sky."}, "304361": {"image_id": 304361, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.11881770515484788, "Bleu_3": 0.06604735246466956, "Bleu_4": 8.801997699586786e-06, "METEOR": 0.20618611522214447, "ROUGE_L": 0.22889305816135083, "CIDEr": 1.7729146360745646e-10, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2727272727272727, "f": 0.23529411764705882, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a girl playing a game on a tablet computer. The girl is sitting on a bed and looking at a screen. She is focused on a remote control. The girl is surrounded by toys. There is a chair in the scene. There is no cup in the scene."}, "446917": {"image_id": 446917, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.0927733381723083, "Bleu_4": 1.1961929431463712e-05, "METEOR": 0.15785417011901773, "ROUGE_L": 0.3374827109266943, "CIDEr": 6.088399161745864e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.3157894736842105, "f": 0.27906976744186046, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a yellow and blue backpack placed on a chair. The backpack is filled with various items, including a banana and a bottle. The banana is inside the backpack. The bottle is in the backpack. The backpack is not open."}, "234676": {"image_id": 234676, "Bleu_1": 0.2741935483826743, "Bleu_2": 0.22236172834399967, "Bleu_3": 0.16031701278825805, "Bleu_4": 0.10871243038872568, "METEOR": 0.23997919580734328, "ROUGE_L": 0.287434554973822, "CIDEr": 3.7383087730638873e-16, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13043478260869565, "f": 0.15, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures a group of seven people enjoying a day at the beach. Some of the people are playing in the water. Some are playing frisbee on the beach. Some are sitting on the beach. Some might be surfing. A surfboard can be seen lying on the sand. A green and purple towel can also be seen lying on the sand."}, "343692": {"image_id": 343692, "Bleu_1": 0.5714285714081633, "Bleu_2": 0.35634832253693677, "Bleu_3": 0.2693262558547325, "Bleu_4": 0.22004136567891838, "METEOR": 0.2963940699122289, "ROUGE_L": 0.4849823321554771, "CIDEr": 0.013717476966483204, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09523809523809523, "f": 0.1, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a silver scooter parked in front of a yellow building. The scooter occupies a parking space. The building appears to be a traffic hazard sign."}, "293011": {"image_id": 293011, "Bleu_1": 0.24999999999652778, "Bleu_2": 0.132686223106713, "Bleu_3": 0.06312255093093734, "Bleu_4": 7.770091505881875e-06, "METEOR": 0.18579677812220066, "ROUGE_L": 0.19444444444444445, "CIDEr": 5.59687454684262e-20, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.18518518518518517, "f": 0.20408163265306123, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two birthday cakes. The first cake is square and has a red border. The second cake is also square and has a blue and white striped border. Both cakes are placed on a dining table. \n\nThere is also an airplane shaped birthday cake with blue frosting design. \n\nThe cakes are surrounded by six lit candles, creating a festive atmosphere. The candles are arranged in various positions around the cakes."}, "104625": {"image_id": 104625, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.09829463743443755, "Bleu_3": 6.033032403124956e-07, "Bleu_4": 1.5032618275449672e-09, "METEOR": 0.22316905357498118, "ROUGE_L": 0.2019867549668874, "CIDEr": 6.978282915870696e-09, "SPICE": {"All": {"pr": 0.375, "re": 0.2903225806451613, "f": 0.3272727272727273, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.5833333333333334, "f": 0.6363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image features two cats sitting on a wooden desk and a TV stand, respectively. Both cats are watching a TV show and are focused on the television screen. The television screen is displaying a soccer game. The cats are positioned on top of the television."}, "175612": {"image_id": 175612, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.26318067797166006, "Bleu_3": 0.19062038143092802, "Bleu_4": 2.4571892148209115e-05, "METEOR": 0.19477717678764433, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.06587238551467067, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.28, "f": 0.29787234042553196, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man holding a skateboard. The man is wearing a blue shirt. The skateboard is positioned on the ground."}, "43448": {"image_id": 43448, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.2577696311071676, "Bleu_3": 0.1479914230685418, "Bleu_4": 1.6871838589262225e-05, "METEOR": 0.23273084458703985, "ROUGE_L": 0.2872277810476751, "CIDEr": 0.0012208147239242424, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features two elephants standing together in a grassy area. The position of the third elephant is behind the two elephants. The elephants are standing close to each other. They appear to be enjoying their time together, possibly grazing on the grass."}, "528705": {"image_id": 528705, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 8.556026937263809e-07, "Bleu_4": 1.931527870007565e-09, "METEOR": 0.20208707310226956, "ROUGE_L": 0.2293233082706767, "CIDEr": 8.440170941384569e-09, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.23809523809523808, "f": 0.2857142857142857, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features three people wearing black coats and one person wearing a red coat. The person is carrying a teddy bear and holding it close to their chest. The teddy bear is positioned on the back of a child. The scene appears to be an outdoor setting."}, "319221": {"image_id": 319221, "Bleu_1": 0.2151898734149976, "Bleu_2": 0.09097545599104417, "Bleu_3": 4.7546576549362057e-07, "Bleu_4": 1.0905260421876281e-09, "METEOR": 0.13206816010820607, "ROUGE_L": 0.15919965202261854, "CIDEr": 3.720258731756622e-28, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.26666666666666666, "f": 0.2962962962962963, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a large dining table filled with a variety of foods. There is a platter on the table, containing a bowl of potatoes. There are also several bowls on the table, containing a variety of food. \n\nThere is no tray in the scene.\n\nThere are two pieces of broccoli, which are vegetables, on the table. \n\nThere are no other specific details mentioned in the passage.\n\nThe overall scene shows a variety of food contained in the bowls."}, "338903": {"image_id": 338903, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.1311312829167715, "Bleu_4": 0.08413498161249076, "METEOR": 0.22505287444067837, "ROUGE_L": 0.31282051282051276, "CIDEr": 8.637289463671107e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.19047619047619047, "f": 0.20512820512820512, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a bowl filled with a delicious breakfast consisting of bananas and cereal. The bananas are cut into slices and placed throughout the bowl, with some of them covering the top and bottom of the bowl. The cereal is mixed in with the bananas, creating a"}, "364993": {"image_id": 364993, "Bleu_1": 0.30769230768047345, "Bleu_2": 0.15689290810439224, "Bleu_3": 1.0084749803087304e-06, "Bleu_4": 2.5841450486370757e-09, "METEOR": 0.17379600764690056, "ROUGE_L": 0.3221830985915493, "CIDEr": 0.02176441588792446, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.06896551724137931, "f": 0.0975609756097561, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a person holding a sandwich in their hands. The sandwich appears to be a turkey sandwich. The person is positioned on a table."}, "37616": {"image_id": 37616, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.23957871187003724, "Bleu_3": 0.18277755597330705, "Bleu_4": 0.15179857311603867, "METEOR": 0.312472084831151, "ROUGE_L": 0.3663663663663663, "CIDEr": 1.0876463212247064e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20689655172413793, "f": 0.2553191489361702, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.38461538461538464, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a man standing in a living room. He is holding a large cardboard box, indicating that he is in the process of moving or unpacking. The living room is furnished with a couch, a chair, and a dining table. \n\nThere are no books in the room."}, "157756": {"image_id": 157756, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2296698215877162, "Bleu_3": 0.10466866334774666, "Bleu_4": 1.2634538413136025e-05, "METEOR": 0.2269173118401568, "ROUGE_L": 0.29901960784313725, "CIDEr": 9.595144383119756e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.23809523809523808, "f": 0.21739130434782608, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a busy city street at night, with a tall clock tower standing out in the scene. The tower has a clock on each of its sides, making it a prominent landmark. The street is bustling with activity, with a car and a truck driving by."}, "516508": {"image_id": 516508, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.15613914506966814, "Bleu_3": 8.092609555849529e-07, "Bleu_4": 1.8525217352695958e-09, "METEOR": 0.15687016815183102, "ROUGE_L": 0.19551282051282048, "CIDEr": 1.295353521453275e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features two clocks mounted on the side of a building. The clocks are prominently displayed, with their faces visible from various angles. The design of the clocks includes a clock face and a neoclassical design. The clocks add a decorative element to the building's architecture."}, "520528": {"image_id": 520528, "Bleu_1": 0.2833333333286111, "Bleu_2": 0.2078950191360966, "Bleu_3": 0.13075565381529075, "Bleu_4": 0.0791364644516525, "METEOR": 0.25073379328192325, "ROUGE_L": 0.23410087719298245, "CIDEr": 2.565475338007246e-16, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a boy wearing a baseball uniform, standing on a baseball field. The boy is throwing a baseball. He is in the process of pitching the ball, with his arm fully extended and the ball in mid-air. The boy is focused on the task at hand, displaying his athleticism and skill.\n\nThe boy is standing on the mound."}, "37675": {"image_id": 37675, "Bleu_1": 0.3181818181673554, "Bleu_2": 0.24618298194720895, "Bleu_3": 0.20870640223236978, "Bleu_4": 0.17588181043376913, "METEOR": 0.2734180551791797, "ROUGE_L": 0.41876430205949655, "CIDEr": 0.10109041001471306, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.17391304347826086, "f": 0.19999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features two horses grazing in a field. The horses are enjoying the grass. A church is visible in the background."}, "232383": {"image_id": 232383, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.18569533817075534, "Bleu_3": 0.107188449849828, "Bleu_4": 1.4614031921262565e-05, "METEOR": 0.2529905826888593, "ROUGE_L": 0.34777651083238315, "CIDEr": 0.0020173106305051113, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08, "f": 0.1, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a cat sitting on a shelf. The head of the cat is visible. The cat is positioned behind the laptop. A laptop is placed on the desk."}, "137658": {"image_id": 137658, "Bleu_1": 0.545454545355372, "Bleu_2": 0.23354968320493186, "Bleu_3": 1.8232183582936018e-06, "Bleu_4": 5.246341021824447e-09, "METEOR": 0.12720219850065295, "ROUGE_L": 0.28818897637795277, "CIDEr": 0.07553093879577552, "SPICE": {"All": {"pr": 0.25, "re": 0.3125, "f": 0.2777777777777778, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a person holding a flashlight in their hands."}, "209322": {"image_id": 209322, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.19445555936085132, "Bleu_4": 2.1726350821144763e-05, "METEOR": 0.35858667183537185, "ROUGE_L": 0.3721132897603485, "CIDEr": 0.000194773256080558, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.4090909090909091, "f": 0.4090909090909091, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.7, "f": 0.7, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image features a bathroom with a white toilet situated in the corner. The toilet is surrounded by a blue and white tiled wall. There are two rolls of toilet paper placed next to the toilet."}, "128644": {"image_id": 128644, "Bleu_1": 0.5423798679746024, "Bleu_2": 0.29196602367259067, "Bleu_3": 0.16825877504789724, "Bleu_4": 2.3109536365003995e-05, "METEOR": 0.24153839403921126, "ROUGE_L": 0.3885350318471337, "CIDEr": 0.3623380431151362, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.3125, "f": 0.2325581395348837, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a small airplane sitting on the wet runway. The airplane is a small plane."}, "342675": {"image_id": 342675, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.22631728213415836, "Bleu_3": 0.18726083047926026, "Bleu_4": 0.16214527868787693, "METEOR": 0.34801223307185053, "ROUGE_L": 0.40696812453669384, "CIDEr": 8.686264496277411e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a man standing in front of a train car. The train car is red. The man is holding a toolbox in his hand. He appears to be working on a laptop. The man is not fixing the train."}, "200234": {"image_id": 200234, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 0.08794832144810151, "Bleu_4": 0.06168026086597909, "METEOR": 0.16565013926891564, "ROUGE_L": 0.27595566613888267, "CIDEr": 1.7044017499210182e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a man playing with a frisbee in a wooded area. The man is surrounded by rocks. He is throwing a frisbee and appears to be preparing to throw it. The man is holding a frisbee. \n\nThe scene also includes several park benches scattered throughout the wooded area."}, "545390": {"image_id": 545390, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.20174997577993367, "Bleu_3": 0.13947999007998124, "Bleu_4": 0.08861775869591867, "METEOR": 0.2384622337708957, "ROUGE_L": 0.317915309446254, "CIDEr": 6.415552990373387e-09, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.21739130434782608, "f": 0.27777777777777773, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a woman sitting at a dining table, holding a pizza in her hands. The woman is smiling and appears to be enjoying the meal. The pizza is placed in the center of the table. There are two tables and two chairs in the scene."}, "43073": {"image_id": 43073, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.1714985851373884, "Bleu_3": 0.09722777968025705, "Bleu_4": 1.3122070075706762e-05, "METEOR": 0.17254302990893042, "ROUGE_L": 0.24478330658105937, "CIDEr": 0.00026466354064292956, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 24.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a boy with blond hair standing in front of a pink wall. The boy is holding a hair dryer, possibly drying his hair. He appears to be smiling, enjoying the process."}, "188651": {"image_id": 188651, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.169030850940941, "Bleu_3": 0.0943664634767626, "Bleu_4": 1.263236816956828e-05, "METEOR": 0.29963799572887223, "ROUGE_L": 0.308080808080808, "CIDEr": 3.9887495891594924e-05, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.20833333333333334, "f": 0.2380952380952381, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a cat laying under a car. The cat is positioned in the middle of the scene, with its head partially hidden by the car's wheel. The car is parked on a street."}, "484551": {"image_id": 484551, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.25035587205681953, "Bleu_3": 0.21564787468580718, "Bleu_4": 0.1700253099507871, "METEOR": 0.23357929683243303, "ROUGE_L": 0.31671858774662515, "CIDEr": 0.029872357562555032, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.46153846153846156, "f": 0.4999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a child wearing a hat and sunglasses, sitting on a boat on a lake. The child is enjoying the ride, smiling and looking ahead."}, "396224": {"image_id": 396224, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.25537695922201126, "Bleu_3": 0.1644412112541288, "Bleu_4": 0.1008418690311334, "METEOR": 0.22357390492005347, "ROUGE_L": 0.3084702907711757, "CIDEr": 1.4852054040970622e-07, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a dining table set with a variety of food items. There is a plate of meat and a plate of vegetables. There is also a bowl of soup. The table is set with utensils, including a plate of food and a wine glass."}, "255067": {"image_id": 255067, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.14524007059304897, "Bleu_4": 1.7080052973039647e-05, "METEOR": 0.28964254351133273, "ROUGE_L": 0.3756735950731332, "CIDEr": 2.2498165721120665e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12903225806451613, "f": 0.14545454545454548, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a polar bear in a body of water. The bear is partially submerged in the water, with its head and body visible. It appears to be playing or swimming in the water, enjoying the cool environment."}, "479129": {"image_id": 479129, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.11289809419085711, "Bleu_4": 0.07562263205115649, "METEOR": 0.2375507806184451, "ROUGE_L": 0.29983323093127356, "CIDEr": 4.294188370449403e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14814814814814814, "f": 0.16666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a dessert served on a white plate. The dessert consists of grilled bananas and ice cream. The banana is cut in half, with one half placed on top of the other, creating a visually appealing presentation. The ice cream is spread across the plate."}, "363887": {"image_id": 363887, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.14922200399597868, "Bleu_3": 0.08442829210502145, "Bleu_4": 1.1370783164998655e-05, "METEOR": 0.19200689923659617, "ROUGE_L": 0.2601279317697228, "CIDEr": 3.0579276321442845e-05, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.19230769230769232, "f": 0.19230769230769232, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a fire truck parked on a dirt road, surrounded by a grass field. The fire truck is red and in good condition. It is positioned in the middle of the scene, with no other vehicles nearby."}, "441969": {"image_id": 441969, "Bleu_1": 0.14503816793782415, "Bleu_2": 0.08837277580954614, "Bleu_3": 0.049471957269267064, "Bleu_4": 0.031186513622762608, "METEOR": 0.12620919522222798, "ROUGE_L": 0.11518748314000539, "CIDEr": 3.025737218082397e-86, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.21739130434782608, "f": 0.27777777777777773, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a balcony with a potted plant placed on top of it. A small plastic santa hat is placed on top of the potted plant. A small plastic container is placed on top of another potted plant. A metal plate is placed on top of another potted plant. A plastic lid is placed on top of another potted plant. A small metal basket is placed on top of another potted plant. The potted plants are surrounded by a glass bowl, a white table and chairs, and a metal fence. A tarpaulin is placed on top of the balcony. A lot of discarded plastic bags is scattered around the balcony. There are no cups or bowls in the scene. There are two flowers and two decorative items in the scene."}, "410225": {"image_id": 410225, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.10496165562800558, "Bleu_3": 0.05748366509372989, "Bleu_4": 7.597830907322432e-06, "METEOR": 0.21597663294334277, "ROUGE_L": 0.18944099378881987, "CIDEr": 9.985770097511293e-15, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.14285714285714285, "f": 0.17857142857142855, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two tables. On the first table, there is a cup placed in the middle, containing coffee. On the second table, there is a cup of food placed in the middle. \n\nThere are three laptops in the image, and a cup of coffee is placed on each of them.\n\nThere is no bowl or breakfast in the scene."}, "277073": {"image_id": 277073, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.22522130822577494, "Bleu_3": 0.15122694444080373, "Bleu_4": 0.09470104449999896, "METEOR": 0.19724775472562178, "ROUGE_L": 0.2367399741267788, "CIDEr": 9.902421938620916e-09, "SPICE": {"All": {"pr": 0.5, "re": 0.14814814814814814, "f": 0.22857142857142856, "fn": 23.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image captures a busy city street scene with a mix of vehicles and pedestrians. On the street is a man riding a scooter. Behind him is another man riding a scooter. Some people are carrying handbags.\n\nThere are several other pedestrians walking on the sidewalk."}, "41011": {"image_id": 41011, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.3099340466837252, "Bleu_3": 1.5265988694268135e-06, "Bleu_4": 3.4201910431350357e-09, "METEOR": 0.25566174123820196, "ROUGE_L": 0.3871260199456029, "CIDEr": 0.009070314700888234, "SPICE": {"All": {"pr": 0.125, "re": 0.2222222222222222, "f": 0.16, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a man dressed in a suit and wearing a top hat. The man is standing in front of a horse. He is looking at the horse."}, "343821": {"image_id": 343821, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.1762329661653903, "Bleu_4": 0.14324501758513128, "METEOR": 0.25204733705649157, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.003452038243947975, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08695652173913043, "f": 0.1081081081081081, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features five swans swimming in a body of water. The swans are white. There are two baby swans. The swan family is spread out across the scene."}, "530620": {"image_id": 530620, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.09990921468676503, "Bleu_3": 0.05627830660728096, "Bleu_4": 7.545101622618582e-06, "METEOR": 0.10895981783194228, "ROUGE_L": 0.16442048517520216, "CIDEr": 3.220779585676561e-14, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.13793103448275862, "f": 0.21052631578947367, "fn": 25.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image depicts a parking lot scene with three men working on different objects. One man is working on a bicycle, possibly repairing a kite. Another man is putting a suitcase on a sled. The third man is working on a horse. They are surrounded by various vehicles, including cars and a truck, parked in the parking lot."}, "22113": {"image_id": 22113, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.23473823892604287, "Bleu_3": 0.1510135442554507, "Bleu_4": 1.645271068557002e-05, "METEOR": 0.235877100632939, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.124888186908675e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 22.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a fire hydrant sitting on a sidewalk. The fire hydrant is red and green. The top of the fire hydrant is green, and the bottom is red. The fire hydrant is surrounded by a concrete surface. There is no water on the ground near the fire hydrant."}, "82836": {"image_id": 82836, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.12792458327416775, "Bleu_3": 0.06596968170956508, "Bleu_4": 8.461771328960578e-06, "METEOR": 0.17643353836296546, "ROUGE_L": 0.20760068065796938, "CIDEr": 3.378501879524537e-15, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09090909090909091, "f": 0.08888888888888888, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features three seagulls gathered on a beach. Some of the seagulls are standing closer to the water, while others are standing further back on a sandbar. Additionally, there are four other birds in the scene, some standing closer to the water and others standing further back on various structures such as a wooden pier and a pier."}, "538925": {"image_id": 538925, "Bleu_1": 0.32758620689090373, "Bleu_2": 0.20057388926795, "Bleu_3": 8.956127238221883e-07, "Bleu_4": 1.9010761735227272e-09, "METEOR": 0.22717180175665008, "ROUGE_L": 0.259298618490967, "CIDEr": 3.832044489416348e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bedroom with a neatly made bed situated in the center of the room. The bed is covered with a brown blanket, giving it a cozy appearance. There is no sheet on the bed. A pillow is placed on the bed, adding to the comfortable setting.\n\nIn addition to the bed, the blanket is white."}, "440189": {"image_id": 440189, "Bleu_1": 0.47338938698644284, "Bleu_2": 0.32745028601878623, "Bleu_3": 0.17243470971491429, "Bleu_4": 2.257201053357322e-05, "METEOR": 0.20814918503860955, "ROUGE_L": 0.4477768456375839, "CIDEr": 0.3217331538771073, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.26666666666666666, "f": 0.26666666666666666, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a boy playing with a frisbee on the sand. The boy is not standing close to anyone."}, "32777": {"image_id": 32777, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.19957280121567952, "Bleu_3": 0.13030969663273198, "Bleu_4": 1.5856799659907666e-05, "METEOR": 0.25398638224005055, "ROUGE_L": 0.23282442748091606, "CIDEr": 7.34011098201987e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a train station with two trains on the tracks. The trains are blue and yellow. Some people are walking to the train, while others are boarding the train. The train is parked at the platform."}, "50679": {"image_id": 50679, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.17857142856774635, "Bleu_3": 0.08787028385478016, "Bleu_4": 1.1020265663118309e-05, "METEOR": 0.20002721855777783, "ROUGE_L": 0.2543786488740617, "CIDEr": 1.6756008679219786e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features an orange sitting on a paved surface. The orange color is orange. The surface is made of asphalt. \n\nIn the background, there are seven cars parked on the left side. The cars are white, red and white, white and black, red, black, and blurry in color."}, "86250": {"image_id": 86250, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.38056219754078957, "Bleu_3": 0.24942396108384463, "Bleu_4": 0.15483270026898163, "METEOR": 0.22328465002713047, "ROUGE_L": 0.37854609929078015, "CIDEr": 0.005683039315814438, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.21052631578947367, "f": 0.2222222222222222, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man sitting on a couch in a living room. The man is surrounded by a couch and a television. The man is sitting on the floor."}, "482432": {"image_id": 482432, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.21821789022534133, "Bleu_3": 1.3583417042548598e-06, "Bleu_4": 3.435094189227651e-09, "METEOR": 0.17279803727899584, "ROUGE_L": 0.33116178067318125, "CIDEr": 0.21756298704203042, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.09090909090909091, "f": 0.10810810810810811, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a bottle of Aveeno Active Naturals Skin Brightening Scrub placed on a table. There is a toothbrush nearby."}, "330880": {"image_id": 330880, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.28154625317878373, "Bleu_3": 0.2166049117576129, "Bleu_4": 0.1520767508410176, "METEOR": 0.3205958019229536, "ROUGE_L": 0.449430676490288, "CIDEr": 5.8187144554734485e-06, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.11764705882352941, "f": 0.10526315789473684, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a man sitting at a dining table in a restaurant. The man is holding a pizza. A pizza is in front of the man. The man is looking at a pizza. The pizza is covered in various toppings."}, "201934": {"image_id": 201934, "Bleu_1": 0.30508474575754096, "Bleu_2": 0.22934868264969802, "Bleu_3": 0.1769115950681267, "Bleu_4": 0.14102146262865686, "METEOR": 0.2594527060967487, "ROUGE_L": 0.2704885580806081, "CIDEr": 1.2823302086623217e-14, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.35714285714285715, "f": 0.20833333333333334, "fn": 9.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.2, "f": 0.10526315789473682, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a white bus parked at a bus stop. The bus is positioned on the side of the road. There is a person standing next to the bus. The person is not standing on the sidewalk. The person is doing a photo of a person in a blue shirt. There is another person playing in the water."}, "579462": {"image_id": 579462, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.17831418028047516, "Bleu_3": 0.1069381840568343, "Bleu_4": 1.2443915680934025e-05, "METEOR": 0.2806225335057895, "ROUGE_L": 0.2979242979242979, "CIDEr": 3.4888459565572086e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a woman standing in a bedroom. She is wearing a dress and is in the process of opening a suitcase. The woman is standing on the bed and pulling the suitcase onto the bed. The bed is situated in the middle of the room. The suitcase is placed on the bed."}, "183657": {"image_id": 183657, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.0631613940786591, "Bleu_3": 4.426378293466139e-07, "Bleu_4": 1.178238656172971e-09, "METEOR": 0.1560040023578581, "ROUGE_L": 0.15641025641025638, "CIDEr": 1.1733772552253228e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.26666666666666666, "f": 0.2758620689655172, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a surface with a puddle on it. There are two bowls placed on top of the surface. One bowl is located closer to the left side of the puddle, while the other is positioned more towards the right side. The bowls are made of clay."}, "352652": {"image_id": 352652, "Bleu_1": 0.17460317460040317, "Bleu_2": 0.09191594370039867, "Bleu_3": 5.173891161710174e-07, "Bleu_4": 1.2326084875124115e-09, "METEOR": 0.1906076218534425, "ROUGE_L": 0.1856925418569254, "CIDEr": 1.0841379536152046e-16, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.15384615384615385, "f": 0.1702127659574468, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a parking lot filled with snow, with a car parked in the middle of the scene. The car is surrounded by a significant amount of snow, which has accumulated on the ground and around the vehicle. The snow is piled up on the car's hood, making it appear as a snowman. The parking meters are also filled with snow."}, "339823": {"image_id": 339823, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 0.1017691319923899, "Bleu_4": 1.2512524442841366e-05, "METEOR": 0.2439950210172989, "ROUGE_L": 0.31565329883570503, "CIDEr": 2.125555726466153e-08, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a woman standing in front of a tall pole, holding a black umbrella with a lacy design. She is wearing a dress that complements the umbrella's style, adding a touch of elegance to the scene. The woman is posing for a picture."}, "203690": {"image_id": 203690, "Bleu_1": 0.2758620689560048, "Bleu_2": 0.1719204765123417, "Bleu_3": 1.0306166382509387e-06, "Bleu_4": 2.5472966536230232e-09, "METEOR": 0.3285516845202696, "ROUGE_L": 0.3935483870967742, "CIDEr": 0.002953443538974054, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image captures a man walking on the beach, carrying a surfboard. There are several other people scattered around the beach. Some of them are carrying surfboards as well."}, "344614": {"image_id": 344614, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.2102800206225174, "Bleu_3": 0.1675544845458638, "Bleu_4": 0.13234510956521162, "METEOR": 0.20441366158171967, "ROUGE_L": 0.3078864353312303, "CIDEr": 6.793059250107493e-10, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.16666666666666666, "f": 0.20833333333333334, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a clock tower standing tall in the middle of a city. There are two clocks on each side of the clock tower. The clock tower is a prominent landmark in the city. The clock tower is surrounded by several buildings, including a skyscraper in the background."}, "573549": {"image_id": 573549, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.20207633640188252, "Bleu_3": 0.09000796940957936, "Bleu_4": 1.0730502268019728e-05, "METEOR": 0.15731364226124095, "ROUGE_L": 0.23591160220994478, "CIDEr": 2.7508538486741538e-15, "SPICE": {"All": {"pr": 0.15625, "re": 0.23809523809523808, "f": 0.18867924528301888, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a group of ten people walking down a sidewalk near a building. Some of the people are walking, others are riding bikes, and some are riding a skateboard. They are engaged in various activities such as talking on the phone, kissing, and enjoying their time together. A bike is near the sidewalk and the building."}, "522941": {"image_id": 522941, "Bleu_1": 0.12857142856959186, "Bleu_2": 0.08633316945910088, "Bleu_3": 0.04785736898629915, "Bleu_4": 6.3597920230090345e-06, "METEOR": 0.12240985931561708, "ROUGE_L": 0.1734597156398104, "CIDEr": 6.264958318582968e-23, "SPICE": {"All": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows an elephant in a zoo. There are 11 people around the elephant. Some of the people are sitting on the ground, playing in the water, holding a red bucket, riding a bike, playing a game, looking at the camera, looking at the ocean, playing a game, walking on the sidewalk, eating a meal in a restaurant, and looking at the ocean. The elephant is in the water."}, "511662": {"image_id": 511662, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.1656472891081792, "Bleu_3": 0.11205846904084894, "Bleu_4": 1.387195318328694e-05, "METEOR": 0.21452230330343958, "ROUGE_L": 0.29897773421089485, "CIDEr": 6.889971653151073e-05, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.2631578947368421, "f": 0.3225806451612903, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.8333333333333334, "f": 0.7692307692307692, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a cruise ship sailing in the ocean. The ship is a Disney cruise ship. In the background, there is a beach. \n\nThere are four palm trees scattered around the beach. \n\nThere are no other ships in the scene."}, "377371": {"image_id": 377371, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2736170867397671, "Bleu_3": 0.13275334828264881, "Bleu_4": 1.657462415789548e-05, "METEOR": 0.28199235246206994, "ROUGE_L": 0.33622047244094483, "CIDEr": 0.0013436707654484372, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a cutting board with a knife positioned on top. Chopped nuts, including walnuts, are spread across the cutting board. Some nuts are closer to the knife and others are further away."}, "170813": {"image_id": 170813, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.3047247001014366, "Bleu_3": 0.17611193887820184, "Bleu_4": 2.017033511873849e-05, "METEOR": 0.2469374666351279, "ROUGE_L": 0.2839851024208566, "CIDEr": 9.458879612890177e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a park with a man sitting on a bench, enjoying the serene surroundings. The bench is located near a tree, providing shade and a place to sit. The man is using a laptop."}, "347210": {"image_id": 347210, "Bleu_1": 0.39999999999111113, "Bleu_2": 0.25226248954908703, "Bleu_3": 0.14357835226443494, "Bleu_4": 0.09162297751166115, "METEOR": 0.28641983070721216, "ROUGE_L": 0.3696969696969697, "CIDEr": 2.7649404391503722e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15789473684210525, "f": 0.16216216216216214, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a bench situated in the middle of a grassy area, surrounded by trees. The bench is empty, with no one sitting on it. The park is well-maintained, and the grass appears to be freshly cut.\n\nThere are several trees in the background."}, "175494": {"image_id": 175494, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.11881770515484788, "Bleu_3": 0.06604735246466956, "Bleu_4": 8.801997699586786e-06, "METEOR": 0.2099098817714, "ROUGE_L": 0.19513755598208574, "CIDEr": 7.058763428800796e-11, "SPICE": {"All": {"pr": 0.1320754716981132, "re": 0.30434782608695654, "f": 0.1842105263157895, "fn": 16.0, "numImages": 1.0, "fp": 46.0, "tp": 7.0}, "Relation": {"pr": 0.05, "re": 0.14285714285714285, "f": 0.07407407407407408, "fn": 6.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.125, "f": 0.09090909090909091, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2631578947368421, "re": 0.625, "f": 0.37037037037037035, "fn": 3.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}}, "caption": "The image features a cozy bedroom scene with a dog sleeping on a bed. The dog is lying on the left side of the bed. Another dog is positioned on the other side of the bed. They appear to be enjoying their restful sleep.\n\nThe bed is surrounded by various items."}, "265879": {"image_id": 265879, "Bleu_1": 0.14084507042154334, "Bleu_2": 0.10482324787574454, "Bleu_3": 0.08190210729136913, "Bleu_4": 0.06305689834785343, "METEOR": 0.18298598385532022, "ROUGE_L": 0.16699850671976108, "CIDEr": 7.544004895398072e-102, "SPICE": {"All": {"pr": 0.25, "re": 0.15555555555555556, "f": 0.1917808219178082, "fn": 38.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features two men sitting at a dining table in a restaurant. The first man is sitting at the table, smiling, and enjoying a plate of food. He is surrounded by food and drinks. The second man is eating a slice of pizza and is not smiling. He is surrounded by a group of people.\n\nThere are several chairs placed around the table and on the ground.\n\nThere are three tables in the scene. One table has a pizza on it, another has a plate of food, and the third has a bottle of wine.\n\nThere are four bottles on the table. The bottles may contain wine, liqueur, stout, or a mystery drink.\n\nOverall, the scene depicts a man sitting at a table in a restaurant, surrounded by chairs and enjoying his meal. There are also bottles and other guests present."}, "433998": {"image_id": 433998, "Bleu_1": 0.4273666516591527, "Bleu_2": 0.3061442716110344, "Bleu_3": 0.2109119036316833, "Bleu_4": 0.12463739875709896, "METEOR": 0.29018547030892383, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.15640270751852578, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress. The pitcher is standing on the mound, preparing to throw a ball. The pitcher is wearing a white and red uniform. The catcher is positioned behind the pitcher, holding a baseball."}, "286711": {"image_id": 286711, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.250791558703178, "Bleu_3": 0.11440864611646838, "Bleu_4": 1.3824459818485092e-05, "METEOR": 0.23807514181884643, "ROUGE_L": 0.23890339425587467, "CIDEr": 5.565740167002378e-07, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.125, "f": 0.12121212121212122, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures a baseball game in progress. There is a batter standing at home plate, holding a baseball bat and preparing to swing. The catcher is positioned behind the batter, ready to catch the ball. \n\nThere are no other players in the scene."}, "552744": {"image_id": 552744, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.2189345354789208, "Bleu_3": 0.1377618726814346, "Bleu_4": 0.08341580367236225, "METEOR": 0.1833906921406708, "ROUGE_L": 0.20670958996950187, "CIDEr": 2.2359751606429383e-12, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features two women standing in a room with a large collection of stuffed animals scattered throughout. The women are surrounded by stuffed animals. One of the women is holding a teddy bear. The teddy bears are of different sizes and are scattered throughout the room. Some of the stuffed animals are placed behind the women."}, "447279": {"image_id": 447279, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.1930821114268906, "Bleu_3": 0.11067523724715086, "Bleu_4": 0.07078470170866812, "METEOR": 0.1848350032225195, "ROUGE_L": 0.20504201680672268, "CIDEr": 6.001599443580191e-14, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.34782608695652173, "f": 0.380952380952381, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image depicts a police officer riding a horse on a city street. The police officer is positioned in the middle of the street. There are at least four horses and three riders visible in the scene. The horses are positioned in the middle of the street. The riders are positioned in the middle of the street."}, "409217": {"image_id": 409217, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.22631728213415833, "Bleu_3": 0.10951079799876592, "Bleu_4": 1.3634738359895023e-05, "METEOR": 0.2636960005550148, "ROUGE_L": 0.3397314768771755, "CIDEr": 3.105762118339903e-05, "SPICE": {"All": {"pr": 0.5333333333333333, "re": 0.27586206896551724, "f": 0.36363636363636365, "fn": 21.0, "numImages": 1.0, "fp": 7.0, "tp": 8.0}, "Relation": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a plate filled with a delicious meal consisting of meat, broccoli, and black beans. \n\nThere is no dining table in the scene. \n\nThere is a fork nearby. \n\nThere are two knives nearby, and a sink is also nearby."}, "28114": {"image_id": 28114, "Bleu_1": 0.20312499999682618, "Bleu_2": 0.1269686250438429, "Bleu_3": 0.06382640464660079, "Bleu_4": 8.08012030740199e-06, "METEOR": 0.2018282541096711, "ROUGE_L": 0.19022869022869024, "CIDEr": 9.127688486303937e-19, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.19047619047619047, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a bus parked on the side of a street. The bus is orange. There are two people around the bus. Some people are standing closer to a store, while others are standing further away from a large advertisement. A woman riding a bike is also among the people. The bus stop is nearby.\n\nThere are no other vehicles in the scene."}, "33994": {"image_id": 33994, "Bleu_1": 0.3953488372001082, "Bleu_2": 0.21694547186055083, "Bleu_3": 1.0470621025717697e-06, "Bleu_4": 2.3145380932838687e-09, "METEOR": 0.1997996964556749, "ROUGE_L": 0.29387474191328283, "CIDEr": 2.093516287561023e-06, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features three flowers displayed in four vases. The flowers are yellow. A large yellow flower is the main focus of the scene. The vase is green and is holding a flower. The green table cloth is drawing attention to the flower."}, "278509": {"image_id": 278509, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.13867504905279598, "Bleu_3": 7.969009659317547e-07, "Bleu_4": 1.9231042777337796e-09, "METEOR": 0.19625113041823822, "ROUGE_L": 0.22426470588235295, "CIDEr": 5.78679582448336e-06, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.07407407407407407, "f": 0.08163265306122448, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features two motorcycles parked on the side of a road. The motorcycles are black. The front wheel of each motorcycle is positioned close to the curb. The side mirrors of the motorcycles are prominently displayed, reflecting the surroundings."}, "544975": {"image_id": 544975, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.27602622372916485, "Bleu_3": 0.20772746475716128, "Bleu_4": 0.1526685055915454, "METEOR": 0.34123749077519827, "ROUGE_L": 0.38730158730158726, "CIDEr": 0.0007746434713297396, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.17647058823529413, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a zebra and a giraffe standing in a zoo enclosure. The zebra is positioned closer to the foreground. The giraffe is standing further back. Both animals are grazing on grass in their habitat."}, "158806": {"image_id": 158806, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.19611613513321832, "Bleu_3": 1.004032301658975e-06, "Bleu_4": 2.28696928997318e-09, "METEOR": 0.2518905241421684, "ROUGE_L": 0.30587392550143266, "CIDEr": 2.385701196394047e-06, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.4117647058823529, "f": 0.43749999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.7142857142857143, "f": 0.7142857142857143, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a dog sitting on the grass, eagerly looking at a plate of food placed in front of it. The plate contains two sandwiches. The dog appears to be very hungry and is staring intently at the food."}, "267321": {"image_id": 267321, "Bleu_1": 0.26984126983698664, "Bleu_2": 0.14751743194767952, "Bleu_3": 0.07092275823078667, "Bleu_4": 8.781150090587107e-06, "METEOR": 0.18618604003444245, "ROUGE_L": 0.3219548975255329, "CIDEr": 2.3175503885361844e-11, "SPICE": {"All": {"pr": 0.625, "re": 0.20833333333333334, "f": 0.3125, "fn": 19.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features a gray couch positioned in front of the window in a modern living room. There is also a gray chair located in the living room. \n\nA dining table is situated in the middle of the room. On top of the dining table, there is a potted plant on one table and a lamp and a vase on the other table."}, "137188": {"image_id": 137188, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.35823642098878333, "Bleu_3": 0.22346724668187978, "Bleu_4": 2.668730618760853e-05, "METEOR": 0.26286544029154674, "ROUGE_L": 0.433502538071066, "CIDEr": 0.040451350327027735, "SPICE": {"All": {"pr": 0.3125, "re": 0.25, "f": 0.2777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a cat sitting on a table in a room, looking out the window. The cat is positioned in front of the window."}, "132702": {"image_id": 132702, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.2942449431545567, "Bleu_3": 0.16297813359661212, "Bleu_4": 2.1847844936428674e-05, "METEOR": 0.28616211707312456, "ROUGE_L": 0.40219780219780216, "CIDEr": 0.04553942529851389, "SPICE": {"All": {"pr": 0.16, "re": 0.21052631578947367, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a close-up view of two broccoli heads on a white cloth. The broccoli is placed on a dining table."}, "151075": {"image_id": 151075, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.15849534045439814, "Bleu_3": 0.1045209718275127, "Bleu_4": 0.07178529103115949, "METEOR": 0.20042997940979376, "ROUGE_L": 0.2827814569536423, "CIDEr": 5.570200517018037e-09, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.28, "f": 0.3181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a surfer skillfully riding a wave on a white surfboard, showcasing their talent and balance. The surfer is positioned in the center of the scene, with the surfboard beneath them. The wave is crashing around the surfer, creating a dynamic and exciting atmosphere."}, "516372": {"image_id": 516372, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.13773990809586936, "Bleu_4": 0.09047502044032775, "METEOR": 0.2876539190763276, "ROUGE_L": 0.2663755458515284, "CIDEr": 5.495943177656201e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a fire hydrant placed in the foreground. The fire hydrant is red. It is surrounded by a bush, adding a touch of greenery to the scene. In the background, there is a black car parked near the fire hydrant."}, "397958": {"image_id": 397958, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2993592018235193, "Bleu_3": 0.19546454494909793, "Bleu_4": 0.12086038782189067, "METEOR": 0.3190359322597908, "ROUGE_L": 0.41581908677775375, "CIDEr": 6.043954944676927e-05, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.34782608695652173, "f": 0.32653061224489793, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a cow standing in the tall grass of a field. The cow is looking over a barbed wire fence. The cow appears to be curious about the camera, as it stares directly at the viewer."}, "154004": {"image_id": 154004, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.2571817658421884, "Bleu_3": 0.20660446111672173, "Bleu_4": 0.16826996322490184, "METEOR": 0.20972501155649248, "ROUGE_L": 0.31063017186505404, "CIDEr": 6.538683041972332e-09, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2727272727272727, "f": 0.2790697674418604, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a lively beach scene with a group of 13 people enjoying their time on the beach. Some of the people are sitting, while others are playing frisbee or laying down. A group of people on a beach is the scene depicted in the image."}, "179599": {"image_id": 179599, "Bleu_1": 0.19999999999749998, "Bleu_2": 0.11250879009118712, "Bleu_3": 5.454556382735483e-07, "Bleu_4": 1.2048885996258901e-09, "METEOR": 0.16927448789290162, "ROUGE_L": 0.157487091222031, "CIDEr": 5.623332426362004e-29, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features three baseball players in blue and gray uniforms. \n\nBaseball player 1 is throwing a ball and holding a baseball. Baseball player 2 is hitting a ball and holding a bat. Baseball player 3 is throwing a ball and holding a baseball.\n\nOne of the players is holding a baseball glove in their left hand.\n\nThere is no pitcher's mound, ball, or other players in the scene. The image does not depict any specific process or winding."}, "282553": {"image_id": 282553, "Bleu_1": 0.49999999998529415, "Bleu_2": 0.3256694736297412, "Bleu_3": 0.18785007548970548, "Bleu_4": 2.150394333576696e-05, "METEOR": 0.3241648136372685, "ROUGE_L": 0.36003372681281615, "CIDEr": 0.0006411185555081848, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures two people standing on a grassy hillside. The people are talking on the phone and walking. One person is holding a cell phone. The scene appears to be a sunny day."}, "53529": {"image_id": 53529, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.083971912273837, "Bleu_3": 5.703763329560112e-07, "Bleu_4": 1.4964792230382814e-09, "METEOR": 0.2089263250169196, "ROUGE_L": 0.17941176470588235, "CIDEr": 0.00032534988598312633, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.22727272727272727, "f": 0.30303030303030304, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features two dogs wearing green hats. One of the dogs is sitting in the car, looking out the window. The dog does not have a smile on its face. The car is decorated with green and white balloons."}, "13168": {"image_id": 13168, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.13867504905279598, "Bleu_3": 7.969009659317547e-07, "Bleu_4": 1.9231042777337796e-09, "METEOR": 0.1971166930945749, "ROUGE_L": 0.23036253776435048, "CIDEr": 2.3625535358150292e-06, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.35294117647058826, "f": 0.3870967741935484, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image captures a train speeding by on the tracks. The train is positioned towards the left side of the scene, and it appears to be traveling. There are two people in the area. Signs are scattered throughout the area."}, "528738": {"image_id": 528738, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.13423121103912666, "Bleu_3": 8.014559500904618e-07, "Bleu_4": 1.9726044742773524e-09, "METEOR": 0.1628451059741302, "ROUGE_L": 0.23735408560311286, "CIDEr": 6.967937718070803e-05, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2413793103448276, "f": 0.2916666666666667, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a countertop with a bunch of vegetables, including cauliflower, placed on it. The vegetables are arranged in different positions, with some placed closer to the front and others towards the back of the counter."}, "368193": {"image_id": 368193, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.2148344622034018, "Bleu_3": 1.2435565865487868e-06, "Bleu_4": 3.0238984686568405e-09, "METEOR": 0.1699534264509773, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.018275894439195372, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.30303030303030304, "f": 0.3508771929824562, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 10.0}, "Relation": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features two people riding horses down a street. The people are riding on a horse. There are three horses standing still on the street."}, "538064": {"image_id": 538064, "Bleu_1": 0.18181818181582055, "Bleu_2": 0.1694347484152566, "Bleu_3": 0.13889307093373862, "Bleu_4": 0.11599653233223772, "METEOR": 0.24048178799718403, "ROUGE_L": 0.2628177509694097, "CIDEr": 6.2778333352910954e-27, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.35, "f": 0.36842105263157887, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a statue of a man with a hat and a hat. The statue is located in the park. A fountain is surrounding the statue. A child is positioned on the left side of the statue. A large wheel is positioned on the right side of the statue. The third car is positioned in front of the statue.\n\nThere are no other men or benches in the scene. There is no park in the scene."}, "265636": {"image_id": 265636, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.22606054094882583, "Bleu_3": 0.18554667634461655, "Bleu_4": 0.14888606314394973, "METEOR": 0.33567844446677636, "ROUGE_L": 0.3647234678624813, "CIDEr": 3.7318181992560546e-07, "SPICE": {"All": {"pr": 0.4, "re": 0.25806451612903225, "f": 0.3137254901960784, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a brown teddy bear holding a green card with the words \"Happy Birthday\" written on it. The teddy bear is positioned in the center of the scene, looking at the green card. The card is placed on the couch."}, "577796": {"image_id": 577796, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1852396434051399, "Bleu_3": 0.08820623589082296, "Bleu_4": 1.0878661088484124e-05, "METEOR": 0.20079686625724913, "ROUGE_L": 0.1920654911838791, "CIDEr": 4.925795060219001e-12, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 10.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a public restroom with five white urinals lined up against a wall. The urinals are placed in a row, with the first one on the left side, the second one in the middle, and the third one on the right side. The restroom appears to be a public restroom."}, "554046": {"image_id": 554046, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.2225972810858974, "Bleu_3": 0.14147093396195143, "Bleu_4": 1.6987547583349597e-05, "METEOR": 0.25187854117938074, "ROUGE_L": 0.3797665369649806, "CIDEr": 1.7043368232670155e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a snowy field with a group of five sheep standing together. Two sheep are standing closer to the foreground and two others are further back. The sheep are enjoying their time in the snow."}, "316534": {"image_id": 316534, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.10050378152407698, "Bleu_3": 5.754792186290893e-07, "Bleu_4": 1.3836345500640894e-09, "METEOR": 0.1426857021217426, "ROUGE_L": 0.2127164942461932, "CIDEr": 3.321150686680797e-13, "SPICE": {"All": {"pr": 0.3125, "re": 0.11904761904761904, "f": 0.17241379310344826, "fn": 37.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.23529411764705882, "f": 0.31999999999999995, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a group of five horses standing on the sandy shore of a beach. Some of the horses are grazing, while others are simply relaxing. The horses' location is on the beach. A large tree can be seen further back on the beach. A rocky beach can be seen closer to the water."}, "158950": {"image_id": 158950, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.11616917255653597, "Bleu_3": 7.144853954819221e-07, "Bleu_4": 1.7841008157179387e-09, "METEOR": 0.18257444674315398, "ROUGE_L": 0.2669584245076586, "CIDEr": 4.568626176343449e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.06451612903225806, "f": 0.09523809523809523, "fn": 29.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a train traveling down the tracks. The train appears to be a freight train. There are two train cars visible. The train is moving through a rural area. There are trees and grass surrounding the tracks."}, "524822": {"image_id": 524822, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1457945082861785, "Bleu_3": 0.09885983548206408, "Bleu_4": 1.2243280475333732e-05, "METEOR": 0.20709814825986694, "ROUGE_L": 0.27619663648124193, "CIDEr": 1.8860632691628674e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 36.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 19.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.5555555555555556, "f": 0.3703703703703704, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "The image features a living room with four couches. The couches are white and beige. A TV is mounted on the wall. \n\nThere is no dog in the image.\n\nThere is one book in the image.\n\nThe room is well-lit, creating a bright and inviting atmosphere."}, "248111": {"image_id": 248111, "Bleu_1": 0.4444444444279836, "Bleu_2": 0.3202563075980849, "Bleu_3": 1.6008542446281582e-06, "Bleu_4": 3.615855225003464e-09, "METEOR": 0.25429895676008696, "ROUGE_L": 0.34173669467787116, "CIDEr": 0.012515435910478639, "SPICE": {"All": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a kitchen with white appliances and wooden cabinets. The kitchen features a white stove and a sink.\n\nThere is no refrigerator in the scene."}, "409964": {"image_id": 409964, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.23354968324417125, "Bleu_3": 0.17264376558872666, "Bleu_4": 0.11860959909843712, "METEOR": 0.3158581111994236, "ROUGE_L": 0.2513243084167157, "CIDEr": 4.4022347049215526e-13, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2222222222222222, "f": 0.24489795918367346, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man playing tennis on a tennis court. The man is holding a tennis racket and preparing to hit a tennis ball. The man is in the middle of a swing, with the racket raised above his head. The tennis ball is visible in the air, close to the man's racket."}, "337987": {"image_id": 337987, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.3351111237096373, "Bleu_3": 0.25985589372428086, "Bleu_4": 0.20299685932625622, "METEOR": 0.3378934962097099, "ROUGE_L": 0.44060995184590684, "CIDEr": 0.001234986074248177, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bird perched on a tree branch. The bird is looking at a tree. The head and neck of the bird is visible.\n\nIn the background, there are several other trees."}, "544104": {"image_id": 544104, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.1322214713349675, "Bleu_3": 0.06488455529243513, "Bleu_4": 8.114669979563551e-06, "METEOR": 0.14512221589177218, "ROUGE_L": 0.23851417399804498, "CIDEr": 7.093507104665755e-19, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a large body of water with numerous boats of various sizes floating on the surface. The boats are scattered throughout the scene, with some closer to the shore and others further out in the water. The water appears to be calm, providing a serene atmosphere for the boats.\n\nThere is no specific information about the shore or the atmosphere in the supplementary information."}, "121210": {"image_id": 121210, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.1027737074612707, "Bleu_4": 1.23943015938953e-05, "METEOR": 0.22969803733732427, "ROUGE_L": 0.26940063091482647, "CIDEr": 1.4229103619758113e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.06666666666666667, "f": 0.09302325581395349, "fn": 28.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a white plate filled with a delicious meal. A stew is placed in the center of the plate. Surrounding the stew are carrots and greens. The plate is filled with a generous serving of meat. The overall presentation of the meal is appetizing and visually appealing."}, "46551": {"image_id": 46551, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.10386373237947197, "Bleu_4": 1.2360545409967114e-05, "METEOR": 0.1758225675743905, "ROUGE_L": 0.26704190118824267, "CIDEr": 7.066748486388308e-09, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.05, "f": 0.060606060606060615, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a group of five people gathered in a room. Some of the people are eating, while others are playing a video game or taking pictures. The room is equipped with a television screen, which is mounted on the wall.\n\nThere are no cups or bottles in the scene."}, "535588": {"image_id": 535588, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.19603921176003908, "Bleu_3": 9.222102361565573e-07, "Bleu_4": 2.0105373453653653e-09, "METEOR": 0.22679245002108844, "ROUGE_L": 0.29204069419509276, "CIDEr": 5.603298212687755e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man standing on the sidewalk. The man is holding a bicycle. He is standing next to a blue bus, which is parked on the side of the road. The man is waiting for the bus to pick him up. There are no other people in the scene."}, "173997": {"image_id": 173997, "Bleu_1": 0.2592592592496571, "Bleu_2": 0.09985744824877686, "Bleu_3": 7.361059130611606e-07, "Bleu_4": 2.0190748509151956e-09, "METEOR": 0.22818268930907684, "ROUGE_L": 0.2278244631185808, "CIDEr": 0.00783621665859043, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features two women sitting on two benches near a pond. A bush is near the first bench, and a tree is near the second bench."}, "320396": {"image_id": 320396, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.22216879699110492, "Bleu_3": 0.15736250546279457, "Bleu_4": 0.12047113836185865, "METEOR": 0.252254781285142, "ROUGE_L": 0.34957020057306587, "CIDEr": 6.06152617929343e-06, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.07142857142857142, "f": 0.06779661016949153, "fn": 26.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image captures a man in a white uniform playing frisbee on a beach. He is in the middle of a frisbee throw, with the frisbee flying through the air towards him. The man is positioned towards the right side."}, "221282": {"image_id": 221282, "Bleu_1": 0.1494252873546043, "Bleu_2": 0.12505011024310073, "Bleu_3": 0.09028239562912126, "Bleu_4": 0.06469787004781936, "METEOR": 0.23310677979817337, "ROUGE_L": 0.25046659201194477, "CIDEr": 2.0068108607116565e-33, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.15151515151515152, "f": 0.19230769230769232, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two women in a kitchen. One of the women is putting a pizza on a wooden board and preparing it. She is wearing a white shirt and appears to be focused on the pizza. The other woman is also preparing food and wearing a white shirt. She is focused on a plate of food.\n\nThere is a pizza placed on a wooden board. The pizza board is on a table.\n\nThere is no apron in the scene. There are no slices of pizza visible."}, "25143": {"image_id": 25143, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.34419020751467316, "Bleu_3": 0.2747124589684076, "Bleu_4": 0.19983563237751384, "METEOR": 0.28255389623675614, "ROUGE_L": 0.38654194327097163, "CIDEr": 1.3780202639684455e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1875, "f": 0.20689655172413793, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image is a collage of multiple photos featuring a group of four people playing frisbee in a park. Some of the people are actively engaged in the game, throwing and catching frisbees, while others are watching or waiting for their turn."}, "52835": {"image_id": 52835, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.17040572913395824, "Bleu_3": 8.033906732368054e-07, "Bleu_4": 1.752283682695063e-09, "METEOR": 0.21587427048451058, "ROUGE_L": 0.23131094257854823, "CIDEr": 7.678887299381743e-14, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.12121212121212122, "f": 0.15384615384615385, "fn": 29.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a lunch box filled with a variety of food items, including a container of green beans, a container of carrots, and a container of meatballs. The lunch box is placed on a dining table. The container of green beans is blue. The containers of carrots are green and orange. The container of meatballs is pink."}, "300962": {"image_id": 300962, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.10540925533701173, "Bleu_3": 0.05940557542491761, "Bleu_4": 7.968371423587569e-06, "METEOR": 0.1980668004410156, "ROUGE_L": 0.21542083578575633, "CIDEr": 1.040480098585126e-13, "SPICE": {"All": {"pr": 0.15625, "re": 0.1724137931034483, "f": 0.1639344262295082, "fn": 24.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image captures a baseball player in the middle of a baseball game. The baseball player is attempting to hit the ball. The player is wearing a baseball uniform and is holding a baseball bat, ready to make contact with the ball. The baseballs are visible in the air, close to the player's bat."}, "332532": {"image_id": 332532, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.2738612787414004, "Bleu_3": 0.14828975322020663, "Bleu_4": 1.962129587263974e-05, "METEOR": 0.2345150665203756, "ROUGE_L": 0.3715736040609137, "CIDEr": 0.039755682958111896, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2777777777777778, "f": 0.25641025641025644, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a bathroom with a sink and four toilets. The sink is located in the bathroom. The toilet is situated in the corner."}, "528261": {"image_id": 528261, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.21764287502183505, "Bleu_3": 1.3806135595106663e-06, "Bleu_4": 3.527295712509229e-09, "METEOR": 0.2508846138919531, "ROUGE_L": 0.44417475728155337, "CIDEr": 0.11454509634939145, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14814814814814814, "f": 0.1509433962264151, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a giraffe grazing on grass in a grassy field. The giraffe is standing near a wooden log."}, "297046": {"image_id": 297046, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.10223972648618562, "Bleu_3": 6.39332019360638e-07, "Bleu_4": 1.6088986597188547e-09, "METEOR": 0.17965161066509724, "ROUGE_L": 0.18236173393124064, "CIDEr": 1.1769351568191691e-06, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.25, "f": 0.2592592592592593, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a street with a train passing through the intersection. The train is orange. The train is positioned in the middle of the street. The cars are positioned in the intersection. The vehicles are waiting for the train to pass."}, "130839": {"image_id": 130839, "Bleu_1": 0.13953488371930775, "Bleu_2": 0.09924475403566661, "Bleu_3": 0.06166734861475139, "Bleu_4": 7.2907454278677176e-06, "METEOR": 0.2089493276983008, "ROUGE_L": 0.17259498787388847, "CIDEr": 1.4885523530467682e-35, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.07142857142857142, "f": 0.07017543859649124, "fn": 26.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a man dressed in a suit, standing in a room with a black suitcase and a black rolling bag. He is pulling the suitcase behind him, possibly preparing for a trip. There are two other people in the room, one standing near the left side of the image and another person closer to the left side. The position of the person in relation to the man is behind the man. The position of the person in relation to the room is left side."}, "451120": {"image_id": 451120, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.287970188151824, "Bleu_3": 0.12859087487843598, "Bleu_4": 1.538019048092943e-05, "METEOR": 0.203263685966947, "ROUGE_L": 0.27875095201827876, "CIDEr": 1.190576193236743e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.25806451612903225, "f": 0.3404255319148936, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a woman standing in a kitchen. She is smiling and holding a wooden rolling pin. The woman is preparing food. The kitchen is well-equipped with multiple bowls placed on the countertops. There is no sink in the scene."}, "378134": {"image_id": 378134, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.29214466689738716, "Bleu_3": 0.22801030540663686, "Bleu_4": 0.17853738103300446, "METEOR": 0.25809054610535664, "ROUGE_L": 0.2793893129770992, "CIDEr": 1.8323988444419244e-05, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.0625, "f": 0.08, "fn": 30.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a group of four people playing frisbee on a grassy field. Some of the people are actively engaged in the game, while others are waiting for their turn. The frisbee is visible in the scene."}, "458953": {"image_id": 458953, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.12253577034561024, "Bleu_3": 7.541989245962001e-07, "Bleu_4": 1.884710726818381e-09, "METEOR": 0.2079082332808242, "ROUGE_L": 0.24419535628502803, "CIDEr": 9.949550139973172e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17647058823529413, "f": 0.15789473684210528, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a lively scene of two people flying a kite in a field. There are eight kites of various sizes and colors soaring high in the sky. The kites are spread out across the field."}, "159451": {"image_id": 159451, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 8.556026937263809e-07, "Bleu_4": 1.931527870007565e-09, "METEOR": 0.23360930401519892, "ROUGE_L": 0.2401574803149606, "CIDEr": 6.15210046506011e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.18518518518518517, "f": 0.20408163265306123, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a truck parked in front of a building. The truck is a dump truck and it is yellow. The dump truck is equipped with a large wheelbase and is suitable for hauling heavy loads.\n\nThere is no warehouse or other dump trucks in the scene."}, "294258": {"image_id": 294258, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.3849001794457496, "Bleu_3": 0.22503546038471237, "Bleu_4": 0.1461178308959271, "METEOR": 0.2941675795350519, "ROUGE_L": 0.4700342465753425, "CIDEr": 0.08426297170865195, "SPICE": {"All": {"pr": 0.25, "re": 0.14814814814814814, "f": 0.18604651162790697, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man wearing a black suit and a brown tie. He is standing in front of a building. The man is wearing a striped shirt."}, "544695": {"image_id": 544695, "Bleu_1": 0.562499999982422, "Bleu_2": 0.3563932224723017, "Bleu_3": 0.1617754212639444, "Bleu_4": 1.9547215687428063e-05, "METEOR": 0.2759120378602448, "ROUGE_L": 0.3570234113712374, "CIDEr": 0.004700434837747345, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a tennis court with two people playing tennis. One person is standing on the left side of the court, holding a tennis racket and preparing to hit the ball"}, "623": {"image_id": 623, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.15585730003579046, "Bleu_3": 8.691288996416392e-07, "Bleu_4": 2.0665100326125144e-09, "METEOR": 0.2501983196041501, "ROUGE_L": 0.3559445660102115, "CIDEr": 1.1445958377389164e-05, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a woman in a gray shirt and a brown teddy bear sitting on a chair. The woman is hugging and kissing the teddy bear. The teddy bear is positioned on the left side of the woman."}, "236690": {"image_id": 236690, "Bleu_1": 0.370370370356653, "Bleu_2": 0.315776977798527, "Bleu_3": 0.2711837370052755, "Bleu_4": 0.2234473632029469, "METEOR": 0.26245984863023725, "ROUGE_L": 0.38006230529595014, "CIDEr": 0.017699009763321564, "SPICE": {"All": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.8, "f": 0.5333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a bird flying over the ocean. The bird is captured in mid-flight, with its wings pointing downward. Its body is positioned in the air."}, "382088": {"image_id": 382088, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.21938172723158908, "Bleu_3": 0.1818738688549909, "Bleu_4": 0.15533439103887883, "METEOR": 0.299987434372963, "ROUGE_L": 0.36371379897785344, "CIDEr": 0.0002867812658835532, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.23333333333333334, "f": 0.23728813559322037, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.46153846153846156, "f": 0.5217391304347826, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a white horse standing in a field. The horse is looking at the camera. The scene is set in a rural area, with a lush green hillside visible in the background."}, "504711": {"image_id": 504711, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.2506402059074552, "Bleu_3": 0.18769784683761237, "Bleu_4": 0.15216835672279275, "METEOR": 0.2806363040517063, "ROUGE_L": 0.38337988826815644, "CIDEr": 1.8097350381519784e-05, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.15384615384615385, "f": 0.1951219512195122, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a delicious chocolate cake on a plate, with a fork placed next to it. The cake is cut into two pieces, and the fork is positioned in front of the cake, ready to be used for serving."}, "495348": {"image_id": 495348, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.08518740546037545, "Bleu_3": 5.220677531965598e-07, "Bleu_4": 1.298831014470151e-09, "METEOR": 0.11912603099424005, "ROUGE_L": 0.14480712166172105, "CIDEr": 8.375801967184473e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.20833333333333334, "f": 0.1851851851851852, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image depicts a group of five zebras grazing in a grassy field. Some zebras are closer to the foreground, while others are further back, creating a sense of depth in the image. Savannas is the zebras' habitat. The zebras are not drinking water. The zebras are not in front of a tree."}, "326217": {"image_id": 326217, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.1770283348412488, "Bleu_3": 1.0782393734290365e-06, "Bleu_4": 2.6883361966028928e-09, "METEOR": 0.20141316397778064, "ROUGE_L": 0.3306233062330623, "CIDEr": 0.01641617634710432, "SPICE": {"All": {"pr": 0.1346153846153846, "re": 0.21875, "f": 0.16666666666666669, "fn": 25.0, "numImages": 1.0, "fp": 45.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.045454545454545456, "re": 0.09090909090909091, "f": 0.060606060606060615, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5454545454545454, "f": 0.41379310344827586, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}}, "caption": "The image features a group of sixteen people sitting on a boat. The boat is filled with fruits and vegetables. Some people are sitting on the boat."}, "59752": {"image_id": 59752, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.11945967146768073, "Bleu_3": 6.978002390453578e-07, "Bleu_4": 1.6966894961903369e-09, "METEOR": 0.14788929740295567, "ROUGE_L": 0.214185393258427, "CIDEr": 1.9157009444501133e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.29411764705882354, "f": 0.25, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8333333333333334, "f": 0.625, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image depicts a river with two boats floating on the water. One of the boats has a man on it. The boats are scattered throughout the river, creating a picturesque view. Some boats are closer to the shore, while others are further away."}, "437393": {"image_id": 437393, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.29957234474633043, "Bleu_3": 0.24305681724091033, "Bleu_4": 0.15639686544681553, "METEOR": 0.2840301714760885, "ROUGE_L": 0.38006230529595014, "CIDEr": 0.00952999538082307, "SPICE": {"All": {"pr": 0.25, "re": 0.22727272727272727, "f": 0.23809523809523808, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a white horse wearing a blue bridle. The horse is standing on a table. The room has a white wall with a blue color."}, "279209": {"image_id": 279209, "Bleu_1": 0.39999999999, "Bleu_2": 0.2264554068231852, "Bleu_3": 0.1105080538539386, "Bleu_4": 1.3819585494470887e-05, "METEOR": 0.19356469563585602, "ROUGE_L": 0.2908719346049046, "CIDEr": 1.362659323530272e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13043478260869565, "f": 0.14634146341463414, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a person doing skiing in a snowy forest. The person is holding a pair of skis and wearing a black and blue jacket. They are surrounded by trees covered in snow. The winter season is the landscape."}, "202228": {"image_id": 202228, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.2303502213753046, "Bleu_3": 0.13027327825651416, "Bleu_4": 0.0828165323626551, "METEOR": 0.26122987357957483, "ROUGE_L": 0.26521739130434785, "CIDEr": 1.0369182489224916e-09, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.16129032258064516, "f": 0.22727272727272727, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man standing in a bathroom, taking a selfie with his cell phone. He is wearing a red and white scarf and appears to be looking at himself in the mirror. The bathroom has a sink visible in the scene.\n\nThere is no toilet in the scene."}, "193661": {"image_id": 193661, "Bleu_1": 0.19999999999428575, "Bleu_2": 0.10846522890618356, "Bleu_3": 0.07090698915331586, "Bleu_4": 1.0273756991669545e-05, "METEOR": 0.18422072293235603, "ROUGE_L": 0.28960278525083083, "CIDEr": 0.00034726454076486785, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a cozy living room with two fireplaces. The fireplaces are surrounded by brick walls. A chair is placed in front of the fireplaces. The living room creates a warm and inviting atmosphere."}, "457060": {"image_id": 457060, "Bleu_1": 0.34615384614053263, "Bleu_2": 0.1664100588610404, "Bleu_3": 1.0488562462463889e-06, "Bleu_4": 2.661368533136455e-09, "METEOR": 0.1992521007166071, "ROUGE_L": 0.19902120717781402, "CIDEr": 0.07853850321375669, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15789473684210525, "f": 0.14634146341463414, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two giraffes standing in a wildlife park. One giraffe is looking at the camera, while the other giraffe is located behind the fence."}, "390215": {"image_id": 390215, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.14189834119414174, "Bleu_4": 0.10500646136283469, "METEOR": 0.2568979694909986, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.0782612001854102e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.15, "f": 0.18749999999999997, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a plate of food with two pieces of meat, possibly chicken, placed on top of a table. The meat is accompanied by a generous amount of broccoli, which is spread across the plate. The broccoli is arranged in various positions, with some pieces closer to the meat."}, "579635": {"image_id": 579635, "Bleu_1": 0.5588235293953288, "Bleu_2": 0.43159530789015565, "Bleu_3": 0.28555371462276785, "Bleu_4": 0.16554857129101963, "METEOR": 0.3436472388649824, "ROUGE_L": 0.3954619124797406, "CIDEr": 0.000653099437925874, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.11428571428571428, "f": 0.13559322033898305, "fn": 31.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.25, "f": 0.2962962962962963, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a man riding a wave on a surfboard in the ocean, skillfully navigating the large wave. The surfer is positioned towards the center of the scene, with the wave behind him."}, "251920": {"image_id": 251920, "Bleu_1": 0.29999999998500004, "Bleu_2": 0.21764287502183505, "Bleu_3": 1.3806135595106661e-06, "Bleu_4": 3.527295712509229e-09, "METEOR": 0.17695816049920768, "ROUGE_L": 0.23223350253807104, "CIDEr": 0.052505638552688846, "SPICE": {"All": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a kitchen with a pizza placed on a pizza pan. The pizza is ready to be cooked."}, "271117": {"image_id": 271117, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.1942571724677524, "Bleu_3": 0.13044729210752723, "Bleu_4": 0.081626993367812, "METEOR": 0.2696205233382998, "ROUGE_L": 0.3124644280022766, "CIDEr": 8.009188845036187e-11, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a desk with a blue vase of flowers placed on it. There are two books scattered around the desk. \n\nA blue bag and a blue box are stacked on top of each other. Books are also stacked on top of each other. \n\nThere are no other items on the desk."}, "11051": {"image_id": 11051, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.2028233864039703, "Bleu_3": 0.09022966481104477, "Bleu_4": 1.0750318607761322e-05, "METEOR": 0.18172215403023254, "ROUGE_L": 0.23591160220994478, "CIDEr": 1.1446612224492369e-13, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man and a woman dressed in formal attire. The man is wearing a black suit and a flower around his neck, and he is holding a flower. The woman is wearing a black dress and her hand is adjusting the flower on the man's lapel. They appear to be enjoying their time together."}, "170605": {"image_id": 170605, "Bleu_1": 0.555555555432099, "Bleu_2": 0.26352313828697443, "Bleu_3": 2.1487199818053206e-06, "Bleu_4": 6.376715692219053e-09, "METEOR": 0.17229458797668012, "ROUGE_L": 0.35672514619883033, "CIDEr": 0.4418579078823786, "SPICE": {"All": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features an airplane parked on the snow."}, "84123": {"image_id": 84123, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.3042903097136056, "Bleu_3": 0.1547196277811361, "Bleu_4": 1.9820118582599933e-05, "METEOR": 0.26399814834821694, "ROUGE_L": 0.3306233062330623, "CIDEr": 0.06117264681284677, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.15384615384615385, "f": 0.21428571428571433, "fn": 33.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.3125, "f": 0.4166666666666667, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a street sign indicating the direction of the road. The sign is positioned on a pole. There are three cars parked on the street."}, "505899": {"image_id": 505899, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.3340900501528661, "Bleu_3": 0.24972956426447246, "Bleu_4": 0.19624795721428936, "METEOR": 0.34274474506509817, "ROUGE_L": 0.3696969696969697, "CIDEr": 1.1133226002994338e-07, "SPICE": {"All": {"pr": 0.4, "re": 0.05263157894736842, "f": 0.09302325581395349, "fn": 36.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.14285714285714285, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image features a dining table with a plate of two donuts and a cup of coffee. The donuts are placed on a white plate, with one of them closer to the front and the other one towards the back. A spoon can be seen."}, "256814": {"image_id": 256814, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.26340122154667245, "Bleu_3": 0.20992207086883408, "Bleu_4": 0.17029245450294903, "METEOR": 0.2526035732320718, "ROUGE_L": 0.30367143746110764, "CIDEr": 2.1286972082044473e-08, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.4166666666666667, "f": 0.5263157894736842, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features two men and two children taking a selfie. One of the men is wearing sunglasses and holding a piece of food in his hand. The other man is holding a cell phone. The children are smiling. The picture captures a man and two women."}, "419680": {"image_id": 419680, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 0.06290089214849724, "Bleu_4": 8.441965712987706e-06, "METEOR": 0.14634146341463414, "ROUGE_L": 0.1888544891640867, "CIDEr": 2.2447413973579364e-11, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2413793103448276, "f": 0.2545454545454545, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a building in the background. The building has a balcony and a sign on the side. The sign reads \"No Ass Allowed.\" There are other signs on the building, including one that says \"No Parking.\"\n\nThere is no street in the image.\n\nThere is a person in the scene.\n\n"}, "519555": {"image_id": 519555, "Bleu_1": 0.1739130434757404, "Bleu_2": 0.08759357436978878, "Bleu_3": 0.048561254579027095, "Bleu_4": 6.454036835718624e-06, "METEOR": 0.14952864816577702, "ROUGE_L": 0.20132013201320131, "CIDEr": 2.7126028416657986e-21, "SPICE": {"All": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a stop sign sitting on the side of a road, surrounded by a grassy area. The stop sign is prominently displayed, with the word \"STOP\" clearly visible. A traffic light is on the left of the stop sign. A traffic sign is on the right of the stop sign. The grassy area extends to the left and right of the stop sign, creating a natural setting."}, "354929": {"image_id": 354929, "Bleu_1": 0.5714285714081633, "Bleu_2": 0.38490017944574956, "Bleu_3": 0.2835269135114829, "Bleu_4": 0.20664181815755847, "METEOR": 0.30558880843257746, "ROUGE_L": 0.4452554744525547, "CIDEr": 0.05994053115308279, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15, "f": 0.1764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a group of seven people riding bicycles down a city street at night. Some riders are wearing backpacks. Two bicycles are visible in the scene."}, "17379": {"image_id": 17379, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.1322214713349675, "Bleu_3": 0.06488455529243513, "Bleu_4": 8.114669979563551e-06, "METEOR": 0.19650126053134145, "ROUGE_L": 0.19823584029712163, "CIDEr": 9.7192089863312e-17, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.5333333333333333, "f": 0.326530612244898, "fn": 7.0, "numImages": 1.0, "fp": 26.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.3333333333333333, "f": 0.14285714285714288, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features a bathroom with a large mirror mounted on the wall. The mirror is reflecting a television screen, which is displaying a sports game. The game appears to be football, as two players are seen on the screen. The mirrored wall creates an illusion of a larger space, making the bathroom appear more spacious.\n\nThere is no other wall or television in the scene."}, "13965": {"image_id": 13965, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.1994310087982287, "Bleu_3": 1.0866121565918492e-06, "Bleu_4": 2.5572642415484343e-09, "METEOR": 0.24950565511101777, "ROUGE_L": 0.3774168600154679, "CIDEr": 0.0009337457996526103, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a trolley bus parked at a station. The trolley bus is green. The doors of the trolley bus are open.\n\nThere is no road, people, or passengers in the scene."}, "422836": {"image_id": 422836, "Bleu_1": 0.2077922077895092, "Bleu_2": 0.16535138333846527, "Bleu_3": 0.12215412449643766, "Bleu_4": 0.08377813158330638, "METEOR": 0.23161871973367096, "ROUGE_L": 0.21698532681191643, "CIDEr": 7.303198845545763e-27, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.12121212121212122, "f": 0.15384615384615385, "fn": 29.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image captures a busy city street scene with two men walking down the sidewalk. The first man is riding a suitcase and carrying a black jacket and a handbag. The second man is walking down the street and carrying a bag of ice cream. \n\nThere are several other people in the scene, some of them walking and others standing. A person walking down a street does the scene capture.\n\nThe street is lined with various shops."}, "513292": {"image_id": 513292, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2132007163490489, "Bleu_3": 0.11360703054848365, "Bleu_4": 1.486872032585981e-05, "METEOR": 0.33648884734645934, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.000578541374827319, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.16666666666666666, "f": 0.14634146341463414, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a boy standing on a sidewalk. The boy is holding a skateboard, which appears to be quite large for him. The boy is holding the skateboard in his left hand."}, "202444": {"image_id": 202444, "Bleu_1": 0.18421052631336565, "Bleu_2": 0.0700876644041179, "Bleu_3": 4.0490252522376036e-07, "Bleu_4": 9.765222631287186e-10, "METEOR": 0.2020042039173496, "ROUGE_L": 0.18744512730465318, "CIDEr": 1.0923115046293824e-25, "SPICE": {"All": {"pr": 0.14634146341463414, "re": 0.25, "f": 0.1846153846153846, "fn": 18.0, "numImages": 1.0, "fp": 35.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image captures a skate park, where four young men are enjoying their time. One of the young men is posing for a photo. Another young man is doing skateboarding. The other two young men are also doing skateboarding. \n\nThere are three skateboards in the scene. One of the skateboarders is riding up a ramp. \n\nOverall, the scene captures the lively atmosphere of the skate park, with young men enjoying their time riding on their skateboards."}, "268541": {"image_id": 268541, "Bleu_1": 0.1585365853639203, "Bleu_2": 0.14672988700504577, "Bleu_3": 0.12912561075921378, "Bleu_4": 0.11308117990174571, "METEOR": 0.2797684167293973, "ROUGE_L": 0.22611202635914332, "CIDEr": 7.7330502391549e-31, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.25, "f": 0.20512820512820512, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man wearing a suit and tie, holding a cup in his hand. The man is looking through a coffee cup. He is possibly examining a cup of coffee. The man is wearing a hat and glasses on his face. He appears to be in a suit and tie.\n\nThere is a room in the background. A man in a suit drinking from a cup is in the background. There is no magnifying glass or couch in the scene."}, "377999": {"image_id": 377999, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.26042109924757323, "Bleu_3": 0.1433974735643138, "Bleu_4": 1.599937421614292e-05, "METEOR": 0.2527709350773894, "ROUGE_L": 0.2952973720608575, "CIDEr": 2.449075956638632e-08, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.14814814814814814, "f": 0.13793103448275862, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a sailboat floating on the water. A man is sitting on a bike next to the sailboat. The man is wearing a white shirt and is possibly preparing to ride his bike or simply enjoying a bike ride. The sailboat is positioned on the water."}, "272694": {"image_id": 272694, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.24330354977564592, "Bleu_3": 0.14126216736382222, "Bleu_4": 1.6192855290859414e-05, "METEOR": 0.3217032415072005, "ROUGE_L": 0.3512797074954296, "CIDEr": 6.435955622741588e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.38461538461538464, "f": 0.4545454545454546, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a table with a cup of coffee and a muffin placed on it. The cup is a Starbucks cup. The muffin is a banana muffin. There are two bananas on the table, one near the left side and the other closer."}, "137844": {"image_id": 137844, "Bleu_1": 0.333333333325926, "Bleu_2": 0.23028309323074364, "Bleu_3": 0.1351124024482053, "Bleu_4": 0.08754051346381944, "METEOR": 0.22365803572951692, "ROUGE_L": 0.28754208754208754, "CIDEr": 2.256839947249876e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image captures a skateboarder performing a trick on a ramp, soaring through the air with his skateboard. The skateboarder is doing a trick. Some of the people in the scene are also doing a trick because they are inspired by the skateboarder's performance."}, "374829": {"image_id": 374829, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.2077944166525388, "Bleu_3": 0.13643933968471528, "Bleu_4": 0.08442327695098985, "METEOR": 0.276362536481859, "ROUGE_L": 0.2877056912273347, "CIDEr": 5.945548220653835e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.11538461538461539, "f": 0.15, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress. There are two batters standing at home plate, each holding a baseball bat and preparing to swing. The catcher is positioned behind the batter, ready to catch the ball. \n\nThere are no other players in the scene.\n\nThe game is taking place on a field."}, "21465": {"image_id": 21465, "Bleu_1": 0.06878306878270486, "Bleu_2": 0.046853007617874504, "Bleu_3": 0.02863437969528853, "Bleu_4": 3.351873334702624e-06, "METEOR": 0.06049877705629623, "ROUGE_L": 0.0594541910331384, "CIDEr": 2.6619225952257463e-191, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14285714285714285, "f": 0.1568627450980392, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features three tables. The first table is blue. On top of the table, there is a vase, a cup, and a bowl. There is also a blue shelf on the left side of the table and another blue shelf on the right side of the table. A blue shelf is also on the table. \n\nThe second table is white. On top of the table, there is a picture, a box, and a hat. There is a small box on the left side of the table and another small box on the right side of the table. A picture is also on the table.\n\nThe third table is green. On top of the table, there is a lamp and a clock. There is a small stool on the left side of the table and another small stool on the right side of the table. A lamp is also on the table.\n\nThere are three chairs in the scene. The first chair is positioned in front of the table. The other two chairs are not mentioned in the supplementary information.\n\nThere are no other items mentioned in the passage."}, "281929": {"image_id": 281929, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.2307304479757116, "Bleu_3": 0.16813724690537885, "Bleu_4": 0.11466074929466666, "METEOR": 0.2940111486287135, "ROUGE_L": 0.3304442036836403, "CIDEr": 3.629765963063635e-14, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.18518518518518517, "f": 0.19999999999999998, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man dressed in a brown suit and tie. He is standing outside a house, holding a bicycle. The man is wearing a hat on his head. The bicycle is positioned next to the man. The front wheel of the bicycle is in front of the man, and the back wheel is in the back."}, "464814": {"image_id": 464814, "Bleu_1": 0.18367346938400672, "Bleu_2": 0.12371791482379726, "Bleu_3": 0.08668270200700182, "Bleu_4": 0.06134227411374885, "METEOR": 0.1927197483663561, "ROUGE_L": 0.3010487353485503, "CIDEr": 4.512190137884024e-10, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.15625, "f": 0.19607843137254902, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.26666666666666666, "f": 0.32, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image is a 3D rendering of a modern living room with a large brown couch situated in the middle of the room. A lamp is placed near the couch. The room also features a chair and a dining table. A black end table is present in the room."}, "213538": {"image_id": 213538, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.14002800840008178, "Bleu_3": 0.07319587495056674, "Bleu_4": 9.458362067959735e-06, "METEOR": 0.22361182629858328, "ROUGE_L": 0.18373493975903615, "CIDEr": 5.755432942416361e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.030303030303030304, "f": 0.05, "fn": 32.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image features two wooden desks. On the first desk, there are two computer monitors placed side by side, creating a dual-screen setup. A keyboard and a mouse can be seen on the desk. On the second desk, there is a laptop computer. A cell phone is also placed on the desk."}, "461573": {"image_id": 461573, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.12666009927244304, "Bleu_3": 7.944072943886587e-07, "Bleu_4": 2.0053583652894944e-09, "METEOR": 0.16040257906976324, "ROUGE_L": 0.1608084358523726, "CIDEr": 8.306892008643879e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.20689655172413793, "f": 0.21052631578947367, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features three benches situated on the side of a road. The benches are not empty. There are no banana peels scattered around the area. The benches are positioned close to a curb."}, "360629": {"image_id": 360629, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2006088294094673, "Bleu_3": 0.12731761426913407, "Bleu_4": 0.08584608022925443, "METEOR": 0.2227271843225199, "ROUGE_L": 0.34634492547906315, "CIDEr": 1.688485986113472e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.47058823529411764, "f": 0.2909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 30.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2857142857142857, "f": 0.16, "fn": 5.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.7142857142857143, "f": 0.4545454545454545, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image features a red tray filled with a variety of food items, including meat, vegetables, and noodles. The tray is divided into four compartments, each containing different foods. The compartments are filled with a mix of meat, vegetables, and noodles."}, "114745": {"image_id": 114745, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.08902660440381881, "Bleu_4": 1.1128852820974656e-05, "METEOR": 0.1869817467999937, "ROUGE_L": 0.23091482649842268, "CIDEr": 5.0622202968692786e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2, "f": 0.21428571428571427, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a black dog wearing a red jacket, skillfully riding a skateboard down a ramp. The dog is doing a trick on the skateboard and appears to be enjoying its time on the skateboard, showcasing its agility and balance.\n\nIn the background, there are no cars parked."}, "548878": {"image_id": 548878, "Bleu_1": 0.06060606060422409, "Bleu_2": 1.3762047063655964e-09, "Bleu_3": 3.938535773814409e-12, "Bleu_4": 2.124324129849806e-13, "METEOR": 0.11262939958592132, "ROUGE_L": 0.10617928633594431, "CIDEr": 3.3520746200297524e-06, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.16666666666666666, "f": 0.2040816326530612, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures three snowboarders in mid-air, performing jumps in front of two buildings. The snowboarders are skillfully riding their snowboards, showcasing their talent and athleticism. The snowboards are positioned underneath the snowboarders."}, "385985": {"image_id": 385985, "Bleu_1": 0.1551724137904281, "Bleu_2": 1.6499463775853805e-09, "Bleu_3": 3.649644341069691e-12, "Bleu_4": 1.7242380943354172e-13, "METEOR": 0.11199799972403819, "ROUGE_L": 0.09452479338842974, "CIDEr": 7.591836721846528e-12, "SPICE": {"All": {"pr": 0.24, "re": 0.3157894736842105, "f": 0.2727272727272727, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features three people sitting on the ground. They are wearing black and white t-shirts and black jeans. Some of the people are also wearing white tank tops. Two people are in the foreground, two people are in the middle, and two more people are in the background. The people are sitting down and playing video games."}, "289714": {"image_id": 289714, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.22086305214437038, "Bleu_3": 0.10683872974724745, "Bleu_4": 1.3297818013256771e-05, "METEOR": 0.2090108935528953, "ROUGE_L": 0.29901960784313725, "CIDEr": 1.0463220060527545e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.09375, "f": 0.11538461538461538, "fn": 29.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a woman standing in a kitchen, preparing food. She is wearing a purple shirt and appears to be focused on the oven. The kitchen is well-equipped with various appliances, including a sink.\n\nThere is no refrigerator in the scene."}, "230226": {"image_id": 230226, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.18731716231147263, "Bleu_3": 0.12378303795228017, "Bleu_4": 0.08519620064749515, "METEOR": 0.19251650151086613, "ROUGE_L": 0.2741573033707865, "CIDEr": 1.8286621330971214e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a bathroom with a glass container filled with various toothbrushes and toothpaste. The container is placed on a countertop. There are at least two toothbrushes inside the container. The toothpaste is also present with the toothbrushes."}, "319534": {"image_id": 319534, "Bleu_1": 0.2142857142806123, "Bleu_2": 0.10223972648618562, "Bleu_3": 6.39332019360638e-07, "Bleu_4": 1.6088986597188547e-09, "METEOR": 0.21457236714443356, "ROUGE_L": 0.2663755458515284, "CIDEr": 4.721224177998996e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.20689655172413793, "f": 0.2142857142857143, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a group of seven people standing on a train, with one person leaning against the door. The train appears to be a bus, as it has a bus-like design. Some of the people are standing closer to the door."}, "427476": {"image_id": 427476, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2015901948875348, "Bleu_3": 0.11680628450365417, "Bleu_4": 0.07513757183070931, "METEOR": 0.2518532391612443, "ROUGE_L": 0.27216954824316786, "CIDEr": 3.8090258858402184e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13043478260869565, "f": 0.13636363636363635, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a girl standing in a bathroom. The girl is holding a toilet seat with her right hand. She appears to be playing with the toilet seat, possibly as a form of entertainment or curiosity. The bathroom is equipped with a sink and a bathtub, which is located near the sink."}, "101223": {"image_id": 101223, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.12948675740619273, "Bleu_4": 1.4739391640949857e-05, "METEOR": 0.22462317642461568, "ROUGE_L": 0.28824571766095686, "CIDEr": 5.732370310279741e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a view from the window seat of an airplane, flying high over a snow-covered mountain range. The wing of the airplane is visible in the foreground, extending from the left to the right side of the image. The wing is adorned with the Southwest Airlines logo."}, "123570": {"image_id": 123570, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.14361061402438519, "Bleu_3": 0.07004986068930465, "Bleu_4": 8.736600035760076e-06, "METEOR": 0.22122519349602296, "ROUGE_L": 0.1953041622198506, "CIDEr": 4.312506757857446e-15, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.25925925925925924, "f": 0.25, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features two men standing outside a building. One man is holding an umbrella, while the other man is looking at his phone and holding a cigar. The umbrella covers both the man and a woman. The man holding the umbrella is dressed in black. \n\nThere is no rain in the scene, and there are no specific details about the surroundings."}, "368581": {"image_id": 368581, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.16528691241294277, "Bleu_4": 0.11372027709677378, "METEOR": 0.2053432931305986, "ROUGE_L": 0.31937172774869105, "CIDEr": 0.019658607124096325, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a container filled with a variety of food items. Inside the container, there is a sandwich surrounded by strawberries. There are also cucumbers placed around the sandwich."}, "446984": {"image_id": 446984, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.15320195579385062, "Bleu_3": 0.08671123520251264, "Bleu_4": 1.1682600305257854e-05, "METEOR": 0.2019112465691239, "ROUGE_L": 0.23940345368916802, "CIDEr": 4.019791286724487e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.23076923076923078, "f": 0.20000000000000004, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a group of ten people gathered around two bicycles. Some of the individuals are standing behind the bike. Other people are standing in the background.\n\nThere are no individuals wearing life jackets in the scene."}, "514668": {"image_id": 514668, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.1996674976872179, "Bleu_3": 0.16940788976229548, "Bleu_4": 0.13818647557441413, "METEOR": 0.26724952779420874, "ROUGE_L": 0.3400696864111499, "CIDEr": 3.536325232479269e-07, "SPICE": {"All": {"pr": 0.4, "re": 0.125, "f": 0.19047619047619047, "fn": 28.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3076923076923077, "f": 0.42105263157894735, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features two cats sitting in a car. One cat is looking out the window, possibly observing the surroundings, while the other cat is sitting in the sun. The car is parked on a road. The cat is positioned in the car."}, "532129": {"image_id": 532129, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.23750843439212802, "Bleu_3": 0.14372582965062497, "Bleu_4": 1.683064218806342e-05, "METEOR": 0.20331364298869836, "ROUGE_L": 0.28416149068322977, "CIDEr": 5.406871973404061e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a pizza sitting on a plate placed on a table. The pizza is not cut into slices. There are two cups on the table, one near the left side and the other closer to the right side."}, "200168": {"image_id": 200168, "Bleu_1": 0.18309859154671693, "Bleu_2": 0.12527635447080343, "Bleu_3": 0.061042133974878586, "Bleu_4": 7.604927052941496e-06, "METEOR": 0.19940066710469356, "ROUGE_L": 0.17741153659718853, "CIDEr": 4.942074792777585e-22, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a child standing on a ski slope. The child is wearing a ski jacket and holding ski poles. The child is doing skiing. The child is wearing skis.\n\nThere are two people in the background. One of them is wearing a black and green jacket and riding a skateboard. The other person is wearing a red jacket and white pants, and they are doing skiing on the snow."}, "470801": {"image_id": 470801, "Bleu_1": 0.2089552238774783, "Bleu_2": 0.17793224105034713, "Bleu_3": 0.134541205611119, "Bleu_4": 0.0785410119873258, "METEOR": 0.2616061094386175, "ROUGE_L": 0.2398034398034398, "CIDEr": 2.980952278028701e-20, "SPICE": {"All": {"pr": 0.375, "re": 0.2857142857142857, "f": 0.3243243243243243, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a girl flying a kite in the sky. The girl is holding onto a kite string, and she appears to be enjoying flying the kite. The kite is soaring high in the sky. The kite is red and white striped and attached to the kite string.\n\nIn the background, there is a clear blue sky. A rainbow kite is also visible in the sky."}, "138713": {"image_id": 138713, "Bleu_1": 0.6236713232712557, "Bleu_2": 0.40828872109385694, "Bleu_3": 2.2891775734611932e-06, "Bleu_4": 5.530011813119188e-09, "METEOR": 0.21660873538248754, "ROUGE_L": 0.4979591836734694, "CIDEr": 0.4027063069279059, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.26666666666666666, "f": 0.326530612244898, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.06666666666666667, "f": 0.09523809523809522, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image captures a scene of three men playing with a frisbee in a field."}, "195917": {"image_id": 195917, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.11851923038388859, "Bleu_4": 0.07596247666198071, "METEOR": 0.22869915603954905, "ROUGE_L": 0.25894481503941785, "CIDEr": 5.185430737444745e-11, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.3157894736842105, "f": 0.36363636363636365, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features two men brushing their teeth. They are holding toothbrushes and cleaning their teeth. One of the men is standing in front of a mirror, ensuring that he is brushing his teeth properly. The other man is standing in front of a television. The brush is in the man's mouth."}, "145391": {"image_id": 145391, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.17339191115885713, "Bleu_3": 0.11014337576432262, "Bleu_4": 1.3200963130423502e-05, "METEOR": 0.20495581765453108, "ROUGE_L": 0.27180140038192235, "CIDEr": 0.00021619745662554738, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16129032258064516, "f": 0.1923076923076923, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a pair of blue scissors sitting on top of a table. The scissors are positioned towards the left side of the table. There is a roll of tape sitting on top of another table. The roll of tape is located towards the right side."}, "459303": {"image_id": 459303, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.11531640100118269, "Bleu_3": 0.0661213089813225, "Bleu_4": 8.952677771744006e-06, "METEOR": 0.19145796561898426, "ROUGE_L": 0.27371794871794874, "CIDEr": 3.335204611162821e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.24, "f": 0.27906976744186046, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a train pulling into the station. The train is positioned on the tracks. There is no train station in the scene. There are 5 people standing closer to the train. There are no people standing further away. The scene is set in a train station."}, "497334": {"image_id": 497334, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.17614871215260033, "Bleu_3": 0.08770015703255855, "Bleu_4": 1.1064891248238045e-05, "METEOR": 0.18319112975420776, "ROUGE_L": 0.2293233082706767, "CIDEr": 3.874700606292714e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.08108108108108109, "f": 0.11764705882352942, "fn": 34.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.21428571428571427, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a pile of books stacked on top of each other, with some of them partially hidden behind a blue blanket. The books are of various sizes and are placed in a somewhat disorganized manner. A book is located on the bed. The blanket is white."}, "173138": {"image_id": 173138, "Bleu_1": 0.4374999999863282, "Bleu_2": 0.2909938476144488, "Bleu_3": 0.22433762449235847, "Bleu_4": 0.18486615215760333, "METEOR": 0.29142678915924647, "ROUGE_L": 0.43416370106761565, "CIDEr": 0.000711750865941906, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.3125, "f": 0.35714285714285715, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.5384615384615384, "f": 0.5599999999999999, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image features a man wearing a wetsuit, sitting on a surfboard in the ocean. The man is surrounded by water and waves, which are crashing around him. The man is surfing."}, "404984": {"image_id": 404984, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.1365577483976988, "Bleu_3": 0.09561469818904189, "Bleu_4": 0.0725798147571237, "METEOR": 0.20847674787926018, "ROUGE_L": 0.17888563049853376, "CIDEr": 2.0291834244141965e-19, "SPICE": {"All": {"pr": 0.3125, "re": 0.22727272727272727, "f": 0.2631578947368421, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of a living room with a large mirror on the wall. The mirror reflects the room's interior, including a couch, a chair, and a TV mounted on the wall. The living room also features a rug, on which a vase of flowers is placed. There is also a potted plant in the room, specifically baby's breath."}, "427965": {"image_id": 427965, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.24330354977564592, "Bleu_3": 0.16170481491531974, "Bleu_4": 0.1007734784396203, "METEOR": 0.30972129807680776, "ROUGE_L": 0.32620320855614976, "CIDEr": 1.1138859412105086e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2777777777777778, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a living room with wooden floors and furniture. The room is filled with various items, including a couch, a chair, and a television. A potted plant is placed in the corner of the room. \n\nThere are no books in the scene."}, "445834": {"image_id": 445834, "Bleu_1": 0.17910447760926712, "Bleu_2": 0.07367094686726784, "Bleu_3": 4.370787733819204e-07, "Bleu_4": 1.0687467158707182e-09, "METEOR": 0.15429140853826454, "ROUGE_L": 0.17985257985257982, "CIDEr": 3.706678974400375e-20, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a bus parked in a garage. The bus is white. There are four men in the scene. The men are police officers. Some of the men are talking to each other and focused on a skateboard, while others are boarding the bus and focused on it. The men are also riding on the bus. \n\nThere are no mechanics or maintenance workers in the scene."}, "386958": {"image_id": 386958, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.14907119849663567, "Bleu_3": 0.10110741541419836, "Bleu_4": 1.2524919232119623e-05, "METEOR": 0.22673543894036782, "ROUGE_L": 0.28754208754208754, "CIDEr": 4.41720804008196e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a fire hydrant sitting on a sidewalk next to a green pole. The fire hydrant is painted in red and white. A parked car is located to the left of the fire hydrant. \n\nThere is a hose next to the yellow pole."}, "306135": {"image_id": 306135, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.20121090914115633, "Bleu_3": 0.10304662546247204, "Bleu_4": 1.3203823351935061e-05, "METEOR": 0.1884508119394968, "ROUGE_L": 0.25363825363825365, "CIDEr": 2.0379713194099355e-05, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.0625, "f": 0.06557377049180328, "fn": 30.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.3333333333333333, "f": 0.125, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features a man riding a skateboard down a staircase in front of a building. The man is wearing a red shirt and appears to be enjoying his ride. The skateboarder is riding his skateboard on the steps."}, "335839": {"image_id": 335839, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.23094010767127685, "Bleu_3": 0.16328797870746478, "Bleu_4": 0.11605473102586131, "METEOR": 0.2271804182294323, "ROUGE_L": 0.2858816637375513, "CIDEr": 3.491861842857038e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.11538461538461539, "f": 0.13636363636363638, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a man standing in front of a brick building, which has graffiti on its side. The man is wearing a black and red jacket and carrying a backpack. He appears to be posing for a picture. The man is positioned on the sidewalk, with a wall behind him."}, "190313": {"image_id": 190313, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.1832114449629405, "Bleu_3": 0.14654089019545116, "Bleu_4": 0.11889099988798969, "METEOR": 0.32637577595007805, "ROUGE_L": 0.2981427174975562, "CIDEr": 1.1996704879340855e-17, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.35, "f": 0.3333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image is a black and white photograph of two women sitting on a bench outside a store. One woman is wearing a black jacket and the other woman is wearing a black coat. The store window showcases a woman sitting on a bench. The woman is waiting for someone. The store window displays various items for sale.\n\nThere are no other people in the scene."}, "85328": {"image_id": 85328, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.12499999999806191, "Bleu_3": 0.079159520964846, "Bleu_4": 0.05318380992999435, "METEOR": 0.16983810205238242, "ROUGE_L": 0.1913225300575013, "CIDEr": 2.8007514503721333e-19, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.2727272727272727, "f": 0.21052631578947367, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.3333333333333333, "f": 0.13333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image features a train stopped at a train station. The train is green and yellow. There are four people visible in the image. Some of the people are standing near a bus, while others are standing near a skateboard. The people are also standing further away from a skateboarder and a group of people. \n\nIn the background, there are no buildings or tracks visible."}, "104002": {"image_id": 104002, "Bleu_1": 0.2413793103365042, "Bleu_2": 0.16081688022002483, "Bleu_3": 0.09857493523971356, "Bleu_4": 1.3854202726840111e-05, "METEOR": 0.18049909216604582, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.0023463917593881905, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image depicts a large, grassy field covered with grass. There are nine cows grazing on the grass. Some cows are walking, while others are standing in the field."}, "37389": {"image_id": 37389, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.07205793047605258, "Bleu_4": 9.44575929237223e-06, "METEOR": 0.22071508745901175, "ROUGE_L": 0.23797139141742527, "CIDEr": 8.252442033784417e-11, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.28, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a clock tower standing tall in the middle of a city. The clock is prominently displayed on the tower, with the hands on the clock face indicating the time as 11:10. The tower is surrounded by a few buildings, giving it a prominent presence in the city."}, "383594": {"image_id": 383594, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.17856107630055562, "Bleu_3": 0.08982012142922804, "Bleu_4": 1.1393656301695435e-05, "METEOR": 0.2086882985755734, "ROUGE_L": 0.33557457212713937, "CIDEr": 1.8435411177696844e-07, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.22727272727272727, "f": 0.16949152542372883, "fn": 17.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.14285714285714285, "f": 0.09523809523809523, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a plate of food on a dining table. The plate contains a sandwich and a side of pickles. The sandwich is placed in the center of the plate, and the pickles are arranged around it. There are also two knives on the table."}, "319696": {"image_id": 319696, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.19234834502379758, "Bleu_3": 0.16392022466196415, "Bleu_4": 0.10180718782372411, "METEOR": 0.27781347766854564, "ROUGE_L": 0.3076368876080692, "CIDEr": 2.510101143369607e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a red microwave sitting on a countertop in the kitchen. The microwave is positioned on the counter. A small refrigerator is in addition to the microwave. A red refrigerator is also sitting on the countertop. Bottles are scattered around the kitchen."}, "318911": {"image_id": 318911, "Bleu_1": 0.20833333333043982, "Bleu_2": 0.16250677125426688, "Bleu_3": 0.12355821603378, "Bleu_4": 0.08599019783976515, "METEOR": 0.2275835504003317, "ROUGE_L": 0.22975517890772126, "CIDEr": 1.607594575821169e-23, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2777777777777778, "f": 0.24390243902439024, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a large herd of twelve sheep gathered together in a field. The sheep are of various sizes and are spread out throughout the field, creating a sense of depth in the scene. Some sheep are standing behind a fence, while others are eating grass or looking at each other. Some sheep are laying down, and others are standing in a pen. They are huddled together, creating a cozy atmosphere."}, "455506": {"image_id": 455506, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.31594579736817135, "Bleu_3": 0.2107328047161774, "Bleu_4": 0.13181313433089503, "METEOR": 0.34931999904780614, "ROUGE_L": 0.4033057851239669, "CIDEr": 0.00038517953832154905, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16666666666666666, "f": 0.19512195121951217, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a brown dog running through a grassy field, holding a green Frisbee in its mouth. The dog is focused on catching the Frisbee and appears to be enjoying the outdoor activity."}, "444631": {"image_id": 444631, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.16307248659580162, "Bleu_3": 0.11185856975273968, "Bleu_4": 0.07070578360988265, "METEOR": 0.29487264059680746, "ROUGE_L": 0.3051695386325736, "CIDEr": 5.641637870266148e-16, "SPICE": {"All": {"pr": 0.1875, "re": 0.10344827586206896, "f": 0.13333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features two people walking on a beach. One person is carrying a surfboard under their arm. The surfboard is red and white. The other person is walking on the street and carrying a bag of groceries. \n\nIn the background, there are no other notable objects or elements. The overall scene depicts a person walking on the beach."}, "497014": {"image_id": 497014, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.32995600878756753, "Bleu_3": 0.2439403297990835, "Bleu_4": 2.6598871139738462e-05, "METEOR": 0.2886382858682949, "ROUGE_L": 0.38125000000000003, "CIDEr": 0.004867210593492105, "SPICE": {"All": {"pr": 0.125, "re": 0.19047619047619047, "f": 0.1509433962264151, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image features a dog standing on its hind legs in a grassy yard. The dog is brown and is catching a blue Frisbee. The dog has a frisbee in its mouth."}, "502749": {"image_id": 502749, "Bleu_1": 0.30769230768047345, "Bleu_2": 0.248069469168685, "Bleu_3": 0.17244679591531836, "Bleu_4": 0.12219667480978094, "METEOR": 0.17221067065485823, "ROUGE_L": 0.2601279317697228, "CIDEr": 0.009637788572904878, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a kitchen with a granite counter top. The kitchen has a large window and two ovens. The oven is positioned on the wall."}, "230593": {"image_id": 230593, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.2474358296476976, "Bleu_3": 0.1854462179194681, "Bleu_4": 0.12835019116177698, "METEOR": 0.288469702497796, "ROUGE_L": 0.30310559006211185, "CIDEr": 2.086631043798899e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a large flock of birds walking on a paved path in a park. The birds are white and gray. Some birds are walking closer to the camera and others are further away. The birds are spread out along the path, creating a sense of movement and activity."}, "364636": {"image_id": 364636, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.23204774044025303, "Bleu_3": 0.14151431132866968, "Bleu_4": 1.6636035584894695e-05, "METEOR": 0.21223365694124668, "ROUGE_L": 0.30070422535211266, "CIDEr": 1.2915240306141857e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.2, "f": 0.24390243902439027, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a dog walking on a dirt field. The dog is brown. The dog is wearing a red collar. The dog is panting, possibly due to the warm weather or exertion.\n\nIn the background, there is a bench."}, "288313": {"image_id": 288313, "Bleu_1": 0.32727272726677686, "Bleu_2": 0.19069251784561925, "Bleu_3": 0.11112381532950553, "Bleu_4": 0.0716728249212735, "METEOR": 0.22484772040551293, "ROUGE_L": 0.2852133255406195, "CIDEr": 5.937334849217317e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.09523809523809523, "f": 0.125, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a dining table with a plate of food arranged on it. One of the plates is placed on the table. The plate contains a variety of food items, including ham, cheese, and pickles. There are also two bowls in the scene. One is a white bowl and the other contains a spoon."}, "384503": {"image_id": 384503, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.16001422411453173, "Bleu_3": 0.0892630166489473, "Bleu_4": 1.193951426417031e-05, "METEOR": 0.2171225736465116, "ROUGE_L": 0.295638126009693, "CIDEr": 7.818566739141074e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.21052631578947367, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks. The train is green. A green trolley is passing by the village. There is a small stone building visible in the background.\n\nThere are no people in the scene."}, "190156": {"image_id": 190156, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.1923131632828435, "Bleu_3": 1.0090325449929141e-06, "Bleu_4": 2.32761887046409e-09, "METEOR": 0.2777966006898701, "ROUGE_L": 0.2517193947730399, "CIDEr": 0.00013515594430678395, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.09523809523809523, "f": 0.11764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a cat sitting on a desk, enjoying a cup of coffee. The cat is positioned near the laptop, which is not open and placed on the desk. There are some books scattered around the desk."}, "174123": {"image_id": 174123, "Bleu_1": 0.39655172413109396, "Bleu_2": 0.3007351347805405, "Bleu_3": 0.22443613649132313, "Bleu_4": 0.1575829510815973, "METEOR": 0.2499639296926556, "ROUGE_L": 0.27890672627514734, "CIDEr": 1.880067159256942e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.10344827586206896, "f": 0.11320754716981132, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two people holding a fork and a knife over a delicious pizza on a white plate. The pizza is generously topped with cheese and vegetables. One person is cutting a mushroom, while the other person is cutting a mushroom. The person is in the process of cutting the pizza into slices, ready to be enjoyed."}, "557239": {"image_id": 557239, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.4082482904448645, "Bleu_3": 0.29240177380734167, "Bleu_4": 0.19045685207403573, "METEOR": 0.37418173873560834, "ROUGE_L": 0.38985939497230504, "CIDEr": 0.22328511967357706, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a cat lying down in a toilet bowl. The cat is orange and white. The toilet bowl is white."}, "184474": {"image_id": 184474, "Bleu_1": 0.33333333331481485, "Bleu_2": 0.14002800839479293, "Bleu_3": 1.070130183555234e-06, "Bleu_4": 3.006454568869563e-09, "METEOR": 0.16755458675287296, "ROUGE_L": 0.3306233062330623, "CIDEr": 0.12217972726713461, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.1724137931034483, "f": 0.17543859649122806, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features a bench sitting in the middle of a hillside. The bench is positioned on grass."}, "335099": {"image_id": 335099, "Bleu_1": 0.22535211267288235, "Bleu_2": 0.12687229593731056, "Bleu_3": 6.155946486078353e-07, "Bleu_4": 1.360955417445814e-09, "METEOR": 0.12605195063057795, "ROUGE_L": 0.16999535531816068, "CIDEr": 6.575780150437169e-19, "SPICE": {"All": {"pr": 0.3, "re": 0.3157894736842105, "f": 0.3076923076923077, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features two dogs standing inside a fenced area. One dog is looking at itself in the mirror and looking out through a window. The other dog is looking through the window and appears to be curious about it. The location of the dog on the left side of the image is behind a fence, while the location of the dog on the right side is also behind the fence."}, "431306": {"image_id": 431306, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.23278142562159646, "Bleu_3": 0.1261375218310181, "Bleu_4": 1.666824532264052e-05, "METEOR": 0.2664888375346488, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.00518278280899702, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.23529411764705882, "f": 0.22857142857142856, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a large bathroom with eight sinks placed side by side under two mirrors. The mirror reflects a person taking a picture. The bathroom is not clean."}, "125815": {"image_id": 125815, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.21103178185560523, "Bleu_3": 0.13402155970338947, "Bleu_4": 1.6080715766744762e-05, "METEOR": 0.19375945038159953, "ROUGE_L": 0.3098244086489624, "CIDEr": 8.035106643835882e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.125, "f": 0.14634146341463414, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a train station with a train on the tracks, pulling into the station. The train is positioned towards the left side of the scene. The station has a platform, where people are waiting for the train."}, "521106": {"image_id": 521106, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.13199091933393275, "Bleu_3": 7.580119263366549e-07, "Bleu_4": 1.828061815856166e-09, "METEOR": 0.20704501636413794, "ROUGE_L": 0.2279521674140508, "CIDEr": 1.0863720042484249e-05, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.05263157894736842, "f": 0.06060606060606061, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image captures a tennis match in progress, with two men playing on the court. The men are wearing black shirts and black shorts. They are actively engaged in the game, swinging their tennis rackets. The tennis ball is on the court."}, "508672": {"image_id": 508672, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.2724821653207854, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.00607398134002326, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.3157894736842105, "f": 0.36363636363636365, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8, "f": 0.7272727272727272, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a bicycle leaning against a fence in a flooded park. The bicycle is affected by the floodwaters. The water level is rising up to the ground."}, "221737": {"image_id": 221737, "Bleu_1": 0.14999999999625002, "Bleu_2": 0.0877058019284822, "Bleu_3": 5.871616519579069e-07, "Bleu_4": 1.5293885404483757e-09, "METEOR": 0.2007798890386352, "ROUGE_L": 0.18944099378881987, "CIDEr": 4.400752141309028e-06, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.34782608695652173, "f": 0.3555555555555555, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features two roads with a traffic light positioned on the side. The traffic light is red. There is no car on the left side of the road. There is no car on the right side of the road."}, "345580": {"image_id": 345580, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.23186944787247984, "Bleu_3": 0.15477697383157918, "Bleu_4": 0.10727295782423153, "METEOR": 0.2578136925760215, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.002221979226181767, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.17647058823529413, "f": 0.1935483870967742, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a zebra standing in a grassy area, surrounded by a fence. The zebra is looking at a tree. The grassy area provides a natural habitat for the zebra."}, "46440": {"image_id": 46440, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.13430879685706595, "Bleu_3": 0.07373360496991944, "Bleu_4": 9.769805815563084e-06, "METEOR": 0.2174798500206875, "ROUGE_L": 0.24416277518345564, "CIDEr": 8.468461575617035e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2, "f": 0.21428571428571427, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image captures a basketball game in progress, with several players on the court. One player is in the process of shooting a basketball, while others are trying to block the shot. There are at least five players visible in the scene, actively participating in the game."}, "270066": {"image_id": 270066, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.32816506164407266, "Bleu_3": 0.2618250193558744, "Bleu_4": 0.19876224716299587, "METEOR": 0.2857199907587987, "ROUGE_L": 0.43839835728952764, "CIDEr": 0.02772697887479187, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23529411764705882, "f": 0.2580645161290323, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a white motorcycle parked on a wet street, with its kickstand not down. The motorcycle is positioned in front of a green truck."}, "419867": {"image_id": 419867, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.16163173752903065, "Bleu_3": 0.100810174751238, "Bleu_4": 1.1964258135320571e-05, "METEOR": 0.23657858401073256, "ROUGE_L": 0.25707405177603854, "CIDEr": 3.473488211099265e-12, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.34782608695652173, "f": 0.34782608695652173, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a grocery store with a large display of bananas. The bananas are arranged in various bunches, including two bunches in the foreground. There are also multiple individual bananas scattered throughout the display. The grocery store is quite spacious, with the bananas taking up a significant portion of the produce area."}, "194724": {"image_id": 194724, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.20659846763023243, "Bleu_3": 0.12983940805705807, "Bleu_4": 1.5492053781230032e-05, "METEOR": 0.18003202873078053, "ROUGE_L": 0.29306794783802337, "CIDEr": 6.366550858480327e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a dining table with a delicious pizza placed on a plate. A pizza and a newspaper is on the dining table. \n\nThere are two plates on the table. \n\nThere are no utensils, forks, or knives in the scene."}, "236426": {"image_id": 236426, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.24866794885861784, "Bleu_3": 0.14112555009560282, "Bleu_4": 1.5989582418932847e-05, "METEOR": 0.2443205307393732, "ROUGE_L": 0.2969401947148818, "CIDEr": 6.257466709472056e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a tennis match in progress, with two men playing on a tennis court. The first man is preparing to play tennis, wearing a white shirt and white shorts. The second man is actively playing tennis. \n\nThe tennis ball is located on the court."}, "499826": {"image_id": 499826, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.1996674976872179, "Bleu_3": 0.12482080040049898, "Bleu_4": 1.4849103163693374e-05, "METEOR": 0.23732328341130698, "ROUGE_L": 0.2576376179079263, "CIDEr": 2.572780292162355e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features four elephants walking down a street. One elephant is in the foreground. The elephants are walking down the street. \n\nA woman is standing next to the elephants, waving to one of them. \n\nThere are no other people in the scene."}, "514904": {"image_id": 514904, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.27275654944002714, "Bleu_3": 0.22789348666671772, "Bleu_4": 0.19260800011599663, "METEOR": 0.3780148506979148, "ROUGE_L": 0.4039735099337748, "CIDEr": 1.7493214515625307e-08, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.10526315789473684, "f": 0.1111111111111111, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a woman wearing sunglasses, standing on a street. She is holding two hot dogs in her hands, which are placed in buns. The woman is smiling and appears to be enjoying her meal.\n\nIn the background, there are no other objects or people."}, "359864": {"image_id": 359864, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.2925089696421188, "Bleu_3": 0.23733737465153115, "Bleu_4": 0.17137271453123876, "METEOR": 0.369189585972771, "ROUGE_L": 0.3999063451182393, "CIDEr": 0.0009200601492120671, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.42857142857142855, "f": 0.4799999999999999, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.75, "re": 0.75, "f": 0.75, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features a man wearing a red jacket and a red baseball cap, sitting in a boat on the water. The man is driving the boat and appears to be enjoying the ride."}, "247333": {"image_id": 247333, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2209045015297887, "Bleu_3": 0.14075279502574425, "Bleu_4": 0.09516407739184628, "METEOR": 0.2516041297230792, "ROUGE_L": 0.37280366692131406, "CIDEr": 7.103071862319494e-05, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2608695652173913, "f": 0.3243243243243243, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features two dining tables, one of which has a plate of food placed on it. The plate is filled with a salad, sliced carrots, and meat. \n\nThere are no pieces of broccoli in the scene."}, "54277": {"image_id": 54277, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.37139067634106854, "Bleu_3": 0.24839327180107798, "Bleu_4": 0.15581581441734033, "METEOR": 0.3104592339307148, "ROUGE_L": 0.40705433746425174, "CIDEr": 0.01217635683423331, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11764705882352941, "f": 0.12903225806451615, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image features a man wearing a blue jacket riding a snowboard on a snow-covered slope in a ski resort. The man is enjoying his time on the snowboard."}, "80172": {"image_id": 80172, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2804086879058332, "Bleu_3": 0.19885093779863972, "Bleu_4": 0.12832055613202045, "METEOR": 0.24333367311616622, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.002269274012491721, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.10344827586206896, "f": 0.1395348837209302, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a boy brushing his teeth in a bathroom. He is holding two toothbrushes in his mouth, actively brushing his teeth. The boy is standing in front of a toilet."}, "376959": {"image_id": 376959, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2094269541404072, "Bleu_3": 0.1333412355009628, "Bleu_4": 0.09008401431897775, "METEOR": 0.21956029288872578, "ROUGE_L": 0.29889402211955757, "CIDEr": 3.775321483353715e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.2413793103448276, "f": 0.24561403508771928, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a girl sitting at a dining table. The girl is holding a knife in her hand. She appears to be having fun with a cell phone. The table is set with a fork and a cup."}, "47055": {"image_id": 47055, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 0.14146439860260482, "Bleu_4": 0.09230372260622217, "METEOR": 0.2011240682199265, "ROUGE_L": 0.27354260089686094, "CIDEr": 4.974592093985618e-06, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.06666666666666667, "f": 0.0784313725490196, "fn": 28.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a bedroom with a large bed placed in the center of the room. The bed has a black and grey color scheme. The bedroom is surrounded by a wooden floor. The room is dimly lit, creating a cozy atmosphere."}, "154816": {"image_id": 154816, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.11527808353813424, "Bleu_3": 6.869153367854085e-07, "Bleu_4": 1.6871838589262224e-09, "METEOR": 0.19338396166274735, "ROUGE_L": 0.24286662242866625, "CIDEr": 4.6261459405910043e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.23809523809523808, "f": 0.20833333333333334, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress, with two boys swinging baseball bats at pitches. The boys are wearing baseball uniforms. The catcher is catching the ball. The boy is positioned behind home plate. \n\nThere are no other people in the scene."}, "155179": {"image_id": 155179, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.286972021583456, "Bleu_3": 0.13564019062788146, "Bleu_4": 1.6711052323228432e-05, "METEOR": 0.2439719499826707, "ROUGE_L": 0.3733741392501913, "CIDEr": 0.00020329384339786907, "SPICE": {"All": {"pr": 0.15, "re": 0.07692307692307693, "f": 0.1016949152542373, "fn": 36.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.1875, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a cake sitting on top of a plate, which is placed on a dining table. The cake appears to be a bread type of cake, with chocolate chips visible throughout its surface."}, "328374": {"image_id": 328374, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.126168012373563, "Bleu_3": 0.06921800773739777, "Bleu_4": 9.165155901802696e-06, "METEOR": 0.11747921902400614, "ROUGE_L": 0.18944099378881987, "CIDEr": 2.1446757725517993e-09, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features four children wearing red jackets and sitting on a snowy surface. The children are wearing skis. The red jackets add a pop of color to the scene.\n\nThe children are spread out across the snowy surface, with some sitting closer to the foreground and others further back."}, "264919": {"image_id": 264919, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.28767798088147595, "Bleu_3": 0.18081247989280658, "Bleu_4": 2.1631187458455554e-05, "METEOR": 0.23768549346889736, "ROUGE_L": 0.3523102310231023, "CIDEr": 0.01695123040148259, "SPICE": {"All": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man standing in a festive atmosphere. The man is surrounded by balloons. He is talking on a cell phone. The man is wearing a blue shirt."}, "48185": {"image_id": 48185, "Bleu_1": 0.2916666666545139, "Bleu_2": 0.19504737439306988, "Bleu_3": 0.15122694443758203, "Bleu_4": 0.1132836045389627, "METEOR": 0.24921087290602761, "ROUGE_L": 0.4137596899224806, "CIDEr": 0.05874406798579378, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bathroom with a mirror on the wall. The mirror reflects the entire bathroom. Under the mirror is the sink located."}, "43376": {"image_id": 43376, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.25440640194528097, "Bleu_3": 0.17537120059764763, "Bleu_4": 0.11141706023091318, "METEOR": 0.1985490013826504, "ROUGE_L": 0.34590303373972214, "CIDEr": 3.146246438233207e-05, "SPICE": {"All": {"pr": 0.4, "re": 0.27586206896551724, "f": 0.32653061224489793, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a giraffe standing in a zoo enclosure. The giraffe is stretching out its neck over a metal fence, possibly reaching for a branch. The enclosure is surrounded by trees, which provide food for the giraffes."}, "204994": {"image_id": 204994, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.17472060423831776, "Bleu_3": 0.11070534149073814, "Bleu_4": 1.3251445746049818e-05, "METEOR": 0.22431519247500156, "ROUGE_L": 0.29186602870813394, "CIDEr": 4.356545968603307e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.12, "f": 0.16216216216216217, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a man standing next to a wooden bench, feeding a giraffe. The giraffe is positioned in front of the man. The man is holding a bottle, likely a juice bottle, in his hand. The man appears to be enjoying the interaction with the giraffe."}, "309264": {"image_id": 309264, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.22228757208608238, "Bleu_3": 0.1591835156119781, "Bleu_4": 0.12600668125185685, "METEOR": 0.264552272226207, "ROUGE_L": 0.34997131382673546, "CIDEr": 7.736480685643043e-10, "SPICE": {"All": {"pr": 0.2, "re": 0.13636363636363635, "f": 0.16216216216216214, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a room with a cage of birds. There are four birds in the cages. The cages are arranged in various sizes and are stacked on top of each other, occupying most of the room. Some cages are placed closer to the front, while others are positioned further back."}, "356028": {"image_id": 356028, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.3710145844238421, "Bleu_3": 0.296409937569477, "Bleu_4": 0.23193107586099126, "METEOR": 0.3796313991725149, "ROUGE_L": 0.5072765072765073, "CIDEr": 4.696443041716749e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of a dormitory room with several beds arranged in rows. Some beds are placed closer to the walls and others in the middle of the room. The beds are neatly made."}, "544794": {"image_id": 544794, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.43033148289628165, "Bleu_3": 0.3290038389458988, "Bleu_4": 0.25567957493925636, "METEOR": 0.3359059283799912, "ROUGE_L": 0.4559530165509877, "CIDEr": 0.054307459053041345, "SPICE": {"All": {"pr": 0.35, "re": 0.28, "f": 0.3111111111111111, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a table with a plate of pizza on it. A slice of pizza is on the plate. The table is set with a white tablecloth."}, "264619": {"image_id": 264619, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1543033499589101, "Bleu_3": 7.971700074705258e-07, "Bleu_4": 1.8216869827152143e-09, "METEOR": 0.16110124675062637, "ROUGE_L": 0.23091482649842268, "CIDEr": 6.998205927205364e-08, "SPICE": {"All": {"pr": 0.08, "re": 0.08333333333333333, "f": 0.08163265306122448, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image captures a beautiful day at the beach, with several people enjoying various water activities. There are three kites flying high in the sky, with one kite being particularly large and colorful. A person is seen kiteboarding in the ocean, skillfully maneuvering the kite while riding the waves."}, "322222": {"image_id": 322222, "Bleu_1": 0.18103448275706005, "Bleu_2": 0.16358978938167684, "Bleu_3": 0.12337651749118402, "Bleu_4": 0.07592980221088419, "METEOR": 0.21580059029495485, "ROUGE_L": 0.21569287758881964, "CIDEr": 4.114241957757663e-64, "SPICE": {"All": {"pr": 0.28, "re": 0.25, "f": 0.2641509433962264, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.6363636363636364, "f": 0.6363636363636364, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image features a tennis court with two men playing a game of tennis. One man is positioned on the left side of the court, holding a tennis racket and preparing to hit the ball. The other man is on the right side of the court, also holding a tennis racket and ready to return the ball.\n\nThe men are playing tennis. The man is holding a tennis racket. He is preparing to hit the ball with his racket. He is ready to hit a tennis ball. The man is holding a tennis racket. He is preparing to hit the ball. He is ready to hit the ball.\n\nThe men are located on a tennis court."}, "359791": {"image_id": 359791, "Bleu_1": 0.14285714285557302, "Bleu_2": 0.0796819072880791, "Bleu_3": 0.04147405300779158, "Bleu_4": 5.33594925484446e-06, "METEOR": 0.10010972185856823, "ROUGE_L": 0.15365239294710328, "CIDEr": 1.0073505107256814e-36, "SPICE": {"All": {"pr": 0.3125, "re": 0.22727272727272727, "f": 0.2631578947368421, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.7142857142857143, "f": 0.7142857142857143, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a large group of 14 orange plastic chairs arranged on a wooden deck. The chairs are orange and made of plastic. \n\nThe deck overlooks a body of water, which appears to be a lake. \n\nThere are three people in the scene. One person is talking on a cell phone, another person is taking a picture, and the third person is also taking a picture. \n\nOverall, the scene depicts a group of chairs on a deck overlooking a lake, with people enjoying the view and engaging in different activities."}, "404635": {"image_id": 404635, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.2994247357980183, "Bleu_3": 0.233969422624909, "Bleu_4": 0.17550354183219571, "METEOR": 0.2693136411358764, "ROUGE_L": 0.4790575916230366, "CIDEr": 0.027684781524166556, "SPICE": {"All": {"pr": 0.25, "re": 0.10344827586206896, "f": 0.14634146341463414, "fn": 26.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a herd of eight elephants standing together in a lush green field. The elephants are spread out across the field, creating a sense of depth and movement."}, "364343": {"image_id": 364343, "Bleu_1": 0.16176470587997407, "Bleu_2": 0.09827306030011396, "Bleu_3": 0.06639239576163196, "Bleu_4": 8.191443048308048e-06, "METEOR": 0.17738395937168586, "ROUGE_L": 0.20728155339805826, "CIDEr": 4.474122487622195e-21, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.24, "f": 0.2553191489361702, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a plate of fruit, including bananas, strawberries, and kiwi. The fruit is arranged in a visually appealing manner.\n\nThe plate is filled with strawberries, bananas, and kiwi. The strawberries are piled high on top of each other, with some placed on the side of the plate. The bananas are placed next to the strawberries, and the kiwi is placed towards the center of the plate."}, "1573": {"image_id": 1573, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.3234156785660397, "Bleu_3": 1.5516295292050031e-06, "Bleu_4": 3.4296522428995585e-09, "METEOR": 0.19550776941398837, "ROUGE_L": 0.34078212290502796, "CIDEr": 0.0035156890692567763, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a kitchen with a stove and a sink. There is a pot on top of the stove. On the countertop, there are cups and bottles scattered around."}, "174898": {"image_id": 174898, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.11688708163230677, "Bleu_4": 0.07999424336103482, "METEOR": 0.26216278855727676, "ROUGE_L": 0.3028368794326241, "CIDEr": 2.0167161705377055e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.08823529411764706, "f": 0.11320754716981131, "fn": 31.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a motorcycle parked on a street. The back tire of the motorcycle is not lifted off the ground. The motorcycle is positioned in the middle of the scene, surrounded by trees and grass. There is no parked car nearby."}, "527580": {"image_id": 527580, "Bleu_1": 0.20512820512557528, "Bleu_2": 0.11541236207473429, "Bleu_3": 5.596248903229258e-07, "Bleu_4": 1.2363956000053837e-09, "METEOR": 0.20198121727590046, "ROUGE_L": 0.21428571428571427, "CIDEr": 1.895874142448635e-24, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a train traveling down the tracks near a beach resort. The train is positioned in the middle of the scene. \n\nThere are at least 11 people visible in the scene. Some of the people are sitting on a bench, some are sitting on a wooden bench, and some are sitting on a chair. \n\nThere are 3 chairs nearby the people. There are also 5 umbrellas in the scene. \n\nThere is a beach near the train."}, "522020": {"image_id": 522020, "Bleu_1": 0.1551724137904281, "Bleu_2": 0.09037128496774492, "Bleu_3": 0.06631843888671014, "Bleu_4": 0.04798826500801556, "METEOR": 0.19603124874934044, "ROUGE_L": 0.20631341600901915, "CIDEr": 4.878940190769061e-15, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1111111111111111, "f": 0.14634146341463417, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a cat sitting in the grass. The cat is white and its fur covers most of its body. The cat is looking at a bird. The cat is positioned in the center of the scene. The cat is sitting on the grass. The picture is for the cat. In the background, there is a building."}, "142890": {"image_id": 142890, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.21070705493664102, "Bleu_3": 0.14691857457136862, "Bleu_4": 1.6676755647077375e-05, "METEOR": 0.2746982081917527, "ROUGE_L": 0.3342465753424657, "CIDEr": 8.077001322386828e-07, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.21052631578947367, "f": 0.2222222222222222, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a cat sitting on a computer desk. The cat is positioned near a keyboard, which is placed on the desk. The desk does not have a mouse or a cell phone on it.\n\nIn the background, there is a computer monitor."}, "503238": {"image_id": 503238, "Bleu_1": 0.2295081967175491, "Bleu_2": 0.1636336037715597, "Bleu_3": 0.1219881532441201, "Bleu_4": 0.07479649448444835, "METEOR": 0.2430403179106913, "ROUGE_L": 0.19794483504597077, "CIDEr": 3.72691594388609e-15, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.07692307692307693, "f": 0.08163265306122448, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a bus driving down the street. The bus is orange and green. It is a large bus. Buildings are closer to the bus. \n\nThere are two sidewalks in the scene. A red bus is visible on each sidewalk.\n\nThere is one person visible in the scene, standing on the sidewalk.\n\nOverall, a bus is driving down the street."}, "522430": {"image_id": 522430, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.18257418583043256, "Bleu_3": 9.57263977034001e-07, "Bleu_4": 2.206598690632221e-09, "METEOR": 0.14948689298053955, "ROUGE_L": 0.18429003021148035, "CIDEr": 2.76572356667857e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features three cows looking at the camera. The cows' eyes are captured in the image, with the first cow's eyes and the second cow's eyes clearly visible. The cows' faces are surrounded by a blurry background."}, "155897": {"image_id": 155897, "Bleu_1": 0.08275862068908445, "Bleu_2": 0.04152273992658264, "Bleu_3": 0.02889051752324973, "Bleu_4": 3.6098936299368142e-06, "METEOR": 0.10446690433205309, "ROUGE_L": 0.09353437260414005, "CIDEr": 5.676532761833124e-112, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.18181818181818182, "f": 0.20512820512820512, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features nine people sitting on a bench. One person is holding a bottle of water and drinking from it. Another person is holding a sandwich and eating it. Two sandwiches are placed on a plastic wrapper. One person is holding a cell phone and bending down. Another person is holding a cell phone and eating a sandwich. One person is holding a stuffed animal and sitting among a row of people. One person is holding a cell phone and talking to someone. One person is holding a cell phone and taking a selfie. One person is holding a sandwich and eating it. One person is holding a cell phone and eating a sandwich.\n\nThe people are sitting on a bench. The shirt worn by the people is blue.\n\nThere is no other specific information about the background or other objects in the scene."}, "214494": {"image_id": 214494, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.20320258681677345, "Bleu_3": 0.1056647524928274, "Bleu_4": 1.3648278496637608e-05, "METEOR": 0.2535323590733881, "ROUGE_L": 0.2848249027237354, "CIDEr": 1.1486489990924576e-05, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.15384615384615385, "f": 0.20512820512820515, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a chocolate cake sitting on a table, covered in a layer of chocolate icing. A person is using a spatula to spread the icing evenly over the cake. The person is creating a cake."}, "223093": {"image_id": 223093, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.0956600132176177, "Bleu_4": 1.248740514185277e-05, "METEOR": 0.2180784113547144, "ROUGE_L": 0.2771467514766015, "CIDEr": 6.618196147171161e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.24, "f": 0.23529411764705882, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a clock tower made of tall bricks. A clock is prominently displayed on the side of the tower. The tower stands tall against a blue sky. There are no other trees or greenery in the scene."}, "422706": {"image_id": 422706, "Bleu_1": 0.34782608694139894, "Bleu_2": 0.25147784537359036, "Bleu_3": 0.14440871014446285, "Bleu_4": 1.969869893685874e-05, "METEOR": 0.19059138634307252, "ROUGE_L": 0.2975609756097561, "CIDEr": 0.11374444544557866, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two people standing on a boat, looking out over the ocean. The people are taking pictures and enjoying the view."}, "4011": {"image_id": 4011, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.14819171472405493, "Bleu_3": 0.07652745233046604, "Bleu_4": 9.829979956142771e-06, "METEOR": 0.2227674360687443, "ROUGE_L": 0.29415310427968655, "CIDEr": 4.274814031302311e-09, "SPICE": {"All": {"pr": 0.04081632653061224, "re": 0.09523809523809523, "f": 0.05714285714285714, "fn": 19.0, "numImages": 1.0, "fp": 47.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 18.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.11764705882352941, "re": 0.2222222222222222, "f": 0.15384615384615383, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}}, "caption": "The image features a woman standing in a kitchen. She is wearing glasses and a white shirt. The woman is holding two dog figurines, which are white. She appears to be proudly displaying the figurines, possibly for a special occasion or event.\n\nThere is no cake or sculpture in the scene."}, "188824": {"image_id": 188824, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.395284707508882, "Bleu_3": 0.31155629277736774, "Bleu_4": 0.2345051558697836, "METEOR": 0.3639792490739618, "ROUGE_L": 0.4463414634146341, "CIDEr": 0.00436982037502192, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a cat sitting on a couch. The cat has a curious expression and occupies a significant portion of the couch. There is also a remote control placed on the couch."}, "247206": {"image_id": 247206, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.23260756692519305, "Bleu_3": 0.15451551194272495, "Bleu_4": 1.7114410710828824e-05, "METEOR": 0.30302092819667864, "ROUGE_L": 0.2827814569536423, "CIDEr": 2.794077323423551e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.35714285714285715, "f": 0.27027027027027023, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man lying on a couch, looking at a cat that is sitting on the floor. The cat is looking at a toy. The man is holding a toothbrush, which is placed on the floor. The couch is located in the living room."}, "430047": {"image_id": 430047, "Bleu_1": 0.3773584905589178, "Bleu_2": 0.28253466077593814, "Bleu_3": 0.21098010976942444, "Bleu_4": 0.13921823813830214, "METEOR": 0.2839544889054493, "ROUGE_L": 0.28355607205113303, "CIDEr": 3.1277376411647993e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.125, "f": 0.14634146341463414, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a black and white photograph. It shows a living room with a large flat-screen TV mounted on the wall. The TV is positioned towards the left side of the room. The living area is furnished with a couch and a coffee table. There are several books scattered around the room."}, "244240": {"image_id": 244240, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.09522194049088256, "Bleu_4": 1.1835581532782098e-05, "METEOR": 0.24279322338105697, "ROUGE_L": 0.2781758957654723, "CIDEr": 5.5431734471584764e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.12903225806451613, "f": 0.1702127659574468, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a toilet sitting in a small room. The toilet is surrounded by dirt and grass. It is in a dirty condition, with the seat up and a broken handle. The room is made of concrete. There is no debris or bench in the scene."}, "49810": {"image_id": 49810, "Bleu_1": 0.13513513513148287, "Bleu_2": 0.08664587414929846, "Bleu_3": 5.986080831486463e-07, "Bleu_4": 1.5848464939717994e-09, "METEOR": 0.10694096910947587, "ROUGE_L": 0.19535628502802244, "CIDEr": 1.0459379552691627e-05, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.0625, "f": 0.058823529411764705, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image features two cats sitting on a wooden deck. The cats are looking at their reflections in mirrors. The cats are curious about their reflections in the mirrors. The cats are also looking at each other."}, "85914": {"image_id": 85914, "Bleu_1": 0.423076923060651, "Bleu_2": 0.26017745422498945, "Bleu_3": 1.4128932794034898e-06, "Bleu_4": 3.327745160433554e-09, "METEOR": 0.2706052836853943, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.03350381465575476, "SPICE": {"All": {"pr": 0.25, "re": 0.21739130434782608, "f": 0.23255813953488372, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a plate filled with a delicious and colorful meal. The plate is topped with potatoes and broccoli. Some pieces of broccoli are closer."}, "442942": {"image_id": 442942, "Bleu_1": 0.2068965517170036, "Bleu_2": 0.1215661347666994, "Bleu_3": 0.08180009678677345, "Bleu_4": 1.2045422179029221e-05, "METEOR": 0.19209764959334244, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.003306049833036425, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.22857142857142856, "f": 0.24242424242424246, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6363636363636364, "re": 0.4666666666666667, "f": 0.5384615384615385, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image features two trains traveling down a track. There are eight people visible on the train. Some people are riding the train, while others are sitting on benches."}, "162543": {"image_id": 162543, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.14458880781007946, "Bleu_3": 8.055078690642645e-07, "Bleu_4": 1.9133137334560038e-09, "METEOR": 0.1934044906351023, "ROUGE_L": 0.2531120331950207, "CIDEr": 7.149517021475953e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2631578947368421, "f": 0.29411764705882354, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a group of five elephants standing behind a fence. The elephants are standing closer to the left side of the fence. A large elephant is standing on the right side of the fence. The field is made of grass."}, "157352": {"image_id": 157352, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.15357377920556234, "Bleu_3": 0.0974311856710336, "Bleu_4": 0.06558144622470677, "METEOR": 0.21638641272229142, "ROUGE_L": 0.29501684083254165, "CIDEr": 6.053816587715556e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image captures a group of four men enjoying a day at a skate park. Some of the men are doing skateboarding, with one man riding a skateboard. Others are sitting on a skateboard. The overall atmosphere of the scene is lively and exciting, as the young men are at a skate park."}, "262810": {"image_id": 262810, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.10219406022809462, "Bleu_4": 0.06730826637311355, "METEOR": 0.25917465065979556, "ROUGE_L": 0.24610951008645532, "CIDEr": 2.6904867105124934e-11, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.09523809523809523, "f": 0.1111111111111111, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures a wedding celebration with a bride and groom standing at a dining table, cutting their wedding cake. The bride and groom are surrounded by a group of six people. Some of the people are taking a picture, some are cutting the cake, some are drinking wine, and some are eating a pizza."}, "498807": {"image_id": 498807, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.20866567588950136, "Bleu_3": 0.15059039854381842, "Bleu_4": 0.09090870283563952, "METEOR": 0.2616126199457199, "ROUGE_L": 0.2959369314736203, "CIDEr": 3.83947056064309e-12, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a girl riding a surfboard on a wave in the ocean. The girl is surfing and skillfully balancing on the surfboard. She is showcasing her surfing skills. The girl is wearing a wetsuit, which is appropriate for the water temperature.\n\nThere are no other objects or people in the scene."}, "563605": {"image_id": 563605, "Bleu_1": 0.3913043478090738, "Bleu_2": 0.2667325346727717, "Bleu_3": 0.1501911109396443, "Bleu_4": 2.0287366423929855e-05, "METEOR": 0.22167417966246486, "ROUGE_L": 0.29242569511025884, "CIDEr": 0.13287063542847138, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image depicts two people standing outside on a rainy day. The people are holding an umbrella to shield themselves from the rain."}, "162503": {"image_id": 162503, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.23346806531979408, "Bleu_3": 0.21129929347819487, "Bleu_4": 0.1896948321827193, "METEOR": 0.2595197189861541, "ROUGE_L": 0.29151732377538825, "CIDEr": 3.861855784288473e-12, "SPICE": {"All": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a beautiful owl perched on a tree branch in a forest. The owl is positioned towards the center of the scene, with its wings spread wide, giving the impression of a majestic presence. The owl is perched on a branch. The forest provides a natural and serene backdrop for the owl."}, "62089": {"image_id": 62089, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.26967994497923586, "Bleu_3": 0.17183700724794354, "Bleu_4": 1.8643403650393198e-05, "METEOR": 0.2796695159508502, "ROUGE_L": 0.3176197117619712, "CIDEr": 2.4037691533951243e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.19230769230769232, "f": 0.2439024390243902, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.09090909090909091, "f": 0.16666666666666669, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a boy standing on a skateboard in a skate park. The boy is wearing a helmet and knee pads, indicating that he is learning skateboarding and practicing his skills. \n\nIn the background, a person can be seen, as well as a tree."}, "340737": {"image_id": 340737, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.13334123550086785, "Bleu_4": 1.6132673522067715e-05, "METEOR": 0.20618834331898941, "ROUGE_L": 0.2733791455034359, "CIDEr": 1.4204964288365003e-05, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3125, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a small bathroom with a bathtub and a sink. The bathtub is located in the bathroom. The sink is situated in the corner. The bathroom has a window. \n\nThere are three towels in the bathroom."}, "423744": {"image_id": 423744, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.22488822254677632, "Bleu_3": 0.1217844383284592, "Bleu_4": 1.608247581870839e-05, "METEOR": 0.1866581837510989, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.02031320142037736, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a laptop on the left side of the desk, and another laptop on the right side of the desk. The desktop computer is not in the image."}, "343903": {"image_id": 343903, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.27588029391667884, "Bleu_3": 0.17583464195898402, "Bleu_4": 0.10730806580090092, "METEOR": 0.28998495502198507, "ROUGE_L": 0.4236111111111111, "CIDEr": 0.0001061724718909475, "SPICE": {"All": {"pr": 0.1, "re": 0.05714285714285714, "f": 0.07272727272727272, "fn": 33.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.13333333333333333, "f": 0.1739130434782609, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a dining table with a plate of food placed on it. The plate contains a small English muffin. A glass of milk is also present on the table, positioned next to the plate. The table is set on a colorful tablecloth."}, "117786": {"image_id": 117786, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.18731716231147263, "Bleu_3": 0.09824666233063457, "Bleu_4": 1.2739803480291042e-05, "METEOR": 0.20950066419408403, "ROUGE_L": 0.32570556826849734, "CIDEr": 4.345316184601899e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a man standing in a courtyard, holding a kite string and preparing to fly the kite. The kite is soaring in the sky. The courtyard is surrounded by buildings, creating a picturesque setting for the kite."}, "3693": {"image_id": 3693, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.13453455879664997, "Bleu_3": 0.07126876576918603, "Bleu_4": 9.270974964697601e-06, "METEOR": 0.18625064531826646, "ROUGE_L": 0.22048192771084338, "CIDEr": 9.963359962080602e-11, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.3125, "f": 0.3333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.8333333333333334, "f": 0.7142857142857143, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a group of five people standing in a room, possibly a garage or a warehouse, with graffiti on the walls. \n\nThere are three people in the scene. One person is standing in the foreground, while the others are scattered around the room. The individuals are engaged in various activities."}, "187852": {"image_id": 187852, "Bleu_1": 0.37037037036351167, "Bleu_2": 0.2772531733803369, "Bleu_3": 0.16429473799793098, "Bleu_4": 1.717217068631794e-05, "METEOR": 0.23810737426216705, "ROUGE_L": 0.2839851024208566, "CIDEr": 7.439760682192675e-09, "SPICE": {"All": {"pr": 0.4, "re": 0.3, "f": 0.34285714285714286, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image captures a lively scene with six men standing in front of a crowd of people. The man is wearing a white hat and a black jacket. He is holding a cell phone and taking a picture. There are several other people in the scene, some of them standing close to the man."}, "414078": {"image_id": 414078, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.1923131632828435, "Bleu_3": 0.10090325449929138, "Bleu_4": 1.3089162801548402e-05, "METEOR": 0.24647462240604873, "ROUGE_L": 0.2733791455034359, "CIDEr": 5.937479303872973e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a cat lying on a bedspread that is blue in color. The cat is positioned on a bed. Its body is spread out and its head is slightly raised. The cat's eyes are open."}, "121716": {"image_id": 121716, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.14458880781007946, "Bleu_3": 0.08055078690642642, "Bleu_4": 1.075935380376544e-05, "METEOR": 0.14792558050031898, "ROUGE_L": 0.21631205673758863, "CIDEr": 3.3603261708323024e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.14705882352941177, "f": 0.17857142857142858, "fn": 29.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a thrilling moment of two skiers skiing down a slope. One skier is in the foreground, wearing a black jacket and tan pants, while the other skier is in the background, also wearing a black jacket and blue pants."}, "327794": {"image_id": 327794, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.14953924108841646, "Bleu_3": 0.07548065617692518, "Bleu_4": 9.582618669737836e-06, "METEOR": 0.17205759404548795, "ROUGE_L": 0.24710648148148148, "CIDEr": 6.190193916581752e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.13333333333333333, "f": 0.1739130434782609, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a large metal bowl filled with a variety of chopped vegetables, including carrots and tofu. The vegetables are scattered throughout the bowl, with some carrots placed closer to the top and others near the bottom. The tofu is also mixed in with the vegetables.\n\nCarrots and onions are in the bowl."}, "143370": {"image_id": 143370, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.19778287446532944, "Bleu_3": 0.14827412650292224, "Bleu_4": 0.11682600305257854, "METEOR": 0.3057085836942883, "ROUGE_L": 0.34491114701130854, "CIDEr": 0.0008369833286978013, "SPICE": {"All": {"pr": 0.3, "re": 0.07894736842105263, "f": 0.125, "fn": 35.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image depicts a bathroom with a white sink and toilet. The sink is located in the bathroom. The toilet is situated in the corner. The bathroom also features two windows, which allow natural light to come in."}, "354202": {"image_id": 354202, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.1348279544430054, "Bleu_4": 1.6508456672891575e-05, "METEOR": 0.2886240307875792, "ROUGE_L": 0.37654320987654316, "CIDEr": 8.546277831027389e-05, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.15384615384615385, "f": 0.21621621621621623, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a giraffe standing in a zoo enclosure, with its head and neck sticking over the top of a fence. The giraffe is looking at a rock. There are other giraffes in the enclosure."}, "189193": {"image_id": 189193, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.22068370737221082, "Bleu_3": 0.16521098823756497, "Bleu_4": 0.12639809921483802, "METEOR": 0.30720283382922847, "ROUGE_L": 0.25296208530805686, "CIDEr": 1.3858890244420197e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.15789473684210525, "f": 0.17647058823529413, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a person riding a skateboard down a street. The person is wearing a hat on their head and a backpack on their back. The person is a woman on a skateboarder. The skateboard is positioned under the person's feet.\n\nThe scene appears to be in a street, rather than a parking lot."}, "561967": {"image_id": 561967, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.21046802246600352, "Bleu_3": 0.10261152169176807, "Bleu_4": 1.2819825042675062e-05, "METEOR": 0.2801793940545109, "ROUGE_L": 0.26852531181217903, "CIDEr": 1.7423591842763104e-07, "SPICE": {"All": {"pr": 0.3125, "re": 0.2631578947368421, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a train traveling down the tracks in a rural area. The train is a long green and yellow engine pulling a red train car behind it. The train is moving at a moderate speed. The tracks are surrounded by trees."}, "404071": {"image_id": 404071, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.10174919922777484, "Bleu_4": 1.2738938828213386e-05, "METEOR": 0.2714172187192042, "ROUGE_L": 0.2888648356108781, "CIDEr": 4.470712657804698e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a train traveling on the tracks. The train is blue and yellow. It is positioned in the middle of the scene, surrounded by a forest. A bridge is visible in the background.\n\nThere are no people scattered along the tracks."}, "251572": {"image_id": 251572, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.24019223070154896, "Bleu_3": 0.1448065155642414, "Bleu_4": 1.6925466459110813e-05, "METEOR": 0.26868191838240324, "ROUGE_L": 0.34574898785425096, "CIDEr": 1.0470041878047664e-05, "SPICE": {"All": {"pr": 0.0625, "re": 0.05, "f": 0.05555555555555556, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a woman and a dog lying together on a couch. The woman is holding a puppy. The puppy is brown and white. They appear to be enjoying each other's company, creating a warm and affectionate scene."}, "436791": {"image_id": 436791, "Bleu_1": 0.387755102032903, "Bleu_2": 0.34809979802171354, "Bleu_3": 0.28522268553333835, "Bleu_4": 0.21194032132060303, "METEOR": 0.34073914404343664, "ROUGE_L": 0.43236857649143534, "CIDEr": 1.0269022367921631e-08, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a man with a bald head, wearing a blue shirt and a backpack, talking on a cell phone. The man is holding the phone to his ear, engaged in a conversation. The man appears to be smiling, possibly enjoying the conversation or having a pleasant interaction."}, "319257": {"image_id": 319257, "Bleu_1": 0.333333333325926, "Bleu_2": 0.17407765595178554, "Bleu_3": 0.0889895891077732, "Bleu_4": 1.1381305436598616e-05, "METEOR": 0.19505510786181215, "ROUGE_L": 0.28073635765943455, "CIDEr": 3.31743858332999e-08, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.24, "f": 0.28571428571428564, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a kangaroo laying down and looking out of a window. The kangaroo is not standing on its hind legs. The kangaroo is looking at a cactus. The eyes body part of the kangaroo is positioned in a way to see the surroundings."}, "279437": {"image_id": 279437, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2829297811792259, "Bleu_3": 0.180998309910211, "Bleu_4": 2.185307482215997e-05, "METEOR": 0.2439842979105945, "ROUGE_L": 0.3597304128053918, "CIDEr": 0.013044864972261778, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.1, "f": 0.10256410256410256, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a bedroom with a bed situated in the center of the room. The bed is covered with a quilt. A vase is placed near the bed."}, "175718": {"image_id": 175718, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.19908326484038252, "Bleu_3": 0.1450024650801868, "Bleu_4": 0.1125493882604948, "METEOR": 0.2320662094483702, "ROUGE_L": 0.3083032490974729, "CIDEr": 3.6945382554260604e-06, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.3076923076923077, "f": 0.3018867924528302, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a pizza sitting on a cutting board placed on a kitchen counter. The pizza is generously topped with cheese, olives, and chicken, making it look mouth-watering. \n\nIn addition to the pizza, there are no bottles in the scene."}, "126671": {"image_id": 126671, "Bleu_1": 0.333333333325926, "Bleu_2": 0.21320071635081886, "Bleu_3": 0.1617048149154053, "Bleu_4": 0.13182877145591065, "METEOR": 0.27168396070944933, "ROUGE_L": 0.3696969696969697, "CIDEr": 2.2746546941573202e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a small bathroom with a toilet and a shower stall. The shower stall has a red and white curtain, adding a pop of color to the space. The toilet is located in the bathroom. The shower stall is situated in the corner."}, "281424": {"image_id": 281424, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.08451542547047053, "Bleu_3": 5.944714686925451e-07, "Bleu_4": 1.5884362032477789e-09, "METEOR": 0.19795749397969017, "ROUGE_L": 0.24918300653594777, "CIDEr": 6.602586040639094e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a cat lying down on a suitcase. The cat is comfortably resting its head on the luggage. The cat appears to be sleeping or relaxing, taking up a significant portion of the suitcase."}, "136": {"image_id": 136, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2067245576408771, "Bleu_3": 1.1956793017371355e-06, "Bleu_4": 2.905080846557291e-09, "METEOR": 0.2158015920607335, "ROUGE_L": 0.2946859903381643, "CIDEr": 0.00836177555544703, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2, "f": 0.25641025641025644, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features two giraffes standing in a wildlife park. One giraffe is standing near the left side, and the other giraffe is standing in the middle."}, "71929": {"image_id": 71929, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.11207313002177546, "Bleu_3": 6.584408628047618e-07, "Bleu_4": 1.6051679053027854e-09, "METEOR": 0.2451866858230844, "ROUGE_L": 0.30160692212608153, "CIDEr": 5.5667634939246485e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.15625, "f": 0.19230769230769232, "fn": 27.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image does not contain a dining table. There are two plates in the image. The plate contains a variety of food items, including shrimp, rice, and meat. The shrimp are scattered across the plate, with some near the rice. The bowl contains shrimp and salad."}, "69293": {"image_id": 69293, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1666666666629209, "Bleu_3": 0.10891466159390667, "Bleu_4": 0.07447361532835538, "METEOR": 0.21964374351374347, "ROUGE_L": 0.24177566389219182, "CIDEr": 9.194127387138594e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.17391304347826086, "f": 0.19999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a bathroom with a toilet situated in the center of the room. The toilet is surrounded by a tiled floor and wall, giving the bathroom a clean and modern appearance. The bathroom also has two sinks, with one located in the corner."}, "90040": {"image_id": 90040, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.16714975946414357, "Bleu_3": 0.1180105578990872, "Bleu_4": 0.07571782782732693, "METEOR": 0.13690973470201862, "ROUGE_L": 0.24811156304474144, "CIDEr": 1.0702662594907448e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a beautiful scene of a city with a river flowing through it. The river is filled with numerous boats of various sizes. The boats are in the river. Some boats are floating close to the shore, while others are further away. A lot of boats is visible in the city."}, "409646": {"image_id": 409646, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.2571817658421884, "Bleu_3": 0.18048562115893838, "Bleu_4": 0.12785752288156155, "METEOR": 0.2232607465332597, "ROUGE_L": 0.27180140038192235, "CIDEr": 7.682213763924487e-09, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 10.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.75, "re": 0.8571428571428571, "f": 0.7999999999999999, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a bear walking across a field near a road. The bear's position is on the road. The bear is facing the camera. The field is surrounded by trees, providing a natural habitat for the bear.\n\nThere are no cars visible in the image."}, "296383": {"image_id": 296383, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.20957473279408315, "Bleu_3": 0.15305490466093202, "Bleu_4": 0.09296621060191432, "METEOR": 0.28598175746221494, "ROUGE_L": 0.31590628853267566, "CIDEr": 6.3759734342401605e-09, "SPICE": {"All": {"pr": 0.09375, "re": 0.12, "f": 0.10526315789473684, "fn": 22.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a cell phone lying on a wooden table. The cell phone is silver. The cell phone is turned on. The screen of the cell phone is illuminated. The cell phone is a flip phone. The screen is located on the top.\n\nThere are no bottles in the image."}, "566672": {"image_id": 566672, "Bleu_1": 0.3199999999936, "Bleu_2": 0.22857142856681054, "Bleu_3": 0.12960175458694234, "Bleu_4": 1.4670121015409243e-05, "METEOR": 0.25299788040490234, "ROUGE_L": 0.26521739130434785, "CIDEr": 5.341668530458555e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.13793103448275862, "f": 0.16, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress. There is a batter at the plate, swinging a baseball bat and attempting to hit a baseball. The catcher and umpire are preparing to throw the ball. The scene takes place on a field. There are no other players in the scene."}, "202865": {"image_id": 202865, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.09589266029382536, "Bleu_3": 6.899287365489461e-07, "Bleu_4": 1.867506984265124e-09, "METEOR": 0.14162617382575884, "ROUGE_L": 0.17630057803468208, "CIDEr": 0.00042089487943835027, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10344827586206896, "f": 0.1276595744680851, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two people holding donuts in their hands. The donuts are covered in powdered sugar. The people are standing outdoors, possibly enjoying a snack while taking a break."}, "226805": {"image_id": 226805, "Bleu_1": 0.4473684210408588, "Bleu_2": 0.29092485085203773, "Bleu_3": 1.3296980952257312e-06, "Bleu_4": 2.8628445964164814e-09, "METEOR": 0.2173505318370881, "ROUGE_L": 0.3155483298847177, "CIDEr": 7.59040288276363e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image showcases a spacious and modern living room with a large couch and a coffee table. The couches are positioned in the center of the room. The room is well-lit, with several lamps scattered throughout the space."}, "235221": {"image_id": 235221, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.11216649288903491, "Bleu_4": 1.323451095652116e-05, "METEOR": 0.13798653764057422, "ROUGE_L": 0.21526879190683448, "CIDEr": 3.818185313665074e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.36363636363636365, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a dramatic scene of a stormy sky with a lightning bolt illuminating the sky. The lightning bolt is visible in the middle of the scene, creating a striking contrast against the dark clouds. The sky is filled with clouds, and the storm appears to be intensifying."}, "499402": {"image_id": 499402, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.17407765595250352, "Bleu_3": 0.08299846557886469, "Bleu_4": 1.0240041382038528e-05, "METEOR": 0.2152731955819987, "ROUGE_L": 0.24358243011979464, "CIDEr": 3.848948722531448e-13, "SPICE": {"All": {"pr": 0.3125, "re": 0.15625, "f": 0.20833333333333334, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image captures a view from an airplane window. There is no airplane window in the image. The image shows the wing of the aircraft. The wing is positioned towards the left side. There are no clouds in the image. The plane is flying high above the clouds, providing a unique perspective of the landscape."}, "539557": {"image_id": 539557, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.13483997248961796, "Bleu_3": 7.505672632527668e-07, "Bleu_4": 1.7812705639924762e-09, "METEOR": 0.16147032427359453, "ROUGE_L": 0.2053872053872054, "CIDEr": 5.4526153444486775e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.23529411764705882, "f": 0.2162162162162162, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two ships. The first ship is white and surrounded by a lighthouse. The second ship is white and purple, and it is surrounded by birds. Some of the birds are on the roof.\n\nThere is no pier or boat in the scene."}, "109976": {"image_id": 109976, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.19920476821678648, "Bleu_3": 0.10528670005678414, "Bleu_4": 1.3713605456575345e-05, "METEOR": 0.21961823541256342, "ROUGE_L": 0.308080808080808, "CIDEr": 6.248484233220664e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a kitchen with a white stove top oven and a microwave above it. The stove is positioned on the counter. The microwave is located under the stove. The kitchen also has a sink."}, "210448": {"image_id": 210448, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.19847906537508855, "Bleu_3": 0.12236681347581897, "Bleu_4": 0.08127096480984838, "METEOR": 0.2013828953182397, "ROUGE_L": 0.24646464646464644, "CIDEr": 1.3992475077347399e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.16666666666666666, "f": 0.21428571428571427, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features six zebras standing together in a zoo enclosure. Some zebras are standing in the dirt, while others are grazing or eating grass. The zebras are of various sizes and positions. The scene also includes a fence separating the zebras from the onlookers."}, "32724": {"image_id": 32724, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.08701138391057635, "Bleu_4": 1.1125382292156774e-05, "METEOR": 0.22682187599626322, "ROUGE_L": 0.25452016689847007, "CIDEr": 9.0707029122068e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1111111111111111, "f": 0.14634146341463417, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a group of four giraffes running together in a grassy field. They are spread out, with one giraffe positioned towards the left side of the field, another in the middle, and the last two giraffes on the right side. The giraffes are running."}, "277689": {"image_id": 277689, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.14607233344869358, "Bleu_3": 8.399971471326652e-07, "Bleu_4": 2.0285762996808684e-09, "METEOR": 0.16125661171281405, "ROUGE_L": 0.2936726272352132, "CIDEr": 0.000164575282410801, "SPICE": {"All": {"pr": 0.36, "re": 0.36, "f": 0.36, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a dining table set with a cake. The table is adorned with five wine glasses. The cake is set on the dining table. The wine glasses are placed closer to the front and further back."}, "167818": {"image_id": 167818, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.19999999999595922, "Bleu_3": 0.14938015821552278, "Bleu_4": 0.109132152379658, "METEOR": 0.24841750086672668, "ROUGE_L": 0.24854481955762517, "CIDEr": 1.7192972129155528e-09, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.4, "f": 0.37209302325581395, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a desk with a laptop and a keyboard on it. There is also a laptop on the desk. The laptops are placed on the left side of the desk. The desktop computer is situated in the middle. The keyboard is positioned in front of the desktop computer."}, "445135": {"image_id": 445135, "Bleu_1": 0.5555555555401235, "Bleu_2": 0.41785544700689964, "Bleu_3": 0.31350284739344847, "Bleu_4": 0.2472109081971659, "METEOR": 0.3803919723108736, "ROUGE_L": 0.4236111111111111, "CIDEr": 0.005208170935028863, "SPICE": {"All": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a man playing tennis on a tennis court. The man is wearing a black shirt and white shorts. He is holding a tennis racket in his left hand, preparing to hit the ball."}, "3145": {"image_id": 3145, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.12483755678422237, "Bleu_3": 0.08326112070177698, "Bleu_4": 0.05744638728503178, "METEOR": 0.20732308377653288, "ROUGE_L": 0.21229698375870068, "CIDEr": 8.861028052947187e-13, "SPICE": {"All": {"pr": 0.43478260869565216, "re": 0.30303030303030304, "f": 0.35714285714285715, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.7777777777777778, "re": 0.5833333333333334, "f": 0.6666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}}, "caption": "The image depicts a spacious living room with a couch situated in the center of the room. A rug is surrounding the couch. The couch and four chairs create a comfortable seating area. A dining table is also present in the room, placed near the couch.\n\nThere are no other objects or furniture in the room."}, "319127": {"image_id": 319127, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.19758299278252553, "Bleu_3": 0.10370754607930319, "Bleu_4": 1.3458232889827183e-05, "METEOR": 0.2969966810501506, "ROUGE_L": 0.2930344275420336, "CIDEr": 1.4975737425993446e-05, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08, "f": 0.0909090909090909, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image depicts a park with a snow-covered field and two trees. The park is covered in snow, creating a serene and peaceful atmosphere. There is a bench in the park. A dog is in the field."}, "380906": {"image_id": 380906, "Bleu_1": 0.3199999999936, "Bleu_2": 0.19794866371815806, "Bleu_3": 9.345903743205193e-07, "Bleu_4": 2.0414630012523327e-09, "METEOR": 0.20781615377634227, "ROUGE_L": 0.255688622754491, "CIDEr": 1.973061530963002e-09, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.125, "f": 0.12000000000000001, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a bench situated on a brick walkway near a body of water, possibly a beach. The bench is adorned with purple ribbons, giving it a festive appearance. The bench is positioned close to the water. The view from the bench provides a pleasant view of the ocean."}, "524850": {"image_id": 524850, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.18463723646331667, "Bleu_3": 0.1032188373500798, "Bleu_4": 1.3836903383875294e-05, "METEOR": 0.1968967855860898, "ROUGE_L": 0.2426412092283214, "CIDEr": 0.0008848297601782179, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a busy airport scene with a large airplane parked on the tarmac. Several people are walking around the airplane. Some of the individuals are carrying luggage, including handbags and suitcases."}, "85926": {"image_id": 85926, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.08960727674188575, "Bleu_4": 1.1308221067043766e-05, "METEOR": 0.19285640589388423, "ROUGE_L": 0.22775357809583074, "CIDEr": 1.4582957219831766e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features three brown bears in a grassy field. The bears are standing close to each other, with one bear positioned in the middle and the other two bears on either side. The field is filled with tall grass, providing a natural habitat for the bears."}, "102355": {"image_id": 102355, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 9.550351820629135e-07, "Bleu_4": 2.1739441180809466e-09, "METEOR": 0.2227999836994592, "ROUGE_L": 0.25957446808510637, "CIDEr": 1.2826406428126477e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a group of four people riding a horse-drawn carriage down a street. Some of the people are sitting on the carriage. Some of the people are sitting on a bench. The horses pulling the carriage are white and grey."}, "47112": {"image_id": 47112, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.22758963106159172, "Bleu_3": 0.15466509142797644, "Bleu_4": 0.09746490477140814, "METEOR": 0.2364019890149497, "ROUGE_L": 0.2809210526315789, "CIDEr": 1.2596154245795931e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10714285714285714, "f": 0.1276595744680851, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.07142857142857142, "f": 0.125, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features two tables. On the first table, there is a glass of wine. On the second table, there is a pizza placed on a plate. The pizza is topped with mushrooms and ham. The other wine glass is closer to the pizza."}, "215709": {"image_id": 215709, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.3110855084092494, "Bleu_3": 0.2684910740226452, "Bleu_4": 0.2273070404563607, "METEOR": 0.2736481562847395, "ROUGE_L": 0.3194832402234637, "CIDEr": 0.0012849259316592672, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a bathroom with a sink and a mirror above it. A towel is hanging on the wall near the sink. There is also a towel rack in the bathroom."}, "512982": {"image_id": 512982, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.23302069120966015, "Bleu_3": 0.16316474245036913, "Bleu_4": 0.11539266904294404, "METEOR": 0.25227129762389994, "ROUGE_L": 0.25722891566265055, "CIDEr": 4.1062597950723745e-11, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bathroom with a sink and a mirror above it. The sink is surrounded by a marble countertop, and there is a vase filled with flowers placed on the counter. The flowers are positioned in the center of the sink, adding a touch of natural beauty to the bathroom."}, "344633": {"image_id": 344633, "Bleu_1": 0.17948717948257728, "Bleu_2": 0.11903797917090887, "Bleu_3": 7.262003529652452e-07, "Bleu_4": 1.8059957191734693e-09, "METEOR": 0.18010679310846528, "ROUGE_L": 0.19885900570497148, "CIDEr": 1.9369355732208594e-06, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.19230769230769232, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features two people riding horses in the scene. The horses are spread out across the area, with one horse in the foreground, another horse in the middle, and the third horse further back. The horses are running."}, "555942": {"image_id": 555942, "Bleu_1": 0.35294117644982703, "Bleu_2": 0.2572478776981582, "Bleu_3": 0.1640101707088765, "Bleu_4": 2.3693055762206496e-05, "METEOR": 0.22877305320803176, "ROUGE_L": 0.31082802547770705, "CIDEr": 0.1766087997439706, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features three motorcycles parked on the sidewalk. The motorcycles are green and orange and white."}, "471567": {"image_id": 471567, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.17393131069069204, "Bleu_3": 9.71435267961373e-07, "Bleu_4": 2.3135181196744457e-09, "METEOR": 0.20948302738422273, "ROUGE_L": 0.31794489947877885, "CIDEr": 0.00020878227545350058, "SPICE": {"All": {"pr": 0.5384615384615384, "re": 0.4117647058823529, "f": 0.4666666666666667, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.8333333333333334, "f": 0.8333333333333334, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image features a giraffe standing in a zoo enclosure. The giraffe is looking at a house. The enclosure is surrounded by a wooden fence. There are no other animals or objects in the scene."}, "24260": {"image_id": 24260, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.10735372697093548, "Bleu_3": 0.063041345480191, "Bleu_4": 8.638055235544587e-06, "METEOR": 0.14214671908952747, "ROUGE_L": 0.2582244799225931, "CIDEr": 1.917453986818437e-05, "SPICE": {"All": {"pr": 0.125, "re": 0.05263157894736842, "f": 0.07407407407407407, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image features a lively scene of two horses standing in a grassy field. The horses are positioned closer to the left side of the field. One horse is standing on the ground, while the other horse is in the air. \n\nThere are no zebras in the scene."}, "106508": {"image_id": 106508, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1348399724902187, "Bleu_3": 0.06956880074617594, "Bleu_4": 8.927747941495415e-06, "METEOR": 0.21272883104557186, "ROUGE_L": 0.2096700274977085, "CIDEr": 1.341899715649455e-12, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.2916666666666667, "f": 0.2978723404255319, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.75, "f": 0.75, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image depicts a street scene with a man in a yellow safety vest ensuring the safety of pedestrians. The man is pointing at something. There is a police officer on the street. A yellow bus is positioned closer to the man. There are several cars on the street. A yellow bus is on the street."}, "311082": {"image_id": 311082, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.1647705109111272, "Bleu_3": 0.12950394190491815, "Bleu_4": 0.10738497851612415, "METEOR": 0.2369022303199039, "ROUGE_L": 0.25176886792452824, "CIDEr": 2.918994155681462e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features three elephants standing next to each other in a grassy area. They appear to be facing each other, possibly engaging in a social interaction or playful behavior. The elephants are positioned close to each other, with one on the left side and the other two on the right side."}, "312167": {"image_id": 312167, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.0800071120572659, "Bleu_3": 5.623217682656264e-07, "Bleu_4": 1.5013144369944e-09, "METEOR": 0.1560836078720838, "ROUGE_L": 0.1812778603268945, "CIDEr": 7.625838776317612e-06, "SPICE": {"All": {"pr": 0.28, "re": 0.35, "f": 0.3111111111111111, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7777777777777778, "f": 0.6086956521739131, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The image features three vases with pink flowers inside, placed on a table. The flowers are positioned towards the center of the vases, and their petals are pink. The table is located in the middle of the room."}, "324937": {"image_id": 324937, "Bleu_1": 0.21052631578393358, "Bleu_2": 0.18476851073338801, "Bleu_3": 0.0982466623305646, "Bleu_4": 1.2829843028855695e-05, "METEOR": 0.24103675627470983, "ROUGE_L": 0.3320373250388802, "CIDEr": 5.288651656488218e-05, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a dog lying on a couch. The dog is comfortably resting its head on the couch. The dog is not sleeping, but rather laying on the couch. The couch is situated in a living room."}, "65415": {"image_id": 65415, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 6.880010617668035e-07, "Bleu_4": 1.631181823642126e-09, "METEOR": 0.23869038479630375, "ROUGE_L": 0.20158625247851947, "CIDEr": 1.2189712783832187e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2857142857142857, "f": 0.2790697674418604, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a woman wearing a red jacket and skiing gear, standing on a snow-covered slope. She is holding ski poles and appears to be enjoying her time on the snow. The woman is positioned towards the center of the scene, with her skis visible beneath her feet."}, "201925": {"image_id": 201925, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.2667325346727717, "Bleu_3": 0.1501911109396443, "Bleu_4": 2.0287366423929855e-05, "METEOR": 0.20442317951578412, "ROUGE_L": 0.36345580933465743, "CIDEr": 0.14714417870220728, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.25, "f": 0.2553191489361702, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a cake baking in a black oven. The cake is brown and there are nuts scattered on top of it."}, "273132": {"image_id": 273132, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.1877669040449484, "Bleu_3": 0.12288385580936055, "Bleu_4": 0.08415321094031712, "METEOR": 0.19214256370360502, "ROUGE_L": 0.2621776504297994, "CIDEr": 3.2261108926210666e-06, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1111111111111111, "f": 0.12244897959183673, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features two women sitting on a bench. Both women are wearing hats and appear to be relaxing and enjoying their time outdoors. The bench is located in front of a building, possibly a park or a public space."}, "475238": {"image_id": 475238, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.2225972810858974, "Bleu_3": 0.16194379301356765, "Bleu_4": 0.10571911064375653, "METEOR": 0.28406684664349785, "ROUGE_L": 0.3097345132743363, "CIDEr": 4.434122783987305e-05, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image is a black and white photograph of two trains traveling down the tracks. The trains are positioned on the tracks. The tracks are visible in the foreground. The trains are moving through a rural area."}, "130527": {"image_id": 130527, "Bleu_1": 0.23529411763321803, "Bleu_2": 0.12126781251081024, "Bleu_3": 9.934208620967142e-07, "Bleu_4": 2.8927969314267103e-09, "METEOR": 0.11939345768621241, "ROUGE_L": 0.2847141190198366, "CIDEr": 0.07212974563337787, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.29411764705882354, "f": 0.22727272727272727, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a hillside covered in lush green grass. There is no sheep in the image."}, "337563": {"image_id": 337563, "Bleu_1": 0.2857142857040817, "Bleu_2": 0.2300218531057509, "Bleu_3": 0.15966079269551264, "Bleu_4": 0.11295714543526911, "METEOR": 0.1928352374405199, "ROUGE_L": 0.27601809954751133, "CIDEr": 0.00610505175989042, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.14285714285714285, "f": 0.17647058823529413, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts a woman sitting on a bed in a room. The woman is peeling a banana. The bed is positioned in the center of the room."}, "135356": {"image_id": 135356, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.20851441405249155, "Bleu_3": 0.14365262974918175, "Bleu_4": 0.0911209149042937, "METEOR": 0.19998895898263008, "ROUGE_L": 0.31812255541069095, "CIDEr": 2.586204587469948e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.4117647058823529, "f": 0.36842105263157887, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man standing in a kitchen. The man is putting a pan in the sink. He is holding a pan. He is wearing a plaid shirt. The baby is not in the scene. The kitchen is well-equipped with a refrigerator and a microwave."}, "290078": {"image_id": 290078, "Bleu_1": 0.340909090901343, "Bleu_2": 0.30844354542515784, "Bleu_3": 0.2512272286370669, "Bleu_4": 0.19832116470666222, "METEOR": 0.3218186057643456, "ROUGE_L": 0.306312769010043, "CIDEr": 2.0056767977709037e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a toilet sitting outside of a building, placed on the sidewalk next to a building. The toilet appears to be old and dirty, with a broken seat. It is positioned on the side of the road. There is a window nearby."}, "578314": {"image_id": 578314, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.13334123550086785, "Bleu_4": 0.09072069007262817, "METEOR": 0.2092332953773523, "ROUGE_L": 0.24636510500807754, "CIDEr": 1.6034898230802935e-05, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.10714285714285714, "f": 0.11764705882352941, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image is a close-up view of a toilet in a bathroom. The toilet is positioned in the center of the room, surrounded by tiled floors. The toilet is white. The lid of the toilet is not open."}, "174893": {"image_id": 174893, "Bleu_1": 0.16666666666269844, "Bleu_2": 0.09016696346457025, "Bleu_3": 5.87956188316209e-07, "Bleu_4": 1.5109238358422705e-09, "METEOR": 0.1685496183206107, "ROUGE_L": 0.21631205673758863, "CIDEr": 6.216132940885702e-07, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.2631578947368421, "f": 0.18867924528301885, "fn": 14.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.625, "f": 0.43478260869565216, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image features a girl wearing a pink and white striped shirt. She is sitting at a table and using scissors to cut up paper. The girl is focused on her task, possibly working on a craft project or a school assignment."}, "539310": {"image_id": 539310, "Bleu_1": 0.37999999999240003, "Bleu_2": 0.2157095552890918, "Bleu_3": 0.1427379958908156, "Bleu_4": 1.577176260837821e-05, "METEOR": 0.20129766815175407, "ROUGE_L": 0.26725082146768897, "CIDEr": 2.467308330945133e-08, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09090909090909091, "f": 0.0975609756097561, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image is a rear view of a car stopped at a traffic light. The traffic light is green, allowing the car to proceed. There are several other cars in the scene, with some positioned behind the car and others further away.\n\nThe car is stopped at the red light."}, "49740": {"image_id": 49740, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.10341753799591613, "Bleu_3": 6.939786934219505e-07, "Bleu_4": 1.8120458368313505e-09, "METEOR": 0.20814049264119683, "ROUGE_L": 0.25979557069846676, "CIDEr": 0.0002718547081373122, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.24, "f": 0.28571428571428564, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5, "f": 0.588235294117647, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image captures a baseball game in progress. The batter is swinging a baseball bat at a pitched ball. The catcher is standing behind the batter. The umpire is not visible in the scene."}, "274549": {"image_id": 274549, "Bleu_1": 0.42499999998937504, "Bleu_2": 0.2761920550598592, "Bleu_3": 0.18193657176704325, "Bleu_4": 0.11295086840060606, "METEOR": 0.2860106620879932, "ROUGE_L": 0.3588235294117647, "CIDEr": 1.2313356860069327e-05, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2222222222222222, "f": 0.27272727272727276, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a person wearing an orange jacket and skiing down a snowy slope. The person is holding ski poles while navigating the snowy terrain. The skier is enjoying their time on the mountain, surrounded by the snowy landscape."}, "537211": {"image_id": 537211, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2738612787456488, "Bleu_3": 0.25087413297980393, "Bleu_4": 0.23378464993189177, "METEOR": 0.4453212720801775, "ROUGE_L": 0.4485294117647059, "CIDEr": 8.285298570982871e-06, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3157894736842105, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a man sitting on a dock, eating a hot dog while wearing sunglasses. He is holding the hot dog in his hands and appears to be enjoying the meal. There is no other person in the scene."}, "533743": {"image_id": 533743, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.17038855026853147, "Bleu_3": 0.10003706449227341, "Bleu_4": 1.3750902304795609e-05, "METEOR": 0.20723069107475328, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.0009483952607960586, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "There is no man in this image. There are two boys standing in a room. They are both holding Nintendo Wii controllers. The boys are positioned in front of the couch."}, "81812": {"image_id": 81812, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.13160986848342304, "Bleu_4": 1.4920276910509015e-05, "METEOR": 0.21779816586467085, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.2545479440409283e-10, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a group of four people gathered around a dining table, enjoying a meal together. The people are eating and drinking wine. The table is filled with various food items, including three plates of pasta, a plate of pizza, and a plate with a bowl of soup."}, "59743": {"image_id": 59743, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.1259881576661928, "Bleu_3": 7.757590387941911e-07, "Bleu_4": 1.939396682572253e-09, "METEOR": 0.21273107290998255, "ROUGE_L": 0.24918300653594777, "CIDEr": 1.6068841556508442e-05, "SPICE": {"All": {"pr": 0.35, "re": 0.28, "f": 0.3111111111111111, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image depicts three people standing on a beach. Two individuals are in the foreground and two more are in the background. They are all holding surfboards, preparing to enter the water for a surfing session."}, "356131": {"image_id": 356131, "Bleu_1": 0.4848484848337925, "Bleu_2": 0.3256694736294419, "Bleu_3": 0.15068295792388314, "Bleu_4": 1.837671114729021e-05, "METEOR": 0.27970864167790244, "ROUGE_L": 0.33395901767558267, "CIDEr": 0.028934040403580448, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1111111111111111, "f": 0.15789473684210525, "fn": 24.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features two sailboats floating on a body of water. One sailboat is positioned towards the center of the image. There are people sitting in a small boat, and they are rowing."}, "311310": {"image_id": 311310, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.1956151991049542, "Bleu_3": 0.1346716546900339, "Bleu_4": 1.5179857311603864e-05, "METEOR": 0.20082208012950617, "ROUGE_L": 0.22679390259015986, "CIDEr": 1.5110110847497126e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.14285714285714285, "f": 0.17647058823529413, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts a lively scene in a park where a group of fifteen people is enjoying a sunny day in the park. Some individuals are playing frisbee, soccer, or other games, while others are walking on the grass or flying a kite. Kites are scattered throughout the park."}, "165257": {"image_id": 165257, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.16012815380103265, "Bleu_3": 0.08771030046935029, "Bleu_4": 1.1620839902592802e-05, "METEOR": 0.169116234151155, "ROUGE_L": 0.30587392550143266, "CIDEr": 3.5263769221614328e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a kitchen with wooden cabinets and a black countertop. The countertop is cluttered with various items, including a microwave oven, a sink, a frying pan, a pot, and a pan. There are no bottles in the scene."}, "202658": {"image_id": 202658, "Bleu_1": 0.4999999999791667, "Bleu_2": 0.39009474878613976, "Bleu_3": 0.3258085751638509, "Bleu_4": 0.26512298020574937, "METEOR": 0.3950640363678702, "ROUGE_L": 0.6124497991967871, "CIDEr": 0.1794490517184461, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.75, "f": 0.5454545454545454, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a toilet with a Hello Kitty design on the seat, placed in a room. The toilet is situated on the ground."}, "50926": {"image_id": 50926, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 0.06923138992163505, "Bleu_4": 9.071482520661878e-06, "METEOR": 0.20094481325716368, "ROUGE_L": 0.22536945812807885, "CIDEr": 7.761632177865364e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.19230769230769232, "f": 0.18867924528301885, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features two people enjoying a sunny day. One person is walking and a woman is flying a kite. The other person is playing frisbee and a man is also flying a kite. \n\nThere is no park in the scene.\n\nThe overall scene shows a kite soaring high in the sky."}, "514797": {"image_id": 514797, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.2623469285652076, "Bleu_3": 0.15495065386507711, "Bleu_4": 1.792955185986044e-05, "METEOR": 0.24035827643690982, "ROUGE_L": 0.22846441947565538, "CIDEr": 6.317164878701205e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.03125, "f": 0.04878048780487805, "fn": 31.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image depicts three people standing on a beach, enjoying a day of kite flying. The people are flying a kite. The man is holding a blue and black kite. The other people are preparing to fly their kites."}, "258021": {"image_id": 258021, "Bleu_1": 0.27027027026296574, "Bleu_2": 2.7399831216808733e-09, "Bleu_3": 5.9860808314864656e-12, "Bleu_4": 2.818299888302426e-13, "METEOR": 0.15867996514608682, "ROUGE_L": 0.2247605011053795, "CIDEr": 9.500834147715306e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.15789473684210525, "f": 0.15384615384615385, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man standing on a motorcycle in a parking lot. The motorcycle is parked near a yellow fence, and the man is positioned close to it. The parking lot is surrounded by three cars."}, "203085": {"image_id": 203085, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1458649914948234, "Bleu_3": 0.07733595213409626, "Bleu_4": 1.0068921364329411e-05, "METEOR": 0.285761900667081, "ROUGE_L": 0.2616421568627451, "CIDEr": 1.8904876029600787e-08, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a man sitting on a toilet in a bathroom. The man is using a computer. He is wearing a gray shirt. \n\nThere is no sink or mirror in the scene.\n\nThere is no laptop in the scene.\n\nThere is no other person in the scene."}, "441442": {"image_id": 441442, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.17878070701566398, "Bleu_4": 0.1485015617961272, "METEOR": 0.2137546651314893, "ROUGE_L": 0.27128335451080055, "CIDEr": 3.7882754787637634e-10, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.1875, "f": 0.23529411764705882, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image captures a horse and a rider in the middle of a jumping competition. The horse is walking. The horse is brown. The rider is riding a horse. The horse is jumping over a fence on a grassy field. There are no other people or spectators in the scene."}, "494759": {"image_id": 494759, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.20134681655868997, "Bleu_3": 0.17958242494459375, "Bleu_4": 0.15035173988049602, "METEOR": 0.30101273195873124, "ROUGE_L": 0.33862014274385416, "CIDEr": 6.262553733617727e-05, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.041666666666666664, "f": 0.044444444444444446, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image features a man and a child standing on a beach, flying a kite together. The kite is soaring above the beach, with its tail visible. The man and the child are enjoying their time outdoors."}, "336937": {"image_id": 336937, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.0645198590415134, "Bleu_3": 4.522633916831482e-07, "Bleu_4": 1.2041494936393691e-09, "METEOR": 0.13341553047421914, "ROUGE_L": 0.20847573479152426, "CIDEr": 9.638249087375837e-10, "SPICE": {"All": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a room with numerous white toilets arranged in rows. The toilets are of various sizes and are placed closely together, occupying most of the space in the room. Some of the toilets are positioned near the center, while others are scattered throughout the room."}, "157155": {"image_id": 157155, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.2836543144559696, "Bleu_3": 0.17912254476139916, "Bleu_4": 0.12078743167256635, "METEOR": 0.25067433843634607, "ROUGE_L": 0.32972972972972975, "CIDEr": 0.01108710767681086, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.09523809523809523, "f": 0.10256410256410256, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image captures a lively scene of two people talking on the phone. They are riding horses down a city street at night. The horses are carrying a police officer."}, "243600": {"image_id": 243600, "Bleu_1": 0.28124999999560546, "Bleu_2": 0.21128856367880158, "Bleu_3": 0.17145603545033664, "Bleu_4": 0.12547651208777577, "METEOR": 0.2610520245935965, "ROUGE_L": 0.30019685039370075, "CIDEr": 4.4878451849192955e-17, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14814814814814814, "f": 0.19047619047619047, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of a room filled with four people sitting at a table. Some people are sitting at the table. Other people are standing. The people are reading books in a library. Some people are writing. A young person is standing. Some people are doing a wedding photo. A man and a woman is sitting on the chairs."}, "542147": {"image_id": 542147, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.23055616707626844, "Bleu_3": 0.10904101282262471, "Bleu_4": 1.3417679370522619e-05, "METEOR": 0.2437712662352347, "ROUGE_L": 0.2902787219578518, "CIDEr": 3.0741891002977967e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15789473684210525, "f": 0.16216216216216214, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a large grassy field with a group of cows grazing on the lush green grass. There are 11 cows visible in the scene. The cows are scattered across the field, with some closer to the foreground and others further away."}, "277227": {"image_id": 277227, "Bleu_1": 0.10526315789196679, "Bleu_2": 0.05333807470484394, "Bleu_3": 4.291318246876245e-07, "Bleu_4": 1.2258181047033616e-09, "METEOR": 0.09849281170950373, "ROUGE_L": 0.14364207221350078, "CIDEr": 2.204103502281e-06, "SPICE": {"All": {"pr": 0.24, "re": 0.2727272727272727, "f": 0.2553191489361702, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features three boats lined up in the water. One boat is positioned in the foreground, while the others are in the background. The boats vary in size and length. There is no dock in the scene."}, "323552": {"image_id": 323552, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.2142857142812956, "Bleu_3": 0.1250180897226835, "Bleu_4": 1.4356222678314862e-05, "METEOR": 0.2678835732940521, "ROUGE_L": 0.26940063091482647, "CIDEr": 7.56301877633177e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1875, "f": 0.17142857142857143, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a woman sitting on a bench at an airport, waiting for her luggage. She is wearing glasses and has a backpack on her back. The backpack is positioned behind her. She appears to be looking at her phone.\n\nThere are no other people in the scene."}, "319607": {"image_id": 319607, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.10040323016589746, "Bleu_4": 1.28605734119315e-05, "METEOR": 0.20105180694241276, "ROUGE_L": 0.2920656634746922, "CIDEr": 0.0002822486714375117, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15789473684210525, "f": 0.16216216216216214, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image features a bicycle rider traveling down a road in a city scene. The cyclist is wearing a black hat. The cyclist is positioned on the sidewalk. There is a traffic light located on the corner of the street."}, "581702": {"image_id": 581702, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.25588315785430304, "Bleu_3": 0.22337017141512605, "Bleu_4": 0.18656145762255902, "METEOR": 0.31665022192972914, "ROUGE_L": 0.3386798272671191, "CIDEr": 1.9818161707305248e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a bird with a red crest perched on a rock. The bird is standing on a rocky surface, possibly a boulder, and appears to be looking around. The bird's crest is red, which is a prominent feature. The scene is set in a natural environment."}, "328818": {"image_id": 328818, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.0927733381723083, "Bleu_4": 1.1961929431463712e-05, "METEOR": 0.2518021466977554, "ROUGE_L": 0.3551673944687045, "CIDEr": 3.5483181385285997e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a woman wearing a pink shirt and blue jeans, standing on a bench. She is bending over, tying her shoelaces, and appears to be in the process of putting on her shoes. The bench is located on a trail."}, "55981": {"image_id": 55981, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.1305582419627553, "Bleu_3": 8.192484549622561e-07, "Bleu_4": 2.06909966109537e-09, "METEOR": 0.18936629886011533, "ROUGE_L": 0.3302397525135344, "CIDEr": 0.0005875892249113603, "SPICE": {"All": {"pr": 0.25, "re": 0.12, "f": 0.16216216216216217, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a girl standing in a hallway. The girl is wearing a blue scarf and holding a blue and yellow suitcase. She is smiling and appears to be enjoying her time."}, "385918": {"image_id": 385918, "Bleu_1": 0.5714285714013606, "Bleu_2": 0.37796447299077907, "Bleu_3": 0.24682706829042084, "Bleu_4": 3.0232667129300415e-05, "METEOR": 0.27864063617968987, "ROUGE_L": 0.5029446407538279, "CIDEr": 0.20435596086356744, "SPICE": {"All": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a group of five people playing frisbee on a grassy field. They are playing with a white frisbee."}, "86625": {"image_id": 86625, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 0.1017691319923899, "Bleu_4": 0.0703630957666405, "METEOR": 0.19332330334799008, "ROUGE_L": 0.24830393487109906, "CIDEr": 8.893158556149117e-09, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.3181818181818182, "f": 0.358974358974359, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man standing in a kitchen. The man is looking at the refrigerator with a surprised expression on his face. He is wearing a blue shirt. \n\nThere are no other items or activities mentioned in the supplementary information, so the passage ends here."}, "87429": {"image_id": 87429, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.2661770133303563, "Bleu_3": 0.1790964078865936, "Bleu_4": 0.1123930692883472, "METEOR": 0.232733712354962, "ROUGE_L": 0.3287143956889915, "CIDEr": 5.7387476033765695e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.2631578947368421, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a busy city street with two cars and three traffic lights. A car with a red tail light can be seen on the street. On the other side of the street is another traffic light located."}, "330091": {"image_id": 330091, "Bleu_1": 0.39999999999, "Bleu_2": 0.20254787341160474, "Bleu_3": 0.10258658975854419, "Bleu_4": 1.3069757021297846e-05, "METEOR": 0.24621290717042216, "ROUGE_L": 0.2839095744680851, "CIDEr": 0.001116960187761843, "SPICE": {"All": {"pr": 0.28125, "re": 0.32142857142857145, "f": 0.30000000000000004, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.46153846153846156, "f": 0.4444444444444445, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image captures a thrilling moment of two skiers racing down a snow-covered slope. The skier in the foreground is wearing a red and black outfit, while the skier in the background is also wearing a red and black outfit."}, "491851": {"image_id": 491851, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.16968474448956103, "Bleu_3": 8.888611274794583e-07, "Bleu_4": 2.0469650963568225e-09, "METEOR": 0.24581574092575226, "ROUGE_L": 0.2902787219578518, "CIDEr": 6.954251049100691e-07, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.2222222222222222, "f": 0.2424242424242424, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a desk with a computer setup. On the desk, there is a computer, a keyboard, a mouse, and a monitor. The monitor is positioned towards the left side of the desk. The keyboard is placed in front of the monitor."}, "203661": {"image_id": 203661, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2166823008689824, "Bleu_3": 0.18190756402244534, "Bleu_4": 0.15865624349390117, "METEOR": 0.3126866231661051, "ROUGE_L": 0.32373009855951485, "CIDEr": 5.903472572938463e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.27586206896551724, "f": 0.28070175438596495, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a kitchen with a wooden dining table surrounded by chairs. The table is set with a plate, a cup, and a knife. \n\nThere is no bowl in the scene. \n\nOne of the knives is placed on the table."}, "150875": {"image_id": 150875, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.0922138891935132, "Bleu_3": 5.655855085604915e-07, "Bleu_4": 1.4082645504822834e-09, "METEOR": 0.16002456827855407, "ROUGE_L": 0.20158625247851947, "CIDEr": 3.152880240739676e-11, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.25925925925925924, "f": 0.25925925925925924, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a stone bench situated in a park, surrounded by trees and flowers. The bench is positioned in the middle of the scene, with a few trees in the background. The bench is adorned with a decorative design, adding a touch of elegance to the park setting."}, "99707": {"image_id": 99707, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.19971489649755367, "Bleu_3": 0.11684953007532978, "Bleu_4": 1.605711128122552e-05, "METEOR": 0.27547568351476054, "ROUGE_L": 0.3440496333897349, "CIDEr": 0.011107505465642646, "SPICE": {"All": {"pr": 0.25, "re": 0.12903225806451613, "f": 0.1702127659574468, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a snowy scene with one person standing on skis, preparing to ski down a snow-covered slope. The person is standing on a snow-covered slope."}, "124647": {"image_id": 124647, "Bleu_1": 0.1935483870936525, "Bleu_2": 0.12595484068769355, "Bleu_3": 0.08086665708971538, "Bleu_4": 0.054715971525656604, "METEOR": 0.13280661477013475, "ROUGE_L": 0.13275299238302501, "CIDEr": 1.5420826682433998e-16, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.19047619047619047, "f": 0.21052631578947367, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features two boys wearing helmets, standing in a skate park. A group of people is around the boys. The first boy is wearing a hat and the second boy is wearing a plaid shirt. The boys are not the center of attention. The first boy is closer to a fence and the second boy is further away from a fence."}, "62167": {"image_id": 62167, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2209045015297887, "Bleu_3": 0.11171556744566542, "Bleu_4": 1.4230348714393923e-05, "METEOR": 0.2642054170522667, "ROUGE_L": 0.27706283118849356, "CIDEr": 2.8983403485150402e-05, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.2, "f": 0.16216216216216214, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a man standing in a grassy field. The man is holding a frisbee and playing frisbee with his dog. The man is playing with a frisbee. The sheep are also playing with a frisbee."}, "300221": {"image_id": 300221, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.2823298512746205, "Bleu_3": 1.535902471682881e-06, "Bleu_4": 3.6242479821540745e-09, "METEOR": 0.20868829857557342, "ROUGE_L": 0.428714859437751, "CIDEr": 0.03848328477694968, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.09523809523809523, "f": 0.14285714285714285, "fn": 19.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image showcases a vibrant display of vegetables arranged on shelves in a market. Carrots, broccoli, cauliflower, and onions are displayed on the shelves."}, "109537": {"image_id": 109537, "Bleu_1": 0.5599999999776001, "Bleu_2": 0.4582575694768719, "Bleu_3": 0.30144232985198327, "Bleu_4": 0.18784407806545977, "METEOR": 0.39682840833931043, "ROUGE_L": 0.5377081292850147, "CIDEr": 0.04689693241561549, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.07692307692307693, "f": 0.0975609756097561, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image captures a man riding a wave on a surfboard in the ocean. The man is skillfully navigating the wave, showcasing his surfing abilities."}, "382715": {"image_id": 382715, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.18663625434394557, "Bleu_3": 0.1684638136346001, "Bleu_4": 0.14786996528680024, "METEOR": 0.3339999786358722, "ROUGE_L": 0.3258160237388724, "CIDEr": 3.180721511892468e-11, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a man riding a skateboard down a city street. He is wearing a black jacket.\n\nThere is no backpack in the scene.\n\nThere are two cars in the background. There is no truck in the scene.\n\nThere are nine people in the scene.\n\nThe man is positioned on a skateboard."}, "52596": {"image_id": 52596, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.25819888973988653, "Bleu_3": 0.19868417242611314, "Bleu_4": 0.14765612529678226, "METEOR": 0.23735083738821056, "ROUGE_L": 0.3341158059467919, "CIDEr": 0.00010849251843433335, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a girl standing in a grassy field. The girl is holding a piece of pizza and enjoying her meal. She is wearing a purple shirt, which contrasts with the green grass around her."}, "500718": {"image_id": 500718, "Bleu_1": 0.5161290322414152, "Bleu_2": 0.2623303343049779, "Bleu_3": 1.3338275265636457e-06, "Bleu_4": 3.0341374366181037e-09, "METEOR": 0.2357611197526307, "ROUGE_L": 0.35376967688483846, "CIDEr": 0.002769448751667124, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.045454545454545456, "f": 0.049999999999999996, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features three airplanes parked on a runway. The airplanes are orange and white. Two of the airplanes are lined up next to each other. The airplanes occupy the tarmac."}, "182240": {"image_id": 182240, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.20083857809555095, "Bleu_3": 0.13471111906856947, "Bleu_4": 0.09348998462305054, "METEOR": 0.2047155694381395, "ROUGE_L": 0.2543786488740617, "CIDEr": 7.95558067010697e-05, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2777777777777778, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features four zebras standing together in a grassy field. They are all facing different directions, creating a dynamic scene.\n\nThe field is surrounded by four trees, providing a natural habitat for the zebras."}, "525083": {"image_id": 525083, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.15263761139750137, "Bleu_4": 0.11939514264170308, "METEOR": 0.26968714322051035, "ROUGE_L": 0.34491114701130854, "CIDEr": 4.323317774913986e-06, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.13043478260869565, "f": 0.10344827586206898, "fn": 20.0, "numImages": 1.0, "fp": 32.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image depicts a spacious, well-lit kitchen with hardwood floors and wood cabinets. The kitchen is equipped with a refrigerator and an oven. There are two chairs placed around the dining table, which is located in the kitchen."}, "56821": {"image_id": 56821, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.11262765836415223, "Bleu_3": 0.08453247893683391, "Bleu_4": 1.1017212838732251e-05, "METEOR": 0.14860088668984917, "ROUGE_L": 0.20265780730897012, "CIDEr": 7.461929566829031e-08, "SPICE": {"All": {"pr": 0.35, "re": 0.25925925925925924, "f": 0.29787234042553196, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a city street with a banner hanging from a building, promoting a home styling business. The banner is visible above the street. A clock is hanging from the building. The \"save the date\" banner is a big hit with the passersby."}, "256367": {"image_id": 256367, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.3418817293630038, "Bleu_3": 0.18012497332786204, "Bleu_4": 2.355006156957201e-05, "METEOR": 0.27330998314105653, "ROUGE_L": 0.40866458240285847, "CIDEr": 0.08296265982005971, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks. The train is positioned on the tracks. The train is surrounded by trees."}, "42667": {"image_id": 42667, "Bleu_1": 0.16393442622682078, "Bleu_2": 0.09053574604102199, "Bleu_3": 0.05179200443176847, "Bleu_4": 6.995842782527095e-06, "METEOR": 0.14139861132926193, "ROUGE_L": 0.16180371352785144, "CIDEr": 8.315924302882658e-17, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.23076923076923078, "f": 0.20000000000000004, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6, "f": 0.48, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image features a baby sitting on a suitcase. The baby is holding a suitcase. The baby is also holding a remote control in its hand. The baby appears to be smiling, enjoying the moment. The chair is positioned in the center of the scene, with the baby occupying most of the frame. There is no dining table in the scene."}, "388453": {"image_id": 388453, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.13801311186458243, "Bleu_3": 8.243669901955128e-07, "Bleu_4": 2.029840717200597e-09, "METEOR": 0.2566895548280835, "ROUGE_L": 0.32348484848484854, "CIDEr": 3.8173071045364194e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image depicts a large group of 32 people gathered in a room. They are talking to each other, standing around, and some are drinking wine. The room is filled with chandeliers, creating a sophisticated atmosphere."}, "38118": {"image_id": 38118, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.152498570329016, "Bleu_3": 0.08277818425483373, "Bleu_4": 1.0912441388233997e-05, "METEOR": 0.20734990877639922, "ROUGE_L": 0.21801286633309508, "CIDEr": 5.434128057351684e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14814814814814814, "f": 0.1509433962264151, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image captures a person wearing a red jacket and skiing down a snow-covered slope. They are skiing down a hill, making their way through the snow. The skier is positioned towards the center of the scene, with their skis visible beneath them."}, "305319": {"image_id": 305319, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.2034190510793456, "Bleu_3": 0.11390472475032028, "Bleu_4": 1.5295559336991324e-05, "METEOR": 0.20334858178610937, "ROUGE_L": 0.2839851024208566, "CIDEr": 0.002141390938096108, "SPICE": {"All": {"pr": 0.2, "re": 0.11428571428571428, "f": 0.14545454545454545, "fn": 31.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image captures a surfer riding a wave in the ocean. The surfer is riding a surfboard and skillfully maneuvering on the water. The wave is visible beneath the surfer."}, "410484": {"image_id": 410484, "Bleu_1": 0.16249999999796877, "Bleu_2": 0.07855498759336749, "Bleu_3": 0.042929020098132514, "Bleu_4": 5.661617828722337e-06, "METEOR": 0.15397334825001105, "ROUGE_L": 0.18944099378881987, "CIDEr": 3.364589300550383e-24, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14814814814814814, "f": 0.15686274509803924, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two people standing in front of four cakes. The people are cutting a cake. A plate is in front of each person. One person is holding a knife and the other person is holding a plate. They are both ready to cut the cake. The cakes are placed on a dining table. There are also other items in the scene, such as a candle near one of the cakes and a plate of cupcakes near another cake."}, "454252": {"image_id": 454252, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.20936574503555552, "Bleu_3": 0.1664801848859185, "Bleu_4": 0.09527411106747781, "METEOR": 0.24204873329633264, "ROUGE_L": 0.2704885580806081, "CIDEr": 2.870540166852793e-14, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a group of nine people standing in a room. The people are pouring wine. Some of the people are posing for a picture. One person is holding a cell phone.\n\nThere are no wine tasting events or bars in the scene.\n\nThere are six wine glasses in the scene.\n\nThe people are standing in a winery."}, "245153": {"image_id": 245153, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.20447945297237122, "Bleu_3": 0.10148763200900297, "Bleu_4": 1.279510009626945e-05, "METEOR": 0.1842156978776934, "ROUGE_L": 0.2469635627530364, "CIDEr": 1.210957828290065e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two birds standing on a grassy hillside. The birds are positioned close to each other, with one bird located in the middle and the other two birds on either side of it. The birds are standing on the grass."}, "528980": {"image_id": 528980, "Bleu_1": 0.1728395061707057, "Bleu_2": 0.14698618394620686, "Bleu_3": 0.10303749930987967, "Bleu_4": 0.06119597122999181, "METEOR": 0.1596389534495091, "ROUGE_L": 0.1776945484810653, "CIDEr": 3.0312916065191372e-30, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.16129032258064516, "f": 0.20408163265306123, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a city street with a red umbrella attached to a pole, standing out against the backdrop of a building. The umbrella is positioned in the middle of the scene, with a stop sign visible in the background. A brick wall is the backdrop of the umbrella.\n\nThere are several cars parked along the street. A white car is parked along the street. A black SUV is parked along the street. A white SUV is parked along the street."}, "402118": {"image_id": 402118, "Bleu_1": 0.14893617020959712, "Bleu_2": 0.08047040239209732, "Bleu_3": 5.240265333324464e-07, "Bleu_4": 1.3447816950952107e-09, "METEOR": 0.12208524743192073, "ROUGE_L": 0.12508544087491455, "CIDEr": 2.8685777853771277e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15789473684210525, "f": 0.16666666666666669, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures two snowboarders in mid-air, performing jumps on a snow-covered slope. The snowboarders are wearing white outfits and are skillfully riding their snowboards, showcasing their talent and athleticism.\n\nIn the background, there are several other elements that add to the overall atmosphere of the scene."}, "303893": {"image_id": 303893, "Bleu_1": 0.24285714285367346, "Bleu_2": 0.1967647227186476, "Bleu_3": 0.1724021552767976, "Bleu_4": 0.1521117726473331, "METEOR": 0.30220973357934894, "ROUGE_L": 0.2890995260663507, "CIDEr": 1.228613129888714e-18, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.23529411764705882, "f": 0.2857142857142857, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a boy and a girl sitting on a sidewalk, enjoying their lunch together. The boy is eating pizza. The girl is eating a cookie. They are both wearing shorts. The girl is also wearing a bow in her hair.\n\nThe children are eating. They are sitting on the ground. They are enjoying a picnic. The boy and the girl are not wearing a dress and a shirt."}, "491836": {"image_id": 491836, "Bleu_1": 0.3999999999800001, "Bleu_2": 0.25131234496212107, "Bleu_3": 1.5195618441138907e-06, "Bleu_4": 3.790325913312514e-09, "METEOR": 0.24818625172831296, "ROUGE_L": 0.38705583756345174, "CIDEr": 0.12494460667753182, "SPICE": {"All": {"pr": 0.375, "re": 0.18181818181818182, "f": 0.24489795918367344, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.45454545454545453, "f": 0.5555555555555556, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a boat floating on the water. The boat is positioned towards the mountains. The water is blue."}, "456816": {"image_id": 456816, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.1791244302026115, "Bleu_3": 1.0008904723903045e-06, "Bleu_4": 2.3847864361324925e-09, "METEOR": 0.17070034299700104, "ROUGE_L": 0.25979557069846676, "CIDEr": 0.0001963666344595839, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.3333333333333333, "f": 0.36842105263157887, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a dining table with a white plate holding a delicious pastry, possibly a donut. The pastry is placed on the plate. It appears to be a large, round, and fluffy treat."}, "495825": {"image_id": 495825, "Bleu_1": 0.2394366197149375, "Bleu_2": 0.11697047727928543, "Bleu_3": 0.058313325760782346, "Bleu_4": 7.348498842873134e-06, "METEOR": 0.16186783112512756, "ROUGE_L": 0.1556784347086346, "CIDEr": 2.298848281220897e-19, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.06896551724137931, "f": 0.08333333333333333, "fn": 27.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a mountain landscape with snow-capped peaks and a lush green field. The color of the peaks is blue. The field is green. The horses are scattered in the grassy field. They are eating grass in the pasture. Some of the horses are closer to the foreground, while others are further away. The equestrians of St Johns County 0 are further away. There is a fence in the scene."}, "174740": {"image_id": 174740, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.25717224992746507, "Bleu_3": 0.1719893752106008, "Bleu_4": 2.1239349525504125e-05, "METEOR": 0.21348364783120694, "ROUGE_L": 0.20677966101694914, "CIDEr": 0.03321817422140719, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.16666666666666666, "f": 0.2040816326530612, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a dining table with a plastic container filled with sugar-covered donuts. There are five donuts in total. The donuts are covered with sugar and cinnamon."}, "507037": {"image_id": 507037, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.2896048475706757, "Bleu_3": 0.20548413835908225, "Bleu_4": 0.13267656524206944, "METEOR": 0.26922162488518914, "ROUGE_L": 0.4260945490831982, "CIDEr": 0.005042478165615939, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2857142857142857, "f": 0.2727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts a group of eight people gathered outside a building. A large American flag is hanging from the side of the building.\n\nThere are no bicycles in the scene."}, "57323": {"image_id": 57323, "Bleu_1": 0.15294117646878894, "Bleu_2": 0.1128941895710936, "Bleu_3": 0.06746808156143887, "Bleu_4": 7.82294555752499e-06, "METEOR": 0.1713637055880326, "ROUGE_L": 0.17435688035933034, "CIDEr": 4.539436050723728e-36, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.22727272727272727, "f": 0.2857142857142857, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.4, "f": 0.5333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image captures a group of motorcyclists riding down a street, with a total of 11 motorcycles visible. The motorcycles vary in color, power, and style. Some of the motorcycles are Harley Davidsons. \n\nThe riders are spread out along the road, with some closer to the foreground and others further back. There are a total of 8 motorcyclists in the image. The diverse group consists of a man on a green motorcycle and a man on a motorcycle.\n\nThere is no road in the scene."}, "516038": {"image_id": 516038, "Bleu_1": 0.22368421052337256, "Bleu_2": 0.17269789055665585, "Bleu_3": 0.10653391003270866, "Bleu_4": 0.06379478603070379, "METEOR": 0.2366059963244745, "ROUGE_L": 0.1889380530973451, "CIDEr": 8.0196014855805e-27, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.16666666666666666, "f": 0.21276595744680848, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image captures a baseball game in progress. There are two pitchers in the scene. The first pitcher is crouching down to catch a ball and is holding a baseball glove. The second pitcher is preparing to throw the ball and is holding a baseball. Both pitchers are wearing white uniforms. The pitcher is positioned on the mound. There is also a catcher in the scene. \n\nThere is no baseball or other players in the image."}, "433915": {"image_id": 433915, "Bleu_1": 0.1521739130418242, "Bleu_2": 0.09143961949393252, "Bleu_3": 4.529067259715684e-07, "Bleu_4": 1.0107856695385423e-09, "METEOR": 0.1446146978680103, "ROUGE_L": 0.13396778916544655, "CIDEr": 1.8670554259273978e-39, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.23529411764705882, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two men and a woman sitting in front of a television screen. One of the men is wearing a suit and looking at the camera, while the other man is also wearing a suit and looking at the TV. The woman is wearing a red jacket and is engaged in a conversation with the man. The man wearing the suit is the one looking at the TV. The man is wearing a tie, and the woman is wearing glasses.\n\nIn the background, there are no other objects or people."}, "17899": {"image_id": 17899, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.10861276726025744, "Bleu_3": 5.950104277147966e-07, "Bleu_4": 1.3989518286920131e-09, "METEOR": 0.203884496813006, "ROUGE_L": 0.20631341600901915, "CIDEr": 1.1286493165866241e-14, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.12903225806451613, "f": 0.125, "fn": 27.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a woman wearing a green and white striped shirt, standing at a dining table and preparing cookies. She is using a cookie cutter to shape the dough, which is spread out on the table. The table is filled with various baking supplies, including multiple bowls.\n\nThere are a total of nine cookies on the table."}, "298252": {"image_id": 298252, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.18712785740116275, "Bleu_3": 0.15826471143700263, "Bleu_4": 0.13972680638010707, "METEOR": 0.31621426548781145, "ROUGE_L": 0.3231312536786345, "CIDEr": 1.1054889982815365e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.46153846153846156, "f": 0.32432432432432434, "fn": 7.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image showcases a bakery display case filled with a variety of donuts and pastries. There are 19 donuts and 5 pastries on display. The donuts are arranged in rows, with some placed closer to the front and others further back in the display case. The pastries are also arranged neatly in the display case."}, "222370": {"image_id": 222370, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2908872369299581, "Bleu_3": 0.21950939626031343, "Bleu_4": 0.14643937863774928, "METEOR": 0.33032189959852104, "ROUGE_L": 0.375770020533881, "CIDEr": 0.015222236421800983, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.21739130434782608, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image depicts a busy city street with three people riding motorcycles down the sidewalk. The man is riding a motorcycle. The people are riding skateboards."}, "374448": {"image_id": 374448, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.1968748077349065, "Bleu_3": 0.09814438977795428, "Bleu_4": 1.239892724075295e-05, "METEOR": 0.2851119777259571, "ROUGE_L": 0.37770897832817335, "CIDEr": 4.405175419048432e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.18181818181818182, "f": 0.17910447761194032, "fn": 27.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.38461538461538464, "f": 0.3448275862068966, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image depicts a room filled with people sitting at numerous tables. The room is a restaurant. The clock is hanging from the ceiling. The clock is positioned in the middle of the room. The clock is surrounded by a large glass window."}, "181278": {"image_id": 181278, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.25452711673434153, "Bleu_3": 0.16798422674169888, "Bleu_4": 0.12407774144162517, "METEOR": 0.25704197059497336, "ROUGE_L": 0.29756097560975614, "CIDEr": 7.765129707786856e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.19230769230769232, "f": 0.20408163265306123, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a baseball player in the process of throwing a baseball during a game. He is wearing a baseball uniform and is standing on a field, holding the ball in his right hand.\n\nThere are three children on the baseball field."}, "373789": {"image_id": 373789, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1456862718139933, "Bleu_3": 7.618427528743762e-07, "Bleu_4": 1.7513564291613392e-09, "METEOR": 0.16701669080824097, "ROUGE_L": 0.25064569147687255, "CIDEr": 5.2269299307610605e-08, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.2857142857142857, "f": 0.28070175438596495, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a plate placed on a countertop, holding a sandwich and a side of potato chips. The sandwich is cut in half, with one half on the left side of the plate and the other half on the right side. The potato chips are scattered around the sandwich."}, "251124": {"image_id": 251124, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.17541160385696436, "Bleu_3": 9.32061023993367e-07, "Bleu_4": 2.1628820160400856e-09, "METEOR": 0.24360419015577894, "ROUGE_L": 0.263536866359447, "CIDEr": 5.624487572017026e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16666666666666666, "f": 0.19512195121951217, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a bicycle parked on the side of a road. The bicycle's lights are on. The bicycle is positioned near a fence. The city lights can be seen in the background, creating a vibrant and lively atmosphere."}, "162249": {"image_id": 162249, "Bleu_1": 0.1904761904716554, "Bleu_2": 0.1524099856160645, "Bleu_3": 0.10511522304355243, "Bleu_4": 0.07387254484889375, "METEOR": 0.15804255017648722, "ROUGE_L": 0.21631205673758863, "CIDEr": 6.882879719546732e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a bathroom with a modern design. The bathroom has a large, circular stone sink, which is surrounded by a black countertop. The sink does the countertop surround. The bathroom also has a marble countertop, giving it a luxurious look."}, "551908": {"image_id": 551908, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.18136906252429263, "Bleu_3": 0.08425349182907671, "Bleu_4": 1.0258703827568718e-05, "METEOR": 0.19457952010011054, "ROUGE_L": 0.28249459709786967, "CIDEr": 2.508424523175915e-11, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.14285714285714285, "f": 0.21428571428571427, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a plate of food with a variety of vegetables and a fish fillet. The plate is placed on a dining table. The food is arranged in an appealing manner. The vegetables include broccoli, which is scattered across the plate. The vegetables also include carrots, which are also present. A fish is on the plate."}, "366367": {"image_id": 366367, "Bleu_1": 0.5294117646903115, "Bleu_2": 0.45667948248215234, "Bleu_3": 0.3885424823686326, "Bleu_4": 0.339244620328712, "METEOR": 0.3372858286278551, "ROUGE_L": 0.4537190082644628, "CIDEr": 0.000775257825568512, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a girl standing in front of a store. The girl is holding a cell phone in her hand. She appears to be focused on the cell phone, possibly playing a game."}, "231343": {"image_id": 231343, "Bleu_1": 0.3220338982996266, "Bleu_2": 0.21075689485807378, "Bleu_3": 0.11594167605155438, "Bleu_4": 0.07263278116073456, "METEOR": 0.25228420279949954, "ROUGE_L": 0.2799592044875064, "CIDEr": 5.427494965798331e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image captures a baseball game in progress, with a batter standing at home plate, holding a baseball bat and preparing to swing. The batter is wearing a baseball uniform. The batter is surrounded by teammates in the dugout. There are no opponents in the scene.\n\nThere are several other people in the scene, including baseball players and coaches."}, "236290": {"image_id": 236290, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.23124864502453574, "Bleu_3": 0.14951317712512502, "Bleu_4": 1.8120458368313502e-05, "METEOR": 0.23732663604219728, "ROUGE_L": 0.3117546848381601, "CIDEr": 0.0003107662441759906, "SPICE": {"All": {"pr": 0.1875, "re": 0.20689655172413793, "f": 0.19672131147540986, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image features two people in an airport. One person is walking down an escalator, carrying a blue suitcase. The suitcase is positioned behind the person. The other person is walking on a stairway."}, "189095": {"image_id": 189095, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.17504208247906033, "Bleu_3": 0.1322380251708152, "Bleu_4": 0.08166132649570104, "METEOR": 0.20307125986514019, "ROUGE_L": 0.24956165984804207, "CIDEr": 1.0352561310933892e-12, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16666666666666666, "f": 0.2285714285714286, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features two brown bears standing next to each other in a rocky area. They appear to be engaged in a playful interaction, with one bear seemingly biting the other bear's ear. The bears are positioned close to each other, with one on the left side and the other on the right side."}, "426546": {"image_id": 426546, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.36004114989795655, "Bleu_3": 0.2747523533099927, "Bleu_4": 0.17145622411361006, "METEOR": 0.34475671170984545, "ROUGE_L": 0.4274274274274274, "CIDEr": 0.12039798155049054, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.23076923076923078, "f": 0.2790697674418605, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a delicious meal consisting of two sandwiches, french fries, and coleslaw. The sandwiches are cut in half. The meal is placed on a plate."}, "114119": {"image_id": 114119, "Bleu_1": 0.206349206345931, "Bleu_2": 0.1631738460789805, "Bleu_3": 0.09557267762714151, "Bleu_4": 1.0982785524768112e-05, "METEOR": 0.18656095686897048, "ROUGE_L": 0.19495046340683922, "CIDEr": 2.7844746549292233e-17, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.23809523809523808, "f": 0.25641025641025644, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a cat sitting next to a clock on a wall. The cat is positioned on the left side of the clock. The clock is located on the right side of the image. The cat appears to be looking at the clock, possibly curious about the time.\n\nIn addition to the cat and clock, there are two walls in the scene."}, "290828": {"image_id": 290828, "Bleu_1": 0.13978494623505608, "Bleu_2": 0.10313006897343155, "Bleu_3": 0.06160080769737071, "Bleu_4": 0.04014478881141622, "METEOR": 0.15473507585892843, "ROUGE_L": 0.1590316573556797, "CIDEr": 1.5759978684631158e-40, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.35294117647058826, "f": 0.26666666666666666, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a giraffe standing in an enclosure. The giraffe is eating a tree. The giraffe is positioned towards the center of the scene. \n\nThere are several people observing the giraffe from a balcony above the enclosure. \n\nThe people are eating a sandwich, walking on a bridge, squatting down to look at something, taking a picture, sitting on a bench, and riding a bike.\n\nThe overall scene includes a grassy area where the giraffe is standing. There is also a bridge where the people are walking on and observing the giraffe from."}, "64103": {"image_id": 64103, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2094269541404072, "Bleu_3": 0.15263761139761006, "Bleu_4": 0.11855723022764682, "METEOR": 0.26009861166834086, "ROUGE_L": 0.3287143956889915, "CIDEr": 1.8620413907181608e-06, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.2916666666666667, "f": 0.34146341463414637, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features two birds, possibly ducks, swimming together in a body of water. They are positioned close to each other, with one bird slightly ahead of the other. The birds are making a heart shape with their beaks."}, "194756": {"image_id": 194756, "Bleu_1": 0.1940298507433727, "Bleu_2": 0.15335830524206745, "Bleu_3": 0.07125801957426106, "Bleu_4": 8.671222248759092e-06, "METEOR": 0.2379699137743066, "ROUGE_L": 0.21233217304823468, "CIDEr": 1.1050265707973907e-19, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.30434782608695654, "f": 0.2692307692307692, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a boat floating on a river. The boat is positioned in the water. A man in a blue shirt is driving the boat. The man is sitting in the driver's seat. \n\nThere are twelve people in the scene. Some of the people are sitting on a boat. Some of the people are sitting on a bench. \n\nThere is no riverbank in the scene."}, "412879": {"image_id": 412879, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.24836183164306555, "Bleu_3": 0.18218943070465532, "Bleu_4": 0.10486966556129235, "METEOR": 0.31903284446311025, "ROUGE_L": 0.28103661044837513, "CIDEr": 2.4842631592660025e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a woman standing on a tennis court. She is holding a tennis racket and preparing to hit a tennis ball. The woman is playing tennis. She is wearing a black outfit and appears to be in the middle of a game. The tennis ball is about to hit the woman."}, "51741": {"image_id": 51741, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.2560199571978607, "Bleu_3": 0.1257026887176931, "Bleu_4": 1.5784140234610454e-05, "METEOR": 0.2643403864561914, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.00064386724002689, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.46153846153846156, "f": 0.3870967741935484, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a bathroom with a toilet and a sink. The toilet is positioned in the corner. The sink is located in the bathroom. The sink is a small, white basin with a faucet."}, "111448": {"image_id": 111448, "Bleu_1": 0.21917808218877838, "Bleu_2": 0.12337220169789911, "Bleu_3": 5.984925663491676e-07, "Bleu_4": 1.3228772884434655e-09, "METEOR": 0.13997579619087397, "ROUGE_L": 0.1891891891891892, "CIDEr": 7.176689086445868e-23, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features three men in a grassy field. One man is riding a horse, another man is leading a horse, and the third man is running with a horse. The horse is black and is wearing a jockey's hat. The man leading the horse is holding a rope. There are also four other people in the scene, some of them standing close to the horse and others scattered around the field."}, "255279": {"image_id": 255279, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.09701425001261196, "Bleu_3": 5.76976768606882e-07, "Bleu_4": 1.4143550190666944e-09, "METEOR": 0.18219239211688218, "ROUGE_L": 0.25553560742070613, "CIDEr": 6.632024028677907e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a black motorcycle parked on a street, surrounded by various items. There are several helmets scattered around the motorcycle, with some placed closer to the front and others further away. A white opel corsa and a black car are parked nearby.\n\nThere is no truck in the scene."}, "243626": {"image_id": 243626, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.21797089763394864, "Bleu_3": 0.15606146188116843, "Bleu_4": 0.09384750542850123, "METEOR": 0.2255908544733607, "ROUGE_L": 0.2760180995475113, "CIDEr": 1.2439750566457785e-09, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a plate with a delicious meal consisting of a large piece of meat, green beans, and a side of polenta. A fork is next to the plate. \n\nThere is no dining table in the scene. There is no glass in the scene. There is no water in the scene."}, "171255": {"image_id": 171255, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.10174919922777484, "Bleu_4": 1.2738938828213386e-05, "METEOR": 0.15152613550244645, "ROUGE_L": 0.24286662242866625, "CIDEr": 1.870166149550299e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2857142857142857, "f": 0.2580645161290323, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a beach with two umbrellas set up on the sand. One of the umbrellas is located on the left side of the beach, while the other is situated towards the center. There are no people or beachgoers in the scene."}, "41119": {"image_id": 41119, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.23473823892604287, "Bleu_3": 0.17904635481650877, "Bleu_4": 0.13835025436702314, "METEOR": 0.33891426443511896, "ROUGE_L": 0.37888198757763975, "CIDEr": 7.53450352264318e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.2, "f": 0.17142857142857143, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a traffic light hanging from the side of a tall building, with the light currently displaying a green signal. The traffic light is positioned in front of a tall building. Its presence adds a unique touch to the urban landscape.\n\nThere is no person in the scene."}}}