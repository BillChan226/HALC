{"overall": {"Bleu_1": 0.2757060140938957, "Bleu_2": 0.18365245144594705, "Bleu_3": 0.114057540426483, "Bleu_4": 0.0695409659517181, "METEOR": 0.22202942227326594, "ROUGE_L": 0.27839496101704186, "CIDEr": 0.013340491689985249, "SPICE": 0.20907513220779617}, "imgToEval": {"504142": {"image_id": 504142, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.1332650098148157, "Bleu_3": 0.06701830194835842, "Bleu_4": 8.487661803821794e-06, "METEOR": 0.17514578673591566, "ROUGE_L": 0.21953727506426737, "CIDEr": 1.6325975116041698e-15, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.1724137931034483, "f": 0.2439024390243903, "fn": 24.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a dog sleeping peacefully on a bed, covered by a blanket. The dog is positioned in the middle of the bed, taking up a significant portion of the space. The bed appears to be a cozy and comfortable spot for the dog to rest. The dog is sleeping on a couch. The dog is positioned under the pillows."}, "49115": {"image_id": 49115, "Bleu_1": 0.25806451612070763, "Bleu_2": 0.1854955582979839, "Bleu_3": 0.10586596094056361, "Bleu_4": 1.434755010621989e-05, "METEOR": 0.279573620114182, "ROUGE_L": 0.31448702526207256, "CIDEr": 0.003948380128173172, "SPICE": {"All": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a giraffe standing on a rock, possibly in a zoo enclosure. The giraffe is eating leaves and looking at a tree. The tree provides food for the giraffe."}, "328284": {"image_id": 328284, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.09087496586948689, "Bleu_4": 1.1854610697110774e-05, "METEOR": 0.24424345231142558, "ROUGE_L": 0.3083032490974729, "CIDEr": 3.94560872149349e-07, "SPICE": {"All": {"pr": 0.24242424242424243, "re": 0.25806451612903225, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 8.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.7, "f": 0.6363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image features a person wearing a purple jacket, standing on a snowy path in the woods. The person is holding ski poles and appears to be doing skiing. The person is positioned towards the trees and is surrounded by snow."}, "434662": {"image_id": 434662, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1030922854689151, "Bleu_3": 6.227779385649834e-07, "Bleu_4": 1.5395110158669013e-09, "METEOR": 0.15316697124817105, "ROUGE_L": 0.16553595658073267, "CIDEr": 2.2646154171594376e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image captures a person riding a snowboard down a snow-covered slope, skillfully navigating the terrain. The snowboarder is wearing a blue shirt and appears to be enjoying the thrill of the ride. The snowboard is visible beneath the person. The snowboarder is bending his knees."}, "307166": {"image_id": 307166, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.19287918744957724, "Bleu_3": 0.12164663509311688, "Bleu_4": 1.3106677591843726e-05, "METEOR": 0.1900055145279832, "ROUGE_L": 0.2722442618305469, "CIDEr": 1.1022180286182424e-15, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.35294117647058826, "f": 0.2790697674418605, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a table with a lot of pizzas on it. One pizza on a tray is covered in cheese and pepperoni. Another pizza on a tray is covered in cheese and tomato sauce, with shredded cheese on top.\n\nThere is also a bottle on the table, which might contain rum, gin, vodka, or other beverages.\n\nOverall, the table is filled with pizzas."}, "386352": {"image_id": 386352, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.08268590713763764, "Bleu_4": 1.0646588104479637e-05, "METEOR": 0.2322970344306699, "ROUGE_L": 0.31579920495516317, "CIDEr": 4.238478162741535e-09, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.21739130434782608, "f": 0.23809523809523808, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a female tennis player in action, swinging her racket and preparing to hit the ball. She is focused and determined, with her tennis racket held up in the air. The scene takes place on a tennis court. There are several people watching the match."}, "74059": {"image_id": 74059, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.14540168172223333, "Bleu_3": 0.07954810829018738, "Bleu_4": 1.0526316596948142e-05, "METEOR": 0.20283816006080255, "ROUGE_L": 0.2787206266318538, "CIDEr": 1.7688235547051862e-07, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a clock tower made of tall bricks. There is a clock on each side of the tower, making it easy to see the time from various angles. The tower is adorned with a coat of arms, adding to its architectural beauty."}, "466882": {"image_id": 466882, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.15541746803663614, "Bleu_3": 8.188084718265141e-07, "Bleu_4": 1.8902516755213052e-09, "METEOR": 0.1492488910947004, "ROUGE_L": 0.16158940397350993, "CIDEr": 5.4952639856342355e-09, "SPICE": {"All": {"pr": 0.35, "re": 0.25, "f": 0.2916666666666667, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a tennis match in progress on a blue court. There are two players actively engaged in the game. The players are spread across the court, with some closer to the net and others further back. There are two additional players on the court."}, "264124": {"image_id": 264124, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.16314309133869306, "Bleu_4": 0.11721806731881168, "METEOR": 0.25675736389869236, "ROUGE_L": 0.26940063091482647, "CIDEr": 1.6708320214248445e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.1875, "f": 0.19354838709677422, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man with a beard talking on a cell phone. He is standing in a kitchen and appears to be engaged in a conversation. The man is holding the cell phone to his ear, and his facial expression suggests that he is focused on the conversation."}, "92205": {"image_id": 92205, "Bleu_1": 0.3448275862009513, "Bleu_2": 0.25796448307633496, "Bleu_3": 0.16813724690537885, "Bleu_4": 0.11466074929466666, "METEOR": 0.2795949627311008, "ROUGE_L": 0.3254122211445199, "CIDEr": 2.4667893819291212e-11, "SPICE": {"All": {"pr": 0.28, "re": 0.3888888888888889, "f": 0.32558139534883723, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a man holding a stop sign on a street corner. He is standing next to a traffic cone. The man is wearing a hard hat and a safety vest, indicating that he is a construction worker. \n\nThe stop sign is positioned in the middle of the road. On the road is the traffic cone located."}, "34071": {"image_id": 34071, "Bleu_1": 0.6666666665555557, "Bleu_2": 0.49236596383340503, "Bleu_3": 0.3646436716648588, "Bleu_4": 4.817712540105097e-05, "METEOR": 0.3226384582107314, "ROUGE_L": 0.5313588850174217, "CIDEr": 0.8032301974534996, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.19047619047619047, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features two parking meters. A street is in the background."}, "555066": {"image_id": 555066, "Bleu_1": 0.23749999999703125, "Bleu_2": 0.14506654954516193, "Bleu_3": 6.46169795187773e-07, "Bleu_4": 1.3681613218993358e-09, "METEOR": 0.22013872711772375, "ROUGE_L": 0.2471636952998379, "CIDEr": 1.119934919319e-28, "SPICE": {"All": {"pr": 0.25, "re": 0.19230769230769232, "f": 0.2173913043478261, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image does not depict a street corner. There are six traffic lights hanging above the street. The traffic lights include a large yellow light, a yellow light, and a green light. The Syracuse City Council's new traffic light is also hanging above the street. \n\nThere are two cars parked along the street. The car on the left side is silver and the car on the right side is blue. \n\nThere is no street or truck in the scene."}, "448786": {"image_id": 448786, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.22941573386460196, "Bleu_3": 0.11246435365320531, "Bleu_4": 1.4098910172173328e-05, "METEOR": 0.21354429908426828, "ROUGE_L": 0.24148851939825808, "CIDEr": 4.10392659475731e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2222222222222222, "f": 0.22857142857142856, "fn": 28.0, "numImages": 1.0, "fp": 26.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.3333333333333333, "f": 0.3448275862068965, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image features a white bullet train parked at a station. The bullet train is positioned on the tracks. The train appears to be a modern, high-speed vehicle designed for efficient transportation.\n\nThere are no people in the image."}, "324308": {"image_id": 324308, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.0956600132176177, "Bleu_4": 1.248740514185277e-05, "METEOR": 0.24568845774127807, "ROUGE_L": 0.2347959969207082, "CIDEr": 2.640279142598793e-06, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16666666666666666, "f": 0.19607843137254902, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features four green bananas hanging from a wooden fence. The bananas are arranged in various positions, with some closer to the top of the fence and others near the bottom. The fence is located in a backyard."}, "42837": {"image_id": 42837, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.22019275302032337, "Bleu_3": 0.15011345265055326, "Bleu_4": 0.11265744222457875, "METEOR": 0.26076145264493805, "ROUGE_L": 0.2742453436095055, "CIDEr": 1.7987597997840081e-07, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.03333333333333333, "f": 0.04761904761904761, "fn": 29.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image features a man riding a surfboard on a wave. The man is skillfully balancing on the surfboard, showcasing his surfing abilities. The wave is large and powerful, providing an exciting experience for the surfer.\n\nThere is no body of water in the scene."}, "314690": {"image_id": 314690, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.21470745394187096, "Bleu_3": 0.10007189813274588, "Bleu_4": 1.2216054866635076e-05, "METEOR": 0.24684875008683643, "ROUGE_L": 0.270595690747782, "CIDEr": 2.3749586832190427e-08, "SPICE": {"All": {"pr": 0.4090909090909091, "re": 0.34615384615384615, "f": 0.37500000000000006, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 9.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image is a collage of two living rooms. The first living room features a couch, a chair, and a TV. The second living room features a laptop. \n\nThere are no books in the scene.\n\nThe living rooms are part of a larger room, with a floor visible."}, "263780": {"image_id": 263780, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.15849534045439814, "Bleu_3": 0.08295835031586613, "Bleu_4": 1.0734404745305494e-05, "METEOR": 0.2095200378471904, "ROUGE_L": 0.1927939317319848, "CIDEr": 3.220926239485535e-08, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.26666666666666666, "f": 0.28571428571428575, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features two elephants standing on a dirt ground near a body of water. The mother elephant is positioned in the foreground, while the baby elephant is standing close to her, possibly nursing. The baby elephant is smaller in size compared to the mother elephant."}, "256035": {"image_id": 256035, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.191273013914278, "Bleu_3": 0.14118482396355853, "Bleu_4": 0.11031958317495014, "METEOR": 0.34515039693715593, "ROUGE_L": 0.3617494440326167, "CIDEr": 2.507597206826121e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.10344827586206896, "f": 0.11320754716981132, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a person wearing a black and white ski suit, skiing down a snow-covered slope. The person is holding ski poles, which they use to help them ski. The skier appears to be in motion, enjoying the winter sport."}, "413900": {"image_id": 413900, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.21693045781436016, "Bleu_3": 0.1566155905072522, "Bleu_4": 0.1124795146748506, "METEOR": 0.22239791195941241, "ROUGE_L": 0.26704190118824267, "CIDEr": 2.2129709407632588e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.14814814814814814, "f": 0.18604651162790697, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image depicts a group of seven people gathered in a room. The people are playing a video game. Some of the people are talking to each other. A person is holding a gun. The people are focused on playing a video game.\n\nThere is no television screen in the scene."}, "357978": {"image_id": 357978, "Bleu_1": 0.1976744186023526, "Bleu_2": 0.10783277320217717, "Bleu_3": 0.05172979462830762, "Bleu_4": 6.3905177075362625e-06, "METEOR": 0.17961430943470466, "ROUGE_L": 0.1417505809450039, "CIDEr": 2.600317295980041e-33, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.25, "f": 0.32558139534883723, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image features two women standing in a room. The first woman is holding a Wii remote and playing a game. The second woman is also holding a Wii remote and playing a video game. The first woman is wearing a red and white checkered shirt. \n\nThere are two people in the image. The first person is standing in front of a white couch. The second person is standing on a red carpet.\n\nThe overall scene shows the women standing in front of a white board."}, "521874": {"image_id": 521874, "Bleu_1": 0.2666666666622222, "Bleu_2": 0.1344585290883029, "Bleu_3": 6.780310347459483e-07, "Bleu_4": 1.5292147053878781e-09, "METEOR": 0.220171132569877, "ROUGE_L": 0.1967741935483871, "CIDEr": 3.406807477560769e-15, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.11538461538461539, "f": 0.13953488372093026, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a train traveling down the tracks. The train is blue and red. It appears to be a model train, as it is not a real-life train. The train is situated in the middle of the scene. \n\nThere are four houses in the scene. \n\nThere is also a bench nearby, and a train is passing by the bench."}, "49517": {"image_id": 49517, "Bleu_1": 0.28124999999560546, "Bleu_2": 0.2004459314311615, "Bleu_3": 0.10902956158180029, "Bleu_4": 1.2073293004110342e-05, "METEOR": 0.23455274135164714, "ROUGE_L": 0.2401574803149606, "CIDEr": 9.645096681864995e-18, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a kitchen with a stove top oven and a stove top burner. The oven is filled with pots and pans. There is a pot of water on the left side of the stove top, and another pot of water on the right side of the stove top. \n\nThere are three pans in the kitchen. \n\nThere is no counter in the kitchen."}, "67616": {"image_id": 67616, "Bleu_1": 0.2531645569588207, "Bleu_2": 0.09867673659199108, "Bleu_3": 5.01933609540321e-07, "Bleu_4": 1.1357462452759417e-09, "METEOR": 0.1528980220629493, "ROUGE_L": 0.18147046323841903, "CIDEr": 1.3596796972274985e-26, "SPICE": {"All": {"pr": 0.2, "re": 0.1875, "f": 0.19354838709677422, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image depicts a busy city street with a row of dining tables and chairs set up outside of three buildings. The tables and chairs are arranged in front of the buildings, creating a lively outdoor dining area. Several people are sitting at the tables, enjoying their meals and conversations. A parking meter is set up outside of one of the buildings. A tree is in front of another building. A sidewalk is in front of the third building."}, "154071": {"image_id": 154071, "Bleu_1": 0.2615384615344379, "Bleu_2": 0.15658617681158973, "Bleu_3": 0.09198819470261023, "Bleu_4": 1.0585250729039836e-05, "METEOR": 0.17969225415180817, "ROUGE_L": 0.2190867111339148, "CIDEr": 5.795693310631128e-18, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.21428571428571427, "f": 0.20338983050847456, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6, "f": 0.48, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image captures a baseball game in progress. The batter is at home plate, holding a baseball bat and preparing to swing at the ball. The catcher is positioned behind the batter, ready to catch the ball. The umpire is a baseball umpire, standing nearby and closely observing the play.\n\nThere is no ball in the image.\n\nThere are no other players in the scene."}, "351133": {"image_id": 351133, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.22086305214437035, "Bleu_3": 0.10683872974724744, "Bleu_4": 1.329781801325677e-05, "METEOR": 0.2806569239350619, "ROUGE_L": 0.3292847503373819, "CIDEr": 1.2100373626629363e-06, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2916666666666667, "f": 0.2916666666666667, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a woman standing in a bathroom, brushing her teeth with a toothbrush. She is wearing a black shirt and appears to be smiling while brushing her teeth. The bathroom has a mirror.\n\nThere is no sink in the scene."}, "270165": {"image_id": 270165, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.32796802466680686, "Bleu_3": 0.21384057212126054, "Bleu_4": 0.13221480419997017, "METEOR": 0.2547571530785736, "ROUGE_L": 0.34574898785425096, "CIDEr": 0.0011682173526386822, "SPICE": {"All": {"pr": 0.3, "re": 0.13043478260869565, "f": 0.18181818181818182, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a pink poodle hanging from a chain outside a building. The poodle is positioned in front of a red cow. The poodle appears to be a cow. The building has three windows."}, "200250": {"image_id": 200250, "Bleu_1": 0.19587628865777446, "Bleu_2": 0.10100440601356367, "Bleu_3": 4.7531955029371863e-07, "Bleu_4": 1.0338494350586613e-09, "METEOR": 0.15240957998028576, "ROUGE_L": 0.15136476426799003, "CIDEr": 2.2737932884773198e-42, "SPICE": {"All": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a woman walking down a city street. The woman is walking on the sidewalk. She is passing by two trucks. One truck has a political advertisement promoting \"Get out of the U.S.\" on its side, while the other truck has a large image of a man promoting a campaign to get rid of the UN.\n\nThere are six people in the scene. Some of them are walking down the street, while others are riding a bike. A man in uniform is looking at the camera, and another man is also looking at the camera."}, "302990": {"image_id": 302990, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.1399708424419251, "Bleu_3": 0.10698389124379477, "Bleu_4": 1.2704697475936369e-05, "METEOR": 0.21930314468743783, "ROUGE_L": 0.27128335451080055, "CIDEr": 2.787840794451484e-10, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}}, "caption": "The image captures a thrilling scene of a surfer riding a wave in the ocean. The surfer is riding a surfboard and skillfully doing surfing. In the background, there is another surfer riding a wave. The scene is filled with excitement as the surfers enjoy the ride on the waves."}, "147425": {"image_id": 147425, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.2786053978963903, "Bleu_3": 0.1729667391512128, "Bleu_4": 2.055286875687254e-05, "METEOR": 0.22546476119037434, "ROUGE_L": 0.2803308823529412, "CIDEr": 0.0006261493481924789, "SPICE": {"All": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image features a brown and black cat sitting on a chair. The cat is standing on a black surface. The cat's eyes are focused on the side of the suitcase."}, "152245": {"image_id": 152245, "Bleu_1": 0.23749999999703125, "Bleu_2": 0.14506654954516193, "Bleu_3": 6.46169795187773e-07, "Bleu_4": 1.3681613218993358e-09, "METEOR": 0.1759567135492842, "ROUGE_L": 0.1734362307067425, "CIDEr": 4.964570386366643e-28, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2727272727272727, "f": 0.24489795918367346, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image depicts an airport with people standing in line, waiting for a plane. Some of the people are putting luggage in a cart, while others are looking at a laptop or talking to each other. Some people are smiling, and some are talking on the phone. Some people are eating, and some are carrying luggage. People with luggage can be seen in the airport.\n\nThere are several suitcases and backpacks scattered throughout the scene, some placed on the floor."}, "191689": {"image_id": 191689, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.15740004692952608, "Bleu_3": 8.91211038234751e-07, "Bleu_4": 2.1360710219633343e-09, "METEOR": 0.16361895321489153, "ROUGE_L": 0.1898832684824903, "CIDEr": 1.0331846607165808e-05, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3333333333333333, "f": 0.34285714285714286, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features two brown bears standing in a grassy field. The bears are standing in tall grass and appear to be looking at something in the field. There is no fence or metal in the scene."}, "51484": {"image_id": 51484, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.4309458036646331, "Bleu_3": 0.2693853056790028, "Bleu_4": 3.228213879874089e-05, "METEOR": 0.342432295456569, "ROUGE_L": 0.4135593220338983, "CIDEr": 0.15658887616234912, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.20833333333333334, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a sandy beach with a group of three people walking along the shore. The people are carrying surfboards."}, "66181": {"image_id": 66181, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.12591131218362533, "Bleu_3": 7.407783780750936e-07, "Bleu_4": 1.8085075412663418e-09, "METEOR": 0.15774251354203106, "ROUGE_L": 0.25756509500351865, "CIDEr": 1.6522916659440036e-06, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.1, "f": 0.10256410256410256, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a table with a vase filled with flowers placed on it. The flowers are white and green in color. A framed picture depicting a drawing of a dog and two children is positioned near the vase of flowers."}, "289263": {"image_id": 289263, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.33733960415104003, "Bleu_3": 0.23296859695472077, "Bleu_4": 2.4516362094067228e-05, "METEOR": 0.31904649025841464, "ROUGE_L": 0.3259541984732824, "CIDEr": 3.9071117833876356e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a woman standing on a beach. She is holding a surfboard and wearing a bikini. The woman is posing for a photo. The surfboard is positioned on the beach. The ocean is in the background."}, "536426": {"image_id": 536426, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.28729720244901713, "Bleu_3": 0.22981831024592703, "Bleu_4": 0.16469009660616415, "METEOR": 0.29574781290678265, "ROUGE_L": 0.38730158730158726, "CIDEr": 0.00017594582074956848, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2608695652173913, "f": 0.19672131147540983, "fn": 17.0, "numImages": 1.0, "fp": 32.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35294117647058826, "re": 0.6, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}}, "caption": "The image features a fire hydrant and a traffic cone sitting on the side of the road. The traffic cones are placed in a circle. The fire hydrant is located on the side of the road."}, "377814": {"image_id": 377814, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.10767638040926633, "Bleu_3": 6.411053581337095e-07, "Bleu_4": 1.573366652415358e-09, "METEOR": 0.18228251303480483, "ROUGE_L": 0.2581620314389359, "CIDEr": 1.3714206935504205e-05, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.30434782608695654, "f": 0.35, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.625, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a box filled with six different donuts. The donuts include chocolate, chocolate frosted, chocolate frosted, chocolate frosted, chocolate frosted, and chocolate.\n\nThere are no other donuts in the scene.\n\nThe donuts come in different shapes and sizes, showcasing a diverse selection for customers."}, "411754": {"image_id": 411754, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.19794866371815809, "Bleu_3": 0.13479125657772084, "Bleu_4": 0.10103674020452826, "METEOR": 0.29574522271011283, "ROUGE_L": 0.3100381194409149, "CIDEr": 1.2338838161906548e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.10714285714285714, "f": 0.13333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man wearing glasses and a red shirt, sitting in a chair and looking at his cell phone. He appears to be texting or browsing the internet on his phone. The man is surrounded by several other people, some of whom are also using their cell phones."}, "340034": {"image_id": 340034, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.1556997888288053, "Bleu_3": 0.10408285482696128, "Bleu_4": 0.07198169585141746, "METEOR": 0.19390155602417114, "ROUGE_L": 0.24177566389219182, "CIDEr": 8.060675192573749e-08, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.22727272727272727, "f": 0.25641025641025644, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a girl sitting on a toilet in a bathroom. The girl is looking at a cell phone and appears to be absorbed in it. The phone screen displays a black screen with a white logo.\n\nIn the background, there is no sink."}, "193050": {"image_id": 193050, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.11485555942835955, "Bleu_4": 0.07312149273625368, "METEOR": 0.3030478038491395, "ROUGE_L": 0.2830626450116009, "CIDEr": 1.3362490407441754e-13, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09090909090909091, "f": 0.0975609756097561, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features a group of six sheep grazing in a grassy field. Some of the sheep are near the center and some are near the edges. The sheep are grazing on grass. Some sheep are standing, some are laying down, and some are eating grass. There is a black and white lamb among the sheep."}, "217269": {"image_id": 217269, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.25226248954908703, "Bleu_3": 0.1808973883271828, "Bleu_4": 0.12957445742199625, "METEOR": 0.2976143566354979, "ROUGE_L": 0.34536447275300775, "CIDEr": 5.160027602044681e-07, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.1935483870967742, "f": 0.26666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.46153846153846156, "f": 0.5714285714285714, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a desk with a computer setup on it. A desktop computer, including a monitor, keyboard, and mouse, is placed on the desk. The monitor is positioned towards the left side of the desk. The keyboard and mouse are located on the desk."}, "437290": {"image_id": 437290, "Bleu_1": 0.33333333331944454, "Bleu_2": 0.2407717061612882, "Bleu_3": 0.17402276781744533, "Bleu_4": 2.2382043226318267e-05, "METEOR": 0.2507529881306639, "ROUGE_L": 0.4621212121212121, "CIDEr": 0.02136074491751134, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15789473684210525, "f": 0.18181818181818182, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a lively scene of a group of 20 people gathered in a room. They are engaged in conversations and enjoying themselves."}, "282928": {"image_id": 282928, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.11527808353813424, "Bleu_3": 6.869153367854085e-07, "Bleu_4": 1.6871838589262224e-09, "METEOR": 0.18618604003444245, "ROUGE_L": 0.25189263592567107, "CIDEr": 2.0097031979966173e-07, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.14814814814814814, "f": 0.2, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a man wearing glasses, who is sitting down and enjoying a hot dog. He is holding the hot dog in his hand and appears to be taking a bite. The hot dog is placed in the center of the scene."}, "188084": {"image_id": 188084, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2132007163490489, "Bleu_3": 0.11360703054848365, "Bleu_4": 1.486872032585981e-05, "METEOR": 0.23226247480350926, "ROUGE_L": 0.27403414195867026, "CIDEr": 0.0004866515375422937, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a sub sandwich placed on a table. The sandwich is cut in half, making it easier to eat. There is a cup next to the sub sandwich, which contains coffee."}, "552320": {"image_id": 552320, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.16094080478419465, "Bleu_3": 0.08318402702711739, "Bleu_4": 1.0694655186909581e-05, "METEOR": 0.21066572268755557, "ROUGE_L": 0.30367143746110764, "CIDEr": 3.123468534660652e-08, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.26666666666666666, "f": 0.33333333333333337, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.8571428571428571, "re": 0.5454545454545454, "f": 0.6666666666666665, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}}, "caption": "The image features one man standing in a kitchen, wearing a red shirt. He is holding a large pizza, which is placed on a dining table in front of him. The pizza appears to be a homemade creation, and the man seems to be excited about it."}, "530313": {"image_id": 530313, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.16922831695751037, "Bleu_3": 0.10016140397870642, "Bleu_4": 1.157386189545469e-05, "METEOR": 0.21304912359225847, "ROUGE_L": 0.2010326266066132, "CIDEr": 1.3575824024949652e-14, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.23809523809523808, "f": 0.25641025641025644, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a group of ten people sitting together in a room. They are sitting on a bench. Some of the people are sitting in a row, while others are sitting in a crowd. Some are sitting at a table, and others are sitting closer to the front. Some people are eating, reading, or engaged in other activities."}, "242060": {"image_id": 242060, "Bleu_1": 0.4374999999863282, "Bleu_2": 0.23759548164820116, "Bleu_3": 0.12345775254393487, "Bleu_4": 1.5960234775441824e-05, "METEOR": 0.3039015327285465, "ROUGE_L": 0.3078734858681023, "CIDEr": 0.0010037589644758007, "SPICE": {"All": {"pr": 0.2, "re": 0.3076923076923077, "f": 0.24242424242424246, "fn": 9.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a table set with a variety of food and drinks. There are several cakes on a plate. A teapot is also present on the table, along with a spoon."}, "391214": {"image_id": 391214, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.2148344622063902, "Bleu_3": 0.10669435290940496, "Bleu_4": 1.3460328045659332e-05, "METEOR": 0.19692545447280219, "ROUGE_L": 0.30587392550143266, "CIDEr": 2.9113585921836244e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a surfer riding a wave in the ocean. The surfer is positioned in the middle of the wave. The surfer is riding a surfboard. The ocean is filled with white-capped waves, creating a dynamic and exciting atmosphere."}, "482367": {"image_id": 482367, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.13453455879664997, "Bleu_3": 7.126876576918604e-07, "Bleu_4": 1.6486383890708068e-09, "METEOR": 0.21910626523178542, "ROUGE_L": 0.23669623059866962, "CIDEr": 2.2767118834250557e-10, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2608695652173913, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image features two men sitting on chairs. They are both wearing tennis outfits and holding tennis rackets. They appear to be taking a break from playing tennis, possibly during a match. One chair is located on the court and the other chair is located on the other side of the court."}, "402334": {"image_id": 402334, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.14757569038041785, "Bleu_3": 0.09196527459886805, "Bleu_4": 1.0905039213056379e-05, "METEOR": 0.1616118687688534, "ROUGE_L": 0.2406989853438557, "CIDEr": 1.1176380790324997e-15, "SPICE": {"All": {"pr": 0.1875, "re": 0.1, "f": 0.13043478260869568, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a clock tower with a steeple, situated on top of a brick building. A clock is prominently displayed on the tower, with the hands on the clock face indicating the time. The tower is adorned with a cross. The brick building is made of clay bricks.\n\nThere is no other architectural beauty in the scene."}, "469398": {"image_id": 469398, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.28867513458592853, "Bleu_3": 0.23776195046624574, "Bleu_4": 0.19147265797760177, "METEOR": 0.3881279289037781, "ROUGE_L": 0.43675417661097854, "CIDEr": 0.003744379099458718, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.16, "f": 0.14285714285714285, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image features a man holding a cell phone in his hand, possibly taking a picture of a baby. The baby is sleeping on a bed. The man is standing in the hospital."}, "316648": {"image_id": 316648, "Bleu_1": 0.15999999999786668, "Bleu_2": 0.10397504898061158, "Bleu_3": 5.29068374961099e-07, "Bleu_4": 1.1975695025264491e-09, "METEOR": 0.18615751952016515, "ROUGE_L": 0.11280628756356914, "CIDEr": 6.226583129266833e-26, "SPICE": {"All": {"pr": 0.4375, "re": 0.3181818181818182, "f": 0.3684210526315789, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8571428571428571, "f": 0.75, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image depicts a busy city street with a group of people walking down the sidewalk. There are at least five people visible in the scene, with some of them carrying backpacks. One person is wearing a backpack on their back, while another person has a backpack. The people are carrying bags. Three many people are visible in the scene. The person is wearing a backpack on his back. The other person has a backpack."}, "254004": {"image_id": 254004, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.24494897426831577, "Bleu_3": 0.13766001253722115, "Bleu_4": 1.855667592931768e-05, "METEOR": 0.3042191284248097, "ROUGE_L": 0.26725082146768897, "CIDEr": 0.022015475317365057, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts three men working together to load luggage onto a bus. The men are wearing orange safety vests. They are likely airport workers."}, "399369": {"image_id": 399369, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.22792115290866924, "Bleu_3": 0.13746108160529513, "Bleu_4": 1.9228544752192987e-05, "METEOR": 0.22715351853099833, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.09454261425307611, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.22580645161290322, "f": 0.2545454545454545, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a boy playing with two frisbees on the beach. The boy is running on the beach, holding a frisbee."}, "206838": {"image_id": 206838, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.36115755924124826, "Bleu_3": 0.26511346924327256, "Bleu_4": 0.17470942956955962, "METEOR": 0.2785785367068738, "ROUGE_L": 0.39144385026737966, "CIDEr": 0.12252088162722011, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2, "f": 0.25925925925925924, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.4166666666666667, "f": 0.5263157894736842, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features two women riding horses through a body of water. They are both wearing bikinis, enjoying their time on the horses."}, "146672": {"image_id": 146672, "Bleu_1": 0.05714285714204083, "Bleu_2": 0.028777723153033636, "Bleu_3": 2.300742328551103e-07, "Bleu_4": 6.529535483154132e-10, "METEOR": 0.12145606563486198, "ROUGE_L": 0.0867298578199052, "CIDEr": 2.627101535605328e-22, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.25, "f": 0.27027027027027023, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features three clocks in different positions. The first clock is on the table. In the background is the second clock. In the background is the third clock. The first clock is on the left. In the background is the second clock. In the middle is the third clock. The top is the first clock. The second clock is on the right. The third clock is in the middle."}, "431256": {"image_id": 431256, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.23260756692519305, "Bleu_3": 0.1349817327318928, "Bleu_4": 1.5464615808906712e-05, "METEOR": 0.24277956802894327, "ROUGE_L": 0.25452016689847007, "CIDEr": 5.1938543844504355e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.19230769230769232, "f": 0.19607843137254902, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image captures a snowy scene with a person riding a snowboard on a snow-covered slope. The snowboarder is in the air, performing a trick. A snow-covered ground is visible underneath the snowboarder, and a snow-covered hill is visible underneath the snowboarder. The snowboarder is skilled."}, "506454": {"image_id": 506454, "Bleu_1": 0.39215686273740874, "Bleu_2": 0.2343116744469622, "Bleu_3": 0.14979742339481708, "Bleu_4": 0.09147827112062706, "METEOR": 0.273512280912579, "ROUGE_L": 0.36329182458040066, "CIDEr": 2.3308253143782367e-07, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.25, "f": 0.2592592592592593, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5454545454545454, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a park with a wooden bench situated in the middle of a grassy area. The bench is surrounded by a mulch bed, which adds a touch of greenery to the scene. The bench is positioned under a tree, providing shade and a comfortable spot for visitors to relax."}, "212384": {"image_id": 212384, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.20159462811746034, "Bleu_3": 1.1460354422397831e-06, "Bleu_4": 2.758387014275457e-09, "METEOR": 0.20211174440351237, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.003681759604949677, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.14285714285714285, "f": 0.13559322033898305, "fn": 24.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a cake with a safari theme, placed on a dining table. The cake is decorated with giraffe-related decorations, including a giraffe head and a giraffe tail."}, "181969": {"image_id": 181969, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.11624763874063387, "Bleu_3": 0.07281710555786126, "Bleu_4": 1.0322985794503843e-05, "METEOR": 0.19219693090488116, "ROUGE_L": 0.2514427040395713, "CIDEr": 6.406825258738184e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a brown cat curled up and sleeping on a couch. The cat is positioned on the couch. The cat appears to be resting peacefully, taking up a significant portion of the couch's surface."}, "450889": {"image_id": 450889, "Bleu_1": 0.2985074626821118, "Bleu_2": 0.25163418847683966, "Bleu_3": 0.18013263235972626, "Bleu_4": 0.11625370483848452, "METEOR": 0.2949303826027341, "ROUGE_L": 0.2846476901539897, "CIDEr": 9.159232591961954e-19, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a man standing in a living room, playing a video game on a Nintendo Wii console. He is holding a Wii remote in his hand, actively engaged in playing the game. The living room is furnished with a couch and a TV, and a boxing game is positioned on the left side of the TV. The man is standing in front of the fireplace."}, "84073": {"image_id": 84073, "Bleu_1": 0.2222222222139918, "Bleu_2": 0.09245003270071499, "Bleu_3": 6.992374974986718e-07, "Bleu_4": 1.9427446513078855e-09, "METEOR": 0.12366091195365163, "ROUGE_L": 0.2278244631185808, "CIDEr": 0.00442237014005133, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a white refrigerator with a door open, revealing its contents. Inside the refrigerator, there are no bottles. There are no shelves in the refrigerator."}, "293207": {"image_id": 293207, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.24194335155767877, "Bleu_3": 0.14425501641879765, "Bleu_4": 0.0942762488834096, "METEOR": 0.22136877696348806, "ROUGE_L": 0.35079872204472845, "CIDEr": 0.0018487288848350555, "SPICE": {"All": {"pr": 0.05, "re": 0.045454545454545456, "f": 0.04761904761904762, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image captures a group of four men playing a game of frisbee on a grassy field. Two men are actively engaged in throwing the frisbee back and forth, while the other two men are watching or waiting for their turn."}, "431691": {"image_id": 431691, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.25819888973988653, "Bleu_3": 0.15769573215932156, "Bleu_4": 0.10440864748108529, "METEOR": 0.2804665905452186, "ROUGE_L": 0.34885620915032683, "CIDEr": 5.142320265608577e-05, "SPICE": {"All": {"pr": 0.15, "re": 0.21428571428571427, "f": 0.1764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man and a woman standing next to each other. The man is eating a donut and holding a donut. The woman is eating a sandwich. They are both enjoying their meals outdoors."}, "218470": {"image_id": 218470, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.10167765666209894, "Bleu_3": 0.057283488202355654, "Bleu_4": 7.681104116484306e-06, "METEOR": 0.17560560642018902, "ROUGE_L": 0.22994076467420568, "CIDEr": 2.8169411825569773e-13, "SPICE": {"All": {"pr": 0.1794871794871795, "re": 0.28, "f": 0.21875, "fn": 18.0, "numImages": 1.0, "fp": 32.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1875, "re": 0.3333333333333333, "f": 0.24000000000000005, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a street scene with a traffic light hanging from a wire above the street. The traffic light is positioned towards the center of the scene. It appears to be a red light. The wire is suspended above the street, with a bird hanging from it. A power pole is also suspended above the street."}, "9050": {"image_id": 9050, "Bleu_1": 0.2666666666622222, "Bleu_2": 0.16467739391575578, "Bleu_3": 0.11194045746119323, "Bleu_4": 0.07043225514233839, "METEOR": 0.2864571316270478, "ROUGE_L": 0.31443298969072164, "CIDEr": 1.767347955389511e-14, "SPICE": {"All": {"pr": 0.19444444444444445, "re": 0.23333333333333334, "f": 0.21212121212121213, "fn": 23.0, "numImages": 1.0, "fp": 29.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.21428571428571427, "f": 0.3, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features a dining table set with three plates of food. The first plate has a piece of meat on it. The second plate has cheese and crackers on it. The third plate has carrots and asparagus on it. There are also several carrots scattered around the table. A fork and a knife are also visible on the table."}, "390769": {"image_id": 390769, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.2258769757216551, "Bleu_3": 0.17574056770956026, "Bleu_4": 0.13716549481276807, "METEOR": 0.3059330001266918, "ROUGE_L": 0.33132166566083276, "CIDEr": 2.1864924579358036e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.22580645161290322, "f": 0.23728813559322032, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.5833333333333334, "f": 0.5833333333333334, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image features a woman standing on a sidewalk. She is talking on a cell phone and wearing a black shirt. The woman appears to be engaged in a conversation. There is a restaurant in the background, but there is no awning, chair, or dining table in the scene."}, "175718": {"image_id": 175718, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.3450327796543363, "Bleu_3": 0.2658863991818757, "Bleu_4": 0.2137772394048396, "METEOR": 0.2874917313166217, "ROUGE_L": 0.48248587570621465, "CIDEr": 0.21188344094912598, "SPICE": {"All": {"pr": 0.24, "re": 0.1935483870967742, "f": 0.21428571428571427, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.125, "f": 0.16, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a pizza sitting on a cutting board placed on a kitchen counter. The pizza looks like a pizza."}, "288430": {"image_id": 288430, "Bleu_1": 0.14666666666471112, "Bleu_2": 0.10904995135979031, "Bleu_3": 0.06881018032739676, "Bleu_4": 8.201747555949934e-06, "METEOR": 0.14955379431738125, "ROUGE_L": 0.16920943134535368, "CIDEr": 6.1732152676829944e-27, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.3333333333333333, "f": 0.2926829268292683, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image captures a lively scene at the beach, where a group of six people is enjoying their time. Some of the people are playing frisbee, while others are flying a kite. One person is playing a game of soccer, and another person is walking down the street. The people are scattered on the beach, with some standing closer to the water. The scene is lively and vibrant, with a kite flying in the sky."}, "568150": {"image_id": 568150, "Bleu_1": 0.454545454535124, "Bleu_2": 0.3561599279620349, "Bleu_3": 0.2471744678664078, "Bleu_4": 0.13853411725353965, "METEOR": 0.27768476286464516, "ROUGE_L": 0.3620007535795026, "CIDEr": 3.7167533665181136e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bathroom with a white toilet situated in the corner. The bathroom has a toilet, a tub, and a window. The toilet is white. The window allows natural light to enter the space. The bathroom has a tiled floor and walls."}, "200109": {"image_id": 200109, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.17654696589776867, "Bleu_3": 0.12008331555545111, "Bleu_4": 0.08990845492072137, "METEOR": 0.2643759346819695, "ROUGE_L": 0.2772727272727273, "CIDEr": 2.661913636865477e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a person holding two cell phones. The person is holding a cell phone. The screen of one of the cell phones is displaying a message, which appears to be a text conversation. \n\nThere is no other phone, table, or bowl in the scene.\n\nThere is a bowl of popcorn placed on the table."}, "292617": {"image_id": 292617, "Bleu_1": 0.1710526315766967, "Bleu_2": 0.13507632669940495, "Bleu_3": 0.09043766473247743, "Bleu_4": 0.05641976717226, "METEOR": 0.211219353700441, "ROUGE_L": 0.21942446043165464, "CIDEr": 2.155720377939062e-24, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15, "f": 0.1764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image is a dimly lit living room with a large window that allows natural light to enter. The room features three couches situated in the middle. There is a dining table with a chair placed around it. There is also a table in the room. \n\nA couch, a TV, a fireplace, and a window are in the living room. There is a large window in the living room. Chairs are placed around the dining table."}, "467990": {"image_id": 467990, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.3441236007881837, "Bleu_3": 0.23608159784189342, "Bleu_4": 0.16679551612892413, "METEOR": 0.33530178343719574, "ROUGE_L": 0.44417475728155337, "CIDEr": 0.3012836437787379, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10526315789473684, "f": 0.12903225806451615, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a yellow and silver passenger train traveling on the tracks. The train is positioned on the tracks."}, "443713": {"image_id": 443713, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2829297811792259, "Bleu_3": 0.20719134323230037, "Bleu_4": 0.16173084901163898, "METEOR": 0.1846531358173086, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.009211737033336114, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.29411764705882354, "f": 0.24390243902439027, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image captures a skateboarder performing a trick on a rail in a parking lot. The skateboarder is in mid-air, showcasing their skills. The people are watching the skateboarder."}, "365129": {"image_id": 365129, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.19611613513437562, "Bleu_3": 9.162603270562093e-07, "Bleu_4": 1.990513566543731e-09, "METEOR": 0.22480541760733497, "ROUGE_L": 0.24151583710407235, "CIDEr": 3.284687547056734e-10, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a serene scene of a sunset over a large body of water, with a mountain in the background. The sun is setting in the distance, casting a warm glow over the sky and the water. The water is calm and reflective. There are eight boats scattered throughout the scene."}, "462904": {"image_id": 462904, "Bleu_1": 0.2656249999958496, "Bleu_2": 0.205335575123675, "Bleu_3": 0.0879384695024735, "Bleu_4": 1.0275470537531875e-05, "METEOR": 0.18492680116279017, "ROUGE_L": 0.26547388781431336, "CIDEr": 2.7499454407350905e-17, "SPICE": {"All": {"pr": 0.35, "re": 0.2413793103448276, "f": 0.2857142857142857, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a black horse standing on a wooden deck near a restaurant. A wooden table is near the black horse. The horse is positioned in the middle of the scene. Hay is scattered around the horse.\n\nThere are several chairs and dining tables scattered around the scene.\n\nThere are several people scattered around the scene.\n\nThere is no moose in the scene."}, "3466": {"image_id": 3466, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.12327121291697288, "Bleu_3": 6.436001859611395e-07, "Bleu_4": 1.4771177397808513e-09, "METEOR": 0.18194785061533536, "ROUGE_L": 0.20760068065796938, "CIDEr": 6.1709677063720916e-15, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two people standing on a brick floor. One person is standing on a toilet, while the other person is standing on a grate. \n\nBoth people are wearing orange shoes. The shoes are prominently displayed, and the person's feet occupy a significant portion of the image. \n\nThe person with the crossed legs is not wearing shoes."}, "134760": {"image_id": 134760, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.14664711501654393, "Bleu_3": 9.051412339008928e-07, "Bleu_4": 2.2685468589522803e-09, "METEOR": 0.19136014486662153, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.0013190845034920236, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.125, "f": 0.12903225806451615, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image captures a snowy mountain scene with a slope and several people enjoying their time on the slope. The people are skiing down the slope or standing/sitting on the snow."}, "364705": {"image_id": 364705, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.12091150252325192, "Bleu_4": 0.07599442723764853, "METEOR": 0.2564669326294365, "ROUGE_L": 0.2830626450116009, "CIDEr": 3.485854816104941e-13, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.05555555555555555, "f": 0.049999999999999996, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features a group of 26 teddy bears sitting on a blue surface. The teddy bears are all wearing bows, with various colors and styles. Some of the teddy bears are wearing bow ties, while others have bows on their necks or in their hair. The bows add a touch of charm to their appearance."}, "191296": {"image_id": 191296, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.19897929585627183, "Bleu_3": 0.09251566147567657, "Bleu_4": 1.1274892861583804e-05, "METEOR": 0.2037234099739805, "ROUGE_L": 0.23047858942065497, "CIDEr": 2.7659908594055296e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a fire hydrant standing in a field. The fire hydrant is positioned in the middle of the field. The hydrant has a red body and silver valve parts, and it is surrounded by green plants. The grass is quite tall, covering the ground and creating a natural, serene atmosphere."}, "457817": {"image_id": 457817, "Bleu_1": 0.333333333325926, "Bleu_2": 0.2752409412754042, "Bleu_3": 0.2310389582841327, "Bleu_4": 0.19574653889033578, "METEOR": 0.3756358301149006, "ROUGE_L": 0.34536447275300775, "CIDEr": 1.603091081098116e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.19047619047619047, "f": 0.24242424242424246, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image captures a man playing tennis on a tennis court. The man is in the middle of a jump, likely after hitting a tennis ball. He is wearing a white shirt and green shorts, and he is holding a tennis racket in his hand."}, "531995": {"image_id": 531995, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.308606699915489, "Bleu_3": 0.2237676280726019, "Bleu_4": 0.16142729064491518, "METEOR": 0.3172596588292278, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.0005362397783105113, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.19047619047619047, "f": 0.21052631578947367, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a black and white cat playing with a pair of black boots on the floor. The cat is sitting on the floor, with its paws inside the boots, seemingly enjoying the playful activity."}, "276673": {"image_id": 276673, "Bleu_1": 0.27272727272314046, "Bleu_2": 0.14484136487336882, "Bleu_3": 0.06895012868910912, "Bleu_4": 8.493098745181431e-06, "METEOR": 0.20981694862354444, "ROUGE_L": 0.2029853584331622, "CIDEr": 1.0227927527458971e-13, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress. There is a batter at the plate, swinging his bat. The players are focused on the game. The pitcher is focused on the game. The batter is surrounded by a baseball player and a pitcher. The catcher is also present. The umpire is overseeing the game.\n\nThere is no baseball game, plate, ball, or bench in the scene."}, "112800": {"image_id": 112800, "Bleu_1": 0.382352941165225, "Bleu_2": 0.3044529883214349, "Bleu_3": 0.24375498310650337, "Bleu_4": 0.1934884374047744, "METEOR": 0.2809454300342698, "ROUGE_L": 0.3566208710903244, "CIDEr": 0.010177767673999284, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.21428571428571427, "f": 0.21052631578947367, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a large body of water with five boats and an airplane. The boat is a tug boat and it is moving through the water. The airplane is flying over the water."}, "390685": {"image_id": 390685, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.15320195579385062, "Bleu_3": 0.08671123520251264, "Bleu_4": 1.1682600305257854e-05, "METEOR": 0.2389802202285954, "ROUGE_L": 0.2733791455034359, "CIDEr": 3.1852733015593325e-05, "SPICE": {"All": {"pr": 0.32142857142857145, "re": 0.4090909090909091, "f": 0.36000000000000004, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features two stop signs with a red and white color scheme. The stop signs are positioned in the center of the scene. There is a tree in the background.\n\nThere are no cars in the image."}, "195002": {"image_id": 195002, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.12038585308312308, "Bleu_3": 6.906098117642891e-07, "Bleu_4": 1.663632685119678e-09, "METEOR": 0.18985862672904563, "ROUGE_L": 0.24238410596026488, "CIDEr": 1.04343218582747e-08, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.20689655172413793, "f": 0.20689655172413793, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a girl dressed as a princess. She is wearing a crown and a yellow dress. The girl is sitting on a couch. She is holding a doughnut and enjoying it. The girl appears to be in a playful mood, as she is smiling."}, "104626": {"image_id": 104626, "Bleu_1": 0.378378378368152, "Bleu_2": 0.22924343512884385, "Bleu_3": 1.1450960685146525e-06, "Bleu_4": 2.57787416098344e-09, "METEOR": 0.2465943508718672, "ROUGE_L": 0.2930344275420336, "CIDEr": 2.731421833415157e-05, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10344827586206896, "f": 0.125, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a blue truck parked on a brick sidewalk. The truck is parked next to a building. There is a tarp covering the back of the truck. \n\nThere are no American flags in the scene."}, "291370": {"image_id": 291370, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.21535276081853263, "Bleu_3": 0.10176913199238992, "Bleu_4": 1.2512524442841368e-05, "METEOR": 0.19573079599368914, "ROUGE_L": 0.28273464658169173, "CIDEr": 1.8440110397739103e-06, "SPICE": {"All": {"pr": 0.375, "re": 0.16666666666666666, "f": 0.23076923076923078, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image captures a lively scene on a city street where a group of people, including two men and five women, are gathered around a man wearing a top hat. The woman in the hat is holding a camera and the man is taking a picture."}, "434804": {"image_id": 434804, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.11964664509646934, "Bleu_4": 1.4127271129810476e-05, "METEOR": 0.22072963028819584, "ROUGE_L": 0.24830393487109906, "CIDEr": 2.7194490938700867e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.35714285714285715, "f": 0.3448275862068965, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a group of four giraffes standing together in a fenced-in area. The giraffes are standing close to each other, with two giraffes on the left side and two on the right side of the enclosure. They are eating and standing in a line."}, "143": {"image_id": 143, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.3457820373893416, "Bleu_3": 0.2535719111447155, "Bleu_4": 0.16692486521271999, "METEOR": 0.39339845463971373, "ROUGE_L": 0.4621212121212121, "CIDEr": 0.0545645419187659, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a group of seven birds perched on the branches of a tree. The birds are positioned closer to the tree trunks."}, "249219": {"image_id": 249219, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.20568833779665252, "Bleu_3": 0.16452500422386435, "Bleu_4": 0.1047426366257458, "METEOR": 0.34240818213304897, "ROUGE_L": 0.2764350453172206, "CIDEr": 1.6847838090770052e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a double-decker bus driving down a street, passing by a building. The bus is a double-decker. There are two people visible in the scene. The people are closer to the window and further away from the camera."}, "19716": {"image_id": 19716, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2455273669893519, "Bleu_3": 0.17371366811587796, "Bleu_4": 0.12354633416040646, "METEOR": 0.3383222680640332, "ROUGE_L": 0.41024700415749565, "CIDEr": 1.1029340189170207e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.3333333333333333, "f": 0.27906976744186046, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a man wearing a suit and tie standing in an elevator. The man is posing for a picture and smiling, but he is not looking at the camera. The elevator is surrounded by a glass wall. The scene appears to be in a corporate setting."}, "517973": {"image_id": 517973, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.30053715350890803, "Bleu_3": 0.1839964505079536, "Bleu_4": 0.12212865548296503, "METEOR": 0.2998596117751062, "ROUGE_L": 0.43536875495638383, "CIDEr": 0.008563503914162631, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08695652173913043, "f": 0.0909090909090909, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a white Volkswagen Beetle parked in a parking lot. There is a surfboard placed on the roof of the car. The car is positioned between two other cars."}, "23019": {"image_id": 23019, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.19674775072873343, "Bleu_3": 0.11010503638215555, "Bleu_4": 1.4776306152176402e-05, "METEOR": 0.19515979135015546, "ROUGE_L": 0.1665150136487716, "CIDEr": 0.000995312172613647, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image captures a city street at dusk, with four buildings and a clock tower in the background. The street is bustling with activity, as cars are driving down the road."}, "177213": {"image_id": 177213, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.3469443332317352, "Bleu_3": 0.28499599110221785, "Bleu_4": 0.22957488465746467, "METEOR": 0.3011275539064863, "ROUGE_L": 0.4792666957660411, "CIDEr": 0.05195450035273031, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2, "f": 0.24489795918367346, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a pizza sitting on a plate on a dining table. The pizza is topped with cheese and basil. There is a fork on the table."}, "514773": {"image_id": 514773, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.1428571428542566, "Bleu_3": 0.10844960613620269, "Bleu_4": 0.07217661658634832, "METEOR": 0.1853866606909808, "ROUGE_L": 0.22235722964763066, "CIDEr": 4.997458338205779e-10, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2857142857142857, "f": 0.2727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a desk with a computer setup. A computer, a keyboard, a mouse, a monitor, and a printer are on the desk. There is also a laptop positioned towards the left side of the desk. The keyboard is for the computer. The laptop serves as the other keyboard."}, "259253": {"image_id": 259253, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.2613021337786361, "Bleu_3": 0.12378303795219202, "Bleu_4": 1.5257340614283253e-05, "METEOR": 0.2563441089674066, "ROUGE_L": 0.37251908396946565, "CIDEr": 5.1051540105481426e-05, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.22727272727272727, "f": 0.24390243902439024, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.75, "f": 0.6666666666666665, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a herd of eight sheep grazing in a grassy field under a large tree. The sheep are scattered across the field, with some closer to the tree. They are enjoying the grass and green grass."}, "85340": {"image_id": 85340, "Bleu_1": 0.43999999999120004, "Bleu_2": 0.2996596708997033, "Bleu_3": 0.21069866689088712, "Bleu_4": 0.1412470464555783, "METEOR": 0.2558251204426074, "ROUGE_L": 0.326397146254459, "CIDEr": 4.875317182830621e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a group of three people, a man and two women, sitting together and enjoying a meal. They are all smiling and posing for a picture. One of the women is holding a hot dog, which is placed on a bun. The other woman is holding a cup."}, "94025": {"image_id": 94025, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1348399724902187, "Bleu_3": 6.956880074617597e-07, "Bleu_4": 1.5876030342378672e-09, "METEOR": 0.179784391827437, "ROUGE_L": 0.23775055679287305, "CIDEr": 2.3885104585072173e-13, "SPICE": {"All": {"pr": 0.3, "re": 0.2222222222222222, "f": 0.25531914893617025, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a red stop sign sitting on the side of a road, surrounded by trees. The sign is positioned near a train track, with a train visible in the background. The train appears to be moving along the tracks, adding to the overall atmosphere of the scene.\n\nThere are no people in the scene."}, "21746": {"image_id": 21746, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.19835388146890715, "Bleu_3": 0.1493939922741549, "Bleu_4": 0.1145969779968592, "METEOR": 0.330766365789851, "ROUGE_L": 0.28053142565150746, "CIDEr": 1.4177732188907866e-15, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.2916666666666667, "f": 0.2592592592592593, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a woman playing tennis on a tennis court. She is swinging a tennis racket to hit a tennis ball. The woman is wearing a white dress and appears to be in the middle of a game. The tennis ball is visible in the air, close to the woman, as she prepares to hit the ball with her racket."}, "338291": {"image_id": 338291, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.11085479909296489, "Bleu_3": 0.07385893702641234, "Bleu_4": 9.052415449788016e-06, "METEOR": 0.16321489751335236, "ROUGE_L": 0.15762273901808782, "CIDEr": 3.331118532342171e-18, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features three snowboarders wearing blue jackets, and each of them is holding a snowboard. They are standing in front of a building, possibly in a parking lot. One person is standing close to the snowboarders, and another person in a black jacket is standing a bit further away. The snowboarders appear to be posing for a picture outside of the building."}, "10142": {"image_id": 10142, "Bleu_1": 0.3103448275755054, "Bleu_2": 0.14888750009041385, "Bleu_3": 9.363773583406064e-07, "Bleu_4": 2.3705266434361037e-09, "METEOR": 0.23592337087049844, "ROUGE_L": 0.31633535004321517, "CIDEr": 0.003285071849364363, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a man skiing on a snow-covered path in the snowy forest. The man is holding ski poles and is positioned towards the center of the scene."}, "327433": {"image_id": 327433, "Bleu_1": 0.14473684210335874, "Bleu_2": 0.07608859102426038, "Bleu_3": 0.04276965904789536, "Bleu_4": 5.721647867042853e-06, "METEOR": 0.19222177865980292, "ROUGE_L": 0.13939670932358317, "CIDEr": 2.4744444363910474e-27, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.10526315789473684, "f": 0.1111111111111111, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image depicts a lush green field with a variety of animals grazing and walking around. There are no zebras in the scene. A giraffe can be seen in the background, standing near the water. \n\nThere are four animals in the scene. The animals are grazing. A lion is laying down in the grass with the animals. The elephants are also grazing in the grass with the animals.\n\nThere is also a fox in the image."}, "177935": {"image_id": 177935, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.12803687993077956, "Bleu_3": 6.525383659983368e-07, "Bleu_4": 1.4794406243584447e-09, "METEOR": 0.17111617255194753, "ROUGE_L": 0.19565914679781887, "CIDEr": 7.719578652750793e-17, "SPICE": {"All": {"pr": 0.2, "re": 0.15151515151515152, "f": 0.17241379310344826, "fn": 28.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a white kitchen with a large, old-fashioned oven. The oven is positioned in the center of the kitchen. There is not a light shining on the oven. A stove is surrounded by various kitchen items, including a knife block, a pot, and a pan. A white wall is surrounding the stove. There is no sink in the kitchen."}, "100354": {"image_id": 100354, "Bleu_1": 0.15217391304017017, "Bleu_2": 1.8389242811841476e-09, "Bleu_3": 4.251658160504893e-12, "Bleu_4": 2.056135070108479e-13, "METEOR": 0.13190751724576585, "ROUGE_L": 0.16158940397350993, "CIDEr": 3.599220334215324e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.10714285714285714, "f": 0.14285714285714285, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.23076923076923078, "f": 0.3157894736842105, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features five sheep in a dirt field. The sheep are of different colors, including brown, black and white. Some of the sheep are mothers with their babies following closely behind. The babies are located on the left and right sides of the mother sheep."}, "377326": {"image_id": 377326, "Bleu_1": 0.5714285714013606, "Bleu_2": 0.4472135954781297, "Bleu_3": 0.3160816010076583, "Bleu_4": 3.639412530792223e-05, "METEOR": 0.3332473416576286, "ROUGE_L": 0.35924617196702, "CIDEr": 0.20871365032090333, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features three cows standing on a muddy bank, drinking water from a lake. The cows are brown and white."}, "300471": {"image_id": 300471, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.327326835338012, "Bleu_3": 0.22425727432945428, "Bleu_4": 0.15821285887535239, "METEOR": 0.24780627507119293, "ROUGE_L": 0.35924617196702, "CIDEr": 0.17425543896040604, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.35294117647058826, "f": 0.35294117647058826, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features two cats sitting and laying on a blue chair. The cats are sitting on the chair's arms."}, "512729": {"image_id": 512729, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 9.166878867586852e-07, "Bleu_4": 2.1980503399202124e-09, "METEOR": 0.16395172478549172, "ROUGE_L": 0.2420634920634921, "CIDEr": 0.0002724656736292486, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11764705882352941, "f": 0.12903225806451615, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a plate filled with a delicious meal, including a generous serving of broccoli. The broccoli is placed in the center of the plate. The plate is white. The meal includes broccoli and sauce."}, "14151": {"image_id": 14151, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 8.243669902025871e-07, "Bleu_4": 1.8483326514023873e-09, "METEOR": 0.18118402701859174, "ROUGE_L": 0.29093799682034976, "CIDEr": 2.2182701974236836e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a person doing skiing on a snow-covered slope. The person is wearing a red outfit and a helmet. They are skiing in the middle of a snowy field. The field is surrounded by a large, green circle. The skier appears to be enjoying their time on the slope."}, "323726": {"image_id": 323726, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.20159019488753482, "Bleu_3": 0.14716669660616322, "Bleu_4": 0.08935413502510754, "METEOR": 0.2373513848558139, "ROUGE_L": 0.25894481503941785, "CIDEr": 4.5940403164271735e-11, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures a baseball game in progress. There are two batters holding baseball bats and preparing to hit the ball. The batters are swinging their bats. The catcher and umpire are watching the baseball game. \n\nThere are no other players in the scene. The baseball game is taking place on a field."}, "270351": {"image_id": 270351, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.13857638305004102, "Bleu_3": 8.110083286556016e-07, "Bleu_4": 1.9758409157987315e-09, "METEOR": 0.18671126854292852, "ROUGE_L": 0.2793893129770992, "CIDEr": 7.2914428947897195e-06, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.17142857142857143, "f": 0.16666666666666669, "fn": 29.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3076923076923077, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image features three pigeons perched on a ledge outside a window. The pigeons are standing close to each other, possibly enjoying the view or waiting for food. The window is located on the side of a building."}, "290113": {"image_id": 290113, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.1825741858276003, "Bleu_3": 1.1316626169059293e-06, "Bleu_4": 2.8489318276508903e-09, "METEOR": 0.1819889891605483, "ROUGE_L": 0.26725082146768897, "CIDEr": 0.009449666898007057, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.125, "f": 0.16216216216216217, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts a ski slope covered in snow. There are two people skiing down the slope. The person is skiing on the snowy slope."}, "535312": {"image_id": 535312, "Bleu_1": 0.11454821312228307, "Bleu_2": 1.8501205457424902e-09, "Bleu_3": 4.746487194235589e-12, "Bleu_4": 2.432256114003697e-13, "METEOR": 0.06357615894039735, "ROUGE_L": 0.2259259259259259, "CIDEr": 0.0008101772106172919, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16, "f": 0.16326530612244897, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "I'm sorry, but I cannot generate a refined passage without the passage and query. Could you please provide the passage and query?"}, "478282": {"image_id": 478282, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.14564381624761055, "Bleu_3": 7.901421228222159e-07, "Bleu_4": 1.8512564664694888e-09, "METEOR": 0.17837574452539262, "ROUGE_L": 0.25258799171842644, "CIDEr": 8.141706400832809e-07, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.23076923076923078, "f": 0.2790697674418605, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a vase filled with colorful flowers. The vase is placed on a table. The vase is tall and has a unique design. The flowers inside the vase are a mix of orange and yellow colors. The flowers create a visually appealing display."}, "64796": {"image_id": 64796, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.1264019129936606, "Bleu_3": 0.08344331191885142, "Bleu_4": 0.05727237722897948, "METEOR": 0.17736597656804953, "ROUGE_L": 0.23448654585392636, "CIDEr": 5.540666817607933e-14, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.11764705882352941, "f": 0.11764705882352941, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a small vase with a black top. The vase is placed on a table. The vase is holding a beautiful arrangement of red roses. Some of the roses are red, while others are red and green in color. The vase is placed on a pedestal, which adds a sense of height to the image."}, "525297": {"image_id": 525297, "Bleu_1": 0.29999999999500004, "Bleu_2": 0.21392220984009222, "Bleu_3": 0.15801000534061047, "Bleu_4": 0.12003973847505747, "METEOR": 0.24601518758665003, "ROUGE_L": 0.29383429672447015, "CIDEr": 6.286165959883142e-13, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.06818181818181818, "f": 0.09836065573770492, "fn": 41.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.16666666666666666, "f": 0.23076923076923078, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a person holding a cell phone in their hand. The person is holding up the cell phone and capturing a picture of a cow. The cow is displayed on the screen of the cell phone. The cow is prominently displayed in the foreground, while the person is visible in the background, holding the phone at an angle."}, "158414": {"image_id": 158414, "Bleu_1": 0.378378378368152, "Bleu_2": 0.22924343512884385, "Bleu_3": 0.1145096068514652, "Bleu_4": 1.449645171861387e-05, "METEOR": 0.16908660602560197, "ROUGE_L": 0.2627422828427854, "CIDEr": 0.00014853188438065864, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.17857142857142858, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a bus stop with a large advertisement for Metro on the side of the bus. The advertisement is prominently displayed. The bus is parked at the stop. There is a person waiting to board."}, "170346": {"image_id": 170346, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.2387049580041334, "Bleu_3": 0.1658075448734274, "Bleu_4": 0.11739521785616198, "METEOR": 0.23080744917722962, "ROUGE_L": 0.2442442442442442, "CIDEr": 0.01107630753968325, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08, "f": 0.08695652173913043, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a mountain goat standing on a grassy hillside. The goat is looking north. The goat is relaxed and enjoying its time on the hill."}, "328315": {"image_id": 328315, "Bleu_1": 0.24615384615005917, "Bleu_2": 0.16408253082592933, "Bleu_3": 0.11956793017644822, "Bleu_4": 0.0861728804342445, "METEOR": 0.18979272147614948, "ROUGE_L": 0.2897862232779097, "CIDEr": 4.0708231681271284e-17, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a desk with a computer setup. There is a desktop computer and a laptop on the desk. The desktop computer is placed on the left side of the desk, while the laptop is situated on the right side. There are two keyboards placed in front of the setup. One keyboard is for the desktop computer, and the other is for the laptop."}, "113246": {"image_id": 113246, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.24019223070154896, "Bleu_3": 0.16576208078090784, "Bleu_4": 0.10533275933494715, "METEOR": 0.2725340171989187, "ROUGE_L": 0.2764350453172206, "CIDEr": 6.579418870837742e-06, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2, "f": 0.25641025641025644, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features three people gathered in a living room, creating a happy atmosphere. One person is sitting on a couch, while another person is not sitting on the couch. The people are playing a video game and enjoying themselves."}, "1290": {"image_id": 1290, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.10783277320095921, "Bleu_3": 6.517545715819412e-07, "Bleu_4": 1.6120076571355242e-09, "METEOR": 0.22438572792721528, "ROUGE_L": 0.29985955056179775, "CIDEr": 7.523781862220661e-08, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.3157894736842105, "f": 0.36363636363636365, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.8333333333333334, "f": 0.7692307692307692, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a baby sitting in a high chair, surrounded by a mother and father. The baby is holding a pacifier. The baby is sitting in a high chair. The cake is placed on the high chair. A candle is on the cake."}, "292365": {"image_id": 292365, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.37696851744318155, "Bleu_3": 0.2508741329730111, "Bleu_4": 3.1044143557203874e-05, "METEOR": 0.28029515619891965, "ROUGE_L": 0.37014563106796117, "CIDEr": 0.22360273802525388, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06666666666666667, "f": 0.08888888888888888, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a cat standing on the toilet in a small bathroom. The cat is looking at the toilet."}, "246746": {"image_id": 246746, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.13240928541024866, "Bleu_4": 0.08383287626240972, "METEOR": 0.2665978733261029, "ROUGE_L": 0.3100381194409149, "CIDEr": 7.002016765066172e-11, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.21052631578947367, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a woman riding a brown horse in a grassy field. The woman is skillfully guiding the horse as they move through the open area. The woman is wearing a helmet, which is essential for safety. \n\nIn the background, there is a person in a blue shirt visible."}, "328464": {"image_id": 328464, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.19754591932503954, "Bleu_3": 0.1000208420156093, "Bleu_4": 1.2738608208588955e-05, "METEOR": 0.20232630152576864, "ROUGE_L": 0.26425992779783397, "CIDEr": 2.810161303976457e-06, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2631578947368421, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a sailboat floating on a body of water, possibly a lake, with a snowy landscape in the background. The boat is positioned near the center of the scene, and it appears to be sailing on a calm day."}, "420852": {"image_id": 420852, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.1030922854689151, "Bleu_3": 0.062277793856498315, "Bleu_4": 8.65730664807734e-06, "METEOR": 0.13839696705646426, "ROUGE_L": 0.22620519159456118, "CIDEr": 4.21588720006635e-08, "SPICE": {"All": {"pr": 0.28125, "re": 0.3333333333333333, "f": 0.3050847457627119, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 9.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Attribute": {"pr": 0.15384615384615385, "re": 0.4, "f": 0.2222222222222222, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a city street with two traffic lights hanging above it. The traffic lights are spread out across the scene, with some located on the street and others in the sky. The scene is bustling with activity, with multiple cars driving down the road."}, "97646": {"image_id": 97646, "Bleu_1": 0.25806451612070763, "Bleu_2": 0.16064386577523138, "Bleu_3": 9.618560885253057e-07, "Bleu_4": 2.374340857937043e-09, "METEOR": 0.22684877608276877, "ROUGE_L": 0.1665150136487716, "CIDEr": 0.00030104163664305505, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.15384615384615385, "f": 0.1951219512195122, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a man walking down a path in a wooded area. The man is in the foreground, and he is walking. The wooded area is surrounded by a forest."}, "545796": {"image_id": 545796, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.14357265694226845, "Bleu_3": 0.07887960518628792, "Bleu_4": 1.045990118964594e-05, "METEOR": 0.2248468823604849, "ROUGE_L": 0.25702247191011235, "CIDEr": 2.6826426366896306e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.11764705882352941, "f": 0.14285714285714285, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a toddler brushing his teeth with a red toothbrush. The child is focused on the task and appears to be enjoying the activity. The toothbrush is visible in the child's mouth, and the child's hand is holding the toothbrush."}, "332407": {"image_id": 332407, "Bleu_1": 0.1752577319569561, "Bleu_2": 0.08545411340673098, "Bleu_3": 0.05357030412491104, "Bleu_4": 0.03576112070520454, "METEOR": 0.1717422450758013, "ROUGE_L": 0.15233678201926504, "CIDEr": 2.6278011378205463e-40, "SPICE": {"All": {"pr": 0.2, "re": 0.19047619047619047, "f": 0.1951219512195122, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features four men standing on a baseball field. One of the men is wearing a yellow sweatshirt, another is wearing a blue sweatshirt, and the third is also wearing a blue sweatshirt. The man wearing the yellow sweatshirt is also wearing a red hat. One of the men is holding a baseball bat, and another man is preparing to hit a baseball. There is also a boy holding a baseball bat. They are all focused on the game.\n\nThere is no information about the number of sweatshirts, baseball bats, or boys in the supplementary information."}, "204448": {"image_id": 204448, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.14341779190946682, "Bleu_3": 0.07161533241989526, "Bleu_4": 9.039904380101799e-06, "METEOR": 0.17808502234140197, "ROUGE_L": 0.2680897818238895, "CIDEr": 2.449578568912213e-10, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.30434782608695654, "f": 0.35, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image depicts a small, cluttered kitchen with wooden cabinets. The cabinets are white and brown. There is a white microwave in the kitchen. \n\nThe kitchen is equipped with a sink, a refrigerator, and a countertop. \n\nSome bottles are placed in the sink. \n\nThere is no stove in the kitchen. \n\nThere are no other people in the kitchen."}, "480842": {"image_id": 480842, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.10767638040926633, "Bleu_3": 6.411053581337095e-07, "Bleu_4": 1.573366652415358e-09, "METEOR": 0.15467186303716032, "ROUGE_L": 0.16553595658073267, "CIDEr": 1.525636715459239e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features four giraffes standing in a lush green forest. The giraffes are surrounded by trees and bushes. One giraffe is standing slightly behind the other. They appear to be looking in different directions, possibly exploring their surroundings. The giraffes are eating from the trees."}, "224155": {"image_id": 224155, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.12923605637746155, "Bleu_4": 1.4799077495755305e-05, "METEOR": 0.27452971087960676, "ROUGE_L": 0.270595690747782, "CIDEr": 1.9320893242614045e-09, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man standing in a bathroom, holding a cell phone up to his face and taking a selfie. He is wearing a green shirt and appears to be looking at the camera with a smile. The bathroom has a sink located on the left side."}, "303647": {"image_id": 303647, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.3123475237694987, "Bleu_3": 0.19578417892468591, "Bleu_4": 0.11854610697110775, "METEOR": 0.24660362105733066, "ROUGE_L": 0.33493479752916955, "CIDEr": 7.684960546214592e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.21428571428571427, "f": 0.1764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a pizza sitting on top of a baking sheet placed on a stove. The pizza is covered in cheese and mushrooms. Mushrooms and basil leaves are on top of the pizza. Basil leaves are scattered across the pizza."}, "448868": {"image_id": 448868, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.07606919312543149, "Bleu_4": 9.785799152874335e-06, "METEOR": 0.2222578464798166, "ROUGE_L": 0.21441124780316342, "CIDEr": 2.1630803301964538e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.11538461538461539, "f": 0.13953488372093026, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a busy city street with six trucks and one car driving down the road. Some of the trucks are large tanker trucks, while others are garment trucks, semi trucks, and water trucks. One of the cars is located in the snow. In the snow is another car located."}, "360705": {"image_id": 360705, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.18569533817075534, "Bleu_3": 1.0718844984982804e-06, "Bleu_4": 2.5987832063232773e-09, "METEOR": 0.21636325124988873, "ROUGE_L": 0.26614310645724254, "CIDEr": 0.0020982881124720645, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.14285714285714285, "f": 0.1568627450980392, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a field that is green. There are two cows in the image. They are all different sizes. The cows are grazing peacefully in the large, grassy field."}, "122678": {"image_id": 122678, "Bleu_1": 0.4500438131024431, "Bleu_2": 0.29594698846822737, "Bleu_3": 0.2061373604227598, "Bleu_4": 0.1456898239949678, "METEOR": 0.2613274046606774, "ROUGE_L": 0.3935483870967742, "CIDEr": 0.17868312543566883, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.2413793103448276, "f": 0.2692307692307692, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a woman wearing a headset, suggesting she is a pilot. She is standing in a control room on a ship. The woman is writing on a wall and appears to be focused on her task."}, "253843": {"image_id": 253843, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.34850751766960786, "Bleu_3": 0.2541348319345581, "Bleu_4": 0.19231042777324445, "METEOR": 0.38306669398839505, "ROUGE_L": 0.3804573804573804, "CIDEr": 4.847034734368825e-05, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman and a man standing next to a brown and white horse in a dirt field. The woman is holding a lead rope. The man is walking the horse. The horse is calm and well-behaved."}, "301421": {"image_id": 301421, "Bleu_1": 0.15789473683933522, "Bleu_2": 0.1187339225343928, "Bleu_3": 0.08003359263491404, "Bleu_4": 9.870878229862094e-06, "METEOR": 0.1438692098092643, "ROUGE_L": 0.17805020431990656, "CIDEr": 1.9228638077807948e-14, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.42105263157894735, "f": 0.42105263157894735, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.7, "re": 0.7, "f": 0.7, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image features a computer desk with a large flat-screen TV mounted on the wall above it. The TV is displaying a car, likely a red sports car, in a fish bowl. The desk is equipped with a keyboard and a mouse, both placed in front of the TV.\n\nThere is no fish tank in the scene."}, "248965": {"image_id": 248965, "Bleu_1": 0.255813953482423, "Bleu_2": 0.13517553494737666, "Bleu_3": 0.09623818952515524, "Bleu_4": 0.06870614559549089, "METEOR": 0.19837327686385645, "ROUGE_L": 0.2902787219578518, "CIDEr": 1.034701378990179e-06, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.20833333333333334, "f": 0.24390243902439027, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a girl standing in the snow, holding a colorful kite. She is wearing a pink coat and appears to be enjoying the outdoor activity. The kite is large and has a vibrant design, making it a fun and eye-catching sight."}, "274134": {"image_id": 274134, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.276533159369469, "Bleu_3": 0.2100616765893022, "Bleu_4": 0.15514226402818007, "METEOR": 0.24058127302891263, "ROUGE_L": 0.31937172774869105, "CIDEr": 0.0018597375857230458, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2, "f": 0.23255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a library with a bookshelf filled with books. The books are arranged in various sizes and positions, creating an inviting atmosphere. There is a bench situated in the corner of the room."}, "527193": {"image_id": 527193, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.19154015512649578, "Bleu_3": 0.08902365931905547, "Bleu_4": 1.0845174330682731e-05, "METEOR": 0.2395930368238966, "ROUGE_L": 0.2053872053872054, "CIDEr": 4.939000126329835e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21052631578947367, "f": 0.186046511627907, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features three elephants in a zoo enclosure. The elephants are standing close together. One of the elephants is a baby, and the other two are adult elephants. The baby elephant is standing in the middle of the group, while the two adult elephants are standing on either side of the baby elephant."}, "277383": {"image_id": 277383, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.24809883171680105, "Bleu_3": 0.12568860753791988, "Bleu_4": 1.6039529419560237e-05, "METEOR": 0.23388463202017973, "ROUGE_L": 0.27403414195867026, "CIDEr": 0.0021408395429672925, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.15384615384615385, "f": 0.16326530612244897, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image captures a group of three people playing frisbee on a grassy field. The people are actively playing frisbee. \n\nThere are no other people in the scene.\n\nThe frisbee is being played."}, "417015": {"image_id": 417015, "Bleu_1": 0.222222222217284, "Bleu_2": 0.1421338109005459, "Bleu_3": 0.07773956660946078, "Bleu_4": 1.028417039620613e-05, "METEOR": 0.21032875765681486, "ROUGE_L": 0.2350674373795761, "CIDEr": 1.9006780534408827e-07, "SPICE": {"All": {"pr": 0.35, "re": 0.30434782608695654, "f": 0.3255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5, "f": 0.588235294117647, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a pink carnation placed in a vase, which is sitting on a table. The vase is made of plastic. The carnation is the main focus of the scene, with its vibrant color and delicate appearance. The vase is sitting on the table."}, "349525": {"image_id": 349525, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.29957234474633043, "Bleu_3": 0.24305681724091033, "Bleu_4": 0.15639686544681553, "METEOR": 0.26615056145810606, "ROUGE_L": 0.4327885468136323, "CIDEr": 0.08539127153219443, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a toaster oven sitting on a table. The toaster oven is silver. A person is standing nearby. The person is standing on the table."}, "567254": {"image_id": 567254, "Bleu_1": 0.3599999999928, "Bleu_2": 0.2571428571376619, "Bleu_3": 0.17662651284533257, "Bleu_4": 0.12374422938762035, "METEOR": 0.19273631875357433, "ROUGE_L": 0.2852466682253917, "CIDEr": 6.941636889291065e-08, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.16129032258064516, "f": 0.20833333333333331, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features two children standing in front of a television. One child is holding a pink toothbrush in their hand, possibly brushing their hair. The child's hair is blonde.\n\nThe television is positioned on the left side of the scene, and the children are located towards the center."}, "19783": {"image_id": 19783, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.2738612787414004, "Bleu_3": 1.4828975322020667e-06, "Bleu_4": 3.489214644859694e-09, "METEOR": 0.17817836599245476, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.012694990680390272, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2631578947368421, "f": 0.23809523809523808, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man standing on a rocky beach. Rocks and a beach are surrounding the man. There is a seagull in the image."}, "562292": {"image_id": 562292, "Bleu_1": 0.18309859154671693, "Bleu_2": 0.10228771509650086, "Bleu_3": 0.06718556183410934, "Bleu_4": 8.172025944802351e-06, "METEOR": 0.1733497639631885, "ROUGE_L": 0.16858590511285118, "CIDEr": 2.816604580192819e-23, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.16666666666666666, "f": 0.22727272727272724, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.21428571428571427, "f": 0.3, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features three women sitting on a bench. The first woman is wearing a black dress and black and white tights. She is holding a cell phone in her hand. The second woman is wearing a blue sweater and a blue dress. She is holding a black purse. The third woman is wearing a black hat and a white dress. She is holding a tennis ball. The tights are brown."}, "538819": {"image_id": 538819, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.08189821165837179, "Bleu_3": 5.561109032117353e-07, "Bleu_4": 1.4585628855619905e-09, "METEOR": 0.10774410774410775, "ROUGE_L": 0.13937547600913938, "CIDEr": 9.104984739757446e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17647058823529413, "f": 0.15789473684210528, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two square-shaped pizzas placed on a white surface, likely a table. Both pizzas are topped with a variety of ingredients, including cheese, tomatoes, and meat. The pizzas are cut into squares, making them easy to eat and share."}, "521259": {"image_id": 521259, "Bleu_1": 0.4999999999791667, "Bleu_2": 0.32969023668385783, "Bleu_3": 0.245642541542721, "Bleu_4": 0.19383418022593038, "METEOR": 0.283764155656827, "ROUGE_L": 0.5083333333333333, "CIDEr": 0.12426182981790534, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16666666666666666, "f": 0.1702127659574468, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image depicts a group of five people gathered in a field, playing with frisbees. Some of the people are playing with a frisbee."}, "470779": {"image_id": 470779, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.2576570236891632, "Bleu_3": 0.17220544249521463, "Bleu_4": 0.10003284273600065, "METEOR": 0.2427898876677717, "ROUGE_L": 0.29151732377538825, "CIDEr": 2.317481082688798e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.08823529411764706, "f": 0.13043478260869565, "fn": 31.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.21428571428571427, "f": 0.3157894736842105, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a group of eight people standing together on a snowy surface. They are all wearing skis and holding ski poles. The people are posing for a picture, smiling and enjoying their time on the snow. The group is spread out across the scene, with some people standing closer to the foreground."}, "92053": {"image_id": 92053, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.15360164850632854, "Bleu_3": 0.07496661627848239, "Bleu_4": 9.355354725668203e-06, "METEOR": 0.2020282509901111, "ROUGE_L": 0.2643553629469122, "CIDEr": 1.933009613894948e-14, "SPICE": {"All": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features a dining table with three plates of food and two drinks. The plates contain different types of food, such as sandwiches and sausages. The drinks have swans on them. The food plates also contain sausages, mashed potatoes, and gravy. The sandwiches contain meat, cheese, and vegetables. The cup on the table is filled with water."}, "361687": {"image_id": 361687, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.17720317768650332, "Bleu_3": 8.936417387415975e-07, "Bleu_4": 2.0183917843818546e-09, "METEOR": 0.2134505904527774, "ROUGE_L": 0.3084702907711757, "CIDEr": 3.2469449271206336e-08, "SPICE": {"All": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2222222222222222, "f": 0.3636363636363636, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a baby sleeping in a crib. The baby's hand is holding a toothbrush. The baby's hand is reaching out from the crib. The baby is reaching for a blanket. The teddy bear is placed on the left side of the crib."}, "386879": {"image_id": 386879, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.34419020751467316, "Bleu_3": 0.3093943246446202, "Bleu_4": 0.27918404944998537, "METEOR": 0.3569048642248556, "ROUGE_L": 0.4218533886583678, "CIDEr": 2.5237602804193078e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.12, "f": 0.12244897959183673, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a woman wearing a red tennis outfit. She is holding a tennis racket in her hand. The woman is playing tennis and posing for the camera. She is standing in front of a tree, which adds a natural element."}, "461855": {"image_id": 461855, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.27715276610008205, "Bleu_3": 0.22014152945079551, "Bleu_4": 0.15713284450350143, "METEOR": 0.31469810137326537, "ROUGE_L": 0.38857431749241655, "CIDEr": 0.00010477024074113313, "SPICE": {"All": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 27.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image is a black and white photograph of a child sitting on a couch. The child is playing with a teddy bear, which is being held by the child. A stuffed animal is situated towards the right."}, "315610": {"image_id": 315610, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.25043516133286925, "Bleu_3": 0.1986553232654495, "Bleu_4": 0.11907182322286093, "METEOR": 0.28327883823629973, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.4658659394684732e-06, "SPICE": {"All": {"pr": 0.3125, "re": 0.2, "f": 0.24390243902439027, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a ferris wheel located in the center of the scene. A large crowd surrounds the ferris wheel. There is one ferris wheel in the image. \n\nSeveral airplanes are flying in the sky. \n\nThe airplanes are flying in the sky."}, "419560": {"image_id": 419560, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.21997067252504504, "Bleu_3": 0.11727427861112526, "Bleu_4": 1.5356865412668173e-05, "METEOR": 0.2710663238016617, "ROUGE_L": 0.32562277580071175, "CIDEr": 0.0002784991565945205, "SPICE": {"All": {"pr": 0.28, "re": 0.2916666666666667, "f": 0.2857142857142857, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5454545454545454, "f": 0.5217391304347826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features two giraffes standing together in a field. Bushes, trees, grass, and twigs are scattered around the area. The giraffes appear to be enjoying their time in the open field."}, "136271": {"image_id": 136271, "Bleu_1": 0.31034482758085613, "Bleu_2": 0.18074256993548982, "Bleu_3": 0.08355599714953282, "Bleu_4": 1.0148282480369203e-05, "METEOR": 0.24555067280035792, "ROUGE_L": 0.23591160220994478, "CIDEr": 4.2144049718992095e-13, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.2, "f": 0.17241379310344826, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.45454545454545453, "f": 0.3703703703703703, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image showcases a large grocery store with a fruit section displaying a variety of apples and oranges. The apples are arranged in multiple baskets, with some placed on the left side of the store and others on the right side. The oranges are not mentioned in the supplementary information, so there is no specific information about them."}, "174633": {"image_id": 174633, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.14524007059304897, "Bleu_4": 0.09604819623180479, "METEOR": 0.21688883229197356, "ROUGE_L": 0.2897862232779097, "CIDEr": 1.3564863624683968e-05, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.09375, "f": 0.11764705882352941, "fn": 29.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man and a boy skiing down a snowy slope. The man is wearing a black jacket and is holding the hand of the child. They are skiing together, enjoying their time on the snowy hill."}, "122120": {"image_id": 122120, "Bleu_1": 0.24999999999218758, "Bleu_2": 0.12700012699615779, "Bleu_3": 8.131344326636123e-07, "Bleu_4": 2.0750198922948024e-09, "METEOR": 0.20999227638355628, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.0004297245353248563, "SPICE": {"All": {"pr": 0.2, "re": 0.13793103448275862, "f": 0.16326530612244897, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image captures a person performing a skateboard trick in mid-air. The skateboarder is wearing a red shirt and is skillfully riding their skateboard, showcasing their talent. The skateboard is in mid-air."}, "34015": {"image_id": 34015, "Bleu_1": 0.4594594594470417, "Bleu_2": 0.3195341955041846, "Bleu_3": 0.20607689301911084, "Bleu_4": 2.252434881196857e-05, "METEOR": 0.3408498343661659, "ROUGE_L": 0.416382252559727, "CIDEr": 0.0006401312878644553, "SPICE": {"All": {"pr": 0.15625, "re": 0.19230769230769232, "f": 0.1724137931034483, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a man wearing a red shirt and blue shorts, walking across a tennis court. The man is holding a tennis racket. The tennis court has a blue surface and white lines indicating the boundaries."}, "369460": {"image_id": 369460, "Bleu_1": 0.31147540983095945, "Bleu_2": 0.2695878254410102, "Bleu_3": 0.21439410618691002, "Bleu_4": 0.15025638878393477, "METEOR": 0.28751662283149554, "ROUGE_L": 0.2912466843501326, "CIDEr": 1.2887904270877106e-14, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.10714285714285714, "f": 0.15384615384615383, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a woman standing on the sidewalk. She is talking on her cell phone and holding a cell phone. The woman is wearing a black outfit and appears to be engaged in a conversation. The woman is positioned near a bus stop, which is visible in the background.\n\nThere is a man on a cell phone in the scene."}, "240049": {"image_id": 240049, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.276533159369469, "Bleu_3": 0.19085369914763303, "Bleu_4": 0.12140538257408166, "METEOR": 0.2732607390163281, "ROUGE_L": 0.28960278525083083, "CIDEr": 0.011665681531036882, "SPICE": {"All": {"pr": 0.125, "re": 0.1875, "f": 0.15, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a woman and a child standing near a fence, watching two giraffes in a zoo enclosure. The giraffes are standing close to the fence, eating grass. The woman is holding a baby."}, "168686": {"image_id": 168686, "Bleu_1": 0.37254901960053827, "Bleu_2": 0.19301528944440835, "Bleu_3": 0.0912702236920151, "Bleu_4": 1.1218544806846731e-05, "METEOR": 0.19349561777971833, "ROUGE_L": 0.25553560742070613, "CIDEr": 1.477485435316157e-10, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a table filled with a variety of fresh fruits and vegetables. There are several bunches of broccoli placed on the table, with some of them in baskets. The broccoli is spread across different areas of the table. Blueberries, apples, oranges, and bananas are also placed on the table."}, "195172": {"image_id": 195172, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.1689414875462283, "Bleu_3": 0.12679871840525084, "Bleu_4": 1.4932763392911851e-05, "METEOR": 0.2693710700561764, "ROUGE_L": 0.29985955056179775, "CIDEr": 4.128987634127996e-08, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.125, "f": 0.15789473684210525, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a giraffe walking in the grass and standing in a field. The giraffe is the main focus of the scene, with its long neck and legs visible. The field is quite large, providing ample space for the giraffe to move around."}, "124798": {"image_id": 124798, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.23302069120966015, "Bleu_3": 0.14824500676535907, "Bleu_4": 0.10738497851612415, "METEOR": 0.21103017904269905, "ROUGE_L": 0.22048192771084338, "CIDEr": 6.553003688969255e-11, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2608695652173913, "f": 0.3, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image depicts a bus driving down the road. The bus is blue and yellow. There are at least 8 cars and 1 truck visible in the scene. The bus is surrounded by a yellow and blue bus positioned behind it and another yellow and blue bus positioned in front of it."}, "279809": {"image_id": 279809, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.08359497709435722, "Bleu_3": 5.122150570969723e-07, "Bleu_4": 1.2740800388313793e-09, "METEOR": 0.16221707617251752, "ROUGE_L": 0.1862026862026862, "CIDEr": 1.357819783929582e-13, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features two cats sitting on a window sill. One cat is looking at the window, while the other cat is looking at a snowy surface. The cats appear to be gazing at a snowy scene. In the background, there is a chair and a window. There is no cross in the image."}, "170898": {"image_id": 170898, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.22488822254677632, "Bleu_3": 0.1217844383284592, "Bleu_4": 1.608247581870839e-05, "METEOR": 0.24957276710109685, "ROUGE_L": 0.3726003490401396, "CIDEr": 0.0022535895209699814, "SPICE": {"All": {"pr": 0.28, "re": 0.30434782608695654, "f": 0.2916666666666667, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a person lying on a couch, partially covered by a blanket. The person is not sleeping. The couch is situated in a room with a bed nearby."}, "274411": {"image_id": 274411, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.15849534045439814, "Bleu_3": 0.1045209718275127, "Bleu_4": 0.07178529103115949, "METEOR": 0.17995562150329972, "ROUGE_L": 0.26991150442477874, "CIDEr": 3.273095293584442e-08, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.2727272727272727, "f": 0.3428571428571428, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features a woman standing on a tennis court. She is holding a tennis racket and playing tennis. She is wearing a blue and white dress, which complements her tennis outfit. The tennis court is surrounded by a fence. There is a car parked nearby."}, "449379": {"image_id": 449379, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1458649914948234, "Bleu_3": 7.733595213409628e-07, "Bleu_4": 1.7905355543488007e-09, "METEOR": 0.1888407694538457, "ROUGE_L": 0.19551282051282048, "CIDEr": 3.9778694400602293e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3157894736842105, "f": 0.2608695652173913, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features three cats sleeping on a red couch. They are all lying down, with some cats positioned closer to the front and others towards the back of the couch. The cats are spread out, with some lying on top of each other, creating a cozy scene."}, "475660": {"image_id": 475660, "Bleu_1": 0.14965986394456016, "Bleu_2": 0.11543776806722386, "Bleu_3": 0.08200236229749845, "Bleu_4": 0.05821829244500972, "METEOR": 0.18705813748840383, "ROUGE_L": 0.17366548042704627, "CIDEr": 5.975069102156473e-96, "SPICE": {"All": {"pr": 0.35, "re": 0.35, "f": 0.35, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a lively scene in front of the United States Capitol building, where a group of people is gathered to watch a band performing on a truck. The band members are standing on top of the truck, playing their instruments. The band members are playing a trumpet, a guitar, a drum, and a keyboard. The president and his family are the band members entertaining.\n\nThere are six people gathered to watch the band. Some of the people are gathered to watch a man play a trumpet, some are gathered to watch a performance by a musician, and others are gathered to watch a man playing an electric guitar. Some people are also gathered to watch a political debate and a parade.\n\nThere are no other instruments in the scene.\n\nThere is a crowd gathered to watch the band.\n\nThere are twelve people in the scene."}, "125535": {"image_id": 125535, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.08268590713763764, "Bleu_4": 1.0646588104479637e-05, "METEOR": 0.16388158626906557, "ROUGE_L": 0.19869706840390877, "CIDEr": 2.009042048049522e-09, "SPICE": {"All": {"pr": 0.1, "re": 0.10526315789473684, "f": 0.10256410256410256, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two birds perched on a tree. The birds are spread across the tree, with some birds closer to the top and others near the bottom. The birds are of various sizes and are positioned in different areas of the tree, creating a lively scene."}, "353898": {"image_id": 353898, "Bleu_1": 0.3953488372001082, "Bleu_2": 0.2744167276557231, "Bleu_3": 0.17662527598171215, "Bleu_4": 1.9265249695988542e-05, "METEOR": 0.3341409400474137, "ROUGE_L": 0.3924231593995712, "CIDEr": 3.4533877843615384e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10714285714285714, "f": 0.12244897959183672, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a man sitting on a bench in a park. The man is surrounded by a flock of birds. The birds are feeding on the ground around the man. Pigeons are scattered throughout the park, with some closer to the bench."}, "177539": {"image_id": 177539, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.23294541396842086, "Bleu_3": 0.13833056672829191, "Bleu_4": 1.6038864534634092e-05, "METEOR": 0.22034185398064438, "ROUGE_L": 0.3400696864111499, "CIDEr": 4.149454629413041e-07, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.2222222222222222, "f": 0.2424242424242424, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a man standing on a beach, holding a surfboard and preparing to surf. The man is wearing striped shorts. He is also wearing a life jacket, which is essential for safety while surfing.\n\nThe surfboard is positioned on the beach."}, "467791": {"image_id": 467791, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.11467434132484901, "Bleu_3": 0.06133182450191993, "Bleu_4": 8.011565846312634e-06, "METEOR": 0.18177734259027897, "ROUGE_L": 0.1994550408719346, "CIDEr": 6.954394444659141e-13, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image captures a baseball game in progress. The batter is at home plate, holding a baseball bat and preparing to hit the ball. The catcher is positioned behind the batter, ready to catch. The umpire is a baseball umpire, closely observing the play.\n\nThere is no ball in the image.\n\nThere are no other players in the scene."}, "197918": {"image_id": 197918, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.12830983841207666, "Bleu_3": 7.501563151170701e-07, "Bleu_4": 1.8256517093417544e-09, "METEOR": 0.1850772407979356, "ROUGE_L": 0.25756509500351865, "CIDEr": 4.85820570237842e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a young girl and a boy standing next to each other in a room. The girl is holding a stuffed animal. The boy is brushing his teeth. They appear to be enjoying their time together in the room."}, "153524": {"image_id": 153524, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.16302782918400804, "Bleu_3": 0.10904101282262468, "Bleu_4": 0.075453155981989, "METEOR": 0.2659384405641161, "ROUGE_L": 0.29756097560975614, "CIDEr": 1.4928401964809568e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.20833333333333334, "f": 0.1923076923076923, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a desk with two computer monitors, one on the left side and the other on the right side. Both monitors are turned on. There are keyboards placed in front of each monitor. There are also two mice on the desk."}, "449428": {"image_id": 449428, "Bleu_1": 0.4081632652977926, "Bleu_2": 0.20619652470632874, "Bleu_3": 9.671376154273476e-07, "Bleu_4": 2.1058466792007324e-09, "METEOR": 0.25621470650391315, "ROUGE_L": 0.26341764342998153, "CIDEr": 2.026285331848702e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.25, "f": 0.22727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features three cows standing in a field. The cows are brown and black and white. They are grazing in the field and focused on a hay bale. The field is spacious, providing ample room for the cows to graze.\n\nThe cows are positioned behind a wire fence."}, "231140": {"image_id": 231140, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.264906471406127, "Bleu_3": 0.19649332466126906, "Bleu_4": 0.1432823594354297, "METEOR": 0.2682605600015599, "ROUGE_L": 0.3655430711610487, "CIDEr": 1.0374765406136921e-05, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1111111111111111, "f": 0.10256410256410256, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features a group of seven zebras standing in a grassy field in front of a building. The zebras are scattered across the field, with some closer to the building. The zebras are black and white in color."}, "540449": {"image_id": 540449, "Bleu_1": 0.17543859648815024, "Bleu_2": 0.1480872194371519, "Bleu_3": 0.10615274788259942, "Bleu_4": 0.06860408726311093, "METEOR": 0.242176694090124, "ROUGE_L": 0.2733893557422969, "CIDEr": 2.1342244465526654e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.12121212121212122, "f": 0.163265306122449, "fn": 29.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a dog laying in the car. The dog is sitting on a car seat and looking at a person. The dog appears to be relaxed. There is a chair visible in the scene. Some of the chairs are placed in the back of the car. There is no view or street in the scene."}, "182755": {"image_id": 182755, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.272021638232674, "Bleu_3": 0.19172225782536853, "Bleu_4": 0.11450077782939158, "METEOR": 0.24816291400036175, "ROUGE_L": 0.3342465753424657, "CIDEr": 1.3824422282494825e-07, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.30434782608695654, "f": 0.3684210526315789, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.7142857142857143, "f": 0.7142857142857143, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a wooden desk with a large wooden wall behind it. On the desk, there are a laptop, two computer monitors, a keyboard, and a mouse. The laptops are placed on the desk. The desktop monitors are also placed on the desk."}, "159170": {"image_id": 159170, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.183339699400327, "Bleu_3": 1.0061584140131916e-06, "Bleu_4": 2.375266140572166e-09, "METEOR": 0.23321541716930833, "ROUGE_L": 0.2622527944969905, "CIDEr": 7.415587119838969e-05, "SPICE": {"All": {"pr": 0.24, "re": 0.2222222222222222, "f": 0.23076923076923075, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a cat lying on a couch. The cat is orange and appears to be relaxed, resting its head on its paw. The couch is situated in a room with a gray background."}, "408480": {"image_id": 408480, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.19847906537508855, "Bleu_3": 0.09712260421875578, "Bleu_4": 1.2152843817707948e-05, "METEOR": 0.21169639155912182, "ROUGE_L": 0.2742453436095055, "CIDEr": 8.086911539983507e-08, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2727272727272727, "f": 0.2666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a large red lighthouse situated on a pier, with a boat docked next to it. The lighthouse serves as a beacon for ships and is a prominent landmark in the scene. The boat is positioned on the left side of the lighthouse."}, "538242": {"image_id": 538242, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 0.09809046705543314, "Bleu_4": 1.2907744865533497e-05, "METEOR": 0.19689864365531096, "ROUGE_L": 0.2293233082706767, "CIDEr": 5.996890790841171e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.26666666666666666, "f": 0.2051282051282051, "fn": 22.0, "numImages": 1.0, "fp": 40.0, "tp": 8.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2916666666666667, "re": 0.5, "f": 0.3684210526315789, "fn": 7.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}}, "caption": "The image features two men wearing military uniforms. One of the men is riding a motorcycle, while the other is walking. The motorcycle is parked on a tarmac. The scene appears to be in a parking lot."}, "552153": {"image_id": 552153, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.17616606584843764, "Bleu_3": 1.0348931048234187e-06, "Bleu_4": 2.531224579106017e-09, "METEOR": 0.24848935657856253, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.0008868224887629711, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a small airplane flying high in the sky. The airplane is positioned towards the center of the scene, soaring above a mountain range. The sky is gray."}, "63617": {"image_id": 63617, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.183339699400327, "Bleu_3": 1.0061584140131916e-06, "Bleu_4": 2.375266140572166e-09, "METEOR": 0.19819098025320436, "ROUGE_L": 0.28960278525083083, "CIDEr": 0.00014715476731592747, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a boy wearing a blue jacket and glasses, standing on a deck. The boy is throwing a baseball. He is focused on the baseball and not yet ready to make the throw.\n\n"}, "366529": {"image_id": 366529, "Bleu_1": 0.5365853658405711, "Bleu_2": 0.327592846633487, "Bleu_3": 0.17655420655385867, "Bleu_4": 1.950799577836031e-05, "METEOR": 0.246392746701786, "ROUGE_L": 0.449430676490288, "CIDEr": 1.3938868312270065e-05, "SPICE": {"All": {"pr": 0.3, "re": 0.15789473684210525, "f": 0.20689655172413793, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a couple dressed in a white wedding dress. The man is dressed in a white suit and wearing a tie. The woman is dressed in a wedding dress and wearing a veil. They are posing for a picture."}, "282841": {"image_id": 282841, "Bleu_1": 0.20312499999682618, "Bleu_2": 0.1269686250438429, "Bleu_3": 0.08041623075336025, "Bleu_4": 0.05403502118618189, "METEOR": 0.15316097841188783, "ROUGE_L": 0.1881167763157895, "CIDEr": 2.8935723957981482e-18, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a table made of wood. On the table, there is a mirror with a metal pan placed on it. The mirror is reflecting the metal pan. \n\nIn front of the mirror, there is a person who is playing a drum. The person is wearing a hat, which can be seen in the reflection. \n\nThere are no knives placed on the wall."}, "169679": {"image_id": 169679, "Bleu_1": 0.15789473684002772, "Bleu_2": 0.15217718204852076, "Bleu_3": 0.12336904476804283, "Bleu_4": 0.09372474126533112, "METEOR": 0.2645399763523951, "ROUGE_L": 0.24292035398230086, "CIDEr": 1.8966161113189073e-26, "SPICE": {"All": {"pr": 0.2, "re": 0.16, "f": 0.17777777777777778, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features three people standing on a snow-covered slope. One person is posing for a picture, wearing a blue jacket. The other two people are skiing, wearing ski jackets. \n\nThere is a ski lift on the slope.\n\nThere is no camera in the scene.\n\nThere is no skier in the scene.\n\nThere is one person skating on the ice.\n\nThere are two mountains in the scene.\n\nThe overall scene depicts people on a ski slope."}, "427034": {"image_id": 427034, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.22037727300834692, "Bleu_3": 0.1292360563774017, "Bleu_4": 0.08369019961116494, "METEOR": 0.3061438748435523, "ROUGE_L": 0.30367143746110764, "CIDEr": 1.3178473958018852e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.19230769230769232, "f": 0.23255813953488372, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.45454545454545453, "f": 0.5555555555555556, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a dog lying on a laptop keyboard, seemingly enjoying the warmth of the laptop. The dog is positioned on the keyboard, with its head resting on it. The laptop is placed on a dining table, and there are several books scattered around the table."}, "381527": {"image_id": 381527, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.2641352718914714, "Bleu_3": 0.20414855750042327, "Bleu_4": 0.15893701509678138, "METEOR": 0.2778802284668627, "ROUGE_L": 0.25003415767181314, "CIDEr": 1.1781705197521078e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09523809523809523, "f": 0.12121212121212123, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image captures a lively skateboarding scene at a skate park, with a man performing a trick on his skateboard. He is in mid-air, showcasing his skills and impressing the onlookers. There are several other people in the park, watching the skateboarding action."}, "81661": {"image_id": 81661, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.16379642331674352, "Bleu_3": 0.08827710327692938, "Bleu_4": 1.1599523689534566e-05, "METEOR": 0.24601437796150852, "ROUGE_L": 0.27875095201827876, "CIDEr": 1.2207169745251536e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.20833333333333334, "f": 0.25, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a table with a laptop, a remote control, and a Coca-Cola can scattered across it. There is also a cell phone and a keyboard on the table. The other object placed on the table is a remote control."}, "501368": {"image_id": 501368, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.12923605637746155, "Bleu_4": 0.08322132850557713, "METEOR": 0.21968351829630864, "ROUGE_L": 0.28018372703412076, "CIDEr": 8.029800491044283e-09, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.22580645161290322, "f": 0.2857142857142857, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.4166666666666667, "f": 0.4761904761904762, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a woman standing in a bathroom. The woman is brushing her hair and holding a towel. She is looking at a mirror. The bathroom has a blue wall. The woman is wearing a yellow shirt.\n\nIn the background, there is a sink and a toilet."}, "51119": {"image_id": 51119, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.2033063824917087, "Bleu_4": 0.1720067346632129, "METEOR": 0.23452476230439398, "ROUGE_L": 0.29204069419509276, "CIDEr": 5.171191412588627e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.1724137931034483, "f": 0.19607843137254902, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a bus that has been severely damaged, with its front end completely destroyed. The bus is parked on the side of a road, and the fire that caused the damage is still visible. The fire appears to have been extinguished, but the bus remains in a burnt state."}, "502006": {"image_id": 502006, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.15249857032909853, "Bleu_3": 0.1034595892554256, "Bleu_4": 0.07209117403210415, "METEOR": 0.24129074653421956, "ROUGE_L": 0.2506849315068493, "CIDEr": 1.2824136531100976e-07, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 39.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}}, "caption": "The image features a brown bear and her cub walking through a lush green forest. The mother bear is positioned in the center of the scene, while the cub is following closely behind her. The bears are exploring the area, possibly searching for food."}, "213457": {"image_id": 213457, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.14118624159718107, "Bleu_3": 7.863217694465758e-07, "Bleu_4": 1.867175871883868e-09, "METEOR": 0.2032350390174619, "ROUGE_L": 0.25505226480836235, "CIDEr": 9.386436423837934e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.09523809523809523, "f": 0.1081081081081081, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image captures a man skiing on a snowy slope. He is performing a trick in mid-air, skillfully executing the jump with his skis on. The man is wearing a black and yellow jacket, which adds a pop of color to the scene."}, "138549": {"image_id": 138549, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.26437184629550714, "Bleu_3": 0.16892248770152052, "Bleu_4": 2.036929948775744e-05, "METEOR": 0.2861995651932641, "ROUGE_L": 0.3885350318471337, "CIDEr": 0.0018986688765452006, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.041666666666666664, "f": 0.04651162790697675, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image features a dining table with a plate of food. The plate is filled with a sandwich and oranges. The glass contains beer. The candle is positioned on the table."}, "579303": {"image_id": 579303, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.17928191078795241, "ROUGE_L": 0.24190350297422336, "CIDEr": 1.376778986221886e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.26666666666666666, "f": 0.23529411764705882, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a table with two sandwiches placed on it. One sandwich is located on the left side of the table, while the other is on the right side. Both sandwiches are cut in half, making them easier to eat.\n\nThere is also a cup on the table."}, "351744": {"image_id": 351744, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.16823164622440862, "Bleu_3": 0.10353608435894587, "Bleu_4": 1.220608250473103e-05, "METEOR": 0.2586105297408966, "ROUGE_L": 0.28554710356933877, "CIDEr": 7.727358216096678e-12, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.21739130434782608, "f": 0.23809523809523808, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks, with a blue and yellow engine car leading the way. The train is surrounded by several other cars, including blue and yellow cars. The train appears to be passing through a train station, as there are multiple sets of tracks visible in the scene."}, "521605": {"image_id": 521605, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.1587768372028858, "Bleu_3": 9.14155586877348e-07, "Bleu_4": 2.2104342120771487e-09, "METEOR": 0.23737961788922038, "ROUGE_L": 0.3359559402045633, "CIDEr": 4.076217574166856e-05, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2, "f": 0.23076923076923075, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a plate of food with a variety of ingredients, including a fried egg. The plate is placed on a dining table. The fried egg is positioned towards the center of the plate."}, "494439": {"image_id": 494439, "Bleu_1": 0.3181818181673554, "Bleu_2": 0.2132007163456888, "Bleu_3": 0.13147679471019455, "Bleu_4": 1.859723721145683e-05, "METEOR": 0.24430620708883174, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.04488075396795756, "SPICE": {"All": {"pr": 0.10810810810810811, "re": 0.13333333333333333, "f": 0.11940298507462686, "fn": 26.0, "numImages": 1.0, "fp": 33.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.06666666666666667, "re": 0.14285714285714285, "f": 0.09090909090909091, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a train station with a blue and white train on the tracks. The train is positioned on the tracks."}, "209753": {"image_id": 209753, "Bleu_1": 0.3953488372001082, "Bleu_2": 0.32178213603889433, "Bleu_3": 0.24745548504430984, "Bleu_4": 0.1659072308632014, "METEOR": 0.3304757757859882, "ROUGE_L": 0.34882058613295214, "CIDEr": 2.5447351327352975e-05, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.16666666666666666, "f": 0.18867924528301885, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a woman standing in a room. She is looking at her cell phone and appears to be focused on her phone screen. The woman is wearing a black dress.\n\nIn the background, there are no other people in the room."}, "435709": {"image_id": 435709, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.12577746725443983, "Bleu_4": 1.434424417587908e-05, "METEOR": 0.24129417457899283, "ROUGE_L": 0.27128335451080055, "CIDEr": 1.1506131286265621e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15, "f": 0.1764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image is a black and white photograph of a city street with tall buildings surrounding the area. The street is lined with various shops and businesses, creating a bustling urban atmosphere.\n\nThere are multiple cars parked along the street, with some closer to the foreground and others further back."}, "38029": {"image_id": 38029, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.19908326484038252, "Bleu_3": 1.005390939719818e-06, "Bleu_4": 2.2740778402219888e-09, "METEOR": 0.2562212746479907, "ROUGE_L": 0.2866092404072043, "CIDEr": 8.438258939903506e-07, "SPICE": {"All": {"pr": 0.5, "re": 0.3793103448275862, "f": 0.4313725490196078, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 11.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.5384615384615384, "f": 0.608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image captures a parade scene with a large red fire hydrant float being pulled down the street. The fire hydrant is prominently featured in the image. The float is being pulled by a truck, which is visible in the background."}, "434494": {"image_id": 434494, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.14815943949377966, "Bleu_3": 8.256538592718127e-07, "Bleu_4": 1.961790432840902e-09, "METEOR": 0.12580262955525853, "ROUGE_L": 0.17617328519855593, "CIDEr": 1.0474633427164922e-06, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.26666666666666666, "f": 0.33333333333333337, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features six construction workers standing on a wet road, possibly near a construction site. Some of the construction workers are standing closer to the front and others further back. They appear to be observing a piece of construction equipment."}, "171062": {"image_id": 171062, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1940285000252239, "Bleu_3": 0.09158935294477764, "Bleu_4": 1.124795146748506e-05, "METEOR": 0.21151177375437172, "ROUGE_L": 0.29204069419509276, "CIDEr": 2.8618028886740377e-10, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.21875, "f": 0.2857142857142857, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a cat sitting on a wooden table, intently watching a television screen. The cat is positioned towards the left side of the table, with its eyes focused on the screen. The television is placed on the right side of the table. The cat is enjoying a tv show."}, "238866": {"image_id": 238866, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.12903971808302675, "Bleu_3": 7.17923383724535e-07, "Bleu_4": 1.7029245450294905e-09, "METEOR": 0.18616347938420394, "ROUGE_L": 0.23843648208469054, "CIDEr": 1.666016836709593e-09, "SPICE": {"All": {"pr": 0.4, "re": 0.21428571428571427, "f": 0.27906976744186046, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a total of 32 donuts sitting on a cooling rack, which is placed on a table. The donuts are arranged in various positions, with some closer to the front and others further back. There are a total of 32 donuts visible in the scene."}, "428454": {"image_id": 428454, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.1412673303879691, "Bleu_3": 7.314271888618252e-07, "Bleu_4": 1.6725758582722137e-09, "METEOR": 0.19793240957291167, "ROUGE_L": 0.25707405177603854, "CIDEr": 1.6789472093897139e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.05555555555555555, "f": 0.08, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image features a man snowboarding on a snow-covered field. The man is holding a snowboard and wearing a green jacket. He is engaging in a winter activity. The kite is flying in the sky. The kite is red and blue. The man is wearing a helmet, likely for safety during this activity."}, "200945": {"image_id": 200945, "Bleu_1": 0.4054054053944486, "Bleu_2": 0.2599376224478953, "Bleu_3": 0.15687969824156975, "Bleu_4": 0.10322985794503843, "METEOR": 0.27923627928024775, "ROUGE_L": 0.3627867459643161, "CIDEr": 0.00017097317255257994, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a hot dog with various toppings, including pickles, onions, and relish. The hot dog is placed on a bun. There is no chips in the scene. The toppings include pickles, onions, tomatoes, and mustard."}, "391139": {"image_id": 391139, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.2823298512804342, "Bleu_3": 0.2331952253744082, "Bleu_4": 0.1959589608403899, "METEOR": 0.2995607473848813, "ROUGE_L": 0.3611163315166323, "CIDEr": 6.982406657616827e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a dog sitting on a wooden bench. The dog is surrounded by hay, and there is a hay bale in front of the dog. The bench is located next to a pumpkin. There are also two ears of corn scattered around the scene."}, "440093": {"image_id": 440093, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.2936101097470465, "Bleu_3": 0.18552513121036915, "Bleu_4": 2.2261720385127662e-05, "METEOR": 0.23290391650458336, "ROUGE_L": 0.3373271889400921, "CIDEr": 0.005369774797123594, "SPICE": {"All": {"pr": 0.15, "re": 0.12, "f": 0.1333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image captures a skateboarder performing a trick on a ramp, soaring through the air with their skateboard. The skateboarder is in the air, showcasing their skill and athleticism."}, "555356": {"image_id": 555356, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 7.901769277795583e-07, "Bleu_4": 1.8299115122529755e-09, "METEOR": 0.16165770694433643, "ROUGE_L": 0.2046979865771812, "CIDEr": 1.6730378250720222e-09, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.2857142857142857, "f": 0.32, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.45454545454545453, "f": 0.5555555555555556, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a kitchen scene with a large oven and a microwave placed next to each other. A square piece of aluminum foil is sitting on the countertop in front of the oven. The aluminum foil is possibly waiting to be used for cooking or baking."}, "561270": {"image_id": 561270, "Bleu_1": 0.4444444444320988, "Bleu_2": 0.2760262237291648, "Bleu_3": 0.18873292695352512, "Bleu_4": 0.11946956198208009, "METEOR": 0.23822275233164703, "ROUGE_L": 0.37014563106796117, "CIDEr": 0.005927793327133038, "SPICE": {"All": {"pr": 0.25, "re": 0.15, "f": 0.18749999999999997, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a marina with three boats docked on the shore. The boats vary in size. One of the boats is red. Some of the boats are on the mud. Some are in the water."}, "351557": {"image_id": 351557, "Bleu_1": 0.29508196720827734, "Bleu_2": 0.21038606199200532, "Bleu_3": 0.09086444379365423, "Bleu_4": 1.0664450456229356e-05, "METEOR": 0.23166691891598984, "ROUGE_L": 0.24936126724578436, "CIDEr": 6.524670869856502e-16, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2916666666666667, "f": 0.30434782608695654, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a group of nine people standing outside a building, leaning against a wall, and watching a kite flying in the sky. \n\nSome of the people are holding a kite and sitting on a bench, while others are holding a flag and walking down the street. They are all focused on the kite, which is flying in the air."}, "123131": {"image_id": 123131, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1642880193591135, "Bleu_3": 0.1298306125408015, "Bleu_4": 0.10500614219604797, "METEOR": 0.25609515116310017, "ROUGE_L": 0.2347959969207082, "CIDEr": 2.5533238239139476e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13793103448275862, "f": 0.1509433962264151, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features three trucks parked in a parking lot. The trucks are black, yellow, and silver respectively. One of the trucks has a trailer attached to its back. The trailer is extending from the front of the truck."}, "326248": {"image_id": 326248, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.13608276348545723, "Bleu_3": 0.10158210507509738, "Bleu_4": 0.06700574965504925, "METEOR": 0.16586823708571022, "ROUGE_L": 0.17579250720461098, "CIDEr": 5.690427916175449e-13, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.2, "f": 0.18750000000000003, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image captures a tennis match in progress, with a man standing on a ladder and holding a tennis racket. The man is reaching for a tennis ball. \n\nThere are four men in the scene, all holding a tennis racket and reaching for a tennis racket. \n\nOverall, the scene takes place on a tennis court."}, "531852": {"image_id": 531852, "Bleu_1": 0.3103448275755054, "Bleu_2": 0.2578807147685126, "Bleu_3": 0.2309305147269271, "Bleu_4": 0.20863283212695624, "METEOR": 0.36837415640680515, "ROUGE_L": 0.5059907834101383, "CIDEr": 0.006041981511395483, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features two men standing in a living room. The men are holding a Nintendo Wii remote in their hands. The living room is furnished with a couch."}, "205720": {"image_id": 205720, "Bleu_1": 0.4999999999880953, "Bleu_2": 0.3981665296810021, "Bleu_3": 0.2875677987173835, "Bleu_4": 0.18687299105743743, "METEOR": 0.392925931120025, "ROUGE_L": 0.5252152521525214, "CIDEr": 4.26481343268543e-05, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1875, "f": 0.15384615384615383, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a man standing on a boat, talking on a cell phone. The man is holding the phone to his ear, engaged in a conversation. The boat is positioned near a city, with several tall buildings visible in the background."}, "69223": {"image_id": 69223, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.1288848155535838, "Bleu_3": 7.399571153427093e-07, "Bleu_4": 1.7839797285693462e-09, "METEOR": 0.17021097632343235, "ROUGE_L": 0.22377109317681584, "CIDEr": 2.1089631355807258e-08, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman standing in a bathroom, looking at a large, fancy bathtub. The bathtub is surrounded by a marble-tiled wall, giving the bathroom a luxurious and elegant appearance. The woman is holding a cell phone and looking at a mirror."}, "233311": {"image_id": 233311, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.22893427324353557, "Bleu_3": 0.1591571275450723, "Bleu_4": 0.11213327957896793, "METEOR": 0.2613274046606774, "ROUGE_L": 0.3279569892473118, "CIDEr": 1.0488828135964815e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a table with a stuffed monkey sitting on top of it. The monkey is positioned near a bowl filled with oranges. The oranges are spread across the table. Some of the oranges are an orange color. Some of the oranges are yellow. The monkey is sitting on top of the table."}, "460294": {"image_id": 460294, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1942853726806771, "Bleu_3": 0.12358053507490456, "Bleu_4": 0.08340582868762969, "METEOR": 0.29853764962256013, "ROUGE_L": 0.29901960784313725, "CIDEr": 5.749382649430833e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.2, "f": 0.15789473684210528, "fn": 24.0, "numImages": 1.0, "fp": 40.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.5, "f": 0.35714285714285715, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "The image is a black and white photograph of three women standing in a parking lot. They are all holding umbrellas, possibly to protect themselves from the sun or rain. The woman in the middle of the picture is holding an umbrella."}, "107907": {"image_id": 107907, "Bleu_1": 0.11538461538350593, "Bleu_2": 0.06693994276349531, "Bleu_3": 0.035285003690946636, "Bleu_4": 4.56680304495898e-06, "METEOR": 0.16401132820101286, "ROUGE_L": 0.1043091655266758, "CIDEr": 7.457087136189597e-52, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a unique art installation in a museum, consisting of three chairs and a tire. The chairs are placed on a stand. Each chair has a different attachment, creating interesting and unconventional pieces of art. The first chair appears to be a bench, with a glass table attached to it. The second chair appears to be a piano, with a large metal pipe attached to it. The third chair appears to be a radiator, with a radiator attached to it. The tire creates a seat, and it appears to be a toilet. \n\nThere are no other objects or artworks in the scene."}, "463084": {"image_id": 463084, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.20641345956409557, "Bleu_3": 0.15704632576959385, "Bleu_4": 0.13014796834239736, "METEOR": 0.22919809300962185, "ROUGE_L": 0.304847576211894, "CIDEr": 2.2273276962270246e-11, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features two buses parked on the side of the road. The buses are positioned on the street. There are several cars parked or driving nearby. \n\nIn addition to the buses and cars, there are two people visible. A woman in a blue shirt is visible. The saga of the San Francisco ferry 0 is visible."}, "279621": {"image_id": 279621, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.327326835338012, "Bleu_3": 0.17799311659104844, "Bleu_4": 2.3658340569278314e-05, "METEOR": 0.27168976241978354, "ROUGE_L": 0.39739413680781754, "CIDEr": 0.1883413546233888, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks, passing through the scenic countryside. The train is positioned on the tracks."}, "199438": {"image_id": 199438, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.1390596095466697, "Bleu_4": 1.538475005178854e-05, "METEOR": 0.19789077040179182, "ROUGE_L": 0.2501464557703574, "CIDEr": 1.0703472212983313e-09, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.19230769230769232, "f": 0.16666666666666669, "fn": 21.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.125, "f": 0.08695652173913045, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man and a woman paddling a boat on a lake. They are both wearing life jackets, ensuring their safety while enjoying their time on the water. The boat is positioned in the middle of the lake. The man and woman are not sitting close to each other."}, "160341": {"image_id": 160341, "Bleu_1": 0.25714285713918367, "Bleu_2": 0.17266633891820174, "Bleu_3": 0.10956602377949345, "Bleu_4": 0.06656381810506862, "METEOR": 0.2230406687506019, "ROUGE_L": 0.1967741935483871, "CIDEr": 7.295118711935846e-21, "SPICE": {"All": {"pr": 0.2, "re": 0.11538461538461539, "f": 0.14634146341463417, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a mountain with a ski lodge in the background. A person is standing on the snowy slope, wearing a white jacket and holding skis and ski poles. The person is preparing to ski down the mountain. Some of the other people are skiing. Some of the other people are wearing a black jacket.\n\nThere is no specific information about the number of other people in the scene."}, "571196": {"image_id": 571196, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.16282722783536435, "Bleu_4": 1.7599168253428858e-05, "METEOR": 0.2818002363765494, "ROUGE_L": 0.27799479166666663, "CIDEr": 9.365363067389246e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.09090909090909091, "f": 0.08888888888888888, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a bed with a colorful blanket. A book is placed on the bed, open and ready to be read. The book is positioned towards the center of the bed, with its spine visible. The bed appears to be made. The blanket is not spread out."}, "370266": {"image_id": 370266, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.24308621739673564, "Bleu_3": 0.1764834841553867, "Bleu_4": 0.10695860479381795, "METEOR": 0.2472040260418964, "ROUGE_L": 0.29468599033816417, "CIDEr": 9.279221841576644e-08, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.09523809523809523, "f": 0.08163265306122448, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a group of six sheep grazing in a grassy field. Some sheep are closer to the foreground, while others are further back. The sheep are enjoying the green grass. Their presence creates a peaceful scene.\n\nIn the background, there are two farms."}, "458487": {"image_id": 458487, "Bleu_1": 0.4473684210408588, "Bleu_2": 0.26934407444214825, "Bleu_3": 0.15914052336111048, "Bleu_4": 1.8421227895358152e-05, "METEOR": 0.23588621138549024, "ROUGE_L": 0.3259541984732824, "CIDEr": 3.781951344001951e-05, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.1875, "f": 0.1791044776119403, "fn": 26.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.3333333333333333, "f": 0.3571428571428571, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image captures a baseball game in progress. The batter is standing on home plate, holding a baseball bat and preparing to hit the ball. The catcher is positioned behind the batter. The umpire is a baseball umpire."}, "521879": {"image_id": 521879, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.10783277320095921, "Bleu_3": 6.517545715819412e-07, "Bleu_4": 1.6120076571355242e-09, "METEOR": 0.13814937668976512, "ROUGE_L": 0.20265780730897012, "CIDEr": 2.222939857343744e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a lively scene at a carnival, where a group of people, including a man and a woman, are walking on the street. The man and woman are wearing costumes, including hats. They are accompanied by a horse. The people are running."}, "307784": {"image_id": 307784, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.22861497842409673, "Bleu_3": 1.0932423750469312e-06, "Bleu_4": 2.4058646499190447e-09, "METEOR": 0.18942476332244362, "ROUGE_L": 0.3292847503373819, "CIDEr": 0.04147486370861652, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a kitchen with a large white sink placed on a countertop. The sink is surrounded by a tiled backsplash, adding a touch of elegance to the space. Above the sink, there is a faucet with a knife holder nearby."}, "154095": {"image_id": 154095, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.14907119849663567, "Bleu_3": 0.08024900879514213, "Bleu_4": 1.0532159683631698e-05, "METEOR": 0.1632761753821767, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.1510828888078082e-07, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.14285714285714285, "f": 0.17647058823529413, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a bedroom with a bed and two chairs. On the bed, there are two backpacks, one blue and one orange. The orange backpack is positioned closer to the left side of the bed, while the blue backpack is on the right side."}, "222322": {"image_id": 222322, "Bleu_1": 0.17441860464913467, "Bleu_2": 0.11095900821699856, "Bleu_3": 5.272484141327573e-07, "Bleu_4": 1.1527680696260416e-09, "METEOR": 0.14669276415100638, "ROUGE_L": 0.14665811828818723, "CIDEr": 1.333453569468071e-35, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.10344827586206896, "f": 0.13043478260869565, "fn": 26.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a beach scene with a large number of people enjoying their time. There are three people in the scene. A woman in a red dress can be seen in a group. A man with a surfboard can be seen in a group. A woman in a black bikini can be seen in a group.\n\nThere are 21 umbrellas scattered across the beach. The umbrellas are blue and white. Some umbrellas are pink, multicolored, yellow, or blue.\n\nThere is no beach in the scene."}, "227042": {"image_id": 227042, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.10583300875240854, "Bleu_4": 1.356590733316526e-05, "METEOR": 0.25117151355598205, "ROUGE_L": 0.38231197771587744, "CIDEr": 0.006124699459752245, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.2857142857142857, "f": 0.3404255319148936, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image captures a group of four players wearing uniforms playing a soccer game on a field. The uniforms are blue and white. One player is kicking the ball, while the others are actively engaged in the game."}, "155897": {"image_id": 155897, "Bleu_1": 0.17741935483584811, "Bleu_2": 0.07626944360167771, "Bleu_3": 0.0459391866706192, "Bleu_4": 6.366847879468056e-06, "METEOR": 0.17060362892164863, "ROUGE_L": 0.19912948857453752, "CIDEr": 4.700510977712277e-18, "SPICE": {"All": {"pr": 0.1875, "re": 0.15789473684210525, "f": 0.17142857142857143, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features nine people sitting on a bench. One person is holding a bottle of water and drinking from it. Another person is holding a sandwich and eating it. Two sandwiches are placed on a plastic wrapper. The wrapper is made of plastic. The person is wearing a blue shirt.\n\nIn the background, there are no other notable objects or activities."}, "33798": {"image_id": 33798, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.08681823924888467, "Bleu_4": 1.1239895308238822e-05, "METEOR": 0.21110166738645245, "ROUGE_L": 0.2197406340057637, "CIDEr": 1.0146591375463979e-07, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.09090909090909091, "f": 0.10909090909090909, "fn": 30.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image depicts a living room with a couch situated in the center of the room. The couch is surrounded by several chairs, creating a comfortable seating area. A dining table is not present in the room. The room is surrounded by a wall."}, "490794": {"image_id": 490794, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.09087496586948689, "Bleu_4": 1.1854610697110774e-05, "METEOR": 0.22233204780669683, "ROUGE_L": 0.22021660649819497, "CIDEr": 3.644183453567371e-06, "SPICE": {"All": {"pr": 0.3125, "re": 0.18518518518518517, "f": 0.2325581395348837, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a city street with two roads. A traffic sign is hanging from a pole above the road. A car is driving down the street. A truck is also on the road. Some cars are positioned on the street."}, "381925": {"image_id": 381925, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.20603150145092247, "Bleu_3": 0.15236855057487514, "Bleu_4": 0.11076550621858337, "METEOR": 0.3158901975577332, "ROUGE_L": 0.326397146254459, "CIDEr": 4.760219156537204e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a girl sitting on a wooden bench, holding a dog in her arms. The girl is enjoying her time with the dog. The dog is white and brown. The bench is situated in front of a rock wall, which adds a sense of history to the scene."}, "145312": {"image_id": 145312, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.16351748503705, "Bleu_3": 9.418739954830287e-07, "Bleu_4": 2.278527011349529e-09, "METEOR": 0.2248824902503647, "ROUGE_L": 0.24478330658105937, "CIDEr": 0.00015159655414471407, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.30434782608695654, "f": 0.27999999999999997, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features two dogs playing with a frisbee in a grassy area. The dogs are catching the frisbee. The frisbee is flying through the air. The dogs appear to be enjoying the game."}, "65798": {"image_id": 65798, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.13160986848342301, "Bleu_4": 0.08390288290062609, "METEOR": 0.23574559783838095, "ROUGE_L": 0.3320631464344039, "CIDEr": 1.1309232221098099e-07, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.30434782608695654, "f": 0.30434782608695654, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image captures a baseball game in progress on a field. The batter is standing at home plate, holding a baseball bat. The catcher is positioned behind the batter, ready to catch the ball. \n\nThere is no ball in the scene.\n\nThere are no other players in the scene."}, "358817": {"image_id": 358817, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.1351686025680867, "Bleu_4": 1.5221849019243578e-05, "METEOR": 0.20476864919850765, "ROUGE_L": 0.236281471917366, "CIDEr": 6.485718342936888e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.20833333333333334, "f": 0.1694915254237288, "fn": 19.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.25, "f": 0.11764705882352941, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image depicts a residential neighborhood with a street corner featuring a traffic light hanging over the street. The traffic light is yellow. Drivers should drive with caution when the traffic light is yellow.\n\nThe street is lined with houses. A car is parked or driving along the street."}, "188465": {"image_id": 188465, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.16222142112789117, "Bleu_3": 0.09854348184583721, "Bleu_4": 1.1537786210260598e-05, "METEOR": 0.24790443492487163, "ROUGE_L": 0.28728414442700156, "CIDEr": 1.2551866187662103e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a baseball game in progress. The batter is standing on the batter's box, holding a baseball bat and waiting for a pitch. The catcher is positioned behind the batter, ready to catch the ball. Some players are standing on the field, preparing to throw a ball.\n\nThere is no baseball game in progress."}, "14285": {"image_id": 14285, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.32857603871822694, "Bleu_3": 0.18003903792202725, "Bleu_4": 2.0065472339680168e-05, "METEOR": 0.2653206289737636, "ROUGE_L": 0.3468372423596305, "CIDEr": 5.321456951778201e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a cat lying on a bed in a small bedroom. The cat is gray and white. The cat occupies the bed. The room appears to be cozy and lived-in, with a chair located near the bed."}, "499631": {"image_id": 499631, "Bleu_1": 0.30952380951644, "Bleu_2": 0.24575371749023728, "Bleu_3": 0.1821098335339126, "Bleu_4": 0.14681289748992396, "METEOR": 0.3155204730962635, "ROUGE_L": 0.34609929078014184, "CIDEr": 4.4502548278701016e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.25, "f": 0.27027027027027023, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.625, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a group of 12 teddy bears dressed in various costumes, sitting together in front of a Christmas tree. Each teddy bear has a distinct outfit and pose. Some of the teddy bears are wearing hats, while others are not."}, "67342": {"image_id": 67342, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.1857681456014507, "Bleu_3": 0.14123276695717468, "Bleu_4": 0.08752684847994747, "METEOR": 0.24702109327944355, "ROUGE_L": 0.26704190118824267, "CIDEr": 1.3739283138177714e-11, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2777777777777778, "f": 0.2777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features two birds perched on a tree branch. One bird is positioned closer to the left side of the branch, while the other bird is located more towards the right side. Both birds are engaged in different activities - one is eating and the other is sitting on a fence."}, "295728": {"image_id": 295728, "Bleu_1": 0.15277777777565588, "Bleu_2": 0.04638749494153315, "Bleu_3": 3.1325734780863456e-07, "Bleu_4": 8.169842370542373e-10, "METEOR": 0.13291296786772466, "ROUGE_L": 0.14359698681732583, "CIDEr": 2.677610565194636e-23, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.19230769230769232, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two clocks mounted on a wall in a room. The first clock is gold and the second clock is yellow. Both clocks are taking up a significant portion of the scene. The first clock is surrounded by a ring of metal and is illuminated by a light. The second clock is surrounded by another clock and is illuminated by a light bulb. The clocks are mounted on a pedestal."}, "267951": {"image_id": 267951, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.21060588478687045, "Bleu_3": 0.11392173307167976, "Bleu_4": 1.5026417037436177e-05, "METEOR": 0.15508755260465115, "ROUGE_L": 0.2970779220779221, "CIDEr": 0.0016230019822555514, "SPICE": {"All": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 24.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features two zebras standing together in a barn. One zebra is standing in the foreground, one is in the middle, and the other is towards the back of the scene."}, "2302": {"image_id": 2302, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.22404481344004462, "Bleu_3": 0.16002133902079144, "Bleu_4": 0.09612207021263638, "METEOR": 0.22148559645826715, "ROUGE_L": 0.29415310427968655, "CIDEr": 1.8543115562496379e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08695652173913043, "f": 0.1081081081081081, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image features two people riding horses on a rocky trail. The first person is positioned on the horse, while the second person is positioned on the back of the horse. Both individuals are wearing backpacks, suggesting they might be hikers or travelers. The horses are walking along the rocky path."}, "146397": {"image_id": 146397, "Bleu_1": 0.10447761193873915, "Bleu_2": 0.0397868586377455, "Bleu_3": 2.8986024060730743e-07, "Bleu_4": 7.854101198732579e-10, "METEOR": 0.13437114742863818, "ROUGE_L": 0.12206103051525762, "CIDEr": 8.032075364473384e-21, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.12121212121212122, "f": 0.12903225806451615, "fn": 29.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features eight men performing skateboard tricks on a sidewalk. The men are wearing black shirts. They are showcasing their skill and athleticism as they perform various tricks on their skateboards.\n\nThere are six skateboards in the image, with each man performing tricks on their respective skateboards.\n\nThe overall scene is filled with energy and excitement as the men showcase their skateboarding skills on the sidewalk."}, "122981": {"image_id": 122981, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.25226248954908703, "Bleu_3": 0.1948658043741257, "Bleu_4": 0.1516246170400026, "METEOR": 0.22987750418070227, "ROUGE_L": 0.29468599033816417, "CIDEr": 1.505019311499109e-07, "SPICE": {"All": {"pr": 0.375, "re": 0.1875, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a boy wearing a green sweatshirt and a hat, standing in front of a bus. The boy is looking at the camera and appears to be posing for a picture. Another person is visible in the background, standing near a sand pit."}, "227878": {"image_id": 227878, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 0.06980462899277687, "Bleu_4": 9.223350291134877e-06, "METEOR": 0.1149092487088549, "ROUGE_L": 0.14932680538555693, "CIDEr": 5.962958625160711e-09, "SPICE": {"All": {"pr": 0.3, "re": 0.11538461538461539, "f": 0.16666666666666669, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a cat sitting on a chair in a room. The cat is observing a bird figurine hanging from a window. The bird figurine is made of glass.\n\nThere is no other bird figurine in the scene.\n\nThe overall scene shows a bird figurine hanging from a window."}, "286858": {"image_id": 286858, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.3450327796551204, "Bleu_3": 0.1812300621585057, "Bleu_4": 2.3658340569338057e-05, "METEOR": 0.1963671442245993, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.07220591003953003, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a bear sitting on a bed. The bear is holding a blanket. The bear is wearing a red shirt."}, "459680": {"image_id": 459680, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 1.0097712220824676e-06, "Bleu_4": 2.3458352758968296e-09, "METEOR": 0.2727939283201269, "ROUGE_L": 0.3520197856553999, "CIDEr": 4.097607066490392e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23076923076923078, "f": 0.25531914893617025, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features a woman dressed in a pink dress, standing on a sidewalk and holding an umbrella. The umbrella is open. \n\nThere is no hat in the scene.\n\nThere is no other person in the scene."}, "462677": {"image_id": 462677, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.2954684201318916, "Bleu_3": 0.14974405772212573, "Bleu_4": 1.9143758008581856e-05, "METEOR": 0.34036377385760963, "ROUGE_L": 0.4295774647887324, "CIDEr": 0.051515090234264274, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.08571428571428572, "f": 0.10344827586206898, "fn": 32.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a parking meter located on the sidewalk. The parking meter is blue. A blue car is parked on the left side of the parking meter."}, "90520": {"image_id": 90520, "Bleu_1": 0.2278481012629386, "Bleu_2": 0.1621424235972869, "Bleu_3": 0.12700416062973605, "Bleu_4": 0.10190020581899742, "METEOR": 0.2170133796359358, "ROUGE_L": 0.20582032897511598, "CIDEr": 1.9991002706537437e-29, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features four teddy bears dressed in different outfits. Two of the teddy bears are dressed in Asian clothing, standing next to each other. They are wearing Asian outfits. One of the teddy bears has a traditional Japanese outfit. The other two teddy bears are dressed in a tuxedo and a Santa Claus outfit, respectively. \n\nOne of the teddy bears is positioned on the floor. The other teddy bear is positioned in front of the other teddy bear."}, "552866": {"image_id": 552866, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.11271279531727188, "Bleu_3": 0.06098918146146617, "Bleu_4": 8.013992490794472e-06, "METEOR": 0.21537522466227305, "ROUGE_L": 0.23131094257854823, "CIDEr": 1.1337918752437656e-14, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.12903225806451613, "f": 0.17777777777777778, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of the iconic clock tower in London, England. The tower, known as Big Ben, stands tall and majestic. The clock is prominently displayed on the side of the tower. The surrounding area is bustling with activity, as people can be seen walking around and enjoying the view of the city."}, "337083": {"image_id": 337083, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.21103178185560523, "Bleu_3": 0.10637298242978967, "Bleu_4": 1.3522216242969559e-05, "METEOR": 0.2665978733261029, "ROUGE_L": 0.3287143956889915, "CIDEr": 5.949023404424937e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.16666666666666666, "f": 0.2051282051282051, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a building located on a corner. A clock is located on the top of the building. The building has 12 windows.\n\nThere is no city in the scene.\n\nThere are no traffic lights in the scene."}, "304828": {"image_id": 304828, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.14695129936263138, "Bleu_3": 8.075839294554588e-07, "Bleu_4": 1.904915665082057e-09, "METEOR": 0.19331035239024918, "ROUGE_L": 0.20608108108108109, "CIDEr": 1.8874892956793816e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a giraffe walking across a field. The giraffe is the main focus of the scene, with its long legs visible as it moves through the grass. The field is relatively empty, with only a few trees scattered around the area."}, "506115": {"image_id": 506115, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.27264804402370063, "ROUGE_L": 0.44153128518578094, "CIDEr": 0.14483970445302355, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.28, "f": 0.35000000000000003, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image features four girls sitting together on a bus. They are holding soccer balls, possibly as a part of a soccer-themed event or simply as a fun activity."}, "147179": {"image_id": 147179, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.17960530202088465, "Bleu_3": 1.0361280619686486e-06, "Bleu_4": 2.5105597927954442e-09, "METEOR": 0.16109054590976246, "ROUGE_L": 0.22202001819836215, "CIDEr": 0.0008013198407282268, "SPICE": {"All": {"pr": 0.25, "re": 0.23809523809523808, "f": 0.24390243902439024, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features two people lying on a bed. They are wearing shorts and white sneakers. The bed is covered with a blanket. The third person is located on the couch."}, "549718": {"image_id": 549718, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.29214466689738716, "Bleu_3": 0.211666017504817, "Bleu_4": 0.12829843028855695, "METEOR": 0.3186456075708246, "ROUGE_L": 0.3259541984732824, "CIDEr": 1.3002412468720327e-05, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.22727272727272727, "f": 0.25, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a yellow and blue bus driving down a street, possibly in a city. The bus is a double decker bus. There are several people visible on the sidewalk, some of them closer to the bus."}, "160820": {"image_id": 160820, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.13497638119624783, "Bleu_3": 7.896560106821803e-07, "Bleu_4": 1.923104277732444e-09, "METEOR": 0.15191328037509594, "ROUGE_L": 0.24148851939825808, "CIDEr": 5.890130965736031e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a group of 15 sheep grazing in the grass. The sheep are of various sizes and are spread out across the hillside. Some of the sheep are eating grass, while others are grazing in the grass."}, "517629": {"image_id": 517629, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.20121090914115636, "Bleu_3": 0.1762072509270296, "Bleu_4": 0.1570208067536025, "METEOR": 0.2738923624429437, "ROUGE_L": 0.3155949741315595, "CIDEr": 2.5299588173450817e-05, "SPICE": {"All": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a white cat sitting in a sink. The cat is positioned in the middle of the sink, occupying most of the space. The sink is located on a countertop. There is no bottle in the scene."}, "433277": {"image_id": 433277, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.1321752642838866, "Bleu_3": 0.0875875427161453, "Bleu_4": 0.060247525296160884, "METEOR": 0.1946834139246741, "ROUGE_L": 0.21863799283154117, "CIDEr": 2.008892997831304e-12, "SPICE": {"All": {"pr": 0.4, "re": 0.35714285714285715, "f": 0.3773584905660378, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 10.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a wooden desk with a large computer setup. There is a computer on the desk. The desk is equipped with three computer monitors arranged in a row. The monitors are positioned at different angles, creating a visually appealing and functional workspace. There is a keyboard and a mouse on the desk."}, "487498": {"image_id": 487498, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.16854996561062321, "Bleu_3": 0.12237946382258252, "Bleu_4": 0.08840994001249032, "METEOR": 0.19792560074296933, "ROUGE_L": 0.2059071729957806, "CIDEr": 0.0004224323156438536, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.2962962962962963, "f": 0.2962962962962963, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.6363636363636364, "f": 0.5833333333333334, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image features four people standing under an umbrella. Some of the people are holding a laptop and a cell phone. The umbrella is open.\n\nThere are no other people in the scene."}, "90640": {"image_id": 90640, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.2915890165723569, "Bleu_3": 0.24911117542599315, "Bleu_4": 0.21550909686389225, "METEOR": 0.33753352935879355, "ROUGE_L": 0.3935483870967742, "CIDEr": 2.588690788106342e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.24, "f": 0.24489795918367346, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of a group of eight elephants walking down a city street. The elephants are walking in a line, creating a sense of order. Some of the elephants are creating a puddle, while others are creating a mud wall."}, "470173": {"image_id": 470173, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.15404159684489246, "Bleu_3": 0.09353181070486517, "Bleu_4": 0.06155322223042297, "METEOR": 0.20721689775951915, "ROUGE_L": 0.22521097046413502, "CIDEr": 9.557830082123934e-16, "SPICE": {"All": {"pr": 0.47058823529411764, "re": 0.27586206896551724, "f": 0.34782608695652173, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.46153846153846156, "f": 0.5454545454545455, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a woman holding a basket, standing in a grassy area. She is surrounded by a statue of a woman. \n\nThere are three potted plants in the scene. One of the potted plants is located in front of the statue, another is located in the grass, and the third one is located in the middle of the statue."}, "536183": {"image_id": 536183, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2289527349375426, "Bleu_3": 0.1204453779926304, "Bleu_4": 1.5667261949798743e-05, "METEOR": 0.2417989488134176, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.000714193864829155, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.4117647058823529, "f": 0.3888888888888889, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8333333333333334, "f": 0.625, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image features a pot filled with a delicious stir-fry. The stir-fry contains carrots and broccoli. The pot is placed on the stove. The food being cooked consists of beet and vegetables."}, "523597": {"image_id": 523597, "Bleu_1": 0.4285714285591838, "Bleu_2": 0.25104822261943865, "Bleu_3": 0.15631840650803838, "Bleu_4": 0.10452498041627553, "METEOR": 0.3092427869739911, "ROUGE_L": 0.31470335339638866, "CIDEr": 0.00038238895233623906, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.38095238095238093, "f": 0.35555555555555557, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman riding on the back of a motorcycle down a road. The woman is sitting behind the man. They are both dressed in white. The motorcycle is positioned on the road."}, "366178": {"image_id": 366178, "Bleu_1": 0.4318181818083678, "Bleu_2": 0.3323629285494853, "Bleu_3": 0.23603801623481724, "Bleu_4": 0.1591468333953587, "METEOR": 0.31133317297597274, "ROUGE_L": 0.3669786096256685, "CIDEr": 1.476651000567806e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16666666666666666, "f": 0.14814814814814814, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a street covered in snow. In the middle of the road, there is a red fire hydrant that appears to be covered in snow. The street is lined with snow. There is one car parked on the side of the road."}, "11260": {"image_id": 11260, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.3143473067169879, "Bleu_3": 0.21112681500742475, "Bleu_4": 2.6190877432762608e-05, "METEOR": 0.2996975583654383, "ROUGE_L": 0.407119021134594, "CIDEr": 0.10217671883609242, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks. The train is passing by the bridge. It appears to be a subway train."}, "92765": {"image_id": 92765, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.16351748503705, "Bleu_3": 9.418739954830287e-07, "Bleu_4": 2.278527011349529e-09, "METEOR": 0.1936966112829024, "ROUGE_L": 0.29373996789727125, "CIDEr": 0.00018761100869725756, "SPICE": {"All": {"pr": 0.25, "re": 0.3157894736842105, "f": 0.27906976744186046, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a large display of 12 bananas for sale at the outdoor market. The bananas are arranged in bunches, with some of them placed closer to the foreground and others further back."}, "171936": {"image_id": 171936, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.24349237676800983, "Bleu_3": 0.17807125229838164, "Bleu_4": 2.3050898625491593e-05, "METEOR": 0.22241069647553713, "ROUGE_L": 0.3769309989701339, "CIDEr": 0.047780397065889726, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image depicts a living room with a couch and a chair. The living room also has a dining table and a refrigerator."}, "244401": {"image_id": 244401, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.11009637651016171, "Bleu_3": 6.55680898648204e-07, "Bleu_4": 1.60955965059484e-09, "METEOR": 0.22510106614605066, "ROUGE_L": 0.17268223637650387, "CIDEr": 1.096444456834182e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.125, "f": 0.13793103448275862, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a wooden pallet filled with a variety of fresh vegetables, including broccoli, lettuce, and carrots. The vegetables are arranged in different sections, with some placed closer to the front and others towards the back of the pallet. The broccoli is prominently displayed."}, "534122": {"image_id": 534122, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.08451542547047053, "Bleu_3": 5.944714686925451e-07, "Bleu_4": 1.5884362032477789e-09, "METEOR": 0.16820460469996582, "ROUGE_L": 0.24918300653594777, "CIDEr": 2.3217203836066873e-05, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.25, "f": 0.24242424242424243, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man surfing on a surfboard on a beach. The man is enjoying surfing and is wearing shorts. He is positioned towards the left side of the scene, with ocean waves behind him."}, "366099": {"image_id": 366099, "Bleu_1": 0.6086956521474481, "Bleu_2": 0.49901087932565624, "Bleu_3": 0.36198194417906726, "Bleu_4": 0.2206773104585631, "METEOR": 0.289183795386489, "ROUGE_L": 0.4241019698725377, "CIDEr": 0.12056090398545247, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.12903225806451613, "f": 0.15999999999999998, "fn": 27.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a pizza with a variety of toppings, including tomatoes, onions, and mushrooms. The pizza is placed on a wooden board."}, "503135": {"image_id": 503135, "Bleu_1": 0.09999999999947369, "Bleu_2": 0.07968190728853909, "Bleu_3": 0.05527268122624623, "Bleu_4": 0.036658947885057296, "METEOR": 0.13435922487079013, "ROUGE_L": 0.09505259057265292, "CIDEr": 8.413731174029711e-191, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.3181818181818182, "f": 0.358974358974359, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a police officer riding a motorcycle down a street, surrounded by a crowd of people. The police officer is wearing a yellow safety vest, which makes him easily visible to the onlookers. \n\nThere are several people standing on the sidewalk, watching the officer as he passes by. Some of the people are talking on the phone, while others are looking at their cell phones or talking to each other. There is also a group of people sitting at a table, a man on a skateboard, a girl talking on the phone, a woman in a pink shirt talking on the phone, a woman in a red shirt standing in a crowd, a woman taking a picture, a man in a black shirt sitting at a table, a man on a skateboard sitting on a bench, a child riding a skateboard, a girl talking on the phone, a man in a hat talking on the phone, a group of people riding bikes, a man in a red hat talking to each other, a man in a yellow shirt drinking from a glass, and a man on a motorcycle."}, "200807": {"image_id": 200807, "Bleu_1": 0.59999999998, "Bleu_2": 0.3523321316968752, "Bleu_3": 0.2069786209646836, "Bleu_4": 2.393884406192111e-05, "METEOR": 0.29355842764073026, "ROUGE_L": 0.3927038626609442, "CIDEr": 0.048376766897169715, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a pair of legs wearing black shoes and black and white striped stockings. The shoes are positioned on the floor. There is no umbrella in the image."}, "328805": {"image_id": 328805, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.22742941306595937, "Bleu_3": 0.17696423166296105, "Bleu_4": 0.14234121841688616, "METEOR": 0.22912239189611205, "ROUGE_L": 0.32972972972972975, "CIDEr": 0.040760565694361095, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2, "f": 0.22727272727272727, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a bathroom with a toilet situated in the center of the room. The tile floor is beige. A vase filled with flowers is placed near the toilet."}, "445055": {"image_id": 445055, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.22522130822577494, "Bleu_3": 0.10485490691362834, "Bleu_4": 1.2796006598878642e-05, "METEOR": 0.18025270264993415, "ROUGE_L": 0.23135271807838179, "CIDEr": 3.5114377926985826e-06, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image captures a lively scene of a man and a child enjoying a day at the beach. The man is surfing in the water. The child is also surfing and holding a surfboard. The man is closer to the water. He is in the water."}, "387223": {"image_id": 387223, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.2613021337786361, "Bleu_3": 0.12378303795219202, "Bleu_4": 1.5257340614283253e-05, "METEOR": 0.316084451447115, "ROUGE_L": 0.3116788321167883, "CIDEr": 5.7325001484073156e-05, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.21739130434782608, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a herd of seven sheep grazing in a snow-covered field. Some of the sheep are eating grass, while others are grazing. One sheep is laying down on a rock. The field is covered with snow."}, "436349": {"image_id": 436349, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.11919584838724184, "Bleu_3": 0.06221428039423801, "Bleu_4": 8.027134931021222e-06, "METEOR": 0.14122222489381514, "ROUGE_L": 0.2322703474535935, "CIDEr": 6.663318568420604e-14, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a parking lot filled with five trucks. The large trucks are blue and green. On the side of the large blue truck, there is a statue of liberty, a large advertisement, and a man in a blue shirt. On the side of the large green truck, there is a man in a blue shirt and a large flag."}, "51335": {"image_id": 51335, "Bleu_1": 0.42553191488456316, "Bleu_2": 0.3331791194232417, "Bleu_3": 0.28105750237816374, "Bleu_4": 0.22411747397322587, "METEOR": 0.265280086580473, "ROUGE_L": 0.3724378543392935, "CIDEr": 3.084574296590553e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.19230769230769232, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a man sitting at a wooden dining table, enjoying a hot dog. The man is holding a hot dog in his hands, and it appears to be a stale piece of bread. The man is smiling, indicating that he is happy with his meal."}, "515531": {"image_id": 515531, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 0.10097712220824674, "Bleu_4": 1.3191601177260918e-05, "METEOR": 0.2091983921265659, "ROUGE_L": 0.3174721189591078, "CIDEr": 0.00012482374327837272, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.05, "f": 0.05714285714285715, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image captures a beautiful night sky with a moon and two jets flying in the sky. The moon is positioned towards the left side of the scene. One of the jets is flying towards the moon."}, "20371": {"image_id": 20371, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.4291975376162593, "Bleu_3": 0.31915054634420614, "Bleu_4": 0.25247838143985674, "METEOR": 0.2827391252421063, "ROUGE_L": 0.458072590738423, "CIDEr": 0.3005066784661262, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07692307692307693, "f": 0.125, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a pigeon sitting on a metal pipe. The pigeon is perched on top of the pipe."}, "180653": {"image_id": 180653, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.2323383451130719, "Bleu_3": 0.11341748684039175, "Bleu_4": 1.4188431559098948e-05, "METEOR": 0.24607721502234026, "ROUGE_L": 0.31145149525893506, "CIDEr": 2.117958075867309e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.20689655172413793, "f": 0.24000000000000002, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man and a woman standing on a snow-covered slope. They are both wearing skis and holding ski poles. The man is positioned slightly behind the woman. They appear to be enjoying their time skiing together."}, "373382": {"image_id": 373382, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.27797972456503717, "Bleu_3": 0.1215773281843103, "Bleu_4": 1.4382259604131016e-05, "METEOR": 0.2692464987643497, "ROUGE_L": 0.28073635765943455, "CIDEr": 1.9164608785624283e-07, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.1724137931034483, "f": 0.16666666666666669, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image captures a tennis match in progress on a tennis court. A man is playing tennis, wearing a white outfit. He is in the middle of a serve, holding a tennis racket. The tennis ball is visible in the air, close to the player."}, "515642": {"image_id": 515642, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.17504208247906033, "Bleu_3": 0.10495739013317465, "Bleu_4": 1.221121650482547e-05, "METEOR": 0.21797050990959338, "ROUGE_L": 0.27555053642010163, "CIDEr": 1.7879949844508646e-12, "SPICE": {"All": {"pr": 0.08955223880597014, "re": 0.2727272727272727, "f": 0.1348314606741573, "fn": 16.0, "numImages": 1.0, "fp": 61.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 31.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.16666666666666666, "f": 0.1, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.22727272727272727, "re": 0.5, "f": 0.3125, "fn": 5.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}}, "caption": "The image features a book with a blue bookmark on it, placed on a table next to a remote control. The book is open to a page with a paragraph of text, and the bookmark is positioned at the top of the page. The remote control is located on the left side of the book."}, "276254": {"image_id": 276254, "Bleu_1": 0.2205882352908737, "Bleu_2": 0.09938352560726808, "Bleu_3": 5.309190243091411e-07, "Bleu_4": 1.2318075922541293e-09, "METEOR": 0.14863433164679926, "ROUGE_L": 0.1506916996047431, "CIDEr": 6.477607933488419e-18, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.19230769230769232, "f": 0.23255813953488372, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a picturesque harbor with numerous boats docked in the harbor. The boats vary in size and are scattered throughout the scene, creating a lively atmosphere. Some boats are closer to the shore, while others are further out in the water.\n\nIn addition to the boats, there are several houses in the scene.\n\nThe overall scene is a bustling harbor with boats docked in the water."}, "332377": {"image_id": 332377, "Bleu_1": 0.255813953482423, "Bleu_2": 0.07804363148971961, "Bleu_3": 5.296191672956597e-07, "Bleu_4": 1.388218324422588e-09, "METEOR": 0.18377730324914907, "ROUGE_L": 0.21254355400696864, "CIDEr": 7.738169690598682e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a table with a bag of donuts placed on it. There are two donuts on the table. One of the donuts is a glazed donut, and the other is also a glazed donut. There are no napkins on the table."}, "66675": {"image_id": 66675, "Bleu_1": 0.3157894736786704, "Bleu_2": 0.249058377064041, "Bleu_3": 0.1652341724911138, "Bleu_4": 0.0956040878734893, "METEOR": 0.2146829941673373, "ROUGE_L": 0.2733893557422969, "CIDEr": 7.619490857164624e-14, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a woman and a boy standing in a bedroom. They are holding a Wii remote. They appear to be playing a video game together. The woman is standing on a bed, while the boy is standing on a couch.\n\nThere is no Nintendo Wii remotes, video game, or Wii sports game in the scene.\n\n"}, "578752": {"image_id": 578752, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.3834824944004226, "Bleu_3": 2.1402603671025405e-06, "Bleu_4": 5.1442012205798955e-09, "METEOR": 0.36554141394197615, "ROUGE_L": 0.3257676902536716, "CIDEr": 0.2781395318111544, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.14814814814814814, "f": 0.2, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a beach with a person standing on it. The person is holding a surfboard."}, "411177": {"image_id": 411177, "Bleu_1": 0.18518518518175586, "Bleu_2": 0.08359497709435722, "Bleu_3": 5.122150570969723e-07, "Bleu_4": 1.2740800388313793e-09, "METEOR": 0.1549370820038023, "ROUGE_L": 0.21403508771929822, "CIDEr": 2.322062442635426e-13, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.0967741935483871, "f": 0.1111111111111111, "fn": 28.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image showcases a spacious living room with a large brown and tan rug on the floor. The rug covers a significant portion of the room, extending from the left side to the right side. There are two couches in the room, one located on the left side and the other on the right."}, "12192": {"image_id": 12192, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.2550510152998425, "Bleu_3": 0.16072835630159776, "Bleu_4": 0.09747200949368506, "METEOR": 0.24720806643707904, "ROUGE_L": 0.34560906515580736, "CIDEr": 1.4810959964824731e-06, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.2, "f": 0.2702702702702703, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.5555555555555556, "f": 0.6666666666666667, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image features a child playing with a tennis racket on a beach. The child is standing in water, holding a tennis racket and preparing to hit a ball. There are two people in the scene, one closer to the water and the other further away from the child."}, "403657": {"image_id": 403657, "Bleu_1": 0.2656249999958496, "Bleu_2": 0.205335575123675, "Bleu_3": 0.1395936189966998, "Bleu_4": 0.09717940039430123, "METEOR": 0.22409018308606396, "ROUGE_L": 0.2701771653543307, "CIDEr": 5.912279014664446e-17, "SPICE": {"All": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a street with a clock tower in the background, likely Big Ben. A red bus is driving down the street, and another red bus is parked on the side of the road. A white van is also driving down the street, and a garbage truck is parked on the side of the road. There are no cars parked along the street."}, "191672": {"image_id": 191672, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.24977708421036346, "Bleu_3": 0.18017401362019048, "Bleu_4": 2.0841486500568142e-05, "METEOR": 0.31712508681980117, "ROUGE_L": 0.37521968365553604, "CIDEr": 0.00041824261981465087, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image captures a man skillfully riding a surfboard on a wave. The man is riding on a surfboard. The wave is large and powerful, providing an exciting and challenging environment for the surfer."}, "461945": {"image_id": 461945, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.20100756304815393, "Bleu_3": 0.1450116762655686, "Bleu_4": 0.08750873255009596, "METEOR": 0.2838450149105891, "ROUGE_L": 0.3099943534726144, "CIDEr": 1.1752282633965986e-12, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.16666666666666666, "f": 0.17142857142857143, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man playing tennis on a tennis court. The man is holding a tennis racket and preparing to hit a tennis ball. The man is in the middle of a swing, with the racket raised above his head. The tennis ball is visible in the air, close to the man's racket."}, "502979": {"image_id": 502979, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.12168393662744252, "Bleu_3": 6.272467465535161e-07, "Bleu_4": 1.4300980356517603e-09, "METEOR": 0.2092987898318215, "ROUGE_L": 0.19307870858830975, "CIDEr": 5.375512941481477e-12, "SPICE": {"All": {"pr": 0.4375, "re": 0.5, "f": 0.4666666666666667, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features two boys eating dinner at a dining table in a restaurant. Plates, glasses, napkins, and a fork are on the dining table. There are multiple dishes and utensils spread across the table. There are four cups, one fork, two knives, and three spoons on the table. The boys are sitting at the table. Plates are spread across the table."}, "43448": {"image_id": 43448, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.1663895814060149, "Bleu_3": 0.08773161697240878, "Bleu_4": 1.139861545684521e-05, "METEOR": 0.1599012496358029, "ROUGE_L": 0.22363436392521083, "CIDEr": 0.0009345800835511938, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.3, "f": 0.3050847457627119, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features two elephants standing together in a grassy area. The position of the third elephant is behind the two elephants. The total number of elephants is two. The elephants appear to be enjoying their time together, possibly grazing on the grass."}, "55022": {"image_id": 55022, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2530600894303559, "Bleu_3": 0.1333606949819784, "Bleu_4": 1.7379110739620047e-05, "METEOR": 0.17040332412815032, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.0018882890852431266, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09523809523809523, "f": 0.1, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image features a room with a wooden floor. There are three bicycles parked in the room. One of the bicycles is pink. The floor is made of wood."}, "204661": {"image_id": 204661, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.11605769149245462, "Bleu_3": 6.54689746724509e-07, "Bleu_4": 1.563155525234599e-09, "METEOR": 0.2223384478882212, "ROUGE_L": 0.22235722964763066, "CIDEr": 1.8942683526571306e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.10714285714285714, "f": 0.13636363636363635, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features two people holding cell phones. One person is holding a Motorola flip phone, showcasing its various features. The flip phone is open, revealing the keypad and display. The other person is holding a Samsung Galaxy S5. The image also shows a desk with a laptop on it."}, "259983": {"image_id": 259983, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.17739371879401636, "Bleu_3": 0.12529069871940626, "Bleu_4": 0.08889175589033883, "METEOR": 0.2566047200220614, "ROUGE_L": 0.24721377912867276, "CIDEr": 4.713708081381136e-18, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15384615384615385, "f": 0.14814814814814817, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a white stove top oven with a metal top. The oven is located in a kitchen, and it appears to be old and in need of repair. The top of the oven is missing. There are two ovens in the scene, both missing their knobs. \n\nThere are five bottles scattered around the area. The bottles possibly contain spices, condiments, or other food items."}, "343561": {"image_id": 343561, "Bleu_1": 0.6499999999675001, "Bleu_2": 0.45305977295901084, "Bleu_3": 0.32462845528150536, "Bleu_4": 0.2518750835061843, "METEOR": 0.31069186879484434, "ROUGE_L": 0.4328287606433302, "CIDEr": 0.30498815184757255, "SPICE": {"All": {"pr": 0.4, "re": 0.19047619047619047, "f": 0.25806451612903225, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.4, "f": 0.5333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image captures a large group of people riding bicycles down a street. Some riders are wearing helmets for safety."}, "559665": {"image_id": 559665, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.22131333406452386, "Bleu_3": 0.17215301886614504, "Bleu_4": 0.13433582021760984, "METEOR": 0.23589984576261266, "ROUGE_L": 0.23252858958068615, "CIDEr": 3.9021141552686875e-10, "SPICE": {"All": {"pr": 0.05, "re": 0.045454545454545456, "f": 0.04761904761904762, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image is a black and white photograph of a man riding a motorcycle with a passenger on the back. The man is wearing a helmet, and the passenger is also wearing a helmet. They are both sitting on the motorcycle, which is parked on the side of the road."}, "137003": {"image_id": 137003, "Bleu_1": 0.13999999999720003, "Bleu_2": 0.10690449676280987, "Bleu_3": 0.07808966656031392, "Bleu_4": 0.05641839301384634, "METEOR": 0.19986766605103126, "ROUGE_L": 0.23797139141742527, "CIDEr": 9.205600842516446e-11, "SPICE": {"All": {"pr": 0.3125, "re": 0.2, "f": 0.24390243902439027, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a girl standing on a grassy field. The girl is holding a kite, which is flying high in the sky.\n\nThere are three people in the background. One person is playing frisbee, another person is riding a bike, and the third person is walking down the street."}, "338203": {"image_id": 338203, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.11428333961393057, "Bleu_4": 0.08975429359940368, "METEOR": 0.2173975365527467, "ROUGE_L": 0.23303196230739842, "CIDEr": 3.423223947788806e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.26666666666666666, "f": 0.23529411764705882, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a bird perched on a tree branch. The bird is possibly a falcon or a hawk. It is positioned near the top of the tree, with its wings spread out, giving the impression of a bird of prey. The bird appears to be observing its surroundings."}, "238691": {"image_id": 238691, "Bleu_1": 0.2058823529381488, "Bleu_2": 0.15678956443155245, "Bleu_3": 0.09065117877676995, "Bleu_4": 1.0346697514431532e-05, "METEOR": 0.20416668086666837, "ROUGE_L": 0.1808300395256917, "CIDEr": 6.259314391483603e-20, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 28.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image depicts a busy airport scene with six people walking and waiting around. One person is sitting on a luggage cart, while another person is talking on the phone. Some people are laying down or walking. One person is sleeping. \n\nThere is an airport in the scene. There is also a luggage carousel where a man is lying on. There are four handbags scattered throughout the scene."}, "454610": {"image_id": 454610, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.13644420572458105, "Bleu_3": 7.396917719335283e-07, "Bleu_4": 1.731749067280523e-09, "METEOR": 0.16205130446132993, "ROUGE_L": 0.1601049868766404, "CIDEr": 2.251795464546565e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.19047619047619047, "f": 0.24242424242424246, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features two people sitting on a boat in the market. The boat is floating on the river. The boat is a long boat. The smaller boats are also located in the water.\n\nThe people on the boats are selling various fruits, such as bananas and apples."}, "163057": {"image_id": 163057, "Bleu_1": 0.24999999999671052, "Bleu_2": 0.1914854215487313, "Bleu_3": 0.11412662871867939, "Bleu_4": 1.1945642856105212e-05, "METEOR": 0.19774400394025435, "ROUGE_L": 0.23184121621621623, "CIDEr": 3.101808828148549e-25, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image captures a lively scene of a large group of 15 people gathered in a grassy field, enjoying a day of flying kites. \n\nSome of the people are playing frisbee, while others are flying kites. Some are standing on the grass, while others are walking on the field. There is a lively atmosphere as people engage in various activities. \n\nThe field is filled with the colorful kites flying in the air, creating a beautiful sight."}, "493623": {"image_id": 493623, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 0.09970052069750876, "Bleu_4": 0.06607272734339885, "METEOR": 0.24339855389672638, "ROUGE_L": 0.17951736315479697, "CIDEr": 1.1731239312822e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features three women standing in a room. One woman is putting on her shoes and arranging flowers. Another woman is brushing her hair and holding a brush. The third woman is putting her hair up and arranging a chair. The room has a carpeted floor. There are no potted plants in the room."}, "564940": {"image_id": 564940, "Bleu_1": 0.255813953482423, "Bleu_2": 0.19116707482361836, "Bleu_3": 0.12125252078651538, "Bleu_4": 1.4529580794887106e-05, "METEOR": 0.25340565624526556, "ROUGE_L": 0.25505226480836235, "CIDEr": 1.0691934211394809e-07, "SPICE": {"All": {"pr": 0.3, "re": 0.35294117647058826, "f": 0.3243243243243243, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features three teddy bears sitting next to each other on a table. Both bears are wearing black shirts. They are positioned close to each other, with one bear on the left side of the table and the other on the right."}, "423229": {"image_id": 423229, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.10540925533657697, "Bleu_3": 0.06369368049040697, "Bleu_4": 8.856455322845592e-06, "METEOR": 0.22372684035500573, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.0166865554386976e-06, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.14285714285714285, "f": 0.12903225806451615, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features a steam train traveling down the tracks, surrounded by two trees. The train is black and is moving at a slow speed. It appears to be a steam locomotive. Grass and trees surround the tracks. There are no people in the scene."}, "412571": {"image_id": 412571, "Bleu_1": 0.10948905109409134, "Bleu_2": 0.07506974000951128, "Bleu_3": 0.04370609615760839, "Bleu_4": 4.996090688998866e-06, "METEOR": 0.15147690210746517, "ROUGE_L": 0.12892998678996037, "CIDEr": 6.794722789173205e-98, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.16666666666666666, "f": 0.2325581395348837, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.21428571428571427, "f": 0.3157894736842105, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a display case filled with a variety of donuts, with a total of 19 donuts visible in the display case. The donuts are arranged on three shelves, with some placed on the top shelf, others on the middle shelf, and the rest on the bottom shelf. \n\nThe donuts come in various flavors and designs. Some of them are chocolate frosted, some are glazed, and some are frosted. \n\nThe donuts come in various shapes and sizes. Some of them are stacked, some are arranged in a plate, and some are arranged in a stack. \n\nThe donuts also come in various designs. Some of them resemble a santa claus, a pumpkin, a ring, a cake, a sourdough bread, a tiger's head, or a stack of pastries. \n\nThere are no other items in the display case."}, "217760": {"image_id": 217760, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.10892385771382775, "Bleu_3": 5.892134857092117e-07, "Bleu_4": 1.3763718914137694e-09, "METEOR": 0.17593231609051663, "ROUGE_L": 0.22956989247311832, "CIDEr": 9.452683751560027e-16, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13793103448275862, "f": 0.1702127659574468, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a black leather case with a set of scissors neatly arranged inside. The scissors are of various sizes and are placed in a row, occupying most of the case. The case is designed to hold and protect the scissors, making it an ideal storage solution for someone who needs to keep their scissors organized and easily accessible."}, "579893": {"image_id": 579893, "Bleu_1": 0.3599999999928, "Bleu_2": 0.32071349028842955, "Bleu_3": 0.26817106052349593, "Bleu_4": 0.187311646460912, "METEOR": 0.24177201717820102, "ROUGE_L": 0.31955762514551805, "CIDEr": 2.915787505412286e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a stop sign with a street sign above it, both mounted on a pole. The street sign is located at the intersection of Woodfield and Old Ridge roads. The stop sign is positioned at the top of the pole, while the street sign is placed below it."}, "5965": {"image_id": 5965, "Bleu_1": 0.1739130434744802, "Bleu_2": 0.06216698721465449, "Bleu_3": 4.44517628108609e-07, "Bleu_4": 1.1955001291193746e-09, "METEOR": 0.13114754098360656, "ROUGE_L": 0.2019867549668874, "CIDEr": 6.891449580755912e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a motorcycle parked on the side of the street, with the front wheel on the ground. The motorcycle is positioned near a building, and there are several potted plants visible in the scene. Some of the potted plants are located on the sidewalk."}, "107375": {"image_id": 107375, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.24308621739673564, "Bleu_3": 0.1764834841553867, "Bleu_4": 0.10695860479381795, "METEOR": 0.2601066262453745, "ROUGE_L": 0.29468599033816417, "CIDEr": 3.4414877372543935e-08, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14814814814814814, "f": 0.14814814814814814, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a white dog running through a wooded area. The dog is running with a water bottle in its mouth. \n\nThere are six rocks scattered around the scene. \n\nThere is no person in the image.\n\nThe dog is running through a wooded area."}, "115721": {"image_id": 115721, "Bleu_1": 0.305555555547068, "Bleu_2": 0.20892772350344985, "Bleu_3": 0.10868536689063704, "Bleu_4": 1.4044291074781953e-05, "METEOR": 0.2929915055797625, "ROUGE_L": 0.32947530864197533, "CIDEr": 0.000100097464069934, "SPICE": {"All": {"pr": 0.3125, "re": 0.21739130434782608, "f": 0.2564102564102564, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a dog lying on a couch, sleeping peacefully. The dog is positioned on the couch. The couch is covered with a blanket, providing a cozy and comfortable environment for the dog to rest."}, "493509": {"image_id": 493509, "Bleu_1": 0.5490196078323722, "Bleu_2": 0.39207842352007816, "Bleu_3": 0.280037343286385, "Bleu_4": 0.1739238543095173, "METEOR": 0.3165585917303882, "ROUGE_L": 0.40155595451825254, "CIDEr": 5.6888142781332705e-09, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man and a woman wearing yellow safety vests and hard hats, standing next to each other. They appear to be working together on a project, possibly in a construction or engineering setting. The man is holding a laptop, while the woman is talking on a cell phone."}, "507797": {"image_id": 507797, "Bleu_1": 0.11428571428408166, "Bleu_2": 0.07049073768400985, "Bleu_3": 0.04180726264010775, "Bleu_4": 5.746720814532872e-06, "METEOR": 0.16729936461719827, "ROUGE_L": 0.20588235294117646, "CIDEr": 2.792629151852261e-23, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.25, "f": 0.2962962962962963, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image depicts a group of five people standing on the sidewalk. The people are preparing to go to the airport and board a plane. Some of the people are walking, while others are boarding a bus. \n\nThere are three individuals carrying handbags. One person is holding a purple shopping bag, another person is carrying a purple and blue floral purse, and another person is carrying a black tote bag."}, "512830": {"image_id": 512830, "Bleu_1": 0.340909090901343, "Bleu_2": 0.21810252258335, "Bleu_3": 0.1313310331806951, "Bleu_4": 1.5331320282613666e-05, "METEOR": 0.21740394687050343, "ROUGE_L": 0.25702247191011235, "CIDEr": 5.184691337030228e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image depicts a group of 22 people sitting in a large airplane cabin. The people are wearing camouflage uniforms. Some of the people are eating, while others are sleeping or talking on the phone. The location of the people is on an airplane."}, "69969": {"image_id": 69969, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.08571428571255398, "Bleu_3": 5.349194562189742e-07, "Bleu_4": 1.3433582021760984e-09, "METEOR": 0.1428766614706716, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.979352404805234e-11, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image depicts a restaurant with a large group of ten people gathered around a dining table. \n\nThe table is filled with eight bottles, a cup, and a vase.\n\nThere are no wine glasses or bowls in the scene.\n\nThe overall scene shows eight people gathered around the dining table."}, "420466": {"image_id": 420466, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.11952286093128565, "Bleu_3": 0.0641952261839719, "Bleu_4": 8.405394134956185e-06, "METEOR": 0.22162172177536554, "ROUGE_L": 0.23775055679287305, "CIDEr": 1.1440397611668476e-13, "SPICE": {"All": {"pr": 0.4, "re": 0.21428571428571427, "f": 0.27906976744186046, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a giraffe walking across a grassy field. The giraffe's neck is long and slender. The giraffe's legs are long and slender. The giraffe is surrounded by grass. The color of the trees is green. The scene is captured in a black and white style, giving it a timeless and classic feel."}, "529850": {"image_id": 529850, "Bleu_1": 0.13725490195809306, "Bleu_2": 0.07409585736202748, "Bleu_3": 4.820927404299034e-07, "Bleu_4": 1.2360545409967113e-09, "METEOR": 0.11484121260879644, "ROUGE_L": 0.17867603983596952, "CIDEr": 2.2490024853359262e-11, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man sitting on the floor in a kitchen. The man is petting a dog, which is black and white. The man is also holding a cell phone. The man's hair is bald. The kitchen is equipped with a refrigerator, but there is no oven or sink."}, "397842": {"image_id": 397842, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.15632047282649467, "Bleu_3": 0.07630558803280324, "Bleu_4": 9.52398752047048e-06, "METEOR": 0.2049455542622461, "ROUGE_L": 0.27819855037055136, "CIDEr": 5.91935815244656e-14, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.21428571428571427, "f": 0.21428571428571427, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a dog running through a lush green field. The dog is brown and white. It is carrying a ball in its mouth and chasing a ball. The field provides a place for the dog to play. The dog is enjoying itself as it chases after a pink Frisbee, which is flying through the air."}, "48555": {"image_id": 48555, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.26726124189998696, "Bleu_3": 0.15285535435915018, "Bleu_4": 2.0821983208129715e-05, "METEOR": 0.24939483042945496, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.06127875571127912, "SPICE": {"All": {"pr": 0.125, "re": 0.045454545454545456, "f": 0.06666666666666667, "fn": 21.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image features three horses running on a beach. The horses are spread out across a track, with some horses further away."}, "51938": {"image_id": 51938, "Bleu_1": 0.18644067796294173, "Bleu_2": 0.1133930235522716, "Bleu_3": 6.087410726083202e-07, "Bleu_4": 1.4166985426338212e-09, "METEOR": 0.14995309195333034, "ROUGE_L": 0.16621253405994552, "CIDEr": 2.2984295717159145e-14, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1111111111111111, "f": 0.10256410256410256, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image captures a snowy slope where a person is performing skiing. The person is soaring through the snowy slope. Some people are closer to him. The person is performing a trick using skis to jump. The person is wearing a white shirt, a blue jacket, or blue pants.\n\nThere are no other specific details mentioned in the passage."}, "380516": {"image_id": 380516, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.23055616707626844, "Bleu_3": 0.1373830673570816, "Bleu_4": 0.08972942994319144, "METEOR": 0.3199398859037725, "ROUGE_L": 0.25505226480836235, "CIDEr": 1.968131230294099e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a boy playing tennis on a blue tennis court. He is holding a tennis racket. The boy is wearing a white headband, which is visible on his head.\n\nThere are three other people in the background, possibly watching the game."}, "461009": {"image_id": 461009, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.19720265943222184, "Bleu_3": 0.15351083131080304, "Bleu_4": 0.1145643364316842, "METEOR": 0.21940955045242816, "ROUGE_L": 0.2922655715263518, "CIDEr": 2.670226459901793e-08, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1111111111111111, "f": 0.12, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man holding an apple in his hand. The apple is small. The man is smiling and appears to be enjoying the moment. The man is wearing a red shirt. There are no other people, friends, or family members in the scene."}, "262323": {"image_id": 262323, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.09550351820629131, "Bleu_4": 1.2224986162514046e-05, "METEOR": 0.14674154861366698, "ROUGE_L": 0.2109266943291839, "CIDEr": 5.07051863465572e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.16666666666666666, "f": 0.14634146341463414, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a giraffe standing in a grassy area, surrounded by a fence. The giraffe appears to be looking at the camera, capturing the viewer's attention. There are no ostriches in the scene. There is a bird in the scene."}, "236049": {"image_id": 236049, "Bleu_1": 0.16666666666452992, "Bleu_2": 0.11396057645816743, "Bleu_3": 5.549219378047397e-07, "Bleu_4": 1.2285946074545025e-09, "METEOR": 0.13398134202108672, "ROUGE_L": 0.15091538842157345, "CIDEr": 7.615465948831257e-21, "SPICE": {"All": {"pr": 0.2, "re": 0.06666666666666667, "f": 0.1, "fn": 28.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image features a design carved into a brick wall. The design is a combination of a heart and a shield, with the heart being the central element. The shield is located in the window of the sacrament church. The two shapes are connected by a line.\n\nIn addition, there are two hearts in the design. The first heart has a pigeon as the central element, while the second heart has a white swan as the central element."}, "373374": {"image_id": 373374, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.11895773785545558, "Bleu_3": 0.06522364605376364, "Bleu_4": 8.631003710817792e-06, "METEOR": 0.22109168276233993, "ROUGE_L": 0.17722254503195814, "CIDEr": 1.0847052063145625e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.20833333333333334, "f": 0.22222222222222224, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a dining table with a white plate containing a delicious-looking sandwich, possibly a lobster roll. The sandwich is placed in the center of the plate. A small bowl of dressing is accompanied by the side salad. The salad is spread out around it.\n\nThere is no fork in the scene."}, "225603": {"image_id": 225603, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.12366938847771936, "Bleu_3": 6.783327450171972e-07, "Bleu_4": 1.5968781455284126e-09, "METEOR": 0.15985550029453566, "ROUGE_L": 0.24497991967871488, "CIDEr": 2.898267505279309e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.37037037037037035, "f": 0.3225806451612903, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 10.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image features two tables with a large pizza on one of them. The pizza is not cut into slices and is placed on a wooden cutting board. There are several forks and a knife surrounding the pizza. \n\nThere are two people in the scene, likely preparing to enjoy the pizza."}, "528729": {"image_id": 528729, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.23555849565513073, "Bleu_3": 0.14170580589433998, "Bleu_4": 1.6542259679051986e-05, "METEOR": 0.2431273984159014, "ROUGE_L": 0.3633355393778955, "CIDEr": 2.2480488363764835e-05, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.2631578947368421, "f": 0.17543859649122803, "fn": 14.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.5, "f": 0.31999999999999995, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image features a man standing in the street. He is talking on his cell phone and holding a cell phone. The man is waiting for a bus. He is wearing a baseball cap. The man is positioned in the street."}, "317070": {"image_id": 317070, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.20657747505062754, "Bleu_3": 0.10583300875240854, "Bleu_4": 1.356590733316526e-05, "METEOR": 0.2505512808601127, "ROUGE_L": 0.23282442748091606, "CIDEr": 9.589449470980789e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14285714285714285, "f": 0.18604651162790697, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a person surfing on a surfboard over the ocean. The person is holding onto a parachute, which is attached to a snowboard. The sky is the backdrop against which the person's silhouette is visible."}, "102331": {"image_id": 102331, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2387049580041334, "Bleu_3": 1.316015355781716e-06, "Bleu_4": 3.1217125272269455e-09, "METEOR": 0.19724775472562187, "ROUGE_L": 0.3536231884057971, "CIDEr": 0.0072761894235375294, "SPICE": {"All": {"pr": 0.2127659574468085, "re": 0.47619047619047616, "f": 0.29411764705882354, "fn": 11.0, "numImages": 1.0, "fp": 37.0, "tp": 10.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.25, "f": 0.125, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3684210526315789, "re": 0.7777777777777778, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}}, "caption": "The image captures a person riding a green dirt bike on a dirt track. The person is skillfully maneuvering the bike, showcasing their expertise in the sport."}, "450452": {"image_id": 450452, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1447907475849832, "Bleu_3": 7.387419460030929e-07, "Bleu_4": 1.6767836295274806e-09, "METEOR": 0.20900660911079055, "ROUGE_L": 0.21585279547062985, "CIDEr": 5.651942373751738e-12, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.05555555555555555, "f": 0.049999999999999996, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image features a red door with a clock mounted on it. The clock is positioned towards the center of the door. The clock does not appear to be rusty. The door is surrounded by a metal frame, which adds to the overall appearance of the clock.\n\nThe clock is positioned on the wall."}, "503292": {"image_id": 503292, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.11630378346259652, "Bleu_3": 6.749086636594644e-07, "Bleu_4": 1.6351840356486612e-09, "METEOR": 0.1837065649250249, "ROUGE_L": 0.2121001390820584, "CIDEr": 1.0260876056760394e-08, "SPICE": {"All": {"pr": 0.15, "re": 0.12, "f": 0.1333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image captures a busy airport scene with six airplanes parked on the runway. One of the airplanes is a large Delta airplane, which is taking off and leaving the runway. Another airplane is visible in the background, likely preparing for takeoff or having just landed."}, "542248": {"image_id": 542248, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.1814970425910117, "Bleu_3": 0.1103716852403353, "Bleu_4": 1.293698116812338e-05, "METEOR": 0.20991373886801895, "ROUGE_L": 0.2858816637375513, "CIDEr": 9.399483331473952e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.09375, "f": 0.1111111111111111, "fn": 29.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.16666666666666666, "f": 0.17391304347826086, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image features a giraffe standing in a grassy field, surrounded by trees. The giraffe is positioned in the middle of the scene, with its head and neck visible as it stands tall. The trees in the background are of varying heights, creating a natural and serene environment for the giraffe."}, "251019": {"image_id": 251019, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.216777492377193, "Bleu_3": 0.13685551833182424, "Bleu_4": 0.08300386118896969, "METEOR": 0.2506721258426198, "ROUGE_L": 0.24413950829045164, "CIDEr": 4.020226193241502e-14, "SPICE": {"All": {"pr": 0.2, "re": 0.13636363636363635, "f": 0.16216216216216214, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man playing tennis. He is wearing a red shirt and black shorts. The man is in the middle of a swing, holding a tennis racket. The tennis ball is visible in the air, close to the man's racket.\n\nThere is no tennis court, swing, or any other tennis-related objects in the scene."}, "48738": {"image_id": 48738, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.16447838792810768, "Bleu_3": 0.10713507226754848, "Bleu_4": 1.3004139996985578e-05, "METEOR": 0.24858194956746346, "ROUGE_L": 0.31812255541069095, "CIDEr": 1.7029105922774845e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a large brown ram with long, curved horns standing in a forest. The ram is looking at the trees. The ram has a mountainous environment. The scene is set against a backdrop of trees, providing a natural and serene environment for the ram."}, "22759": {"image_id": 22759, "Bleu_1": 0.382352941165225, "Bleu_2": 0.3229211588918931, "Bleu_3": 0.2535153985740639, "Bleu_4": 0.1800612800289555, "METEOR": 0.26089126161866366, "ROUGE_L": 0.4033057851239669, "CIDEr": 0.0005055172588655792, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.21739130434782608, "f": 0.27777777777777773, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a brown and white cat lying on a bed. The cat is positioned on the bed, with its head resting on a pillow. The cat appears to be a little fat."}, "577065": {"image_id": 577065, "Bleu_1": 0.27272727271487607, "Bleu_2": 0.11396057645433466, "Bleu_3": 8.65950551279142e-07, "Bleu_4": 2.4178614975561836e-09, "METEOR": 0.10632680266841672, "ROUGE_L": 0.20938215102974828, "CIDEr": 0.01085361955323604, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.10714285714285714, "f": 0.09375, "fn": 25.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "There are no horses in this image. The image shows a field with a tree in the background. The field is brown."}, "116461": {"image_id": 116461, "Bleu_1": 0.49999999997222233, "Bleu_2": 0.3834824944017541, "Bleu_3": 0.26391679797893985, "Bleu_4": 0.1871015822927144, "METEOR": 0.21961823541256348, "ROUGE_L": 0.4149659863945578, "CIDEr": 0.3556587131529673, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a pizza sitting on a metal plate. The pizza is topped with cheese and tomatoes."}, "7214": {"image_id": 7214, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.21290467263078663, "Bleu_3": 0.10024266962117512, "Bleu_4": 1.230060008283069e-05, "METEOR": 0.29831465162199783, "ROUGE_L": 0.27180140038192235, "CIDEr": 5.50398808321401e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 24.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.2727272727272727, "f": 0.39999999999999997, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image features a bathroom with a sink, toilet, and a mirror. The sink is located in the center of the room. The toilet is situated to the right of the sink. A window provides a view of a tree. \n\nThere are no books in the scene."}, "264336": {"image_id": 264336, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.17168710855232877, "Bleu_4": 0.1529388540448376, "METEOR": 0.2604799311275686, "ROUGE_L": 0.34957020057306587, "CIDEr": 6.347803897711359e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.1111111111111111, "f": 0.1212121212121212, "fn": 32.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.25, "f": 0.2580645161290323, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image features a man riding a bicycle on a grassy field. The man is wearing a red jacket. The man is enjoying the outdoor activity. The kite is positioned in the sky. There is no backpack in the scene."}, "91994": {"image_id": 91994, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.21969401454816964, "Bleu_3": 0.1568828531255759, "Bleu_4": 0.09421771973768849, "METEOR": 0.2698886081616105, "ROUGE_L": 0.28773584905660377, "CIDEr": 1.1348315512000048e-10, "SPICE": {"All": {"pr": 0.15625, "re": 0.2631578947368421, "f": 0.19607843137254902, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a man sitting at a desk in a room. In front of the man, there is a computer screen. The man is wearing glasses and appears to be focused on the content displayed on the screen. He is likely a computer programmer. The man is wearing a black shirt."}, "222831": {"image_id": 222831, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.20100756304732487, "Bleu_3": 9.794571638096428e-07, "Bleu_4": 2.174837249054904e-09, "METEOR": 0.1628092337550407, "ROUGE_L": 0.3134232498394348, "CIDEr": 2.3147731197203676e-07, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.35, "f": 0.31818181818181823, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a white shelf with various items displayed on it. There are two vases of different colors, including white and beige. Some of the vases are placed on the wall. A mug, a book, and a purse are also displayed on the shelf."}, "167122": {"image_id": 167122, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.21172526113776916, "Bleu_3": 0.11698471131245454, "Bleu_4": 1.5604716741454922e-05, "METEOR": 0.2572280247405249, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.020002683357401983, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a car parked in a parking lot at night. The car is positioned towards the left side of the scene. The area around the headlights is illuminated."}, "561699": {"image_id": 561699, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.16866980207552001, "Bleu_3": 9.245364897036987e-07, "Bleu_4": 2.1798470960469237e-09, "METEOR": 0.2181328111083347, "ROUGE_L": 0.24636510500807754, "CIDEr": 6.252531372039847e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13636363636363635, "f": 0.14634146341463414, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "There is no person in this image. There is a pizza on a plate. The pizza is cut into slices, and there is a slice of pizza on each plate. The plates are placed on a dining table."}, "144932": {"image_id": 144932, "Bleu_1": 0.2592592592496571, "Bleu_2": 0.09985744824877686, "Bleu_3": 7.361059130611606e-07, "Bleu_4": 2.0190748509151956e-09, "METEOR": 0.1696909387856005, "ROUGE_L": 0.2357487922705314, "CIDEr": 0.01186320623818493, "SPICE": {"All": {"pr": 0.25, "re": 0.15555555555555556, "f": 0.1917808219178082, "fn": 38.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a boat floating on the water. The boat is yellow. The water is calm, and the boat seems to be enjoying a peaceful ride."}, "267321": {"image_id": 267321, "Bleu_1": 0.26984126983698664, "Bleu_2": 0.14751743194767952, "Bleu_3": 0.07092275823078667, "Bleu_4": 8.781150090587107e-06, "METEOR": 0.18618604003444245, "ROUGE_L": 0.3219548975255329, "CIDEr": 2.0346084770670012e-11, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.17391304347826086, "f": 0.2222222222222222, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a gray couch positioned in front of the window in a modern living room. There is also a gray chair located in the living room. \n\nA dining table is situated in the middle of the room. On top of the dining table, there is a potted plant on one table and a lamp and a vase on the other table."}, "47837": {"image_id": 47837, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.18535150310271878, "Bleu_3": 0.13488222755190674, "Bleu_4": 0.10459901189645937, "METEOR": 0.23622507611091187, "ROUGE_L": 0.31431726168568275, "CIDEr": 3.5012448024263444e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features four people sitting at a dining table in a cabin. They are enjoying a meal together. The people are sitting at a table. The people are eating a meal. The table is set with three bowls, one cup, and five bottles."}, "119802": {"image_id": 119802, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.06356417261520644, "Bleu_3": 4.240167136485046e-07, "Bleu_4": 1.100364056976739e-09, "METEOR": 0.16992788748596696, "ROUGE_L": 0.17134831460674158, "CIDEr": 4.963608378734457e-13, "SPICE": {"All": {"pr": 0.1875, "re": 0.15789473684210525, "f": 0.17142857142857143, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features four teddy bears sitting on the side of a road. The teddy bears are pink. They are surrounded by various stuffed animals. A pink teddy bear is positioned in the center of the scene, with a pink teddy bear on its left side and another pink teddy bear on its right side."}, "186624": {"image_id": 186624, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 0.09970052069750876, "Bleu_4": 0.06607272734339885, "METEOR": 0.2219288137444941, "ROUGE_L": 0.24956165984804207, "CIDEr": 2.3730541661201275e-12, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.21052631578947367, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a man standing next to a large, old-fashioned steam locomotive. The train is parked inside a building, possibly a train depot or a museum. The man is inspecting a large red machine. The man is working on a large machine. The man is holding a hose. The man is possibly a mechanic."}, "43345": {"image_id": 43345, "Bleu_1": 0.18421052631094187, "Bleu_2": 0.07055964054000095, "Bleu_3": 5.171343737911396e-07, "Bleu_4": 1.4098910172162998e-09, "METEOR": 0.12499115441888478, "ROUGE_L": 0.19152276295133436, "CIDEr": 3.15235536740451e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.3157894736842105, "f": 0.3076923076923077, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a dog standing in a room. The dog is brown and white. The dog is standing on the floor.\n\nThere is no person or object in the scene. There are no chairs in the room."}, "260802": {"image_id": 260802, "Bleu_1": 0.387755102032903, "Bleu_2": 0.2696369441112524, "Bleu_3": 0.1835863167540986, "Bleu_4": 0.12807025450919163, "METEOR": 0.3078058294304554, "ROUGE_L": 0.3010487353485503, "CIDEr": 1.6006583765119222e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.13043478260869565, "f": 0.16666666666666669, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image captures a dynamic moment during a tennis match, with a male tennis player in action on a clay court. The male tennis player is playing tennis. He is in the process of hitting the tennis ball with his racket. The tennis ball is close to the player."}, "225537": {"image_id": 225537, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.25717224992746507, "Bleu_3": 0.1719893752106008, "Bleu_4": 0.11943763958353004, "METEOR": 0.23685433946331488, "ROUGE_L": 0.2782846715328467, "CIDEr": 0.00514466683587045, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a laptop computer sitting on a table. The laptop's keyboard is not open. The laptop's screen is not open. The background is black."}, "533548": {"image_id": 533548, "Bleu_1": 0.25396825396422273, "Bleu_2": 0.19200614429185545, "Bleu_3": 0.1445739812879152, "Bleu_4": 0.08424221804183649, "METEOR": 0.280208236113718, "ROUGE_L": 0.22067183462532297, "CIDEr": 3.6156340834791935e-16, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.19047619047619047, "f": 0.26666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features two men sitting at a table in a library. The first man is working on a laptop computer, which is located to the left and right side of him. The second man is also working on a laptop. The man is wearing a red jacket and appears to be focused on his task. The table is surrounded by seven chairs."}, "120783": {"image_id": 120783, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.21470745394187096, "Bleu_3": 0.15885423636837526, "Bleu_4": 0.11553231385242531, "METEOR": 0.30051079543622355, "ROUGE_L": 0.38220551378446116, "CIDEr": 3.772951308294527e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.46153846153846156, "f": 0.4999999999999999, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a woman standing in a room. She is holding a bunch of bananas on her head. The woman is wearing a dress and appears to be smiling. The bananas are spread across her head, with some placed in the front and others in the back."}, "574823": {"image_id": 574823, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.15328483486852826, "Bleu_3": 0.09489031659247031, "Bleu_4": 1.1215483008811741e-05, "METEOR": 0.22678678315600023, "ROUGE_L": 0.24413950829045164, "CIDEr": 6.248751893815533e-13, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a baseball field with several players on the field. A baseball player in a red jersey and black helmet is standing in the center of the field, holding a baseball bat. Another baseball player is visible in the background, closer to the right side of the field. There are two benches in the scene."}, "455301": {"image_id": 455301, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.14882336590863374, "Bleu_3": 8.14428187387852e-07, "Bleu_4": 1.9170109753033433e-09, "METEOR": 0.2427061163062223, "ROUGE_L": 0.25505226480836235, "CIDEr": 2.0825507413656897e-06, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.30434782608695654, "f": 0.27999999999999997, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a woman and a baby lying in bed. The woman is holding the baby, who is not sleeping. The woman is positioned on the bed, while the baby is positioned on the bed. A blanket is placed on the bed."}, "463498": {"image_id": 463498, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.10562592656622659, "Bleu_4": 1.2211216504829663e-05, "METEOR": 0.18355411360807863, "ROUGE_L": 0.2717149220489977, "CIDEr": 2.049541173927815e-13, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.10526315789473684, "f": 0.125, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image is a bird's eye view of a cozy living room with a couch, a chair, and a rug. The couch is positioned in front of the fireplace. The chair is located near the left side of the room. The rug covers the floor, adding warmth and a pop of color to the space."}, "132362": {"image_id": 132362, "Bleu_1": 0.2666666666622222, "Bleu_2": 0.15032920559803906, "Bleu_3": 0.0730386791087442, "Bleu_4": 9.092765040070276e-06, "METEOR": 0.22134846234633704, "ROUGE_L": 0.26236559139784943, "CIDEr": 2.533208780538048e-16, "SPICE": {"All": {"pr": 0.125, "re": 0.11764705882352941, "f": 0.12121212121212122, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a dining table filled with a variety of food items, including bowls, plates, and cups. There are six bowls placed on the table, containing a variety of food. There are five plates and one cup on the table as well.\n\nThere are two food items in the bowls. A variety of food is contained in the bowls."}, "496198": {"image_id": 496198, "Bleu_1": 0.14772727272559402, "Bleu_2": 0.08241394612589059, "Bleu_3": 4.2904316647922057e-07, "Bleu_4": 9.81795439563233e-10, "METEOR": 0.13600028809143222, "ROUGE_L": 0.14137824474660074, "CIDEr": 2.4630056302076946e-34, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2777777777777778, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a dome of a church in the center of the scene. There are ten people walking in the street. Some of the people are carrying a red bag, a slingshot, a bag, a hat, a cell phone, a bag of sand, a bag, a large bag of food, a bag of sand, and a bag of trash. \n\nThere are two handbags being carried by some of the people.\n\nThere is no building or courthouse in the scene.\n\nThere are no cars parked in the scene."}, "227830": {"image_id": 227830, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.22041550750546754, "Bleu_3": 0.15793120213643597, "Bleu_4": 0.10227637589661819, "METEOR": 0.2733301428545398, "ROUGE_L": 0.3198501872659176, "CIDEr": 1.3163276149709229e-05, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.2, "f": 0.15789473684210528, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a truck parked at a gas station. The driver is likely filling up the tank. The truck is positioned in front of the gas station. There are two cars parked in front of the gas station."}, "440528": {"image_id": 440528, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.18227065413983304, "Bleu_3": 0.11746087033063704, "Bleu_4": 0.07978199887125366, "METEOR": 0.2146829941673373, "ROUGE_L": 0.2616154395997141, "CIDEr": 1.3912470304669005e-07, "SPICE": {"All": {"pr": 0.5, "re": 0.2972972972972973, "f": 0.3728813559322034, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 11.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.8, "re": 0.23529411764705882, "f": 0.3636363636363636, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5454545454545454, "f": 0.6, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image features a dining table with two plates. A spoon is on each plate. A delicious dessert, consisting of a chocolate cake with a drizzle of icing, is placed on one of the plates. A pear is also placed on the table."}, "163412": {"image_id": 163412, "Bleu_1": 0.16853932584080294, "Bleu_2": 0.09785753961258026, "Bleu_3": 4.79243734771928e-07, "Bleu_4": 1.0636352458389118e-09, "METEOR": 0.14110321300474493, "ROUGE_L": 0.16673174541194843, "CIDEr": 1.2029390305887497e-37, "SPICE": {"All": {"pr": 0.12280701754385964, "re": 0.30434782608695654, "f": 0.175, "fn": 16.0, "numImages": 1.0, "fp": 50.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2222222222222222, "f": 0.14814814814814814, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.5555555555555556, "f": 0.29411764705882354, "fn": 4.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}}, "caption": "The image captures a lively scene of a large group of 34 people gathered on a street. Some of the people are riding bicycles. \n\nThe scene is bustling with activity, with people engaged in various activities. Some are sitting on a bench, while others are playing frisbee or riding skateboards. There are also people sitting in lawn chairs and even riding horses. \n\nThe overall atmosphere is energetic and vibrant, with people enjoying their time outdoors. The street is filled with laughter and movement, creating a lively and dynamic scene."}, "389174": {"image_id": 389174, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.18898223649928916, "Bleu_3": 1.016531912449821e-06, "Bleu_4": 2.3752661405742283e-09, "METEOR": 0.2772949523083194, "ROUGE_L": 0.2824074074074074, "CIDEr": 0.00013604230336518883, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.3, "f": 0.33962264150943394, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.13333333333333333, "f": 0.18181818181818182, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features two men sitting on two benches. A tree is near the first bench, and a pond is near the second bench. The park is surrounded by trees, some of which have fallen leaves."}, "250427": {"image_id": 250427, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.0846667513321056, "Bleu_3": 4.898148929041865e-07, "Bleu_4": 1.1830039010250525e-09, "METEOR": 0.14579862545808842, "ROUGE_L": 0.15474378488077117, "CIDEr": 1.2753286442651143e-17, "SPICE": {"All": {"pr": 0.3, "re": 0.1935483870967742, "f": 0.23529411764705882, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.4, "f": 0.48, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image depicts a man standing in front of a building. The man is holding an umbrella. The street is lined with various businesses, but there is no sidewalk. There is a sign with red and white colors. \n\nThere are five people in the image. Some of the people are carrying bags, while others are carrying a large white flag or a dog."}, "399741": {"image_id": 399741, "Bleu_1": 0.41860465115305573, "Bleu_2": 0.35995570047742576, "Bleu_3": 0.2934954777307622, "Bleu_4": 0.20867305598207972, "METEOR": 0.2830282245521698, "ROUGE_L": 0.41432540907687554, "CIDEr": 0.0004911475682676814, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.19047619047619047, "f": 0.15384615384615383, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features a girl sitting on the floor, surrounded by a pile of presents. The girl is holding a stuffed animal and is surrounded by toys. She is wearing a white shirt. The stuffed animal on the floor is a teddy bear."}, "555461": {"image_id": 555461, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.31814238147962415, "Bleu_3": 0.2675344974647728, "Bleu_4": 0.2270919391152995, "METEOR": 0.4173009044784577, "ROUGE_L": 0.5495495495495495, "CIDEr": 6.271795839464219e-05, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.08695652173913043, "f": 0.08888888888888888, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a man wearing a yellow hat and a yellow jacket, sitting at a dining table with a laptop in front of him. The man is pointing at the laptop. The table is surrounded by two chairs."}, "6593": {"image_id": 6593, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.33776026472651466, "Bleu_3": 0.22032450159630393, "Bleu_4": 0.136287703576046, "METEOR": 0.2591504483543033, "ROUGE_L": 0.3216168717047452, "CIDEr": 0.01828626241937585, "SPICE": {"All": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image captures a tennis match in progress on the court. There are two men playing tennis. The man is in a white shirt and black shorts. The other man is also playing tennis."}, "536088": {"image_id": 536088, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.18731716231147263, "Bleu_3": 9.82466623306346e-07, "Bleu_4": 2.265493021694376e-09, "METEOR": 0.22370864583266561, "ROUGE_L": 0.3559445660102115, "CIDEr": 1.9208455237051712e-05, "SPICE": {"All": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 22.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a cake with a yellow and white color scheme, resembling a wicker basket. The cake is adorned with numerous white flowers, giving it a vibrant and eye-catching appearance. The cake is placed on a dining table."}, "106849": {"image_id": 106849, "Bleu_1": 0.5769230769008876, "Bleu_2": 0.40191847621848265, "Bleu_3": 0.23788381719511645, "Bleu_4": 0.1555398640677602, "METEOR": 0.28678103536049565, "ROUGE_L": 0.48316831683168315, "CIDEr": 0.025573849530110195, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15789473684210525, "f": 0.16666666666666669, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features two men in shirts. The man's shirt is white. The man is standing in front of a counter with bottles of wine."}, "38259": {"image_id": 38259, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1489923873895453, "Bleu_3": 8.085240745765992e-07, "Bleu_4": 1.8948452736055547e-09, "METEOR": 0.20477728471232332, "ROUGE_L": 0.214185393258427, "CIDEr": 1.0564285853058865e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16129032258064516, "f": 0.18867924528301885, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a large airplane parked on the runway. The airplane is positioned on the tarmac. The nose of the airplane is visible through a window located in the dining room. \n\nInside the airport terminal, there are seven chairs arranged around the terminal."}, "535602": {"image_id": 535602, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.2355932146939368, "Bleu_3": 0.13511835401219335, "Bleu_4": 1.538766030885031e-05, "METEOR": 0.29445582971595047, "ROUGE_L": 0.31063017186505404, "CIDEr": 1.3439599161417022e-08, "SPICE": {"All": {"pr": 0.375, "re": 0.16666666666666666, "f": 0.23076923076923078, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a cat standing in a room with a pizza box and a laptop on the floor. The cat is looking at a bicycle. A bicycle is attracting the cat. The pizza box is placed next to the laptop. There are several pieces of pizza."}, "448600": {"image_id": 448600, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.23452078798159529, "Bleu_3": 0.13372469554821612, "Bleu_4": 1.8157374167807726e-05, "METEOR": 0.17910447761194032, "ROUGE_L": 0.3462630085146642, "CIDEr": 0.06543832634790235, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.20833333333333334, "f": 0.21739130434782608, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image features a cake placed on a plate, which is positioned on a dining table. The cake is adorned with a strawberry on top."}, "499226": {"image_id": 499226, "Bleu_1": 0.378378378368152, "Bleu_2": 0.22924343512884385, "Bleu_3": 0.1145096068514652, "Bleu_4": 1.449645171861387e-05, "METEOR": 0.20564730651996418, "ROUGE_L": 0.332295719844358, "CIDEr": 0.00013229212671292078, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.2916666666666667, "f": 0.2592592592592593, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.625, "f": 0.43478260869565216, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image features a gray cat lying on a couch. The cat is resting its head on a pillow. The couch is covered with a floral pattern, adding a touch of warmth and coziness to the scene."}, "286303": {"image_id": 286303, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.26437184629550714, "Bleu_3": 0.16892248770152052, "Bleu_4": 0.1145449886714462, "METEOR": 0.2526591154062461, "ROUGE_L": 0.36464560204953034, "CIDEr": 0.033536591644752554, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.038461538461538464, "f": 0.05128205128205129, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a man wearing a tie with a pattern of squares and rectangles. The tie is prominently displayed. The man is wearing a tie. The tie covers the neck."}, "363072": {"image_id": 363072, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.28171808489925787, "Bleu_3": 0.14506145713745966, "Bleu_4": 1.8693000799253376e-05, "METEOR": 0.20191423869422073, "ROUGE_L": 0.2978515625, "CIDEr": 0.011090185979182168, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.2222222222222222, "f": 0.2962962962962963, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.0625, "f": 0.1, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.46153846153846156, "f": 0.5714285714285714, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features a train traveling down the tracks, passing by a tall building. The train is positioned on the tracks. The building is located in the city."}, "416193": {"image_id": 416193, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.0956600132176177, "Bleu_4": 1.248740514185277e-05, "METEOR": 0.21001259707073372, "ROUGE_L": 0.28175519630484985, "CIDEr": 9.97770526929397e-06, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.3, "f": 0.33962264150943394, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.5454545454545454, "f": 0.631578947368421, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image features two zebras standing and grazing in a grassy field. The zebras are grazing on grass. A zoo is the zebras' habitat. Zebra and giraffe are visible in the scene. Two zebras are visible in the scene."}, "390048": {"image_id": 390048, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.24046440328937668, "Bleu_3": 0.15454026854146363, "Bleu_4": 0.09464371716192442, "METEOR": 0.24555619891795477, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.8874361903662173e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.125, "f": 0.13559322033898305, "fn": 28.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a man sitting at a dining table in a restaurant. He is eating a sandwich and appears to be enjoying it. The man is wearing a black shirt. He is taking a bite of the sandwich, and his mouth is open, showing the sandwich's contents."}, "46924": {"image_id": 46924, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.20159462811746034, "Bleu_3": 0.11460354422397828, "Bleu_4": 1.551155008995511e-05, "METEOR": 0.24235829617030039, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.004221889230924138, "SPICE": {"All": {"pr": 0.05405405405405406, "re": 0.1111111111111111, "f": 0.07272727272727272, "fn": 16.0, "numImages": 1.0, "fp": 35.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.4, "f": 0.1739130434782609, "fn": 3.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}}, "caption": "The image features a person holding two cell phones. The person is holding a small black and silver phone. The cell phones are positioned in the person's hands."}, "26026": {"image_id": 26026, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.10435177140627983, "Bleu_3": 0.05793449266323809, "Bleu_4": 7.711027176657378e-06, "METEOR": 0.17568276696407423, "ROUGE_L": 0.16850828729281767, "CIDEr": 1.9860832642244276e-14, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.21052631578947367, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features an elephant standing in a circus ring. A ring is close to the elephant. The elephant is surrounded by a group of people. There are at least 11 people visible in the scene. Some of the people are riding on the elephant. A fence is surrounding the elephant. In the stands, the people are scattered."}, "382333": {"image_id": 382333, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.1539536764846181, "Bleu_4": 1.9355268993636573e-05, "METEOR": 0.22538222630334476, "ROUGE_L": 0.3809099018733274, "CIDEr": 0.005261970213574613, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.21739130434782608, "f": 0.24390243902439024, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a garden with a variety of plants. There is a bush in the garden, which is brown. Additionally, there is a tomato plant in the garden."}, "508899": {"image_id": 508899, "Bleu_1": 0.5277777777631173, "Bleu_2": 0.3473253814913661, "Bleu_3": 0.24211296096327467, "Bleu_4": 0.14400747787822876, "METEOR": 0.22919268496535336, "ROUGE_L": 0.3721132897603485, "CIDEr": 0.001127049809458141, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.23529411764705882, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a small white cat sitting on a carpeted floor in a living room. The cat is surrounded by furniture, including a couch and a chair. The TV is located in the living room."}, "20553": {"image_id": 20553, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.11429089766174176, "Bleu_3": 6.350643060633274e-07, "Bleu_4": 1.5044258140708105e-09, "METEOR": 0.12612152658142473, "ROUGE_L": 0.19624664879356574, "CIDEr": 2.972056885704523e-10, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.16666666666666666, "f": 0.20833333333333334, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features three teddy bears sitting on a chair in the middle of a dirt field. The teddy bears are dressed in different outfits, including a baseball uniform, a sarong, and a red hat. The chair is placed on a dirt surface. The teddy bears are surrounded by various items, including bottles."}, "65465": {"image_id": 65465, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.1996674976872179, "Bleu_3": 0.09907033493163239, "Bleu_4": 1.2486557620082352e-05, "METEOR": 0.21514938742147596, "ROUGE_L": 0.3132795304475422, "CIDEr": 3.695932143752809e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a group of four elephants standing together in a grassy field. There are three adult elephants and one baby elephant in the group. The adult elephants are positioned on either side of the baby elephant, which is in the middle."}, "320823": {"image_id": 320823, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.20562903028343854, "Bleu_3": 0.10022433611412394, "Bleu_4": 1.2517970591861958e-05, "METEOR": 0.22923873510458034, "ROUGE_L": 0.20890410958904113, "CIDEr": 1.6834035908542286e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image captures a joyful celebration, with a group of people gathered around a dining table. The people are cutting a cake. The main focus is on a woman who is surrounded by other people. They are sharing a laugh and enjoying the festivities."}, "477087": {"image_id": 477087, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.18210783976741574, "Bleu_3": 0.12839858194733528, "Bleu_4": 0.0979463398478606, "METEOR": 0.2709857866924505, "ROUGE_L": 0.2945081472540736, "CIDEr": 5.88010042442965e-09, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.045454545454545456, "f": 0.046511627906976744, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image features a collection of baseball memorabilia, including a baseball bat, a baseball glove, and a baseball. The baseball bat is placed in the center. The baseball glove is positioned on the left side of the image. The baseball is positioned in the middle of the baseball memorabilia."}, "71357": {"image_id": 71357, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.18881372800670282, "Bleu_3": 0.13061179075716728, "Bleu_4": 1.637368248793686e-05, "METEOR": 0.23091211157790748, "ROUGE_L": 0.3216168717047452, "CIDEr": 0.00010204349466315818, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.36363636363636365, "f": 0.3137254901960784, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5454545454545454, "re": 0.75, "f": 0.631578947368421, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a yellow train traveling down the tracks, passing by a platform. The train is positioned at the station. The platform is located on the tracks. The train is a passenger train."}, "343453": {"image_id": 343453, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.245934688411173, "Bleu_3": 1.2632988704413624e-06, "Bleu_4": 2.8875537785495685e-09, "METEOR": 0.28487720293917623, "ROUGE_L": 0.36247877758913405, "CIDEr": 0.0012071731873276523, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.4090909090909091, "f": 0.4186046511627907, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 9.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.8571428571428571, "f": 0.7058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image features a woman standing on skis and holding ski poles. She is positioned in the center of a snowy slope, surrounded by trees. The woman is posing for a picture."}, "34580": {"image_id": 34580, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.24442576475815658, "Bleu_3": 0.14916736567829222, "Bleu_4": 1.7548433487930022e-05, "METEOR": 0.25417284768160436, "ROUGE_L": 0.3412587412587412, "CIDEr": 0.00019478784690320504, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.17857142857142858, "f": 0.21739130434782608, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5, "f": 0.588235294117647, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features a fire hydrant situated in the grassy field. The fire hydrant is red and white. The hydrant is surrounded by ten cars parked in the grass. The cars are parked in a somewhat random manner."}, "151393": {"image_id": 151393, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.21148042285421853, "Bleu_3": 0.1509613123538503, "Bleu_4": 0.09062681199181734, "METEOR": 0.24891045431951073, "ROUGE_L": 0.30530530530530536, "CIDEr": 6.250752594643977e-08, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.28, "f": 0.2692307692307692, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image features a stop sign with several street signs attached to it, including a \"no parking\" sign and a \"no left turn\" sign. The stop sign is located on a pole. The street signs are placed on a pole. A brick building is visible in the background. The scene is in a city."}, "239351": {"image_id": 239351, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.3027650353973863, "Bleu_3": 0.22866601286411384, "Bleu_4": 0.15268470848129914, "METEOR": 0.20778383865626204, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.07963250303405346, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features four people standing on a dirt road. Two of the people are holding open umbrellas. The people are posing for a picture."}, "357109": {"image_id": 357109, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.16012815380103265, "Bleu_3": 0.11050805385393858, "Bleu_4": 0.07771324020542086, "METEOR": 0.1865897117274709, "ROUGE_L": 0.23680124223602486, "CIDEr": 1.2844158723736412e-06, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image captures a lively scene at a skate park, where two skateboarders are performing tricks on a ramp. The skateboarders are in the middle of the ramp, skillfully executing their tricks. A crowd of people is watching the skateboarders."}, "174888": {"image_id": 174888, "Bleu_1": 0.127999999998976, "Bleu_2": 0.10160010159933631, "Bleu_3": 0.07486595906525724, "Bleu_4": 0.051213072938171365, "METEOR": 0.19032493798263225, "ROUGE_L": 0.1559216131780744, "CIDEr": 5.6353457129093976e-80, "SPICE": {"All": {"pr": 0.35, "re": 0.2692307692307692, "f": 0.3043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features four men standing outside a restaurant. \n\nMan 1 is eating a slice of pizza and holding a paper plate. He is wearing a gray sweatshirt and enjoying his meal. \n\nMan 2 is holding a paper plate and eating a donut. He is wearing a white apron and enjoying a hot dog. \n\nMan 3 is looking at his phone and eating a sandwich. He is wearing a blue shirt and enjoying a cigarette. \n\nMan 4 is eating a sandwich and holding a cell phone. He is wearing a blue shirt and enjoying a burger. \n\nThere are also two other people in the scene. Person 1 is walking down the street and not eating. Person 2 is looking at the window and not eating."}, "542934": {"image_id": 542934, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.2130071614174478, "Bleu_3": 0.14798582729591478, "Bleu_4": 0.10419141114820699, "METEOR": 0.22631284663748583, "ROUGE_L": 0.23131094257854823, "CIDEr": 1.9856561797920917e-14, "SPICE": {"All": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a kitchen with wooden cabinets and a large wooden countertop. The countertop is cluttered with multiple bottles, cups, and a bowl. \n\nThere are no knives in the scene.\n\nThe kitchen is well-equipped with a sink positioned in the middle of the kitchen. A microwave, a toaster, and a blender are also placed on the countertop."}, "467848": {"image_id": 467848, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.18227065413983304, "Bleu_3": 9.322875456397681e-07, "Bleu_4": 2.1215213862352894e-09, "METEOR": 0.15465031128066492, "ROUGE_L": 0.2620596538603167, "CIDEr": 3.399181399783355e-06, "SPICE": {"All": {"pr": 0.3125, "re": 0.17857142857142858, "f": 0.22727272727272727, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a man loading a tank onto the back of a truck. The tank is positioned on a ramp, and the man is standing next to it, ensuring that it is properly secured. The truck is parked in a parking lot."}, "413124": {"image_id": 413124, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.22479304902841, "Bleu_3": 0.10318169109005193, "Bleu_4": 1.2499678782703702e-05, "METEOR": 0.22346402467374415, "ROUGE_L": 0.2952973720608575, "CIDEr": 1.6831982625388872e-08, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14814814814814814, "f": 0.14285714285714285, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a boy wearing a baseball uniform, standing on a baseball field. The boy is holding a baseball glove and appears to be a baseball player. The boy is positioned in the center of the scene. The baseball glove is covering the boy's left hand."}, "300773": {"image_id": 300773, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 0.07502652544655376, "Bleu_4": 9.635230436528825e-06, "METEOR": 0.19790683391349284, "ROUGE_L": 0.18780788177339902, "CIDEr": 5.613134563755224e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.09523809523809523, "f": 0.12903225806451613, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image depicts two men and a woman standing next to each other in front of a red door. The first man is wearing a red robe, and the second man is wearing a yellow shirt. The woman is wearing a striped shirt. They appear to be looking at their cell phones."}, "373440": {"image_id": 373440, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.17039568890752202, "Bleu_3": 0.12032507801506327, "Bleu_4": 0.07721791910699559, "METEOR": 0.22025666051550696, "ROUGE_L": 0.2544696066746126, "CIDEr": 8.939781337945462e-11, "SPICE": {"All": {"pr": 0.3125, "re": 0.20833333333333334, "f": 0.25, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a store with a shelf filled with a variety of teddy bears. There are eight teddy bears arranged on the shelf. The teddy bears are of different sizes and colors. They are placed in various positions on the shelf, some closer to the front and others towards the back."}, "334321": {"image_id": 334321, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.18677184190511298, "Bleu_3": 0.14921454814781854, "Bleu_4": 0.12486557620089443, "METEOR": 0.2533966759441985, "ROUGE_L": 0.285427807486631, "CIDEr": 1.029540186988218e-06, "SPICE": {"All": {"pr": 0.1875, "re": 0.10344827586206896, "f": 0.13333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a dog sitting on a bench. The dog is white. The bench is green. \n\nThere is a man and a woman seated on the bench. \n\nIn the background, there are two people. A baby stroller can be seen in the background."}, "535668": {"image_id": 535668, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.20173664619184403, "Bleu_3": 0.12467616434935537, "Bleu_4": 1.474489249311284e-05, "METEOR": 0.2530098440790394, "ROUGE_L": 0.29985955056179775, "CIDEr": 3.4740522939209044e-08, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1111111111111111, "f": 0.10256410256410256, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image captures a baseball game in progress. The batter is swinging a baseball bat at a pitched ball. The catcher and umpire are closely watching the play. The catcher is holding a bat. \n\nThere is no baseball or baseball glove in the scene."}, "157184": {"image_id": 157184, "Bleu_1": 0.15789473683933522, "Bleu_2": 0.1501878522938693, "Bleu_3": 0.12704540914145687, "Bleu_4": 0.10331208012034214, "METEOR": 0.3161072637952931, "ROUGE_L": 0.28488032691185056, "CIDEr": 1.848068694612657e-14, "SPICE": {"All": {"pr": 0.09259259259259259, "re": 0.21739130434782608, "f": 0.12987012987012986, "fn": 18.0, "numImages": 1.0, "fp": 49.0, "tp": 5.0}, "Relation": {"pr": 0.041666666666666664, "re": 0.1111111111111111, "f": 0.06060606060606061, "fn": 8.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.19047619047619047, "re": 0.5, "f": 0.27586206896551724, "fn": 4.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}}, "caption": "The image features a man wearing glasses and a plaid shirt. He is holding a large pair of scissors in his hands. The man is in a kitchen.\n\nThere is no picture or room in the scene. There is no window in the scene.\n\nThe man is also holding a remote control in one of his hands."}, "64390": {"image_id": 64390, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.3027650353973863, "Bleu_3": 0.15854815808014064, "Bleu_4": 2.0630760173659833e-05, "METEOR": 0.19947418440859183, "ROUGE_L": 0.3462630085146642, "CIDEr": 0.05983003940307369, "SPICE": {"All": {"pr": 0.125, "re": 0.13636363636363635, "f": 0.13043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image features a street corner with a traffic light hanging above the street. The traffic light is red. There are vehicles on the street."}, "91857": {"image_id": 91857, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.09983569293155374, "Bleu_4": 1.2127601540611025e-05, "METEOR": 0.1786941012443853, "ROUGE_L": 0.24190350297422336, "CIDEr": 6.717370192726253e-10, "SPICE": {"All": {"pr": 0.12, "re": 0.13636363636363635, "f": 0.1276595744680851, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image features two giraffes standing in a forest. One giraffe is eating from a feeder, while the other giraffe is reaching for a tree. The giraffe's long necks are stretched out to reach the food. The scene is lively and depicts the giraffes in their natural habitat."}, "275202": {"image_id": 275202, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2497770842103635, "Bleu_3": 0.12492568368856392, "Bleu_4": 1.5836105185157607e-05, "METEOR": 0.249995098960509, "ROUGE_L": 0.41654021244309564, "CIDEr": 0.0004942893838369781, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a pizza sitting on a plate on a dining table. The pizza is topped with cheese, basil, and tomatoes. There is a fork and a knife placed next to the pizza."}, "508811": {"image_id": 508811, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.23145502493836512, "Bleu_3": 0.1506556909135452, "Bleu_4": 1.65120006937825e-05, "METEOR": 0.21260441604461885, "ROUGE_L": 0.28621700879765394, "CIDEr": 3.2396378762978734e-07, "SPICE": {"All": {"pr": 0.28, "re": 0.35, "f": 0.3111111111111111, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image captures a man playing tennis. He is swinging a tennis racket with great intensity. The man is wearing a white and green shirt and black shorts. The tennis ball is visible in the air, close to the man's racket. The man is swinging his racket backwards."}, "511111": {"image_id": 511111, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.2602575457946004, "Bleu_3": 0.1358775263736997, "Bleu_4": 1.7624523616137678e-05, "METEOR": 0.2723818617821227, "ROUGE_L": 0.3010858835143139, "CIDEr": 0.005918013670649023, "SPICE": {"All": {"pr": 0.375, "re": 0.2857142857142857, "f": 0.3243243243243243, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a juicer on the kitchen counter. The juicer is juicing an orange. There is a glass filled with juice on the right side of the counter."}, "70471": {"image_id": 70471, "Bleu_1": 0.2857142857097506, "Bleu_2": 0.23515854049712342, "Bleu_3": 0.1536327800964496, "Bleu_4": 0.11603938494584821, "METEOR": 0.29780485422065744, "ROUGE_L": 0.34359283846308586, "CIDEr": 7.515321047033422e-14, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a baby sitting on a person's lap. The baby is holding a remote control in its mouth. The person is also holding a remote control. The baby appears to be enjoying the remote, but it is not chewing on it or playing with it. The person is sitting on a couch. A bottle of orange juice is placed nearby."}, "95516": {"image_id": 95516, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.21380899352561974, "Bleu_3": 0.12395961884568825, "Bleu_4": 1.418847468492011e-05, "METEOR": 0.2566759460016686, "ROUGE_L": 0.26521739130434785, "CIDEr": 3.7055887931817196e-10, "SPICE": {"All": {"pr": 0.24, "re": 0.3, "f": 0.2666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image features a pickup truck parked on a gravel surface. The truck bed is filled with firewood, with logs stacked neatly in the back. The firewood covers almost the entire bed and appears to be ready for transportation.\n\nThere is no other information or objects mentioned in the passage."}, "299946": {"image_id": 299946, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.09087496586948689, "Bleu_4": 1.1854610697110774e-05, "METEOR": 0.2018524666481771, "ROUGE_L": 0.28715534633490253, "CIDEr": 9.189314536866518e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.12, "f": 0.16216216216216217, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a woman standing in a kitchen, making a smoothie. She is wearing a white shirt and is focused on a blender. The kitchen is well-equipped with a countertop where a bowl of greens is placed near the blender."}, "356456": {"image_id": 356456, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.18227065413983304, "Bleu_3": 0.09322875456397678, "Bleu_4": 1.1930191477552195e-05, "METEOR": 0.18767398779892702, "ROUGE_L": 0.26852531181217903, "CIDEr": 6.393983927069111e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.3125, "f": 0.2777777777777778, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image features a train traveling on the tracks. The train is a passenger train, specifically an Amtrak train. It is positioned towards the left side of the scene. On the right side, there is a small red building located on the tracks."}, "420181": {"image_id": 420181, "Bleu_1": 0.06324110671911763, "Bleu_2": 0.03880387398396573, "Bleu_3": 0.022892970488383686, "Bleu_4": 0.014801018762082323, "METEOR": 0.09693743609339807, "ROUGE_L": 0.07222140002959893, "CIDEr": 0.0, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.3888888888888889, "f": 0.34146341463414637, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image captures a scene at a food festival, where two people are standing and talking. Some of the people are wearing a black leather jacket. One person is holding a phone and talking, while another person is also talking on the phone and wearing a hoodie. Another person is holding a phone and a man is doing something. Some of the people are wearing a black jacket. Another person is eating, and some of the people are wearing a hat. Another person is holding a hat and a man is doing something. Some of the people are wearing a black jacket. Another person is talking on the phone and wearing a blue shirt.\n\nThere is no tent or food in the scene.\n\nThere are six people in total. One person is holding a phone and talking, while another person is also talking on the phone and wearing a hoodie. Another person is holding a phone and a man is doing something. Some of the people are wearing a black jacket. Another person is eating, and some of the people are wearing a hat. Another person is holding a hat and a man is doing something. Some of the people are wearing a black jacket. Another person is talking on the phone and wearing a blue shirt.\n\nThere is no backpack in the scene.\n\nThere is no man in the scene.\n\nThere is one jacket in the scene, and it is black.\n\nThere is one person standing near the center of the scene."}, "324785": {"image_id": 324785, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.16012815380103265, "Bleu_3": 0.08771030046935029, "Bleu_4": 1.1620839902592802e-05, "METEOR": 0.1845200504881098, "ROUGE_L": 0.21034482758620687, "CIDEr": 1.9798263642761586e-05, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.06451612903225806, "f": 0.06451612903225806, "fn": 29.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image features a harbor filled with various boats and cages. The boats can be seen scattered throughout the scene, with some positioned closer to the water's edge and others further out. Some boats are positioned on the dock."}, "100329": {"image_id": 100329, "Bleu_1": 0.1408450704205515, "Bleu_2": 0.0634361479686553, "Bleu_3": 3.8780032799182475e-07, "Bleu_4": 9.623408045685037e-10, "METEOR": 0.15167630057803466, "ROUGE_L": 0.19453302961275623, "CIDEr": 1.192818302367384e-22, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.21428571428571427, "f": 0.2857142857142857, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a bear walking through a rocky area. The bear is brown. The bear is eating a piece of ice. The bear is climbing a boat. The bear is in the process of climbing a rocky hill, with its front paws on the rocks. The bear appears to be focused on its surroundings. The bear is walking through a forest.\n\nThere is no river or food in the scene."}, "191425": {"image_id": 191425, "Bleu_1": 0.378378378368152, "Bleu_2": 0.22924343512884385, "Bleu_3": 0.1442730640873472, "Bleu_4": 0.09694361543381819, "METEOR": 0.1903066382559066, "ROUGE_L": 0.2930344275420336, "CIDEr": 5.27666694887763e-05, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.7, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image features a sunset over a body of water. The sun is setting in the background, casting a warm glow on the scene. There is no bird in the image. The water is calm and serene."}, "494620": {"image_id": 494620, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.22841609628304363, "Bleu_3": 0.1923316074401127, "Bleu_4": 0.16959513235152923, "METEOR": 0.28854392919884186, "ROUGE_L": 0.38364779874213834, "CIDEr": 1.3587481515168054e-06, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.16666666666666666, "f": 0.15, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of a man riding a horse in front of a brick building. The man is wearing a hat and a jacket, and he appears to be enjoying his ride. The horse is positioned in front of the building."}, "359260": {"image_id": 359260, "Bleu_1": 0.18644067796294173, "Bleu_2": 0.13887752404723028, "Bleu_3": 0.06968345758419357, "Bleu_4": 8.816582219575545e-06, "METEOR": 0.2555238078187109, "ROUGE_L": 0.28788673308862084, "CIDEr": 3.998638689766273e-14, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.22727272727272727, "f": 0.22727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a man sitting on a boat, holding a large tire in one hand and a horse in the other. The man is preparing to fish. The man is holding a stick in one hand and a hat in the other. The man is leading the horse to the water. The horse is positioned on the beach."}, "286342": {"image_id": 286342, "Bleu_1": 0.21052631578393358, "Bleu_2": 0.13065106688931807, "Bleu_3": 7.797842756795139e-07, "Bleu_4": 1.918509013645893e-09, "METEOR": 0.21669214525526037, "ROUGE_L": 0.23940345368916802, "CIDEr": 8.399872608871464e-06, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.18181818181818182, "f": 0.14545454545454545, "fn": 18.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image features a black keyboard placed on a bed. There is also a mouse located on the right side of the keyboard. The keyboard and mouse are connected, indicating that they are part of a computer setup."}, "576191": {"image_id": 576191, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.09525009524711837, "Bleu_3": 6.712276850566138e-07, "Bleu_4": 1.797019940085349e-09, "METEOR": 0.22977453183024552, "ROUGE_L": 0.25311203319502074, "CIDEr": 0.0013231425232311676, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.23076923076923078, "f": 0.22641509433962265, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a cat lying on the ground next to a green bench. The cat is positioned under the bench. The bench is situated in a concrete area, possibly a park."}, "580908": {"image_id": 580908, "Bleu_1": 0.1891891891866326, "Bleu_2": 0.13469012250287526, "Bleu_3": 0.09109336628116305, "Bleu_4": 1.0157819149349337e-05, "METEOR": 0.2362457996426993, "ROUGE_L": 0.24221605949829828, "CIDEr": 1.3169303824088578e-24, "SPICE": {"All": {"pr": 0.24, "re": 0.25, "f": 0.24489795918367346, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a group of five baseball players standing together on a field. They are all wearing black and white uniforms. They are all holding baseball bats, with some of them holding them in their hands and others resting them on the ground.\n\nThe players are standing in various positions, with some closer to the foreground and others further back. Some of the baseball players are resting the baseball bats on the ground."}, "556420": {"image_id": 556420, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.1877669040449484, "Bleu_3": 0.09753298099084377, "Bleu_4": 1.2583840141545549e-05, "METEOR": 0.19134120939377844, "ROUGE_L": 0.25558659217877094, "CIDEr": 1.4069388071768388e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.2631578947368421, "f": 0.25641025641025644, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a beach scene with a thatched umbrella providing shade for a bench. The umbrella is located on the beach. The bench is situated on the beach. The beach is surrounded by a palm tree, which is green."}, "81251": {"image_id": 81251, "Bleu_1": 0.6249999999739584, "Bleu_2": 0.436139187975756, "Bleu_3": 0.35096664832143043, "Bleu_4": 0.2533098404853243, "METEOR": 0.2891210258585972, "ROUGE_L": 0.5400505902192243, "CIDEr": 0.13868109298364117, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.21739130434782608, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image features a pizza topped with tomatoes, arugula, and parmesan cheese. The pizza is sitting on a plate placed on a wooden table."}, "130437": {"image_id": 130437, "Bleu_1": 0.21428571428265308, "Bleu_2": 0.13650472655602283, "Bleu_3": 6.495244273014659e-07, "Bleu_4": 1.4220927286209104e-09, "METEOR": 0.21001348732621702, "ROUGE_L": 0.1764705882352941, "CIDEr": 2.249932169740292e-22, "SPICE": {"All": {"pr": 0.3125, "re": 0.15625, "f": 0.20833333333333334, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a train traveling down the tracks near a city street. The train is positioned in the middle of the scene. A car driving down the street is visible on the left side of the image. A white Toyota Rav4 is also visible on the left side of the image. The street is lined with buildings, creating a bustling urban environment.\n\nThere are no people in the scene."}, "359546": {"image_id": 359546, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.21213203434730224, "Bleu_3": 0.12507242179545755, "Bleu_4": 1.7268932788606005e-05, "METEOR": 0.19891736687686679, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.018689814196785854, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image features a beach scene with three umbrellas and five chairs arranged near the ocean. The umbrellas provide shade for people on the beach."}, "298979": {"image_id": 298979, "Bleu_1": 0.43902439023319456, "Bleu_2": 0.2963188789875593, "Bleu_3": 0.13106438047696786, "Bleu_4": 1.560154507213612e-05, "METEOR": 0.258545404305523, "ROUGE_L": 0.3768016472203157, "CIDEr": 5.067083355505451e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18518518518518517, "f": 0.17543859649122806, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a group of eight zebras grazing on a lush green field near a body of water. Some zebras are standing in the field, while others are scattered across the grass. The zebras are of various sizes and positions."}, "413079": {"image_id": 413079, "Bleu_1": 0.222222222217284, "Bleu_2": 0.1421338109005459, "Bleu_3": 0.07773956660946078, "Bleu_4": 1.028417039620613e-05, "METEOR": 0.2132537981049872, "ROUGE_L": 0.3134232498394348, "CIDEr": 7.442133687431073e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1875, "f": 0.2222222222222222, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.35714285714285715, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image captures a jockey riding a horse over a jump in a grassy field. The horse is jumping over an obstacle. The jockey is guiding the horse. The scene is set in a black and white photo, which adds a timeless and nostalgic feel."}, "403584": {"image_id": 403584, "Bleu_1": 0.34615384614053263, "Bleu_2": 0.2631174057817865, "Bleu_3": 0.2053066689333913, "Bleu_4": 0.16562574028886803, "METEOR": 0.29261979359734114, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.023302536816793385, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.10526315789473684, "f": 0.09523809523809525, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features three people standing on a beach. The people are holding surfboards. They are wearing wetsuits, indicating that they are preparing to go surfing."}, "401004": {"image_id": 401004, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.2822385621600037, "Bleu_3": 0.16417992979299406, "Bleu_4": 1.8857018976734923e-05, "METEOR": 0.2191701274655075, "ROUGE_L": 0.3356258596973865, "CIDEr": 0.00012214551328156318, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image depicts a lively bar scene with a group of 11 people sitting at a bar. Some people are sitting on chairs and others are standing nearby. The bar is well-stocked with various bottles, cups, and wine."}, "489829": {"image_id": 489829, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.13693063937416847, "Bleu_3": 0.08411954328568416, "Bleu_4": 9.898622389283045e-06, "METEOR": 0.18868321249407147, "ROUGE_L": 0.21774604793472715, "CIDEr": 2.2941500317925037e-18, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a woman standing in a room with a variety of clocks on display. She is surrounded by several clocks of different sizes and styles. Some of the clocks are on the floor and others are on the walls. The woman appears to be in a clock shop, possibly discussing the clocks with a customer.\n\nThere is no other customer in the scene."}, "177810": {"image_id": 177810, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.15404159684489246, "Bleu_3": 0.09353181070486517, "Bleu_4": 1.0945882771391123e-05, "METEOR": 0.2665978733261029, "ROUGE_L": 0.30098684210526316, "CIDEr": 1.0500408294717016e-14, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features three teddy bears sitting in a circle. The teddy bears are of various sizes, with some being small and one being a standard size of a teddy. A small Christmas tree is placed in the middle of the teddy bears. The Christmas tree is adorned with lights. The overall ambiance of the scene is cozy and festive."}, "130225": {"image_id": 130225, "Bleu_1": 0.4285714285591838, "Bleu_2": 0.3175536744057716, "Bleu_3": 0.1828311173754695, "Bleu_4": 2.0904996083255102e-05, "METEOR": 0.26187171988636493, "ROUGE_L": 0.31470335339638866, "CIDEr": 0.0003124103480401475, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a group of five people standing on a beach. Some of the people are playing with a frisbee, while others are flying a kite. The kites are soaring high in the sky."}, "364010": {"image_id": 364010, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.28419928002220657, "Bleu_3": 0.2459537584056061, "Bleu_4": 0.20026481987655226, "METEOR": 0.27485902092591574, "ROUGE_L": 0.34078212290502796, "CIDEr": 3.9128525152952356e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.125, "f": 0.17391304347826086, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a dog sitting in the back seat of a car. The dog is black and brown. The dog is not relaxed and not enjoying the ride. The dog is positioned on the back seat, between the chairs."}, "527728": {"image_id": 527728, "Bleu_1": 0.3913043478090738, "Bleu_2": 0.32667930387375627, "Bleu_3": 0.2166130652166942, "Bleu_4": 2.6699675741779013e-05, "METEOR": 0.22260333764147208, "ROUGE_L": 0.39144385026737966, "CIDEr": 0.05303546166342146, "SPICE": {"All": {"pr": 0.3, "re": 0.21428571428571427, "f": 0.25, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a large elephant standing in a zoo enclosure. The elephant is standing in the water, which is surrounded by rocks."}, "8787": {"image_id": 8787, "Bleu_1": 0.08484848484797063, "Bleu_2": 0.07192835393955897, "Bleu_3": 0.03166194180583706, "Bleu_4": 3.7413161281398893e-06, "METEOR": 0.1340934528098161, "ROUGE_L": 0.10822798846750943, "CIDEr": 6.190903723978649e-145, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image features a man walking on a city street with a dog in his arms. The man is holding a camera. The dog is being held close to the man's chest. The dog is not a puppy. \n\nThere are a total of fourteen people in the scene. Some of the people are sitting on a bench. Some of the people are holding a stuffed animal. Some of the people are eating a sandwich. Some of the people are putting on a hat. Some of the people are taking pictures. Some of the people are riding on a bike. Some of the people are doing a girl in a red skirt and a boy in a yellow shirt. Some of the people are doing a little girl in a red skirt. Some of the people are doing a woman putting on her pink shirt. Some of the people are doing a woman holding a baby.\n\nThere is no puppy or chest in the scene."}, "198717": {"image_id": 198717, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.06657795516001168, "Bleu_3": 4.584595505702186e-07, "Bleu_4": 1.2096859591117995e-09, "METEOR": 0.15869048360309204, "ROUGE_L": 0.19551282051282048, "CIDEr": 6.410647659932241e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3, "f": 0.25531914893617025, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two men in a bedroom. One of the men is lying in bed, while the other is sitting on the bed. The man lying in bed is holding a plate, and the other man is holding a frisbee. They appear to be eating in bed."}, "465223": {"image_id": 465223, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.26208179769640866, "Bleu_3": 0.1998903164886561, "Bleu_4": 0.15454743722279543, "METEOR": 0.28540671452690153, "ROUGE_L": 0.37446286065070594, "CIDEr": 9.56950563029983e-07, "SPICE": {"All": {"pr": 0.08, "re": 0.1111111111111111, "f": 0.09302325581395349, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image captures a tennis match in progress, with two players standing on opposite sides of the net. They are holding tennis rackets. The players are engaged in a tennis match. The audience is watching the match intently, with several people scattered around the court."}, "377595": {"image_id": 377595, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.07725027140990079, "Bleu_3": 0.04465893976449208, "Bleu_4": 6.061014491860736e-06, "METEOR": 0.13212688133004502, "ROUGE_L": 0.16968011126564672, "CIDEr": 8.924933030908474e-20, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.32, "f": 0.37209302325581395, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7777777777777778, "re": 0.5833333333333334, "f": 0.6666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}}, "caption": "The image features a burrito sitting on a dining table. The burrito appears to be a cake, with the cheese exposed. It is a stuffed tortilla. A knife is placed next to the burrito. \n\nThere are three bowls on the table. \n\nThere is no fork, meat, or other ingredients in the scene. \n\nThere is no cup in the scene. \n\nA pair of scissors is placed next to the burrito."}, "386968": {"image_id": 386968, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.32836322897522124, "Bleu_3": 0.23414052245317735, "Bleu_4": 0.13301832449356157, "METEOR": 0.32079309619798535, "ROUGE_L": 0.31431726168568275, "CIDEr": 6.56958280700935e-06, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.2222222222222222, "f": 0.1702127659574468, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.6, "f": 0.3157894736842105, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image features a woman riding a bicycle down a street, accompanied by a dog. The woman is wearing a coat and a scarf, and she is holding the dog. The dog is sitting in a basket, attached to the back of the bicycle."}, "405994": {"image_id": 405994, "Bleu_1": 0.3225806451508845, "Bleu_2": 3.2791291788122237e-09, "Bleu_3": 7.18411073437036e-12, "Bleu_4": 3.39226878067752e-13, "METEOR": 0.1565252267949109, "ROUGE_L": 0.2149779735682819, "CIDEr": 0.00018045647458267712, "SPICE": {"All": {"pr": 0.0625, "re": 0.0625, "f": 0.0625, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features a display case filled with various wooden toys and decorations. There is a wooden toy airplane made of wood. The toy airplane showcases the colors of the rainbow."}, "134815": {"image_id": 134815, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.23218786590068996, "Bleu_3": 0.10867840345149304, "Bleu_4": 1.3301832449356157e-05, "METEOR": 0.20194351940520935, "ROUGE_L": 0.2889039242219215, "CIDEr": 4.768815459890899e-07, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.25, "f": 0.27906976744186046, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a large, well-equipped kitchen with wooden cabinets and a stove. The cabinets are made of wood. \n\nThe kitchen is clean and organized, with various cooking utensils and pots placed on the countertops. There are no knives or spoons in the scene.\n\n"}, "201934": {"image_id": 201934, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.28657565120073264, "Bleu_3": 0.22373076962696106, "Bleu_4": 0.17965618424902763, "METEOR": 0.29384820177053034, "ROUGE_L": 0.3299208035541819, "CIDEr": 3.7556363020394014e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.19230769230769232, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a white bus parked at a bus stop. The bus is positioned on the side of the road. There is a person standing on the sidewalk. The person is not standing next to the bus. \n\nThere are no other people in the scene."}, "320899": {"image_id": 320899, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.06502560887474053, "Bleu_3": 4.65200159363572e-07, "Bleu_4": 1.251797059186196e-09, "METEOR": 0.20434615263037667, "ROUGE_L": 0.214185393258427, "CIDEr": 1.2511896114412277e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image features a bedroom with two beds placed in the center of the room. The beds are covered with brown and beige comforters. One bed is surrounded by a wrought iron fence, while the other bed is surrounded by a wooden slatted wall."}, "406217": {"image_id": 406217, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.19050019049423664, "Bleu_3": 0.13424553701132264, "Bleu_4": 1.699516529547108e-05, "METEOR": 0.22110594050294963, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.0011666015708571367, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.13793103448275862, "f": 0.1904761904761905, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07692307692307693, "f": 0.125, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features two signs hanging from the side of a building, advertising Factory Trained Technicians. The signs are prominently displayed in the foreground. Factory Trained Technicians is visible in the windows."}, "130076": {"image_id": 130076, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.26271583096647133, "Bleu_3": 0.14123276695717468, "Bleu_4": 1.5564719247748716e-05, "METEOR": 0.27529128223891053, "ROUGE_L": 0.3051907442151345, "CIDEr": 2.0691803658914416e-11, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1875, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a man standing in a living room. The man is holding a Nintendo Wii remote in his hand. He is playing a video game, possibly on the Wii console. The living room is furnished with a couch and a chair, providing a comfortable space for relaxation and entertainment."}, "407042": {"image_id": 407042, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.17733172552966228, "Bleu_3": 0.08456484271613046, "Bleu_4": 1.0435177484324181e-05, "METEOR": 0.2319416098461669, "ROUGE_L": 0.2445589919816724, "CIDEr": 2.765284899297283e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.3333333333333333, "f": 0.26315789473684204, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.75, "f": 0.46153846153846156, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features one child, a boy, and two girls. The children are standing next to each other and holding stuffed animals. The boy is holding a stuffed animal. The girls are also holding stuffed animals. The stuffed animals include a dog and a cat.\n\nThey are all smiling and enjoying their time together."}, "170784": {"image_id": 170784, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.15541746803663614, "Bleu_3": 0.08188084718265139, "Bleu_4": 1.0629666321559288e-05, "METEOR": 0.33113677179835416, "ROUGE_L": 0.2827814569536423, "CIDEr": 7.781376877066263e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.08695652173913043, "f": 0.125, "fn": 21.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image features a red double-decker bus parked on a city street. There are several people around the bus. Some people are standing on the sidewalk, while others are walking on the street. The bus is quite large and occupies a significant portion of the scene."}, "189744": {"image_id": 189744, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.1332650098148157, "Bleu_3": 0.08443776935294735, "Bleu_4": 0.05676041543224515, "METEOR": 0.20306147868680155, "ROUGE_L": 0.22438255386232267, "CIDEr": 3.5534065666134023e-16, "SPICE": {"All": {"pr": 0.125, "re": 0.17647058823529413, "f": 0.14634146341463414, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image features a building with a sign that reads \"The Peel Aldergate.\" The building appears to be a pub. A car is parked in front of the building. The building is situated on the corner of St John's Road and St John's.\n\nThere is no city in the scene.\n\nThere is no other commercial establishment in the scene."}, "222440": {"image_id": 222440, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.20314980006762443, "Bleu_3": 0.13439856314503967, "Bleu_4": 0.09261204717123699, "METEOR": 0.186458655735202, "ROUGE_L": 0.29047619047619044, "CIDEr": 4.0183798514002795e-05, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.25, "f": 0.25641025641025644, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image does not depict any people or a fence. There is one animal in the scene. The scene shows a lively zoo scene with a group of people gathered around a fence, observing the animals."}, "78060": {"image_id": 78060, "Bleu_1": 0.19999999999714288, "Bleu_2": 0.10767638041008373, "Bleu_3": 0.055451163250179424, "Bleu_4": 7.102549926177596e-06, "METEOR": 0.23535268803767653, "ROUGE_L": 0.2200180342651037, "CIDEr": 3.1914927435608905e-21, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.08, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image features a man and a young girl standing on a snow-covered slope. They are both wearing a pair of skis. The man is giving the girl a hug. The man is holding a snowboard. The girl is likely having her first time on skis and the man is assisting her. They are not surrounded by a group of other people.\n\nThere are no other people in the scene."}, "224647": {"image_id": 224647, "Bleu_1": 0.4285714285306123, "Bleu_2": 0.2927700218563286, "Bleu_3": 0.2081820120668931, "Bleu_4": 0.149628483710643, "METEOR": 0.24890862335496508, "ROUGE_L": 0.46003016591251883, "CIDEr": 0.4205829690152928, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a girl standing on a green field. The girl is holding a tennis racket, possibly practicing her skills."}, "301326": {"image_id": 301326, "Bleu_1": 0.15624999999511724, "Bleu_2": 0.07099522927862878, "Bleu_3": 5.517966071705036e-07, "Bleu_4": 1.5514392334764108e-09, "METEOR": 0.12263320673634291, "ROUGE_L": 0.19805194805194803, "CIDEr": 0.00033217014785846084, "SPICE": {"All": {"pr": 0.1875, "re": 0.17647058823529413, "f": 0.1818181818181818, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a cat and a dog standing together. The cat is positioned behind the dog on the left side. The dog is positioned behind the cat on the right side."}, "128058": {"image_id": 128058, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 8.206702275709718e-07, "Bleu_4": 1.85183396023708e-09, "METEOR": 0.2505250362123615, "ROUGE_L": 0.26521739130434785, "CIDEr": 6.219713935994119e-11, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.23333333333333334, "f": 0.2692307692307693, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image features a man playing tennis on a court. The man is wearing a white shirt and holding a tennis racket. He is actively engaged in the game, playing tennis. The man is positioned closer to the net. The other man is on the other side of the court."}, "123867": {"image_id": 123867, "Bleu_1": 0.3454545454482645, "Bleu_2": 0.22622654834606154, "Bleu_3": 0.14255337633579895, "Bleu_4": 0.08639374396357648, "METEOR": 0.26578271574992063, "ROUGE_L": 0.24956165984804207, "CIDEr": 1.5910855596156353e-11, "SPICE": {"All": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a dog walking across a grassy field. The dog is brown and is wearing a red shirt. The dog is carrying a frisbee. There are no other people close to the dog.\n\nThere are two owners in the scene. The overall relationship between the person and the dog is owner and pet."}, "331753": {"image_id": 331753, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.20550493309104514, "Bleu_3": 0.11909718541937828, "Bleu_4": 0.07662616731096747, "METEOR": 0.2228962654382591, "ROUGE_L": 0.2482558139534883, "CIDEr": 7.075606017066736e-11, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1111111111111111, "f": 0.13636363636363638, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a room filled with three white toilets. The toilets are arranged in different positions. Toilet 1 and toilet 2 are arranged in a row, while toilet 3 is arranged side by side with another toilet. The toilets are sitting on the floor in a storage area or a warehouse."}, "425690": {"image_id": 425690, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1348399724902187, "Bleu_3": 0.06956880074617594, "Bleu_4": 8.927747941495415e-06, "METEOR": 0.22142516657478603, "ROUGE_L": 0.20795454545454545, "CIDEr": 3.17142334542871e-14, "SPICE": {"All": {"pr": 0.3, "re": 0.14285714285714285, "f": 0.19354838709677416, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image is a black and white photograph that depicts a city street at night. The photograph captures the lights of a city. The city is filled with traffic, including multiple cars and a truck. The cars and the truck are scattered throughout the scene, with the truck located towards the right side of the intersection."}, "225658": {"image_id": 225658, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.14607233344869358, "Bleu_3": 8.399971471326652e-07, "Bleu_4": 2.0285762996808684e-09, "METEOR": 0.22519782138617356, "ROUGE_L": 0.28728414442700156, "CIDEr": 5.9992152982251485e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "There is no man in this image. There is a tie with an American Flag design in the image. The tie is being held by someone. The image shows a room with dim lighting, creating a cozy atmosphere."}, "331236": {"image_id": 331236, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.31171460007158086, "Bleu_3": 0.1989808460068978, "Bleu_4": 2.1628820160385834e-05, "METEOR": 0.31662028120701985, "ROUGE_L": 0.3287143956889915, "CIDEr": 0.00017294596212205255, "SPICE": {"All": {"pr": 0.15, "re": 0.12, "f": 0.1333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image features a blue shirt with an orange design on it, placed on a bed. The frisbee is located on the bed. The shirt is surrounded by various items, including a cell phone, a book, and a pen."}, "47225": {"image_id": 47225, "Bleu_1": 0.17741935483584811, "Bleu_2": 0.12059257882752877, "Bleu_3": 0.0899229176792115, "Bleu_4": 0.07046075433689628, "METEOR": 0.1749178202283816, "ROUGE_L": 0.1953041622198506, "CIDEr": 1.6510290084006535e-16, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.28, "f": 0.3333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image features a table with a teddy bear placed on it. There are four stuffed animals on the table, including a teddy bear, a tiger, and a lion. The teddy bear is on the left side of the table, in the middle of the table, and on the right side of the table. The tiger toy is located near the center."}, "64300": {"image_id": 64300, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.22447181760045806, "Bleu_3": 0.17003301679096786, "Bleu_4": 1.8723409997052042e-05, "METEOR": 0.22707556089346545, "ROUGE_L": 0.21801286633309508, "CIDEr": 2.469445934102659e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a beach with a large body of water in the background. There are several birds standing on the shore, with one bird in the foreground and others scattered around the area. The birds are enjoying their time on the beach."}, "59547": {"image_id": 59547, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.168845408373504, "Bleu_3": 0.08032892222096841, "Bleu_4": 9.898183824655714e-06, "METEOR": 0.2567323000456603, "ROUGE_L": 0.3321664721898094, "CIDEr": 3.6406258832675737e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a woman standing in a yard. She is holding a green plate with a slice of rainbow cake on it. The cake is decorated with candles, making it look like a birthday cake. The woman is smiling and appears to be enjoying the moment.\n\nIn the background, there are no other objects or people."}, "501538": {"image_id": 501538, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.24112141107953186, "Bleu_3": 0.1415487039853373, "Bleu_4": 0.09176232845032237, "METEOR": 0.2569711786497726, "ROUGE_L": 0.2888648356108781, "CIDEr": 8.17517426727594e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.19230769230769232, "f": 0.2173913043478261, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a woman standing in front of a blue wall. The woman is holding bananas in her hand. She is wearing a gray shirt and glasses. The woman is not smiling. She is positioned towards the left side of the image."}, "318471": {"image_id": 318471, "Bleu_1": 0.17857142856823985, "Bleu_2": 0.08058229640108601, "Bleu_3": 4.935848712474828e-07, "Bleu_4": 1.2273047425649952e-09, "METEOR": 0.16840200110555753, "ROUGE_L": 0.20378619153674835, "CIDEr": 1.4408589291237477e-13, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.18518518518518517, "f": 0.22222222222222224, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features three street signs located on poles. The street sign prominently displays the name \"Roberts St\". The street sign prominently displays the words \"no left turn\". The street sign prominently displays the name \"Cedar St\".\n\nThere is no Rosemary Street or any other streets in the scene.\n\nThere are no cars in the scene."}, "6091": {"image_id": 6091, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.18093671611020545, "Bleu_3": 0.1407143904422717, "Bleu_4": 0.104911217308913, "METEOR": 0.16284336977193864, "ROUGE_L": 0.2208811104405552, "CIDEr": 2.905846527677159e-08, "SPICE": {"All": {"pr": 0.4375, "re": 0.30434782608695654, "f": 0.358974358974359, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a stop sign with a red background, prominently displayed in the center of the scene. The stop sign is surrounded by a black background, which emphasizes its importance. The sign does the background emphasize. On the side of the road is the stop sign prominently displayed."}, "73": {"image_id": 73, "Bleu_1": 0.21052631578393358, "Bleu_2": 0.10667614940968784, "Bleu_3": 6.81204309942168e-07, "Bleu_4": 1.7335685886739763e-09, "METEOR": 0.14017723479317679, "ROUGE_L": 0.1829085457271364, "CIDEr": 8.69121990272863e-06, "SPICE": {"All": {"pr": 0.36, "re": 0.34615384615384615, "f": 0.35294117647058826, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.875, "f": 0.7368421052631579, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image features two motorcycles parked on a sidewalk. The motorcycles are black and silver. The kickstands of the motorcycles are not down.\n\nThere is no bench in the scene.\n\nThere are no other motorcycles in the scene."}, "196715": {"image_id": 196715, "Bleu_1": 0.20833333333043982, "Bleu_2": 0.15321285325683098, "Bleu_3": 0.11880118932177944, "Bleu_4": 0.09240248103016933, "METEOR": 0.20885586721602986, "ROUGE_L": 0.1999063670411985, "CIDEr": 4.1365943061017767e-23, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a beach scene with a white truck parked on the sand. The truck is equipped with a surfboard, and there is a banana visible on top of the truck. The white truck likely belongs to a lifeguard.\n\nThere are two people enjoying a day at the beach. One person is playing beach volleyball, while the other person is walking on the beach. \n\nThere is no water in the scene."}, "461467": {"image_id": 461467, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.18920628274676068, "Bleu_4": 0.14966430143282045, "METEOR": 0.2921284247311809, "ROUGE_L": 0.5008210180623974, "CIDEr": 0.01646742934366277, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.125, "f": 0.12000000000000001, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image features two women sitting at a dining table, enjoying a delicious pizza together. The pizza is placed in the center of the table. There are no slices visible."}, "398066": {"image_id": 398066, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.14280110945625535, "Bleu_3": 0.09406593130377755, "Bleu_4": 1.1475297679846863e-05, "METEOR": 0.16853583937387115, "ROUGE_L": 0.2238532110091743, "CIDEr": 5.085841040612096e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13793103448275862, "f": 0.1702127659574468, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a man standing in a park, wearing a white shirt. The man is playing baseball and holding a baseball bat. He is preparing to throw a baseball. There is another person visible in the background, and trees are visible as well. The man is standing on the dirt."}, "431140": {"image_id": 431140, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.06657795516001168, "Bleu_3": 4.584595505702186e-07, "Bleu_4": 1.2096859591117995e-09, "METEOR": 0.1907433380084152, "ROUGE_L": 0.2559952038369305, "CIDEr": 5.7110980372397634e-09, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.2962962962962963, "f": 0.3902439024390244, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a restroom with two toilets. The toilets are white. A sink is located next to the toilets. The sink is white. There is a roll of toilet paper placed next to one of the toilets. A hand soap dispenser is placed next to the sink."}, "67315": {"image_id": 67315, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.20568833779665252, "Bleu_3": 0.14948088660548933, "Bleu_4": 0.09747400659908459, "METEOR": 0.23339829365402529, "ROUGE_L": 0.2764350453172206, "CIDEr": 1.5901070409978583e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 28.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image features a man in a suit standing in a room with a window. The suit is well-tailored. The man is wearing a tie, which is neatly placed on his shoulder.\n\nThere is no other entity in the scene."}, "261777": {"image_id": 261777, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.0956600132176177, "Bleu_4": 1.248740514185277e-05, "METEOR": 0.18299818895648343, "ROUGE_L": 0.22846441947565538, "CIDEr": 7.077960715896297e-06, "SPICE": {"All": {"pr": 0.42105263157894735, "re": 0.3076923076923077, "f": 0.35555555555555557, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.75, "f": 0.7058823529411765, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image captures a person performing a ski jump high into the air. The person is wearing a black jacket and is in mid-air, surrounded by a blue sky. The skis are still attached to the person's feet."}, "62296": {"image_id": 62296, "Bleu_1": 0.3999999999800001, "Bleu_2": 4.588314677175783e-09, "Bleu_3": 1.0536053366894084e-11, "Bleu_4": 5.121488960836982e-13, "METEOR": 0.149812734082397, "ROUGE_L": 0.23223350253807104, "CIDEr": 0.05821727546757292, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.17857142857142858, "f": 0.19607843137254902, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features a lake with two boats docked along its shoreline. The boats are blue and white in color."}, "329088": {"image_id": 329088, "Bleu_1": 0.2777777777700618, "Bleu_2": 2.817180849015683e-09, "Bleu_3": 6.157203571278694e-12, "Bleu_4": 2.9000744655888966e-13, "METEOR": 0.21351819757365684, "ROUGE_L": 0.19365079365079363, "CIDEr": 3.3635958737259205e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a person standing on a snow-covered slope. The person is wearing skis and holding ski poles. They are doing skiing. The person is possibly admiring the view of the mountains in the distance."}, "337120": {"image_id": 337120, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.20584674239469475, "Bleu_3": 0.14296838069826945, "Bleu_4": 0.08461771328963097, "METEOR": 0.21018906970648804, "ROUGE_L": 0.2553064275037369, "CIDEr": 9.259527418236822e-14, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1, "f": 0.14634146341463417, "fn": 27.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image features a building with a clock mounted on its side. The building is made of brick. The clock is located on the side of the building and can be easily seen from the street. The building has several windows, including windows of different shapes, such as square and octagonal.\n\nIn front of the building, there are two bicycles."}, "60240": {"image_id": 60240, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2963744891737883, "Bleu_3": 0.2469382016149895, "Bleu_4": 0.21692718598330413, "METEOR": 0.3368556170173779, "ROUGE_L": 0.39071257005604487, "CIDEr": 4.124531032781233e-05, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.043478260869565216, "f": 0.04878048780487805, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image features two people sitting in a car. Both people are holding a cell phone in their hands and are focused on it. The car is in motion, indicating that the people are on the go."}, "134657": {"image_id": 134657, "Bleu_1": 0.206349206345931, "Bleu_2": 0.14131269593760892, "Bleu_3": 0.10940340527874705, "Bleu_4": 0.0899529956754857, "METEOR": 0.2665944314142262, "ROUGE_L": 0.2569773565034228, "CIDEr": 6.955555038031731e-17, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.17857142857142858, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image captures a highway scene with a blue sky and clouds above. The road is busy with six cars driving in both directions. The cars are spread out across the road, with some closer to the left side and others closer to the right side. The overall atmosphere of the scene is lively and dynamic, as the cars move along the road."}, "166979": {"image_id": 166979, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.22918388364562542, "Bleu_3": 0.16968881945964054, "Bleu_4": 0.12350515853971517, "METEOR": 0.23075349582194937, "ROUGE_L": 0.24177566389219182, "CIDEr": 1.934960027617979e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.17857142857142858, "f": 0.20408163265306123, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image features a boat speeding across a large body of water, likely a lake or a bay. The boat is moving quickly, leaving a trail of water behind it. The water appears to be calm, providing a perfect environment for the boat to cruise."}, "160437": {"image_id": 160437, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.15755219780890306, "Bleu_3": 8.141361391768222e-07, "Bleu_4": 1.8608854771631139e-09, "METEOR": 0.1767066552954159, "ROUGE_L": 0.20013123359580048, "CIDEr": 2.004449912775324e-09, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.3125, "f": 0.20408163265306123, "fn": 11.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image features two zebras resting in a sandy area, possibly a zoo enclosure. The zebras are lying down. One zebra is lying down on the ground and the other zebra is standing nearby. The standing zebra appears to be looking at the ground, possibly observing its surroundings."}, "426815": {"image_id": 426815, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.27715276610008205, "Bleu_3": 0.22014152945079551, "Bleu_4": 0.17389607800310708, "METEOR": 0.28198515424146064, "ROUGE_L": 0.36961696602467, "CIDEr": 2.1719853612656115e-05, "SPICE": {"All": {"pr": 0.15, "re": 0.1875, "f": 0.16666666666666663, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a man riding a horse through the water, with the horse standing on a beach. The man is skillfully guiding the horse as they navigate the shallow water. The horse is walking in the water."}, "31749": {"image_id": 31749, "Bleu_1": 0.12499999999739586, "Bleu_2": 1.630820182599269e-09, "Bleu_3": 3.8667976067048165e-12, "Bleu_4": 1.893260841337042e-13, "METEOR": 0.12043010752688173, "ROUGE_L": 0.1601049868766404, "CIDEr": 1.1082441983163626e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.2608695652173913, "f": 0.15584415584415584, "fn": 17.0, "numImages": 1.0, "fp": 48.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 22.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image features two dolls with clock faces on their heads. The dolls create a double image kind of visual effect. The clock faces are positioned in the center of the scene and cover the faces of the dolls, making it appear as if they are wearing hats."}, "54337": {"image_id": 54337, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.16379642331674352, "Bleu_3": 0.08827710327692938, "Bleu_4": 1.1599523689534566e-05, "METEOR": 0.26476218189819656, "ROUGE_L": 0.26425992779783397, "CIDEr": 3.695830163948778e-06, "SPICE": {"All": {"pr": 0.36, "re": 0.375, "f": 0.3673469387755102, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.7272727272727273, "f": 0.6956521739130435, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 8.0}}, "caption": "The image depicts a group of five men sitting around a table in a room. The men are drinking wine. Some of the men are sitting closer to the table. The table is set with wine glasses, a cup, and bottles."}, "161044": {"image_id": 161044, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.20080483221924839, "Bleu_3": 1.1035932143410068e-06, "Bleu_4": 2.6091993798285682e-09, "METEOR": 0.2402255606351407, "ROUGE_L": 0.2803308823529412, "CIDEr": 0.0005289438704332263, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image captures a sky with two airplanes flying. The airplanes are positioned towards the top of the scene, with one slightly higher than the other. The sky is filled with clouds."}, "161978": {"image_id": 161978, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.1471224715772784, "Bleu_3": 1.0266979059547529e-06, "Bleu_4": 2.747221058959446e-09, "METEOR": 0.16759659289833262, "ROUGE_L": 0.3489702517162472, "CIDEr": 0.08621781068885573, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21052631578947367, "f": 0.21621621621621623, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image showcases a series of photos capturing 15 people riding skateboards on a cement surface. The surface is made of concrete."}, "106046": {"image_id": 106046, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.14953924108841646, "Bleu_3": 0.09509966757718548, "Bleu_4": 0.06408283331673237, "METEOR": 0.249700825016702, "ROUGE_L": 0.3210526315789473, "CIDEr": 1.9331451531868542e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.14285714285714285, "f": 0.13043478260869565, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features a young girl sitting at a dining table, looking at a variety of desserts placed in front of her. There are several plates of cakes and pastries, with some of them placed closer to her and others further away. The girl is contemplating her choices, possibly deciding which dessert to enjoy."}, "138970": {"image_id": 138970, "Bleu_1": 0.17543859648815024, "Bleu_2": 0.07915594835626187, "Bleu_3": 4.847689643174701e-07, "Bleu_4": 1.2051820812146925e-09, "METEOR": 0.19137659801778625, "ROUGE_L": 0.14244016345592528, "CIDEr": 4.481945727847411e-15, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.24, "f": 0.20689655172413793, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image depicts a man and two women standing next to a refrigerator. They are possibly moving the refrigerator. The man is on the left side of the refrigerator, while the women are on the right side. The man and the women are wearing white t-shirts. They appear to be in the process of moving the refrigerator."}, "450037": {"image_id": 450037, "Bleu_1": 0.15740740740594994, "Bleu_2": 0.12720876510715215, "Bleu_3": 0.09139015294606159, "Bleu_4": 0.0683372569086987, "METEOR": 0.1505677033505697, "ROUGE_L": 0.14064558629776022, "CIDEr": 1.2059655260151115e-56, "SPICE": {"All": {"pr": 0.1, "re": 0.08695652173913043, "f": 0.09302325581395349, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image features a group of four people riding horses in a field. The people are spread out across the field, with one person riding a horse in the middle, another person riding a horse closer to the left side, and a third person riding a horse on the right side.\n\nThere are four horses in the image. The horses are engaged in different activities, such as jumping, grazing, and riding. One horse is located in the middle of the field, another horse is closer to the left side, and the third horse is behind the rider.\n\nOverall, the image depicts people riding horses in a dirt field."}, "237869": {"image_id": 237869, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.06989787123302858, "Bleu_4": 9.090870283563952e-06, "METEOR": 0.20137532168702973, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.0466363690454173e-10, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.1935483870967742, "f": 0.2727272727272727, "fn": 25.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.06666666666666667, "f": 0.1111111111111111, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image features a stack of four colorful shopping bags. Each bag has a different design and size. The bags are placed on a table. The top bag is the largest and the bottom bag is the smallest. A clock is prominently displayed on the top of the stack, adding a unique touch."}, "323598": {"image_id": 323598, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.23262966005988533, "Bleu_3": 0.19323671068891465, "Bleu_4": 0.1489307483399702, "METEOR": 0.25391078379924276, "ROUGE_L": 0.32555036691127415, "CIDEr": 5.946668097838278e-09, "SPICE": {"All": {"pr": 0.39285714285714285, "re": 0.3548387096774194, "f": 0.3728813559322034, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 11.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.6363636363636364, "f": 0.6086956521739131, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image is a panoramic view of a large, modern bathroom with a wooden floor. The bathroom features a large tub, a toilet, and a sink. The tub is situated in the corner. The toilet is located in the bathroom. The sink is situated in the bathroom."}, "261948": {"image_id": 261948, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.22792115290866924, "Bleu_3": 1.3746108160529518e-06, "Bleu_4": 3.419372521783676e-09, "METEOR": 0.14085891105858592, "ROUGE_L": 0.2281795511221945, "CIDEr": 0.06756547022973151, "SPICE": {"All": {"pr": 0.21212121212121213, "re": 0.30434782608695654, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.75, "f": 0.5217391304347827, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image features a suitcase with a floral pattern. The suitcase is positioned on a stool. The floor is made of carpet."}, "438539": {"image_id": 438539, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 0.06474337870309639, "Bleu_4": 8.764094705114603e-06, "METEOR": 0.15610536948089765, "ROUGE_L": 0.19242902208201892, "CIDEr": 1.650040281788481e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.20833333333333334, "f": 0.1851851851851852, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image features a group of five people playing a game of frisbee in a grassy field. Some of the people are actively participating in the game, throwing and catching frisbees, while others are watching or waiting for their turn. One person is in the air, holding a frisbee."}, "204044": {"image_id": 204044, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.31072773312239654, "Bleu_3": 0.19034610712449662, "Bleu_4": 2.248107416659061e-05, "METEOR": 0.28310583259976113, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.006002897384081995, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image features a small, clean kitchen with wooden cabinets and a white stove. The sink is located on the left side of the kitchen. A window provides natural light."}, "142454": {"image_id": 142454, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.2296698215877162, "Bleu_3": 0.17898089669544753, "Bleu_4": 0.12634538413136023, "METEOR": 0.2621857493089951, "ROUGE_L": 0.44013637805264827, "CIDEr": 0.0005716387574178078, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image features two cats sitting on a bathroom sink. One cat is positioned on the left side of the sink, while the other cat is on the right side. They are looking at a mirror. They appear to be curious and attentive, possibly observing something above them."}, "239455": {"image_id": 239455, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.23546453742246556, "Bleu_3": 0.15461557958139502, "Bleu_4": 1.8894719111229462e-05, "METEOR": 0.2154165187887248, "ROUGE_L": 0.2713523131672598, "CIDEr": 0.0014731044005229857, "SPICE": {"All": {"pr": 0.25, "re": 0.35, "f": 0.2916666666666667, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image does not feature a harbor. There are four boats in the image. The boats are docked near a pier. The boats vary in size and are tied to the pier."}, "409725": {"image_id": 409725, "Bleu_1": 0.18840579709871877, "Bleu_2": 0.13926490730595353, "Bleu_3": 0.10500811418508206, "Bleu_4": 0.0769641822632844, "METEOR": 0.19259927797030854, "ROUGE_L": 0.21212121212121215, "CIDEr": 4.1769393626615436e-22, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.3076923076923077, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.8, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image captures a lively scene of a group of three people flying kites in a city park. Some of the people are talking on their cell phones, while others are holding up their kites. The kites are spread out across the scene, with six kites in total. The overall atmosphere of the scene is joyful and energetic, as the people enjoy their time flying kites in the park."}, "299493": {"image_id": 299493, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.1184508853673932, "Bleu_3": 6.683330244266766e-07, "Bleu_4": 1.5960821227040779e-09, "METEOR": 0.2101587137400264, "ROUGE_L": 0.20158625247851947, "CIDEr": 4.943618544699603e-10, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.2, "f": 0.27272727272727276, "fn": 24.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.38461538461538464, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image features two buses driving down a street. The buses are yellow and green. One of the buses is passing by a building with a blue roof. There are two cars parked or driving along the street. A sign is located on the left side of the bus."}, "460390": {"image_id": 460390, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.13206763594580717, "Bleu_3": 0.0746072740739093, "Bleu_4": 1.0032055246769756e-05, "METEOR": 0.17905981469378032, "ROUGE_L": 0.20890410958904113, "CIDEr": 1.9031711233034128e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.08695652173913043, "f": 0.11428571428571427, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image captures a ski slope with several skiers enjoying their time on the slopes. The skiers are skiing down a slope. Some of the skiers are skiing down the slopes of a mountain. The skiers are doing a slalom race on the lake."}, "473002": {"image_id": 473002, "Bleu_1": 0.2023809523785431, "Bleu_2": 0.16377292817084405, "Bleu_3": 0.08680940718259585, "Bleu_4": 9.47990178929218e-06, "METEOR": 0.19726331528132449, "ROUGE_L": 0.21682464454976302, "CIDEr": 4.959506100536238e-32, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2857142857142857, "f": 0.2162162162162162, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image features a young boy standing on a skateboard, likely in a park or a similar outdoor setting. He is wearing a black shirt and appears to be enjoying his time riding on the skateboard. \n\nThere are a total of ten people in the scene. Some of them are walking down the street, while others are riding a skateboard, eating a banana, playing a game of chess, or playing tennis. \n\nThe overall scene suggests that the boy is likely located in a park."}, "523470": {"image_id": 523470, "Bleu_1": 0.5454545454297521, "Bleu_2": 0.322329185595152, "Bleu_3": 0.21820586554493196, "Bleu_4": 0.15291898798206363, "METEOR": 0.32371816636103257, "ROUGE_L": 0.5392927308447937, "CIDEr": 0.22143062058456534, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.125, "f": 0.16326530612244897, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07142857142857142, "f": 0.11111111111111112, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image features a plate of food placed on a dining table. The meal consists of a meat skewer and a salad."}, "85944": {"image_id": 85944, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.1322214713349675, "Bleu_3": 0.06488455529243513, "Bleu_4": 8.114669979563551e-06, "METEOR": 0.15842434774630287, "ROUGE_L": 0.17888563049853376, "CIDEr": 8.823069389572637e-20, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.08695652173913043, "f": 0.1176470588235294, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image does not contain a woman. There is a counter in the image. There are two drinks on the counter. There are three groups of people in the image. There are eight people in the image. The people are drinking wine, taking pictures, standing at a bar, eating, playing a game, and eating a pizza. \n\nThe image does not contain a bar or a shirt."}, "258523": {"image_id": 258523, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.17070350164878656, "Bleu_3": 0.08651487447770963, "Bleu_4": 1.1014249684706096e-05, "METEOR": 0.2447928003534432, "ROUGE_L": 0.27180140038192235, "CIDEr": 7.19997232285006e-09, "SPICE": {"All": {"pr": 0.1891891891891892, "re": 0.4117647058823529, "f": 0.2592592592592593, "fn": 10.0, "numImages": 1.0, "fp": 30.0, "tp": 7.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.2, "f": 0.1, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image features a black cat lying on a toilet seat. The cat is comfortably resting on the white porcelain surface. The cat appears to be enjoying its time on the toilet, possibly seeking warmth or a unique vantage point.\n\nThere is no sink in the scene."}}}