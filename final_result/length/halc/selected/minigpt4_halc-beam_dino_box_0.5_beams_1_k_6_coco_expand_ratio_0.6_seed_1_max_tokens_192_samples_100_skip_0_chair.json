{"overall": {"Bleu_1": 0.12582159624411965, "Bleu_2": 0.08345208799694041, "Bleu_3": 0.052646928977786715, "Bleu_4": 0.032687709022549576, "METEOR": 0.14799949088758246, "ROUGE_L": 0.17796846554165757, "CIDEr": 0.0037936524216473063, "SPICE": 0.1598649492600228}, "imgToEval": {"281533": {"image_id": 281533, "Bleu_1": 0.12080536912670602, "Bleu_2": 0.07558946658534474, "Bleu_3": 0.053771861657963486, "Bleu_4": 0.04227741297056054, "METEOR": 0.15325280121818513, "ROUGE_L": 0.1493268053855569, "CIDEr": 2.945425291747407e-110, "SPICE": {"All": {"pr": 0.1320754716981132, "re": 0.3181818181818182, "f": 0.18666666666666665, "fn": 15.0, "numImages": 1.0, "fp": 46.0, "tp": 7.0}, "Relation": {"pr": 0.043478260869565216, "re": 0.09090909090909091, "f": 0.0588235294117647, "fn": 10.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3157894736842105, "re": 0.6666666666666666, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}}, "caption": "The image shows a brown and white dog sitting in front of a television. The dog is looking at the television with its head tilted to the side. The television is showing a blue screen with white text on it. The room is decorated with a brown and white rug, a brown couch, and a brown coffee The dog is wearing a brown collar with a tag on it. The room has a window with a view of the outdoors.\n\nThe image shows a brown and white dog sitting in front of a television. The dog is looking at the television with its head tilted to the side. The television is showing a blue screen with white on it. The room is decorated with a brown and white rug, a brown and a brown. The dog is wearing a brown with a tag on it. The room has a"}, "397773": {"image_id": 397773, "Bleu_1": 0.1304347826072779, "Bleu_2": 0.0757191986065591, "Bleu_3": 0.050319135129221586, "Bleu_4": 0.03459014434374488, "METEOR": 0.1691349033423239, "ROUGE_L": 0.16272865853658539, "CIDEr": 2.8564591413791326e-40, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.19230769230769232, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a bowl of pasta with broccoli and sausage. The pasta is cooked and has a golden brown color. The meat is cooked and has a brown color. The broccoli is cooked and has a green color. The cheese is shredded and has a yellow color. The sauce is a creamy white color. The bowl is made of ceramic and has a white and brown design. The table is made of wood and has a white and brown design. The lighting is bright and the background is a white wall."}, "371250": {"image_id": 371250, "Bleu_1": 0.11999999999880001, "Bleu_2": 0.04923659639123825, "Bleu_3": 2.913734595418572e-07, "Bleu_4": 7.106316715359211e-10, "METEOR": 0.1190753351787174, "ROUGE_L": 0.14707908514742354, "CIDEr": 9.000871617401882e-47, "SPICE": {"All": {"pr": 0.10869565217391304, "re": 0.2, "f": 0.14084507042253522, "fn": 20.0, "numImages": 1.0, "fp": 41.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee The couch is brown and has two pillows on it. The coffee are on the coffees. The walls are painted a light brown color. There is a table in the corner of the room with a on it. The room is well lit by a large window.\n\nThe couch is brown and has two pillows on it. The coffee are on thes. The walls are painted a light brown color. There is a in the of the room with a on it. The room is well lit by a large window."}, "573877": {"image_id": 573877, "Bleu_1": 0.0961538461532298, "Bleu_2": 0.06589713014791122, "Bleu_3": 0.048315976089914704, "Bleu_4": 0.034845982121935994, "METEOR": 0.16373250279775733, "ROUGE_L": 0.1511261261261261, "CIDEr": 8.509504670358767e-121, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2727272727272727, "f": 0.19672131147540986, "fn": 16.0, "numImages": 1.0, "fp": 33.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The cat is sitting on the laptop, looking at the screen.\n\nThe laptop is open and the cat is looking at the screen. The laptop is on a desk in front of a\nwindow. The cat is white and has blue eyes. The cat is sitting on the laptop and looking at the screen.\n\nThe laptop is open and the cat is looking at the screen. The laptop is on a desk in front of a window. The cat is white and has blue eyes. The cat is sitting on the laptop and looking at the screen.\n\nThe laptop is open and the cat is looking at the screen. The laptop is on a desk in front of a window. The cat is white and has blue eyes. The cat is sitting on the laptop and looking at the screen.\n\nThe laptop is open and the cat is looking at the screen. The laptop is on"}, "181859": {"image_id": 181859, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.2431322695333988, "Bleu_3": 1.2984955969042475e-06, "Bleu_4": 3.0292633045111215e-09, "METEOR": 0.18691108540950052, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.002790427534401154, "SPICE": {"All": {"pr": 0.25, "re": 0.15789473684210525, "f": 0.1935483870967742, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image is of a cat lying on a bed in a bathroom. The cat is on its back with its paws tucked under its body. The cat's"}, "119939": {"image_id": 119939, "Bleu_1": 0.07586206896499408, "Bleu_2": 0.039754996794026644, "Bleu_3": 0.02227490203524774, "Bleu_4": 2.9702278502616912e-06, "METEOR": 0.07715736040609138, "ROUGE_L": 0.0911854103343465, "CIDEr": 4.565107175834903e-109, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.38461538461538464, "f": 0.22727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on the sidewalk in front of a building. They are all wearing black and white clothing and have their skateboards with them. The building is a large, modern structure with large windows and a large sign on the The building is a large, modern structure with large windows and a large sign on the side. The people are standing on the sidewalk in front of the building, looking at their skateboards. The sky is clear and blue.\n\nThe image shows a group of people standing on the of a building. They are all wearing black and white clothing and have their skateboards with them. The building is a large, modern structure with large windows and a large sign on the side. The people are standing on the sidewalk in front of the building, looking at their skateboards"}, "385320": {"image_id": 385320, "Bleu_1": 0.305555555547068, "Bleu_2": 0.20892772350344985, "Bleu_3": 0.10868536689063704, "Bleu_4": 1.4044291074781953e-05, "METEOR": 0.23866103143481893, "ROUGE_L": 0.32348484848484854, "CIDEr": 0.00012545819755601894, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2857142857142857, "f": 0.2033898305084746, "fn": 15.0, "numImages": 1.0, "fp": 32.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.8, "f": 0.3478260869565218, "fn": 1.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image shows a young girl sitting on a couch, holding a toy mouse in her mouth. She is wearing a striped shirt and white shorts. The room appears to be a living room with a"}, "490415": {"image_id": 490415, "Bleu_1": 0.07643312101862146, "Bleu_2": 0.058563566555809, "Bleu_3": 0.03537130726588782, "Bleu_4": 4.117258672280374e-06, "METEOR": 0.14472660569969434, "ROUGE_L": 0.1148505530713109, "CIDEr": 1.2897601320189856e-128, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.06896551724137931, "f": 0.06896551724137931, "fn": 27.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man standing in a park, holding a camera and looking up at a a k k flying in the sky. The man is wearing a black shirt and jeans, and has a the The sky is blue and there are clouds in the background. The grass is green and there are trees in the distance. The man is standing on a hill, and there is a baseball field in the background. The image is taken from a low angle, and the camera is pointed up at the kite. The image is in black and white.\n\nThe image shows a man standing in a holding a camera and looking up at a kite flying in the sky. The man is wearing a black shirt and jeans, and has a back back. The sky is blue and there are clouds in the background. The grass is green and there are in the distance. The man"}, "432293": {"image_id": 432293, "Bleu_1": 0.06666666666617285, "Bleu_2": 0.0546358364704091, "Bleu_3": 0.0282077113387703, "Bleu_4": 3.6110408813572215e-06, "METEOR": 0.10507148906631528, "ROUGE_L": 0.11432396251673357, "CIDEr": 6.450899474078839e-95, "SPICE": {"All": {"pr": 0.11904761904761904, "re": 0.2, "f": 0.1492537313432836, "fn": 20.0, "numImages": 1.0, "fp": 37.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "The image shows a pizza on a wooden cutting board with various toppings such as shrimp, tomatoes, and lettuce. The pizza is being prepared on a wooden cutting board with various toppings such as shrimp, tomatoes, and che lettuce. The\n\npizza is being prepared on a wooden cutting board with various toppings such as shrimp, tomatoes, and che lettuce. The pizza is being prepared on a wooden cutting board with various toppings such as shrimp, tomatoes, and che lettuce. The pizza is being prepared on a wooden cutting board with various toppings such as shrimp, tomatoes, and che lettuce. The pizza is being prepared on a wooden cutting board with various toppings such as shrimp, tomatoes, and che lettuce. The pizza is being prepared on a wooden cutting board with various toppings such as shrimp,"}, "256301": {"image_id": 256301, "Bleu_1": 0.10596026489996054, "Bleu_2": 0.059430706120448706, "Bleu_3": 0.02872622144685631, "Bleu_4": 3.557488044192255e-06, "METEOR": 0.10655913186326697, "ROUGE_L": 0.11656713871353011, "CIDEr": 1.0331829150396128e-110, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.20689655172413793, "f": 0.2142857142857143, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a large red and white sign with the words \"public market\" written on it. The sign is mounted on a tall The sign is mounted on a tallpole and is surrounded by a crowd of people. Thesign is a large red and white sign with the words \"public market market\" written on it. The sign is mounted on a tall pole and is surrounded by a crowd ofpeople. The sign is a large red and white sign with thewords \"public market\" written on it. The sign is mounted on a tallpole and is surrounded by a crowd of\n\n\nThe image shows a large red and white sign with the words \"public market\" written on it. The sign is mounted on a tall pole and is surrounded by a crowd of The sign is a large red and white sign with the \"public market\" written on it. The sign"}, "361103": {"image_id": 361103, "Bleu_1": 0.07894736842053326, "Bleu_2": 0.056008762944944, "Bleu_3": 0.03973568025149733, "Bleu_4": 0.025473517713048177, "METEOR": 0.10913470010993077, "ROUGE_L": 0.12121881209980129, "CIDEr": 9.75735652931459e-106, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08695652173913043, "f": 0.10526315789473685, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man standing on the sidewalk looking at his The image shows a man standing on the sidewalk looking at his phone. The man is wearing a black suit and a white and a black tie. He is standing in front of a building with a large red and white sign that reads'The' on it. The building is a large tall building with many windows and a large red and white sign that reads'The' on it. The is a large tall building with many windows and a large red and white sign that reads'The' on it. The building is a large tall building with many windows and a large red and white sign that on it. The building is a large tall building with many windows and a large red and white sign that reads'The on it. The building is a large tall building with"}, "567562": {"image_id": 567562, "Bleu_1": 0.10273972602669358, "Bleu_2": 0.059520997751296385, "Bleu_3": 0.03664397990514656, "Bleu_4": 0.02421965585763439, "METEOR": 0.1543179257823999, "ROUGE_L": 0.11747713047664901, "CIDEr": 1.211540299201572e-105, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.19047619047619047, "f": 0.17777777777777778, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table eating pizza and drinking soda. There are two women and two men in the image, all of whom are wearing The are sitting in a dining room with a wooden table and chairs. The walls are painted a light blue color and there are some books on the shelves. The floor is made of hardwood and there is a rug in the center of the room. The lighting is from overhead and there are no windows in the room.\n\nThe image is taken from a low angle, looking down at the group of sitting around the table. The are all facing the and are looking at each other. The are all smiling and appear to be enjoying their\n\nThe image is in format, with a resolution of 72 and a frame rate of 30 f"}, "448320": {"image_id": 448320, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.31814238147962415, "Bleu_3": 0.23915003304404414, "Bleu_4": 0.139613433798816, "METEOR": 0.2842018223803625, "ROUGE_L": 0.400437636761488, "CIDEr": 0.00014246247132948127, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.14285714285714285, "f": 0.13114754098360656, "fn": 24.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image is of a bathroom with a to the left and a toilet to the right. The sink has a faucet and a mirror above it. The toilet has a seat and a lid. There is a wooden"}, "14874": {"image_id": 14874, "Bleu_1": 0.12871287128585435, "Bleu_2": 0.09492049825996336, "Bleu_3": 0.07140274998950866, "Bleu_4": 0.043901532922200656, "METEOR": 0.17179827221105282, "ROUGE_L": 0.16503212715590124, "CIDEr": 2.010185160672646e-49, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.15789473684210525, "f": 0.12000000000000001, "fn": 16.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a person standing in the snow with skis on their Hinweis: The image shows a person standing in the snow with skis on their\n\nThe person is wearing a blue jacket, black pants, and black ski They have a pair of goggles on their face and are holding a pair of skis in their hands. The skis are red and black and have a pair of bindings on them. The person is standing in front of a mountain with a snow covered peak in the background. The sky is blue and there are some clouds in the distance."}, "373713": {"image_id": 373713, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.1693335026642112, "Bleu_3": 0.11213961682443137, "Bleu_4": 0.08280164924731272, "METEOR": 0.17221762641081306, "ROUGE_L": 0.21863799283154117, "CIDEr": 2.0022477432285216e-17, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table in a conference room. They are all wearing black shirts and black pants. One of them is holding a\n\nboard with a white screen on it. The other two are typing on their laptops. The room is dimly lit and there are no windows. The walls are painted a light gray color."}, "539326": {"image_id": 539326, "Bleu_1": 0.08593749999932863, "Bleu_2": 0.07803883043089883, "Bleu_3": 0.06619127343202356, "Bleu_4": 0.05519351422394683, "METEOR": 0.1985254975055057, "ROUGE_L": 0.13847900113507378, "CIDEr": 2.368214454430281e-86, "SPICE": {"All": {"pr": 0.06976744186046512, "re": 0.21428571428571427, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 40.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.5, "f": 0.2727272727272727, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a group of cows grazing in a green field. The\n\nThe image shows a herd of grazing in a green field. The cows are brown and white and have long, curved horns. They are standing in a row, eating grass and looking up at the sky. In the background, there is a a blue sky with some white clouds. The field is surrounded by tall, greengrass and some trees in the distance.\n\nThe image is taken from a bird's eye view, looking down on the the field. The lighting is bright and clear, and the the colors are vivid.\n\nThe image is taken in the, and the camera is positioned on a hill overlooking the field. The lighting is soft and warm, and the"}, "20059": {"image_id": 20059, "Bleu_1": 0.18571428571163268, "Bleu_2": 0.11600671073446796, "Bleu_3": 0.07342248901273177, "Bleu_4": 8.767042795566411e-06, "METEOR": 0.1823136398074738, "ROUGE_L": 0.20588235294117646, "CIDEr": 7.188577331483318e-23, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.12903225806451613, "f": 0.16326530612244897, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a group of zebras grazing in a green field. The zebras are standing in a, with their heads down and their ears up. They are wearing black and white stripes on their backs. The sun is shining down on them, casting a warm glow over the scene. The grass is green and lush, and there are some trees in the background. The sky is blue and cloudy."}, "530520": {"image_id": 530520, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.17736390622619813, "Bleu_3": 0.13097874297652884, "Bleu_4": 0.07994843029011257, "METEOR": 0.17540556358736265, "ROUGE_L": 0.20631341600901915, "CIDEr": 3.44129353706923e-15, "SPICE": {"All": {"pr": 0.05714285714285714, "re": 0.08333333333333333, "f": 0.06779661016949153, "fn": 22.0, "numImages": 1.0, "fp": 33.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting on the grass outside a building, using laptops and drinking coffee. They are all wearing They are all wearing and white shirts. The building in the background is a a building with a large window on the top floor. The sky is blue and there are trees in the background."}, "117337": {"image_id": 117337, "Bleu_1": 0.07006369426706967, "Bleu_2": 0.051911053464489605, "Bleu_3": 0.037362541787170654, "Bleu_4": 0.02412387836897836, "METEOR": 0.08195536167089207, "ROUGE_L": 0.08570224324450895, "CIDEr": 3.1507939777293155e-124, "SPICE": {"All": {"pr": 0.08771929824561403, "re": 0.23809523809523808, "f": 0.1282051282051282, "fn": 16.0, "numImages": 1.0, "fp": 52.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 21.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.8333333333333334, "f": 0.3846153846153846, "fn": 1.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "This is a collage of images that show different.\n\nThe first image is a collage of images that show different shades of orange and blue. The second image is a collage of images that show different shades of orange and blue. The third image is a collage of images that show different shades of orange and blue. The fourth image is a collage of images that show different shades of orange and blue. The fifth image is a collage of images that show different shades of orange and blue. The sixth image is a collage of images that show different shades of orange and blue. The seventh image is a collage of images that show different shades of orange and blue. The eighth image is a collage of images that show different shades of orange and blue. The ninth image is a collage of images that show different shades of orange and blue. The tenth image is"}, "256504": {"image_id": 256504, "Bleu_1": 0.09722222222154708, "Bleu_2": 0.06898644619824557, "Bleu_3": 0.05858640066744169, "Bleu_4": 0.04887174349248429, "METEOR": 0.12740111877967059, "ROUGE_L": 0.12323232323232322, "CIDEr": 8.671274218739723e-110, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13793103448275862, "f": 0.12307692307692307, "fn": 25.0, "numImages": 1.0, "fp": 32.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows two people sitting on a bed with laptops in The image shows two they are both wearing pajamas and have a laptop on their laps. The laptop are both open and they are both looking at the screen. The room is dimly lit and there is a large tapestry on the wall.\n\nThe image is taken at night and the lighting is is dim. The room is decorated with a tapestry on the wall and there are two people sitting on a bed with laptops on their laps. The laptops are both open and they are both looking at the screen. The room is dimly lit and there is a large on the wall.\n\nThe image is taken at night and the lighting is dim. The room is decorated with a on the wall and there are two sitting on a"}, "265472": {"image_id": 265472, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.23891934293536143, "Bleu_3": 0.2118932510457333, "Bleu_4": 0.1845586395388077, "METEOR": 0.3387783896090854, "ROUGE_L": 0.38553370786516855, "CIDEr": 1.1510635280192331e-07, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.2777777777777778, "f": 0.3448275862068966, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.8, "re": 0.6666666666666666, "f": 0.7272727272727272, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a plate of French toast with bacon, bananas, and maple syrup. The plate is on a wooden cutting board with a white background. The bacon is cooked and crispy, while the bananas are sliced and placed on top of the French"}, "441083": {"image_id": 441083, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.18812283124541943, "Bleu_3": 8.581535337000927e-07, "Bleu_4": 1.8411241471139253e-09, "METEOR": 0.1762294284770835, "ROUGE_L": 0.2544316996871741, "CIDEr": 1.43268686642064e-12, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08333333333333333, "f": 0.0930232558139535, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a dog sitting in the back of a car with its tongue hanging out of its mouth. The dog is wearing a chain around its neck. The car is parked on the side of the road with other cars passing by in the background. The sky is blue and there are trees in the background."}, "126958": {"image_id": 126958, "Bleu_1": 0.11940298507373581, "Bleu_2": 0.08474747453742479, "Bleu_3": 0.0378930764770509, "Bleu_4": 4.514421190851538e-06, "METEOR": 0.14174895949266433, "ROUGE_L": 0.12903225806451613, "CIDEr": 4.332512660258194e-86, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.17391304347826086, "f": 0.11940298507462685, "fn": 19.0, "numImages": 1.0, "fp": 40.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.13636363636363635, "re": 0.3333333333333333, "f": 0.1935483870967742, "fn": 6.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}}, "caption": "The image shows a room with a blue wall, a white ceiling, and a white wooden door. There is a mirror on the wall opposite the door. The room has a window with a view of the sky. The the room has a white wooden bed with a white, wooden headboard. There is a white, wooden on the wall opposite the bed. The room has a white, wooden dresser with a white, wooden drawers. There is a white, wooden chair in the corner of the room. The room has a white, wooden coffee on the table. The room has a white, wooden lamp on the. The room has a white, woodenMir on the wall. The room has a White, WoodenMir on the wall. The room has a White, on the wall. The room has"}, "484075": {"image_id": 484075, "Bleu_1": 0.19277108433502685, "Bleu_2": 0.13713837922640926, "Bleu_3": 0.0975658125434085, "Bleu_4": 0.058371486405853525, "METEOR": 0.20011176334516528, "ROUGE_L": 0.26017836370686315, "CIDEr": 3.753477083033895e-30, "SPICE": {"All": {"pr": 0.0975609756097561, "re": 0.21052631578947367, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 37.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.5, "f": 0.13333333333333336, "fn": 1.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image is of a cluttered desk with a computer, keyboard, mouse, and other office.\n\nThe has a wooden top and metal legs. The computer is on the left side of the desk and the keyboard and mouse are on the right side. There are several books and papers on the desk. The computer screen is showing a black screen with white text. The room is dimly lit and there are several other objects on the desk, including a and a small lamp."}, "274528": {"image_id": 274528, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.23546453742246556, "Bleu_3": 0.15461557958139502, "Bleu_4": 1.8894719111229462e-05, "METEOR": 0.16634243981178679, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.0007121080817998129, "SPICE": {"All": {"pr": 0.0851063829787234, "re": 0.14285714285714285, "f": 0.10666666666666665, "fn": 24.0, "numImages": 1.0, "fp": 43.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.36363636363636365, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a truck with a banner on it. The banner reads, \"The Tour de France 2013.\" There are several bicycles parked in"}, "286820": {"image_id": 286820, "Bleu_1": 0.08888888888823047, "Bleu_2": 0.04460997367421539, "Bleu_3": 0.024641705580470324, "Bleu_4": 3.2629437755114455e-06, "METEOR": 0.0776844070961718, "ROUGE_L": 0.06661206661206662, "CIDEr": 1.3179508785024417e-96, "SPICE": {"All": {"pr": 0.125, "re": 0.13333333333333333, "f": 0.12903225806451615, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows two white iphones on a green background. The iphones are placed on a table with a white tablecloth. The iphones are in different one is on the left and the other is on the right. The iphones have different features such as a and a screen. The iphones are in good condition.\n\nThe image shows two white iphones on a green car background. The iphones are placed on a table with a white tablecloth. The iphones are in different one is on the left and the other is on the right. The i iphones have different features such as a screen and a camera. The iphones are in good condition.\n\nThe image shows two white iphones on a green car background. The iphones are placed on a table with a white tablecloth"}, "69236": {"image_id": 69236, "Bleu_1": 0.04487179487150724, "Bleu_2": 5.380478145871889e-10, "Bleu_3": 1.234166273766769e-12, "Bleu_4": 5.920486538032107e-14, "METEOR": 0.08198630136986301, "ROUGE_L": 0.05727699530516432, "CIDEr": 1.2814392969688491e-129, "SPICE": {"All": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a bench in the middle of a, with a view of the surrounding The bench is made of metal and has a backrest. The is a of the bench, with a view of the surrounding The bench is in the middle of a with a view of the surrounding. The bench is made of with a view of the surrounding. The bench is in the middle of a with a view of the surrounding. The bench is made of with a view of the surrounding. The bench is in the middle of a with a view of the surrounding. The bench is made of with a view of the surrounding. The bench is in the middle of a with a view of the surrounding. The bench is made of with a view of the surrounding. The bench is in the middle of a with a view of the surrounding. The bench is made"}, "333237": {"image_id": 333237, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.26967994497923586, "Bleu_3": 0.17183700724794354, "Bleu_4": 0.10483956314820705, "METEOR": 0.2537977401122923, "ROUGE_L": 0.3370165745856354, "CIDEr": 5.45121425607183e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a bedroom with a white bedspread and white curtains. There is a dresser in the corner of the room and a mirror on the. The walls are painted red and there are red and white stripedpaper. The floor is made of wood."}, "285258": {"image_id": 285258, "Bleu_1": 0.0992907801411398, "Bleu_2": 0.06523280730487993, "Bleu_3": 0.03128281160005802, "Bleu_4": 3.8593090934489905e-06, "METEOR": 0.13580969748394295, "ROUGE_L": 0.12561132561132562, "CIDEr": 3.0409853916906315e-104, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.17857142857142858, "f": 0.17543859649122806, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of dogs playing in a grassy area. The dogs are of different breeds and sizes, and they are all wearing collars and leashes. The dogs are standing in a line, with their Hinweis: The image shows a group of dogs playing in a grassy area. The dogs are of different breeds and sizes, and they are all wearing and leashes. The dogs are standing in a line, with their tails wagging. The dogs are all looking at each other and barking. The dogs are in a fenced in area, with a fence in the background. The dogs are all wearing collars and leashes. The dogs are standing in a and looking at each other. The dogs are all barking and wagging theirs. The dogs are in a fenced in area, with a fence in the background"}, "574454": {"image_id": 574454, "Bleu_1": 0.08450704225292603, "Bleu_2": 0.04896287267690925, "Bleu_3": 0.032474707403021386, "Bleu_4": 0.022279489478654817, "METEOR": 0.0713498274727522, "ROUGE_L": 0.09395215114488141, "CIDEr": 3.375508254596787e-106, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.2631578947368421, "f": 0.18181818181818182, "fn": 14.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.14285714285714285, "f": 0.09090909090909091, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5714285714285714, "f": 0.34782608695652173, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a group of people on the beach, with a windsurfer in the Hinweis: The image shows a group of people on the beach, with a windsurfer in the of the image. The are standing on the sand, with the mountains in the background. The sky is clear and blue, with a few clouds in the distance. The water is calm and clear, with a few waves breaking on the shore. The people are wearing beachwear and sunglasses, and one of them is holding a surfboard. The image is taken from a low angle, with the the beach and the mountains in the background. The lighting is bright and sunny, with the and the shadows of the on the sand. The image is taken in the, with the windsurfer in the of the image. The image is taken in the"}, "57703": {"image_id": 57703, "Bleu_1": 0.11382113821045675, "Bleu_2": 0.09163318909284739, "Bleu_3": 0.06523190695879676, "Bleu_4": 0.04637749031546204, "METEOR": 0.145617564852154, "ROUGE_L": 0.14357163871726983, "CIDEr": 4.439532912788402e-75, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.26666666666666666, "f": 0.18604651162790697, "fn": 11.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in a forest with their dogs. They are all wearing hiking and carrying backpacks. The dogs are all wearing and leashes. The are standing in a clearing surrounded by of.\n\nThe image shows a group of people standing in a forest with their dogs. They are all wearing hiking boots and carrying backpacks. The dogs are all wearing leashes. They are standing in a clearing surrounded by of Ms.\n\nThe image shows a group of people standing in a forest with their dogs. They are all wearing hiking and carrying backpacks. The dogs are all wearing leashes. They are standing in a clearing surrounded by Ms.\n\nThe image shows a group of people standing in"}, "70294": {"image_id": 70294, "Bleu_1": 0.06832298136603528, "Bleu_2": 0.058447832023783515, "Bleu_3": 0.035025947705939364, "Bleu_4": 4.060954742110124e-06, "METEOR": 0.1372472005362535, "ROUGE_L": 0.12317702490464438, "CIDEr": 1.6539491932354582e-132, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.24, "f": 0.2608695652173913, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a blue bus parked on the side of a The bus is parked on the side of a road with a building in the background. The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has a large windshield and a small front The bus has"}, "279769": {"image_id": 279769, "Bleu_1": 0.05517241379272297, "Bleu_2": 0.019574007317021337, "Bleu_3": 1.3889112161288536e-07, "Bleu_4": 3.706242037759639e-10, "METEOR": 0.04995306643482409, "ROUGE_L": 0.07585177816463566, "CIDEr": 5.202751897033296e-111, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.375, "f": 0.2181818181818182, "fn": 10.0, "numImages": 1.0, "fp": 33.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.5, "f": 0.15384615384615385, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 1.0, "f": 0.5263157894736842, "fn": 0.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a close to the edge of a tablecloth. The tablecloth is white and has a is a pattern of small, white dots on it. The tablecloth is also white and has a pattern of small, white on it. The ban is yellow and has a black spot on it. The tablecloth is white and has a pattern of small, white on it. The ban is yellow and has apot on it. The tablecloth is white and has a a pattern of small, white on it. The ban is yellow and has a black spot on it. The tablecloth is white and has a a pattern of small, white on it. The ban is yellow and has a blackpot on it. The tablecloth is white and has a a pattern of small, white d on it. The ban is yellow and has a"}, "541474": {"image_id": 541474, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.12262786789482262, "Bleu_3": 0.06490406357826438, "Bleu_4": 8.435396018679067e-06, "METEOR": 0.17812239363326418, "ROUGE_L": 0.20670958996950187, "CIDEr": 1.6099075740699923e-14, "SPICE": {"All": {"pr": 0.20588235294117646, "re": 0.30434782608695654, "f": 0.2456140350877193, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6666666666666666, "f": 0.4800000000000001, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "The image shows a person skiing down a snowy slope. The person is wearing a blue jacket and black pants, and has a black helmet on their\nhead. They are holding onto a white skis and are moving down the slope at a high speed. The sky is blue and there are some clouds in the background."}, "217561": {"image_id": 217561, "Bleu_1": 0.09395973154299357, "Bleu_2": 0.050392977723563166, "Bleu_3": 0.02585081479027576, "Bleu_4": 3.2981276704488754e-06, "METEOR": 0.11344911480902273, "ROUGE_L": 0.11946144430844552, "CIDEr": 6.324700846346726e-114, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17857142857142858, "f": 0.17241379310344826, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Size": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a toothbrush and toothpaste on a plate. There are also several forks and spoons on the table. The table is covered with a white tablecloth. There are several plates and cups on the table. The room is decorated with white and There are several chairs around the table. The room is decorated with white and gold and there are several chairs around the table. The room is decorated with white and and there are several chairs around the table. The room is decorated with white and gold and there are several around the table. The room is decorated with white and and there are several chairs around the table. The room is decorated with white and and there are several around the table. The room is decorated with white and and there are several around the table. The room is decorated with white and and there"}, "303778": {"image_id": 303778, "Bleu_1": 0.07692307692253902, "Bleu_2": 0.057011146768496446, "Bleu_3": 0.02845990724642372, "Bleu_4": 3.582144503966414e-06, "METEOR": 0.15624496980181904, "ROUGE_L": 0.1085133418043202, "CIDEr": 7.094272330269172e-108, "SPICE": {"All": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a baseball player in a white uniform with a bat in his hand, walking towards theout. The player is wearing a helmet and has a glove on his left hand. The player is wearing a helmet and has a glove on his left hand. The player is wearing a helmet and has a glove on his left hand. The dirt in the background is dark and there are some small rocks on the ground.\n\nThe image is in black and white and has a grainy texture. The player is walking towards the dugout, which is in the background. The dugout is made of The player is walking towards the dugout, which is in the background. The are made of wood and have a smallroof on top. The dugout is surrounded by a white fence.\n\nThe image is in black and"}, "40426": {"image_id": 40426, "Bleu_1": 0.07692307692258385, "Bleu_2": 0.04981354813835146, "Bleu_3": 0.031822532807310136, "Bleu_4": 3.8095896614509506e-06, "METEOR": 0.09788328195042591, "ROUGE_L": 0.11265004616805173, "CIDEr": 1.1996026076761713e-124, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.32142857142857145, "f": 0.3673469387755102, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 9.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a blender with a bowl of strawberries and a spoon on top of it. There is also a plate of food on the counter next to the blender. The blender is black and has a digital The blender is black and has a digital the blender is black and has a digital display on the front. The display shows the and the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black and has a digital the blender is black"}, "324291": {"image_id": 324291, "Bleu_1": 0.1118421052624221, "Bleu_2": 0.06085541035051731, "Bleu_3": 0.03668701486549375, "Bleu_4": 0.02399317461386875, "METEOR": 0.13085552961782995, "ROUGE_L": 0.11531190926275992, "CIDEr": 3.462479205784427e-115, "SPICE": {"All": {"pr": 0.06976744186046512, "re": 0.13636363636363635, "f": 0.09230769230769229, "fn": 19.0, "numImages": 1.0, "fp": 40.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 18.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a man and a woman riding on the back of a horse in a green field. The man is wearing a white, the woman is wearing a black and the horse is wearing a brown saddle. The horse is grazing in the field and the man and woman are holding onto the reins. There are trees in the background and a blue sky.\n\nThe image is taken from a bird's eye view, so it is possible to see the entire field and the people and the horse in detail. The lighting is bright and clear, so it is possible to see the details of the horse's saddle and the people's\n\nThe image is taken in the, so the lighting is bright and clear. The image is taken from a bird's eye view, so it is possible to see the entire field and the people and"}, "96241": {"image_id": 96241, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.12712834523041283, "Bleu_3": 0.06730845772977347, "Bleu_4": 8.750873255009596e-06, "METEOR": 0.24539833359313076, "ROUGE_L": 0.24110671936758893, "CIDEr": 1.7918199898227235e-12, "SPICE": {"All": {"pr": 0.125, "re": 0.06666666666666667, "f": 0.08695652173913045, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of people standing next to a train that is parked on the tracks. The train is black and has a number on the side. There are a few people standing next to the train, looking at it. The image is taken from a low angle, looking down at the train."}, "326911": {"image_id": 326911, "Bleu_1": 0.12162162161997811, "Bleu_2": 0.08163454198339706, "Bleu_3": 0.06523974072376104, "Bleu_4": 0.05288433912709082, "METEOR": 0.17213321153957672, "ROUGE_L": 0.19011576135351735, "CIDEr": 2.3647969786738073e-25, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 22.0, "numImages": 1.0, "fp": 32.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}}, "caption": "The image shows a black and white cat sitting on the sidewalk next to a bicycle. The cat is looking at the camera. The bicycle is parked on the sidewalk. The image is taken in a residential area with a few trees and buildings in the background. The lighting is natural, with the The sun is shining down on the scene. The cat is wearing a and the bicycle has a bell on it."}, "209222": {"image_id": 209222, "Bleu_1": 0.16842105262980608, "Bleu_2": 0.13385489628063443, "Bleu_3": 0.11048276597053724, "Bleu_4": 0.08750622417878115, "METEOR": 0.20320466801842774, "ROUGE_L": 0.18080770655798445, "CIDEr": 4.909523332900281e-44, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.3157894736842105, "f": 0.19672131147540983, "fn": 13.0, "numImages": 1.0, "fp": 36.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.1111111111111111, "re": 1.0, "f": 0.19999999999999998, "fn": 0.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Object": {"pr": 0.3125, "re": 0.7142857142857143, "f": 0.43478260869565216, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a man sitting on a bench in the middle of a The image shows a man sitting on a bench in the middle of a city square. The man is wearing a black and a black hat. He is sitting on the bench with his back to the camera. The bench is made of wood and has a small shadow of a tree on it. The square is surrounded by tall buildings on all sides. There are people walking on the sidewalks and cars driving by. The are in black and white."}, "362293": {"image_id": 362293, "Bleu_1": 0.11805555555473574, "Bleu_2": 0.09953270772274728, "Bleu_3": 0.06534832018332137, "Bleu_4": 0.0375077526244884, "METEOR": 0.15261011566208482, "ROUGE_L": 0.135706340378198, "CIDEr": 1.1881011411933668e-100, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.26666666666666666, "f": 0.1568627450980392, "fn": 11.0, "numImages": 1.0, "fp": 32.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a horse and carriage on a street in a city. The horse is pulling a carriage with two people inside. The carriage is decorated with flowers and ribbons. The street is lined with buildings on either side. There are cars parked on the side of the street. The sky is blue and there are trees in the background.\n\nThe image is taken from a high showing the street and the buildings and cars in the background. The lighting is bright and the colors are vivid. The image is in focus and the details are clear.\n\nThe image is taken in the city. The street is lined with buildings on either side. There are cars parked on the side of the street. The sky is blue and there are trees in the background.\n\nThe image shows a horse and carriage on a"}, "144481": {"image_id": 144481, "Bleu_1": 0.07317073170687093, "Bleu_2": 0.036697419303730064, "Bleu_3": 2.0257476538199417e-07, "Bleu_4": 4.766861561934565e-10, "METEOR": 0.08041039699810944, "ROUGE_L": 0.08206278026905829, "CIDEr": 1.7580352306495188e-143, "SPICE": {"All": {"pr": 0.125, "re": 0.18181818181818182, "f": 0.14814814814814814, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image is of a group of vases on a blue background. The vases are made of black and have a red and white design on them. They are placed on a table in front of a large\n\nThe image is of a group of vases on a blue background. The v vases are made of black and have a red and white design on them. They are placed on a table in front of a large\n\nThe image is of a group of vases on a blue background. The v vases are made of black and have a red and white design on them. They are placed on a table in front of a large\n\nThe image is of a group of vases on a blue background. The v vases are made of black and have a red and white design on them. They are placed on a table in\n\nThe image is of a group of v vases on a blue background."}, "433804": {"image_id": 433804, "Bleu_1": 0.10489510489437139, "Bleu_2": 0.06657467634706815, "Bleu_3": 0.031559710081526846, "Bleu_4": 3.87095163217433e-06, "METEOR": 0.13192781141568988, "ROUGE_L": 0.13701023209383578, "CIDEr": 6.060536760444875e-104, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15, "f": 0.14634146341463414, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a small boat traveling down a river surrounded by tall palmland trees. The boat is white and has a blue stripe on the side. There are no people in the boat. The water is calm and clear. The sun is shining down on the scene.\n\nThe image is taken from a bird's eye view, looking down on the river and the\nboat. The perspective is straight on, with the boat in the center of the image. The image is in focus, with clear details of the boat and the surrounding\nlandscape. The lighting is bright and natural, with the sun shining down on the scene.\n\nThe image is taken in a tropical with lush green trees and palm\ntrees surrounding the river. The image is taken in the morning or late afternoon,\nwith the sun shining brightly in the"}, "142815": {"image_id": 142815, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.3143473067169879, "Bleu_3": 0.16757146412074078, "Bleu_4": 2.202381494555949e-05, "METEOR": 0.3287339232277604, "ROUGE_L": 0.3534183082271147, "CIDEr": 0.18128957854576083, "SPICE": {"All": {"pr": 0.1875, "re": 0.125, "f": 0.15, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man sitting on a bed, looking at a camera. He is wearing a red shirt and has a serious"}, "85292": {"image_id": 85292, "Bleu_1": 0.2058823529381488, "Bleu_2": 0.12395303423735725, "Bleu_3": 0.061516289159189684, "Bleu_4": 7.735960758934913e-06, "METEOR": 0.21944889626503467, "ROUGE_L": 0.2037213740458015, "CIDEr": 8.046751750232444e-21, "SPICE": {"All": {"pr": 0.06818181818181818, "re": 0.15, "f": 0.09374999999999999, "fn": 17.0, "numImages": 1.0, "fp": 41.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}}, "caption": "This is an image of a train traveling along a track with other trains in the background. The train is made up of several cars, each with a red and yellow striped body and black wheels. The train is traveling at a moderate speed and has a long line of cars behind it. There are buildings and trees in the background, and the sky is clear and blue."}, "500423": {"image_id": 500423, "Bleu_1": 0.0787878787874013, "Bleu_2": 0.043836692167279256, "Bleu_3": 2.2759496442115386e-07, "Bleu_4": 5.193895806511083e-10, "METEOR": 0.0936643937726508, "ROUGE_L": 0.0967595739859506, "CIDEr": 4.602892071889757e-145, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.12, "f": 0.09375000000000001, "fn": 22.0, "numImages": 1.0, "fp": 36.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The train is a red and white train with a large window on the side. It is parked in a train station with a large clock on the wall. There are people standing on the platform looking at the train.\n\nThe train is a red and white train with a large window on the side. It is parked in a train station with a large Hinweis on the wall. There are people standing on the platform looking at the train.\n\nThe train is a red and white train with a large window on the side. It is parked in a train station with a large clock on the wall. There are people standing on the platform looking at the train.\n\nThe train is a red and white train with a large window on the side. It is parked in a train station with a large clock on the wall. There are standing on the platform looking at the train.\n\nThe train is a red and"}, "196280": {"image_id": 196280, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.33282011772208075, "Bleu_3": 0.20977124924927762, "Bleu_4": 2.5169669586788924e-05, "METEOR": 0.18555260201383686, "ROUGE_L": 0.41536964980544744, "CIDEr": 0.02977570460557473, "SPICE": {"All": {"pr": 0.25, "re": 0.11538461538461539, "f": 0.15789473684210525, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a young boy standing in front of a kitchen counter with several pots and pans on it. The boy is wearing a white"}, "84752": {"image_id": 84752, "Bleu_1": 0.10204081632583648, "Bleu_2": 0.052873800728039475, "Bleu_3": 0.03378425536189371, "Bleu_4": 0.022748100605648077, "METEOR": 0.08082893418276314, "ROUGE_L": 0.10582403965303593, "CIDEr": 4.667589921150458e-111, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.14814814814814814, "f": 0.14035087719298248, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a large, white and red airplane sitting on the ground in a parking lot. The plane has a long, pointed The plane has a long, pointed nose and two large engines on the sides. The plane is parked in a The plane has a long, pointed nose and two large on the sides. The plane is parked in a parking lot in front of a large building. The building has a large sign on the front that reads, \"Welcome to the. The plane is parked in a next to a large building with a sign that reads, \"Welcome to the. The plane is parked in a par parking lot in front of a large building with a sign that reads, \"Welcome to the. The plane is parked in a next to a large building with a sign that reads, \"Welcome to the. The plane"}, "222317": {"image_id": 222317, "Bleu_1": 0.10948905109409134, "Bleu_2": 0.08025292777993918, "Bleu_3": 0.06201822544962883, "Bleu_4": 0.05165689521895594, "METEOR": 0.16492199510090924, "ROUGE_L": 0.14504623513870543, "CIDEr": 1.2871534155128016e-97, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.16666666666666666, "f": 0.13636363636363638, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a small brown dog sitting on a couch in a living room. The dog is looking up at the camera with its tongue hanging out of its is mouth. The room is dimly lit with a lamp on a nearby. The walls are made of wood and have a few pictures hanging on them. The floor is made of wood and has a few throw pillows on it. The couch is covered in a light brown blanket.\n\nThe image shows a small brown dog sitting on a couch in a living room. The dog is looking up at the with its tongue hanging out of its mouth. The room is dimly lit with a lamp on a nearby. The walls are made of wood and have a few pictures hanging on them. The floor"}, "544421": {"image_id": 544421, "Bleu_1": 0.18840579709871877, "Bleu_2": 0.11770032894399912, "Bleu_3": 0.05913258301516445, "Bleu_4": 7.4814220226521244e-06, "METEOR": 0.19295810938995311, "ROUGE_L": 0.21212121212121215, "CIDEr": 3.8206229040484274e-18, "SPICE": {"All": {"pr": 0.13953488372093023, "re": 0.3157894736842105, "f": 0.19354838709677416, "fn": 13.0, "numImages": 1.0, "fp": 37.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.25, "f": 0.11764705882352941, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.29411764705882354, "re": 0.625, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image is a cake with a waterfall in the middle. The cake is made of chocolate and has green icing on top. There are also small trees and The cake is on a white plate.\n\nThe cake is decorated with small rocks andgreen icing on top. There are also small trees and a small waterfall in the middle of the cake. The cake is on a white plate."}, "526827": {"image_id": 526827, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.14953924108841646, "Bleu_3": 7.54806561769252e-07, "Bleu_4": 1.7040573474649363e-09, "METEOR": 0.22375517038434034, "ROUGE_L": 0.21863799283154117, "CIDEr": 9.303927437827469e-12, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.11764705882352941, "f": 0.0909090909090909, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.4, "f": 0.2222222222222222, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a pair of scissors on a green cutting board. The scissors are made of red, yellow, and blue plastic and have sharp nobody knows what they are for. The cutting board is made of green and has a small hole in the center. There are no other objects in the image."}, "527529": {"image_id": 527529, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.21764287502183505, "Bleu_3": 0.13806135595106658, "Bleu_4": 1.983544145310677e-05, "METEOR": 0.2515044175077868, "ROUGE_L": 0.38705583756345174, "CIDEr": 0.12101815366076041, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.3125, "f": 0.2631578947368421, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a white cat sitting on top of a black bag. The cat is looking up at the."}, "152785": {"image_id": 152785, "Bleu_1": 0.1442307692293824, "Bleu_2": 0.09166129162417772, "Bleu_3": 0.054819355220605624, "Bleu_4": 0.035737165129485174, "METEOR": 0.1550246367618095, "ROUGE_L": 0.1454359673024523, "CIDEr": 7.971760920862528e-54, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.21739130434782608, "f": 0.22727272727272724, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of elephants walking across a dry, dusty The field is covered in tall grasses and trees in the background. The sun is setting in the distance, casting a warm orange glow over the scene. They are all facing the same and seem to be moving in unison. They are walking slowly and deliberately, as if they are on a mission. The scene is peaceful and with the only sound being the rustling of the grasses and the trumpeting of the elephants.\n\nThe image is taken at sunset, with the sky turning a warm orange and pink hue. The light"}, "516212": {"image_id": 516212, "Bleu_1": 0.10869565217312542, "Bleu_2": 0.08907294319634483, "Bleu_3": 0.07756769652765741, "Bleu_4": 0.06748621038636111, "METEOR": 0.2084884218122658, "ROUGE_L": 0.20239918325676368, "CIDEr": 3.5206251210305747e-94, "SPICE": {"All": {"pr": 0.0625, "re": 0.11764705882352941, "f": 0.08163265306122448, "fn": 15.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on top of a microwave oven in a kitchen. The cat is looking directly at the The cat is looking directly at the camera with its eyes. The cat's fur is a light gray and it has a white patch on its chest. The cat is wearing a red collar with a bell on it. The microwave oven is white and has a digital display on the front. There are several kitchen utensils on the counter, including a blender, a and a a coffee maker. The wall behind the counter has a large window with a view of the outdoors.\n\nThe cat is sitting on top of the microwave oven in a kitchen. The cat is looking directly at the camera with its eyes. The cat's fur is a light"}, "403378": {"image_id": 403378, "Bleu_1": 0.07299270072939423, "Bleu_2": 0.05180304212934851, "Bleu_3": 0.027088955105203667, "Bleu_4": 3.4899402408352017e-06, "METEOR": 0.130583369308534, "ROUGE_L": 0.12892998678996037, "CIDEr": 6.906717859209744e-98, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.22727272727272727, "f": 0.16949152542372883, "fn": 17.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a woman holding a mirror in, looking at her reflection. She is wearing a white dress and has long blonde hair. The background is dark and there are candles on the\n\nThe image shows a woman holding a mirror in, looking at her reflection. She is wearing a white dress and has long blonde hair. The background is dark and there are candles on the the\n\nThe image shows a woman holding a mirror in, looking at her reflection. She is wearing a white and has long blonde hair. The background is dark and there are candles on the\n\nThe image shows a woman holding a mirror in, looking at her reflection. She is wearing a white and has long blonde hair. The background is dark and there are candles on the\n\nThe image"}, "216051": {"image_id": 216051, "Bleu_1": 0.10273972602669358, "Bleu_2": 0.0652019862271986, "Bleu_3": 0.049061375141308, "Bleu_4": 0.039673552646736894, "METEOR": 0.15153982521828246, "ROUGE_L": 0.138147961751384, "CIDEr": 1.4036512007539558e-111, "SPICE": {"All": {"pr": 0.05405405405405406, "re": 0.06896551724137931, "f": 0.06060606060606061, "fn": 27.0, "numImages": 1.0, "fp": 35.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a woman sitting on a bench in a park with her dog. The woman is wearing a is sitting on a bench in a park with her dog. The woman is wearing a and the dog is sitting on her lap. The woman is wearing a pur and the dog is sitting on her lap. The woman is wearing a pur pur and the dog is sitting on her\n\nThe image shows a woman sitting on a bench in a park with her dog. The woman is wearing a purple shirt and the dog is sitting on her lap. The woman is wearing a sitting on a bench in a park with her dog. The woman is wearing a purple shirt and the dog is sitting on her lap. The woman is wearing a sitting on a bench in a park with her"}, "543043": {"image_id": 543043, "Bleu_1": 0.17441860464913467, "Bleu_2": 0.11095900821699856, "Bleu_3": 0.07604237987282313, "Bleu_4": 0.05705316623197793, "METEOR": 0.17484512157043614, "ROUGE_L": 0.1944223107569721, "CIDEr": 5.549840140478202e-34, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.19230769230769232, "f": 0.15384615384615385, "fn": 21.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21052631578947367, "re": 0.3333333333333333, "f": 0.2580645161290323, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}}, "caption": "The image shows a red Ford Mustang parked in front of a small, rustic building with a sign that reads \"Old Town Hinweis.\" The building appears to be made of wood and has a small porch with a wooden on it. The car is parked on the side of the road, with its hood up and the engine exposed. There are several other cars parked nearby, including a blue pickup truck and a white van. The sky is cloudy and there are trees in the background."}, "392493": {"image_id": 392493, "Bleu_1": 0.11029411764624786, "Bleu_2": 0.049507377148468354, "Bleu_3": 0.02634783971887404, "Bleu_4": 3.4244895824441795e-06, "METEOR": 0.115229648068478, "ROUGE_L": 0.11248682824025288, "CIDEr": 1.4740491979817148e-95, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.13793103448275862, "f": 0.13559322033898305, "fn": 25.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on a grassy hill with kites flying in the sky. The kites are made of colorful streamers and are being flown by Hinweis people. The sun is setting in the background, casting a warm orange glow over the scene. The houses in the distance are visible through the trees.\n\nThe image is taken at sunset, with the the sky turning orange and pink. The kites are flying high in the sky, with their streamers blowing in the wind. The people are standing on the with their kites, enjoying the view. The houses in the are visible in the distance.\n\nThe image is taken at, with the sun setting in the background, casting a warm orange glow over the scene. The kites are flying high in the sky, with"}, "524681": {"image_id": 524681, "Bleu_1": 0.22535211267288235, "Bleu_2": 0.1501173250060309, "Bleu_3": 0.08676558773199856, "Bleu_4": 0.05567156198405537, "METEOR": 0.24736819736278093, "ROUGE_L": 0.2274755277352334, "CIDEr": 4.088317874398914e-23, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a beach with a\n\nThe image shows a group of people standing on a beach with a kite flying in the sky. The are wearing sunglasses and hats, and some of them are holding cameras. The sky is clear and blue, with a few clouds scattered about. The beach is covered in sand and there are some rocks in the the background."}, "265816": {"image_id": 265816, "Bleu_1": 0.1176470588225408, "Bleu_2": 0.05469028176186142, "Bleu_3": 2.9458558161993405e-07, "Bleu_4": 6.851633398448309e-10, "METEOR": 0.1169302514193025, "ROUGE_L": 0.14528133373027685, "CIDEr": 1.2610465842512956e-68, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.25, "f": 0.2413793103448276, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a horse and carriage in the middle of a street. The carriage is white and has a red and white striped Hinweis on the side. The horse is black and has a long mane and tail. There are buildings on either side of the street with windows and shutters. The are some people walking on the street.\n\nThe image shows a horse and carriage in the middle of a street. The carriage is white and has a red and white striped canopy on the side. The horse is black and has a long mane and tail. There are buildings on either side of the street with windows and shutters. There are people walking on the sidewalk."}, "528984": {"image_id": 528984, "Bleu_1": 0.3913043478175804, "Bleu_2": 0.2467175818921615, "Bleu_3": 0.1607026084013227, "Bleu_4": 1.7625850434748632e-05, "METEOR": 0.258352917461762, "ROUGE_L": 0.29249580436346195, "CIDEr": 1.2020231940619149e-06, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.23076923076923078, "f": 0.1846153846153846, "fn": 20.0, "numImages": 1.0, "fp": 33.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2631578947368421, "re": 0.45454545454545453, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}}, "caption": "The image shows a ski slope with snow on it. There are several people on the slope, some of them are skiing and others are standing at the base of the slope. There is a sign at the top of the slope that reads, \"Ski Resort\"."}, "565776": {"image_id": 565776, "Bleu_1": 0.12030075187879474, "Bleu_2": 0.08538708719276973, "Bleu_3": 0.05506531384664108, "Bleu_4": 0.033664545155527206, "METEOR": 0.14051964982232973, "ROUGE_L": 0.16082256788821514, "CIDEr": 1.3556114152750047e-88, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.09090909090909091, "f": 0.09302325581395349, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a kitchen with a large island in the center of the room. The countertops are made of white and black granite. The walls are painted white and the floors are made of wood. There is a large stainless steel refrigerator in the corner of the room. The room has a large window with a view of the outdoors.\n\nThe image shows a kitchen with a large island in the center of the room. The countertops are made of white and black. The walls are painted white and the are made of hardwood. There is a large stainless steel refrigerator in the corner of the room. The room has a large window with a view of the outdoors.\n\nThe image shows a kitchen with a large island in the center of"}, "208132": {"image_id": 208132, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.168845408373504, "Bleu_3": 0.13736052482031916, "Bleu_4": 0.09898183824655712, "METEOR": 0.21867419631682306, "ROUGE_L": 0.26798462383305877, "CIDEr": 2.9399527497167806e-13, "SPICE": {"All": {"pr": 0.05, "re": 0.07407407407407407, "f": 0.05970149253731344, "fn": 25.0, "numImages": 1.0, "fp": 38.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2222222222222222, "f": 0.14814814814814814, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}}, "caption": "The image shows a plate of food with a drink on the side. There are two, a salad, and a drink on the side. The plate is on a table with a white tablecloth. The drink is a red sauce. The background is a dark colored wall with a window in the background. The lighting is dim."}, "37017": {"image_id": 37017, "Bleu_1": 0.2608695652136106, "Bleu_2": 0.195865186683031, "Bleu_3": 0.14199396977894593, "Bleu_4": 0.08115521673637668, "METEOR": 0.2904983685030185, "ROUGE_L": 0.2876001885902876, "CIDEr": 3.0125758136489436e-21, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.17857142857142858, "f": 0.15151515151515152, "fn": 23.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.2, "f": 0.1111111111111111, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a black dog sitting on the floor in front of a window. The dog is looking up at the the camera with its head tilted to the side. The dog is wearing a red collar with a tag on it. The background of the image is a white kitchen with a stove, and refrigerator. There is a wooden on the floor in front of the dog."}, "20536": {"image_id": 20536, "Bleu_1": 0.07575757575700186, "Bleu_2": 0.048095825391019836, "Bleu_3": 2.610701011197586e-07, "Bleu_4": 6.094252237654776e-10, "METEOR": 0.10809747413899497, "ROUGE_L": 0.09902597402597405, "CIDEr": 9.06081517397758e-88, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a toilet in a bathroom with a toilet paper roll on the floor\n\nThe toilet is in a bathroom with a toilet is in a bathroom with a toilet roll on the floor. The toilet is in a bathroom with a toilet roll on the floor. The toilet is in a bathroom with a toilet roll on the floor. The toilet is in a bathroom with a toilet roll on the floor. The toilet is in a is in a bathroom with a toilet roll on the floor. The toilet is in a bathroom with a toilet roll on the floor. The toilet is in a with a toilet roll on the floor. The toilet is in a bathroom with a toilet roll on the floor. The toilet is"}, "289264": {"image_id": 289264, "Bleu_1": 0.07006369426706967, "Bleu_2": 0.04238519766611215, "Bleu_3": 0.022630748027339716, "Bleu_4": 2.9453980955554374e-06, "METEOR": 0.10405324218423062, "ROUGE_L": 0.09964994165694281, "CIDEr": 6.027847836715066e-129, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23529411764705882, "f": 0.20512820512820512, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a brown dog sitting on a wooden The dog is looking out the window at the view outside. The dog's collar is red and it has a tag on it that says \"Buddy\". The dog is sitting on the windowsill, looking out at the view outside. The dog's collar is red and it has a tag on it that says \"Buddy\". The dog is sitting on the windowsill, looking out at the view outside. The dog is sitting on the looking out at the view outside. The dog is sitting on the windowsill looking out at the view outside. The dog is sitting on the windowsill looking out at the view outside. The dog is sitting on the windowsill looking out at the view outside. The dog is sitting on the looking out at the view outside. The dog is sitting on the windowsill looking out at the view outside. The dog"}, "18014": {"image_id": 18014, "Bleu_1": 0.12949640287676623, "Bleu_2": 0.0684974353893728, "Bleu_3": 0.040915326117864415, "Bleu_4": 4.737287973575267e-06, "METEOR": 0.0953035206636722, "ROUGE_L": 0.11204408291786931, "CIDEr": 4.8597047292547725e-101, "SPICE": {"All": {"pr": 0.10810810810810811, "re": 0.17391304347826086, "f": 0.13333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 33.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4444444444444444, "f": 0.2962962962962963, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image is a pizza with various toppings, including cheese, is a pizza with various toppings, including cheese, peppers, and onions. The pizza is cut into slices and is sitting in a on top of a blue tarp. The tarp has a white border around it. The pizza is surrounded by a white border. The pizza is cut into slices and is sitting in a bowl on top of a blue tarp. The tarp has a white border around it. The pizza is surrounded by a white border. The pizza is cut into slices and is sitting in a on top of a blue tarp. The tarp has a white border around it. The pizza is surrounded by a white border. The pizza is cut into slices and is sitting in a bowl on top of a blue tarp."}, "381123": {"image_id": 381123, "Bleu_1": 0.08724832214706546, "Bleu_2": 0.06423869419012376, "Bleu_3": 0.0438327894640115, "Bleu_4": 4.9007338586640155e-06, "METEOR": 0.12044474914884677, "ROUGE_L": 0.11916140509994069, "CIDEr": 1.183061078962335e-111, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.25, "f": 0.1935483870967742, "fn": 18.0, "numImages": 1.0, "fp": 32.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a group of people standing on a beach with kayaks in the water. The sky is cloudy and there are mountains in the background.\n\nThe image is taken from a high, looking down on the beach and the kayaks in the water. The beach is sandy and there are some rocks in the distance. The mountains in the background are covered in clouds and there is a small town in the distance.\n\nThe image is taken in the morning, as the sun is just rising over the mountains. The sky is cloudy and there is a light breeze blowing. The water is calm and there are a few boats in the distance.\n\nThe image is taken from a high looking down on the beach and the kayaks in the water. The beach is sandy and there are some rocks in the distance. The mountains in the"}, "19608": {"image_id": 19608, "Bleu_1": 0.13793103448180738, "Bleu_2": 0.08753762190587591, "Bleu_3": 0.04750009543299633, "Bleu_4": 5.2414177552369766e-06, "METEOR": 0.12057084279273023, "ROUGE_L": 0.15972387526779336, "CIDEr": 2.9683997959762397e-102, "SPICE": {"All": {"pr": 0.08108108108108109, "re": 0.14285714285714285, "f": 0.10344827586206896, "fn": 18.0, "numImages": 1.0, "fp": 34.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.5, "f": 0.3, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a close up of a bird standing on the, with its beak in the water. The bird is a heron, with its feathers a deep blue and its legs long and slender. The water is The bird is standing on one leg and the other is tucked under its body. The bird is looking down at the water with its beak open. The water is is\n\nThe image shows a close up of a bird standing on the edge of a pond, with its beak in the water. The bird is a heron, with its a deep blue and its legs long and slender. The water is is clear and The bird is standing on one leg, with the other tucked under its body. The bird is looking down at the water with its beak open, as if it is searching for"}, "497348": {"image_id": 497348, "Bleu_1": 0.18947368420853186, "Bleu_2": 0.11878443686321362, "Bleu_3": 0.05333496886321093, "Bleu_4": 6.372532771796204e-06, "METEOR": 0.17672037635096224, "ROUGE_L": 0.19558247239045243, "CIDEr": 8.15952234363882e-42, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a road with no traffic on it. The road is lined with trees on bothsides and there is a sign on the left side of the road that says \"no through traffic\". The sky is cloudy and there are some birds flying in the air.\n\nThe image shows a road with notraffic on it. The road is lined with on both sides and there is a sign on the left side of the road that says \"no through traffic\". The sky is cloudy and there are some birds flying in the air."}, "437594": {"image_id": 437594, "Bleu_1": 0.13698630136892476, "Bleu_2": 0.11082206669916453, "Bleu_3": 0.0842033453197345, "Bleu_4": 0.06759358814404712, "METEOR": 0.16205721663501388, "ROUGE_L": 0.1747016706443914, "CIDEr": 5.4608946191987905e-105, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.2631578947368421, "f": 0.13513513513513514, "fn": 14.0, "numImages": 1.0, "fp": 50.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 20.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5555555555555556, "f": 0.3448275862068966, "fn": 4.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "The image shows a woman sitting at a desk in front of a computer. She is wearing a blue shirt and has a serious Hinweis on her face. There are several objects on the desk, including a laptop, a pen, and a The woman is sitting in front of a brick wall with a large window behind her. The lighting in the room is soft and warm, with a few of light coming from the window. The woman is sitting in a comfortable position, with her back straight and her hands on the desk. She is looking at the computer screen intently, as if she is working on something important. The room is tidy and organized, with a few objects scattered around the desk. There is a bookshelf in the background, with a few books on it. The overall of the image is calm and focused."}, "413404": {"image_id": 413404, "Bleu_1": 0.06993006992958092, "Bleu_2": 0.04962183396403059, "Bleu_3": 0.03268778568126663, "Bleu_4": 0.02234894966855871, "METEOR": 0.10110602192731118, "ROUGE_L": 0.07750952986022873, "CIDEr": 2.173866446545578e-105, "SPICE": {"All": {"pr": 0.11290322580645161, "re": 0.30434782608695654, "f": 0.16470588235294115, "fn": 16.0, "numImages": 1.0, "fp": 55.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 25.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.16666666666666666, "f": 0.1, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2608695652173913, "re": 0.5454545454545454, "f": 0.3529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}}, "caption": "The image shows a group of people standing in a park. They are all wearing sunglasses and are looking at something on their phones. There are several trees in the background, and a bench in the foreground. The sky is cloudy and there is a blowing.\n\nThe image is taken from a bird's eye view, and the the people are standing in the The image is taken from a bird's eye view, and the people are standing in the shade of the The image is taken from a bird's view, and the people are standing in the foreground of the image is taken from a bird's eye view, and the are standing in the of the image is taken from a bird's view, and the are standing in the for sh of the image is taken from a"}, "332775": {"image_id": 332775, "Bleu_1": 0.1694915254208561, "Bleu_2": 0.12087736925536453, "Bleu_3": 0.08003532503880463, "Bleu_4": 0.05500653367161062, "METEOR": 0.2395678492664983, "ROUGE_L": 0.2659400544959128, "CIDEr": 9.113631637700082e-16, "SPICE": {"All": {"pr": 0.038461538461538464, "re": 0.034482758620689655, "f": 0.03636363636363637, "fn": 28.0, "numImages": 1.0, "fp": 25.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a cat sitting in a bag on a bed. The cat is looking out of the\n\nbag and appears to be happy. The bag is black and has wheels on the bottom. The bed is made of wood and has a blanket on it. The room is well lit and has a window on the wall."}, "530624": {"image_id": 530624, "Bleu_1": 0.18749999999707034, "Bleu_2": 0.09449111825081868, "Bleu_3": 5.241594611405222e-07, "Bleu_4": 1.2395530354396154e-09, "METEOR": 0.1636705594717369, "ROUGE_L": 0.18673469387755104, "CIDEr": 1.715676973214539e-18, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a black and white dog lying under a floral patterned blanket on a white bed. The dog is looking up at the nobody in the image. The bed is covered with a floral patterned blanket and there is a white pillow on the bed. The room is dimly lit and there is a window on the left side of the image."}, "139113": {"image_id": 139113, "Bleu_1": 0.21249999999734373, "Bleu_2": 0.10372797920819334, "Bleu_3": 0.051669280093049906, "Bleu_4": 6.5058137589539435e-06, "METEOR": 0.1408588905939297, "ROUGE_L": 0.157487091222031, "CIDEr": 6.0438036516924665e-28, "SPICE": {"All": {"pr": 0.1, "re": 0.06896551724137931, "f": 0.08163265306122448, "fn": 27.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of men playing baseball on a dirt field. They are wearing red and blue jerseys and black The men are standing in a with their feet on the ground and their on their hands. One of the men is holding a baseball bat and the other is holding a baseball. The men are wearing baseball gloves and are standing in a line. The field is made of dirt and there are trees in the background."}, "192858": {"image_id": 192858, "Bleu_1": 0.05405405405376188, "Bleu_2": 0.03832571153281327, "Bleu_3": 0.02522627464027393, "Bleu_4": 3.064587266352521e-06, "METEOR": 0.12707889393303243, "ROUGE_L": 0.08325209592513161, "CIDEr": 1.2474769263529044e-179, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting at as table with a s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s s"}, "482742": {"image_id": 482742, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.19410642689759766, "Bleu_3": 0.11788286024426503, "Bleu_4": 1.3812900077678662e-05, "METEOR": 0.17923536014685112, "ROUGE_L": 0.2559952038369305, "CIDEr": 5.286910432328228e-06, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.15151515151515152, "f": 0.1694915254237288, "fn": 28.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a man riding a bicycle on a sidewalk in\n\na residential area. The man is wearing a helmet and has a backpack on his back. There are buildings on either side of the sidewalk. The sky is blue and there are trees in the background."}, "398818": {"image_id": 398818, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.1666666666629209, "Bleu_3": 0.12467616434942133, "Bleu_4": 0.08241860357860763, "METEOR": 0.242625860074832, "ROUGE_L": 0.21048999309868874, "CIDEr": 1.1001151115931254e-08, "SPICE": {"All": {"pr": 0.10416666666666667, "re": 0.2, "f": 0.136986301369863, "fn": 20.0, "numImages": 1.0, "fp": 43.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.5, "f": 0.37037037037037035, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows three bananas on a countertop. The bananas are yellow and have blue stickers on them. The stickers have the words \"Banana\" and \"Banana\" written on them. The bananas are arranged in a row on the countertop. The countertop is made of white"}, "305871": {"image_id": 305871, "Bleu_1": 0.3913043478090738, "Bleu_2": 0.18860838403019278, "Bleu_3": 1.1920676375093199e-06, "Bleu_4": 3.0336688656211814e-09, "METEOR": 0.24607056564800603, "ROUGE_L": 0.30287984111221444, "CIDEr": 0.03824438757058288, "SPICE": {"All": {"pr": 0.11904761904761904, "re": 0.2, "f": 0.1492537313432836, "fn": 20.0, "numImages": 1.0, "fp": 37.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.625, "f": 0.35714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "The image shows a street with a sign on the sidewalk that reads, \"San Francisco's historic district.\" The sign is made of"}, "443818": {"image_id": 443818, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.21751282250452736, "Bleu_3": 0.14832029316654308, "Bleu_4": 1.847612635182097e-05, "METEOR": 0.2509629008610033, "ROUGE_L": 0.3443085606773283, "CIDEr": 0.0011120448500247856, "SPICE": {"All": {"pr": 0.1, "re": 0.08695652173913043, "f": 0.09302325581395349, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a brown dog lying on its back in a small, white, and tan dog bed. The dog is wearing a brown collar and is looking up at the"}, "421109": {"image_id": 421109, "Bleu_1": 0.06790123456748211, "Bleu_2": 0.035570217818555884, "Bleu_3": 0.019922829680751104, "Bleu_4": 2.6556081057437996e-06, "METEOR": 0.10395292290772479, "ROUGE_L": 0.11065759637188209, "CIDEr": 2.123502267630541e-139, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.21052631578947367, "f": 0.17777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a brown horse standing in a green field with mountains in the background. The horse is wearing a brown saddle and bridle. The horse is grazing on the grass in the field. There are two other horses in the background grazing as well. The sky is clear and blue.\n\nThe image is taken from a low angle, looking up at the horse. The horse is standing in the center of the image, with the mountains in the background. The horse is grazing on the grass in the field. There are two other horses in the background grazing as well. The Hinweis is taken from a low angle, looking up at the horse. The horse is standing in the center of the image, with the mountains in the background. The horse is grazing on the grass in the field. There are two other horses in the background grazing as well. The\n\nThe image is taken from a low angle, looking"}, "416660": {"image_id": 416660, "Bleu_1": 0.14492753623083388, "Bleu_2": 0.11726997895202934, "Bleu_3": 0.07966512895185736, "Bleu_4": 0.043991397174792654, "METEOR": 0.16045499153268136, "ROUGE_L": 0.12773913693814973, "CIDEr": 1.7045830066027645e-97, "SPICE": {"All": {"pr": 0.11666666666666667, "re": 0.5384615384615384, "f": 0.1917808219178082, "fn": 6.0, "numImages": 1.0, "fp": 53.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 22.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.5, "f": 0.125, "fn": 1.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.8571428571428571, "f": 0.3870967741935483, "fn": 1.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}}, "caption": "The image shows a group of people standing in a storefront. They are looking at the display of items in the store. There are several people in the store, including a woman in a white dress and a man in a black suit. The store has a large window display of items, including a large display ofM. The store has a large display ofM.\n\nThe image shows a group of people standing in front of a store. They are looking at the display of in the store. There are several people in the store, including a woman in a white dress and a man in a black suit. The store has a large display of items, including a large display ofM.\n\nThe image shows a group of people standing in front of a store. They are looking at"}, "322845": {"image_id": 322845, "Bleu_1": 0.07801418439660984, "Bleu_2": 0.052784665114856924, "Bleu_3": 2.716440813568887e-07, "Bleu_4": 6.173485232644881e-10, "METEOR": 0.10458650777432862, "ROUGE_L": 0.10870118629397688, "CIDEr": 4.705049946748596e-101, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.17647058823529413, "f": 0.13953488372093026, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a red stop sign on the side of a building. The sign is made of is made of metal and has a white background with red letters. The sign is attached to a metal pole that is attached to the side of the building. The pole is made of metal and has a white background with red letters. The sign is attached to the pole with a metal hook. The pole is attached to the side of the building with a metal hook. The sign is made of metal and has a white background with red letters. The sign is attached to the pole with a metal hook. The pole is made of and has a white background with letters. The sign is attached to the pole with a hook. The sign is made of MS and has"}, "304361": {"image_id": 304361, "Bleu_1": 0.0641025641021532, "Bleu_2": 0.049813548138351454, "Bleu_3": 0.031822532807310136, "Bleu_4": 3.8095896614509506e-06, "METEOR": 0.11999551905412312, "ROUGE_L": 0.09884259259259259, "CIDEr": 9.71554471935986e-126, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a young girl sitting on the floor in a hotel room, looking at a The girl is wearing a pink nightgown and has a toy in her hand. The room is dimly lit and there are suitcases and bags on the floor. The girl is holding a and looking at it. The room is decorated with a few pieces of furniture and some plants. The girl is sitting on the floor and looking at the screen of the with her tablet. The room is decorated with a few and some on the floor. The girl is sitting on the floor and looking at the screen of her table. The room is decorated with a few and some on the floor. The girl is sitting on the floor and looking at the screen of her tablet. The room is decorated with a few and some on the floor. The girl is sitting on the"}, "446917": {"image_id": 446917, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.18136906252429263, "Bleu_3": 0.10615274788259942, "Bleu_4": 0.06860408726311093, "METEOR": 0.190718287825207, "ROUGE_L": 0.2793893129770992, "CIDEr": 5.3909573849479806e-12, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3157894736842105, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a backpack with a banana and a water The backpack is blue and has the logo of the company on it. The banana pe is yellow and has the company's logo on it. The water is also blue and has the company's logo on it. The image is taken on a bicycle."}, "234676": {"image_id": 234676, "Bleu_1": 0.12162162162079987, "Bleu_2": 0.10370946732410996, "Bleu_3": 0.07617487214405803, "Bleu_4": 0.049690606643052755, "METEOR": 0.1476034877224335, "ROUGE_L": 0.14892578125, "CIDEr": 7.386869875431287e-112, "SPICE": {"All": {"pr": 0.125, "re": 0.13043478260869565, "f": 0.1276595744680851, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a beach next to a surfboard. The surfboard is lying on the sand, and the people are looking out at the ocean. There are some waves in the and the sky is blue.\n\nThe image is taken from a low looking down at the people and the surfboard on the beach. The sand is light brown and the water is blue. There are some waves in the ocean.\n\nThe image is taken in the morning, as the the are some clouds in the sky. The are some people standing on the beach, looking out at the ocean. There is a surfboard lying on the sand. The sky is blue and there are some clouds in the sky.\n\nThe image is taken in the, as the sun is shining brightly. The people are standing on the beach, looking out at"}, "343692": {"image_id": 343692, "Bleu_1": 0.12179487179409107, "Bleu_2": 0.08409494811031036, "Bleu_3": 0.05684509912306223, "Bleu_4": 0.04356394760740256, "METEOR": 0.13926229213478877, "ROUGE_L": 0.1408125577100646, "CIDEr": 7.371762906902019e-127, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a motorcycle parked in front of a yellow building with a sign that reads \"traffic ahead\". The motorcycle is a silver and black color and has a small mirror on the side. The building is a yellow color with a large\n\nThe image shows a scooter parked in front of a yellow building with a sign that reads \"traffic ahead\". The scooter is a silver and black color and has a small mirror on the side. The building is a yellow color with a large sign that reads \"traffic ahead\". The scooter is parked on the sidewalk in front of the building. There are no other vehicles or\n\nThe image shows a scooter parked in front of a yellow building with a sign that reads \"traffic ahead\". The scooter is a silver and black color and has a small mirror on the side. The building is a yellow color with a large sign"}, "293011": {"image_id": 293011, "Bleu_1": 0.10810810810737766, "Bleu_2": 0.0717496003329311, "Bleu_3": 0.041314772989440036, "Bleu_4": 4.696096661109873e-06, "METEOR": 0.1363973286951501, "ROUGE_L": 0.1556122448979592, "CIDEr": 1.9884565367670654e-105, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.1935483870967742, "f": 0.23076923076923075, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a close to a with a plane on it. The cake is decorated with a red and blue icing.\n\nThe plane is painted in red and blue colors and has a number 6 on the side. The cake is decorated with a red and blue icing. The plane is painted in red and blue colors and has a number 6 on the side. The cake is decorated with a red and blue icing.\n\nThe cake is decorated with a red and blue icing. The c plane is painted in red and blue colors and has a number 6 on the side. The cake is decorated with a red and blue icing. The are decorated with a red and blue icing. The cake is decorated with a red and blue icing. The cake is decorated with a red and blue icing. The cake is decorated with"}, "104625": {"image_id": 104625, "Bleu_1": 0.13186813186668278, "Bleu_2": 0.09376144618666303, "Bleu_3": 0.04622598733849055, "Bleu_4": 5.7882059982722295e-06, "METEOR": 0.20550892478777255, "ROUGE_L": 0.15986521901909398, "CIDEr": 3.4355614482265834e-40, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16, "f": 0.15094339622641512, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on a windowsill, looking at a television nobody is watching. The television is showing aoccer match. The cat is wearing a and has a tag on its collar. The tag reads, \"I'm a cat.\" The cat is looking at the television with a curious expression on its face. The background of the image is a white wall with a window on the left side of the image. The window has a view of a park outside. The image is well lit and in focus."}, "175612": {"image_id": 175612, "Bleu_1": 0.07352941176416525, "Bleu_2": 0.057166195047081064, "Bleu_3": 0.028999549972419447, "Bleu_4": 3.6798535371374714e-06, "METEOR": 0.11197541592337465, "ROUGE_L": 0.12855637513171758, "CIDEr": 3.6908071423294235e-96, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.21428571428571427, "f": 0.15, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image is of a skateboarder standing on a sidewalk with a skateboard in his hand. The skateboarder is wearing a red and blue striped shirt and blue jeans. The The skateboarder is standing in front of a large tree with leaves on the the and the sun shining through the leaves. The skateboarder is looking down at the skateboard in his hand. The skateboard has a red and blue striped deck and black trucks. The skateboarder is standing in front of a large tree with leaves on the ground and the the shining through the leaves. The skateboarder is looking down at the skateboard in his hand. The skateboard has a red and blue striped deck and black trucks. The skateboarder is standing in front of a large tree with leaves on the and the"}, "43448": {"image_id": 43448, "Bleu_1": 0.14074074073969822, "Bleu_2": 0.08574455229075087, "Bleu_3": 0.038093757345619136, "Bleu_4": 4.523732077342287e-06, "METEOR": 0.11661372114103316, "ROUGE_L": 0.14285714285714285, "CIDEr": 1.4906054267149856e-75, "SPICE": {"All": {"pr": 0.14583333333333334, "re": 0.3333333333333333, "f": 0.2028985507246377, "fn": 14.0, "numImages": 1.0, "fp": 41.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.16666666666666666, "f": 0.10526315789473684, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07142857142857142, "re": 0.125, "f": 0.09090909090909091, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.23809523809523808, "re": 0.7142857142857143, "f": 0.35714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}}, "caption": "The image shows two elephants standing on a rocky beach with the, sun shining down on them. The elephants are both looking at each other and appear to be communicating with each other. The background is a dense jungle with tall and trees. The elephants are both brown in with some white on their faces and.\n\nThe image is taken from a bird's looking down on the elephants from above. The lighting is bright and clear, and the the colors are vivid. The image is taken in the morning, and the sky is blue and cloudy.\n\nThe elephants are standing on a rocky beach with a small stream running through it. The beach is covered in sand and rocks, and there are some small trees in the background. The elephants are both standing on"}, "319221": {"image_id": 319221, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.122140963308627, "Bleu_3": 6.154331740919409e-07, "Bleu_4": 1.3869172173844396e-09, "METEOR": 0.18816346041896484, "ROUGE_L": 0.18340348767288037, "CIDEr": 7.882974464423318e-19, "SPICE": {"All": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a tray of food on a cart with a white tablecloth. There are several plates of asparagus, chicken, and other dishes on the tray. The tablecloth is white and the plates are made of ceramic. There are several on the tray, including a knife, a spoon, and a fork. The background is a dark and there are no other objects in the image."}, "338903": {"image_id": 338903, "Bleu_1": 0.0689655172409037, "Bleu_2": 0.021884405476468992, "Bleu_3": 1.4961592527011867e-07, "Bleu_4": 3.9188738260824403e-10, "METEOR": 0.0875452861764737, "ROUGE_L": 0.0918444165621079, "CIDEr": 3.6149976528757416e-112, "SPICE": {"All": {"pr": 0.08888888888888889, "re": 0.19047619047619047, "f": 0.12121212121212122, "fn": 17.0, "numImages": 1.0, "fp": 41.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.06666666666666667, "re": 0.14285714285714285, "f": 0.09090909090909091, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.15789473684210525, "re": 0.42857142857142855, "f": 0.23076923076923078, "fn": 4.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}}, "caption": "The image shows a plate with a banana and some crisps on the side. There is also a spoon on the plate. The background is a wooden table with a white tablecloth. The lighting is bright and the colors are vivid.\n\nThe image is taken with a, and the camera is held at a slight angle. The focus is on the banana and the crisps. The image is in focus, and the colors are vivid. The lighting is bright, and the shadows are minimal.\n\nThe image is taken in a kitchen, and the background is a wooden table with a white tablecloth. The lighting is bright, and the colors are vivid. The image is taken with a, and the is held at a slight angle. The focus is on the banana and the for crisps. The image is in focus, and the colors are vivid."}, "364993": {"image_id": 364993, "Bleu_1": 0.0909090909084552, "Bleu_2": 0.04382481713189434, "Bleu_3": 0.023882165530552838, "Bleu_4": 3.140676964741259e-06, "METEOR": 0.11709493820403749, "ROUGE_L": 0.10801922590437643, "CIDEr": 2.206030236626107e-102, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.1724137931034483, "f": 0.19607843137254902, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a sandwich with meat, lettuce, and tomato on a bun. The meat is cooked and the lettuce is wilted. The The sandwich is cut in half and the person is holding it with their left hand. The background is a white table with a white napkin on it.\n\nThe image shows a sandwich with meat, lettuce, and tomato on a bun. The sand meat is cooked and the lettuce is wilted. The sandwich is cut in half and the person is holding it with their left hand. The background is a white table with a white napkin on it.\n\nThe image shows a sandwich with. The lettuce is wilted and the tomato is sliced. The sandwich is cut in half and the person is holding it with their left hand. The background is a white table with a white nap"}, "37616": {"image_id": 37616, "Bleu_1": 0.19512195121713266, "Bleu_2": 0.16278219422760917, "Bleu_3": 0.12572597723869736, "Bleu_4": 0.10015600426612022, "METEOR": 0.20456179321805598, "ROUGE_L": 0.21999599278701665, "CIDEr": 1.2617449480218882e-29, "SPICE": {"All": {"pr": 0.1875, "re": 0.20689655172413793, "f": 0.19672131147540986, "fn": 23.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.38461538461538464, "f": 0.3448275862068966, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a man standing in a living room with a nobody in the background. The man is wearing a black and a pair of glasses. He is holding a box in his hand and looking at it. The room is filled with and a couch, coffee table, and a d. The man is standing in front of a window with a view of the outdoors. The lighting in the room is dim and the walls are painted a light color."}, "157756": {"image_id": 157756, "Bleu_1": 0.10447761193951885, "Bleu_2": 0.06865330091524659, "Bleu_3": 0.04148836342511998, "Bleu_4": 4.831999758193725e-06, "METEOR": 0.12337490407004335, "ROUGE_L": 0.12903225806451613, "CIDEr": 3.3272846869427334e-91, "SPICE": {"All": {"pr": 0.03773584905660377, "re": 0.09523809523809523, "f": 0.05405405405405406, "fn": 19.0, "numImages": 1.0, "fp": 51.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.08, "re": 0.25, "f": 0.12121212121212122, "fn": 6.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}}, "caption": "The image shows a large brick building with a clock tower on top. The building is surrounded by a large The building is surrounded by a sidewalk and streetlights. There are people walking on the sidewalk and cars parked on the\n\nThe image shows a large brick building with a clock tower on top. The building is surrounded by a large and a streetlights. There are walking on the sidewalk and cars parked on the street.\n\nThe building is a tall, brick structure with a clock tower on top. The building is surrounded by a largeide and streetlights. There are people walking on the and cars parked on the street.\n\nThe image shows a large brick building with a clock tower on top. The building is surrounded by a large and streetlights. There are"}, "516508": {"image_id": 516508, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.0631613940786591, "Bleu_3": 4.426378293466139e-07, "Bleu_4": 1.178238656172971e-09, "METEOR": 0.13330399659651448, "ROUGE_L": 0.19551282051282048, "CIDEr": 4.544040270091294e-10, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3, "f": 0.3243243243243243, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a large, ornate clock hanging from the ceiling of a church. The clock has two hands and a face with Roman numerals. The clock is surrounded by intricate carvings and has a large, ornate frame around it. The walls of the church are made of"}, "520528": {"image_id": 520528, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.315328111933741, "Bleu_3": 0.14747595901295488, "Bleu_4": 1.8082588864847716e-05, "METEOR": 0.30350715669370804, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.0003541035900993987, "SPICE": {"All": {"pr": 0.1, "re": 0.3125, "f": 0.15151515151515152, "fn": 11.0, "numImages": 1.0, "fp": 45.0, "tp": 5.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.14285714285714285, "f": 0.09090909090909091, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4444444444444444, "f": 0.2580645161290322, "fn": 5.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}}, "caption": "The image shows a young boy in a baseball uniform holding a,baseball bat. He is standing on a grassy field with other players in the background. The sky is clear and sunny."}}}