{"overall": {"Bleu_1": 0.31174703595526293, "Bleu_2": 0.20593534663025426, "Bleu_3": 0.13237734697381504, "Bleu_4": 0.08571096048215306, "METEOR": 0.22989205844850602, "ROUGE_L": 0.3099970408253697, "CIDEr": 0.10825854524160283, "SPICE": 0.19156826977881697}, "imgToEval": {"281533": {"image_id": 281533, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.4744557145690982, "Bleu_3": 0.4072279138147114, "Bleu_4": 0.3651171690566475, "METEOR": 0.4489222651430913, "ROUGE_L": 0.6281464530892449, "CIDEr": 0.16998144664050668, "SPICE": {"All": {"pr": 0.28, "re": 0.3181818181818182, "f": 0.29787234042553196, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A small dog is sitting in front of a television, watching a show. The room is decorated with plants and a couch."}, "397773": {"image_id": 397773, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.10446386175302294, "Bleu_3": 0.05604198220001126, "Bleu_4": 7.329133916814422e-06, "METEOR": 0.1996279748583679, "ROUGE_L": 0.2219334719334719, "CIDEr": 9.090384570656658e-18, "SPICE": {"All": {"pr": 0.3125, "re": 0.19230769230769232, "f": 0.2380952380952381, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This image shows a bowl of pasta with meatballs, broccoli, and cheese. The pasta is cooked and has a golden brown color, while the meatballs are small and round, with a reddish brown color. The broccoli is green and has florets that are slightly curled. The cheese is shredded and white in color. The bowl is made of ceramic and has a white background."}, "371250": {"image_id": 371250, "Bleu_1": 0.18032786884950286, "Bleu_2": 0.09495469152350963, "Bleu_3": 5.346385631454265e-07, "Bleu_4": 1.2740551048499696e-09, "METEOR": 0.14518493462144086, "ROUGE_L": 0.18702095043433828, "CIDEr": 3.1617294862438667e-15, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a couch with two pillows on it. The couch is brown in color and has a pattern of palm trees on the upholstery. There are two lamps on the coffee table in front of the couch, one on each side. The room is well lit and there is a TV on the wall above the couch."}, "573877": {"image_id": 573877, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.3321055820573897, "Bleu_3": 0.24499865249946995, "Bleu_4": 0.1800282927025759, "METEOR": 0.2618980775388274, "ROUGE_L": 0.44248704663212435, "CIDEr": 0.7832270319338417, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A white cat sitting on a laptop with its paws on the keyboard, looking at the screen."}, "181859": {"image_id": 181859, "Bleu_1": 0.24999999999652778, "Bleu_2": 0.20555661294538444, "Bleu_3": 0.12188830570609638, "Bleu_4": 1.2727973355219968e-05, "METEOR": 0.2472335556460401, "ROUGE_L": 0.2459677419354839, "CIDEr": 1.9918191069084015e-22, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.10526315789473684, "f": 0.125, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a cat laying on top of a sink in a bathroom. The cat is looking up at the camera with its eyes closed. The sink is made of white marble and has a faucet on the right side. There is a towel hanging on the left side of the sink. The walls are painted white and there is a window on the right side of the image."}, "119939": {"image_id": 119939, "Bleu_1": 0.27272727271487607, "Bleu_2": 0.11396057645433466, "Bleu_3": 8.65950551279142e-07, "Bleu_4": 2.4178614975561836e-09, "METEOR": 0.11995668833535127, "ROUGE_L": 0.20938215102974828, "CIDEr": 0.019484114297337686, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.38461538461538464, "f": 0.22727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.26666666666666666, "re": 0.6666666666666666, "f": 0.3809523809523809, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people skateboarding on the sidewalk in front of a building\""}, "385320": {"image_id": 385320, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.2355041079699752, "Bleu_3": 0.18873292695336627, "Bleu_4": 0.15844501336795438, "METEOR": 0.30009254776422645, "ROUGE_L": 0.3733741392501913, "CIDEr": 0.0005072541613893933, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.19047619047619047, "f": 0.16326530612244897, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.8, "f": 0.4210526315789473, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a young girl sitting on the floor, holding a toothbrush in her mouth. She is wearing a striped shirt and white shorts. There is a toothbrush on the floor next to her."}, "490415": {"image_id": 490415, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2006088294094673, "Bleu_3": 0.12731761426913407, "Bleu_4": 1.5265831690423254e-05, "METEOR": 0.272954092584186, "ROUGE_L": 0.3165307635285397, "CIDEr": 2.3334379214752873e-06, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.13793103448275862, "f": 0.11940298507462686, "fn": 25.0, "numImages": 1.0, "fp": 34.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a man standing in a park, holding a kite and flying it in the air. There are several people in the background watching him fly the kite. The sky is clear and there are no clouds in sight."}, "432293": {"image_id": 432293, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2477973138852387, "Bleu_3": 0.11839421659860744, "Bleu_4": 1.465285462748969e-05, "METEOR": 0.2526423889823177, "ROUGE_L": 0.3559445660102115, "CIDEr": 7.4956089700297546e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16, "f": 0.15094339622641512, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a pizza on a wooden cutting board with various toppings such as shrimp, tomatoes, and cheese. There is also a knife and a spatula on the board. The pizza appears to be ready to be served."}, "256301": {"image_id": 256301, "Bleu_1": 0.4374999999863282, "Bleu_2": 0.31430927853687557, "Bleu_3": 0.2145712186802577, "Bleu_4": 0.13585608691982629, "METEOR": 0.24916197440354762, "ROUGE_L": 0.31551724137931036, "CIDEr": 0.009147430665239077, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13793103448275862, "f": 0.1509433962264151, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a large neon sign with the words \"Public Market\" written in red letters on a black background. The sign is surrounded by people standing around it, looking at it."}, "361103": {"image_id": 361103, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.15985738224085583, "Bleu_4": 1.8353711358781696e-05, "METEOR": 0.21183642495935345, "ROUGE_L": 0.29889402211955757, "CIDEr": 0.001166152833689737, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.13043478260869565, "f": 0.16666666666666669, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a street scene with people walking on the sidewalk. There are several buildings on either side of the street, including a bank and a restaurant. The sky is blue and there are clouds in the background."}, "567562": {"image_id": 567562, "Bleu_1": 0.14893617021118155, "Bleu_2": 0.06931372582256569, "Bleu_3": 0.03737807119993596, "Bleu_4": 4.894432203470721e-06, "METEOR": 0.18185023547964335, "ROUGE_L": 0.15549890750182083, "CIDEr": 9.205206668358695e-40, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table with plates of food in front of them. There are two adults and three children at the table, all of whom appear to be enjoying their meals. The adults are wearing casual clothing, while the children are wearing t-shirts and shorts. The table is covered with a red and white checkered tablecloth, and there are several glasses of soda and juice on the table. The room appears to be a kitchen or dining area, with a stove and refrigerator visible in the background."}, "448320": {"image_id": 448320, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.1887840379814224, "Bleu_3": 0.11108422721947973, "Bleu_4": 0.07200236383858592, "METEOR": 0.24439583156315484, "ROUGE_L": 0.31443298969072164, "CIDEr": 1.9363380545772523e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.10714285714285714, "f": 0.11111111111111112, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bathroom with a sink, toilet, and mirror. The sink is made of wood and has a large bowl for washing hands. The toilet is white and has a seat and lid. The mirror is framed in wood and has a light above it. There are no other objects in the room."}, "14874": {"image_id": 14874, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.2383656473040621, "Bleu_3": 0.1942652896112717, "Bleu_4": 0.16454943953709725, "METEOR": 0.29830840022535315, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.0006327499323322137, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21052631578947367, "f": 0.21621621621621623, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man standing in the snow with skis and poles. He is wearing a blue jacket, black pants, and goggles. The background is a mountain range with snow covered peaks."}, "373713": {"image_id": 373713, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.2791452631065508, "Bleu_3": 0.2269432455075259, "Bleu_4": 0.18728674626942446, "METEOR": 0.2771714886600897, "ROUGE_L": 0.3489702517162472, "CIDEr": 0.05455539730409441, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people sitting around a table, discussing something on their laptops.\""}, "539326": {"image_id": 539326, "Bleu_1": 0.5624999999648439, "Bleu_2": 0.5477225574697925, "Bleu_3": 0.5047172596882444, "Bleu_4": 0.4715663208579191, "METEOR": 0.46140152879666385, "ROUGE_L": 0.6740331491712707, "CIDEr": 1.6587374435044602, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "A herd of cows grazing in a green pasture with a blue sky in the background."}, "20059": {"image_id": 20059, "Bleu_1": 0.18421052631094187, "Bleu_2": 0.1222128823790783, "Bleu_3": 0.09396955198772322, "Bleu_4": 0.06977877744333115, "METEOR": 0.20671638502472842, "ROUGE_L": 0.23940345368916802, "CIDEr": 8.346872288052286e-06, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.12903225806451613, "f": 0.12903225806451613, "fn": 27.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThe zebras are grazing in the grassy area. They are standing next to each other and looking at something in the distance. The zookeeper is standing nearby, watching them."}, "530520": {"image_id": 530520, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.42919753761745155, "Bleu_3": 0.3446412921079625, "Bleu_4": 0.2215201577642272, "METEOR": 0.2734202029537304, "ROUGE_L": 0.42558139534883715, "CIDEr": 0.13219254409364406, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.041666666666666664, "f": 0.05405405405405406, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of people sitting on the grass outside a building, using laptops and working on something."}, "117337": {"image_id": 117337, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.16568337391262167, "Bleu_3": 0.1188942937395292, "Bleu_4": 0.07692375025894271, "METEOR": 0.1815322956368704, "ROUGE_L": 0.25553560742070613, "CIDEr": 4.5906185908759345e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.14285714285714285, "f": 0.1395348837209302, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Here is a short caption for the image:\n\n\"A colorful and vibrant image of an orange and blue themed room with various objects such as a vase, a lamp, and a bookshelf. The walls are painted in shades of orange and blue, and there are several decorative items on the shelves.\""}, "256504": {"image_id": 256504, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.23904572186014378, "Bleu_3": 0.18873292695352514, "Bleu_4": 0.15723078586343264, "METEOR": 0.2525353137376389, "ROUGE_L": 0.33888888888888885, "CIDEr": 5.958968526461626e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.1724137931034483, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows two people sitting on a bed, both of them holding laptops. The room is decorated with a colorful tapestry on the wall and a large wooden headboard. The atmosphere is cozy and relaxing."}, "265472": {"image_id": 265472, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.12549213105688165, "Bleu_4": 0.08233704127828195, "METEOR": 0.23516044899560642, "ROUGE_L": 0.2873485868102288, "CIDEr": 9.317116881497645e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This image shows a plate of food with bacon, bananas, and maple syrup. The bacon is cooked and crispy, while the bananas are sliced and topped with maple syrup. The plate is on a white tablecloth, and there is a fork and knife on the side."}, "441083": {"image_id": 441083, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.3627381250353841, "Bleu_3": 0.19780890040014282, "Bleu_4": 2.637268672345515e-05, "METEOR": 0.28036772816306954, "ROUGE_L": 0.3652694610778443, "CIDEr": 0.6488736369452848, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.16666666666666666, "f": 0.1509433962264151, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The dog is sitting in the back seat of a car, looking out the window at the road ahead."}, "126958": {"image_id": 126958, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.2276604231967495, "Bleu_3": 0.10994365150211913, "Bleu_4": 1.3675138027356721e-05, "METEOR": 0.20429965843489178, "ROUGE_L": 0.32685867381111855, "CIDEr": 2.1291583426207245e-05, "SPICE": {"All": {"pr": 0.21212121212121213, "re": 0.30434782608695654, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a bedroom with a blue wall and a white ceiling. There is a mirror on the wall opposite the bed, and a window on the left side of the room. The floor is covered in a light blue carpet."}, "484075": {"image_id": 484075, "Bleu_1": 0.340909090901343, "Bleu_2": 0.15422177271257892, "Bleu_3": 8.273336660439995e-07, "Bleu_4": 1.9278114644534454e-09, "METEOR": 0.22329241236501138, "ROUGE_L": 0.285427807486631, "CIDEr": 5.454592725988966e-07, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.3157894736842105, "f": 0.36363636363636365, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a cluttered room with a desk, chair, and computer in the center. There are various items on the desk such as a keyboard, mouse, and headphones. The walls are painted white and there is a window to the left of the desk."}, "274528": {"image_id": 274528, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.25717224992746507, "Bleu_3": 0.1719893752106008, "Bleu_4": 2.1239349525504125e-05, "METEOR": 0.17987071945698688, "ROUGE_L": 0.2782846715328467, "CIDEr": 0.015505085376403892, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.10714285714285714, "f": 0.10169491525423728, "fn": 25.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of bicyclists ride down the street, passing by a truck with a banner promoting a cycling event.\""}, "286820": {"image_id": 286820, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.24494897426831577, "Bleu_3": 1.376600125372212e-06, "Bleu_4": 3.2998954723870518e-09, "METEOR": 0.19786350792416824, "ROUGE_L": 0.24771573604060915, "CIDEr": 0.01551597688628659, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.26666666666666666, "f": 0.18604651162790697, "fn": 11.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.8, "f": 0.4444444444444444, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows two iPhones on a green carpet. One iPhone is white and the other is black. Both phones have their screens turned off."}, "69236": {"image_id": 69236, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.1914854215434487, "Bleu_3": 1.1681928168373074e-06, "Bleu_4": 2.9176300839656436e-09, "METEOR": 0.20110765620703397, "ROUGE_L": 0.2571127502634352, "CIDEr": 0.01726862226950011, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a view of a park at night with a bench and trees. The sky is clear and there are no clouds in sight."}, "333237": {"image_id": 333237, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.2469323991564464, "Bleu_3": 0.16598638698273332, "Bleu_4": 0.10406104960584484, "METEOR": 0.22676916401571745, "ROUGE_L": 0.2952973720608575, "CIDEr": 4.899585916156194e-06, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.1, "f": 0.0784313725490196, "fn": 18.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a bedroom with a white bed and red curtains. There are two windows on the wall, one of which has a view of the garden outside. The room is decorated with red and white striped wallpaper and a red carpet."}, "285258": {"image_id": 285258, "Bleu_1": 0.3220338982996266, "Bleu_2": 0.21075689485807378, "Bleu_3": 0.11594167605155438, "Bleu_4": 1.291613792319972e-05, "METEOR": 0.18903493916953967, "ROUGE_L": 0.169538632573652, "CIDEr": 2.3056006308760262e-15, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.17857142857142858, "f": 0.21739130434782608, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of dogs playing in a grassy area. One dog is standing on its hind legs and appears to be trying to catch another dog that is running away. There are several other dogs in the background, some of which are also running around. The sky is blue and there are trees in the background."}, "574454": {"image_id": 574454, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.10182666119201575, "Bleu_4": 0.06813136779964551, "METEOR": 0.13023332821234695, "ROUGE_L": 0.1920654911838791, "CIDEr": 4.017457859757816e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2631578947368421, "f": 0.2040816326530612, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people on the beach, with kite surfers in the foreground and Table Mountain in the background. The sky is clear and blue, with a few clouds scattered across it. The waves are crashing against the shore, and there are some rocks and driftwood on the beach."}, "57703": {"image_id": 57703, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.2544697557892895, "Bleu_3": 0.19305302549200576, "Bleu_4": 0.14882455879058204, "METEOR": 0.294519922127194, "ROUGE_L": 0.36624416277518346, "CIDEr": 3.5501575220823795e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.26666666666666666, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "Here is a short caption for the image:\n\nA group of people hiking in the woods with their dogs. One person is holding a leash and another is petting a dog. The dogs are wearing collars and tags. The trees in the background are tall and green."}, "70294": {"image_id": 70294, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.23294541396842086, "Bleu_3": 0.10979304357192392, "Bleu_4": 1.3487023691913746e-05, "METEOR": 0.27219376338769874, "ROUGE_L": 0.31774970699309807, "CIDEr": 1.781797049787209e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.12, "f": 0.15789473684210525, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a blue bus parked on the side of a road in front of a building. The bus has the words \"Wheelchair Accessible\" written on the side in white letters. There are people standing next to the bus, looking at it."}, "279769": {"image_id": 279769, "Bleu_1": 0.6249999999609376, "Bleu_2": 0.45643546455816036, "Bleu_3": 0.3098990470998254, "Bleu_4": 0.21874057154605617, "METEOR": 0.26677160653704535, "ROUGE_L": 0.53643216080402, "CIDEr": 0.7684354931440136, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a banana on a table with a piece of paper next to it."}, "541474": {"image_id": 541474, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.13231937691727144, "Bleu_3": 0.06912848008424652, "Bleu_4": 8.92774794149235e-06, "METEOR": 0.24627732618977388, "ROUGE_L": 0.2127164942461932, "CIDEr": 2.3217878880946996e-13, "SPICE": {"All": {"pr": 0.35, "re": 0.30434782608695654, "f": 0.3255813953488372, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a blue jacket and black pants, and has a helmet on their head. They are holding onto the handlebars of their snowboard as they ride down the slope. In the background, there is a blue sky with some clouds."}, "217561": {"image_id": 217561, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.18609684207103389, "Bleu_3": 1.2008331555190807e-06, "Bleu_4": 3.089751861772178e-09, "METEOR": 0.0992745006913252, "ROUGE_L": 0.21837708830548927, "CIDEr": 0.05647961186520957, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a table set with white plates, silverware, and glasses. There are also several empty wine glasses on the table."}, "303778": {"image_id": 303778, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.23055616707626844, "Bleu_3": 0.15726435388931506, "Bleu_4": 1.7658659133673575e-05, "METEOR": 0.3364491264261352, "ROUGE_L": 0.38257839721254355, "CIDEr": 3.449424000165715e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a baseball player in a uniform, holding a bat and standing on the field. The player is wearing a white jersey with blue pants and white cleats. The player is standing on the field, looking at the scoreboard."}, "40426": {"image_id": 40426, "Bleu_1": 0.24285714285367346, "Bleu_2": 0.13265874899453015, "Bleu_3": 6.372663118511302e-07, "Bleu_4": 1.4019160888620642e-09, "METEOR": 0.17229807237639905, "ROUGE_L": 0.17112399476341872, "CIDEr": 8.178568436041969e-21, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.17857142857142858, "f": 0.2127659574468085, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a kitchen countertop with various ingredients and utensils. There is a blender on the counter, next to a bowl of strawberries and whipped cream. A spoon is sitting in the bowl, and there are several other ingredients on the counter, including a jar of jam and a container of yogurt. The overall appearance of the image is messy and chaotic, with various items scattered around the countertop."}, "324291": {"image_id": 324291, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.23904572186014378, "Bleu_3": 0.17147524405636724, "Bleu_4": 0.11117895489532319, "METEOR": 0.2668506916364323, "ROUGE_L": 0.33888888888888885, "CIDEr": 0.0006825471837476125, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2727272727272727, "f": 0.18749999999999997, "fn": 16.0, "numImages": 1.0, "fp": 36.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Object": {"pr": 0.29411764705882354, "re": 0.625, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "A woman is riding a pony in a green field. The pony is wearing a red halter and lead rope. The woman is wearing a white shirt and black pants. There are trees in the background."}, "96241": {"image_id": 96241, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.11065666703226196, "Bleu_3": 6.342171440889115e-07, "Bleu_4": 1.5263496054154455e-09, "METEOR": 0.19244177463909382, "ROUGE_L": 0.2594167679222357, "CIDEr": 4.357949164488092e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1, "f": 0.12765957446808512, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of people standing next to a train that is parked on the tracks. The train has a black and yellow paint job and is decorated with flags and other decorations. The people are dressed in formal attire and are looking at the train with interest."}, "326911": {"image_id": 326911, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.16866980207552001, "Bleu_3": 0.13334123550086785, "Bleu_4": 0.10788569011232613, "METEOR": 0.27801830064184596, "ROUGE_L": 0.3172362555720654, "CIDEr": 1.4575501431914813e-05, "SPICE": {"All": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a small dog standing on the sidewalk next to a bicycle. The dog is looking up at the bicycle with its tail wagging. There are some plants and trees in the background of the image."}, "209222": {"image_id": 209222, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.17516794979677439, "Bleu_3": 0.13910246118351624, "Bleu_4": 0.11775221946012629, "METEOR": 0.24785683183949114, "ROUGE_L": 0.2712618121178432, "CIDEr": 3.273282574778557e-15, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.2631578947368421, "f": 0.35714285714285715, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a man sitting on a bench in the middle of a city street. He is wearing a black hoodie and has his arms crossed over his chest. There are people walking by on either side of him, but he appears to be lost in thought. The sky is cloudy and there are trees in the background."}, "362293": {"image_id": 362293, "Bleu_1": 0.4347826086862004, "Bleu_2": 0.3260064312740514, "Bleu_3": 0.19351158547000502, "Bleu_4": 0.11393656301695436, "METEOR": 0.27420426400060216, "ROUGE_L": 0.30451060795150653, "CIDEr": 1.3742772100847772e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.26666666666666666, "f": 0.21621621621621623, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A horse and carriage are driving down the street in front of a group of people. The horse is pulling a carriage with two people inside. There are buildings on either side of the street, and a few cars parked along the side of the road."}, "144481": {"image_id": 144481, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1258455564244646, "Bleu_3": 0.06816612219878869, "Bleu_4": 8.966592262802168e-06, "METEOR": 0.1616161616161616, "ROUGE_L": 0.22048192771084338, "CIDEr": 1.0857090143431692e-11, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.18181818181818182, "f": 0.21621621621621623, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows two large vases on display in a museum. One of the vases is black and has a red handle, while the other is red and has a black handle. They are placed on a blue carpet in front of a white wall with a few other objects on it."}, "433804": {"image_id": 433804, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.13762047063655966, "Bleu_3": 8.485318099037327e-07, "Bleu_4": 2.124324129849806e-09, "METEOR": 0.18097639444904065, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.0006002209816769799, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.5, "f": 0.3, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a small boat traveling down a river surrounded by tall palm trees and lush green foliage. The water is calm and peaceful, with the sun shining down on the scene."}, "142815": {"image_id": 142815, "Bleu_1": 0.30952380951644, "Bleu_2": 0.2128289624210096, "Bleu_3": 0.13132391458151957, "Bleu_4": 1.5523573890829092e-05, "METEOR": 0.2761408588324961, "ROUGE_L": 0.29383429672447015, "CIDEr": 5.429291282187273e-06, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.20833333333333334, "f": 0.2380952380952381, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a man sitting on a bed, holding a camera in his hand. He is wearing red shorts and a white shirt. There is a TV in the background with a blue screen displaying an image of a city skyline."}, "85292": {"image_id": 85292, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.23488808779791684, "Bleu_3": 0.1253683714769749, "Bleu_4": 1.6436148153953708e-05, "METEOR": 0.26469191334542014, "ROUGE_L": 0.321390937829294, "CIDEr": 0.004272393417869744, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a train traveling along the tracks, with several cars loaded with cargo. The train is traveling through a rural area with fields and trees in the background."}, "500423": {"image_id": 500423, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.20100756304732487, "Bleu_3": 0.09794571638096426, "Bleu_4": 1.2230008607068681e-05, "METEOR": 0.2542268023088094, "ROUGE_L": 0.30219391365888176, "CIDEr": 2.840156653128294e-08, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.08, "f": 0.07272727272727272, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a red and orange train on the tracks in a large, modern train station. The train is parked next to other trains and has a large, orange engine at the front. There are people standing on the platform looking at the train."}, "196280": {"image_id": 196280, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.15182109665359528, "Bleu_3": 0.07942711818418766, "Bleu_4": 1.0272436745896128e-05, "METEOR": 0.150233623975341, "ROUGE_L": 0.270595690747782, "CIDEr": 5.052342850427143e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a young boy standing in front of a kitchen counter with several pots and pans on it. He is wearing a white shirt and black pants, and has a spoon in his hand. The caption reads, \"Growing up always means learning new ways to cook.\""}, "84752": {"image_id": 84752, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.15639188177115004, "Bleu_3": 0.11216278231474784, "Bleu_4": 0.08624849693567765, "METEOR": 0.203263685966947, "ROUGE_L": 0.2853801169590643, "CIDEr": 9.87591322020074e-12, "SPICE": {"All": {"pr": 0.3, "re": 0.2222222222222222, "f": 0.25531914893617025, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a large, white jet plane sitting on the ground in front of a building. The plane has a black nose and tail, and its wings are folded back. There are several people standing around the plane, looking at it. The sky is cloudy and there are some trees in the background."}, "222317": {"image_id": 222317, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.26846242207825327, "Bleu_3": 0.2175486149850356, "Bleu_4": 0.18655741294299272, "METEOR": 0.32219510310953003, "ROUGE_L": 0.4272373540856031, "CIDEr": 5.233289833065124e-05, "SPICE": {"All": {"pr": 0.15, "re": 0.16666666666666666, "f": 0.15789473684210525, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "A small dog is sitting on a couch in a living room. The dog is wearing a collar and looking up at the camera. There are two lamps on the coffee table in front of the couch."}, "544421": {"image_id": 544421, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.36927447290582666, "Bleu_3": 2.389091911370125e-06, "Bleu_4": 6.238986071516447e-09, "METEOR": 0.24096385542168677, "ROUGE_L": 0.46212121212121204, "CIDEr": 0.6664098582835156, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.15789473684210525, "f": 0.15, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a chocolate cake with a waterfall and trees on it."}, "526827": {"image_id": 526827, "Bleu_1": 0.6923076922011837, "Bleu_2": 0.41602514710358474, "Bleu_3": 2.5058139740241378e-06, "Bleu_4": 6.29812999135685e-09, "METEOR": 0.2188102421987333, "ROUGE_L": 0.4834874504623514, "CIDEr": 0.7507080976224378, "SPICE": {"All": {"pr": 0.25, "re": 0.23529411764705882, "f": 0.24242424242424243, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A pair of scissors and a ruler are sitting on a green table."}, "527529": {"image_id": 527529, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.11677484162212426, "Bleu_3": 0.06320745022725612, "Bleu_4": 8.308205615194402e-06, "METEOR": 0.2099013842740579, "ROUGE_L": 0.18068720379146921, "CIDEr": 6.203442204539876e-14, "SPICE": {"All": {"pr": 0.4, "re": 0.125, "f": 0.19047619047619047, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a white cat sitting on top of a black bag that is hanging from the handle of a suitcase. The cat appears to be looking at something on the ground in front of it. There are several other bags and items scattered around the room, including a laptop and a pair of shoes."}, "152785": {"image_id": 152785, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.18252590494116377, "Bleu_3": 0.1493538217984022, "Bleu_4": 0.12259259836512526, "METEOR": 0.24951136180278793, "ROUGE_L": 0.2596928690892504, "CIDEr": 1.0421927956740133e-16, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2608695652173913, "f": 0.2666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a herd of elephants walking across a dry, dusty field at sunset. The sky is orange and pink, with clouds in the distance. The elephants are walking in a line, with their trunks held high and their ears flapping in the wind. They seem to be enjoying the warm weather and the freedom of being out in the open."}, "516212": {"image_id": 516212, "Bleu_1": 0.7122777526922006, "Bleu_2": 0.46887861829052635, "Bleu_3": 0.33326034014641265, "Bleu_4": 0.24195572800734544, "METEOR": 0.42160638319548127, "ROUGE_L": 0.7018697349496609, "CIDEr": 2.116203148399291, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.29411764705882354, "f": 0.3846153846153846, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.6666666666666666, "f": 0.7272727272727272, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The cat is sitting on top of the microwave oven in the kitchen."}, "403378": {"image_id": 403378, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.17864740024886272, "Bleu_3": 0.14052875118914693, "Bleu_4": 0.1166275293058485, "METEOR": 0.27078434785700556, "ROUGE_L": 0.28018372703412076, "CIDEr": 1.5452425143903165e-09, "SPICE": {"All": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The woman in the image is looking at herself in a mirror. She has long blonde hair and is wearing a white dress with a red sash around her waist. There are candles on the table behind her, and she is holding a small candle in her hand."}, "216051": {"image_id": 216051, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.19973386548003494, "Bleu_3": 0.15138000825437872, "Bleu_4": 0.12331859801407646, "METEOR": 0.27821582224073127, "ROUGE_L": 0.3202099737532808, "CIDEr": 2.965841969378839e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.10344827586206896, "f": 0.11538461538461538, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a woman sitting on a bench in the woods, holding a small dog. The woman is wearing purple scrubs and has her arms around the dog. The dog is sitting on her lap and looks happy. The background is made up of trees and bushes."}, "543043": {"image_id": 543043, "Bleu_1": 0.1971830985887721, "Bleu_2": 0.14042189949789, "Bleu_3": 0.10455870503444678, "Bleu_4": 0.08427004627116261, "METEOR": 0.23992073558911986, "ROUGE_L": 0.2571428571428571, "CIDEr": 6.736985617748875e-22, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a red sports car parked in front of an old, rusted school bus. The car has a flat tire and is covered in dust and dirt. The bus has a faded paint job and is covered in rust. There are several other old vehicles parked nearby, including a pickup truck and a motorcycle. The scene is set in a rural area with trees and hills in the background."}, "392493": {"image_id": 392493, "Bleu_1": 0.21212121211799817, "Bleu_2": 0.15114173097832803, "Bleu_3": 0.0893729860406773, "Bleu_4": 1.031738326811257e-05, "METEOR": 0.24784967879889108, "ROUGE_L": 0.26832844574780057, "CIDEr": 2.97095856432013e-19, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.20689655172413793, "f": 0.2608695652173913, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a colorful kite flying in the sky with a sunset in the background. The kite is made of brightly colored streamers and has a long tail that trails behind it. The sky is a deep orange and pink, with clouds visible in the distance. The grass on the ground is green and there are people standing on the sidewalk looking at the kite."}, "524681": {"image_id": 524681, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.1930821114268906, "Bleu_3": 0.11067523724715086, "Bleu_4": 0.07078470170866812, "METEOR": 0.276080577413818, "ROUGE_L": 0.26798462383305877, "CIDEr": 4.916418330718234e-14, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.14285714285714285, "f": 0.11538461538461538, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a beach with a kite flying in the sky. The people are wearing casual clothing and are looking up at the kite. The sky is clear and blue, with a few clouds scattered about. The beach is covered in sand and there are some rocks in the distance."}, "265816": {"image_id": 265816, "Bleu_1": 0.2857142857097506, "Bleu_2": 0.16628219863944732, "Bleu_3": 0.07681639004822483, "Bleu_4": 9.322933958235267e-06, "METEOR": 0.21016695702507368, "ROUGE_L": 0.24910668708524755, "CIDEr": 5.448511959634358e-16, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14285714285714285, "f": 0.18604651162790697, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.23076923076923078, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a horse and carriage parked on the side of a cobblestone street in front of an old building with white walls and red roof tiles. The carriage is black and has a white canopy with lace trim. The driver is wearing a straw hat and a white shirt with black pants. There are palm trees and greenery in the background."}, "528984": {"image_id": 528984, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.15720795999973383, "Bleu_4": 0.09693770419482768, "METEOR": 0.2617368011081236, "ROUGE_L": 0.28817763080193687, "CIDEr": 4.6855720293324716e-07, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.19230769230769232, "f": 0.21276595744680848, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is an image of a ski slope with people skiing down it. There are several people in the background, some of whom are wearing helmets and others who are not. The snow is covered in a layer of fog, making it difficult to see very far."}, "565776": {"image_id": 565776, "Bleu_1": 0.4838709677263268, "Bleu_2": 0.2540002539920509, "Bleu_3": 0.13054395556610796, "Bleu_4": 1.6789125214955685e-05, "METEOR": 0.20553359683794464, "ROUGE_L": 0.31743278404163056, "CIDEr": 0.0026375139121826404, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13636363636363635, "f": 0.14634146341463414, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a kitchen with white and pink cabinets, black countertops, and a wooden table. There is a refrigerator, stove, and sink in the kitchen. The floor is made of hardwood."}, "208132": {"image_id": 208132, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.28509785718527286, "Bleu_3": 0.24690585127674183, "Bleu_4": 0.21936644510644115, "METEOR": 0.2712478362329535, "ROUGE_L": 0.4353256021409455, "CIDEr": 0.01802882026986888, "SPICE": {"All": {"pr": 0.15625, "re": 0.18518518518518517, "f": 0.1694915254237288, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a table with a plate of food on it, including a hamburger, fries, and a drink. There are also two glasses of water on the table."}, "37017": {"image_id": 37017, "Bleu_1": 0.25396825396422273, "Bleu_2": 0.18102512887767164, "Bleu_3": 0.12904344906492463, "Bleu_4": 0.07735958996389883, "METEOR": 0.2208783394096717, "ROUGE_L": 0.22920021470746108, "CIDEr": 1.7775479295998e-17, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14285714285714285, "f": 0.14545454545454545, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a black dog sitting on the floor in front of a kitchen counter. The dog is looking up at the camera with its tongue hanging out of its mouth. There is a white cat sitting on top of the counter next to the dog. The room appears to be a kitchen with white cabinets and a stove in the background."}, "20536": {"image_id": 20536, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.19758299278252553, "Bleu_3": 1.0370754607930322e-06, "Bleu_4": 2.3932498443488304e-09, "METEOR": 0.17424403266854754, "ROUGE_L": 0.2697126013264554, "CIDEr": 7.127721038559052e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.13636363636363635, "f": 0.21428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.42857142857142855, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet and a sink. The toilet is on the left side of the room and the sink is on the right side. There are also some trash cans in the room."}, "289264": {"image_id": 289264, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.18136906252429263, "Bleu_3": 0.10615274788259942, "Bleu_4": 1.2199723582450367e-05, "METEOR": 0.231087787939439, "ROUGE_L": 0.24413950829045164, "CIDEr": 1.4067206223933865e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.23529411764705882, "f": 0.17777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a brown dog sitting on the windowsill of a house, looking out at the rain. The dog is wearing a collar and has its head tilted to the side as if it is looking at something outside. The background of the image is a rainy day with trees and buildings visible through the window."}, "18014": {"image_id": 18014, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.32686022521796804, "Bleu_3": 0.2044582845909689, "Bleu_4": 2.4428720698922525e-05, "METEOR": 0.25524087225174297, "ROUGE_L": 0.42235410484668645, "CIDEr": 0.013147504358044865, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a pizza with various toppings such as vegetables, meat, and cheese. It is sitting in a box with a lid on top of it."}, "381123": {"image_id": 381123, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.22525531672830446, "Bleu_3": 0.15360570823926997, "Bleu_4": 1.7242869929285294e-05, "METEOR": 0.1798933905144819, "ROUGE_L": 0.3042394014962594, "CIDEr": 1.1467693173853559e-06, "SPICE": {"All": {"pr": 0.0847457627118644, "re": 0.20833333333333334, "f": 0.12048192771084336, "fn": 19.0, "numImages": 1.0, "fp": 54.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 21.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21739130434782608, "re": 0.5, "f": 0.30303030303030304, "fn": 5.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on the beach, looking out at the ocean. There are several kayaks and paddleboards on the sand, and the water is calm and clear. In the background, there are mountains and hills visible through the clouds."}, "19608": {"image_id": 19608, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.14953924108841646, "Bleu_3": 7.54806561769252e-07, "Bleu_4": 1.7040573474649363e-09, "METEOR": 0.16430361617278874, "ROUGE_L": 0.2533748701973001, "CIDEr": 1.6266189542232177e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.047619047619047616, "f": 0.06451612903225806, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA heron stands on the edge of a pond, looking out at the water. The pond is surrounded by trees and grass, and there are people walking their bikes on the path nearby. The sky is clear and blue, with a few clouds scattered about."}, "497348": {"image_id": 497348, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.23533936215658835, "Bleu_3": 0.13214760629595454, "Bleu_4": 1.779764404504326e-05, "METEOR": 0.22078252172051804, "ROUGE_L": 0.29158699808795413, "CIDEr": 0.02971609867769062, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2777777777777778, "f": 0.27027027027027023, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a road with no traffic on it. There are trees on both sides of the road and a few houses in the distance."}, "437594": {"image_id": 437594, "Bleu_1": 0.4594594594470417, "Bleu_2": 0.3195341955041846, "Bleu_3": 0.22681696947578164, "Bleu_4": 0.17912955294697497, "METEOR": 0.2939919802329883, "ROUGE_L": 0.3890857547838412, "CIDEr": 0.0005029726177641284, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A woman is sitting at a desk in front of a brick wall. She is wearing a blue shirt and has a laptop open in front of her. There are several photos on the wall behind her."}, "413404": {"image_id": 413404, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.276533159369469, "Bleu_3": 0.16672606319803102, "Bleu_4": 1.9508106914572997e-05, "METEOR": 0.25806933219990347, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.000260397960531859, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a park with several benches and trees. People are walking on the sidewalk, some of them sitting on the benches. There is a building in the background with windows and a door."}, "332775": {"image_id": 332775, "Bleu_1": 0.24999999997916675, "Bleu_2": 4.767312945812628e-09, "Bleu_3": 1.3147679470444613e-11, "Bleu_4": 7.08885680157797e-13, "METEOR": 0.208812158625653, "ROUGE_L": 0.2932692307692307, "CIDEr": 0.8171605111991675, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.06896551724137931, "f": 0.10526315789473684, "fn": 27.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The cat is sitting in the suitcase, looking out at the camera."}, "530624": {"image_id": 530624, "Bleu_1": 0.17647058823269898, "Bleu_2": 0.1026428638838207, "Bleu_3": 0.05424643415537024, "Bleu_4": 7.039633631433768e-06, "METEOR": 0.203373081978904, "ROUGE_L": 0.20728155339805826, "CIDEr": 3.0775967334443076e-21, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a brown and white dog lying under a floral quilt on a bed. The dog is curled up and appears to be sleeping. The quilt has a floral pattern with pink, purple, and blue flowers. The bed is covered in a white sheet and there are pillows on the bed. The room is dimly lit by a window on the left side of the image."}, "139113": {"image_id": 139113, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.3086066999098223, "Bleu_3": 0.2426427503086868, "Bleu_4": 0.19692215901893703, "METEOR": 0.2839803828554559, "ROUGE_L": 0.40219780219780216, "CIDEr": 0.13179814188422032, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.06896551724137931, "f": 0.09302325581395349, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "Sure, here is a short caption for the image:\n\nA group of young men playing soccer on a dusty field at night."}, "192858": {"image_id": 192858, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.3469443332317352, "Bleu_3": 0.2645668419848922, "Bleu_4": 0.1961887304180976, "METEOR": 0.20303345370936524, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.01851557717980648, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of people sitting at a table with pizzas in front of them. They are all smiling and laughing as they enjoy their meals."}, "482742": {"image_id": 482742, "Bleu_1": 0.5128205128073636, "Bleu_2": 0.3852895575760813, "Bleu_3": 0.2522382326554385, "Bleu_4": 0.1453056698631099, "METEOR": 0.2743015453671973, "ROUGE_L": 0.3232093859400133, "CIDEr": 0.0035740252546030884, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.18181818181818182, "f": 0.21818181818181817, "fn": 27.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.46153846153846156, "f": 0.48000000000000004, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a person riding a bicycle on the sidewalk next to a building with a red roof. There are trees and bushes on either side of the street, and a stop sign is visible in the distance."}, "398818": {"image_id": 398818, "Bleu_1": 0.5714285713877553, "Bleu_2": 0.29649972664244745, "Bleu_3": 1.9421783838169644e-06, "Bleu_4": 5.080057942628497e-09, "METEOR": 0.20367632405846198, "ROUGE_L": 0.3620178041543027, "CIDEr": 0.5013519287073454, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "There are three bananas on the counter, each with a different sticker on them."}, "305871": {"image_id": 305871, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.21060588478687045, "Bleu_3": 0.11392173307167976, "Bleu_4": 1.5026417037436177e-05, "METEOR": 0.26379694055954406, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.0008330665371262945, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a street with a sign on the sidewalk that reads, \"San Carlos Street.\" The street is lined with buildings and has a blue sky in the background."}, "443818": {"image_id": 443818, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.12517793602840982, "Bleu_3": 8.557991578273926e-07, "Bleu_4": 2.260612270720178e-09, "METEOR": 0.25304276110822804, "ROUGE_L": 0.30530530530530536, "CIDEr": 0.0076724406624265, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08695652173913043, "f": 0.10526315789473685, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a brown and white dog lying in a small, furry bed. The dog is wearing a collar and tag on its neck."}, "421109": {"image_id": 421109, "Bleu_1": 0.5384615384201185, "Bleu_2": 0.36689969282327245, "Bleu_3": 0.23044502516602136, "Bleu_4": 3.3260249502635095e-05, "METEOR": 0.2381786129196738, "ROUGE_L": 0.5343065693430658, "CIDEr": 0.926156537460675, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A brown horse grazing in a green field with mountains in the background."}, "416660": {"image_id": 416660, "Bleu_1": 0.17094017093870992, "Bleu_2": 0.12139284012049628, "Bleu_3": 0.08002937622684919, "Bleu_4": 0.04604800941773961, "METEOR": 0.12669252935773606, "ROUGE_L": 0.131425053862727, "CIDEr": 3.960547513400366e-68, "SPICE": {"All": {"pr": 0.7142857142857143, "re": 0.38461538461538464, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5714285714285714, "f": 0.7272727272727273, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This is an image of a group of people standing in front of a storefront. The storefront has a large window with display cases filled with various items, including clothing and accessories. There are several people standing outside the store, looking at the displays. The building behind the store appears to be a tall, multi-story structure with a sign reading \"johnson's\" on the side.\n\nThe people in the image are dressed in casual clothing, such as jeans and t-shirts. They appear to be browsing through the displays, looking at the various items for sale. The overall atmosphere of the image is one of quiet contemplation, with the people lost in thought as they examine the merchandise."}, "322845": {"image_id": 322845, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.11688708163230677, "Bleu_4": 0.07999424336103482, "METEOR": 0.2019060919331895, "ROUGE_L": 0.2543786488740617, "CIDEr": 2.706190684975887e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.17647058823529413, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.75, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a stop sign on the side of a building. The sign is made of metal and has the words \"stop\" written on it in white letters. The background is a blue sky with some clouds in it."}, "304361": {"image_id": 304361, "Bleu_1": 0.12499999999776788, "Bleu_2": 1.507556722861653e-09, "Bleu_3": 3.4784400373088004e-12, "Bleu_4": 1.6786858261541666e-13, "METEOR": 0.10689184547448694, "ROUGE_L": 0.14153132250580044, "CIDEr": 1.2483704912001515e-13, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13636363636363635, "f": 0.14634146341463414, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young child sitting on the floor, playing with a tablet computer. The child is wearing a white onesie and has a look of concentration on their face as they play with the device. The room appears to be a bedroom, with a bed in the background and a window in the background."}, "446917": {"image_id": 446917, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.17541160385452437, "Bleu_3": 0.10863467408031745, "Bleu_4": 1.536541839019132e-05, "METEOR": 0.15667323418197873, "ROUGE_L": 0.32527550657660864, "CIDEr": 0.0610333902642162, "SPICE": {"All": {"pr": 0.25, "re": 0.3157894736842105, "f": 0.27906976744186046, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A cyclist wearing a yellow jersey and carrying a banana on their handlebars rides down a street.\""}, "234676": {"image_id": 234676, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2823724831943621, "Bleu_3": 0.18002274574304641, "Bleu_4": 0.10989565913581459, "METEOR": 0.2706244197512065, "ROUGE_L": 0.3400696864111499, "CIDEr": 1.250473209240531e-06, "SPICE": {"All": {"pr": 0.375, "re": 0.13043478260869565, "f": 0.19354838709677416, "fn": 20.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on the beach next to a surfboard. The sky is clear and blue, with some clouds in the distance. The waves are crashing against the shore, and there are some people in the water surfing."}, "343692": {"image_id": 343692, "Bleu_1": 0.6315789473351802, "Bleu_2": 0.4588314677163038, "Bleu_3": 0.3336769761698013, "Bleu_4": 0.2610490903179286, "METEOR": 0.3137833376316078, "ROUGE_L": 0.4707828004410144, "CIDEr": 0.3148635152956298, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2857142857142857, "f": 0.24489795918367344, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a yellow scooter parked in front of a building with a sign that reads \"traffic ahead.\""}, "293011": {"image_id": 293011, "Bleu_1": 0.378378378368152, "Bleu_2": 0.3241991750442078, "Bleu_3": 0.26216155574410954, "Bleu_4": 0.18043239916327294, "METEOR": 0.32329122168690894, "ROUGE_L": 0.38911037703610896, "CIDEr": 0.0015136526284147077, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2222222222222222, "f": 0.20689655172413793, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a birthday cake with an airplane on it. The cake is decorated with blue frosting and has candles on it. There are also some other decorations on the cake, such as balloons and streamers."}, "104625": {"image_id": 104625, "Bleu_1": 0.388888888867284, "Bleu_2": 0.33819977077792013, "Bleu_3": 0.27783223331616935, "Bleu_4": 3.457913759026956e-05, "METEOR": 0.29191477099806956, "ROUGE_L": 0.46003016591251883, "CIDEr": 0.6047431429072474, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.1935483870967742, "f": 0.25, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on top of a television set, looking at the screen with interest."}, "175612": {"image_id": 175612, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.11881770515484788, "Bleu_3": 0.0832144496600632, "Bleu_4": 1.0467398290586188e-05, "METEOR": 0.15397828647770256, "ROUGE_L": 0.18654434250764526, "CIDEr": 3.359250095288934e-11, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a cartoon character holding a skateboard in front of a pile of leaves on the ground. The character is wearing a red and blue striped shirt and has a yellow hat on its head. The sun is shining behind the character, casting a warm glow on the scene."}, "43448": {"image_id": 43448, "Bleu_1": 0.30357142856600766, "Bleu_2": 0.1819804470697048, "Bleu_3": 0.08496079452594105, "Bleu_4": 1.037158083282231e-05, "METEOR": 0.19161359064015082, "ROUGE_L": 0.26124197002141325, "CIDEr": 8.642599706881923e-08, "SPICE": {"All": {"pr": 0.09375, "re": 0.21428571428571427, "f": 0.13043478260869562, "fn": 11.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 1.0, "f": 0.16666666666666669, "fn": 0.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows two elephants standing on a rocky beach with trees in the background. One of the elephants is holding a small rock in its trunk while the other one is looking at it. The image appears to be taken in a zoo or wildlife sanctuary, as there are fences and signs in the background."}, "528705": {"image_id": 528705, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.10480530666648924, "Bleu_4": 1.271816004077363e-05, "METEOR": 0.2478527103578613, "ROUGE_L": 0.20346897931954633, "CIDEr": 2.29822179874912e-08, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.2857142857142857, "f": 0.37499999999999994, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a young girl sitting on the back of an adult's red jacket, holding a stuffed teddy bear. The girl is wearing a red coat and has a red hat on her head. The background is a large stone building with a clock tower."}, "319221": {"image_id": 319221, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.250791558703178, "Bleu_3": 0.1650058207009288, "Bleu_4": 0.10231244993055355, "METEOR": 0.21498888521027396, "ROUGE_L": 0.24583557227297154, "CIDEr": 3.5227721303924074e-07, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.26666666666666666, "f": 0.18181818181818182, "fn": 11.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a tray filled with various dishes, including meat and vegetables. There are several servers standing around the table, preparing to serve the food to guests. The atmosphere appears to be formal and elegant, with white tablecloths and fine china."}, "338903": {"image_id": 338903, "Bleu_1": 0.7272727272066117, "Bleu_2": 0.5393598899191094, "Bleu_3": 0.40134229189878995, "Bleu_4": 0.2998221389022263, "METEOR": 0.3586416176643412, "ROUGE_L": 0.6110183639398998, "CIDEr": 2.086379925992914, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.23809523809523808, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.13333333333333333, "re": 0.2857142857142857, "f": 0.18181818181818182, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.17647058823529413, "re": 0.42857142857142855, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "The image shows a bowl of cereal with bananas and milk."}, "364993": {"image_id": 364993, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.27888667550350105, "Bleu_3": 0.16601049188899675, "Bleu_4": 0.1085108504636519, "METEOR": 0.25055795870551956, "ROUGE_L": 0.34885620915032683, "CIDEr": 0.00019747116050825318, "SPICE": {"All": {"pr": 0.5, "re": 0.10344827586206896, "f": 0.17142857142857143, "fn": 26.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.15384615384615385, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This is an image of a person holding a sandwich in their hand. The sandwich appears to be made with meat, cheese, and vegetables. There are also some crumbs on the plate next to the sandwich."}, "37616": {"image_id": 37616, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.1674925960284444, "Bleu_3": 0.09947534543406261, "Bleu_4": 0.06474997203684948, "METEOR": 0.22278895313066177, "ROUGE_L": 0.2531683094938116, "CIDEr": 4.7288915062014905e-14, "SPICE": {"All": {"pr": 0.375, "re": 0.20689655172413793, "f": 0.26666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.38461538461538464, "f": 0.4761904761904762, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is a man standing in front of a couch with a box on the floor next to him. He is wearing glasses and has his hands in his pockets. There are two chairs in the room, one on each side of the couch. The walls are painted white and there are windows on either side of the room."}, "157756": {"image_id": 157756, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.3311896883635246, "Bleu_3": 0.2598710284799138, "Bleu_4": 0.21641925722603572, "METEOR": 0.272632764239156, "ROUGE_L": 0.4408310749774164, "CIDEr": 0.05128274642656529, "SPICE": {"All": {"pr": 0.0625, "re": 0.14285714285714285, "f": 0.08695652173913043, "fn": 18.0, "numImages": 1.0, "fp": 45.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.13636363636363635, "re": 0.375, "f": 0.19999999999999998, "fn": 5.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}}, "caption": "The image shows a large clock tower in the middle of a city square. The clock face is illuminated and there are people walking around the square."}, "516508": {"image_id": 516508, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.15430334995774453, "Bleu_3": 0.08880224204971929, "Bleu_4": 1.2069505116085885e-05, "METEOR": 0.18293669762954917, "ROUGE_L": 0.25673400673400676, "CIDEr": 3.4259854672330296e-05, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.15, "f": 0.19354838709677416, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This image shows a large, ornate clock hanging on the wall of a church. The clock has two hands and is surrounded by intricate carvings. The walls are made of stone and have stained glass windows."}, "520528": {"image_id": 520528, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.30053715350890803, "Bleu_3": 0.14603807954737016, "Bleu_4": 1.8262493612863805e-05, "METEOR": 0.29782642252924046, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.001293644542209661, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a young boy in a baseball uniform holding a baseball bat and about to throw a pitch. The background is a green field with trees in the distance."}, "37675": {"image_id": 37675, "Bleu_1": 0.22499999999437506, "Bleu_2": 0.13155870289272328, "Bleu_3": 0.07693994231890816, "Bleu_4": 1.0533275933494714e-05, "METEOR": 0.23999610854583595, "ROUGE_L": 0.22426470588235295, "CIDEr": 1.299248692263222e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.2608695652173913, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 34.0, "tp": 6.0}, "Relation": {"pr": 0.0625, "re": 0.1, "f": 0.07692307692307693, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "The image shows a white church with a red roof and steeple in the background. In front of the church, there are two horses grazing on the grass. The sky is clear and blue, with some clouds in the distance."}, "232383": {"image_id": 232383, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.29388734334062333, "Bleu_3": 0.21057493618191458, "Bleu_4": 0.1269051898409943, "METEOR": 0.2766666412709063, "ROUGE_L": 0.33648542159180456, "CIDEr": 6.5954107533507554e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on top of a computer monitor, looking at the screen. The cat is black and white and has piercing green eyes. The background is a messy room with a desk, chair, and bookshelf."}, "137658": {"image_id": 137658, "Bleu_1": 0.2615384615344379, "Bleu_2": 0.15658617681158973, "Bleu_3": 0.07301107851978952, "Bleu_4": 8.901099392611368e-06, "METEOR": 0.19875359128210182, "ROUGE_L": 0.21128154379020286, "CIDEr": 2.3633130760391163e-18, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.25, "f": 0.24242424242424243, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This image shows a person holding a small flashlight in their hand. The flashlight is attached to a harness that is worn around the person's wrist. The person is wearing a backpack with various items inside, including a laptop and a cell phone. The background of the image appears to be a dark room or hallway with a few lights on in the distance."}, "209322": {"image_id": 209322, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.3470304129597038, "Bleu_3": 0.25515202680037635, "Bleu_4": 0.15606652450341843, "METEOR": 0.33287084461486094, "ROUGE_L": 0.41673783091374894, "CIDEr": 0.005682744174815719, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2727272727272727, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted blue and white tiles line the floor. There is a mirror on the wall above the sink."}, "128644": {"image_id": 128644, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.21398889174339228, "Bleu_3": 0.13736495494745896, "Bleu_4": 1.4941910307668207e-05, "METEOR": 0.18399752387382431, "ROUGE_L": 0.2658241638522715, "CIDEr": 2.8600227777729434e-09, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.3125, "f": 0.2325581395348837, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a small airplane parked on the runway at an airport. The plane has a red and white paint job with the words \"Southern Airways\" written on the side. There are several people standing around the plane, looking at it. The sky is cloudy and there is snow on the ground."}, "342675": {"image_id": 342675, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.16302782918400804, "Bleu_3": 0.08654590923115621, "Bleu_4": 1.1282878483696187e-05, "METEOR": 0.2874100929105498, "ROUGE_L": 0.30521801286633315, "CIDEr": 1.325007459997608e-07, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.125, "f": 0.12903225806451615, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a man standing on the platform of a train station, looking at his phone. The train is red and has the words \"train\" written on it in white letters. There are people standing on the platform and others walking by."}, "200234": {"image_id": 200234, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.13197176106186115, "Bleu_3": 0.06989787123302858, "Bleu_4": 9.090870283563952e-06, "METEOR": 0.15921505329302044, "ROUGE_L": 0.21266705403834982, "CIDEr": 6.395830653649526e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.21052631578947367, "f": 0.21052631578947367, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young boy is playing with a soccer ball in a park surrounded by trees. There are picnic tables and benches nearby, and a small stream runs through the area. The sun is shining down on the scene, casting a warm glow over everything."}, "545390": {"image_id": 545390, "Bleu_1": 0.5499999999725, "Bleu_2": 0.4501461750660246, "Bleu_3": 0.3832376860180962, "Bleu_4": 0.315696117051117, "METEOR": 0.32833972543794804, "ROUGE_L": 0.5674418604651164, "CIDEr": 0.4405079183743604, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A woman holding a pizza in her hands at a restaurant\""}, "43073": {"image_id": 43073, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.20966962740242623, "Bleu_3": 0.1441827180568874, "Bleu_4": 0.0913729807004326, "METEOR": 0.24073192930361428, "ROUGE_L": 0.3084702907711757, "CIDEr": 4.2725867175996104e-08, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.21428571428571427, "f": 0.26666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a young boy sitting on a bed, looking at the camera with a smile on his face. He has short blonde hair and is wearing a blue shirt with white stripes. The background of the image is a pink and purple floral wallpaper."}, "188651": {"image_id": 188651, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.0927733381723083, "Bleu_4": 1.1961929431463712e-05, "METEOR": 0.20840122076474188, "ROUGE_L": 0.2663755458515284, "CIDEr": 1.9561157744900803e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a cat lying on the ground next to a car. The cat is white with black spots and has a pink nose. The car is a silver sedan with tinted windows. There are no other objects in the image."}, "484551": {"image_id": 484551, "Bleu_1": 0.4324324324207451, "Bleu_2": 0.28997255745928074, "Bleu_3": 0.21260260500126002, "Bleu_4": 0.15419283939073053, "METEOR": 0.2939022963485673, "ROUGE_L": 0.3542466037540185, "CIDEr": 0.000173191312689702, "SPICE": {"All": {"pr": 0.15555555555555556, "re": 0.2, "f": 0.17500000000000002, "fn": 28.0, "numImages": 1.0, "fp": 38.0, "tp": 7.0}, "Relation": {"pr": 0.058823529411764705, "re": 0.1, "f": 0.07407407407407408, "fn": 9.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3157894736842105, "re": 0.46153846153846156, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}}, "caption": "The woman is sitting in the front of a small boat on the water. She is wearing an orange shirt and has her hands on the steering wheel. There are trees and rocks visible in the background."}, "396224": {"image_id": 396224, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.19738550847874506, "Bleu_3": 1.2489168104898057e-06, "Bleu_4": 3.182084683852089e-09, "METEOR": 0.13364796171197912, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.043937998806853645, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2608695652173913, "f": 0.3, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a table set with a turkey, mashed potatoes, and vegetables. There are also glasses of wine on the table."}, "255067": {"image_id": 255067, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 0.06923138992163505, "Bleu_4": 9.071482520661878e-06, "METEOR": 0.19440927420940435, "ROUGE_L": 0.18780788177339902, "CIDEr": 7.460107272330019e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.03225806451612903, "f": 0.046511627906976744, "fn": 30.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a polar bear standing on the edge of a small pond, looking out at the water. The bear is wearing a blue collar and has a tag on its neck that reads \"Polar Bear\". The background of the image is a rocky terrain with some trees in the distance."}, "479129": {"image_id": 479129, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.192868005722087, "Bleu_3": 0.09455603100869434, "Bleu_4": 1.1841311663495051e-05, "METEOR": 0.21126339880046954, "ROUGE_L": 0.24238410596026488, "CIDEr": 4.3626066788631294e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14814814814814814, "f": 0.14545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a plate with a banana split on it. The banana is topped with whipped cream and chocolate sauce, and there are sprinkles of cinnamon on top. The plate is on a white tablecloth, and there is a fork and knife on the side."}, "363887": {"image_id": 363887, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.12483755678422238, "Bleu_3": 0.06608439529502602, "Bleu_4": 8.590238521223447e-06, "METEOR": 0.21678260801344126, "ROUGE_L": 0.21229698375870068, "CIDEr": 3.0394130182704023e-12, "SPICE": {"All": {"pr": 0.3125, "re": 0.19230769230769232, "f": 0.2380952380952381, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an old fire truck parked on the side of a dirt road in the mountains. The truck is red and has a large ladder on the back. There are several other vehicles parked nearby, including a pickup truck and a motorcycle. The sky is clear and blue, with a few clouds scattered across it."}, "441969": {"image_id": 441969, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.19738550848437394, "Bleu_3": 0.15336829563872276, "Bleu_4": 0.11953994172638398, "METEOR": 0.2340136888084681, "ROUGE_L": 0.2426136363636364, "CIDEr": 7.026693950981311e-13, "SPICE": {"All": {"pr": 0.14634146341463414, "re": 0.2608695652173913, "f": 0.1875, "fn": 17.0, "numImages": 1.0, "fp": 35.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.5, "f": 0.35714285714285715, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "This image shows a small balcony with a table and chairs on it. There is a large window on the wall behind the table, which allows natural light to enter the room. The balcony is surrounded by brick walls and has a wooden floor. There are plants on the table and in pots on the balcony."}, "410225": {"image_id": 410225, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.2823298512746205, "Bleu_3": 1.535902471682881e-06, "Bleu_4": 3.6242479821540745e-09, "METEOR": 0.2571891908950349, "ROUGE_L": 0.38677536231884063, "CIDEr": 0.04996724827871868, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.17142857142857143, "f": 0.22641509433962265, "fn": 29.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.35714285714285715, "f": 0.41666666666666663, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A table with a cup of coffee and a spoon sitting on it. There are several laptops and cups of coffee on the table."}, "277073": {"image_id": 277073, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.1996674976872179, "Bleu_3": 0.1428841479853578, "Bleu_4": 0.10989565913581457, "METEOR": 0.18092672354061487, "ROUGE_L": 0.21254355400696864, "CIDEr": 1.1661997882929366e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.18518518518518517, "f": 0.18518518518518517, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man riding on the back of a motorcycle, wearing a helmet and holding onto the handlebars. The motorcycle is driving down the street, passing by other vehicles and pedestrians. The background is made up of tall buildings and trees."}, "41011": {"image_id": 41011, "Bleu_1": 0.4999999999791667, "Bleu_2": 0.39009474878613976, "Bleu_3": 0.2747975949286121, "Bleu_4": 0.1772984226390508, "METEOR": 0.3270915987085849, "ROUGE_L": 0.5029446407538279, "CIDEr": 0.10059290936829776, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.3888888888888889, "f": 0.1728395061728395, "fn": 11.0, "numImages": 1.0, "fp": 56.0, "tp": 7.0}, "Relation": {"pr": 0.13043478260869565, "re": 0.42857142857142855, "f": 0.2, "fn": 4.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.6666666666666666, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}}, "caption": "The image shows a man in a black suit and top hat riding a horse through a field with other horses in the background."}, "343821": {"image_id": 343821, "Bleu_1": 0.22499999999437506, "Bleu_2": 0.07595545252935183, "Bleu_3": 5.334717645470252e-07, "Bleu_4": 1.4232564071963268e-09, "METEOR": 0.19684233360950465, "ROUGE_L": 0.22426470588235295, "CIDEr": 8.633312135843897e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.08695652173913043, "f": 0.125, "fn": 21.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "A white swan is standing in the water with its babies. The swan is looking down at the water and the babies are looking up at it. The sky is cloudy and there are some birds flying in the distance."}, "530620": {"image_id": 530620, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.08206702275709715, "Bleu_4": 1.041362763232212e-05, "METEOR": 0.18179525596617024, "ROUGE_L": 0.23252858958068615, "CIDEr": 3.9680677283507054e-10, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.034482758620689655, "f": 0.05, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "A group of people are standing next to a truck that is parked on the side of a road. They are all wearing yellow vests and helmets, and one person is holding a large balloon. The sky is clear and there are no buildings or other structures in the background."}, "22113": {"image_id": 22113, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2736170867397671, "Bleu_3": 0.16725873794533458, "Bleu_4": 0.11084119214220596, "METEOR": 0.275910274092318, "ROUGE_L": 0.3061224489795918, "CIDEr": 0.0003011123268272047, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.16666666666666666, "f": 0.14545454545454548, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is an image of a red fire hydrant on the side of a street. The hydrant has a green handle and is surrounded by concrete. There are no other objects in the image."}, "82836": {"image_id": 82836, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2993592018235193, "Bleu_3": 0.23174884373154778, "Bleu_4": 0.16330657473497684, "METEOR": 0.2459896961858296, "ROUGE_L": 0.3320373250388802, "CIDEr": 2.268311438877738e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of seagulls standing on the beach, looking out at the ocean. The sky is cloudy and there are waves crashing against the shore. In the background, there are mountains visible in the distance."}, "538925": {"image_id": 538925, "Bleu_1": 0.4651162790589508, "Bleu_2": 0.34902173044391227, "Bleu_3": 0.22820598130551353, "Bleu_4": 0.13128958317871112, "METEOR": 0.3102365921683252, "ROUGE_L": 0.3642999336429994, "CIDEr": 4.6914227702357246e-05, "SPICE": {"All": {"pr": 0.1794871794871795, "re": 0.4375, "f": 0.2545454545454545, "fn": 9.0, "numImages": 1.0, "fp": 32.0, "tp": 7.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.8333333333333334, "f": 0.45454545454545453, "fn": 1.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a bedroom with a white wall and a wooden floor. There is a bed with a white sheet on it, and a brown blanket on top of the bed. The room has a window with a view of the outside."}, "440189": {"image_id": 440189, "Bleu_1": 0.7499999999531252, "Bleu_2": 0.5916079782717537, "Bleu_3": 0.3684031498394055, "Bleu_4": 4.428500142384227e-05, "METEOR": 0.2690688369212308, "ROUGE_L": 0.5897790055248618, "CIDEr": 0.4991894623215585, "SPICE": {"All": {"pr": 0.25, "re": 0.26666666666666666, "f": 0.2580645161290323, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A young boy is playing with a frisbee on the beach in front of a castle."}, "32777": {"image_id": 32777, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.21733262130578967, "Bleu_3": 0.15645512323417216, "Bleu_4": 0.10155860260081065, "METEOR": 0.22199447253826055, "ROUGE_L": 0.22846441947565538, "CIDEr": 2.6214660017304008e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4444444444444444, "re": 0.6666666666666666, "f": 0.5333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a train station with a large train on the platform. There are people standing on the platform and looking at the train. The train has a blue and yellow livery and is pulling into the station."}, "50679": {"image_id": 50679, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.37762745601340564, "Bleu_3": 0.29902635425025, "Bleu_4": 0.2255391761236893, "METEOR": 0.29142678915924647, "ROUGE_L": 0.41567291311754684, "CIDEr": 0.0005701285706060025, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15, "f": 0.13953488372093023, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows an orange lying on the ground in the middle of a parking lot. There are cars parked on either side of the road, and trees can be seen in the background."}, "86250": {"image_id": 86250, "Bleu_1": 0.21951219511927422, "Bleu_2": 0.127515342611103, "Bleu_3": 0.07407783780844739, "Bleu_4": 0.04762768256198227, "METEOR": 0.16145275031643397, "ROUGE_L": 0.17457072771872448, "CIDEr": 6.796535125103023e-31, "SPICE": {"All": {"pr": 0.125, "re": 0.10526315789473684, "f": 0.11428571428571428, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young woman sitting on the floor in a living room, wearing a black shirt and jeans. She is holding a book in her hand and looking up at the ceiling with a thoughtful expression on her face. There are two couches in the room, one with a blanket on it and the other with a pillow on it. The walls are painted white and there are windows on either side of the room that let in natural light."}, "482432": {"image_id": 482432, "Bleu_1": 0.692307692254438, "Bleu_2": 0.48038446137676916, "Bleu_3": 0.39777317387085076, "Bleu_4": 0.33495318894035875, "METEOR": 0.25133343486244786, "ROUGE_L": 0.5922330097087377, "CIDEr": 1.3957419039877124, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.18181818181818182, "f": 0.27586206896551724, "fn": 18.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "The image shows a sink with a toothbrush and toothpaste on the counter."}, "330880": {"image_id": 330880, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.21711298242232585, "Bleu_3": 0.17474938488327146, "Bleu_4": 0.13246197301306972, "METEOR": 0.24635927782159314, "ROUGE_L": 0.2978838849701574, "CIDEr": 6.006327359257279e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.11764705882352941, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is a photo of a man sitting at a table in a restaurant, holding a large pizza in his hands. The pizza has various toppings on it, including pepperoni and mushrooms. There are other people sitting at tables nearby, enjoying their meals. The atmosphere is cozy and inviting, with dim lighting and comfortable seating."}, "201934": {"image_id": 201934, "Bleu_1": 0.5757575757401286, "Bleu_2": 0.444878260487613, "Bleu_3": 0.2944829952668866, "Bleu_4": 0.20312919694591627, "METEOR": 0.29449765076720663, "ROUGE_L": 0.39967239967239965, "CIDEr": 0.0013387316494315098, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.42857142857142855, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.8333333333333334, "f": 0.5263157894736842, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is an image of a white school bus parked on the side of a road next to a fence. There are no people in the image, just the bus and the fence."}, "579462": {"image_id": 579462, "Bleu_1": 0.18421052631336565, "Bleu_2": 0.13112201361970038, "Bleu_3": 0.061476127138953875, "Bleu_4": 7.511024179023079e-06, "METEOR": 0.21234744235283695, "ROUGE_L": 0.1909660107334526, "CIDEr": 2.0939515212974073e-26, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.125, "f": 0.11538461538461538, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The woman is standing in front of a bed with an open suitcase on it. She is wearing a dress and has her hair tied back. There are curtains hanging in the background.\n\nThe image is taken in a room with a bed, a lamp, and a suitcase. The woman is standing next to the bed, looking at the suitcase. The lighting in the room is dim, and there is a window visible in the background."}, "183657": {"image_id": 183657, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.05714544883087091, "Bleu_3": 4.0006544362303344e-07, "Bleu_4": 1.0637896949215625e-09, "METEOR": 0.13706812930030038, "ROUGE_L": 0.18100890207715134, "CIDEr": 2.477458948116571e-12, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.3333333333333333, "f": 0.27027027027027023, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a cup of coffee floating in the water. The cup is made of ceramic and has a white handle. The cup is surrounded by ice and snow, with a small rock in the center of the cup. The background is a frozen lake with trees and rocks in the distance."}, "352652": {"image_id": 352652, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.18490006540142992, "Bleu_3": 1.1099703391050027e-06, "Bleu_4": 2.7474558341074007e-09, "METEOR": 0.1797882322104056, "ROUGE_L": 0.2278244631185808, "CIDEr": 0.018001580529429517, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.19230769230769232, "f": 0.18181818181818185, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is an image of a car parked in the snow. The car has snow on its hood and windshield, and there are other cars parked nearby."}, "339823": {"image_id": 339823, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.17720317768650332, "Bleu_3": 0.08936417387415972, "Bleu_4": 1.1350251107826057e-05, "METEOR": 0.26977542243940283, "ROUGE_L": 0.2447178389943835, "CIDEr": 2.0595056130282013e-08, "SPICE": {"All": {"pr": 0.5384615384615384, "re": 0.2916666666666667, "f": 0.3783783783783784, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The woman in the image is wearing a yellow and black dress with an orange scarf around her neck. She is holding an umbrella over her head, and her hair is blowing in the wind. The background is blue and there are clouds in the sky."}, "203690": {"image_id": 203690, "Bleu_1": 0.30434782607372407, "Bleu_2": 0.16633695977521876, "Bleu_3": 0.10962747416686626, "Bleu_4": 1.6020720993317762e-05, "METEOR": 0.25434156493021653, "ROUGE_L": 0.3262032085561497, "CIDEr": 0.0459603348443305, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16666666666666666, "f": 0.16, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A group of people are walking on the beach with surfboards. The sky is cloudy and there are palm trees in the background."}, "344614": {"image_id": 344614, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.23632829671335462, "Bleu_3": 0.1824236779225367, "Bleu_4": 0.1418365277267857, "METEOR": 0.2047155694381395, "ROUGE_L": 0.31282051282051276, "CIDEr": 1.9045006232089083e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1, "f": 0.13953488372093023, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a clock tower in the middle of a city. The clock tower is made of stone and has a large clock face on it. There are buildings in the background, including a tall skyscraper with windows on each floor. The sky is clear and blue."}, "573549": {"image_id": 573549, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.19674775072873346, "Bleu_3": 1.1010503638215559e-06, "Bleu_4": 2.627640098684675e-09, "METEOR": 0.18309736969610135, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.0007063822297631734, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.23809523809523808, "f": 0.1724137931034483, "fn": 16.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a street with a few people walking on it. There are buildings on either side of the street, and a sign on one of them reads \"dance impersons\"."}, "522941": {"image_id": 522941, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1458649914948234, "Bleu_3": 0.07733595213409626, "Bleu_4": 1.0068921364329411e-05, "METEOR": 0.22721409658474676, "ROUGE_L": 0.23461538461538461, "CIDEr": 9.99970443499658e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2777777777777778, "f": 0.24390243902439024, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a large elephant standing in the middle of a dirt road with people gathered around it. The elephant has a large tusk and is wearing a decorative headdress on its head. The people are standing in front of the elephant, looking at it with amazement."}, "511662": {"image_id": 511662, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.15632047282649467, "Bleu_3": 0.11005170155236454, "Bleu_4": 0.07048539394099318, "METEOR": 0.2074171011421714, "ROUGE_L": 0.30642267671331175, "CIDEr": 3.129652672465354e-11, "SPICE": {"All": {"pr": 0.1875, "re": 0.15789473684210525, "f": 0.17142857142857143, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a beach with palm trees and a large cruise ship in the background. The ship has several colorful sails and is docked at the shore. There are several umbrellas on the sand and a few people are standing on the beach. The sky is clear and blue, with a few clouds in the distance."}, "377371": {"image_id": 377371, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.36037498506145293, "Bleu_3": 0.2690709701483211, "Bleu_4": 0.1789417717985297, "METEOR": 0.3081325017228779, "ROUGE_L": 0.35952848722986247, "CIDEr": 0.239251570520479, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.16, "f": 0.20512820512820512, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a wooden cutting board with sliced nuts on it. There are also bananas and other fruits on the table."}, "170813": {"image_id": 170813, "Bleu_1": 0.2857142857040817, "Bleu_2": 0.14547859348536976, "Bleu_3": 9.337019798776129e-07, "Bleu_4": 2.3887527916706003e-09, "METEOR": 0.16609198505780884, "ROUGE_L": 0.23828124999999997, "CIDEr": 0.000761332863478183, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a person sitting on a bench in the grass, looking at their phone. There are trees in the background and a building in the distance."}, "347210": {"image_id": 347210, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.12321617651106383, "Bleu_4": 1.4359444090526792e-05, "METEOR": 0.2803914581464157, "ROUGE_L": 0.23843648208469054, "CIDEr": 3.099185736435294e-09, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.10526315789473684, "f": 0.0975609756097561, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a park with a bench in the middle of the grass. The bench is made of wood and has a green seat and backrest. There are trees on either side of the bench, with leaves on the ground. The sky is clear and blue."}, "175494": {"image_id": 175494, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.2718301411002404, "Bleu_3": 0.1762329661653903, "Bleu_4": 0.12045422179029222, "METEOR": 0.24151979586644273, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.006771942295750129, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.17391304347826086, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a picture of a dog lying on a bed with a cartoon character on the wall. The dog is wearing a collar and appears to be sleeping."}, "265879": {"image_id": 265879, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.15320195579385062, "Bleu_3": 0.10924931049403099, "Bleu_4": 0.0781262569105578, "METEOR": 0.2554527829485677, "ROUGE_L": 0.30897250361794504, "CIDEr": 6.240421324920593e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.08888888888888889, "f": 0.12698412698412698, "fn": 41.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.1875, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a group of people sitting at a table outside in the evening. They are wearing casual clothing and have plates of food in front of them. There are also several bottles of wine on the table."}, "433998": {"image_id": 433998, "Bleu_1": 0.37984802606153906, "Bleu_2": 0.24791115094281552, "Bleu_3": 0.19448917516315248, "Bleu_4": 0.1529965015599936, "METEOR": 0.24859447603918527, "ROUGE_L": 0.46960607878424315, "CIDEr": 0.028430553592570063, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a baseball game in progress, with a pitcher standing on the mound and a catcher behind him. The crowd is seated in the stands, watching the game."}, "286711": {"image_id": 286711, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.2039228056469627, "ROUGE_L": 0.26361279170267937, "CIDEr": 0.01063647114512796, "SPICE": {"All": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.5, "f": 0.3, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and running towards home plate. The crowd is cheering and watching from the stands."}, "552744": {"image_id": 552744, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.10675210253269501, "Bleu_3": 7.69610448813251e-07, "Bleu_4": 2.0876149875064654e-09, "METEOR": 0.15326709003579042, "ROUGE_L": 0.2606837606837607, "CIDEr": 0.011007235749125498, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The woman is wearing a black shirt and has her hair tied back. She is holding a stuffed animal in her arms and looking at the camera."}, "447279": {"image_id": 447279, "Bleu_1": 0.2676056337990478, "Bleu_2": 0.21418508703397826, "Bleu_3": 0.14924500009860525, "Bleu_4": 0.11004692923993462, "METEOR": 0.267543366401026, "ROUGE_L": 0.2857142857142857, "CIDEr": 6.222095097019812e-23, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This image shows a group of people standing on the sidewalk in front of a street with a sign that reads \"No Horses Allowed\". The people are wearing yellow vests and helmets, and they are looking at something on the ground. There are several horses standing in the street, and they are wearing yellow vests and helmets as well. The sky is cloudy and there is rain falling from the sky."}, "409217": {"image_id": 409217, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.26874192493724514, "Bleu_3": 0.20326259477011585, "Bleu_4": 0.1414126547200183, "METEOR": 0.22161855396255412, "ROUGE_L": 0.3040498442367601, "CIDEr": 7.789036545851316e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.27586206896551724, "f": 0.23880597014925373, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 8.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.1, "f": 0.08333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.625, "f": 0.43478260869565216, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "This image shows a plate of food with steak, broccoli, and beans. The steak is cooked to perfection and the broccoli is tender and crispy. The beans are cooked in a flavorful sauce. The dish is served on a white plate with a green background."}, "28114": {"image_id": 28114, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.08081987454730763, "Bleu_4": 1.0188015780213461e-05, "METEOR": 0.21399339718582042, "ROUGE_L": 0.18373493975903615, "CIDEr": 1.1811538149037375e-11, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a bus driving down the street. It is a large, orange and white bus with the words \"Van\" written on the side. There are people walking on the sidewalk and biking on the road. The sky is blue and there are trees and buildings in the background."}, "33994": {"image_id": 33994, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.17890134124348953, "Bleu_3": 9.615566980269285e-07, "Bleu_4": 2.2449887135893984e-09, "METEOR": 0.2016739480116305, "ROUGE_L": 0.2733791455034359, "CIDEr": 4.61540905706465e-05, "SPICE": {"All": {"pr": 0.1875, "re": 0.2857142857142857, "f": 0.22641509433962265, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a large, yellow flower sitting on a table with several other flowers around it. The table has a green cloth covering it and there are several people standing around the table looking at the flowers."}, "278509": {"image_id": 278509, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.24343224777560685, "Bleu_3": 0.19854523240208147, "Bleu_4": 0.16562895523388302, "METEOR": 0.27675127565839824, "ROUGE_L": 0.27555053642010163, "CIDEr": 3.9930675461285765e-12, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a motorcycle parked on the side of a road. The motorcycle has a black and white striped seat cover and a black helmet on the handlebars. There are no other vehicles or people in the image. The background is a city street with buildings and trees visible in the distance."}, "544975": {"image_id": 544975, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.25425669045977695, "Bleu_3": 0.14433404172174796, "Bleu_4": 1.635739937151075e-05, "METEOR": 0.280891368297458, "ROUGE_L": 0.26212400245549416, "CIDEr": 1.5876154138724733e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11764705882352941, "f": 0.11428571428571428, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a giraffe standing next to a zebra in a zoo enclosure. The giraffe is looking down at the zebra, while the zebra looks up at the giraffe. Both animals are standing on the ground, with rocks and trees visible in the background."}, "158806": {"image_id": 158806, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.11997212723629987, "Bleu_4": 1.4074957768979279e-05, "METEOR": 0.2722406311672511, "ROUGE_L": 0.23297262889879056, "CIDEr": 4.657369850474429e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.29411764705882354, "f": 0.21276595744680848, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "A dog is sitting on the ground next to a person who is holding a plate with a piece of toast on it. The dog is looking up at the person with its mouth open, as if it is waiting for them to give it some food."}, "267321": {"image_id": 267321, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2771809306010938, "Bleu_3": 0.2143601397219743, "Bleu_4": 0.1508931842274024, "METEOR": 0.24437039797271012, "ROUGE_L": 0.3808344068972352, "CIDEr": 0.002460137144758688, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.125, "f": 0.19354838709677416, "fn": 21.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is a living room with a couch, chair, and coffee table. There are plants on the coffee table and a red chair in the corner. The walls are painted white and there are windows on one side of the room."}, "137188": {"image_id": 137188, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.3120938919516558, "Bleu_3": 0.16950408960275246, "Bleu_4": 2.250073658261664e-05, "METEOR": 0.21637051730225304, "ROUGE_L": 0.40219780219780216, "CIDEr": 0.10189601534764006, "SPICE": {"All": {"pr": 0.3125, "re": 0.25, "f": 0.2777777777777778, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A cat sits on a shelf next to a bookshelf in a store.\""}, "132702": {"image_id": 132702, "Bleu_1": 0.5833333332847223, "Bleu_2": 0.39886201757398354, "Bleu_3": 0.3168777796754753, "Bleu_4": 4.336189089930935e-05, "METEOR": 0.24345245401142424, "ROUGE_L": 0.5865384615384615, "CIDEr": 0.6317309820876293, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.21052631578947367, "f": 0.17391304347826086, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a plate of steamed broccoli on a white surface."}, "151075": {"image_id": 151075, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.2681074537606562, "Bleu_3": 0.17251621196512443, "Bleu_4": 0.10578557985936674, "METEOR": 0.2536292464924659, "ROUGE_L": 0.2924657534246575, "CIDEr": 5.8599686337433105e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2, "f": 0.20408163265306126, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and has their arms outstretched as they jump off the wave. The sky is cloudy and there are waves crashing on the shore in the background."}, "516372": {"image_id": 516372, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2829297811792259, "Bleu_3": 0.22804358065127064, "Bleu_4": 0.19233147636007186, "METEOR": 0.3753820630166391, "ROUGE_L": 0.3935483870967742, "CIDEr": 0.008509417027200239, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20833333333333334, "f": 0.25641025641025644, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a parked car in front of a house with a red fire hydrant next to it. There are also some bushes and trees in the background."}, "397958": {"image_id": 397958, "Bleu_1": 0.18749999999707034, "Bleu_2": 0.16366341767441678, "Bleu_3": 0.13736863969771954, "Bleu_4": 0.11418215551674102, "METEOR": 0.18860444693761202, "ROUGE_L": 0.2401574803149606, "CIDEr": 1.7063665733548015e-17, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black and white cow standing in a field with tall grass and wildflowers growing around it. The cow is looking directly at the camera with its eyes and mouth open, as if it is about to speak. The sky in the background is blue with some clouds.\n\nCaption: A curious cow stands in a field, looking directly at the camera."}, "154004": {"image_id": 154004, "Bleu_1": 0.18947368420853186, "Bleu_2": 0.1738826108999409, "Bleu_3": 0.11757990916559877, "Bleu_4": 0.0771010659443247, "METEOR": 0.19496720898870426, "ROUGE_L": 0.19812342114760018, "CIDEr": 8.002701281899854e-44, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.75, "f": 0.5714285714285714, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a group of people sitting on the beach, looking out at the ocean. They are wearing swimsuits and sunglasses, and some of them have surfboards. The sky is clear and blue, with a few clouds in the distance. The sand is white and the water is blue.\n\nThe image is taken from a high angle, looking down on the people and the beach. It is a sunny day, with the sun shining brightly overhead. There are no other people or objects in the image, just the group of people on the beach."}, "179599": {"image_id": 179599, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.22019275302032337, "Bleu_3": 0.13113617972964073, "Bleu_4": 1.5222275337401534e-05, "METEOR": 0.23452997926239968, "ROUGE_L": 0.29468599033816417, "CIDEr": 1.0573962961979957e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a baseball player standing on a mound, holding a baseball in his hand. He is wearing a blue jersey with the number 27 on the back and white pants. The background is a green field with a blue sky in the distance."}, "282553": {"image_id": 282553, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.10341753799591613, "Bleu_3": 6.939786934219505e-07, "Bleu_4": 1.8120458368313505e-09, "METEOR": 0.11556982343499199, "ROUGE_L": 0.1958266452648475, "CIDEr": 0.00016148234775352103, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows two people walking through a field at sunset. The sky is painted with hues of orange and pink, and the silhouette of a large structure can be seen in the distance."}, "53529": {"image_id": 53529, "Bleu_1": 0.4038461538383876, "Bleu_2": 0.26695873898979966, "Bleu_3": 0.11253978816983062, "Bleu_4": 1.305962029153501e-05, "METEOR": 0.27124539359024097, "ROUGE_L": 0.375770020533881, "CIDEr": 1.9237037934662348e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.13636363636363635, "f": 0.11538461538461538, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA woman is sitting in the driver's seat of a green truck, wearing a green shamrock hat and holding a leash with her dog sitting next to her. The truck has a green bumper sticker that reads \"Happy St. Patrick's Day!\""}, "13168": {"image_id": 13168, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 9.809046705543318e-07, "Bleu_4": 2.2953576924413835e-09, "METEOR": 0.22983240604595892, "ROUGE_L": 0.2848249027237354, "CIDEr": 2.3305912553928664e-05, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.29411764705882354, "f": 0.3225806451612903, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a train at a station with people standing on the platform. The train is silver and has windows on the sides. There are streetlights on the platform and a sign that reads \"train station\"."}, "528738": {"image_id": 528738, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.10675210253269501, "Bleu_3": 7.69610448813251e-07, "Bleu_4": 2.0876149875064654e-09, "METEOR": 0.19755530238253094, "ROUGE_L": 0.17681159420289855, "CIDEr": 0.010600829838871471, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a kitchen countertop with various vegetables and fruits arranged on it. There are carrots, beets, potatoes, onions, garlic, lemons, limes, and other vegetables and fruits."}, "368193": {"image_id": 368193, "Bleu_1": 0.1666666666635803, "Bleu_2": 0.0560772154081562, "Bleu_3": 3.9251522966741233e-07, "Bleu_4": 1.0435177484324181e-09, "METEOR": 0.21061753848476603, "ROUGE_L": 0.1783625730994152, "CIDEr": 4.02714471455299e-13, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.09090909090909091, "f": 0.13043478260869568, "fn": 30.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.21428571428571427, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of horses standing on the side of the road in front of a white building with a red roof. The horses are wearing saddles and bridles, and one of them is pulling a cart with a person sitting in it. There are trees and houses visible in the background."}, "538064": {"image_id": 538064, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.20870354281255962, "Bleu_3": 0.14598577364278748, "Bleu_4": 0.10313349331598666, "METEOR": 0.28831172074719413, "ROUGE_L": 0.2643553629469122, "CIDEr": 4.704145598699269e-14, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.3, "f": 0.22641509433962265, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a statue of a man standing on a pedestal in front of a building. The man is wearing a hat and has a cigar in his mouth. There are several other statues nearby, including one of a woman holding a baby. In the background, there is a large clock tower with a flag flying from it."}, "265636": {"image_id": 265636, "Bleu_1": 0.222222222217284, "Bleu_2": 0.1421338109005459, "Bleu_3": 7.773956660946081e-07, "Bleu_4": 1.8288128464905184e-09, "METEOR": 0.20516265154715793, "ROUGE_L": 0.25258799171842644, "CIDEr": 1.1362572966634201e-08, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.22580645161290322, "f": 0.2641509433962264, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a stuffed animal sitting on top of a pile of presents. The stuffed animal is wearing a birthday hat and holding a sign that says \"happy birthday\". There are also several balloons and streamers on the table next to the stuffed animal."}, "577796": {"image_id": 577796, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2477973138852387, "Bleu_3": 0.14916736567839847, "Bleu_4": 1.7425278978111283e-05, "METEOR": 0.2244251857143539, "ROUGE_L": 0.24148851939825808, "CIDEr": 3.7859949064050603e-06, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bathroom with three urinals on the wall. The urinals are made of white porcelain and have nozzles on the bottom. There is a tile floor in front of them and a white sink to the left."}, "554046": {"image_id": 554046, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.38490017944522087, "Bleu_3": 0.2872579586598586, "Bleu_4": 0.17727652989120093, "METEOR": 0.2455919231424428, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.011261822222573048, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.12, "f": 0.15789473684210525, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a group of sheep standing in a snowy field. They are wearing coats and hats to keep warm in the cold weather."}, "316534": {"image_id": 316534, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.1791244302026115, "Bleu_3": 0.10008904723903041, "Bleu_4": 1.3410639647907158e-05, "METEOR": 0.2602782059316696, "ROUGE_L": 0.25206611570247933, "CIDEr": 0.0002933461340447234, "SPICE": {"All": {"pr": 0.375, "re": 0.14285714285714285, "f": 0.20689655172413796, "fn": 36.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.18181818181818182, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.23529411764705882, "f": 0.3333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Here is a short caption for the image:\n\nA herd of cows graze on the grass next to a body of water. The sky is clear and blue, with palm trees in the background."}, "158950": {"image_id": 158950, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.22522130822577494, "Bleu_3": 0.15122694444080373, "Bleu_4": 0.11261915591758805, "METEOR": 0.2654661609923835, "ROUGE_L": 0.28968792401628224, "CIDEr": 1.4693295898653735e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.0967741935483871, "f": 0.15000000000000002, "fn": 28.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a blue and yellow train traveling along a track through a rural area. The train is pulling a large cargo car with the words \"Sydney to Melbourne\" written on it. The sky is cloudy and there are trees and fields in the background."}, "524822": {"image_id": 524822, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.1526138463085648, "Bleu_3": 0.1184913406929158, "Bleu_4": 0.07416077978634553, "METEOR": 0.20066330026199622, "ROUGE_L": 0.20631341600901915, "CIDEr": 3.540583505760688e-14, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.25, "f": 0.23076923076923075, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a living room with white couches and a white coffee table. There is a large window on one wall that lets in natural light. The walls are painted white and there are black and white photographs hanging on them. The floor is made of hardwood and there is a fireplace in the corner of the room."}, "248111": {"image_id": 248111, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.31072773312239654, "Bleu_3": 0.19034610712449662, "Bleu_4": 2.248107416659061e-05, "METEOR": 0.21589589243946913, "ROUGE_L": 0.31937172774869105, "CIDEr": 0.0031761057768564457, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2222222222222222, "f": 0.20689655172413793, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a kitchen with white cabinets, a white refrigerator, and a white stove. There is also a white sink and a white microwave. The floor is made of hardwood."}, "409964": {"image_id": 409964, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.1643989873008524, "Bleu_3": 9.174380408476639e-07, "Bleu_4": 2.1830457064027044e-09, "METEOR": 0.2587537964991009, "ROUGE_L": 0.2848249027237354, "CIDEr": 2.070917632426588e-05, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.18518518518518517, "f": 0.17857142857142858, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and blue shorts, and has a racket in his hand. The background is a green field with trees in the distance."}, "337987": {"image_id": 337987, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.3098662125759413, "Bleu_3": 0.2519991441397994, "Bleu_4": 0.2067984532323631, "METEOR": 0.3533665879614452, "ROUGE_L": 0.36961696602467, "CIDEr": 6.0975329768904707e-05, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.32, "f": 0.2909090909090909, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "This is a small bird perched on a branch of a tree. It has a brown and white striped body with a black head and beak. The bird appears to be looking down at something on the ground."}, "544104": {"image_id": 544104, "Bleu_1": 0.29999999999500004, "Bleu_2": 0.17466675291893885, "Bleu_3": 0.11642276735502893, "Bleu_4": 0.07253702250673588, "METEOR": 0.18383017279683078, "ROUGE_L": 0.19303797468354428, "CIDEr": 6.715687040575182e-15, "SPICE": {"All": {"pr": 0.15, "re": 0.13043478260869565, "f": 0.13953488372093023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a harbor with several boats docked at the pier. The boats are painted in various colors and have different shapes, some of them are small and others are larger. In the background, there is a city with buildings and a castle on top of a hill. The sky is orange and pink, with clouds floating in it."}, "121210": {"image_id": 121210, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.23553456043175583, "Bleu_3": 0.14552767544422202, "Bleu_4": 1.722630701442229e-05, "METEOR": 0.2679193527479828, "ROUGE_L": 0.3116788321167883, "CIDEr": 0.00015193321215853673, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 27.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a plate of food with a stew and vegetables on it. The stew has beef in it and there are carrots and potatoes on the side. There is also a fork and knife on the plate."}, "46551": {"image_id": 46551, "Bleu_1": 0.21428571428316326, "Bleu_2": 0.1524329372008475, "Bleu_3": 0.10426405027865411, "Bleu_4": 0.07273395239286487, "METEOR": 0.22099731446744972, "ROUGE_L": 0.17231638418079095, "CIDEr": 1.4709429735864555e-28, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in a room with a large wooden table in the center. One person is holding a camera and taking pictures of the others, while another person is sitting at the table looking at a computer screen. There are various objects on the table, including a bottle of beer, a book, and a pair of sunglasses. The walls of the room are made of brick and there are several windows on the left side of the image."}, "535588": {"image_id": 535588, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2976467318172675, "Bleu_3": 0.12928241614120298, "Bleu_4": 1.5245427153839246e-05, "METEOR": 0.2534573716853156, "ROUGE_L": 0.2620596538603167, "CIDEr": 3.1648323668887705e-05, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.18181818181818182, "f": 0.1509433962264151, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a bus parked on the side of the road. The bus has a bike rack on the back and a person is standing next to it, looking at their phone. There are trees and buildings in the background."}, "173997": {"image_id": 173997, "Bleu_1": 0.8461538460887575, "Bleu_2": 0.4599331054670464, "Bleu_3": 0.2679161448961319, "Bleu_4": 3.723909894612898e-05, "METEOR": 0.25532454094734547, "ROUGE_L": 0.4834874504623514, "CIDEr": 0.7095674236006434, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A couple sitting on a bench in the park, looking at the water."}, "320396": {"image_id": 320396, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.21442250696028833, "Bleu_3": 1.179761544419741e-06, "Bleu_4": 2.7925742928429696e-09, "METEOR": 0.21796330522437268, "ROUGE_L": 0.3726003490401396, "CIDEr": 0.0020640848164466905, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA man in black pants and a white shirt is throwing a frisbee on a sandy beach with birds flying overhead."}, "221282": {"image_id": 221282, "Bleu_1": 0.16666666666452992, "Bleu_2": 0.08058229640149824, "Bleu_3": 4.404418339157378e-07, "Bleu_4": 1.0331208012085358e-09, "METEOR": 0.19171061303712686, "ROUGE_L": 0.18341924398625428, "CIDEr": 2.6136055079128867e-26, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12121212121212122, "f": 0.14035087719298245, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.14285714285714285, "f": 0.16, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a woman in a kitchen preparing a pizza. She is wearing a white apron and has a wooden cutting board on the counter in front of her. There are several pizzas on the counter, and she is using a knife to cut one of them. The walls of the room are painted a light green color, and there are several windows on the opposite side of the room that let in natural light."}, "25143": {"image_id": 25143, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.3237880628910851, "Bleu_3": 0.27575107927576725, "Bleu_4": 0.24520590089598954, "METEOR": 0.2819355591584615, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.002251367117860898, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1875, "f": 0.1818181818181818, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of people playing frisbee in a park. One person is throwing the frisbee while another person is catching it. There are trees and grass in the background."}, "52835": {"image_id": 52835, "Bleu_1": 0.3749999999765626, "Bleu_2": 0.15811388299820756, "Bleu_3": 1.2132137515201732e-06, "Bleu_4": 3.4234749556315017e-09, "METEOR": 0.1549776364094465, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.1876225038430544, "SPICE": {"All": {"pr": 0.1875, "re": 0.09090909090909091, "f": 0.12244897959183672, "fn": 30.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a lunchbox filled with various food items such as carrots, beans, and oranges."}, "300962": {"image_id": 300962, "Bleu_1": 0.2833333333286111, "Bleu_2": 0.21914059155811866, "Bleu_3": 0.17962711797860478, "Bleu_4": 0.1571621730633555, "METEOR": 0.3353642655901958, "ROUGE_L": 0.30098684210526316, "CIDEr": 3.7772836711784967e-16, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.1724137931034483, "f": 0.18867924528301888, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a baseball player swinging a bat at a ball on a baseball field. The player is wearing a white jersey with the number 12 on the back and blue pants. The ball is flying through the air towards the catcher, who is standing behind home plate. The sky is cloudy and there are trees in the background."}, "332532": {"image_id": 332532, "Bleu_1": 0.38095238093424044, "Bleu_2": 0.276026223723469, "Bleu_3": 0.15887260951182014, "Bleu_4": 2.1725443230337628e-05, "METEOR": 0.19704433497536944, "ROUGE_L": 0.3446327683615819, "CIDEr": 0.1528108371549063, "SPICE": {"All": {"pr": 0.15, "re": 0.16666666666666666, "f": 0.15789473684210525, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are painted orange and there is a wooden floor."}, "528261": {"image_id": 528261, "Bleu_1": 0.25806451612070763, "Bleu_2": 0.09274777914899197, "Bleu_3": 6.669137632818231e-07, "Bleu_4": 1.8041089137611838e-09, "METEOR": 0.2174722369781793, "ROUGE_L": 0.2775250227479527, "CIDEr": 0.0006193772406497243, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14814814814814814, "f": 0.14285714285714285, "fn": 23.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The giraffe is standing in front of a wooden fence, looking out at the grass. It has long legs and a long neck, and its spots are visible on its fur."}, "297046": {"image_id": 297046, "Bleu_1": 0.1874999999960938, "Bleu_2": 0.10939874362111757, "Bleu_3": 0.06383942191769575, "Bleu_4": 8.71994169021714e-06, "METEOR": 0.1762215103921747, "ROUGE_L": 0.12298387096774195, "CIDEr": 7.28291026032754e-09, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.2857142857142857, "f": 0.29629629629629634, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a train traveling down the tracks, with buildings and trees visible in the background. The train is red and has the words \"CPR\" written on it. There are cars parked on the side of the road, and people can be seen walking on the sidewalk."}, "130839": {"image_id": 130839, "Bleu_1": 0.10204081632583648, "Bleu_2": 0.06475691627264721, "Bleu_3": 0.04426989824971935, "Bleu_4": 0.02786061955066738, "METEOR": 0.11089287646057687, "ROUGE_L": 0.10677669417354337, "CIDEr": 4.650778878050287e-114, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.17857142857142858, "f": 0.17543859649122806, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.45454545454545453, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "A man in a black suit and tie is carrying two large suitcases down a staircase at night. The stairs are made of metal and have handrails on either side. There are windows on either side of the stairs that provide a view of the city below. The man is walking down the stairs with his hands full of luggage, looking tired and stressed.\n\nThe image is taken at night, and there are streetlights on either side of the stairs. The sky is dark and cloudy, with a few stars visible in the distance. The building behind the stairs appears to be a hotel or office building, with windows on each floor.\n\nThe overall mood of the image is one of tiredness and stress, as the man carries his heavy luggage down the stairs. The dark and cloudy sky adds to the feeling of fatigue and exhaustion."}, "451120": {"image_id": 451120, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.24866794885861784, "Bleu_3": 0.19153683966557564, "Bleu_4": 0.1487998309407241, "METEOR": 0.24625775550504284, "ROUGE_L": 0.2827814569536423, "CIDEr": 1.3042125932575013e-08, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16129032258064516, "f": 0.18867924528301885, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This image shows a woman standing at a table with various ingredients and kitchen tools. She is wearing a blue sweater and has a friendly expression on her face. The background of the image appears to be a room with a wooden floor and white walls."}, "378134": {"image_id": 378134, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4577377081947216, "Bleu_3": 0.38061268797915826, "Bleu_4": 0.3096168826464989, "METEOR": 0.3027877915202508, "ROUGE_L": 0.4135593220338983, "CIDEr": 0.2122533205239045, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.09375, "f": 0.11764705882352941, "fn": 29.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people playing frisbee on a grassy field at sunset."}, "458953": {"image_id": 458953, "Bleu_1": 0.3015873015825145, "Bleu_2": 0.184526906467268, "Bleu_3": 0.11875090841855829, "Bleu_4": 0.07268417959828058, "METEOR": 0.209437946926502, "ROUGE_L": 0.2663755458515284, "CIDEr": 2.1443401823037764e-15, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.23529411764705882, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of a field with a group of people flying kites in the background. The sky is clear and blue, with a few clouds scattered across it. There are several people standing on the grassy hillside, holding their kites and watching them fly. In the distance, there is a body of water that appears to be a lake or river."}, "159451": {"image_id": 159451, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.24671758189216153, "Bleu_3": 0.1905340106122511, "Bleu_4": 0.14821514446378253, "METEOR": 0.25195501953841515, "ROUGE_L": 0.27619663648124193, "CIDEr": 9.432563282308485e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is an image of a yellow tractor parked on a dirt road in front of a large building. The tractor has a front end loader and is parked next to a pile of dirt and gravel. There are trees and buildings visible in the background."}, "294258": {"image_id": 294258, "Bleu_1": 0.28787878787442606, "Bleu_2": 0.23053601268615334, "Bleu_3": 0.18798759389850128, "Bleu_4": 0.14331008461266712, "METEOR": 0.2572445045217868, "ROUGE_L": 0.28800755429650615, "CIDEr": 1.249178607661977e-16, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14814814814814814, "f": 0.19047619047619047, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.23076923076923078, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a man in a suit and tie standing outside a building. He is wearing a red striped shirt underneath the tie and a black suit jacket. The man has a serious expression on his face and is looking down at something in his hand. There are other people in the background, but they are not visible due to the angle of the camera."}, "544695": {"image_id": 544695, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.14564381624761055, "Bleu_3": 7.901421228222159e-07, "Bleu_4": 1.8512564664694888e-09, "METEOR": 0.19651197978559626, "ROUGE_L": 0.24063116370808676, "CIDEr": 4.3949178430561524e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.13043478260869565, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A man and a woman are playing tennis on a court. The man is holding a racket and hitting the ball with his other hand, while the woman is standing behind him and watching. There are trees in the background and a blue sky above."}, "623": {"image_id": 623, "Bleu_1": 0.2173913043446755, "Bleu_2": 0.12643043435419762, "Bleu_3": 0.08945059574131524, "Bleu_4": 0.0682431308327574, "METEOR": 0.22964121172776364, "ROUGE_L": 0.1952446273433928, "CIDEr": 1.5397323893809796e-20, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The woman is sitting on the floor next to a large stuffed bear. She is wearing a black shirt and pants, and has her arms around the bear's neck. The bear is wearing a white apron with red trim, and has its paws on the woman's shoulders. The room appears to be a restaurant or cafe, with tables and chairs set up in front of the windows."}, "236690": {"image_id": 236690, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2387049580041334, "Bleu_3": 0.1658075448734274, "Bleu_4": 0.11739521785616198, "METEOR": 0.193729577635694, "ROUGE_L": 0.31671858774662515, "CIDEr": 0.00841374184181509, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.4166666666666667, "f": 0.2631578947368421, "fn": 7.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.8, "f": 0.47058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a seagull flying over the ocean with its wings spread wide. The sky is blue and cloudy, and there are waves in the distance."}, "382088": {"image_id": 382088, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.1877669040449484, "Bleu_3": 0.14066689992484502, "Bleu_4": 0.11075185402506073, "METEOR": 0.26298089099122585, "ROUGE_L": 0.32250755287009064, "CIDEr": 2.2842601200684196e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.13333333333333333, "f": 0.1739130434782609, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA beautiful white horse standing in a field with a fence in the background. The horse has a flowing mane and tail, and its eyes are looking directly at the camera."}, "504711": {"image_id": 504711, "Bleu_1": 0.6363636363347108, "Bleu_2": 0.5773502691627578, "Bleu_3": 0.5108729549046713, "Bleu_4": 0.4328015276059101, "METEOR": 0.49037203760017767, "ROUGE_L": 0.6832993890020366, "CIDEr": 0.7178718138195763, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a piece of chocolate cake with frosting on top, sitting on a plate with a fork next to it."}, "495348": {"image_id": 495348, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.2433792297516304, "Bleu_3": 0.14360812424536362, "Bleu_4": 1.6600382900059705e-05, "METEOR": 0.24033225642045494, "ROUGE_L": 0.2881241565452092, "CIDEr": 1.9935700594750336e-06, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a group of zebras grazing in a grassy field surrounded by trees. There are several other animals in the background, including a giraffe and some antelopes. The sky is clear and blue, with a few clouds scattered across it."}, "326217": {"image_id": 326217, "Bleu_1": 0.6666666666296297, "Bleu_2": 0.3429971702654019, "Bleu_3": 0.1944555593549452, "Bleu_4": 2.646015952198224e-05, "METEOR": 0.23569765162038217, "ROUGE_L": 0.3940568475452197, "CIDEr": 0.43622862742613355, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.1875, "f": 0.19047619047619047, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people in a boat on a river, surrounded by fruit and vegetables."}, "59752": {"image_id": 59752, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.21821789022534133, "Bleu_3": 1.3583417042548598e-06, "Bleu_4": 3.435094189227651e-09, "METEOR": 0.26394598012755305, "ROUGE_L": 0.4135593220338983, "CIDEr": 0.08145152902602122, "SPICE": {"All": {"pr": 0.15, "re": 0.17647058823529413, "f": 0.16216216216216214, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a photograph of a river with boats docked on both sides. There are trees and buildings in the background."}, "437393": {"image_id": 437393, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.3107277331223966, "Bleu_3": 0.21789189983999352, "Bleu_4": 0.13990713818737435, "METEOR": 0.26710009326551193, "ROUGE_L": 0.34078212290502796, "CIDEr": 0.002348120799016281, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "This is a white horse with blue and pink accents on its mane and tail. It has a pink rose on its head and a blue ribbon around its neck."}, "279209": {"image_id": 279209, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.10540925533597618, "Bleu_3": 6.887995549333558e-07, "Bleu_4": 1.7739491161500997e-09, "METEOR": 0.20778383865626204, "ROUGE_L": 0.22897897897897898, "CIDEr": 9.86076585045635e-05, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.13043478260869565, "f": 0.1764705882352941, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A person is skiing down a snowy mountain trail with trees on either side. The person is wearing a black and red jacket, blue pants, and black skis. The sign in the background reads \"Ski Resort\"."}, "202228": {"image_id": 202228, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.3073547405967436, "Bleu_3": 0.19712110312662995, "Bleu_4": 0.14362555317372588, "METEOR": 0.3097579288457601, "ROUGE_L": 0.34183928750125087, "CIDEr": 2.812689249926389e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.1935483870967742, "f": 0.23076923076923075, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a man standing in front of a mirror, taking a selfie. He is wearing a red jacket and black pants, and has a hat on his head. The mirror is reflecting the image of the man."}, "193661": {"image_id": 193661, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.1996674976872179, "Bleu_3": 0.15726435388931506, "Bleu_4": 0.11809057094527546, "METEOR": 0.2132248228583972, "ROUGE_L": 0.3238221632382216, "CIDEr": 4.22219076810973e-06, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a living room with a fireplace and hardwood floors. There are two chairs in front of the fireplace and a television on the wall. The walls are painted yellow and there are white trim and molding around the windows and doors."}, "457060": {"image_id": 457060, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.16516802780065545, "Bleu_3": 0.13468197343591923, "Bleu_4": 0.11030904314820933, "METEOR": 0.21837857065648322, "ROUGE_L": 0.19796012980992117, "CIDEr": 3.8134262823600935e-19, "SPICE": {"All": {"pr": 0.2, "re": 0.2631578947368421, "f": 0.22727272727272727, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows two giraffes standing next to each other in a fenced enclosure. One of the giraffes is looking directly at the camera while the other is looking off to the side. Both giraffes have long necks and spotted coats. The fence in the background is made of metal bars and has a gate that is open. There are trees in the background, and the sky is cloudy."}, "390215": {"image_id": 390215, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.09125318612878565, "Bleu_4": 1.1336958836408244e-05, "METEOR": 0.28199235246206994, "ROUGE_L": 0.31504196255648803, "CIDEr": 2.243379193723927e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.15, "f": 0.19354838709677416, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a plate with two roasted chicken breasts on it, next to a bowl of broccoli. The chicken breasts are seasoned with herbs and spices, and the broccoli is steamed. The plate is on a white tablecloth, and there is a fork and knife on the side."}, "579635": {"image_id": 579635, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.2620817976974896, "Bleu_3": 0.17306899825616445, "Bleu_4": 0.09992257656080383, "METEOR": 0.24671030322085866, "ROUGE_L": 0.2987174504469491, "CIDEr": 5.1351430591840155e-12, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.08571428571428572, "f": 0.13043478260869562, "fn": 32.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.1875, "f": 0.2727272727272727, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on the ocean. The surfer is wearing a black wetsuit and standing on a surfboard, with his arms outstretched to balance himself. The wave is large and white, with a sailboat in the distance. The sky is clear and blue, with a sun setting in the background."}, "251920": {"image_id": 251920, "Bleu_1": 0.27999999998880004, "Bleu_2": 0.15275252315895732, "Bleu_3": 0.10048077661732781, "Bleu_4": 1.4654012818359005e-05, "METEOR": 0.19530191462083643, "ROUGE_L": 0.26180257510729615, "CIDEr": 0.09861824283713472, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.18518518518518517, "f": 0.18867924528301885, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "There are three pizzas on the stove top, one with pepperoni and mushrooms, one with cheese and tomato sauce, and one with ham and pineapple."}, "271117": {"image_id": 271117, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.23445316701614308, "Bleu_3": 0.17363647849776928, "Bleu_4": 0.13989915023174126, "METEOR": 0.27612031754972477, "ROUGE_L": 0.35835509138381205, "CIDEr": 8.018809056648675e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a small room with a desk, chair, and bookshelf. There are several books on the shelf, as well as a lamp and a vase of flowers on the desk. The walls are painted yellow and there is a window in the background."}, "11051": {"image_id": 11051, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.3009646327016102, "Bleu_3": 0.16027633953001283, "Bleu_4": 2.1042495246621463e-05, "METEOR": 0.20608244278312962, "ROUGE_L": 0.45692883895131087, "CIDEr": 0.042895651918278446, "SPICE": {"All": {"pr": 0.15555555555555556, "re": 0.35, "f": 0.21538461538461537, "fn": 13.0, "numImages": 1.0, "fp": 38.0, "tp": 7.0}, "Relation": {"pr": 0.0625, "re": 0.125, "f": 0.08333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.5, "f": 0.1818181818181818, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "The image shows a young woman in a black dress and a man in a tuxedo standing next to each other, both holding flowers."}, "170605": {"image_id": 170605, "Bleu_1": 0.2741935483826743, "Bleu_2": 0.17738329521250532, "Bleu_3": 0.10160179812238379, "Bleu_4": 1.1546837198050896e-05, "METEOR": 0.17134425863684194, "ROUGE_L": 0.1769483658866757, "CIDEr": 1.7151268239290318e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1, "f": 0.09302325581395349, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people on snowmobiles in the middle of a snowy field. One person is flying an airplane overhead, while another person is standing on the ground and looking up at it. There are several other people in the background, some of whom are also looking up at the plane. The sun is shining brightly in the sky."}, "84123": {"image_id": 84123, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2976467318172675, "Bleu_3": 0.20522304338353606, "Bleu_4": 0.14418234806412633, "METEOR": 0.2024479998992281, "ROUGE_L": 0.283344392833444, "CIDEr": 9.490491147946351e-06, "SPICE": {"All": {"pr": 0.1875, "re": 0.07692307692307693, "f": 0.1090909090909091, "fn": 36.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a street with cars parked on the side of the road. There are signs on the street indicating the direction of traffic and parking restrictions. The sky is cloudy and there is no sunlight visible in the image."}, "505899": {"image_id": 505899, "Bleu_1": 0.4857142857004082, "Bleu_2": 0.4309458036731736, "Bleu_3": 0.35574635021034584, "Bleu_4": 0.30311376420535113, "METEOR": 0.36841378874316066, "ROUGE_L": 0.4445344129554656, "CIDEr": 0.0003998385529550472, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.07894736842105263, "f": 0.09230769230769231, "fn": 35.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.21428571428571427, "f": 0.23999999999999996, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A plate of donuts and a cup of coffee on a wooden table\n\nThe plate has three donuts on it, each one topped with glaze. The cup of coffee is sitting next to the plate."}, "256814": {"image_id": 256814, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.17541160385696436, "Bleu_3": 9.32061023993367e-07, "Bleu_4": 2.1628820160400856e-09, "METEOR": 0.20983647970254463, "ROUGE_L": 0.2764350453172206, "CIDEr": 4.417928000677277e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13636363636363635, "f": 0.16666666666666663, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a man and two women holding up a donut. One of the women is smiling and the other two are looking at the camera. The man is wearing sunglasses and has a serious expression on his face."}, "419680": {"image_id": 419680, "Bleu_1": 0.24999999999632352, "Bleu_2": 0.16161498378646913, "Bleu_3": 0.07341865714123474, "Bleu_4": 8.833371352550806e-06, "METEOR": 0.1855148714989831, "ROUGE_L": 0.2037213740458015, "CIDEr": 1.3488425161620702e-20, "SPICE": {"All": {"pr": 0.1875, "re": 0.10344827586206896, "f": 0.13333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a street scene in New Orleans, Louisiana. The building on the left has a sign that reads \"No Parking\" in white letters on a green background. There are also several other signs on the building, including one that reads \"No Trespassing\" in red letters on a white background. The street is lined with tall trees and there are cars parked along the side of the road."}, "519555": {"image_id": 519555, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1922322627296484, "Bleu_3": 0.14352058006177876, "Bleu_4": 0.10480792301723448, "METEOR": 0.2435262616677926, "ROUGE_L": 0.25722891566265055, "CIDEr": 6.020612585234701e-11, "SPICE": {"All": {"pr": 0.1, "re": 0.05555555555555555, "f": 0.07142857142857142, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "This is an image of a stop sign in the middle of a field. The sign is made of metal and has the words \"stop\" written on it in white letters. There are no other objects or people in the image, just the sign and some grass and trees in the background."}, "354929": {"image_id": 354929, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.2285817953234835, "Bleu_3": 0.14539343121758774, "Bleu_4": 0.0885454171445769, "METEOR": 0.25706642102889504, "ROUGE_L": 0.27774615822424586, "CIDEr": 2.7128678284306287e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a group of people riding bicycles down a street at night. They are wearing helmets and have their lights on, and the road is lit up with streetlights. There are buildings on either side of the street, and there are cars parked along the side of the road."}, "17379": {"image_id": 17379, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 0.07502652544655376, "Bleu_4": 9.635230436528825e-06, "METEOR": 0.2557314796144292, "ROUGE_L": 0.22870915907873593, "CIDEr": 2.167431752386065e-09, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.3333333333333333, "f": 0.3125, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a bathroom with a large mirror on the wall. The mirror has a television mounted on it, showing a sports game. There are two sinks in the room, one on each side of the mirror. The walls are made of tiles and the floor is made of tile as well."}, "13965": {"image_id": 13965, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.14953924108841646, "Bleu_3": 0.07548065617692518, "Bleu_4": 9.582618669737836e-06, "METEOR": 0.19398465652327915, "ROUGE_L": 0.2684268426842684, "CIDEr": 2.5657876905210305e-11, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3, "f": 0.3243243243243243, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a green and white trolley car parked at a train station. The trolley car has the words \"Green Line\" written on the side in white letters. There are several other cars parked next to it, and people can be seen standing on the platform waiting to board the trolley."}, "422836": {"image_id": 422836, "Bleu_1": 0.1904761904716554, "Bleu_2": 0.06815981765745711, "Bleu_3": 4.879016455216701e-07, "Bleu_4": 1.3136602547196461e-09, "METEOR": 0.1554240233904631, "ROUGE_L": 0.22197962154294032, "CIDEr": 3.570579087515105e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 30.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.21428571428571427, "f": 0.2608695652173913, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man standing on the sidewalk, looking at his phone. He is wearing a black jacket and jeans, and has a backpack slung over his shoulder. There are several buildings in the background, including a caf\u00e9 with outdoor seating."}, "513292": {"image_id": 513292, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.18971331171167066, "Bleu_3": 0.09574966238312985, "Bleu_4": 1.2171327283748823e-05, "METEOR": 0.25787285201724863, "ROUGE_L": 0.29387474191328283, "CIDEr": 1.14318366205108e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.2777777777777778, "f": 0.2631578947368421, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a young boy holding a skateboard in his hand while walking on the sidewalk. He is wearing red shorts and a black shirt with white letters on it. The background is a grassy area with some trees in the distance."}, "202444": {"image_id": 202444, "Bleu_1": 0.2153846153813018, "Bleu_2": 0.12971863041368145, "Bleu_3": 6.440032414686258e-07, "Bleu_4": 1.4406819585573353e-09, "METEOR": 0.14647057479047979, "ROUGE_L": 0.15649050795279631, "CIDEr": 3.3986055378255212e-18, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a skateboarder performing a trick on a half pipe. The skateboarder is wearing a black shirt and jeans, and has his arms outstretched as he jumps off the ramp. There are several people watching from the sidelines, including a man in a yellow shirt and a woman in a green shirt. The background is a park with trees and grass."}, "268541": {"image_id": 268541, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.25819888973988653, "Bleu_3": 0.19868417242611314, "Bleu_4": 0.14765612529678226, "METEOR": 0.29159142395042503, "ROUGE_L": 0.3408365261813538, "CIDEr": 0.00016802856388422758, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.375, "f": 0.30769230769230765, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The man is holding a cup of coffee in his hand and looking at the camera. He is wearing a suit and tie, and has a beard. There are several books on the shelf behind him."}, "377999": {"image_id": 377999, "Bleu_1": 0.32758620689090373, "Bleu_2": 0.21442250696382964, "Bleu_3": 0.11797615444397525, "Bleu_4": 0.0739188164316642, "METEOR": 0.18646910249578946, "ROUGE_L": 0.2643553629469122, "CIDEr": 3.248864570748335e-13, "SPICE": {"All": {"pr": 0.10810810810810811, "re": 0.14814814814814814, "f": 0.125, "fn": 23.0, "numImages": 1.0, "fp": 33.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.36363636363636365, "f": 0.2962962962962963, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a man standing on the shore of a body of water, looking out at a sailboat in the distance. The sky is clear and blue, with a few clouds scattered across it. The water is calm and reflects the colors of the sky. There are some buildings visible in the background, including a church steeple."}, "272694": {"image_id": 272694, "Bleu_1": 0.9999999998000004, "Bleu_2": 0.816496580759891, "Bleu_3": 0.6933612742036167, "Bleu_4": 0.6147881528161697, "METEOR": 0.29629404242286655, "ROUGE_L": 0.7070186735350935, "CIDEr": 2.282277256720819, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.21875, "f": 0.2641509433962264, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.38461538461538464, "f": 0.4545454545454546, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "A cup of coffee and a banana on a table."}, "137844": {"image_id": 137844, "Bleu_1": 0.17721518987117452, "Bleu_2": 0.12611077390900094, "Bleu_3": 5.911139639289716e-07, "Bleu_4": 1.283955630289815e-09, "METEOR": 0.21565728429719505, "ROUGE_L": 0.20899357601713062, "CIDEr": 4.197016654115924e-30, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a skateboarder performing a trick on a halfpipe in a park. The skateboarder is wearing a black and white striped shirt and black pants, and has a red helmet on their head. The halfpipe is made of concrete and has a steep slope leading up to the top. There are several people watching from the sidelines, including a man with a camera around his neck. The sky is blue and there are mountains in the background."}, "374829": {"image_id": 374829, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.12366938847771936, "Bleu_3": 0.0678332745017197, "Bleu_4": 8.979905725239549e-06, "METEOR": 0.1797403674444341, "ROUGE_L": 0.2238532110091743, "CIDEr": 2.3129097173067227e-08, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.11538461538461539, "f": 0.15, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a baseball player in the middle of a swing, with his bat raised and ready to hit the ball. The crowd is watching from behind the fence, and there are several umpires standing on the field. The sky is cloudy and there are some trees in the background."}, "21465": {"image_id": 21465, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.1594482010331402, "Bleu_3": 0.07596328743558894, "Bleu_4": 9.36448933840202e-06, "METEOR": 0.140871039885856, "ROUGE_L": 0.2006578947368421, "CIDEr": 3.6867421790975705e-16, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a small, blue shelf with several items on it. There are two vases on the shelf, one with flowers and the other with a candle. There is also a small wooden box with a handle on top of the shelf. The floor is made of wood and there are some plants in pots on it."}, "281929": {"image_id": 281929, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.10540925533701173, "Bleu_3": 5.940557542491763e-07, "Bleu_4": 1.416999083410831e-09, "METEOR": 0.18808777429467083, "ROUGE_L": 0.24358243011979464, "CIDEr": 8.102589549865267e-13, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.2962962962962963, "f": 0.3333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.6363636363636364, "f": 0.6666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The man is standing in front of a house wearing a brown suit and holding a black bicycle. The house has a white facade with windows on the second floor and a balcony on the first floor. There are plants and flowers in pots on the balcony, and a car is parked in the driveway."}, "464814": {"image_id": 464814, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.2531848417613592, "Bleu_3": 0.21726934816097013, "Bleu_4": 0.1892240568721587, "METEOR": 0.28868031002481914, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.021345860150676178, "SPICE": {"All": {"pr": 0.4375, "re": 0.21875, "f": 0.2916666666666667, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8571428571428571, "re": 0.4, "f": 0.5454545454545455, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}}, "caption": "This is a living room with a couch, coffee table, and TV. The walls are painted white and there are windows on one side of the room."}, "213538": {"image_id": 213538, "Bleu_1": 0.39999999999, "Bleu_2": 0.2480694691721357, "Bleu_3": 0.1693667280474557, "Bleu_4": 0.10704604894315069, "METEOR": 0.22790176235134102, "ROUGE_L": 0.2937534397358283, "CIDEr": 0.0001444077849527036, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.030303030303030304, "f": 0.041666666666666664, "fn": 32.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "This is a computer desk with a red curtain behind it. There are two computers on the desk, one with a keyboard and mouse, and the other with a monitor. There is also a cup of coffee on the desk."}, "461573": {"image_id": 461573, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.0973123680171955, "Bleu_3": 6.734801438348329e-07, "Bleu_4": 1.7863365456276687e-09, "METEOR": 0.1685937990393695, "ROUGE_L": 0.2059071729957806, "CIDEr": 0.00020989131239301106, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.20689655172413793, "f": 0.25, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a park bench made of metal with two seats and a backrest. The bench is located on the sidewalk in front of a building with greenery around it."}, "360629": {"image_id": 360629, "Bleu_1": 0.624999999921875, "Bleu_2": 0.4999999999364584, "Bleu_3": 0.37697372051580974, "Bleu_4": 0.3013040488881211, "METEOR": 0.2675380970032834, "ROUGE_L": 0.505524861878453, "CIDEr": 0.7053910386781319, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.29411764705882354, "f": 0.2631578947368421, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a tray filled with various types of food, including sushi rolls, rice, and vegetables."}, "114745": {"image_id": 114745, "Bleu_1": 0.5499999999725, "Bleu_2": 0.24061325158054672, "Bleu_3": 1.476121796196066e-06, "Bleu_4": 3.708765841904931e-09, "METEOR": 0.20231255884724333, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.12051627024871375, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.2, "f": 0.14634146341463417, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A gorilla rides a skateboard down a ramp at an event.\""}, "548878": {"image_id": 548878, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.1390096093683277, "Bleu_3": 0.07601144519394981, "Bleu_4": 1.0052917730118351e-05, "METEOR": 0.20986033047580907, "ROUGE_L": 0.2794502617801047, "CIDEr": 8.354097884815463e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2, "f": 0.23076923076923075, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a person wearing a snowboarding helmet and goggles jumping off a ramp in the air. The person is wearing a black and red jacket with white pants and black boots. The background is a city skyline with tall buildings and a blue sky."}, "385985": {"image_id": 385985, "Bleu_1": 0.37096774192950055, "Bleu_2": 0.23395073312491413, "Bleu_3": 0.13987484182449395, "Bleu_4": 1.467545933692982e-05, "METEOR": 0.20886138449142566, "ROUGE_L": 0.21311639049710518, "CIDEr": 1.7880424374219093e-12, "SPICE": {"All": {"pr": 0.8571428571428571, "re": 0.3157894736842105, "f": 0.46153846153846156, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5714285714285714, "f": 0.7272727272727273, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "The image shows a young couple sitting on the ground, both holding cell phones in their hands. The woman is wearing black ripped jeans and a white t-shirt, while the man is wearing a black t-shirt and blue jeans. They are both looking at their phones intently, with their heads bent down towards the screens. The background is a dark, graffiti-covered wall."}, "289714": {"image_id": 289714, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.1027737074612707, "Bleu_4": 0.0696982798311994, "METEOR": 0.2243800282832596, "ROUGE_L": 0.19242902208201892, "CIDEr": 7.454509708100537e-10, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.15625, "f": 0.17857142857142858, "fn": 27.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is an image of a kitchen with green walls and yellow tiles on the floor. There is a woman standing in front of the stove, wearing a white apron and holding a mixing bowl. The room has a vintage feel to it, with old fashioned appliances and decorations."}, "230226": {"image_id": 230226, "Bleu_1": 0.517241379292509, "Bleu_2": 0.3039153369167485, "Bleu_3": 1.5067706657715286e-06, "Bleu_4": 3.386819335316256e-09, "METEOR": 0.26342884458655075, "ROUGE_L": 0.3010858835143139, "CIDEr": 0.0025758349248353974, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.26666666666666666, "f": 0.19047619047619047, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a clear plastic container filled with various toiletries such as toothbrushes, toothpaste, and floss. It is hanging on the wall next to a sink in a bathroom."}, "319534": {"image_id": 319534, "Bleu_1": 0.1538461538441815, "Bleu_2": 0.10948978028885897, "Bleu_3": 0.05403118909678745, "Bleu_4": 6.772017601230833e-06, "METEOR": 0.18986854503982756, "ROUGE_L": 0.22536945812807885, "CIDEr": 3.134584016015798e-26, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.13793103448275862, "f": 0.21052631578947367, "fn": 25.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.08333333333333333, "f": 0.14285714285714285, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThe woman in the image is standing on the side of a bus, looking out at the people on the street. She is wearing a white shirt and jeans, and her hair is tied back in a ponytail. The bus is green and has a number on the side. There are other people on the bus, including children and adults. The image was taken in a busy city street."}, "427476": {"image_id": 427476, "Bleu_1": 0.32758620689090373, "Bleu_2": 0.22742941306971548, "Bleu_3": 0.12270014518239296, "Bleu_4": 1.3537645428326462e-05, "METEOR": 0.2719736762818851, "ROUGE_L": 0.25649496921459675, "CIDEr": 9.945865557895177e-14, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.043478260869565216, "f": 0.038461538461538464, "fn": 22.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The little girl is standing in the bathroom, looking at the toilet. She is wearing a white shirt and jeans, and her hair is tied back in a ponytail. The bathroom has a white tile floor and a white bathtub with a shower head attached to it. There is also a sink in the corner of the room."}, "101223": {"image_id": 101223, "Bleu_1": 0.39999999999, "Bleu_2": 0.267945650816049, "Bleu_3": 0.155756653561564, "Bleu_4": 0.10052741725150512, "METEOR": 0.27382337313381716, "ROUGE_L": 0.33242506811989103, "CIDEr": 2.5013090437891272e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a view of the mountains from an airplane window. The sky is clear and blue, with snow covered peaks in the distance. The plane's wing is visible in the foreground, with a runway in the background."}, "123570": {"image_id": 123570, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.22493385270597108, "Bleu_3": 0.14781244934349233, "Bleu_4": 0.09153639452791133, "METEOR": 0.2904446222738783, "ROUGE_L": 0.28393317263735346, "CIDEr": 2.1537910879792134e-08, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.037037037037037035, "f": 0.047619047619047616, "fn": 26.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a woman standing in front of a store at night, holding an umbrella. She is wearing a black dress and has her hair tied back in a ponytail. The building behind her is lit up with neon lights, and there are cars parked along the street."}, "368581": {"image_id": 368581, "Bleu_1": 0.7272727271404961, "Bleu_2": 0.5393598898700768, "Bleu_3": 0.4013422918623043, "Bleu_4": 5.331675362351891e-05, "METEOR": 0.1862030900381086, "ROUGE_L": 0.4853375767219823, "CIDEr": 0.514963184872115, "SPICE": {"All": {"pr": 0.03125, "re": 0.041666666666666664, "f": 0.03571428571428572, "fn": 23.0, "numImages": 1.0, "fp": 31.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "This is a lunchbox with a sandwich, fruit, and vegetables inside."}, "446984": {"image_id": 446984, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.2451550735724403, "Bleu_3": 0.1774834119198727, "Bleu_4": 0.10741279167487963, "METEOR": 0.32309752631754396, "ROUGE_L": 0.28754208754208754, "CIDEr": 5.512454354306577e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.38461538461538464, "f": 0.27777777777777773, "fn": 8.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.3333333333333333, "f": 0.2, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.75, "f": 0.39999999999999997, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a group of people on bicycles standing in front of a park. They are wearing yellow vests and helmets, and one person is holding a pair of scissors. The background is a green field with trees and a river in the distance."}, "514668": {"image_id": 514668, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.31565436976372857, "Bleu_3": 0.23862030429939607, "Bleu_4": 0.15948715930717874, "METEOR": 0.3332974610330624, "ROUGE_L": 0.428714859437751, "CIDEr": 0.06761991889212764, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.15625, "f": 0.22222222222222224, "fn": 27.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a cat sitting in the back seat of a car looking out the window at a mountain range in the distance."}, "532129": {"image_id": 532129, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.2506402059074552, "Bleu_3": 0.17053481135943918, "Bleu_4": 0.10759927692070036, "METEOR": 0.23691502989896643, "ROUGE_L": 0.23036253776435048, "CIDEr": 5.184942194829523e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.13333333333333333, "f": 0.1739130434782609, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.08333333333333333, "f": 0.14285714285714285, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a pizza that has been cut into slices and placed on a plate. The pizza appears to be topped with cheese, pepperoni, and other toppings. There are two glasses of water on the table next to the pizza."}, "200168": {"image_id": 200168, "Bleu_1": 0.2857142857040817, "Bleu_2": 0.14547859348536976, "Bleu_3": 9.337019798776129e-07, "Bleu_4": 2.3887527916706003e-09, "METEOR": 0.16497619359715274, "ROUGE_L": 0.2469635627530364, "CIDEr": 0.004527720730541213, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2, "f": 0.17857142857142855, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a helmet and holding skis, and there are trees in the background."}, "470801": {"image_id": 470801, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.19802950859148932, "Bleu_3": 0.11619120889626242, "Bleu_4": 1.3376143914343889e-05, "METEOR": 0.23883483101116276, "ROUGE_L": 0.28773584905660377, "CIDEr": 3.090610545966851e-11, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.19047619047619047, "f": 0.20512820512820512, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A woman is holding a kite in her hand and flying it in the sky. The kite has a red and white design with a smiley face on it. The woman is wearing a black shirt and jeans, and she is standing in front of a blue sky with fluffy white clouds."}, "138713": {"image_id": 138713, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.08268590713763764, "Bleu_4": 1.0646588104479637e-05, "METEOR": 0.16571323144765257, "ROUGE_L": 0.23843648208469054, "CIDEr": 6.698608940675485e-08, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.23333333333333334, "f": 0.26415094339622636, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.06666666666666667, "f": 0.08, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "This image shows a group of people playing frisbee in a park. One person is throwing the frisbee while another person is catching it. The other people are watching and cheering from the sidelines. The sky is clear and sunny, with a few clouds in the distance."}, "195917": {"image_id": 195917, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.19957280121567952, "Bleu_3": 0.10342687475822786, "Bleu_4": 1.3333925991412677e-05, "METEOR": 0.2679763755021114, "ROUGE_L": 0.28249459709786967, "CIDEr": 5.920082609261607e-05, "SPICE": {"All": {"pr": 0.125, "re": 0.21052631578947367, "f": 0.1568627450980392, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The man in the image is holding a toothbrush and brushing his teeth. He has long hair and is wearing a black shirt. There are other people in the background of the image, but they are not visible."}, "145391": {"image_id": 145391, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.11639071281079828, "Bleu_3": 7.946165946823695e-07, "Bleu_4": 2.0959208882844414e-09, "METEOR": 0.20403071221324967, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.1178823395977114, "SPICE": {"All": {"pr": 0.5, "re": 0.1935483870967742, "f": 0.27906976744186046, "fn": 25.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a roll of tape with various colors and patterns on it. There are also scissors and other crafting supplies on the table next to the tape."}, "459303": {"image_id": 459303, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.1968748077349065, "Bleu_3": 9.81443897779543e-07, "Bleu_4": 2.204875701880168e-09, "METEOR": 0.20198552096914552, "ROUGE_L": 0.25505226480836235, "CIDEr": 6.763260697466024e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.15384615384615385, "f": 0.2666666666666667, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a train traveling down the tracks in a station. There are people standing on the platform and others waiting to board the train. The train is painted in black and yellow colors with the words \"train\" written on the side."}, "497334": {"image_id": 497334, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.19166296949610964, "Bleu_3": 0.0914699403543824, "Bleu_4": 1.129625096611556e-05, "METEOR": 0.23703710127493416, "ROUGE_L": 0.25386444708680145, "CIDEr": 6.335013197740024e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.02702702702702703, "f": 0.045454545454545456, "fn": 36.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image shows a book lying on a bed with a red cover. The book has a white page with black text on it. There is a blank space in the middle of the page where the text would go. The book is open and the pages are spread out."}, "173138": {"image_id": 173138, "Bleu_1": 0.2857142857040817, "Bleu_2": 0.10286889997098608, "Bleu_3": 7.410797525412568e-07, "Bleu_4": 2.0086936594431116e-09, "METEOR": 0.1384714437687119, "ROUGE_L": 0.21554770318021202, "CIDEr": 0.002001647151647645, "SPICE": {"All": {"pr": 0.25, "re": 0.1875, "f": 0.21428571428571427, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a person standing on the beach, looking out at the ocean. There are waves crashing against the shore and the sky is clear and blue."}, "404984": {"image_id": 404984, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.315328111933741, "Bleu_3": 0.23410349247718354, "Bleu_4": 0.17101456687983987, "METEOR": 0.3586416176643412, "ROUGE_L": 0.39967239967239965, "CIDEr": 0.0008124546731376915, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and television. The walls are painted white and there are wooden floors. There is a wooden bench in the corner of the room."}, "427965": {"image_id": 427965, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.3973597070991224, "Bleu_3": 0.32737967506077853, "Bleu_4": 0.2805155031864108, "METEOR": 0.3471061696642509, "ROUGE_L": 0.4765625, "CIDEr": 0.28687030662387514, "SPICE": {"All": {"pr": 0.24, "re": 0.3333333333333333, "f": 0.27906976744186046, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a living room with a couch, chair, and coffee table. There are also two dogs in the room."}, "445834": {"image_id": 445834, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.07347183583515587, "Bleu_3": 5.26437340454787e-07, "Bleu_4": 1.4188431559098949e-09, "METEOR": 0.13872832369942195, "ROUGE_L": 0.22846441947565538, "CIDEr": 4.8600459091895436e-06, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.28, "f": 0.29787234042553196, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "This is an image of a bus parked in front of a building. The bus has a large window on the side and a door on the back. There are several people standing around the bus, looking at it."}, "386958": {"image_id": 386958, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.15512630699387414, "Bleu_3": 9.093693442749552e-07, "Bleu_4": 2.2192938453856764e-09, "METEOR": 0.2309294110379753, "ROUGE_L": 0.25979557069846676, "CIDEr": 0.0007421860393253936, "SPICE": {"All": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a fire hydrant on the side of a road. The hydrant is painted with yellow and green stripes, and there are some leaves on the ground next to it."}, "306135": {"image_id": 306135, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.19871830896102974, "Bleu_3": 0.09957231203386964, "Bleu_4": 1.2613563322945842e-05, "METEOR": 0.25038937329223504, "ROUGE_L": 0.29047619047619044, "CIDEr": 3.863982787333408e-06, "SPICE": {"All": {"pr": 0.1891891891891892, "re": 0.21875, "f": 0.20289855072463767, "fn": 25.0, "numImages": 1.0, "fp": 30.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.6666666666666666, "f": 0.26666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 1.0, "f": 0.33333333333333337, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man walking down a set of stairs in front of a building with columns and arches. There are people standing on the steps and others walking by. The sky is blue and there are trees in the background."}, "335839": {"image_id": 335839, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.23063280200236536, "Bleu_3": 0.15138000825437875, "Bleu_4": 1.6662810872720654e-05, "METEOR": 0.24119564691133655, "ROUGE_L": 0.32562277580071175, "CIDEr": 5.5437856674855756e-08, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.07692307692307693, "f": 0.0975609756097561, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a man standing on the sidewalk in front of a brick building with graffiti on the walls. He is wearing a black jacket and pants, and has a red hat on his head. There are other buildings in the background with similar graffiti on them."}, "190313": {"image_id": 190313, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.31382295722076564, "Bleu_3": 0.2812129107965588, "Bleu_4": 0.25824620057735515, "METEOR": 0.326675826053803, "ROUGE_L": 0.4262895174708818, "CIDEr": 0.004736630460810905, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The woman is sitting on a bench outside of a store. She is wearing a black jacket and has her hands in her pockets. There are other people walking by in the background."}, "85328": {"image_id": 85328, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.26726124189937955, "Bleu_3": 1.5549130951147036e-06, "Bleu_4": 3.801556631685876e-09, "METEOR": 0.20394411174117272, "ROUGE_L": 0.26492942453854507, "CIDEr": 0.10928800598329844, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.22727272727272727, "f": 0.27027027027027023, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is an image of a train on the tracks, with people standing on the platform and buildings in the background."}, "104002": {"image_id": 104002, "Bleu_1": 0.4374999999726563, "Bleu_2": 0.1707825127549637, "Bleu_3": 1.2771823872371912e-06, "Bleu_4": 3.5579828676919253e-09, "METEOR": 0.23021055431705648, "ROUGE_L": 0.4433139534883721, "CIDEr": 0.3078734288091749, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.3076923076923077, "f": 0.26666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.75, "f": 0.5217391304347827, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "A herd of cows grazing in a green pasture with a wooden fence in the background."}, "37389": {"image_id": 37389, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.21931085605462405, "Bleu_3": 0.15089125644562476, "Bleu_4": 0.09567579772168915, "METEOR": 0.25359119119430595, "ROUGE_L": 0.2636887608069164, "CIDEr": 5.753876984243155e-08, "SPICE": {"All": {"pr": 0.375, "re": 0.24, "f": 0.2926829268292683, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is an image of a clock tower in the middle of a city. The clock face is green and has Roman numerals on it. There are buildings around the clock tower, and there are people walking on the sidewalk in front of it."}, "383594": {"image_id": 383594, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.18257418583043256, "Bleu_3": 0.12060770349712197, "Bleu_4": 1.4756414813339652e-05, "METEOR": 0.2376226365583253, "ROUGE_L": 0.3043044469783352, "CIDEr": 1.5508925965009897e-05, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.045454545454545456, "f": 0.04, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "This is an image of a plate with two chicken sandwiches, fries, and pickles on the side. The sandwiches are made with bread and filled with chicken. There are also some condiments on the table, such as ketchup and mustard."}, "319696": {"image_id": 319696, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.2691909510231658, "Bleu_3": 0.2259030488747848, "Bleu_4": 0.1521710209100825, "METEOR": 0.2896791951652187, "ROUGE_L": 0.2969401947148818, "CIDEr": 5.508332653887773e-09, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2, "f": 0.1851851851851852, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a red microwave sitting on top of a wooden counter in a kitchen. The counter has a tile backsplash and the walls are painted a light brown color. There is a window to the left of the microwave and a sink to the right."}, "318911": {"image_id": 318911, "Bleu_1": 0.3913043478090738, "Bleu_2": 0.23099715104243387, "Bleu_3": 1.3645768027438209e-06, "Bleu_4": 3.3573064839407454e-09, "METEOR": 0.2237741769128606, "ROUGE_L": 0.339265850945495, "CIDEr": 0.07165799794555854, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.2222222222222222, "f": 0.27586206896551724, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A flock of sheep grazing in a green pasture with trees in the background.\""}, "455506": {"image_id": 455506, "Bleu_1": 0.9999999998000004, "Bleu_2": 0.9428090413882642, "Bleu_3": 0.9196413919320425, "Bleu_4": 0.9036020034112857, "METEOR": 0.5792878359573337, "ROUGE_L": 0.9, "CIDEr": 2.710780072536463, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.20833333333333334, "f": 0.24390243902439027, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The dog is running with a frisbee in its mouth."}, "444631": {"image_id": 444631, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.32969023668385783, "Bleu_3": 0.21458852559989583, "Bleu_4": 0.1472821272346842, "METEOR": 0.3564831304754864, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.038063537982837146, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.13793103448275862, "f": 0.16666666666666666, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A person is walking on the beach with a surfboard under their arm. The sky is cloudy and there are waves in the distance."}, "497014": {"image_id": 497014, "Bleu_1": 0.6363636363057852, "Bleu_2": 0.5045249790613539, "Bleu_3": 0.3838700925692668, "Bleu_4": 0.28997844144056417, "METEOR": 0.2689082197032768, "ROUGE_L": 0.5417406749555951, "CIDEr": 0.690811058084721, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.14285714285714285, "f": 0.17647058823529413, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The dog is playing fetch with a stick in the grass."}, "502749": {"image_id": 502749, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.23426064282712405, "Bleu_3": 0.14118482396355853, "Bleu_4": 1.6496625424549473e-05, "METEOR": 0.23188431924417746, "ROUGE_L": 0.2713120830244626, "CIDEr": 6.277516645870884e-07, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09090909090909091, "f": 0.0975609756097561, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a kitchen with white cabinets and countertops. There is a large island in the center of the room with a sink, stove, and refrigerator on it. The walls are painted red and there are wreaths hanging from the ceiling."}, "230593": {"image_id": 230593, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.21213203434730224, "Bleu_3": 0.12507242179545755, "Bleu_4": 1.7268932788606005e-05, "METEOR": 0.20601432160231611, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.029020511363219897, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.34615384615384615, "f": 0.32727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5454545454545454, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of geese walk along a path in a park, surrounded by trees and grass."}, "364636": {"image_id": 364636, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.2385593618010997, "Bleu_3": 0.11247197267340707, "Bleu_4": 1.3820287655682624e-05, "METEOR": 0.2412389310788975, "ROUGE_L": 0.3028368794326241, "CIDEr": 1.8613807476776029e-06, "SPICE": {"All": {"pr": 1.0, "re": 0.24, "f": 0.3870967741935484, "fn": 19.0, "numImages": 1.0, "fp": 0.0, "tp": 6.0}, "Relation": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3, "f": 0.4615384615384615, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "This is a dog walking on a leash in the dirt. The dog is brown and white with a collar around its neck. It is looking up at the camera with its mouth open. There are trees and buildings in the background."}, "288313": {"image_id": 288313, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.35948681369506397, "Bleu_3": 0.27823060044492287, "Bleu_4": 0.17493298655958203, "METEOR": 0.37965533018634895, "ROUGE_L": 0.47339246119733924, "CIDEr": 0.024917008108437454, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.23809523809523808, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.45454545454545453, "f": 0.3846153846153846, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "A plate of food is set on a table with a fork and knife. There are several other plates of food on the table as well."}, "384503": {"image_id": 384503, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2253202848508038, "Bleu_3": 0.12836987367391073, "Bleu_4": 1.741467509925889e-05, "METEOR": 0.22970064814942065, "ROUGE_L": 0.36237623762376237, "CIDEr": 0.01828938387710487, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2631578947368421, "f": 0.27027027027027023, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a trolley car traveling down a rainy street with a yellow bow on the front. There are trees and buildings in the background."}, "190156": {"image_id": 190156, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.28455519660484385, "Bleu_3": 0.18724814514971858, "Bleu_4": 0.1381958549446129, "METEOR": 0.26693305766345, "ROUGE_L": 0.3034825870646766, "CIDEr": 6.212980378125519e-05, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.09523809523809523, "f": 0.10526315789473684, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "A black and white cat is sitting on a table with a cup of coffee in its paws. The cat is looking up at the camera with its eyes closed. There are papers and pens scattered around the table."}, "174123": {"image_id": 174123, "Bleu_1": 0.378378378368152, "Bleu_2": 0.17757120129627854, "Bleu_3": 0.09658114290938676, "Bleu_4": 1.2758497299410827e-05, "METEOR": 0.2086658315451713, "ROUGE_L": 0.3490146217418945, "CIDEr": 0.0013881209350914499, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13793103448275862, "f": 0.1951219512195122, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of a pizza with various toppings on it. The pizza has a crispy crust and the toppings are visible through the cheese. There is a fork on the plate next to the pizza."}, "557239": {"image_id": 557239, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.16205747826515882, "Bleu_3": 0.11412860603242152, "Bleu_4": 0.08695659942154278, "METEOR": 0.2661112323244153, "ROUGE_L": 0.24358243011979464, "CIDEr": 1.615878544997575e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a cat sitting in a toilet bowl with its paws up on the rim. The cat is looking directly at the camera with its eyes wide open and its mouth closed. The background of the image is a white bathroom with a toilet seat and a toilet paper roll on the wall."}, "184474": {"image_id": 184474, "Bleu_1": 0.19999999999200002, "Bleu_2": 0.09128709291380017, "Bleu_3": 7.129027762094492e-07, "Bleu_4": 2.014499014470129e-09, "METEOR": 0.1572961426659624, "ROUGE_L": 0.20043811610076673, "CIDEr": 0.008078962640107603, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2413793103448276, "f": 0.26415094339622647, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a bench sitting on top of a hill overlooking the ocean. The grass is green and there are some trees in the background."}, "335099": {"image_id": 335099, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.2431322695333988, "Bleu_3": 0.1298495596904247, "Bleu_4": 1.7034799410092803e-05, "METEOR": 0.2596067597123075, "ROUGE_L": 0.32649420160570913, "CIDEr": 0.0332539909877, "SPICE": {"All": {"pr": 0.2, "re": 0.05263157894736842, "f": 0.08333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "The image shows a dog standing on the porch of a house, looking out at the street through an iron gate. The dog is wearing a collar and tag."}, "431306": {"image_id": 431306, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.26940795303160764, "Bleu_3": 0.19361556807026736, "Bleu_4": 0.125778295946822, "METEOR": 0.32377148485518076, "ROUGE_L": 0.39246323529411764, "CIDEr": 0.0008272685967012996, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23529411764705882, "f": 0.20512820512820512, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a bathroom with two sinks and a mirror on the wall. The mirror has a light on either side of it, and there are no other objects in the room."}, "125815": {"image_id": 125815, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.21060588478687045, "Bleu_3": 0.1435323895375142, "Bleu_4": 1.7869522053917207e-05, "METEOR": 0.21559638307219128, "ROUGE_L": 0.3194832402234637, "CIDEr": 0.00678913029852116, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.25, "f": 0.1935483870967742, "fn": 18.0, "numImages": 1.0, "fp": 32.0, "tp": 6.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.1, "f": 0.08, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.5, "f": 0.37037037037037035, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a train station with a train on the tracks. There are people standing on the platform and in the background, there is a building with windows and a roof."}, "521106": {"image_id": 521106, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.06897007347916975, "Bleu_3": 4.83827662986667e-07, "Bleu_4": 1.28920522667564e-09, "METEOR": 0.1813739343661638, "ROUGE_L": 0.20890410958904113, "CIDEr": 1.7610454482245957e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15789473684210525, "f": 0.15789473684210525, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a yellow shirt and black shorts, and has a racket in his hand. Another player is standing behind him, watching the game. The background is a blue sky with some clouds."}, "508672": {"image_id": 508672, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.21302148074284213, "Bleu_3": 0.190152024801609, "Bleu_4": 0.17121949782523824, "METEOR": 0.3596566375513402, "ROUGE_L": 0.36715391229578676, "CIDEr": 0.0001862628316202954, "SPICE": {"All": {"pr": 0.5833333333333334, "re": 0.3684210526315789, "f": 0.4516129032258065, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}, "Relation": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8, "f": 0.7272727272727272, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is an image of a bicycle parked next to a flooded road. The bike is covered in mud and the water is up to the tires. There are trees and bushes in the background."}, "221737": {"image_id": 221737, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.12903971808302675, "Bleu_3": 0.10354246916903506, "Bleu_4": 0.07087216811989007, "METEOR": 0.18993760286329234, "ROUGE_L": 0.2543180464562239, "CIDEr": 5.4756473850235565e-08, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.30434782608695654, "f": 0.3684210526315789, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.625, "f": 0.7142857142857143, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows a road with a sign that reads \"Stop\" in white letters on a green background. There is a small bridge over the road with no cars or people on it. The sky is blue and there are trees on either side of the road."}, "345580": {"image_id": 345580, "Bleu_1": 0.3199999999872001, "Bleu_2": 0.2309401076664203, "Bleu_3": 0.19089624343986394, "Bleu_4": 0.1333497993154046, "METEOR": 0.29932937528426923, "ROUGE_L": 0.4499473129610117, "CIDEr": 0.055757294468353584, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.11764705882352941, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a zebra standing in the dirt, looking at the camera. It has black and white stripes on its body and long legs."}, "46440": {"image_id": 46440, "Bleu_1": 0.39999999999, "Bleu_2": 0.3038218101174071, "Bleu_3": 0.24426909075081468, "Bleu_4": 0.21066551866989422, "METEOR": 0.3724064504930865, "ROUGE_L": 0.3685800604229607, "CIDEr": 1.1614376147855425e-05, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of young men playing basketball in a gym. One player is dribbling the ball while another player is trying to block his shot. The other players are watching the game and cheering for their team."}, "270066": {"image_id": 270066, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.16282722783536435, "Bleu_4": 0.1176927314512938, "METEOR": 0.2663635610399797, "ROUGE_L": 0.28018372703412076, "CIDEr": 9.919274515217166e-09, "SPICE": {"All": {"pr": 0.5, "re": 0.35294117647058826, "f": 0.41379310344827586, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.8, "f": 0.7272727272727272, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a white motorcycle parked in front of a building with a large green and yellow logo on the side. The motorcycle has a black helmet and a black backpack on the back seat. There is a person standing next to the motorcycle, looking at it."}, "419867": {"image_id": 419867, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.29777500018082764, "Bleu_3": 0.21437689969939125, "Bleu_4": 0.1395211837846754, "METEOR": 0.2678345345462022, "ROUGE_L": 0.4024505183788879, "CIDEr": 0.006139594325010324, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a grocery store with a display of bananas on the shelf. There are several people shopping in the store, and some are holding bags of groceries."}, "194724": {"image_id": 194724, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2132007163490489, "Bleu_3": 0.11360703054848365, "Bleu_4": 1.486872032585981e-05, "METEOR": 0.13430256150693246, "ROUGE_L": 0.2426412092283214, "CIDEr": 0.0051750913527367865, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.35, "f": 0.3414634146341463, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a table with two pizzas on it, one with pepperoni and the other with mushrooms. There are also two glasses of soda on the table and a couple of napkins."}, "236426": {"image_id": 236426, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.23836564730406207, "Bleu_3": 0.12237946382258255, "Bleu_4": 1.5721757596698785e-05, "METEOR": 0.2397376089814446, "ROUGE_L": 0.31266017426960535, "CIDEr": 0.0017029466081222703, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.125, "f": 0.11538461538461538, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a tennis player in mid air, jumping to hit the ball with his racket. The background is a green grass court with a crowd of people watching from the stands."}, "499826": {"image_id": 499826, "Bleu_1": 0.28169014084110294, "Bleu_2": 0.21974926263633632, "Bleu_3": 0.1613314377660033, "Bleu_4": 0.0886465881376154, "METEOR": 0.24391642316033643, "ROUGE_L": 0.3226497071972797, "CIDEr": 8.052062294702034e-18, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a woman standing on the sidewalk next to a group of elephants. The elephants are walking in a line, with their trunks curled up and their ears flapping in the wind. The woman is wearing a white shirt and jeans, and she is looking at the elephants with a smile on her face. There are trees and greenery in the background, and the sky is blue and cloudy."}, "514904": {"image_id": 514904, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1824897193978171, "Bleu_3": 0.1435846767449069, "Bleu_4": 0.10770240491398318, "METEOR": 0.24665558709713495, "ROUGE_L": 0.317915309446254, "CIDEr": 2.873309865256965e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.21052631578947367, "f": 0.1568627450980392, "fn": 15.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "Here is a short caption for the image:\n\nA woman is holding two sausages in her hands while standing on the sidewalk. She is wearing a black and white striped shirt and has a red scarf around her neck. There are buildings and cars in the background."}, "359864": {"image_id": 359864, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.1250180897226835, "Bleu_4": 0.09600584732205708, "METEOR": 0.28630578398470014, "ROUGE_L": 0.33132166566083276, "CIDEr": 2.6544849256801547e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.35714285714285715, "f": 0.22727272727272724, "fn": 9.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.75, "f": 0.375, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man standing on the deck of a boat, wearing a red life jacket and sunglasses. He is looking out at the water in front of him, with his arms crossed over his chest. The background is a blue ocean with white caps on the waves."}, "247333": {"image_id": 247333, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.32816506164407266, "Bleu_3": 0.23788381719511642, "Bleu_4": 0.18496911301593644, "METEOR": 0.35054868583848214, "ROUGE_L": 0.43306288032454365, "CIDEr": 0.05654209734263674, "SPICE": {"All": {"pr": 0.24, "re": 0.2608695652173913, "f": 0.24999999999999994, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a plate of food with various vegetables, meats, and condiments. There is a glass of soda on the table next to the plate."}, "54277": {"image_id": 54277, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.17040572913395824, "Bleu_3": 0.08033906732368051, "Bleu_4": 9.85381528236167e-06, "METEOR": 0.24396781726551137, "ROUGE_L": 0.19904285403524036, "CIDEr": 2.881974098462602e-14, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.17647058823529413, "f": 0.15384615384615383, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person standing on top of a snow covered slope, wearing ski gear and holding a snowboard. The person is looking down the slope with their arms outstretched. There are several other people in the background, also skiing down the slope. The image appears to be taken in a large indoor ski resort or arena."}, "80172": {"image_id": 80172, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2660221937781222, "Bleu_3": 0.18459831800739637, "Bleu_4": 0.14390899797272783, "METEOR": 0.325952528663389, "ROUGE_L": 0.34163036714374606, "CIDEr": 3.566614326902494e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.06896551724137931, "f": 0.0975609756097561, "fn": 27.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a young boy sitting on the edge of a bathtub, brushing his teeth with a toothbrush. He is wearing a blue shirt and has a towel around his neck. The bathroom is clean and well lit, with a sink and toilet in the background."}, "376959": {"image_id": 376959, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.27439773622258, "Bleu_3": 0.2307907074427526, "Bleu_4": 0.16648830933698916, "METEOR": 0.2627129005558405, "ROUGE_L": 0.3190932868352223, "CIDEr": 3.636756759415631e-09, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.1724137931034483, "f": 0.20833333333333334, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a young girl sitting at a table with a pencil and paper in front of her. She is wearing a pink dress and has long blonde hair. The background is a light brown color with a few objects on the table, such as a book and a pen."}, "47055": {"image_id": 47055, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.14062009564344036, "Bleu_3": 0.0880168037197584, "Bleu_4": 1.0458164798239607e-05, "METEOR": 0.16099460655335995, "ROUGE_L": 0.22435897435897437, "CIDEr": 5.026740462645359e-13, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1, "f": 0.13636363636363638, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a bedroom with a white bed, gray walls, and black blinds. The bed has a white headboard and footboard, and the sheets are white. There is a nightstand on one side of the bed with a lamp on it. The floor is made of hardwood and there is a rug in front of the bed."}, "154816": {"image_id": 154816, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.0968245836536842, "Bleu_3": 0.06676572575138977, "Bleu_4": 0.04680769532677705, "METEOR": 0.17498846320014694, "ROUGE_L": 0.23315814620162445, "CIDEr": 9.575128549860647e-18, "SPICE": {"All": {"pr": 0.1891891891891892, "re": 0.3333333333333333, "f": 0.24137931034482757, "fn": 14.0, "numImages": 1.0, "fp": 30.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3125, "re": 0.625, "f": 0.4166666666666667, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a young boy playing baseball in a field with other players. He is wearing a red and white uniform and has a bat in his hand as he prepares to hit the ball. There are several people watching from the sidelines, including an umpire in a black and white striped shirt. The sky is cloudy and there are trees in the background."}, "155179": {"image_id": 155179, "Bleu_1": 0.4999999999500001, "Bleu_2": 0.33333333329814824, "Bleu_3": 0.24037492835763732, "Bleu_4": 3.753119268302293e-05, "METEOR": 0.16184282510593162, "ROUGE_L": 0.465648854961832, "CIDEr": 0.3961793828648369, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 36.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a loaf of bread on a plate."}, "328374": {"image_id": 328374, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.17797249265986642, "Bleu_3": 0.08588393224796005, "Bleu_4": 1.0663135316252687e-05, "METEOR": 0.1632406527811072, "ROUGE_L": 0.2771467514766015, "CIDEr": 4.96582001177645e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.36363636363636365, "f": 0.30769230769230765, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.625, "f": 0.43478260869565216, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people are sitting on skis at the bottom of a snowy hill. They are all wearing ski gear and helmets, and some of them are holding poles. The sky is dark and cloudy, and there is snow on the ground.\""}, "264919": {"image_id": 264919, "Bleu_1": 0.19565217391091683, "Bleu_2": 0.09273670015926441, "Bleu_3": 4.571796832840585e-07, "Bleu_4": 1.0179294756051877e-09, "METEOR": 0.14335589795875547, "ROUGE_L": 0.15459811730629977, "CIDEr": 2.956079637856894e-34, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3181818181818182, "f": 0.3255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a man wearing a colorful costume made of balloons. He is standing on the sidewalk, holding a phone to his ear and looking down at it. The costume is made up of long, thin balloons that are tied together in the shape of a mohawk. The balloons are brightly colored and have different shapes and patterns on them. The man's body is covered in the balloons, with some of them covering his face and neck as well. The overall effect is one of a playful and festive atmosphere."}, "48185": {"image_id": 48185, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.20121090914115636, "Bleu_3": 0.1635763216609011, "Bleu_4": 0.1381958549446129, "METEOR": 0.2837669671360129, "ROUGE_L": 0.3519835136527563, "CIDEr": 1.7967210376601704e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a bathroom with a large mirror, sink, and shower. The walls are white and the floor is tiled in black and white. There is a window on one side of the room that lets in natural light."}, "43376": {"image_id": 43376, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.24112141107953186, "Bleu_3": 0.1415487039853373, "Bleu_4": 1.6317905930043706e-05, "METEOR": 0.25579251368794664, "ROUGE_L": 0.3400696864111499, "CIDEr": 5.716980643678624e-07, "SPICE": {"All": {"pr": 0.375, "re": 0.20689655172413793, "f": 0.26666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a giraffe standing on a fence in a zoo. The giraffe is looking down and appears to be eating something from its mouth. The background is made up of trees and greenery, with a few birds flying in the sky."}, "204994": {"image_id": 204994, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.11952286093128565, "Bleu_3": 6.419522618397191e-07, "Bleu_4": 1.4947139323454504e-09, "METEOR": 0.2053229983754627, "ROUGE_L": 0.2330786026200873, "CIDEr": 2.439362246572048e-13, "SPICE": {"All": {"pr": 0.1875, "re": 0.12, "f": 0.14634146341463414, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a man standing on a bench next to a giraffe. The man is wearing a black shirt and pants, and has his hands in his pockets. The giraffe is standing on the ground, looking at the man with its large eyes. The sky is blue and there are palm trees in the background."}, "309264": {"image_id": 309264, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.13561270071956377, "Bleu_3": 0.0869255738105391, "Bleu_4": 1.2488771902030573e-05, "METEOR": 0.20067252011401562, "ROUGE_L": 0.2350674373795761, "CIDEr": 0.0019739193865151742, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A colorful bird cage filled with various birds, including parakeets, cockatiels, and finches, sits on a shelf in a pet store.\""}, "356028": {"image_id": 356028, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.36709140217978414, "Bleu_3": 0.314467264387792, "Bleu_4": 0.26471191840584474, "METEOR": 0.30586168310352074, "ROUGE_L": 0.4085733422638982, "CIDEr": 9.215061289084587e-06, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.21739130434782608, "f": 0.19230769230769232, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a black and white photograph of a room with several beds in it. There are curtains on the windows and a wooden floor. The walls are made of brick and there are no furniture or decorations in the room."}, "544794": {"image_id": 544794, "Bleu_1": 0.5833333332361111, "Bleu_2": 0.398862017540745, "Bleu_3": 0.2515060603801396, "Bleu_4": 3.646285861281333e-05, "METEOR": 0.2415383940392113, "ROUGE_L": 0.4326241134751773, "CIDEr": 1.1477036733639547, "SPICE": {"All": {"pr": 0.1, "re": 0.12, "f": 0.1090909090909091, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a plate of pizza with mushrooms and cheese on it."}, "264619": {"image_id": 264619, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.23008949664965453, "Bleu_3": 0.14799245941635208, "Bleu_4": 0.09065032831177448, "METEOR": 0.20962684266151066, "ROUGE_L": 0.2893689114781872, "CIDEr": 8.198491722951064e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.125, "f": 0.15789473684210525, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people on the beach, with kite surfers in the background flying their kites over the ocean. The sky is clear and blue, with a few clouds scattered about. The waves are crashing against the shore, and there are some rocks and sand in the foreground."}, "322222": {"image_id": 322222, "Bleu_1": 0.49999999998437505, "Bleu_2": 0.2540002539923155, "Bleu_3": 0.16262688653272234, "Bleu_4": 0.11035569779270682, "METEOR": 0.302915279107814, "ROUGE_L": 0.3758802816901408, "CIDEr": 0.0037446349633261837, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.07692307692307693, "f": 0.08333333333333334, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing white clothing and has a racket in his hand. There are other people watching him play from the sidelines."}, "359791": {"image_id": 359791, "Bleu_1": 0.21333333333048887, "Bleu_2": 0.07593263965918065, "Bleu_3": 4.290534301310897e-07, "Bleu_4": 1.0234117753719075e-09, "METEOR": 0.11267605633802819, "ROUGE_L": 0.11280628756356914, "CIDEr": 1.2782342717175165e-23, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on the deck of a boat, looking out at the water. There are several orange chairs lined up along the railing, and a couple is standing in the back, holding an umbrella over their heads to protect themselves from the rain. The sky is gray and cloudy, with a few white clouds visible in the distance. The water is calm and reflects the colors of the sky."}, "404635": {"image_id": 404635, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.24096579866284706, "Bleu_3": 0.18177940993538677, "Bleu_4": 0.14392177550546975, "METEOR": 0.3199710823736472, "ROUGE_L": 0.41673783091374894, "CIDEr": 0.00969285523837624, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.20689655172413793, "f": 0.24000000000000002, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.3333333333333333, "f": 0.3846153846153846, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a group of elephants standing in a grassy field with trees in the background. They are all facing each other and appear to be communicating with each other."}, "364343": {"image_id": 364343, "Bleu_1": 0.16071428571141586, "Bleu_2": 0.09362816758816678, "Bleu_3": 0.05455146638784257, "Bleu_4": 7.439364783947175e-06, "METEOR": 0.1846985566072809, "ROUGE_L": 0.2426136363636364, "CIDEr": 9.248939875249876e-14, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2, "f": 0.21739130434782608, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This image appears to be a plate of food, possibly breakfast or brunch. It contains various fruits such as strawberries, bananas, and grapes, as well as some sliced bread and a dollop of whipped cream on top. The plate is surrounded by a white tablecloth and there are several glasses of orange juice on the table."}, "1573": {"image_id": 1573, "Bleu_1": 0.5652173912797732, "Bleu_2": 0.32057261019905153, "Bleu_3": 1.6977660468584403e-06, "Bleu_4": 3.955040035595633e-09, "METEOR": 0.23790782351823148, "ROUGE_L": 0.379746835443038, "CIDEr": 0.06651110677899923, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a kitchen with a stove, sink, and refrigerator. There are also some pots and pans on the countertops."}, "174898": {"image_id": 174898, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2961744388718521, "Bleu_3": 0.2550726073391884, "Bleu_4": 0.20722265741677282, "METEOR": 0.30504948967121387, "ROUGE_L": 0.4112359550561798, "CIDEr": 1.7255118272646115e-05, "SPICE": {"All": {"pr": 0.1, "re": 0.058823529411764705, "f": 0.07407407407407408, "fn": 32.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe black motorcycle is parked on the side of the road in front of some trees. The sun is shining down on it, casting a warm glow over the vehicle."}, "527580": {"image_id": 527580, "Bleu_1": 0.35087719297630043, "Bleu_2": 0.23746784506878557, "Bleu_3": 0.16006718526982805, "Bleu_4": 0.11101605489146435, "METEOR": 0.20938944088649886, "ROUGE_L": 0.2213582166925868, "CIDEr": 5.448377928935442e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting on the beach in front of a hotel with an old fashioned trolley car parked next to it. The trolley car has a red and white striped awning over it, and there are several umbrellas set up around it. In the background, there are mountains visible through the trees."}, "522020": {"image_id": 522020, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.3627381250353841, "Bleu_3": 0.31400205658385943, "Bleu_4": 0.24941747175577164, "METEOR": 0.30370921359602093, "ROUGE_L": 0.458072590738423, "CIDEr": 0.24446206437287846, "SPICE": {"All": {"pr": 0.3125, "re": 0.18518518518518517, "f": 0.2325581395348837, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a white cat sitting in the grass, looking up at the camera with its big green eyes."}, "142890": {"image_id": 142890, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.19847906537508855, "Bleu_3": 0.14007503420163694, "Bleu_4": 0.08994110735166029, "METEOR": 0.26243228155538256, "ROUGE_L": 0.2922655715263518, "CIDEr": 1.9689193399726735e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2631578947368421, "f": 0.2040816326530612, "fn": 14.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a black cat sitting on top of a computer keyboard. The cat is looking directly at the camera with its eyes fixed on it. The background of the image is a messy office space with papers and other office supplies scattered around."}, "503238": {"image_id": 503238, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.18726083047926023, "Bleu_4": 0.13634738359895024, "METEOR": 0.3167965319655202, "ROUGE_L": 0.2713120830244626, "CIDEr": 8.956425937213446e-06, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.11538461538461539, "f": 0.10000000000000002, "fn": 23.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a bus driving down the street in a city. The bus is orange and has a number on the side. There are people walking on the sidewalk and cars parked on the side of the road."}, "522430": {"image_id": 522430, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.13805054457255134, "Bleu_4": 1.5820356672588363e-05, "METEOR": 0.20179789970046727, "ROUGE_L": 0.24646464646464644, "CIDEr": 5.0573039694267976e-08, "SPICE": {"All": {"pr": 0.3, "re": 0.13043478260869565, "f": 0.18181818181818182, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of cows standing in a field at sunset. The cows are brown and white, with long, curly hair. They are standing in a line, looking out at the camera. The sky is orange and pink, with clouds in the background."}, "155897": {"image_id": 155897, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.13199091933393275, "Bleu_3": 0.0955035182062913, "Bleu_4": 0.06874614919061829, "METEOR": 0.2204960346672059, "ROUGE_L": 0.2279521674140508, "CIDEr": 1.6946565830626585e-07, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a woman sitting on a bench holding a sandwich in her hand. The sandwich appears to be made of bread, meat, and vegetables. There are several people standing around the bench, watching the woman eat her sandwich."}, "214494": {"image_id": 214494, "Bleu_1": 0.5833333332847223, "Bleu_2": 0.5149286504995761, "Bleu_3": 0.43006931372929474, "Bleu_4": 0.3066148709997289, "METEOR": 0.3081739754982745, "ROUGE_L": 0.5669144981412639, "CIDEr": 1.482607949058436, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.11538461538461539, "f": 0.15, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a chocolate cake with a knife cutting into it."}, "223093": {"image_id": 223093, "Bleu_1": 0.5416666666440973, "Bleu_2": 0.37590470576205304, "Bleu_3": 0.2680925216167677, "Bleu_4": 3.094986086648064e-05, "METEOR": 0.3070313668276877, "ROUGE_L": 0.4621212121212121, "CIDEr": 0.08067226515160446, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.16, "f": 0.12698412698412698, "fn": 21.0, "numImages": 1.0, "fp": 34.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3333333333333333, "f": 0.2962962962962963, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a brick building with a clock tower on top. The clock face is visible, and the sky is clear and blue."}, "422706": {"image_id": 422706, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.18650096164396338, "Bleu_3": 0.11649657484397867, "Bleu_4": 0.07786956589908328, "METEOR": 0.16278985185399206, "ROUGE_L": 0.2887573964497041, "CIDEr": 4.514241201832748e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.045454545454545456, "f": 0.06896551724137931, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "A group of people are standing on the deck of a cruise ship, looking out at the ocean. One person is holding a camera and taking pictures of the water and sky. The ship is traveling through the ocean, with the sun shining down on it."}, "4011": {"image_id": 4011, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.17817416127214353, "Bleu_3": 0.11538242716705423, "Bleu_4": 1.2597149807626527e-05, "METEOR": 0.2716584780792054, "ROUGE_L": 0.2459677419354839, "CIDEr": 3.4964809406538286e-15, "SPICE": {"All": {"pr": 0.1, "re": 0.09523809523809523, "f": 0.0975609756097561, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a woman standing in front of a table with a cake on it. The cake appears to be a white dog with blue eyes and a pink nose. The woman is wearing an apron and has a smile on her face. There are several utensils and ingredients on the table, including a mixing bowl, a measuring cup, and a pastry bag."}, "188824": {"image_id": 188824, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.2088724735450347, "Bleu_3": 0.15376602628644037, "Bleu_4": 0.10536340312160568, "METEOR": 0.2787329477386416, "ROUGE_L": 0.29698149951314506, "CIDEr": 4.3207933291558036e-15, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.2222222222222222, "f": 0.2424242424242424, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a gray and white cat sitting on top of a couch, looking at the camera with its green eyes. The cat is wearing a collar around its neck and has a tag on its ear. The background of the image is a messy living room with a television in the corner and a coffee table in front of it."}, "247206": {"image_id": 247206, "Bleu_1": 0.5416666666440973, "Bleu_2": 0.43405736612273677, "Bleu_3": 0.25777088273627524, "Bleu_4": 3.005180557232568e-05, "METEOR": 0.2760628865802841, "ROUGE_L": 0.5083333333333333, "CIDEr": 0.09318817994071686, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.42857142857142855, "f": 0.24, "fn": 8.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man lying on the floor with his head resting on his hand while a cat is sitting next to him."}, "430047": {"image_id": 430047, "Bleu_1": 0.3599999999928, "Bleu_2": 0.2571428571376619, "Bleu_3": 0.19026514322667332, "Bleu_4": 0.11002590761556934, "METEOR": 0.25270407748820445, "ROUGE_L": 0.2901307966706302, "CIDEr": 1.0142756498535815e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a living room with a television on the wall and a couch in front of it. There are also some books on the shelves and a coffee table in front of the couch. The walls are painted white and there are windows on one side of the room."}, "244240": {"image_id": 244240, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.22454435656302607, "Bleu_3": 0.14511315402717082, "Bleu_4": 1.7578936267302155e-05, "METEOR": 0.20954427831497874, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.0005675695081490602, "SPICE": {"All": {"pr": 0.15, "re": 0.0967741935483871, "f": 0.11764705882352941, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a photo of a toilet in a bathroom. The toilet is white and has a seat on it. There is a sink next to the toilet and some plants growing outside the window."}, "49810": {"image_id": 49810, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.10040323016589746, "Bleu_4": 1.28605734119315e-05, "METEOR": 0.22896826745476048, "ROUGE_L": 0.32250755287009064, "CIDEr": 8.855027313879034e-06, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.3125, "f": 0.27027027027027023, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on a wooden deck, looking at its reflection in a mirror. The cat has long, fluffy white fur and bright green eyes. The background is a blurred view of the sky through a window."}, "85914": {"image_id": 85914, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.23836564730406207, "Bleu_3": 0.1541884625449198, "Bleu_4": 1.869642599434227e-05, "METEOR": 0.22035928143712577, "ROUGE_L": 0.40219780219780216, "CIDEr": 0.010310309379923562, "SPICE": {"All": {"pr": 0.5, "re": 0.2608695652173913, "f": 0.3428571428571428, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a plate with a variety of vegetables, including broccoli, carrots, and potatoes, topped with a piece of beef. The dish appears to be a hearty stew or casserole."}, "442942": {"image_id": 442942, "Bleu_1": 0.1904761904716554, "Bleu_2": 0.09639253854005296, "Bleu_3": 6.147175534710986e-07, "Bleu_4": 1.5622141216088897e-09, "METEOR": 0.17578378468011005, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.6693918995922702e-07, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.14285714285714285, "f": 0.17241379310344826, "fn": 30.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.08333333333333333, "f": 0.08695652173913043, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.26666666666666666, "f": 0.2962962962962963, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a train on a track in the middle of a field. There are people standing on the platform and looking out at the train. The train has a red and white striped awning on top of it."}, "162543": {"image_id": 162543, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.1703995441436427, "Bleu_3": 0.1132319414877341, "Bleu_4": 1.3890266032645653e-05, "METEOR": 0.1949390195393295, "ROUGE_L": 0.22344322344322343, "CIDEr": 6.821694624227435e-07, "SPICE": {"All": {"pr": 0.07894736842105263, "re": 0.15789473684210525, "f": 0.10526315789473684, "fn": 16.0, "numImages": 1.0, "fp": 35.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.42857142857142855, "f": 0.26086956521739124, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a field with a fence surrounding them. They are wearing collars and appear to be in a zoo or wildlife sanctuary. There is a building in the background with windows and a roof."}, "157352": {"image_id": 157352, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.1714985851373884, "Bleu_3": 0.09722777968025705, "Bleu_4": 1.3122070075706762e-05, "METEOR": 0.18993760286329228, "ROUGE_L": 0.24478330658105937, "CIDEr": 0.0003336926573542209, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09523809523809523, "f": 0.0851063829787234, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people skateboarding down a ramp. One person is jumping off the ramp while another person is riding on the board. There are trees and buildings in the background."}, "262810": {"image_id": 262810, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.0645198590415134, "Bleu_3": 4.522633916831482e-07, "Bleu_4": 1.2041494936393691e-09, "METEOR": 0.15213946117274169, "ROUGE_L": 0.158957654723127, "CIDEr": 6.065566506444303e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09523809523809523, "f": 0.11428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This image shows a wedding reception with guests dancing and taking photos. The bride and groom are standing at the head table, surrounded by their friends and family. There are several tables set up with food and drinks, and the room is decorated with balloons and streamers."}, "498807": {"image_id": 498807, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.24308621739673564, "Bleu_3": 0.1901110702410287, "Bleu_4": 0.13449332525999214, "METEOR": 0.27557865116672625, "ROUGE_L": 0.336783988957902, "CIDEr": 2.815252294387729e-08, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.09523809523809523, "f": 0.0784313725490196, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "A young girl is surfing on a pink surfboard in the ocean. She is wearing a black wetsuit and has her hair tied back. The waves are crashing against the shore and she is standing on the board, balancing herself as she rides the wave."}, "563605": {"image_id": 563605, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1628822035823003, "Bleu_3": 0.11836112830783165, "Bleu_4": 0.07706946743067312, "METEOR": 0.1897503086707035, "ROUGE_L": 0.24854481955762517, "CIDEr": 1.0977400483852301e-08, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08, "f": 0.08695652173913043, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people standing under an umbrella on the sidewalk in front of a building. They are all wearing casual clothing and have their heads down, looking at something on their phones. There is a large umbrella over their heads to protect them from the rain."}, "162503": {"image_id": 162503, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.1624330521596262, "Bleu_4": 0.14612476989078169, "METEOR": 0.26721552613895605, "ROUGE_L": 0.27128335451080055, "CIDEr": 4.3020827135602417e-10, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.21428571428571427, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A barn owl perched on a branch in a forest of tall trees. The owl has a round, fluffy body and big, round eyes. Its feathers are a mottled brown and white color, with a distinctive white patch on its forehead.\""}, "62089": {"image_id": 62089, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.12993504870706918, "Bleu_3": 0.06787131897112117, "Bleu_4": 8.763866421088602e-06, "METEOR": 0.1753387485372847, "ROUGE_L": 0.23461538461538461, "CIDEr": 1.7758926670375285e-11, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a young boy wearing a skateboard helmet and holding onto the handlebars of a skateboard. He is standing on the sidewalk in front of a basketball court, looking down at his feet as he rides the board. There are other people in the background, including some playing basketball and others watching him ride."}, "340737": {"image_id": 340737, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.21223817998318864, "Bleu_3": 0.13704703969756082, "Bleu_4": 0.09327870647149639, "METEOR": 0.2645920188964988, "ROUGE_L": 0.2930344275420336, "CIDEr": 3.986726552445844e-05, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.4375, "f": 0.45161290322580644, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is a bathroom with a bathtub, sink, and toilet. The walls are yellow and the floor is made of tile. There is a window on one side of the room and a door on the other."}, "423744": {"image_id": 423744, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.09712858623387621, "Bleu_3": 5.697810303144272e-07, "Bleu_4": 1.3868787330575517e-09, "METEOR": 0.14194466058581803, "ROUGE_L": 0.18100890207715134, "CIDEr": 1.2655014414426081e-10, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.36363636363636365, "f": 0.32653061224489793, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is an image of a workshop with various tools and equipment on the workbench. There are two laptops on the bench, one with a screen open and the other closed. There are also several wires and cables hanging from the ceiling and walls, as well as a large toolbox in the background."}, "343903": {"image_id": 343903, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.3960590171788445, "Bleu_3": 0.2904780222375453, "Bleu_4": 0.16768512376618397, "METEOR": 0.3109704547161949, "ROUGE_L": 0.5312046444121916, "CIDEr": 0.02769662274300403, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2, "f": 0.22950819672131148, "fn": 28.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a plate with a blueberry pancake on it, sitting on top of a colorful tablecloth. There is a glass of milk next to the plate and a fork on the side."}, "117786": {"image_id": 117786, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.1348399724902187, "Bleu_3": 0.06956880074617594, "Bleu_4": 8.927747941495415e-06, "METEOR": 0.18423775996225916, "ROUGE_L": 0.2096700274977085, "CIDEr": 3.645665149849857e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.11538461538461539, "f": 0.15789473684210525, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a man standing in front of a large building with a fountain in the foreground. The building appears to be made of stone and has several windows on the upper floors. There are several people walking around the area, including one woman who is pushing a stroller. The sky is clear and blue."}, "3693": {"image_id": 3693, "Bleu_1": 0.6153846153609468, "Bleu_2": 0.3843075691171325, "Bleu_3": 0.26429521259190897, "Bleu_4": 0.16831972515625004, "METEOR": 0.25422242610889106, "ROUGE_L": 0.42277227722772265, "CIDEr": 0.021745846586503484, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1875, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people standing in front of a graffiti wall, smiling and looking at their phones.\""}, "187852": {"image_id": 187852, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.21103178185560523, "Bleu_3": 0.13402155970338947, "Bleu_4": 0.09042851014280592, "METEOR": 0.13944792618010438, "ROUGE_L": 0.22101449275362312, "CIDEr": 6.881798744239509e-05, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.25, "f": 0.19607843137254902, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a building, looking at something on their phones. They are all wearing sunglasses and have their hands on their hips. There are trees and buildings in the background."}, "414078": {"image_id": 414078, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.18299102222839972, "Bleu_4": 2.0311720520162125e-05, "METEOR": 0.21521138953099092, "ROUGE_L": 0.3155949741315595, "CIDEr": 2.413739822521651e-05, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.09090909090909091, "f": 0.08163265306122448, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a black and white cat lying on top of a blue blanket. The cat is looking up at the camera with its eyes. The background is a blue bedspread with white pillows and a blue comforter."}, "121716": {"image_id": 121716, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.15118578920063636, "Bleu_3": 7.808966656031396e-07, "Bleu_4": 1.78410623850286e-09, "METEOR": 0.17325487151287464, "ROUGE_L": 0.18944099378881987, "CIDEr": 3.236034745349645e-10, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.20588235294117646, "f": 0.22222222222222224, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.375, "f": 0.38709677419354843, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a black and white jacket, black pants, and black ski boots. They are holding onto two skis with poles in their hands. The background is a snowy mountain landscape with trees in the distance."}, "327794": {"image_id": 327794, "Bleu_1": 0.4324324324207451, "Bleu_2": 0.189831599145298, "Bleu_3": 0.10097712220824674, "Bleu_4": 1.3191601177260918e-05, "METEOR": 0.19127674619959734, "ROUGE_L": 0.2988103568929321, "CIDEr": 0.00012837469284456108, "SPICE": {"All": {"pr": 0.16216216216216217, "re": 0.2, "f": 0.1791044776119403, "fn": 24.0, "numImages": 1.0, "fp": 31.0, "tp": 6.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.125, "f": 0.09090909090909091, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a bowl of vegetables and meat being cooked in a pan. The vegetables are carrots, onions, and mushrooms, while the meat is chicken. The sauce is made with soy sauce, oyster sauce, and sesame oil."}, "143370": {"image_id": 143370, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.282038037400203, "Bleu_3": 0.19745053261647894, "Bleu_4": 0.1505119274735858, "METEOR": 0.3661395583890436, "ROUGE_L": 0.4593044101828613, "CIDEr": 0.010588398121993445, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.15789473684210525, "f": 0.16901408450704225, "fn": 32.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.11764705882352941, "f": 0.13793103448275862, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a bathroom with a white sink, toilet, and mirror on the wall. The mirror has a picture of a woman hanging on it. There are also some plants in the room."}, "354202": {"image_id": 354202, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.25354627640617955, "Bleu_3": 0.150125208731753, "Bleu_4": 2.0821983208077135e-05, "METEOR": 0.24534005987138902, "ROUGE_L": 0.46362649294245384, "CIDEr": 0.14542218809078203, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A giraffe peers over the fence at its companion in the zoo.\""}, "189193": {"image_id": 189193, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 7.587175464144185e-07, "Bleu_4": 1.710675170420534e-09, "METEOR": 0.21546860016245742, "ROUGE_L": 0.1862026862026862, "CIDEr": 7.662374383148261e-13, "SPICE": {"All": {"pr": 0.16, "re": 0.21052631578947367, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A woman in a green sweater and blue jeans is standing on a skateboard in the middle of a parking lot. She is wearing a black helmet and has her arms out to the side. There are cars parked along the side of the road, and a building can be seen in the background."}, "561967": {"image_id": 561967, "Bleu_1": 0.6470588234913496, "Bleu_2": 0.28439822948000854, "Bleu_3": 1.7535608433906583e-06, "Bleu_4": 4.430049923968651e-09, "METEOR": 0.26542299679366677, "ROUGE_L": 0.4982497082847141, "CIDEr": 0.35191988268654667, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.10526315789473684, "f": 0.09523809523809525, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "A train traveling on a railroad track with several cars and a conductor standing on the platform."}, "404071": {"image_id": 404071, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.2954684201318916, "Bleu_3": 0.14974405772212573, "Bleu_4": 1.9143758008581856e-05, "METEOR": 0.25362990903840293, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.01041551244393011, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2777777777777778, "f": 0.25641025641025644, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA blue and white train traveling down a railroad track next to trees and a bridge in the background."}, "251572": {"image_id": 251572, "Bleu_1": 0.33333333332679743, "Bleu_2": 0.19999999999603923, "Bleu_3": 0.11775100856360317, "Bleu_4": 0.07636830779166373, "METEOR": 0.2669209032259375, "ROUGE_L": 0.3216168717047452, "CIDEr": 8.600236936555334e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "A woman is sitting on a couch with her dog in her lap. The dog is a small, fluffy white puppy with brown spots. The woman is wearing a gray sweater and has her arms around the dog. The background is a beige colored wall with a window in the background."}, "436791": {"image_id": 436791, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.278652218402176, "Bleu_3": 0.23317016082633985, "Bleu_4": 0.19951806878305178, "METEOR": 0.3287080240385856, "ROUGE_L": 0.33577981651376143, "CIDEr": 9.344608957365546e-10, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The man in the image is holding a cell phone to his ear while walking down the street. He is wearing a black jacket and has a serious expression on his face. The background of the image appears to be a city street with buildings and trees visible in the distance."}, "319257": {"image_id": 319257, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.1709408646863767, "Bleu_3": 0.08148906680071043, "Bleu_4": 1.0052070847735423e-05, "METEOR": 0.17167860133526344, "ROUGE_L": 0.20460644007155634, "CIDEr": 2.427034372814599e-13, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.24, "f": 0.30769230769230765, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a cat sitting on top of a potted cactus plant. The cat is looking up at the sun through the window. The plant has long, spiky leaves and a small flower on top. The cat's fur is fluffy and white, and it looks like it is enjoying the warmth of the sun."}, "279437": {"image_id": 279437, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.2909938476144488, "Bleu_3": 0.1780568905576084, "Bleu_4": 2.100485022857964e-05, "METEOR": 0.2558216867665205, "ROUGE_L": 0.4210122699386504, "CIDEr": 0.003687286352589101, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a bedroom with a large bed, a dresser, and a window with floral wallpaper. The bed has a white comforter and pillows, and there is a vase on the nightstand."}, "175718": {"image_id": 175718, "Bleu_1": 0.8749999999453126, "Bleu_2": 0.6390096503814245, "Bleu_3": 0.44395200084161557, "Bleu_4": 0.28642846472173955, "METEOR": 0.3110467261093701, "ROUGE_L": 0.6014084507042253, "CIDEr": 0.9914776239106314, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.15384615384615385, "f": 0.17777777777777778, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A pizza with cheese and pepperoni on a wooden cutting board next to a beer bottle."}, "126671": {"image_id": 126671, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.2799063742426443, "Bleu_3": 0.21105822162357615, "Bleu_4": 0.16730402691842622, "METEOR": 0.3257201943101257, "ROUGE_L": 0.4714975845410628, "CIDEr": 0.04200446947613539, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.12, "f": 0.13636363636363635, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, shower, and sink. The walls are white and the floor is tiled. There is a curtain hanging in the window."}, "281424": {"image_id": 281424, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.14189834119414174, "Bleu_4": 0.10500646136283469, "METEOR": 0.21421893613408818, "ROUGE_L": 0.27128335451080055, "CIDEr": 2.2834137025159359e-10, "SPICE": {"All": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a cat sleeping in a suitcase. The cat is lying on its side with its head resting on the handle of the suitcase. The suitcase appears to be black and has a zipper on the front. There are some books and papers on top of the suitcase."}, "136": {"image_id": 136, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.10735372697093548, "Bleu_3": 6.304134548019102e-07, "Bleu_4": 1.5360875768147853e-09, "METEOR": 0.15195076636427327, "ROUGE_L": 0.23461538461538461, "CIDEr": 6.394108194794096e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of giraffes standing in a large enclosure. They are looking out the window at something, possibly other animals or people. The enclosure is made of metal and has a wooden floor. There are several people standing around the enclosure, looking at the giraffes."}, "71929": {"image_id": 71929, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.18463723646567207, "Bleu_3": 0.1237244007877382, "Bleu_4": 0.07731656515919258, "METEOR": 0.22712374022396462, "ROUGE_L": 0.33152173913043476, "CIDEr": 6.475796344366478e-10, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.15625, "f": 0.20408163265306123, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A plate of food with shrimp, rice, and vegetables on a table\n\nThe image shows a plate of food with shrimp, rice, and vegetables on a table. The plate is white and has a red and green pattern on it. There are two forks and a knife on the plate. The food looks delicious and fresh."}, "69293": {"image_id": 69293, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.22140372137841335, "Bleu_3": 0.1452390111187727, "Bleu_4": 0.09970617113142893, "METEOR": 0.24631216457873134, "ROUGE_L": 0.3477198697068403, "CIDEr": 0.0005160795945715513, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are made of beige tiles and the floor is made of wood. There is a shower in the corner of the room."}, "90040": {"image_id": 90040, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.1630820182599269, "Bleu_3": 8.330762903217117e-07, "Bleu_4": 1.893260841337042e-09, "METEOR": 0.18064478884294116, "ROUGE_L": 0.23680124223602486, "CIDEr": 2.9693715136552945e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This image shows a riverbank with several boats docked at the shore. There are buildings on either side of the river, and a red flag is flying from a pole in the center of the image. The sky is cloudy and there are some trees in the background."}, "409646": {"image_id": 409646, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.0956600132176177, "Bleu_4": 1.248740514185277e-05, "METEOR": 0.2126315731093983, "ROUGE_L": 0.2669584245076586, "CIDEr": 9.700129660329332e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a black bear standing in the middle of a dirt road. The bear is looking directly at the camera, and its fur is shiny and smooth. The background is a green field with trees and bushes."}, "296383": {"image_id": 296383, "Bleu_1": 0.31034482758085613, "Bleu_2": 0.23333765443696047, "Bleu_3": 0.14287874532628775, "Bleu_4": 1.517522183850875e-05, "METEOR": 0.19966401150794866, "ROUGE_L": 0.2621642363775901, "CIDEr": 9.677931518709165e-12, "SPICE": {"All": {"pr": 0.10810810810810811, "re": 0.16, "f": 0.12903225806451613, "fn": 21.0, "numImages": 1.0, "fp": 33.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.4444444444444444, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "This is an image of a cell phone with a glowing light on the screen. The light is shining bright green and blue, and it appears to be coming from the phone's screen. The phone is sitting on a wooden floor, and there are some other objects in the background, such as a lamp and a bookshelf."}, "566672": {"image_id": 566672, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.17393278705640786, "Bleu_4": 0.1258146658036402, "METEOR": 0.29487264059680746, "ROUGE_L": 0.3286195286195286, "CIDEr": 1.3628244061117422e-07, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.10344827586206896, "f": 0.09230769230769231, "fn": 26.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.3, "f": 0.23076923076923075, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a baseball player in the batter's box, ready to hit the ball. The umpire is standing behind him, holding a baseball bat and wearing a white uniform with a red hat. The crowd is seated in the stands, watching the game."}, "202865": {"image_id": 202865, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.2623469285652076, "Bleu_3": 0.12298441547429191, "Bleu_4": 1.5076895886062216e-05, "METEOR": 0.29827063643640345, "ROUGE_L": 0.31145149525893506, "CIDEr": 4.347603351623764e-06, "SPICE": {"All": {"pr": 0.15625, "re": 0.1724137931034483, "f": 0.1639344262295082, "fn": 24.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A hand is holding a doughnut with a bite taken out of it. The doughnut has a glaze on top and is sprinkled with sugar. There are people in the background, some of whom are eating doughnuts as well."}, "226805": {"image_id": 226805, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.250791558703178, "Bleu_3": 0.1441458615321118, "Bleu_4": 0.09244973475148012, "METEOR": 0.2855630710675111, "ROUGE_L": 0.34269662921348315, "CIDEr": 1.3028048504649377e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.10714285714285714, "f": 0.14285714285714285, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a large, open living room with high ceilings and large windows. There are several couches and chairs arranged around the room, and a fireplace in one corner. The walls are painted white and there are several pieces of art on display."}, "235221": {"image_id": 235221, "Bleu_1": 0.37999999999240003, "Bleu_2": 0.2920721185692543, "Bleu_3": 0.22010508275712398, "Bleu_4": 0.14595050032627388, "METEOR": 0.2356994571010865, "ROUGE_L": 0.31624423963133635, "CIDEr": 5.553254559238451e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.36363636363636365, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a lightning storm in the background, with a clock tower in the foreground. The clock tower is illuminated by the lightning, and there are people standing on the sidewalk in front of it. The sky is dark and stormy, with clouds and lightning visible in the distance."}, "499402": {"image_id": 499402, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.4654746681029118, "Bleu_3": 0.32462845528236417, "Bleu_4": 0.20879582605318123, "METEOR": 0.3170184304004672, "ROUGE_L": 0.5029446407538279, "CIDEr": 0.1824299430779994, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.15625, "f": 0.21739130434782608, "fn": 27.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a view of the wing of an airplane from above, with the snow covered mountains in the background."}, "539557": {"image_id": 539557, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1923483450237976, "Bleu_3": 0.0958611289126843, "Bleu_4": 1.2106983211839111e-05, "METEOR": 0.2202195061824329, "ROUGE_L": 0.2506849315068493, "CIDEr": 2.2247027745327788e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a large ship with a purple and white hull, a white mast, and a white light on top of the mast. There are several birds flying in the sky above the ship. The background is a blue sky with some clouds."}, "109976": {"image_id": 109976, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.313559129551974, "Bleu_3": 0.22841694424328834, "Bleu_4": 0.16520235814636053, "METEOR": 0.31319349883414965, "ROUGE_L": 0.3951417004048583, "CIDEr": 0.00017489264631776337, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.2692307692307692, "f": 0.27999999999999997, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a kitchen with white cabinets and a white refrigerator. There is a stove and an oven on the countertops. The floor is made of tile and there is a microwave on the wall."}, "210448": {"image_id": 210448, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.16205747826449043, "Bleu_3": 0.0848444097298203, "Bleu_4": 1.0981334023238417e-05, "METEOR": 0.19901818940655994, "ROUGE_L": 0.28073635765943455, "CIDEr": 2.6927568013036687e-08, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2777777777777778, "f": 0.27027027027027023, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of zebras standing in a enclosure made of wood and metal bars. They are all looking at each other and appear to be in good health. There is a small pond in the background with some plants growing around it."}, "32724": {"image_id": 32724, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.18394180184223394, "Bleu_3": 0.13500589269947996, "Bleu_4": 0.08216107324774444, "METEOR": 0.24775843310922235, "ROUGE_L": 0.24247586598523563, "CIDEr": 2.7111543516410623e-14, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1111111111111111, "f": 0.10909090909090909, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of giraffes running across a grassy plain. They are running in a line, with their long necks and legs stretched out in front of them. The sky is clear and blue, with some clouds visible in the distance. The landscape is flat and open, with no trees or other vegetation in sight."}, "277689": {"image_id": 277689, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.18219102867095022, "Bleu_3": 0.08610272124760734, "Bleu_4": 1.0577185330931625e-05, "METEOR": 0.2640799525779094, "ROUGE_L": 0.2824074074074074, "CIDEr": 1.7190437775781456e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.24, "f": 0.2553191489361702, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2222222222222222, "f": 0.3636363636363636, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a white wedding cake with red strawberries on top, sitting on a glass table in front of a blue ocean. There are several glasses of champagne and other drinks on the table, as well as a few candles. The sky is clear and blue, with palm trees visible in the background."}, "167818": {"image_id": 167818, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.169030850940941, "Bleu_3": 0.0943664634767626, "Bleu_4": 1.263236816956828e-05, "METEOR": 0.17416196508100484, "ROUGE_L": 0.2420634920634921, "CIDEr": 7.941344315734697e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.45, "f": 0.3829787234042553, "fn": 11.0, "numImages": 1.0, "fp": 18.0, "tp": 9.0}, "Relation": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a desk with a computer, keyboard, mouse, and other office supplies. The desk is made of wood and has a white surface. There are windows on either side of the desk, providing natural light."}, "445135": {"image_id": 445135, "Bleu_1": 0.39999999999111113, "Bleu_2": 0.30151134457098727, "Bleu_3": 0.23321869982838225, "Bleu_4": 0.1734964202725773, "METEOR": 0.317135020371649, "ROUGE_L": 0.3903432228039558, "CIDEr": 9.404578004726476e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. He is wearing a black shirt and white shorts, and has a racket in his hand. The sun is shining down on him, casting a shadow on the ground."}, "3145": {"image_id": 3145, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.18726083047926023, "Bleu_4": 0.11465402609758038, "METEOR": 0.2330095912304027, "ROUGE_L": 0.3434201266713582, "CIDEr": 1.2764655873677009e-05, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.21212121212121213, "f": 0.23333333333333334, "fn": 26.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a living room with a couch, coffee table, and chairs. There are windows on either side of the room and a ceiling fan in the center. The walls are painted green and there is a rug on the floor."}, "319127": {"image_id": 319127, "Bleu_1": 0.423076923060651, "Bleu_2": 0.34418242031260665, "Bleu_3": 0.24556273427937614, "Bleu_4": 2.8326302346036566e-05, "METEOR": 0.30793370075872956, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.014758993267560284, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.16, "f": 0.14814814814814817, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a snowy scene with trees and a park bench in the foreground. The sky is cloudy and there are no people in the image."}, "380906": {"image_id": 380906, "Bleu_1": 0.5454545454297521, "Bleu_2": 0.322329185595152, "Bleu_3": 1.7319011025582833e-06, "Bleu_4": 4.0663421317499444e-09, "METEOR": 0.23087811903707842, "ROUGE_L": 0.40219780219780216, "CIDEr": 0.24268324566728655, "SPICE": {"All": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a picture of a bench on the beach with purple flowers in the foreground and the ocean in the background."}, "524850": {"image_id": 524850, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.09486600651870754, "Bleu_4": 1.1431164199464497e-05, "METEOR": 0.15229610901510116, "ROUGE_L": 0.2083096186681844, "CIDEr": 3.631637451751839e-11, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.3157894736842105, "f": 0.36363636363636365, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.625, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a large airplane with passengers boarding and deplaning. There are several people standing around the plane, some of them carrying luggage. The plane's engines are visible on the wing, and there is a large banner on the side of the plane that reads \"Welcome to [Airline Name]\"."}, "85926": {"image_id": 85926, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.19278507708010587, "Bleu_3": 0.09758032910433394, "Bleu_4": 1.2423831629820798e-05, "METEOR": 0.2658353807530415, "ROUGE_L": 0.3214756258234519, "CIDEr": 2.439121098265644e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.22727272727272727, "f": 0.23809523809523808, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a mother bear and her cubs standing in a field of tall grass. The mother bear is looking down at her cubs while they are eating something from the ground. There are birds flying in the sky above them."}, "102355": {"image_id": 102355, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.14695129936263138, "Bleu_3": 8.075839294554588e-07, "Bleu_4": 1.904915665082057e-09, "METEOR": 0.16952663976133472, "ROUGE_L": 0.21254355400696864, "CIDEr": 5.624829483341872e-07, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.043478260869565216, "f": 0.06666666666666667, "fn": 22.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image shows a group of people walking down the street with a horse and carriage. The people are dressed in traditional clothing and the horse is pulling the carriage. The building in the background is painted yellow and has a red roof."}, "47112": {"image_id": 47112, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.3333333333212081, "Bleu_3": 0.20445828459126097, "Bleu_4": 0.13597796343320864, "METEOR": 0.2702312344617227, "ROUGE_L": 0.3655821917808219, "CIDEr": 0.03839516083897663, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.10714285714285714, "f": 0.15384615384615383, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "There is a plate of pizza on the table with a glass of wine next to it. The pizza has various toppings such as mushrooms, pepperoni, and cheese."}, "215709": {"image_id": 215709, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.17504208247906033, "Bleu_3": 0.1322380251708152, "Bleu_4": 0.09711223048924789, "METEOR": 0.2140120542755413, "ROUGE_L": 0.2127164942461932, "CIDEr": 5.933418759547217e-13, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a bathroom with a sink, toilet, and shower. The walls are made of wood and there are tiles on the floor. There is a wooden bench in front of the sink and a mirror above it. The shower has a glass door and a curtain. There is a towel rack on the wall."}, "512982": {"image_id": 512982, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.3143473067169879, "Bleu_3": 0.21112681500742475, "Bleu_4": 2.6190877432762608e-05, "METEOR": 0.20251407827412146, "ROUGE_L": 0.39144385026737966, "CIDEr": 0.07416416691567786, "SPICE": {"All": {"pr": 0.16, "re": 0.14285714285714285, "f": 0.15094339622641512, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bathroom with a sink, toilet, and shower. The walls are painted yellow and there is a window in the background."}, "344633": {"image_id": 344633, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.0659858805309306, "Bleu_3": 4.4032899654667034e-07, "Bleu_4": 1.1431164199464498e-09, "METEOR": 0.2108470312910231, "ROUGE_L": 0.21266705403834982, "CIDEr": 1.6035916352522665e-12, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.19230769230769232, "f": 0.18867924528301885, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows two horses in a corral, one of which is being ridden by a person wearing a helmet and riding boots. The other horse is standing nearby, looking at the person on the back of the first horse. The ground is covered with grass and there are trees in the background."}, "555942": {"image_id": 555942, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.15694120513807777, "Bleu_3": 0.09698473885583787, "Bleu_4": 1.3686241957090147e-05, "METEOR": 0.1777931816567934, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.001068190401352369, "SPICE": {"All": {"pr": 0.12, "re": 0.125, "f": 0.12244897959183673, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of motorcycles parked on the sidewalk, with one bike in the foreground and several others in the background.\""}, "471567": {"image_id": 471567, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.22247460415230486, "Bleu_3": 0.13204059575577154, "Bleu_4": 0.08604354276570775, "METEOR": 0.18811636853561695, "ROUGE_L": 0.24646464646464644, "CIDEr": 1.1001343170658206e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.11764705882352941, "f": 0.15999999999999998, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a giraffe standing in front of a fence at an animal sanctuary. The giraffe has a long neck and spotted fur, and its eyes are looking directly at the camera. The background is a green and brown landscape with trees and rocks."}, "24260": {"image_id": 24260, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.16652655174285833, "Bleu_3": 0.11889429373840883, "Bleu_4": 0.08513012360629148, "METEOR": 0.16507189051692442, "ROUGE_L": 0.21554770318021202, "CIDEr": 0.0046105438818191576, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.05263157894736842, "f": 0.05405405405405406, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows two horses standing in a field with people watching them. One of the horses is white and brown, while the other is brown and white. They are both wearing saddles and bridles."}, "106508": {"image_id": 106508, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.19438820598718592, "Bleu_3": 1.0070384043317263e-06, "Bleu_4": 2.3078570221283513e-09, "METEOR": 0.2434029662418114, "ROUGE_L": 0.3398802061568464, "CIDEr": 2.283242649333588e-05, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.125, "f": 0.17142857142857143, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a traffic police officer standing on the side of the road, directing traffic. There are several cars and buses passing by in the background. The officer is wearing a yellow vest and holding a stop sign."}, "311082": {"image_id": 311082, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.1769023808359136, "Bleu_3": 0.09543806343349583, "Bleu_4": 1.2553771013542623e-05, "METEOR": 0.2707057063190774, "ROUGE_L": 0.28728414442700156, "CIDEr": 1.8031959730679078e-05, "SPICE": {"All": {"pr": 0.16, "re": 0.14285714285714285, "f": 0.15094339622641512, "fn": 24.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two elephants standing on the dirt path, looking at each other. One of them is larger than the other and has a trunk that is curled up. They are both wearing green and brown fur."}, "312167": {"image_id": 312167, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.22450662752633968, "Bleu_3": 0.1497806431280913, "Bleu_4": 1.844982574944515e-05, "METEOR": 0.20874298811360506, "ROUGE_L": 0.3078734858681023, "CIDEr": 0.0014149026657022388, "SPICE": {"All": {"pr": 0.28, "re": 0.35, "f": 0.3111111111111111, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is a painting of a pink flower in a vase on a table. The flower has long, thin stems and delicate, pink petals. The background is a soft, blurred red color."}, "324937": {"image_id": 324937, "Bleu_1": 0.7499999999531252, "Bleu_2": 0.6708203932066132, "Bleu_3": 0.577757035627622, "Bleu_4": 0.4935578819637505, "METEOR": 0.41909558280567527, "ROUGE_L": 0.7223684210526317, "CIDEr": 1.433079006163337, "SPICE": {"All": {"pr": 0.1, "re": 0.11538461538461539, "f": 0.10714285714285714, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "A small white dog is laying on top of a couch, looking up at the camera."}, "65415": {"image_id": 65415, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2132007163490489, "Bleu_3": 1.1360703054848368e-06, "Bleu_4": 2.6440739209103714e-09, "METEOR": 0.16464852543648126, "ROUGE_L": 0.21922731356693623, "CIDEr": 8.863618366253197e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.09523809523809523, "f": 0.16, "fn": 19.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}}, "caption": "This is a woman skiing down a snowy slope. She is wearing red and white clothing and has skis on her feet. There are trees in the background and a blue sky above."}, "201925": {"image_id": 201925, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.24809883171680105, "Bleu_3": 0.12568860753791988, "Bleu_4": 1.6039529419560237e-05, "METEOR": 0.2004438325383986, "ROUGE_L": 0.3396976929196499, "CIDEr": 0.0019142674103218593, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a cake baking in an oven. The cake is covered with flour and has a fork on top of it. There is a bowl of flour next to the oven."}, "273132": {"image_id": 273132, "Bleu_1": 0.4324324324207451, "Bleu_2": 0.28997255745928074, "Bleu_3": 0.19316228581877343, "Bleu_4": 0.14349260557576346, "METEOR": 0.349079646125722, "ROUGE_L": 0.36941710825132484, "CIDEr": 8.367363191782014e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14814814814814814, "f": 0.14545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of an older woman sitting on a bench in a park. She is wearing a hat and sunglasses, and has a cigarette in her hand. The background is a fence and some trees."}, "475238": {"image_id": 475238, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.17377018855424126, "Bleu_3": 8.509776518247445e-07, "Bleu_4": 1.8929027702829327e-09, "METEOR": 0.20275754763914502, "ROUGE_L": 0.23416506717850286, "CIDEr": 1.0581956005268273e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.24, "f": 0.23529411764705882, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a train traveling down the tracks. The train is made up of several cars, including a caboose and a locomotive. There are also several people standing on the platform, watching the train go by. The sky is clear and blue, with some clouds in the distance."}, "130527": {"image_id": 130527, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.15240998561606448, "Bleu_3": 0.08343000781860355, "Bleu_4": 1.104652199055032e-05, "METEOR": 0.1722194721369903, "ROUGE_L": 0.22197962154294032, "CIDEr": 8.514739191993113e-07, "SPICE": {"All": {"pr": 0.3, "re": 0.35294117647058826, "f": 0.3243243243243243, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a green field with cows grazing in it. In the background, there is a mountain range with blue sky and clouds. The image is taken from a car window, with the road running along the side of the field."}, "337563": {"image_id": 337563, "Bleu_1": 0.25806451612070763, "Bleu_2": 0.13116516715248897, "Bleu_3": 8.402586888233753e-07, "Bleu_4": 2.14545915648463e-09, "METEOR": 0.19346327494297083, "ROUGE_L": 0.17215428033866415, "CIDEr": 0.0006946472575952815, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.14285714285714285, "f": 0.18749999999999997, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The woman is sitting on the bed holding a banana in her hand. The child is sitting next to her, also holding a banana. They are both smiling at each other."}, "135356": {"image_id": 135356, "Bleu_1": 0.2758620689560048, "Bleu_2": 0.19851666678721847, "Bleu_3": 0.113434038700165, "Bleu_4": 1.539267887805166e-05, "METEOR": 0.2512688262555853, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.002152169493977593, "SPICE": {"All": {"pr": 0.4, "re": 0.35294117647058826, "f": 0.37500000000000006, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man standing in a kitchen, holding a sink sponge and looking at something on the counter. There is a stove and refrigerator in the background."}, "290078": {"image_id": 290078, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.29214466689738716, "Bleu_3": 0.19231133960538557, "Bleu_4": 2.1231792381840078e-05, "METEOR": 0.26677602691833274, "ROUGE_L": 0.32775560331593495, "CIDEr": 1.857699298443342e-05, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.08, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is an image of a toilet sitting on the sidewalk in front of a building. The toilet is white and has a small sink attached to it. There are no people or other objects in the image."}, "578314": {"image_id": 578314, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.15740004692952608, "Bleu_3": 8.91211038234751e-07, "Bleu_4": 2.1360710219633343e-09, "METEOR": 0.23959965255683888, "ROUGE_L": 0.20115416323165708, "CIDEr": 1.4548557348546333e-05, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet and sink in it. The walls are white and the floor is made of tile. There is a window on one side of the room that lets in natural light."}, "174893": {"image_id": 174893, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.14185186364132965, "Bleu_3": 8.020507112003898e-07, "Bleu_4": 1.9195767099451357e-09, "METEOR": 0.26888864361260434, "ROUGE_L": 0.22021660649819497, "CIDEr": 2.3392543906922293e-06, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.3684210526315789, "f": 0.28, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4117647058823529, "re": 0.875, "f": 0.56, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}}, "caption": "The little girl is sitting at a table with scissors in her hand, cutting up pieces of paper. She is wearing a pink shirt and has long blonde hair. The background is a wooden floor with a white tablecloth on it."}, "539310": {"image_id": 539310, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.2823298512746205, "Bleu_3": 0.1935115854658825, "Bleu_4": 0.13629358171800737, "METEOR": 0.21483565795891763, "ROUGE_L": 0.36309523809523814, "CIDEr": 0.1481569878980505, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a street with cars parked on both sides. There are trees and buildings in the background, and the sky is cloudy."}, "49740": {"image_id": 49740, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.12399138853119372, "Bleu_3": 0.0839337382802947, "Bleu_4": 0.05835255555224193, "METEOR": 0.1981444523944461, "ROUGE_L": 0.21863799283154117, "CIDEr": 3.97289900185401e-12, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.12, "f": 0.16666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a baseball player swinging a bat at a ball that is being thrown by a catcher. The player is wearing a white jersey with red and black stripes, and the catcher is wearing a black and white jersey. The background is a green field with trees in the distance."}, "274549": {"image_id": 274549, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.25928148941334883, "Bleu_3": 0.15971769248511944, "Bleu_4": 0.10622513109945873, "METEOR": 0.2599495845378156, "ROUGE_L": 0.2543786488740617, "CIDEr": 0.00016136889065795863, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.18181818181818182, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a backpack and carrying skis on their back. There are trees in the background and the sky is cloudy."}, "537211": {"image_id": 537211, "Bleu_1": 0.44444444441975317, "Bleu_2": 0.3615507630104168, "Bleu_3": 0.2904780222292266, "Bleu_4": 0.23909453159899263, "METEOR": 0.4172650714153907, "ROUGE_L": 0.6024691358024692, "CIDEr": 0.9308830297992574, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15789473684210525, "f": 0.15789473684210525, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The man is sitting on the dock, eating a hot dog. There are tall buildings in the background."}, "533743": {"image_id": 533743, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.11085479909296489, "Bleu_3": 0.07385893702641234, "Bleu_4": 9.052415449788016e-06, "METEOR": 0.19184083970404117, "ROUGE_L": 0.16061084781463927, "CIDEr": 2.231377402857196e-18, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.3888888888888889, "f": 0.2978723404255319, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.625, "f": 0.4166666666666667, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a man standing in front of a television playing video games. He is wearing a black shirt and jeans, and has a controller in his hand. There are other people in the room, some of whom are also playing video games on their own televisions. The room appears to be a living room with a couch, coffee table, and chairs."}, "81812": {"image_id": 81812, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.20597146021399534, "Bleu_3": 0.158770352928071, "Bleu_4": 0.13246197301306972, "METEOR": 0.2625326940235139, "ROUGE_L": 0.2872277810476751, "CIDEr": 1.731042762332514e-13, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting around a table in a restaurant, with plates of food in front of them. One person is holding up a plate of pasta, while another person is pouring wine into glasses. There are candles on the table and a view of the city outside through the windows."}, "59743": {"image_id": 59743, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.1769023808359136, "Bleu_3": 0.09543806343349583, "Bleu_4": 1.2553771013542623e-05, "METEOR": 0.20539551867170727, "ROUGE_L": 0.19709208400646203, "CIDEr": 6.131758271310819e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.08, "f": 0.09756097560975609, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of people surfing in the ocean. They are standing on their surfboards in the water, with the waves crashing against them. There is a cloudy sky in the background, with some clouds visible."}, "356131": {"image_id": 356131, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.294392028865574, "Bleu_3": 0.15561140325389933, "Bleu_4": 2.0343486922522005e-05, "METEOR": 0.2652126673403065, "ROUGE_L": 0.321390937829294, "CIDEr": 0.10690916440359902, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.14814814814814814, "f": 0.21052631578947367, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "A small boat is sailing on the water with a person sitting in it. The sky is cloudy and there are trees in the background."}, "311310": {"image_id": 311310, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.1756502051074256, "Bleu_3": 0.08197909100624547, "Bleu_4": 1.0004298733278404e-05, "METEOR": 0.19173186828796712, "ROUGE_L": 0.22431183021643206, "CIDEr": 8.172454626498207e-14, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.14285714285714285, "f": 0.12765957446808512, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people flying kites in a park. They are standing on a grassy field with trees in the background. One person is holding a kite and another is holding onto it. There are several other kites in the air, flying in different directions. The sky is clear and blue with some white clouds."}, "165257": {"image_id": 165257, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 0.07205793047605258, "Bleu_4": 9.44575929237223e-06, "METEOR": 0.17773754865946997, "ROUGE_L": 0.29647630619684084, "CIDEr": 3.087065123079183e-10, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.037037037037037035, "f": 0.05128205128205128, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This image shows a kitchen with wooden floors and cabinets. There is a sink and stove in the center of the room, and a refrigerator and microwave on the wall. The countertops are made of black granite, and there are several windows in the room that let in natural light."}, "202658": {"image_id": 202658, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.14922200399597868, "Bleu_3": 8.442829210502149e-07, "Bleu_4": 2.0220429578334317e-09, "METEOR": 0.15246936966244484, "ROUGE_L": 0.2347959969207082, "CIDEr": 3.5696402904658757e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.26666666666666666, "f": 0.2105263157894737, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a toilet in a bathroom. The toilet is pink and has a cartoon character on it. There is a sink next to the toilet and a trash can in the corner of the room."}, "50926": {"image_id": 50926, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.28729720244901713, "Bleu_3": 0.1693315787820608, "Bleu_4": 0.11013490543100266, "METEOR": 0.2681300450118851, "ROUGE_L": 0.33888888888888885, "CIDEr": 3.871431699194952e-05, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.19230769230769232, "f": 0.17543859649122806, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a large, empty field with mountains in the background. One person is holding a kite and another is holding a camera to take a photo."}, "514797": {"image_id": 514797, "Bleu_1": 0.378378378368152, "Bleu_2": 0.17757120129627854, "Bleu_3": 9.65811429093868e-07, "Bleu_4": 2.2688173050579472e-09, "METEOR": 0.1756246727496278, "ROUGE_L": 0.23735408560311286, "CIDEr": 1.661247519815716e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09375, "f": 0.11320754716981132, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A group of people are standing on the beach, looking up at a kite flying in the sky. The kite has a blue and white design with a red tail. There is a lighthouse in the background."}, "258021": {"image_id": 258021, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.14270041527824082, "Bleu_3": 0.09047027838968494, "Bleu_4": 1.0821339066753336e-05, "METEOR": 0.17725146131771466, "ROUGE_L": 0.20670958996950187, "CIDEr": 3.372917462990648e-14, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.05263157894736842, "f": 0.06060606060606061, "fn": 18.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a man standing on the sidewalk next to a parked motorcycle. He is wearing a black jacket and has his hands in his pockets. There are puddles of water on the sidewalk and the ground is wet. The building behind him appears to be made of concrete and has windows on the upper floors."}, "203085": {"image_id": 203085, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.1295047816452144, "Bleu_3": 6.857872734978661e-07, "Bleu_4": 1.5858040477395045e-09, "METEOR": 0.19257978287336033, "ROUGE_L": 0.24355464293862653, "CIDEr": 3.842467451342478e-11, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.045454545454545456, "f": 0.060606060606060615, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "This is a man sitting at a desk in a room. He is wearing a white shirt and blue pants. There are several items on the desk, including a computer, a keyboard, and a mouse. The walls of the room are painted a light gray color and there is a window in the background."}, "441442": {"image_id": 441442, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.13794014695833945, "Bleu_3": 7.680285411963504e-07, "Bleu_4": 1.82321151624697e-09, "METEOR": 0.1942327187438971, "ROUGE_L": 0.214185393258427, "CIDEr": 7.616455247614682e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.09375, "f": 0.1111111111111111, "fn": 29.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a horse and rider in a field with a fence in the background. The horse is brown and has a saddle on its back. The rider is wearing a helmet and riding boots. There are flowers and grass in the background."}, "494759": {"image_id": 494759, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.1889822365007167, "Bleu_3": 0.1448554036562842, "Bleu_4": 0.10721833691147503, "METEOR": 0.2898034502031619, "ROUGE_L": 0.3441389809259425, "CIDEr": 7.392803100396141e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two people standing on a beach with a kite flying in the sky. The person on the left is holding the kite and the person on the right is looking at it. There are clouds in the sky and the sun is shining down on them."}, "336937": {"image_id": 336937, "Bleu_1": 0.27272727271487607, "Bleu_2": 3.603749850614529e-09, "Bleu_3": 8.659505512791422e-12, "Bleu_4": 4.299633317430035e-13, "METEOR": 0.13658536585365852, "ROUGE_L": 0.20109890109890108, "CIDEr": 0.03668814198882136, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.42857142857142855, "f": 0.27272727272727276, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This image shows a large number of white ceramic sinks arranged in rows, with no visible people or objects in the background."}, "157155": {"image_id": 157155, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.12903971808302675, "Bleu_3": 7.179233837245351e-07, "Bleu_4": 1.7029245450294905e-09, "METEOR": 0.18254150069964878, "ROUGE_L": 0.21075665092709892, "CIDEr": 2.0325551540085124e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23809523809523808, "f": 0.19607843137254902, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a photograph of a street scene at night. There are several people walking down the sidewalk, some of whom are wearing costumes and holding balloons. In the background, there are several buildings with lights on, including a large building with a sign that reads \"Theater.\""}, "243600": {"image_id": 243600, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.2537081316938597, "Bleu_3": 1.3197861940352348e-06, "Bleu_4": 3.0376430894125655e-09, "METEOR": 0.22240481020694827, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.006830007075889088, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.25925925925925924, "f": 0.3181818181818182, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is an image of a library with several people sitting at tables reading books. There are bookshelves on the walls and a fireplace in the corner of the room."}, "542147": {"image_id": 542147, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.161880977056518, "Bleu_3": 7.95785637725362e-07, "Bleu_4": 1.772982824869927e-09, "METEOR": 0.23742572892610642, "ROUGE_L": 0.20962199312714777, "CIDEr": 2.7727177670321975e-12, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3157894736842105, "f": 0.2608695652173913, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a large, open field with several cows grazing in it. In the background, there is a large building with windows and a roof. The building appears to be under construction, with scaffolding and construction equipment visible on the ground. The sky is clear and blue, with some clouds in the distance."}, "277227": {"image_id": 277227, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.126168012373563, "Bleu_3": 0.06921800773739777, "Bleu_4": 9.165155901802696e-06, "METEOR": 0.17587396265406732, "ROUGE_L": 0.18944099378881987, "CIDEr": 6.506998568249594e-11, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.22727272727272727, "f": 0.20408163265306123, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a photograph of a small boat docked in a harbor. The boat is white and has a blue hull. There are several other boats docked nearby, some of which are also white and have blue hulls. The background is made up of buildings with red roofs and greenery."}, "323552": {"image_id": 323552, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.38674623406228154, "Bleu_3": 0.18153932907774883, "Bleu_4": 2.2344736320294692e-05, "METEOR": 0.27755279250873116, "ROUGE_L": 0.3621713316369805, "CIDEr": 0.07057659826809269, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A young woman sits on the floor next to her luggage at an airport, looking at her phone.\""}, "319607": {"image_id": 319607, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.3216337604404325, "Bleu_3": 0.15459249573783163, "Bleu_4": 1.923314763603185e-05, "METEOR": 0.23601557364280928, "ROUGE_L": 0.3523102310231023, "CIDEr": 0.025029531834834605, "SPICE": {"All": {"pr": 0.3, "re": 0.15789473684210525, "f": 0.20689655172413793, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is an image of a street with a red light at the intersection. There are buildings on either side of the street, and people are walking on the sidewalk."}, "581702": {"image_id": 581702, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2663118206400466, "Bleu_3": 0.18338382022808725, "Bleu_4": 0.12866935745872493, "METEOR": 0.2885108837283171, "ROUGE_L": 0.27799479166666663, "CIDEr": 6.0462278817156026e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a small bird perched on a rock in a garden. The bird has a red head and black and white feathers, with a yellow beak. It is standing on one leg, looking down at the ground. There are some leaves and branches in the background."}, "328818": {"image_id": 328818, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.13869867869725044, "Bleu_4": 0.11138679826412459, "METEOR": 0.25459852471426564, "ROUGE_L": 0.3246407663650879, "CIDEr": 1.6312046738832435e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA woman is sitting on a bench next to a bike rack in the woods. She is wearing pink pants and a white shirt, and has her bicycle propped up against the rack. The trees are green and there is a path leading through the woods."}, "55981": {"image_id": 55981, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.2148344622034018, "Bleu_3": 1.2435565865487868e-06, "Bleu_4": 3.0238984686568405e-09, "METEOR": 0.2172601001264495, "ROUGE_L": 0.32737030411449025, "CIDEr": 0.02161070097091676, "SPICE": {"All": {"pr": 0.125, "re": 0.08, "f": 0.09756097560975609, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The little girl is standing in front of a staircase, holding a suitcase and wearing a pink sweater. She looks happy and excited to be traveling."}, "385918": {"image_id": 385918, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.30678599553005403, "Bleu_3": 0.20453114927632365, "Bleu_4": 0.12787395553128056, "METEOR": 0.27504893278313697, "ROUGE_L": 0.3561301084236864, "CIDEr": 0.00038706819185772574, "SPICE": {"All": {"pr": 0.08, "re": 0.1111111111111111, "f": 0.09302325581395349, "fn": 16.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people playing frisbee on a field. One person is throwing the frisbee while another person is catching it. There are several other people in the background watching the game."}, "86625": {"image_id": 86625, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.25819888974062344, "Bleu_3": 0.21915874167881316, "Bleu_4": 0.1836680712977894, "METEOR": 0.323731372198519, "ROUGE_L": 0.3685800604229607, "CIDEr": 2.508837179931171e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.18181818181818182, "f": 0.21621621621621623, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a man standing in front of a refrigerator with a container of food on the counter. He is wearing a black hoodie and has his hands in his pockets. The image appears to be taken in a kitchen."}, "87429": {"image_id": 87429, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.17320508074981525, "Bleu_3": 0.1092608243577702, "Bleu_4": 1.560424226798813e-05, "METEOR": 0.14952101601919807, "ROUGE_L": 0.3141630901287554, "CIDEr": 0.03982710923813881, "SPICE": {"All": {"pr": 0.02857142857142857, "re": 0.05263157894736842, "f": 0.037037037037037035, "fn": 18.0, "numImages": 1.0, "fp": 34.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.06666666666666667, "re": 0.125, "f": 0.08695652173913045, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}}, "caption": "The image shows a large brick building with several cars parked in front of it. There are also trees and bushes visible in the background."}, "330091": {"image_id": 330091, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.21967782188085846, "Bleu_3": 0.09817496396521207, "Bleu_4": 1.172892101907699e-05, "METEOR": 0.2170494839136494, "ROUGE_L": 0.28571428571428575, "CIDEr": 3.7217246848996037e-07, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.25, "f": 0.27450980392156865, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.38461538461538464, "f": 0.4761904761904762, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is an image of a skier on a snowy slope. The skier is wearing a red and black jacket, black pants, and black ski boots. They are holding onto the handlebars of their snowboard as they ride down the slope. In the background, there are trees and mountains visible through the fog."}, "491851": {"image_id": 491851, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.16302782918400804, "Bleu_3": 0.08654590923115621, "Bleu_4": 1.1282878483696187e-05, "METEOR": 0.24404661152398746, "ROUGE_L": 0.283344392833444, "CIDEr": 1.1690236015223236e-06, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.1111111111111111, "f": 0.12903225806451615, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is a cluttered room with a computer desk, chair, and other items. There are several cables and wires hanging from the ceiling and walls. The walls are painted a light green color and there are windows on one side of the room."}, "203661": {"image_id": 203661, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.1448065155642414, "Bleu_4": 0.09517889238081183, "METEOR": 0.25210691235878313, "ROUGE_L": 0.32250755287009064, "CIDEr": 1.348813493062587e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1724137931034483, "f": 0.22727272727272724, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a small kitchen with a wooden table and chairs. There is a stove on the counter and a sink next to it. The walls are painted white and there are some pots and pans hanging from the ceiling."}, "150875": {"image_id": 150875, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.12768847960837637, "Bleu_3": 9.049548604494648e-07, "Bleu_4": 2.437335780312719e-09, "METEOR": 0.16346956169215587, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.00903074977248461, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.14814814814814814, "f": 0.2, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is a bench made of stone with intricate carvings on it. It is located in a park with trees and flowers around it."}, "99707": {"image_id": 99707, "Bleu_1": 0.5714285714013606, "Bleu_2": 0.1690308509374531, "Bleu_3": 1.1456697640101971e-06, "Bleu_4": 3.023266712930042e-09, "METEOR": 0.25691703302107194, "ROUGE_L": 0.35924617196702, "CIDEr": 0.15242865188280846, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.0967741935483871, "f": 0.15000000000000002, "fn": 28.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "A person is standing in the snow wearing a purple jacket and holding skis. The sign in the background reads \"superstar\"."}, "124647": {"image_id": 124647, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.13386988814827444, "Bleu_3": 0.08375716851901807, "Bleu_4": 9.947837396031269e-06, "METEOR": 0.2092258211405849, "ROUGE_L": 0.21585279547062985, "CIDEr": 9.943206877276603e-17, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.23809523809523808, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a young boy wearing a black helmet and standing next to a skateboard ramp. He is looking down at the ground with his hands on his hips, as if he is contemplating something. There are other people in the background, including some adults and children, who are also skateboarding. The sky is cloudy and there are trees in the background."}, "62167": {"image_id": 62167, "Bleu_1": 0.36842105261218844, "Bleu_2": 0.20232565954468354, "Bleu_3": 0.13403483047483825, "Bleu_4": 1.9696236772973402e-05, "METEOR": 0.18241531133796718, "ROUGE_L": 0.2398427260812582, "CIDEr": 0.1541396242390392, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.13333333333333333, "f": 0.10256410256410255, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a man standing in the grass with his dog, while other dogs are running around him."}, "300221": {"image_id": 300221, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.1646013245913028, "Bleu_3": 1.0011541742360995e-06, "Bleu_4": 2.4924840328306803e-09, "METEOR": 0.181062130357905, "ROUGE_L": 0.272078501338091, "CIDEr": 0.0026176524453390203, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09523809523809523, "f": 0.12121212121212123, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a display of fresh vegetables and fruits in wooden crates. There are carrots, beets, potatoes, onions, garlic, and other vegetables arranged in rows on the shelves."}, "109537": {"image_id": 109537, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.17787191480959694, "Bleu_3": 8.170756266318369e-07, "Bleu_4": 1.7588466577944542e-09, "METEOR": 0.20627525976666122, "ROUGE_L": 0.25738396624472576, "CIDEr": 1.8121829760567143e-15, "SPICE": {"All": {"pr": 0.125, "re": 0.15384615384615385, "f": 0.13793103448275862, "fn": 22.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This image shows a surfer riding a wave on a surfboard. The surfer is wearing a wetsuit and sunglasses, and is standing on the board with one foot in the air. The wave is large and white, and is crashing onto the shore. There are people watching from the beach, and a few buildings can be seen in the background."}, "382715": {"image_id": 382715, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.11725757533584186, "Bleu_3": 6.119418985567577e-07, "Bleu_4": 1.4038465507365007e-09, "METEOR": 0.16886464396573767, "ROUGE_L": 0.22356020942408372, "CIDEr": 1.103291768028523e-16, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A person on a skateboard riding down the sidewalk\n\nThe image shows a person on a skateboard riding down a sidewalk in front of a group of buildings. The person is wearing a black jacket and black pants, and has a red hat on their head. There are cars parked along the side of the road, and people walking on the sidewalk."}, "52596": {"image_id": 52596, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.3120938919516558, "Bleu_3": 0.24446720039491812, "Bleu_4": 0.1665240823320508, "METEOR": 0.29974695884461106, "ROUGE_L": 0.38985939497230504, "CIDEr": 0.1542086477372459, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The little girl is holding a slice of pizza in her hand and looking at it with a smile on her face."}, "500718": {"image_id": 500718, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.22217382360533403, "Bleu_3": 0.13514041895491033, "Bleu_4": 1.586071618969467e-05, "METEOR": 0.18989394022169523, "ROUGE_L": 0.2881241565452092, "CIDEr": 1.8159141543666002e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of airplanes parked on the tarmac at an airport. They are all painted in different colors and have their landing gear extended. There are people standing around the planes, looking at them or talking to each other."}, "182240": {"image_id": 182240, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.2782433374469758, "Bleu_3": 0.20007412898454674, "Bleu_4": 0.13004800470982877, "METEOR": 0.24632442501499718, "ROUGE_L": 0.3125533731853117, "CIDEr": 0.0020909547510711193, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of zebras standing in a field with tall grass and trees in the background. They are all facing the same direction, looking out into the distance."}, "525083": {"image_id": 525083, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.17996850826166377, "Bleu_3": 0.0956600132176177, "Bleu_4": 1.248740514185277e-05, "METEOR": 0.22088770498142216, "ROUGE_L": 0.2897862232779097, "CIDEr": 1.9098239592579665e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a kitchen with wooden floors and white cabinets. There is a table in the center of the room with chairs around it. The walls are painted white and there are windows on one side of the room."}, "56821": {"image_id": 56821, "Bleu_1": 0.382352941165225, "Bleu_2": 0.10764038629729775, "Bleu_3": 7.12743894381194e-07, "Bleu_4": 1.8486713289327752e-09, "METEOR": 0.24126354915784973, "ROUGE_L": 0.25206611570247933, "CIDEr": 0.0002605789006717242, "SPICE": {"All": {"pr": 0.15, "re": 0.1111111111111111, "f": 0.12765957446808512, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a street scene in a city with tall buildings on either side of the road. There are people walking down the sidewalk and cars driving by. The sky is clear and blue."}, "256367": {"image_id": 256367, "Bleu_1": 0.35294117644982703, "Bleu_2": 0.2572478776981582, "Bleu_3": 1.6401017070887656e-06, "Bleu_4": 4.2132873222835864e-09, "METEOR": 0.24315758541560337, "ROUGE_L": 0.4662420382165604, "CIDEr": 0.38934004286852203, "SPICE": {"All": {"pr": 0.15, "re": 0.10344827586206896, "f": 0.12244897959183673, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a train traveling on the tracks, with trees and buildings visible in the background."}, "42667": {"image_id": 42667, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.17842851423634928, "Bleu_3": 0.10987673829748816, "Bleu_4": 1.2961487777593183e-05, "METEOR": 0.23202349238029488, "ROUGE_L": 0.22938079719227877, "CIDEr": 2.815158098626416e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.11538461538461539, "f": 0.13333333333333333, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young girl sitting on top of a suitcase, looking up at the camera with a curious expression on her face. She is wearing a green shirt and has long black hair. The background is a messy room with a couch and a table in the foreground."}, "388453": {"image_id": 388453, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.11651034560483009, "Bleu_3": 6.475197095245912e-07, "Bleu_4": 1.5342308957715506e-09, "METEOR": 0.19296622530737298, "ROUGE_L": 0.17609699769053117, "CIDEr": 1.3799298573852775e-11, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a large room with a high ceiling and chandeliers hanging from it. There are several people standing around the room, dressed in suits and dresses, talking to each other. The walls are painted white and there are windows on either side of the room that let in natural light."}, "38118": {"image_id": 38118, "Bleu_1": 0.7499999998125003, "Bleu_2": 0.5669467093670424, "Bleu_3": 0.4749571256683354, "Bleu_4": 0.38260294151932694, "METEOR": 0.4063432927421277, "ROUGE_L": 0.5820610687022901, "CIDEr": 1.3003587891771142, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.18518518518518517, "f": 0.17857142857142858, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "A person skiing down a snowy mountain slope."}, "305319": {"image_id": 305319, "Bleu_1": 0.2105263157857803, "Bleu_2": 0.1371021242743437, "Bleu_3": 0.06991578304852385, "Bleu_4": 8.919345345892188e-06, "METEOR": 0.19744584103360902, "ROUGE_L": 0.24413950829045164, "CIDEr": 2.969177466648483e-14, "SPICE": {"All": {"pr": 0.4, "re": 0.17142857142857143, "f": 0.24000000000000002, "fn": 29.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.35714285714285715, "f": 0.45454545454545453, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a black wetsuit and has their arms outstretched to balance themselves on the board. The water is choppy and there are whitecaps on the surface of the waves. The sky is clear and blue, with some clouds visible in the distance."}, "410484": {"image_id": 410484, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.08223919396405388, "Bleu_3": 5.356753613377428e-07, "Bleu_4": 1.3750203938570617e-09, "METEOR": 0.16720046185722587, "ROUGE_L": 0.24830393487109906, "CIDEr": 2.4125847902235088e-06, "SPICE": {"All": {"pr": 0.1875, "re": 0.1111111111111111, "f": 0.13953488372093023, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a bride and groom cutting into a cake with a red, white, and blue design. The bride is wearing a white dress and the groom is wearing a black suit. There are several plates of food on the table in front of them."}, "454252": {"image_id": 454252, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2908872369299581, "Bleu_3": 0.21950939626031343, "Bleu_4": 0.14643937863774928, "METEOR": 0.3378292154984874, "ROUGE_L": 0.39019189765458434, "CIDEr": 0.03385798948124653, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.75, "f": 0.75, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "Here is a short caption for the image:\n\n\"A group of people standing in front of a barrel of wine, smiling and holding glasses of wine.\""}, "245153": {"image_id": 245153, "Bleu_1": 0.5833333332361111, "Bleu_2": 0.32566947358395304, "Bleu_3": 2.197107811108781e-06, "Bleu_4": 5.859059369098998e-09, "METEOR": 0.1811591444677181, "ROUGE_L": 0.4326241134751773, "CIDEr": 0.3974839609348265, "SPICE": {"All": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 12.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Two puffins perched on top of a grassy hill overlooking the ocean."}, "528980": {"image_id": 528980, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.14544361846700224, "Bleu_3": 8.226250211193223e-07, "Bleu_4": 1.9694774163640186e-09, "METEOR": 0.17692485271721323, "ROUGE_L": 0.23036253776435048, "CIDEr": 2.8172323665444963e-06, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.1935483870967742, "f": 0.19999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is an image of a red and white umbrella on the sidewalk in front of a building. The umbrella is open and has a handle on top. There are cars parked on the street in front of the building."}, "402118": {"image_id": 402118, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.07347183583515587, "Bleu_3": 5.26437340454787e-07, "Bleu_4": 1.4188431559098949e-09, "METEOR": 0.16723373170040148, "ROUGE_L": 0.22846441947565538, "CIDEr": 2.023783640602081e-06, "SPICE": {"All": {"pr": 0.1875, "re": 0.15789473684210525, "f": 0.17142857142857143, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a person snowboarding down a mountain. The person is wearing a white suit and helmet, and is jumping off a ramp while holding onto the board. The background is a black and white photograph of mountains."}, "303893": {"image_id": 303893, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.15694120513807777, "Bleu_3": 0.09698473885583787, "Bleu_4": 1.3686241957090147e-05, "METEOR": 0.2097476630311268, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.005064861645575546, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.29411764705882354, "f": 0.3448275862068966, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.6666666666666666, "f": 0.7272727272727272, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows two young children sitting on the ground, one holding a bowl of food and the other holding a spoon. They are surrounded by trees and greenery."}, "491836": {"image_id": 491836, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.2385593618010997, "Bleu_3": 0.17853812773870492, "Bleu_4": 0.13070421084372014, "METEOR": 0.24768056549305767, "ROUGE_L": 0.34609929078014184, "CIDEr": 6.243717862607236e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.09090909090909091, "f": 0.13636363636363635, "fn": 30.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a body of water with a small boat in the distance. The sky is clear and blue, with some clouds in the distance. There are trees on the shore and a small island in the middle of the water."}, "456816": {"image_id": 456816, "Bleu_1": 0.5833333332847223, "Bleu_2": 0.46056618643171326, "Bleu_3": 0.2768182380335083, "Bleu_4": 3.918189149692743e-05, "METEOR": 0.21205375641048094, "ROUGE_L": 0.43821839080459773, "CIDEr": 0.5249144276335967, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "A plate with a doughnut on it sitting on a wooden table."}, "495825": {"image_id": 495825, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.14357265694226845, "Bleu_3": 0.07887960518628792, "Bleu_4": 1.045990118964594e-05, "METEOR": 0.1498294686074396, "ROUGE_L": 0.19677419354838707, "CIDEr": 5.3942026770273535e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10344827586206896, "f": 0.1276595744680851, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a herd of cows grazing in a green field with mountains in the background. The sky is clear and blue, with some clouds scattered across it. The sun is setting in the distance, casting a warm orange glow over the scene."}, "174740": {"image_id": 174740, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.36890203261675947, "Bleu_3": 0.23874852587662318, "Bleu_4": 2.617315183516272e-05, "METEOR": 0.26157515202869497, "ROUGE_L": 0.4080267558528428, "CIDEr": 0.006336632607614919, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 25.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.06666666666666667, "re": 0.1111111111111111, "f": 0.08333333333333334, "fn": 8.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a box of donuts sitting on top of a wooden table. There is a bottle of soda next to the box and a glass of water on the table."}, "507037": {"image_id": 507037, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.22538468968297923, "Bleu_3": 0.18147214205472437, "Bleu_4": 0.13760850821115508, "METEOR": 0.2917892738425711, "ROUGE_L": 0.2959369314736203, "CIDEr": 4.081391223037821e-11, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.19047619047619047, "f": 0.14814814814814814, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4444444444444444, "f": 0.32, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a group of people standing outside a building with bicycles parked next to them. The building appears to be a church with a large cross on the front. There are several people standing in front of the building, some of whom are holding bicycles. The sky is clear and sunny."}, "57323": {"image_id": 57323, "Bleu_1": 0.23809523809145886, "Bleu_2": 0.1752768273470684, "Bleu_3": 0.10024199990373374, "Bleu_4": 1.138280980594174e-05, "METEOR": 0.2289656231181395, "ROUGE_L": 0.19645732689210949, "CIDEr": 1.3819153700939746e-18, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5, "f": 0.588235294117647, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a group of people riding motorcycles down the street. They are all wearing helmets and riding in a line, with one person leading the way. There are cars parked on both sides of the road, and a few people are standing on the sidewalk watching the motorcyclists pass by. The sky is clear and blue, with no clouds in sight."}, "516038": {"image_id": 516038, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.27327631272580527, "Bleu_3": 0.12753630366950341, "Bleu_4": 1.560300897501174e-05, "METEOR": 0.2397932474517964, "ROUGE_L": 0.28728414442700156, "CIDEr": 1.2075593615084056e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.16666666666666666, "f": 0.1851851851851852, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a baseball game in progress on a green field. There are several players on the field, including one pitcher throwing a ball to a catcher. The crowd is seated in the stands behind the field."}, "433915": {"image_id": 433915, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.13187609467625871, "Bleu_3": 7.338824344329119e-07, "Bleu_4": 1.741216427287497e-09, "METEOR": 0.20439557997040736, "ROUGE_L": 0.2719745222929936, "CIDEr": 5.330115321686343e-08, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.11764705882352941, "f": 0.1111111111111111, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man and woman standing in front of a television screen. The man is wearing a suit and tie, while the woman is wearing a red shirt and black pants. They are both looking at the screen with serious expressions on their faces."}, "17899": {"image_id": 17899, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.14531393175596577, "Bleu_3": 0.07502652544655376, "Bleu_4": 9.635230436528825e-06, "METEOR": 0.18148251084394063, "ROUGE_L": 0.2167219327333018, "CIDEr": 3.135170419376838e-11, "SPICE": {"All": {"pr": 0.08, "re": 0.06451612903225806, "f": 0.07142857142857142, "fn": 29.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA woman is sitting at a table, cutting bread into small pieces. There are several other items on the table, including a loaf of bread, a knife, and some plates. The woman is wearing an apron and has a spoon in her hand."}, "298252": {"image_id": 298252, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.22450662752633968, "Bleu_3": 0.17145603544752394, "Bleu_4": 0.13654398783043348, "METEOR": 0.35460918294532817, "ROUGE_L": 0.3798932384341636, "CIDEr": 0.0015137277646758516, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.3076923076923077, "f": 0.1951219512195122, "fn": 9.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a display case filled with various types of donuts, including chocolate frosted, glazed, and sprinkled. There are also other baked goods such as croissants and muffins on the shelves."}, "222370": {"image_id": 222370, "Bleu_1": 0.14062499999780276, "Bleu_2": 0.06681531047705384, "Bleu_3": 4.160256400067748e-07, "Bleu_4": 1.0423357040180334e-09, "METEOR": 0.10648543065327046, "ROUGE_L": 0.15852390852390852, "CIDEr": 6.55844503221692e-20, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.30434782608695654, "f": 0.31111111111111117, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of people walking down a narrow street lined with tall buildings on either side. The buildings are made of stone and have balconies on the upper floors. There is a small park in the center of the street with trees and benches. The people in the image are wearing casual clothing and appear to be walking to their destination."}, "374448": {"image_id": 374448, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.11725757533584186, "Bleu_3": 6.119418985567577e-07, "Bleu_4": 1.4038465507365007e-09, "METEOR": 0.17464299188474652, "ROUGE_L": 0.20788704965920152, "CIDEr": 2.08861519158083e-15, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 27.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07692307692307693, "f": 0.09090909090909093, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.38461538461538464, "f": 0.41666666666666663, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a large, open room with high ceilings and wooden beams. There are several long tables set up in the room, each with several people sitting at them. The walls are painted a warm, earthy color and there are several large windows that let in natural light. A large chandelier hangs from the ceiling, providing additional lighting to the room."}, "181278": {"image_id": 181278, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.07591054832679767, "Bleu_3": 5.003594906637297e-07, "Bleu_4": 1.291690536859318e-09, "METEOR": 0.21573033707865175, "ROUGE_L": 0.23461538461538461, "CIDEr": 4.865321684620849e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.19230769230769232, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of young boys playing baseball on a field. They are wearing white and blue uniforms with the number 12 on their jerseys. One boy is throwing a ball while another is catching it. There are several spectators in the background watching the game."}, "373789": {"image_id": 373789, "Bleu_1": 0.378378378368152, "Bleu_2": 0.25112360116008, "Bleu_3": 0.17549958365991042, "Bleu_4": 0.11228903217058282, "METEOR": 0.18611419341760932, "ROUGE_L": 0.24419535628502803, "CIDEr": 0.0009958421119335924, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.17857142857142858, "f": 0.23255813953488372, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a plate with two pieces of toast on it. One piece has chicken on it and the other has cheese on it. The plate is sitting on a counter in a kitchen."}, "251124": {"image_id": 251124, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.18476851073338801, "Bleu_3": 9.824666233056464e-07, "Bleu_4": 2.2815045692245487e-09, "METEOR": 0.23242062543898304, "ROUGE_L": 0.30897250361794504, "CIDEr": 3.278769372830172e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a bicycle parked on the sidewalk in front of a city skyline at night. The sky is filled with bright lights and the reflection of the city's buildings can be seen in the water."}, "162249": {"image_id": 162249, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.1027737074612707, "Bleu_4": 0.0696982798311994, "METEOR": 0.21028760301212934, "ROUGE_L": 0.23303196230739842, "CIDEr": 1.0304484695579922e-09, "SPICE": {"All": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a bathroom with a large tub in the center of the room. There are two windows on either side of the tub and a mirror on the wall opposite the tub. The floor is made of wood and there is a rug in front of the tub."}, "551908": {"image_id": 551908, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.5838742080702745, "Bleu_3": 0.40852897028427665, "Bleu_4": 0.29502343629121847, "METEOR": 0.374151714560774, "ROUGE_L": 0.5865384615384615, "CIDEr": 1.8030210079255156, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a plate of food with fish, broccoli, and potatoes."}, "366367": {"image_id": 366367, "Bleu_1": 0.27536231883658896, "Bleu_2": 0.21105426912770198, "Bleu_3": 0.14924318019292332, "Bleu_4": 0.10018262019005832, "METEOR": 0.19793145439973206, "ROUGE_L": 0.20839433870180576, "CIDEr": 1.8584695139953735e-21, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.06896551724137931, "f": 0.0784313725490196, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young girl is standing in front of a whiteboard with various words and phrases written on it. She is holding a small tablet in her hand and looking at it intently. The room is filled with various educational materials, such as books and posters, and there are several other children standing around the room, also looking at their tablets."}, "231343": {"image_id": 231343, "Bleu_1": 0.3399999999932, "Bleu_2": 0.2634155559173319, "Bleu_3": 0.21629503306402295, "Bleu_4": 0.15941924907234672, "METEOR": 0.22600411914871485, "ROUGE_L": 0.26228501228501233, "CIDEr": 1.3350365495539585e-06, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.4166666666666667, "f": 0.29411764705882354, "fn": 7.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a baseball player in the middle of a game. He is wearing a black and white uniform with a number on the back and is holding a bat. The field behind him is green and there are other players on the field playing the game."}, "236290": {"image_id": 236290, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.2942449431545567, "Bleu_3": 0.16297813359661212, "Bleu_4": 2.1847844936428674e-05, "METEOR": 0.24250316799355823, "ROUGE_L": 0.2911694510739857, "CIDEr": 0.11205328117489739, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.1724137931034483, "f": 0.17857142857142858, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a person standing on the stairs of an airport with a suitcase in hand, looking up at the escalator."}, "189095": {"image_id": 189095, "Bleu_1": 0.3157894736675901, "Bleu_2": 0.2294157338581519, "Bleu_3": 0.183629516657305, "Bleu_4": 2.4941747175577164e-05, "METEOR": 0.17489049410428395, "ROUGE_L": 0.3053817271589487, "CIDEr": 0.3109324693368632, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16666666666666666, "f": 0.19512195121951217, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two brown bears standing on the ground, one of them is biting the other's ear."}, "426546": {"image_id": 426546, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.18535150310271878, "Bleu_3": 0.11783047902946191, "Bleu_4": 0.0794780619228253, "METEOR": 0.1973841578604651, "ROUGE_L": 0.2889039242219215, "CIDEr": 5.606417025864669e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a plate of food with two sandwiches, fries, and a drink on the table. The sandwiches are made with meat and cheese, and the fries are served with ketchup and mustard. There is also a glass of soda on the table."}, "114119": {"image_id": 114119, "Bleu_1": 0.3199999999936, "Bleu_2": 0.18070158057739935, "Bleu_3": 0.08794832144810152, "Bleu_4": 1.0968473790380014e-05, "METEOR": 0.20601765534120814, "ROUGE_L": 0.2357639783560938, "CIDEr": 3.059289885562547e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.09523809523809523, "f": 0.10256410256410256, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a cat sleeping on top of a clock. The clock has the numbers 12, 3, 6, and 9 on it. The cat is laying on its back with its paws tucked under its body. The cat's eyes are closed and it appears to be very relaxed."}, "290828": {"image_id": 290828, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.23546453742246556, "Bleu_3": 0.15461557958139502, "Bleu_4": 0.10625281384108193, "METEOR": 0.19074433511378777, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.0013367553688318906, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.4117647058823529, "f": 0.36842105263157887, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a giraffe standing on the sidewalk in front of a zoo. There are people walking by and looking at the giraffe. The giraffe is eating leaves from a tree."}, "64103": {"image_id": 64103, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.36037498506145293, "Bleu_3": 0.29615092273975135, "Bleu_4": 0.22866722230456127, "METEOR": 0.2549467865195706, "ROUGE_L": 0.41876430205949655, "CIDEr": 0.07503041203511843, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.2916666666666667, "f": 0.32558139534883723, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "Two birds are swimming in a body of water, one is holding its beak open and the other is looking at it."}, "194756": {"image_id": 194756, "Bleu_1": 0.24999999999107145, "Bleu_2": 0.13608276348300427, "Bleu_3": 8.930538163621018e-07, "Bleu_4": 2.3103257619722554e-09, "METEOR": 0.2059982766945552, "ROUGE_L": 0.2782846715328467, "CIDEr": 0.006811303602346599, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.17391304347826086, "f": 0.1904761904761905, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a small boat with a man sitting in the front, surrounded by people on the sidewalk. There are buildings and trees visible in the background."}, "412879": {"image_id": 412879, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.19278507708010587, "Bleu_3": 0.09758032910433394, "Bleu_4": 1.2423831629820798e-05, "METEOR": 0.22162172177536554, "ROUGE_L": 0.25957446808510637, "CIDEr": 1.1727477250610988e-06, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.16666666666666666, "f": 0.14035087719298245, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The woman in the image is playing tennis with a racket and ball on a court. She is wearing black pants and a white shirt, and has long blonde hair. The background is a green grassy field with trees in the distance."}, "51741": {"image_id": 51741, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.25928148941334883, "Bleu_3": 1.2676801653440607e-06, "Bleu_4": 2.8246833943934737e-09, "METEOR": 0.30653871802035504, "ROUGE_L": 0.34574898785425096, "CIDEr": 0.0008698682819311078, "SPICE": {"All": {"pr": 0.6, "re": 0.46153846153846156, "f": 0.5217391304347826, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are made of wood and the floor is made of tile. There is a window in the background that lets in natural light."}, "111448": {"image_id": 111448, "Bleu_1": 0.35294117644982703, "Bleu_2": 0.21004201259146, "Bleu_3": 1.432760811493401e-06, "Bleu_4": 3.8071348661994064e-09, "METEOR": 0.17484656415424732, "ROUGE_L": 0.2971985383678441, "CIDEr": 0.4189723991612949, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.11538461538461539, "f": 0.15384615384615388, "fn": 23.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a horse and jockey standing on the track, with people in the background watching."}, "255279": {"image_id": 255279, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.12038585308312308, "Bleu_3": 6.906098117642891e-07, "Bleu_4": 1.663632685119678e-09, "METEOR": 0.16375921459200252, "ROUGE_L": 0.2378476735118274, "CIDEr": 1.7407035232380382e-08, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.13333333333333333, "f": 0.13333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe black motorcycle is parked on the side of the road, with the rider's helmet and gloves laid out next to it. The bike has a sleek, modern design and appears to be in good condition."}, "243626": {"image_id": 243626, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.3638034375324306, "Bleu_3": 0.20663986647296506, "Bleu_4": 2.8175950488572184e-05, "METEOR": 0.22484772040551296, "ROUGE_L": 0.42707117852975496, "CIDEr": 0.6794061464336336, "SPICE": {"All": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This image shows a plate of food with a piece of meat, green beans, and orange slices."}, "171255": {"image_id": 171255, "Bleu_1": 0.30645161289828304, "Bleu_2": 0.22413828170744018, "Bleu_3": 0.1496167692106403, "Bleu_4": 0.0868004949161612, "METEOR": 0.1927197483663561, "ROUGE_L": 0.22356020942408372, "CIDEr": 3.1710943937442885e-15, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.07142857142857142, "f": 0.0689655172413793, "fn": 13.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a group of people standing on the beach, looking out at the ocean. There is a blue tarp set up on the sand, and a few people are sitting under it. In the background, there is a large building with a red roof and white walls. The sky is clear and blue, with a few clouds scattered across it."}, "41119": {"image_id": 41119, "Bleu_1": 0.44999999998875007, "Bleu_2": 0.3222516933095853, "Bleu_3": 0.20163969170320736, "Bleu_4": 0.12200611199251925, "METEOR": 0.26130200384788665, "ROUGE_L": 0.34574898785425096, "CIDEr": 1.1911081487184106e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.26666666666666666, "f": 0.2105263157894737, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a green traffic light hanging from a pole in the middle of a busy street. The building in the background is a tall, modern skyscraper with large windows and a reflective surface on the side."}, "84982": {"image_id": 84982, "Bleu_1": 0.4285714285591838, "Bleu_2": 0.19446111706001165, "Bleu_3": 0.10464469202081998, "Bleu_4": 1.3756261043022842e-05, "METEOR": 0.2619388689468707, "ROUGE_L": 0.27107095245148866, "CIDEr": 0.0011508344977801122, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.06451612903225806, "f": 0.09523809523809523, "fn": 29.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a street sign with the words \"store\" written on it in red letters. The sign is attached to a pole and there are plants growing on either side of it."}, "232309": {"image_id": 232309, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.14882336590863374, "Bleu_3": 0.08144281873878519, "Bleu_4": 1.0780144922565258e-05, "METEOR": 0.17926530369788346, "ROUGE_L": 0.2704243191893604, "CIDEr": 6.082447168134293e-06, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.1875, "f": 0.15789473684210525, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a person holding a kite on the beach. The kite has a long tail and is being held by a person in a white shirt and black pants. The sky is cloudy and there are waves crashing on the shore."}, "438059": {"image_id": 438059, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.2842676218010918, "Bleu_3": 0.23606311064468202, "Bleu_4": 0.20820760292433108, "METEOR": 0.4020949263015853, "ROUGE_L": 0.37888198757763975, "CIDEr": 3.17374476957669e-07, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.06451612903225806, "f": 0.09090909090909091, "fn": 29.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a black and white cat wearing a red scarf sitting on top of a pile of presents. The cat is looking up at the camera with its eyes. There is a Christmas tree in the background with lights and ornaments on it."}, "572861": {"image_id": 572861, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.10079509744376741, "Bleu_3": 5.840314225182713e-07, "Bleu_4": 1.4128129251678322e-09, "METEOR": 0.18344259513292271, "ROUGE_L": 0.21356050881082975, "CIDEr": 2.730694370660015e-11, "SPICE": {"All": {"pr": 0.08823529411764706, "re": 0.125, "f": 0.10344827586206896, "fn": 21.0, "numImages": 1.0, "fp": 31.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a horse and carriage parked in front of a building. The horse is wearing a red and white harness and has a bridle on its head. The carriage is white with red trim and has a canopy over the top. There are people standing around the carriage, looking at it."}, "9262": {"image_id": 9262, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.21764287502183505, "Bleu_3": 0.13806135595106658, "Bleu_4": 1.983544145310677e-05, "METEOR": 0.2103213123580071, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.2169632114023452, "SPICE": {"All": {"pr": 0.125, "re": 0.17391304347826086, "f": 0.14545454545454545, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A table with various teddy bears and food items on it.\""}, "308430": {"image_id": 308430, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.23124864502453574, "Bleu_3": 0.11866868732576562, "Bleu_4": 1.5237428484669e-05, "METEOR": 0.2672277829495527, "ROUGE_L": 0.3117546848381601, "CIDEr": 0.000553008753130589, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.09375, "f": 0.15384615384615383, "fn": 29.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This is a pan with vegetables and meat cooking in it. There are carrots, mushrooms, and onions in the pan. The pan is on a stove top and there is a spatula in it."}, "28071": {"image_id": 28071, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.19738550848437394, "Bleu_3": 0.08969032338542009, "Bleu_4": 1.0801653085536467e-05, "METEOR": 0.19233657956216693, "ROUGE_L": 0.3087044534412956, "CIDEr": 2.3235351089426416e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.46153846153846156, "f": 0.3428571428571428, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a red stop sign on the side of a road in front of a parking lot. The sign is made of metal and has the words \"stop\" written on it in white letters. There are no cars or people in the image, just the sign and some trees in the background."}, "393942": {"image_id": 393942, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.18375590810914594, "Bleu_3": 0.10773900313322693, "Bleu_4": 0.06969646435516218, "METEOR": 0.20986392559175768, "ROUGE_L": 0.2426136363636364, "CIDEr": 4.286982294759229e-12, "SPICE": {"All": {"pr": 0.15625, "re": 0.22727272727272727, "f": 0.18518518518518515, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a train crossing a railroad track in the middle of a forest. The train is moving slowly and the tracks are covered in leaves and branches. There is a person standing on the platform of the train, looking out at the forest. The sky is cloudy and there are trees in the background."}, "526751": {"image_id": 526751, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.16528691241294277, "Bleu_4": 0.11372027709677378, "METEOR": 0.2716271072194908, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.008338999791873114, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20833333333333334, "f": 0.25641025641025644, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A small boat is docked at the shore of a river, surrounded by green hills and trees. The sky is clear and blue, with a few clouds scattered across it."}, "440830": {"image_id": 440830, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 0.11472200633111387, "Bleu_4": 0.07888036262328214, "METEOR": 0.2185981988829963, "ROUGE_L": 0.2663755458515284, "CIDEr": 7.50615289816219e-07, "SPICE": {"All": {"pr": 0.28, "re": 0.28, "f": 0.28, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The woman is standing next to a pile of luggage on the sidewalk. She is wearing a white shirt and black pants, and has a black backpack slung over her shoulder. The luggage includes several large suitcases with different colors and designs."}, "400317": {"image_id": 400317, "Bleu_1": 0.5789473683905818, "Bleu_2": 0.35868505787991106, "Bleu_3": 0.24736365056100337, "Bleu_4": 0.17537670873641137, "METEOR": 0.24044012667135153, "ROUGE_L": 0.38812301166489926, "CIDEr": 0.41807462362112013, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 21.0, "numImages": 1.0, "fp": 28.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court with a crowd of people watching in the background."}, "565650": {"image_id": 565650, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.14285714285419707, "Bleu_3": 0.07572431510387477, "Bleu_4": 9.856825261135735e-06, "METEOR": 0.20954990622777767, "ROUGE_L": 0.23091482649842268, "CIDEr": 4.837428628294196e-10, "SPICE": {"All": {"pr": 0.15, "re": 0.17647058823529413, "f": 0.16216216216216214, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A purple umbrella is hanging on the side of a motorcycle parked on the sidewalk. The umbrella has a cartoon character's face on it, with a big smile and sunglasses. The character appears to be enjoying the sunny day.\""}, "286182": {"image_id": 286182, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.19425717246782156, "Bleu_3": 0.08986355476387574, "Bleu_4": 1.0921823440887e-05, "METEOR": 0.2588327490428001, "ROUGE_L": 0.26468309313497596, "CIDEr": 4.855231291390018e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a table set with various dishes and utensils. There are plates, bowls, and cups on the table. A man is sitting at the table, wearing a white shirt and black pants. He appears to be eating something from one of the plates. The room behind him has a bookshelf and a couch."}, "232460": {"image_id": 232460, "Bleu_1": 0.340909090901343, "Bleu_2": 0.25184310024886714, "Bleu_3": 0.1445485056949405, "Bleu_4": 1.647457579085305e-05, "METEOR": 0.3050430352537348, "ROUGE_L": 0.32620320855614976, "CIDEr": 3.0606433685367753e-07, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.14705882352941177, "f": 0.15873015873015872, "fn": 29.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a baseball player in a black and gold uniform throwing a ball on the field. He is wearing a helmet and glove, and his face is turned towards the camera. The background is a grassy field with trees in the distance."}, "346752": {"image_id": 346752, "Bleu_1": 0.818181818033058, "Bleu_2": 0.6396021489476329, "Bleu_3": 0.44964431293646534, "Bleu_4": 5.8060307534352256e-05, "METEOR": 0.2763606753201802, "ROUGE_L": 0.5763779527559055, "CIDEr": 1.027522754449031, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a plate with slices of orange on it."}, "534421": {"image_id": 534421, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.19754591932503954, "Bleu_3": 0.1000208420156093, "Bleu_4": 1.2738608208588955e-05, "METEOR": 0.14923319331792878, "ROUGE_L": 0.2042866711319491, "CIDEr": 4.504300506211204e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.2, "f": 0.24242424242424246, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This image shows a group of people skiing down a snowy slope. They are all wearing yellow vests and helmets, and one person is holding a ski pole. The background is a winter landscape with trees and mountains in the distance."}, "330967": {"image_id": 330967, "Bleu_1": 0.45238095237018144, "Bleu_2": 0.36387385338642725, "Bleu_3": 0.28508864260491323, "Bleu_4": 0.22079222864558645, "METEOR": 0.3808274945167757, "ROUGE_L": 0.43262411347517726, "CIDEr": 2.354784930099972e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a young woman in a red shirt and blue pants playing tennis on a court. She is holding a tennis racket and swinging it to hit the ball. The background is a green field with trees in the distance."}, "146640": {"image_id": 146640, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.12097167577883941, "Bleu_3": 7.212750820939888e-07, "Bleu_4": 1.7726777657776637e-09, "METEOR": 0.20178037028882453, "ROUGE_L": 0.2713120830244626, "CIDEr": 3.307331838486263e-06, "SPICE": {"All": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a woman playing tennis with a racket. She is wearing a white shirt and black shorts, and has a blue ribbon tied around her left wrist. There are other people in the background watching her play."}, "147576": {"image_id": 147576, "Bleu_1": 0.19999999999428575, "Bleu_2": 2.425356250293015e-09, "Bleu_3": 5.62789145869357e-12, "Bleu_4": 2.7319439827503003e-13, "METEOR": 0.1629327902240326, "ROUGE_L": 0.20980223559759242, "CIDEr": 4.2140698647925773e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a view of a canal with several boats docked at the shore. In the background, there are several buildings with red brick facades and white shutters. The sky is clear and blue."}, "19923": {"image_id": 19923, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.25761406704390316, "Bleu_3": 0.21979596238164803, "Bleu_4": 0.1814296504132375, "METEOR": 0.28377055830657927, "ROUGE_L": 0.35219399538106233, "CIDEr": 4.923572138293223e-10, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.1111111111111111, "f": 0.10909090909090909, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows two red cars parked in front of a building with a clock tower in the background. The cars are parked on the street, and there is a lot of space between them. The building has a clock tower on top, and there are other buildings visible in the background."}, "328940": {"image_id": 328940, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.28097574345930926, "Bleu_3": 0.16683848808490073, "Bleu_4": 2.321091111608818e-05, "METEOR": 0.2911812085351851, "ROUGE_L": 0.3605911330049261, "CIDEr": 0.5241063453804735, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.2727272727272727, "f": 0.3428571428571428, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.625, "f": 0.7142857142857143, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows two children sitting on a couch, one holding a laptop and the other petting a dog."}, "489829": {"image_id": 489829, "Bleu_1": 0.20312499999682618, "Bleu_2": 0.1502313031419669, "Bleu_3": 0.10297934962957972, "Bleu_4": 0.0773548678769161, "METEOR": 0.21667915468786725, "ROUGE_L": 0.21785714285714283, "CIDEr": 5.346732733683035e-18, "SPICE": {"All": {"pr": 0.12, "re": 0.15, "f": 0.1333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a wall of clocks. He is wearing a black shirt and jeans, and has a serious expression on his face. There are several clocks on the wall, each with different designs and colors. Some of the clocks have hands, while others do not. The overall atmosphere of the image is one of nostalgia and tradition."}, "406070": {"image_id": 406070, "Bleu_1": 0.20547945205197976, "Bleu_2": 0.13085598064574844, "Bleu_3": 0.06224573527398609, "Bleu_4": 7.66139212649701e-06, "METEOR": 0.17954483789899472, "ROUGE_L": 0.20324864639733445, "CIDEr": 1.9695108505718726e-20, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.047619047619047616, "f": 0.044444444444444446, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "This is an image of a person doing a trick on a skateboard in the middle of a city street. The person is wearing a black and white striped shirt and black pants, and has a red and white striped helmet on their head. There are several buildings visible in the background, including tall skyscrapers and smaller buildings. The street is lined with parked cars and there are pedestrians walking on the sidewalk."}, "506187": {"image_id": 506187, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.42971978183198023, "Bleu_3": 0.34676533803204534, "Bleu_4": 0.22961695060374626, "METEOR": 0.3897689765648407, "ROUGE_L": 0.5147679324894515, "CIDEr": 0.002134679623997163, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a banana with a smiley face drawn on it. The banana is sitting in a mirror, and the reflection of the banana's smile can be seen in the mirror."}, "299481": {"image_id": 299481, "Bleu_1": 0.5999999998800002, "Bleu_2": 0.3651483715950527, "Bleu_3": 2.55436477410356e-06, "Bleu_4": 6.985342055045127e-09, "METEOR": 0.2383446345364981, "ROUGE_L": 0.5313588850174217, "CIDEr": 0.8340475860852259, "SPICE": {"All": {"pr": 0.7142857142857143, "re": 0.1724137931034483, "f": 0.2777777777777778, "fn": 24.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "A group of people skiing down a snowy mountain trail."}, "427160": {"image_id": 427160, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.2433035497756459, "Bleu_3": 0.14126216736382222, "Bleu_4": 0.0910591170287744, "METEOR": 0.23061304656975684, "ROUGE_L": 0.2889039242219215, "CIDEr": 1.0183981274256609e-06, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.13333333333333333, "f": 0.10256410256410255, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a group of young boys playing baseball on a field. They are wearing baseball uniforms and helmets, and one of them is holding a bat. The field is surrounded by trees and there is a fence in the background."}, "483531": {"image_id": 483531, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.18569533817075534, "Bleu_3": 1.0718844984982804e-06, "Bleu_4": 2.5987832063232773e-09, "METEOR": 0.16187880445979763, "ROUGE_L": 0.264069264069264, "CIDEr": 0.002533847716230785, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2222222222222222, "f": 0.20512820512820512, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bedroom with two beds, a desk, and a window with curtains. The walls are painted a light beige color and there is a carpet on the floor."}, "269287": {"image_id": 269287, "Bleu_1": 0.3599999999928, "Bleu_2": 0.2267786838009545, "Bleu_3": 0.12892319893629803, "Bleu_4": 1.4612476989078167e-05, "METEOR": 0.27670014819565186, "ROUGE_L": 0.2594167679222357, "CIDEr": 2.915594692616698e-09, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.25, "f": 0.2162162162162162, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a bathroom with white tiles on the walls and floor. There is a sink in the corner of the room with a mirror above it. There are two windows on either side of the room with curtains. The room has a white vanity with a mirror above it."}, "429839": {"image_id": 429839, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.11741874968995038, "Bleu_4": 1.3772093427778417e-05, "METEOR": 0.2263949535861768, "ROUGE_L": 0.29901960784313725, "CIDEr": 1.1986960936810979e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a small bird perched on the railing of a balcony. The bird is white with black spots and has a long, curved beak. It looks out at the viewer with its large, round eyes. The background is a cityscape with tall buildings and busy streets."}, "502024": {"image_id": 502024, "Bleu_1": 0.5333333332977779, "Bleu_2": 0.33806170186806433, "Bleu_3": 0.20638725024557966, "Bleu_4": 2.9256127305132916e-05, "METEOR": 0.2538375320346069, "ROUGE_L": 0.39559014267185466, "CIDEr": 0.4822423250761555, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a white game controller with a red button on it."}, "2139": {"image_id": 2139, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.16302782918400804, "Bleu_3": 0.1090410128226247, "Bleu_4": 0.075453155981989, "METEOR": 0.16730986410589332, "ROUGE_L": 0.25505226480836235, "CIDEr": 8.070819576776398e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.25, "f": 0.23255813953488372, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a photo of a bedroom with a bicycle on the floor. There are several items on the floor, including a pillow, a blanket, and a pair of shoes. The walls are painted blue and there are two windows in the background."}, "283438": {"image_id": 283438, "Bleu_1": 0.25806451612486997, "Bleu_2": 0.19512840014305818, "Bleu_3": 0.12393776418796779, "Bleu_4": 0.08962872923135419, "METEOR": 0.20497946125290548, "ROUGE_L": 0.2323177366702938, "CIDEr": 1.1207466938414159e-15, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.3125, "f": 0.2325581395348837, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person taking a picture of themselves in front of a mirror. The mirror is made of glass and has a frame around it. The person is standing on one side of the mirror, holding a camera in their hand, and looking at themselves in the mirror. There is a towel hanging on the wall next to the mirror."}, "1554": {"image_id": 1554, "Bleu_1": 0.5263157894459835, "Bleu_2": 0.34199278400988514, "Bleu_3": 1.9019320107005801e-06, "Bleu_4": 4.553719183884792e-09, "METEOR": 0.2647345978037693, "ROUGE_L": 0.42020665901262916, "CIDEr": 0.18958644190990095, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10714285714285714, "f": 0.12244897959183672, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"Three sheep standing in a field with people watching them\""}, "512254": {"image_id": 512254, "Bleu_1": 0.2187499999931641, "Bleu_2": 2.6563982405609075e-09, "Bleu_3": 6.1728876271967496e-12, "Bleu_4": 3.001005413145576e-13, "METEOR": 0.10788320922719, "ROUGE_L": 0.15775862068965518, "CIDEr": 3.447428542991571e-05, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a field with their trunks sticking out of the ground. They are all looking at each other and seem to be enjoying themselves."}, "447522": {"image_id": 447522, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.16578342426777695, "Bleu_3": 0.08681823924888467, "Bleu_4": 1.1239895308238822e-05, "METEOR": 0.23582361021439507, "ROUGE_L": 0.24583557227297154, "CIDEr": 1.6540676263565808e-07, "SPICE": {"All": {"pr": 0.09375, "re": 0.25, "f": 0.13636363636363635, "fn": 9.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.6, "f": 0.2727272727272727, "fn": 2.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "This image shows a plate of food with broccoli, carrots, and rice. The broccoli is cooked in a sauce made with tomatoes, onions, and garlic. The carrots are sliced and served alongside the broccoli. The rice is cooked and served as a side dish."}, "183889": {"image_id": 183889, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.17677669529119638, "Bleu_3": 0.10026809779454411, "Bleu_4": 1.3539161486777476e-05, "METEOR": 0.26984530432507764, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.0005746776356928197, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.16129032258064516, "f": 0.17241379310344826, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a person standing in front of a wall with several cans of soup on it. The person is holding a cell phone to their ear and looking at the cans."}, "313454": {"image_id": 313454, "Bleu_1": 0.4761904761678005, "Bleu_2": 0.43643578045068265, "Bleu_3": 0.3918135478584406, "Bleu_4": 0.34002156195059, "METEOR": 0.29546736784225447, "ROUGE_L": 0.5211289092295956, "CIDEr": 0.22319578385894157, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "A man standing at a podium in front of a large screen displaying the image of a person giving a presentation."}, "20438": {"image_id": 20438, "Bleu_1": 0.3142857142812245, "Bleu_2": 0.24333772933085054, "Bleu_3": 0.17352168116084307, "Bleu_4": 0.12367357727934745, "METEOR": 0.2417337812583186, "ROUGE_L": 0.32737030411449014, "CIDEr": 6.9217596900323725e-19, "SPICE": {"All": {"pr": 0.39285714285714285, "re": 0.39285714285714285, "f": 0.39285714285714285, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 11.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.2, "f": 0.1111111111111111, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 8.0}}, "caption": "The image shows a black and white dog lying on top of a bed, with its head resting on the pillow. The dog is wearing a blue collar and has its paws tucked under its body. The bed is covered in a blue and white striped blanket, and there are several pillows scattered around it. The room is dimly lit by a window on the left side of the image."}, "357229": {"image_id": 357229, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.29361010974739604, "Bleu_3": 0.1454771082839364, "Bleu_4": 1.8376172280249086e-05, "METEOR": 0.2758359360106028, "ROUGE_L": 0.3505747126436782, "CIDEr": 0.02335648537829001, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.2857142857142857, "f": 0.2580645161290323, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a pizza on a plate with slices cut out of it. There are also utensils such as forks and knives on the table next to the plate."}, "311081": {"image_id": 311081, "Bleu_1": 0.39999999999, "Bleu_2": 0.267945650816049, "Bleu_3": 0.155756653561564, "Bleu_4": 1.787658362427431e-05, "METEOR": 0.26205034020112145, "ROUGE_L": 0.31961077844311375, "CIDEr": 1.6137511705938957e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.21052631578947367, "f": 0.1904761904761905, "fn": 15.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a white bathtub, toilet, and sink. The walls are painted beige and the floor is made of tile. There is a window on one side of the room and a door on the other."}, "561563": {"image_id": 561563, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.36115755924124826, "Bleu_3": 0.2315979476693905, "Bleu_4": 0.15786779060858716, "METEOR": 0.3110654659896386, "ROUGE_L": 0.407119021134594, "CIDEr": 0.08972853148857537, "SPICE": {"All": {"pr": 0.12, "re": 0.2, "f": 0.15, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted green and there is a rug on the floor."}, "191693": {"image_id": 191693, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.19738550848437394, "Bleu_3": 0.15336829563872276, "Bleu_4": 0.10801653085536465, "METEOR": 0.26960361104283304, "ROUGE_L": 0.2883403361344538, "CIDEr": 3.829761274458848e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a man playing a guitar on a stage in front of a large audience. He is wearing a suit and tie and has his guitar strapped to his chest. The audience is seated in chairs and watching him play. There are microphones on the stage and a podium in the background."}, "379837": {"image_id": 379837, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.37509017673027106, "Bleu_3": 0.27634665580696127, "Bleu_4": 0.1825585845283238, "METEOR": 0.3330914558652968, "ROUGE_L": 0.5036697247706422, "CIDEr": 0.717613032694995, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.1, "f": 0.16216216216216217, "fn": 27.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The woman is holding a cake with candles on it and the child is sitting in a high chair at the table."}, "575088": {"image_id": 575088, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.13719886811129003, "Bleu_3": 0.10484363678213088, "Bleu_4": 0.08324415466849458, "METEOR": 0.2323232258966692, "ROUGE_L": 0.2780626780626781, "CIDEr": 3.35905718374785e-09, "SPICE": {"All": {"pr": 0.1875, "re": 0.13043478260869565, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The man in the white suit is sitting on a bench, looking at his phone. He has a book in his hand and is wearing sunglasses. There are people walking by on the sidewalk, some of them carrying bags or shopping. The sky is blue and there are clouds in it."}, "354832": {"image_id": 354832, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.20597146021314577, "Bleu_3": 0.1808973883271828, "Bleu_4": 0.16293125439544623, "METEOR": 0.30424700628610957, "ROUGE_L": 0.336783988957902, "CIDEr": 3.70832654289565e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.1794871794871795, "f": 0.18918918918918923, "fn": 32.0, "numImages": 1.0, "fp": 28.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.3333333333333333, "f": 0.3571428571428571, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of people playing frisbee in a park. One person is throwing the frisbee while another person is catching it. There are several other people standing around watching the game. The grass is green and there are trees in the background."}, "222332": {"image_id": 222332, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.12654285084562092, "Bleu_4": 1.4487343343293782e-05, "METEOR": 0.2581789931158049, "ROUGE_L": 0.27566171723692706, "CIDEr": 1.1381615415395245e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man in a blue shirt and white shorts playing tennis on a green court. He is holding a tennis racket in his right hand and is about to hit the ball with his left hand. There are several other people watching him from the sidelines."}, "387850": {"image_id": 387850, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.11459194182328535, "Bleu_3": 6.280739235613542e-07, "Bleu_4": 1.4774310979864886e-09, "METEOR": 0.13315200868633914, "ROUGE_L": 0.17951736315479697, "CIDEr": 2.4859632381912244e-14, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16666666666666666, "f": 0.21621621621621623, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a bus stop. There are several people sitting on benches, and one person is standing next to a bus. The bus has the words \"Bus Stop\" written on it in white letters. The sky is blue and there are some clouds in the background."}, "178810": {"image_id": 178810, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.21931085605462405, "Bleu_3": 0.15089125644562476, "Bleu_4": 0.09567579772168915, "METEOR": 0.2409662880416712, "ROUGE_L": 0.25702247191011235, "CIDEr": 2.8288166843395887e-07, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1, "f": 0.09302325581395349, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is an image of a red fire hydrant on the sidewalk in front of a house. The hydrant is painted red and has a small handle on top. There are trees and bushes nearby, and a fence separates the hydrant from the street."}, "333303": {"image_id": 333303, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.40674460838530657, "Bleu_3": 0.22259604833645616, "Bleu_4": 2.9792440366740352e-05, "METEOR": 0.20663677130044844, "ROUGE_L": 0.40720961281708945, "CIDEr": 0.5946092078689074, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16666666666666666, "f": 0.2285714285714286, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a kitchen with a blender on the counter and a refrigerator in the background."}, "539075": {"image_id": 539075, "Bleu_1": 0.39583333332508686, "Bleu_2": 0.24280424359293504, "Bleu_3": 0.10862211080317753, "Bleu_4": 1.2990789632433087e-05, "METEOR": 0.20137041279684534, "ROUGE_L": 0.2401574803149606, "CIDEr": 1.8055798496071792e-09, "SPICE": {"All": {"pr": 0.4, "re": 0.38461538461538464, "f": 0.39215686274509803, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 10.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5833333333333334, "re": 0.7, "f": 0.6363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "Sure, here is a short caption of the image:\n\n\"A group of motorcycles on display at a motorcycle show. The bikes are parked in rows, with some of them having their engines running. There are people standing around the bikes, looking at them and talking to each other.\""}, "61624": {"image_id": 61624, "Bleu_1": 0.4038461538383876, "Bleu_2": 0.2354354778941374, "Bleu_3": 0.10349624746218525, "Bleu_4": 1.2264347083847836e-05, "METEOR": 0.23076139275873353, "ROUGE_L": 0.22241127856101123, "CIDEr": 1.9260662592742855e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.125, "f": 0.14814814814814814, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is an image of a large airplane on the runway at an airport. The plane has a red and white tail and is parked on the tarmac. There are several people standing around the plane, including one man in a yellow vest who appears to be loading something onto the plane."}, "174567": {"image_id": 174567, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.09671474291033856, "Bleu_3": 5.838426740772723e-07, "Bleu_4": 1.442223004001259e-09, "METEOR": 0.24333012166276433, "ROUGE_L": 0.16126900198281557, "CIDEr": 7.425427069961619e-10, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.15, "f": 0.16216216216216214, "fn": 17.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a kitchen with a countertop and stove. There are three laptops on the counter, one of which is open and has a screen displaying an image of a mountain range. There is also a cup of coffee on the counter next to one of the laptops."}, "549327": {"image_id": 549327, "Bleu_1": 0.4444444444320988, "Bleu_2": 0.2760262237291648, "Bleu_3": 0.13086010274442147, "Bleu_4": 1.614272906449152e-05, "METEOR": 0.29743010231479844, "ROUGE_L": 0.29383429672447015, "CIDEr": 7.969047797674178e-05, "SPICE": {"All": {"pr": 0.375, "re": 0.10344827586206896, "f": 0.16216216216216217, "fn": 26.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a man standing in a kitchen with an open refrigerator. He is holding a bag of groceries and looking at the refrigerator. There are several bottles of beer on the counter next to him."}, "553847": {"image_id": 553847, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.277350098092042, "Bleu_3": 1.8576267964549764e-06, "Bleu_4": 4.913270547748174e-09, "METEOR": 0.1873424440130257, "ROUGE_L": 0.2982885085574572, "CIDEr": 0.5949508273564821, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The boy is holding a guitar in his hands and smiling at the camera."}, "390283": {"image_id": 390283, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.16165520152449506, "Bleu_3": 8.677070481028558e-07, "Bleu_4": 2.0230829597025574e-09, "METEOR": 0.18559892686472085, "ROUGE_L": 0.22197962154294032, "CIDEr": 3.6416439910536076e-07, "SPICE": {"All": {"pr": 0.375, "re": 0.2222222222222222, "f": 0.27906976744186046, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a man lying on an inflatable raft in the middle of a balcony. He is wearing a red and white striped shirt, a white hat, and sunglasses. The balcony has white curtains and a blue sky in the background."}, "451859": {"image_id": 451859, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.1475489144223407, "Bleu_3": 0.10859446879612174, "Bleu_4": 0.08460008059351494, "METEOR": 0.2648322217206262, "ROUGE_L": 0.2507339988256019, "CIDEr": 2.689168466128609e-11, "SPICE": {"All": {"pr": 0.3, "re": 0.24, "f": 0.2666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is an image of a field filled with colorful kites flying in the sky. There are people standing on the grassy field, watching the kites fly. The sky is clear and blue, with a few clouds scattered about. The sun is shining down on the scene, casting a warm glow over everything."}, "276840": {"image_id": 276840, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.23570226038887507, "Bleu_3": 0.14839736556269426, "Bleu_4": 0.09975648967960957, "METEOR": 0.2803983248522054, "ROUGE_L": 0.33888888888888885, "CIDEr": 0.00010040040066019208, "SPICE": {"All": {"pr": 0.125, "re": 0.10344827586206896, "f": 0.11320754716981132, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a group of people skiing on a snowy slope. They are all wearing ski gear and some are holding poles. The snow is deep and there are trees in the background."}, "74139": {"image_id": 74139, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.3333333333212081, "Bleu_3": 0.23404631037963888, "Bleu_4": 0.15048435360920345, "METEOR": 0.2146496738949481, "ROUGE_L": 0.38705583756345174, "CIDEr": 0.012443826420522176, "SPICE": {"All": {"pr": 0.5, "re": 0.1875, "f": 0.2727272727272727, "fn": 26.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.0625, "f": 0.09523809523809523, "fn": 15.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is a pizza with vegetables and cheese on top of a crust. The crust is folded in half and there are slices of pizza on the plate."}, "235252": {"image_id": 235252, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.11155016321612385, "Bleu_3": 0.06290089214849724, "Bleu_4": 8.441965712987706e-06, "METEOR": 0.14611522008438482, "ROUGE_L": 0.24233825198637912, "CIDEr": 2.0289922760011968e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.18181818181818182, "f": 0.16326530612244897, "fn": 18.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of giraffes stand in a dry, barren landscape with no trees or vegetation in sight. They are all looking out into the distance, possibly searching for food or water. The sky is clear and blue, with a few clouds scattered about."}, "104893": {"image_id": 104893, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.16624095289858323, "Bleu_3": 0.08377724227293193, "Bleu_4": 1.063298221330347e-05, "METEOR": 0.18517523445014022, "ROUGE_L": 0.2208811104405552, "CIDEr": 2.8996971960432454e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a train traveling along a track next to a building with a clock tower. The train has a yellow and blue striped body and is pulling into a station. There are people standing on the platform and looking at the train as it approaches."}, "446459": {"image_id": 446459, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.17320508074981525, "Bleu_3": 1.0926082435777024e-06, "Bleu_4": 2.774870273442235e-09, "METEOR": 0.16631746346379625, "ROUGE_L": 0.2571127502634352, "CIDEr": 0.03190871575564292, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.05263157894736842, "f": 0.05555555555555555, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA zebra standing in a grassy area, looking around with its head tilted to the side."}, "549167": {"image_id": 549167, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.2942449431545567, "Bleu_3": 0.2053395811909504, "Bleu_4": 0.1461053448586489, "METEOR": 0.20824295010845986, "ROUGE_L": 0.41876430205949655, "CIDEr": 0.07842164790702066, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.18518518518518517, "f": 0.19607843137254902, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This image shows a plate of food with broccoli, almonds, and rice. The dish is topped with a sprinkle of parmesan cheese."}, "18519": {"image_id": 18519, "Bleu_1": 0.2586206896507135, "Bleu_2": 0.17821457732346996, "Bleu_3": 0.11938228648243487, "Bleu_4": 0.07457860352741073, "METEOR": 0.1504930948284936, "ROUGE_L": 0.23131094257854823, "CIDEr": 5.041942039328371e-14, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.15, "f": 0.1016949152542373, "fn": 17.0, "numImages": 1.0, "fp": 36.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a skateboarder performing a trick on a halfpipe in a park. The skateboarder is wearing black pants and a black shirt, and has a helmet on his head. The halfpipe is made of concrete and has a blue and green graffiti design on it. There are trees and grass in the background of the image."}, "528786": {"image_id": 528786, "Bleu_1": 0.18032786884950286, "Bleu_2": 0.10964423342383232, "Bleu_3": 0.05884458799865846, "Bleu_4": 7.698797497340994e-06, "METEOR": 0.16639482405393446, "ROUGE_L": 0.18702095043433828, "CIDEr": 7.094438433274813e-15, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.4166666666666667, "f": 0.2325581395348837, "fn": 7.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5714285714285714, "f": 0.36363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a large statue of a woman on horseback, standing on a pedestal in the middle of a park. The statue is made of bronze and has intricate details, including the woman's hair and clothing. In the background, there are several people walking on the sidewalk and riding bicycles. The sky is cloudy with some birds flying overhead."}, "156756": {"image_id": 156756, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.07446639778133946, "Bleu_4": 9.43994412057466e-06, "METEOR": 0.2435520601246655, "ROUGE_L": 0.27555053642010163, "CIDEr": 1.8261941503137247e-12, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.17647058823529413, "f": 0.20000000000000004, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "A man is riding a brown horse through a herd of cows in a barn. The man is wearing a cowboy hat and holding onto the reins of the horse with one hand while leading the herd with the other. The cows are standing in the background, some of them are running around the barn."}, "433204": {"image_id": 433204, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.15289912176646533, "Bleu_3": 0.07429821419893698, "Bleu_4": 9.250959395998023e-06, "METEOR": 0.18728278809635643, "ROUGE_L": 0.2197632527020072, "CIDEr": 1.6226096370251427e-14, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.19047619047619047, "f": 0.12698412698412698, "fn": 17.0, "numImages": 1.0, "fp": 38.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.3333333333333333, "f": 0.24000000000000005, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a group of people riding motorcycles down the street in front of a building with a blue roof. There are trees and bushes on either side of the road, and a few cars parked along the side of the road. The sky is cloudy and there are no other vehicles or people visible in the image."}, "203201": {"image_id": 203201, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.2166823008689824, "Bleu_3": 0.16886802358325678, "Bleu_4": 0.13963522201453288, "METEOR": 0.32357350361707465, "ROUGE_L": 0.32520944402132523, "CIDEr": 1.040032198149337e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1, "f": 0.11320754716981132, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a black and white photograph of a young boy holding a baseball bat. He is standing in the middle of a grassy field, wearing a white shirt and blue pants. The background is a clear sky with some clouds."}, "522940": {"image_id": 522940, "Bleu_1": 0.49999999997222233, "Bleu_2": 0.29704426287601454, "Bleu_3": 0.17667460064728172, "Bleu_4": 2.4623953023773364e-05, "METEOR": 0.212053756410481, "ROUGE_L": 0.3765432098765432, "CIDEr": 0.45720102286602726, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2692307692307692, "f": 0.2916666666666667, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a stop sign on the side of a road with snow-covered mountains in the background."}, "202507": {"image_id": 202507, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.20121090914115636, "Bleu_3": 1.0304662546247208e-06, "Bleu_4": 2.3480087200537226e-09, "METEOR": 0.24301808870539743, "ROUGE_L": 0.1931908155186065, "CIDEr": 4.379169656038042e-06, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.30434782608695654, "f": 0.25925925925925924, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "There are several baskets filled with apples, oranges, and other fruits on display. The apples are red, green, and yellow, while the oranges are yellow and green. The other fruits are also various colors, including red, green, and yellow."}, "390463": {"image_id": 390463, "Bleu_1": 0.23999999999520005, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.10067569617030046, "Bleu_4": 0.06826042950277836, "METEOR": 0.17721649358022842, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.7179087128764707e-10, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2, "f": 0.1951219512195122, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A table with a cupcake on it, surrounded by other cupcakes and a sign that says \"Happy Birthday\"\n\nThe image shows a table with a cupcake on it, surrounded by other cupcakes and a sign that says \"Happy Birthday\". The cupcakes are decorated with blue and pink frosting and sprinkles."}, "531324": {"image_id": 531324, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.08347838711095647, "Bleu_3": 5.585079625938627e-07, "Bleu_4": 1.4538040525271515e-09, "METEOR": 0.12392426850258176, "ROUGE_L": 0.20962199312714774, "CIDEr": 6.495951644001241e-08, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2, "f": 0.1886792452830189, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a street with several bicycles parked on the side of the road. There are buildings on either side of the street, with windows and balconies visible. The sky is clear and blue, with a few clouds scattered across it."}, "576667": {"image_id": 576667, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.25437350952720955, "Bleu_3": 0.21402603671736703, "Bleu_4": 0.18710158229851495, "METEOR": 0.3736428471413314, "ROUGE_L": 0.41960447119518485, "CIDEr": 5.4236736699961424e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.30434782608695654, "f": 0.27450980392156865, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.75, "f": 0.8571428571428571, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are made of wood and the floor is made of tile. There is a window in the background that lets in natural light."}, "44068": {"image_id": 44068, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.20412414522772235, "Bleu_3": 0.16426825166182765, "Bleu_4": 0.14011697930927772, "METEOR": 0.3145698530502556, "ROUGE_L": 0.31504196255648803, "CIDEr": 5.063320240542258e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.20689655172413793, "f": 0.21052631578947367, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.08333333333333333, "f": 0.08695652173913043, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a brown teddy bear sitting on a wooden chair in front of a window. The chair has a red and white striped cushion and the walls are painted a light blue color. There is a curtain hanging in the window and a rug on the floor."}, "399790": {"image_id": 399790, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.13819269959596528, "Bleu_3": 0.12271846684110282, "Bleu_4": 0.11094110391125546, "METEOR": 0.2743261420076079, "ROUGE_L": 0.28010204081632656, "CIDEr": 2.191497947439384e-18, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.041666666666666664, "f": 0.05128205128205127, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a baseball player pitching a ball on a field. The player is wearing a red and white uniform with the number 17 on the back. The catcher is standing behind home plate, ready to catch the ball. The umpire is standing on the side of the field, watching the play. The crowd is sitting in the stands, cheering for the team."}, "462371": {"image_id": 462371, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.26244532957850014, "Bleu_3": 0.18030728618319325, "Bleu_4": 0.10624793541683013, "METEOR": 0.2617368011081236, "ROUGE_L": 0.3059013163786155, "CIDEr": 3.497371525596297e-09, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 27.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6, "f": 0.631578947368421, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "This is a black and white photograph of a group of people gathered around a table with a cake on it. The people are all smiling and looking at the cake, which appears to be a wedding cake. There are several bottles of champagne on the table as well."}, "547783": {"image_id": 547783, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.3047247001014366, "Bleu_3": 0.23902067469183821, "Bleu_4": 0.18770611871215762, "METEOR": 0.37605864141164175, "ROUGE_L": 0.4107744107744108, "CIDEr": 4.3474251581000584e-05, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.26666666666666666, "f": 0.2105263157894737, "fn": 11.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This image shows a group of giraffes standing in a field with green grass and blue sky in the background. The giraffes are tall and have long necks, and they are looking directly at the camera."}, "296524": {"image_id": 296524, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2477973138852387, "Bleu_3": 0.14916736567839847, "Bleu_4": 1.7425278978111283e-05, "METEOR": 0.326357795505727, "ROUGE_L": 0.2897862232779097, "CIDEr": 2.664542262336107e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.22727272727272727, "f": 0.23809523809523808, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a man wearing a blue shirt and holding a red scarf in his hand. He is standing in front of a wooden table with a painting on it. There are several paintings on the walls behind him."}, "165522": {"image_id": 165522, "Bleu_1": 0.7999999999200001, "Bleu_2": 0.5962847939370028, "Bleu_3": 0.3542195230211848, "Bleu_4": 5.019724248194722e-05, "METEOR": 0.3025667339240407, "ROUGE_L": 0.5729492798998121, "CIDEr": 1.0461912334525896, "SPICE": {"All": {"pr": 0.16, "re": 0.2222222222222222, "f": 0.18604651162790697, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "A man and woman walking on the beach with surfboards."}, "424192": {"image_id": 424192, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.14285714285419707, "Bleu_3": 7.572431510387479e-07, "Bleu_4": 1.75281894102292e-09, "METEOR": 0.16794125160848794, "ROUGE_L": 0.19242902208201892, "CIDEr": 2.860527243535603e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a room with a bed, a table, and a chair. The walls are made of stone and there is a large wooden door in the background. There is also a rug on the floor and a small window in the corner of the room."}, "232760": {"image_id": 232760, "Bleu_1": 0.1643835616415838, "Bleu_2": 0.11704114719451614, "Bleu_3": 0.05778382195755017, "Bleu_4": 7.245697316917544e-06, "METEOR": 0.22191202419598927, "ROUGE_L": 0.19869706840390877, "CIDEr": 2.4627369102177223e-24, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.16666666666666666, "f": 0.14035087719298245, "fn": 20.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a person standing on the beach holding a surfboard. The sun is shining down on the person and the waves are crashing against the shore. The person is wearing a black wetsuit and sunglasses, and their hair is blown back by the wind. The sky is clear and blue, with some clouds in the distance. The beach is sandy and there are some rocks and shells scattered along the shore."}, "369998": {"image_id": 369998, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.20314980006762443, "Bleu_3": 0.10667221025972526, "Bleu_4": 1.3848731186391142e-05, "METEOR": 0.2071733200015221, "ROUGE_L": 0.29901960784313725, "CIDEr": 4.100564307112019e-05, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.18181818181818182, "f": 0.2580645161290322, "fn": 18.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image is a stuffed animal, a teddy bear, sitting on a pink background. The bear has a white face with black eyes and a black nose. It is wearing a pink bow around its neck."}, "134213": {"image_id": 134213, "Bleu_1": 0.387755102032903, "Bleu_2": 0.22015764295863793, "Bleu_3": 0.12729164253796107, "Bleu_4": 1.4551590344176511e-05, "METEOR": 0.20072221058867867, "ROUGE_L": 0.2822440717177559, "CIDEr": 4.259275589155603e-09, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a photo of a wall with a clock hanging on it. The clock has the words \"houston to\" written on it, indicating that it is a train station. There are also several signs and posters hanging on the wall, advertising different attractions and events in the area."}, "539453": {"image_id": 539453, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.18890811128268284, "Bleu_3": 0.14281978481313226, "Bleu_4": 0.11616125223116953, "METEOR": 0.22592484014569444, "ROUGE_L": 0.26704190118824267, "CIDEr": 7.825465706735581e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.10526315789473684, "f": 0.12903225806451615, "fn": 17.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a group of people playing frisbee on a grassy field. They are all wearing casual clothing and are standing in a circle around the frisbee. One person is throwing the frisbee while the others watch and try to catch it. There are trees and buildings in the background."}, "18982": {"image_id": 18982, "Bleu_1": 0.4999999999166667, "Bleu_2": 0.3015113445263697, "Bleu_3": 2.0870640220585245e-06, "Bleu_4": 5.63756031424638e-09, "METEOR": 0.2145902585327078, "ROUGE_L": 0.43821839080459773, "CIDEr": 0.6392599068409401, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.1111111111111111, "f": 0.12903225806451615, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The man is sitting on a bus, talking on his cell phone."}, "338153": {"image_id": 338153, "Bleu_1": 0.2424242424168963, "Bleu_2": 0.15075567228424214, "Bleu_3": 0.09016995990182317, "Bleu_4": 1.2503053621425558e-05, "METEOR": 0.15138742089416973, "ROUGE_L": 0.21922731356693623, "CIDEr": 0.00026638531186456017, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.21739130434782608, "f": 0.23809523809523808, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a traffic light at an intersection with a red and green light on the top and bottom respectively. There are also pedestrian crossing signs on the side of the road."}, "31620": {"image_id": 31620, "Bleu_1": 0.26865671641390065, "Bleu_2": 0.19140273452372267, "Bleu_3": 0.1500990891024072, "Bleu_4": 0.12749144693968473, "METEOR": 0.3111489923269348, "ROUGE_L": 0.24859908303616912, "CIDEr": 1.8778953801470201e-13, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is a photo of a bride and groom cutting their wedding cake at a reception. The bride is wearing a white wedding dress and the groom is wearing a black tuxedo. They are standing in front of a large tent with colorful streamers hanging from the ceiling. There are several guests in the background, including some who are dancing and others who are sitting at tables."}, "325992": {"image_id": 325992, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.15585730003579046, "Bleu_3": 0.10950337957304693, "Bleu_4": 0.07771324020536689, "METEOR": 0.19291514508424976, "ROUGE_L": 0.2669584245076586, "CIDEr": 6.395030244231042e-06, "SPICE": {"All": {"pr": 0.09375, "re": 0.13636363636363635, "f": 0.1111111111111111, "fn": 19.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a desk with a laptop on it, surrounded by various items such as a cup of coffee, a pen, and a notebook. There is also a window in the background with a view of the outside."}, "55840": {"image_id": 55840, "Bleu_1": 0.44230769229918643, "Bleu_2": 0.29449447955494185, "Bleu_3": 0.1907281374690863, "Bleu_4": 0.12972376796188165, "METEOR": 0.2536562904720557, "ROUGE_L": 0.32199413489736073, "CIDEr": 1.6624593318524884e-05, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.07407407407407407, "f": 0.07843137254901962, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a black cat sitting on a windowsill, looking out the window at night. There is a glass of wine on the table next to the cat and a vase of flowers on the windowsill. The cat has green eyes and is wearing a collar with a bell on it."}, "32708": {"image_id": 32708, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2613777310992162, "Bleu_3": 0.22709459150255668, "Bleu_4": 0.20371727825395644, "METEOR": 0.2673854041650235, "ROUGE_L": 0.3596168017686072, "CIDEr": 0.00012782720133821548, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.10344827586206896, "f": 0.10714285714285715, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a man sitting on the floor with a white shirt on and glasses on his face. He is holding a pair of headphones in his hand and has a look of concentration on his face."}, "20774": {"image_id": 20774, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.2896048475706757, "Bleu_3": 0.17950692908366503, "Bleu_4": 0.11988681018480625, "METEOR": 0.31843645872828386, "ROUGE_L": 0.4113184828416616, "CIDEr": 0.008546238283771617, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people walking down a sidewalk in front of a building with umbrellas. They are all wearing casual clothing and appear to be enjoying the rain."}, "471450": {"image_id": 471450, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.15937104245046027, "Bleu_3": 0.1258257556742031, "Bleu_4": 0.0944804946451367, "METEOR": 0.19841342122253072, "ROUGE_L": 0.19340519974635384, "CIDEr": 2.5418228858618248e-12, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of brown bears standing in a grassy field. They are looking at something in the distance, possibly another bear or a bird. The bears are standing on their hind legs and appear to be communicating with each other. The background is a clear blue sky with some clouds."}, "123627": {"image_id": 123627, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 0.08618888098293648, "Bleu_4": 1.0746774156673132e-05, "METEOR": 0.20534487182798836, "ROUGE_L": 0.21441124780316342, "CIDEr": 1.464457107366617e-08, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.47058823529411764, "f": 0.42105263157894735, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 1.0, "f": 0.7142857142857143, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a horse race taking place on a track with a crowd of people watching from the stands. The horses are racing in a straight line, with one horse leading and the other following closely behind. The crowd is cheering and waving their arms as they watch the race."}, "145436": {"image_id": 145436, "Bleu_1": 0.5999999999700001, "Bleu_2": 0.43528575004367004, "Bleu_3": 0.2191587416728791, "Bleu_4": 2.8051550318641083e-05, "METEOR": 0.3628114844184789, "ROUGE_L": 0.3519230769230769, "CIDEr": 0.3561906689242391, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.16, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a cutting board with several oranges on it, along with a glass of juice and a knife."}, "246590": {"image_id": 246590, "Bleu_1": 0.4418604651060033, "Bleu_2": 0.271373194787634, "Bleu_3": 0.17531689256421082, "Bleu_4": 0.10773401006270078, "METEOR": 0.3061872602942874, "ROUGE_L": 0.3400696864111499, "CIDEr": 5.967538218097058e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.26666666666666666, "f": 0.23529411764705882, "fn": 11.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a yellow motorcycle parked on the side of the road with its front tire raised and a bicycle rack attached to the back. There are people walking by in the background, and a street sign is visible in the distance."}, "430681": {"image_id": 430681, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.25300470311328, "Bleu_3": 0.15263761139750137, "Bleu_4": 0.10039894744611405, "METEOR": 0.18609459979528203, "ROUGE_L": 0.3356258596973865, "CIDEr": 6.45926027514383e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.04878048780487805, "f": 0.0816326530612245, "fn": 39.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a brown bear standing in a stream, drinking water. The bear is standing on the rocks in the stream and its fur is wet. There are trees and greenery in the background of the image."}, "359136": {"image_id": 359136, "Bleu_1": 0.42499999998937504, "Bleu_2": 0.23342489045605275, "Bleu_3": 0.11276394045397138, "Bleu_4": 1.4030632571755696e-05, "METEOR": 0.2852265845340286, "ROUGE_L": 0.32670237184391737, "CIDEr": 6.294483736981846e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a woman lying on the floor in a bathroom. She is wearing black boots and a black top, and her hair is tied back in a ponytail. There is a bathtub in the background of the image."}, "399349": {"image_id": 399349, "Bleu_1": 0.1538461538441815, "Bleu_2": 0.08939803125238129, "Bleu_3": 4.7200591281426447e-07, "Bleu_4": 1.088166278884448e-09, "METEOR": 0.20892605645266538, "ROUGE_L": 0.22324851864761244, "CIDEr": 8.711649220404146e-26, "SPICE": {"All": {"pr": 0.08, "re": 0.125, "f": 0.09756097560975609, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "A man is riding a horse down a dirt road in front of a small shack. The man is wearing a cowboy hat and holding the reins of the horse with his left hand, while his right hand is on the saddle. The horse is brown and has a saddle on its back. In the background, there are two dogs standing next to each other, one black and one white. The dogs are both looking at the camera."}, "523677": {"image_id": 523677, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.23836564730406207, "Bleu_3": 0.1541884625449198, "Bleu_4": 1.869642599434227e-05, "METEOR": 0.20855498185383636, "ROUGE_L": 0.32129420617005267, "CIDEr": 0.0020224916577874026, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.1, "f": 0.0851063829787234, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a view of a pizza shop with several pizzas on display in the window. There are two cashiers behind the counter, and a sign on the wall that reads \"Pizza Shop\"."}, "309900": {"image_id": 309900, "Bleu_1": 0.35135135134660334, "Bleu_2": 0.25013879893391117, "Bleu_3": 0.17340447118869276, "Bleu_4": 0.12183187977152243, "METEOR": 0.262773521731401, "ROUGE_L": 0.26637554585152845, "CIDEr": 4.3627697987027105e-16, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.16, "f": 0.14814814814814817, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a picture of a man standing in front of a television with a remote control in his hand. He is wearing white sneakers and a black shirt. There are two other men sitting on the couch behind him, one of them is holding a controller and the other is playing a video game on the TV. The room appears to be a living room with a carpeted floor and a white ceiling."}, "14557": {"image_id": 14557, "Bleu_1": 0.22666666666364443, "Bleu_2": 0.17501608677435423, "Bleu_3": 0.10797373159615446, "Bleu_4": 0.06466294186250336, "METEOR": 0.1893890100470418, "ROUGE_L": 0.21834451901566, "CIDEr": 1.9742494395059374e-23, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a large, ornate building with a clock tower on top. The clock face is visible on the front of the building, with the hands pointing to 12 o'clock. The building appears to be made of stone and has a large, arched entrance. There are windows on either side of the entrance, and the roof is flat and covered in snow. In the background, there is a blue sky with fluffy white clouds."}, "191381": {"image_id": 191381, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.3162277660039253, "Bleu_3": 0.23539531025786062, "Bleu_4": 0.1560424226798813, "METEOR": 0.2901380103051492, "ROUGE_L": 0.4182174338883448, "CIDEr": 0.05432988540270632, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.16666666666666666, "f": 0.1276595744680851, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet and sink in it. The floor is made of concrete and there are no windows in the room."}, "267571": {"image_id": 267571, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.1923131632828435, "Bleu_3": 0.12713013434655676, "Bleu_4": 0.08753250723793518, "METEOR": 0.25819697512387385, "ROUGE_L": 0.23940345368916802, "CIDEr": 3.255643588950322e-05, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16, "f": 0.2105263157894737, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a giraffe standing in a field with its head tilted to the side and its eyes looking directly at the camera. The giraffe has a brown coat with white spots on its back and legs."}, "322654": {"image_id": 322654, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.245934688411173, "Bleu_3": 0.1263298870441362, "Bleu_4": 1.6237908183879646e-05, "METEOR": 0.24132269459663325, "ROUGE_L": 0.31551724137931036, "CIDEr": 0.000511058348233145, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.2, "f": 0.15789473684210528, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people are sitting on the sidewalk, looking at their phones. The street sign in the background reads 'Hudson River Drive.'\""}, "553667": {"image_id": 553667, "Bleu_1": 0.23913043477741028, "Bleu_2": 0.17856107630055562, "Bleu_3": 0.12954303153626337, "Bleu_4": 0.08432249109179957, "METEOR": 0.2121832397027983, "ROUGE_L": 0.2121001390820584, "CIDEr": 1.0928026156635303e-08, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.047619047619047616, "f": 0.04081632653061224, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a young girl holding a sandwich in her hand, with a look of concentration on her face. She is wearing a green shirt and has her hair tied back in a ponytail. The background is a dark brown table with a checkered pattern."}, "214698": {"image_id": 214698, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 0.07063108368194851, "Bleu_4": 9.57049894254339e-06, "METEOR": 0.24172774143356768, "ROUGE_L": 0.25258799171842644, "CIDEr": 2.7827719925357054e-08, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.06666666666666667, "f": 0.07017543859649124, "fn": 28.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is an image of a street with a stop sign in the middle of the road. There are houses on either side of the street and trees in the background. The sky is cloudy and there are no cars or people in the image."}, "271240": {"image_id": 271240, "Bleu_1": 0.2608695652117203, "Bleu_2": 2.407717061662461e-09, "Bleu_3": 5.088456599619501e-12, "Bleu_4": 2.352731906103417e-13, "METEOR": 0.17589545897916725, "ROUGE_L": 0.2367399741267788, "CIDEr": 1.068385995202849e-07, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.15384615384615385, "f": 0.13333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.2222222222222222, "f": 0.16666666666666669, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "This image shows a snow covered road with two stop signs on either side. The road is empty and there are no cars or people in sight. The snow is piled up on the sides of the road and there are some trees in the background."}, "406959": {"image_id": 406959, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.1643989873008524, "Bleu_3": 0.09174380408476636, "Bleu_4": 1.2276168154895987e-05, "METEOR": 0.16027633760556706, "ROUGE_L": 0.31466470154753134, "CIDEr": 2.781000087554697e-05, "SPICE": {"All": {"pr": 0.125, "re": 0.14814814814814814, "f": 0.13559322033898305, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3333333333333333, "f": 0.2962962962962963, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a close up of an old clock tower in the city. The clock has Roman numerals on it and is surrounded by a metal frame. There are buildings in the background with windows and doors."}, "575624": {"image_id": 575624, "Bleu_1": 0.43396226414275546, "Bleu_2": 0.3418128057724483, "Bleu_3": 0.2840112178509869, "Bleu_4": 0.2379762570235083, "METEOR": 0.36050062817526224, "ROUGE_L": 0.43357025697102247, "CIDEr": 4.4014228833636697e-10, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.15384615384615385, "f": 0.20512820512820515, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is an image of a barn with cows grazing in the field. The barn is made of wood and has a red roof. There are several cows lying on the grass in front of the barn, chewing on some hay. The sky is clear and blue, with some clouds in the distance."}, "565813": {"image_id": 565813, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.30053715350890803, "Bleu_3": 0.2106233574757137, "Bleu_4": 0.16073034971795816, "METEOR": 0.2273197079943073, "ROUGE_L": 0.37110266159695815, "CIDEr": 0.010580667417659603, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.1875, "f": 0.16901408450704225, "fn": 26.0, "numImages": 1.0, "fp": 33.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5454545454545454, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "The image shows a large ship traveling through the water with the Statue of Liberty in the background. The sky is cloudy and there are some buildings visible on the horizon."}, "544071": {"image_id": 544071, "Bleu_1": 0.8461538460236689, "Bleu_2": 0.7510676160808549, "Bleu_3": 0.5897597461221931, "Bleu_4": 0.37844811369685144, "METEOR": 0.31975637617741826, "ROUGE_L": 0.507628294036061, "CIDEr": 1.1051268805535186, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.2, "f": 0.21428571428571427, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "A group of zebras grazing in a field with trees in the background."}, "185335": {"image_id": 185335, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 1.3118830932044058e-06, "Bleu_4": 3.023990415416095e-09, "METEOR": 0.17608542823351844, "ROUGE_L": 0.3405103668261563, "CIDEr": 0.007156081587001678, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.15789473684210525, "f": 0.11111111111111112, "fn": 16.0, "numImages": 1.0, "fp": 32.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The laptop is sitting on a desk in front of a window. There are several books and papers scattered around the room, as well as a television in the corner."}, "573094": {"image_id": 573094, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.3746343246229452, "Bleu_3": 0.33599885885330516, "Bleu_4": 0.30300529884997063, "METEOR": 0.3591396424972384, "ROUGE_L": 0.48316831683168315, "CIDEr": 0.0004521625401480437, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a living room with a Christmas tree in the corner. There are two chairs and a coffee table in front of the window. The walls are painted white and there is a brown rug on the floor."}, "485951": {"image_id": 485951, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.32703497007409993, "Bleu_3": 0.21563531546400697, "Bleu_4": 2.3847864361324923e-05, "METEOR": 0.2538253887777292, "ROUGE_L": 0.38065522620904835, "CIDEr": 0.0020661244822583833, "SPICE": {"All": {"pr": 0.5, "re": 0.17857142857142858, "f": 0.2631578947368421, "fn": 23.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.09090909090909091, "f": 0.16666666666666669, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This image shows a kitchen with wooden cabinets and black appliances. The countertops are made of granite and the floor is made of hardwood. There is a refrigerator, stove, and dishwasher in the kitchen."}, "310879": {"image_id": 310879, "Bleu_1": 0.4374999999726563, "Bleu_2": 0.3818813078883236, "Bleu_3": 0.27516060405615367, "Bleu_4": 3.5579828676919246e-05, "METEOR": 0.19378079595226191, "ROUGE_L": 0.4212707182320442, "CIDEr": 0.35117714584267046, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.34782608695652173, "f": 0.32653061224489793, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.6363636363636364, "f": 0.5833333333333334, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "A flock of birds standing in the water with their heads tilted downwards, looking for food."}, "339368": {"image_id": 339368, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.27216552696600854, "Bleu_3": 1.4176345675574154e-06, "Bleu_4": 3.2672940260811183e-09, "METEOR": 0.2529027043801177, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.031967971411051156, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 24.0, "numImages": 1.0, "fp": 33.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A street scene in a coastal town with green buildings and cars parked on the side of the road.\""}, "115412": {"image_id": 115412, "Bleu_1": 0.09523809523658354, "Bleu_2": 0.05542739954648245, "Bleu_3": 3.692946851320619e-07, "Bleu_4": 9.571763961331237e-10, "METEOR": 0.11074310968197698, "ROUGE_L": 0.12609819121447027, "CIDEr": 5.613908103067811e-18, "SPICE": {"All": {"pr": 0.5, "re": 0.26666666666666666, "f": 0.3478260869565218, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a small, yellow, and white candle sitting on top of a white surface. The candle has a small, round, and white base with a long, thin, and yellow wick in the center. The wick is surrounded by a small, round, and white flame. The image is taken from a close-up perspective, showing the details of the candle and the flame."}, "144694": {"image_id": 144694, "Bleu_1": 0.339622641503026, "Bleu_2": 0.16163173752903065, "Bleu_3": 0.08001308872460663, "Bleu_4": 1.006070177716116e-05, "METEOR": 0.17416196508100484, "ROUGE_L": 0.24007646463510626, "CIDEr": 5.331942384925547e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.19047619047619047, "f": 0.16326530612244897, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a soccer game being played on a field with two teams of players in orange and blue uniforms. One player is kicking the ball towards the goal while another player is running down the field to try and block the shot. There are spectators in the stands watching the game."}, "160728": {"image_id": 160728, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.13427153888031182, "Bleu_3": 6.589854024909179e-07, "Bleu_4": 1.4657466944798315e-09, "METEOR": 0.13992663285869106, "ROUGE_L": 0.20056364490371065, "CIDEr": 4.520497601503607e-17, "SPICE": {"All": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This image shows a group of people standing on the beach in front of a large body of water. There are several boats and kayaks in the water, and people are standing on the shore, some of them holding surfboards. The sky is clear and blue, with a few clouds scattered across it. The background is a rocky cliff face with trees growing on it."}, "56250": {"image_id": 56250, "Bleu_1": 0.1866666666641778, "Bleu_2": 0.1123058885912667, "Bleu_3": 0.05569643513336668, "Bleu_4": 6.999023070853623e-06, "METEOR": 0.16154653956658732, "ROUGE_L": 0.1410078594544614, "CIDEr": 3.0708737956382923e-25, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.21212121212121213, "f": 0.23728813559322037, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5454545454545454, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This image shows a table set up for a wedding reception. There is a white tablecloth on the table and two chairs at either end. A bride and groom are standing at the table, holding hands and smiling at each other. The bride is wearing a white wedding dress and veil, while the groom is wearing a black tuxedo and bow tie. Behind them, there is a large window with a view of the ocean."}, "462840": {"image_id": 462840, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.1748949264355777, "Bleu_3": 0.10767861130247747, "Bleu_4": 0.07141456170370668, "METEOR": 0.23706683577088705, "ROUGE_L": 0.2893689114781872, "CIDEr": 2.08724048426006e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.125, "f": 0.14814814814814814, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a dog sitting on the back of a pickup truck, looking out at the road. The dog is wearing a collar and appears to be enjoying the ride. The truck is parked at the side of the road, and there are other cars passing by in the background."}, "234518": {"image_id": 234518, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.1599005372617867, "Bleu_3": 9.378053745851064e-07, "Bleu_4": 2.2898351849923084e-09, "METEOR": 0.20099097687447257, "ROUGE_L": 0.25738396624472576, "CIDEr": 0.00039813872354304907, "SPICE": {"All": {"pr": 0.5, "re": 0.12, "f": 0.1935483870967742, "fn": 22.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young woman in green shirt and black pants is throwing a frisbee in the park. There are trees and grass in the background."}, "291680": {"image_id": 291680, "Bleu_1": 0.3749999999921875, "Bleu_2": 0.17864740024886272, "Bleu_3": 0.08852756586932273, "Bleu_4": 1.1143093224787654e-05, "METEOR": 0.17393835169502805, "ROUGE_L": 0.2839851024208566, "CIDEr": 2.5128153490435294e-06, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.09523809523809523, "f": 0.09302325581395349, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a baseball player in the middle of a swing, with his teammates watching from the sidelines. The player is wearing a maroon and white uniform and has a bat in his hand. The field behind him is green and there are spectators in the stands."}, "470604": {"image_id": 470604, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.15007505629280368, "Bleu_3": 0.10877430749251783, "Bleu_4": 0.07843772989138478, "METEOR": 0.2536565778357828, "ROUGE_L": 0.3017312448474856, "CIDEr": 1.8159097761858108e-05, "SPICE": {"All": {"pr": 0.08108108108108109, "re": 0.11538461538461539, "f": 0.09523809523809523, "fn": 23.0, "numImages": 1.0, "fp": 34.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.3, "f": 0.23076923076923075, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a young boy holding two tennis rackets. He is wearing a white shirt and has short, dark hair. The background of the image is a wooden floor with a white wall in the background."}, "568981": {"image_id": 568981, "Bleu_1": 0.1739130434757404, "Bleu_2": 0.11308281825632424, "Bleu_3": 0.07254087892307427, "Bleu_4": 8.720695571553305e-06, "METEOR": 0.17476510477979973, "ROUGE_L": 0.20132013201320131, "CIDEr": 2.0907733508134764e-21, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.19047619047619047, "f": 0.16326530612244897, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people are standing on the sidewalk next to a skate park. One person is taking a photo of another person who is standing on a skateboard, while another person is holding a camera and taking a photo of the first person. The skate park has ramps and rails, and there are several people skateboarding in the background."}, "177357": {"image_id": 177357, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.23783535599888, "Bleu_3": 0.10957078983962544, "Bleu_4": 1.3303281214014741e-05, "METEOR": 0.2003189737664298, "ROUGE_L": 0.28754208754208754, "CIDEr": 6.812629743677101e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is an image of a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and has his arms outstretched as he jumps off the wave. The wave is white and foamy, and there are other surfers in the background."}, "233112": {"image_id": 233112, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.14118624159718107, "Bleu_3": 0.09907033493163236, "Bleu_4": 1.2486557620082349e-05, "METEOR": 0.16004436432032546, "ROUGE_L": 0.2778139232270657, "CIDEr": 8.219728445631472e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a bathroom with a shower, toilet, and sink. There are several items on the counter, including towels, toothbrushes, and toothpaste. The floor is made of white tiles and there is a red sign on the wall that says \"Caution Wet Floor\"."}, "150016": {"image_id": 150016, "Bleu_1": 0.42857142854081637, "Bleu_2": 0.18156825978717286, "Bleu_3": 1.400552969760177e-06, "Bleu_4": 3.975360175943345e-09, "METEOR": 0.1435897435897436, "ROUGE_L": 0.271513353115727, "CIDEr": 0.22775330049175116, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.09090909090909091, "f": 0.1290322580645161, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "A herd of cows grazing on a green hillside with mountains in the background."}, "359126": {"image_id": 359126, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.12219311400302733, "Bleu_4": 1.6275776313020367e-05, "METEOR": 0.25584795907908264, "ROUGE_L": 0.357921207041073, "CIDEr": 0.012119825320713692, "SPICE": {"All": {"pr": 0.1, "re": 0.11538461538461539, "f": 0.10714285714285714, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2727272727272727, "f": 0.23076923076923075, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a man standing at a podium, wearing a suit and tie, speaking into a microphone. Behind him is a large banner that reads \"growth jobs 2012\"."}, "295242": {"image_id": 295242, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 7.063108368194853e-07, "Bleu_4": 1.7019021213324188e-09, "METEOR": 0.1555293349071674, "ROUGE_L": 0.2053872053872054, "CIDEr": 4.293388054776081e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.35294117647058826, "f": 0.30769230769230765, "fn": 11.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a white jetliner taking off from a runway at an airport. The plane has a red tail and white wings, with the airline's logo on the side of the fuselage. The sky is clear and blue, with clouds in the distance."}, "357888": {"image_id": 357888, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.29080336344446667, "Bleu_3": 0.20044867222824783, "Bleu_4": 0.11838765649001967, "METEOR": 0.2858852306511863, "ROUGE_L": 0.285427807486631, "CIDEr": 1.509546053273004e-07, "SPICE": {"All": {"pr": 0.5625, "re": 0.28125, "f": 0.375, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 9.0}, "Relation": {"pr": 0.4, "re": 0.13333333333333333, "f": 0.2, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.8571428571428571, "re": 0.6, "f": 0.7058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man stands in a kitchen holding up a sign that says 'Happy New Year' in orange and white letters. The man is wearing an orange shirt and has a friendly smile on his face.\""}, "509223": {"image_id": 509223, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.12119928026283562, "Bleu_3": 0.07971389456746727, "Bleu_4": 0.05459863774002323, "METEOR": 0.17946453530673961, "ROUGE_L": 0.1937738246505718, "CIDEr": 1.7889091576402475e-15, "SPICE": {"All": {"pr": 0.5, "re": 0.13636363636363635, "f": 0.21428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing green and black clothing and has a pair of skis on their feet. They are holding onto the poles with both hands and appear to be in control of the skis. The background is a winter landscape with trees and mountains in the distance."}, "314992": {"image_id": 314992, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.28867513458302535, "Bleu_3": 0.19351158546623434, "Bleu_4": 2.3956565611738468e-05, "METEOR": 0.260929377712134, "ROUGE_L": 0.35847208619000986, "CIDEr": 0.026215365757547626, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13636363636363635, "f": 0.15, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The woman is holding a small flashlight in her hand and smiling at the camera. She is wearing a black jacket and carrying a backpack."}, "370448": {"image_id": 370448, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.24442576475815658, "Bleu_3": 0.14916736567829222, "Bleu_4": 0.0986820934261727, "METEOR": 0.19781513487692354, "ROUGE_L": 0.3053817271589487, "CIDEr": 0.0009179467565037912, "SPICE": {"All": {"pr": 0.1, "re": 0.05555555555555555, "f": 0.07142857142857142, "fn": 34.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a city street with tall buildings on either side. There are cars parked along the sidewalk and people walking down the street. The sky is clear and there are trees in the background."}, "279933": {"image_id": 279933, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.08960727674188575, "Bleu_4": 1.1308221067043766e-05, "METEOR": 0.2010099617327094, "ROUGE_L": 0.23404527433175598, "CIDEr": 6.850983068718549e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a train traveling along a railroad track. The train is moving at a slow pace and has a long line of cars behind it. There are trees and fields on either side of the track, and the sky is clear and blue."}, "349616": {"image_id": 349616, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.294392028865574, "Bleu_3": 0.15561140325389933, "Bleu_4": 2.0343486922522005e-05, "METEOR": 0.20982197697039429, "ROUGE_L": 0.3462630085146642, "CIDEr": 0.029479048836884427, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A group of horses are standing on the beach in front of a cliff. The sky is cloudy and there are rocks in the background."}, "477671": {"image_id": 477671, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.09550351820629131, "Bleu_4": 1.2224986162514046e-05, "METEOR": 0.16121283302215392, "ROUGE_L": 0.3292847503373819, "CIDEr": 1.2419837991884163e-07, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.14285714285714285, "f": 0.14545454545454545, "fn": 24.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man standing in front of a store with a sign that reads, \"Halloween 99.\" The man is wearing a costume and holding a broom. There are pumpkins and other decorations on the sidewalk in front of the store."}, "301317": {"image_id": 301317, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.22312917498915605, "Bleu_3": 0.11141322343035455, "Bleu_4": 1.4098910172163e-05, "METEOR": 0.2921257346325704, "ROUGE_L": 0.2733791455034359, "CIDEr": 1.331945290301241e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a yellow shirt and black shorts, and has a racket in his hand. The background is a green grassy field with trees in the distance."}, "551052": {"image_id": 551052, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.22792115290866924, "Bleu_3": 0.13746108160529513, "Bleu_4": 1.9228544752192987e-05, "METEOR": 0.16098567679674353, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.035291423731108655, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15151515151515152, "f": 0.20833333333333331, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.35714285714285715, "f": 0.5, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows a small brown rat with a green leaf in its mouth, standing on the edge of a white sink."}, "556005": {"image_id": 556005, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.10079509744376741, "Bleu_3": 5.840314225182713e-07, "Bleu_4": 1.4128129251678322e-09, "METEOR": 0.21881216394912187, "ROUGE_L": 0.28554710356933877, "CIDEr": 6.648518383653484e-11, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1111111111111111, "f": 0.0975609756097561, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a red poinsettia flower sitting on a wooden table. The table has a white vase with water and a small candle on it. There is also a wooden chair next to the table. The background of the image is a wooden floor with a pattern of wood grain on it."}, "32056": {"image_id": 32056, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.16974114626800244, "Bleu_3": 0.12339926173807332, "Bleu_4": 0.09559579550549896, "METEOR": 0.23024361787254344, "ROUGE_L": 0.29901960784313725, "CIDEr": 6.145679393225763e-09, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.16666666666666666, "f": 0.24242424242424243, "fn": 20.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a young man standing in front of a group of students, smiling and making a gesture with his hand. He is wearing a red sweater and white shirt, and has a tie around his neck. The background is a school hallway with lockers and chairs."}, "329604": {"image_id": 329604, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.22496063532707972, "Bleu_3": 0.11100361229353628, "Bleu_4": 1.3961343379881599e-05, "METEOR": 0.2737477854432501, "ROUGE_L": 0.22846441947565538, "CIDEr": 5.217153326359768e-06, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13636363636363635, "f": 0.11764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The woman is walking through the woods with an umbrella in her hand. She is wearing a black jacket and jeans, and has a backpack on her back. The trees are bare and there is snow on the ground."}, "577364": {"image_id": 577364, "Bleu_1": 0.1846153846125444, "Bleu_2": 0.07595545253009733, "Bleu_3": 4.507396749882127e-07, "Bleu_4": 1.1024183105884024e-09, "METEOR": 0.16981400553317838, "ROUGE_L": 0.15365239294710328, "CIDEr": 1.1027112099865758e-18, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.11428571428571428, "f": 0.12903225806451613, "fn": 31.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.21428571428571427, "f": 0.23076923076923075, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows an elephant and its baby standing in a dirt area. The elephant is large and gray, with a long trunk and tusks. The baby elephant is smaller and has a shorter trunk and tusks. They are both standing next to each other, with their heads down and their ears up. There is a tree in the background, with leaves on the branches."}, "575643": {"image_id": 575643, "Bleu_1": 0.3157894736675901, "Bleu_2": 0.1324532356993396, "Bleu_3": 1.010552174586843e-06, "Bleu_4": 2.833929617442683e-09, "METEOR": 0.1618437342250549, "ROUGE_L": 0.3053817271589487, "CIDEr": 0.0833647171098802, "SPICE": {"All": {"pr": 0.15, "re": 0.12, "f": 0.1333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA zebra standing in a field, looking at the camera."}, "422918": {"image_id": 422918, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.3438409530246834, "Bleu_3": 0.29728128073381627, "Bleu_4": 0.25214324242770014, "METEOR": 0.3742500467826563, "ROUGE_L": 0.5059907834101383, "CIDEr": 0.014532926689778021, "SPICE": {"All": {"pr": 0.12195121951219512, "re": 0.20833333333333334, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 36.0, "tp": 5.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The woman is sitting on the couch, using her laptop. She is wearing a pink shirt and black shorts. There is a lamp on the table next to her."}, "324189": {"image_id": 324189, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.12399138853119372, "Bleu_3": 0.0839337382802947, "Bleu_4": 0.05835255555224193, "METEOR": 0.11852845211472096, "ROUGE_L": 0.2367487247726769, "CIDEr": 5.929937789482398e-12, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.10526315789473684, "f": 0.08333333333333333, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.4, "f": 0.21052631578947364, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "This image shows a small wooden table sitting on top of a pile of branches and leaves in a grassy area. The table has a white plate on it with a small flower pot on top of it. There are several other plants growing around the table, including some tall trees in the background."}, "466901": {"image_id": 466901, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.33476703169424327, "Bleu_3": 0.23178266456896568, "Bleu_4": 2.6306760830581542e-05, "METEOR": 0.23848307376331848, "ROUGE_L": 0.3597304128053918, "CIDEr": 0.009175004720047855, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people standing around a table with several missiles on it. They are all wearing military uniforms and looking at the missiles with interest."}, "560637": {"image_id": 560637, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.18299102222839972, "Bleu_4": 0.1142211983420398, "METEOR": 0.2162869399613097, "ROUGE_L": 0.3287143956889915, "CIDEr": 7.007772279390842e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a black and white image of a horse standing in a field. The horse is brown and has a long mane and tail. It is standing in the middle of a field with trees in the background."}, "228867": {"image_id": 228867, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.19278507708010587, "Bleu_3": 9.758032910433397e-07, "Bleu_4": 2.209304398110063e-09, "METEOR": 0.18198089970750797, "ROUGE_L": 0.3001230012300123, "CIDEr": 2.930559488985348e-05, "SPICE": {"All": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a room with a bed, a desk, and a chair. There are people standing in the room looking at something on the desk. The walls are painted yellow and there is a window on one side of the room."}, "393226": {"image_id": 393226, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.2271847336913753, "Bleu_3": 0.15268513667670872, "Bleu_4": 0.10618375120204802, "METEOR": 0.27993065013458585, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.0014533935898697298, "SPICE": {"All": {"pr": 0.2, "re": 0.08, "f": 0.11428571428571428, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a blue ice cream truck driving down the street with people walking on the sidewalk. There are buildings in the background and a stop sign at the intersection."}, "413320": {"image_id": 413320, "Bleu_1": 0.17647058823010386, "Bleu_2": 0.1034175379959161, "Bleu_3": 6.939786934219503e-07, "Bleu_4": 1.8120458368313503e-09, "METEOR": 0.10183347171124166, "ROUGE_L": 0.20165289256198346, "CIDEr": 2.4351824430686572e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a yellow submarine floating on the water in the middle of a city park. There are buildings and trees in the background, and people can be seen walking along the shore."}, "15303": {"image_id": 15303, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.1651445647659783, "Bleu_3": 0.07963639705150245, "Bleu_4": 9.88017723049474e-06, "METEOR": 0.20364199831059177, "ROUGE_L": 0.2426136363636364, "CIDEr": 3.135641862416917e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a black wetsuit and has his arms outstretched as he jumps off the wave. The water is choppy and there are whitecaps on the surface of the ocean. The sky is cloudy and there are some birds flying in the distance."}, "124215": {"image_id": 124215, "Bleu_1": 0.8461538460887575, "Bleu_2": 0.6504436355358721, "Bleu_3": 0.4252903702473842, "Bleu_4": 5.266403878016922e-05, "METEOR": 0.38257943573142167, "ROUGE_L": 0.5970636215334422, "CIDEr": 1.4719264785874557, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A computer mouse and keyboard sit on a desk next to a laptop."}, "396461": {"image_id": 396461, "Bleu_1": 0.23880597014568944, "Bleu_2": 0.1203041524616647, "Bleu_3": 0.0606106990607401, "Bleu_4": 7.680101793187824e-06, "METEOR": 0.2036815619737372, "ROUGE_L": 0.20381861575178994, "CIDEr": 4.018466952193804e-19, "SPICE": {"All": {"pr": 0.125, "re": 0.18181818181818182, "f": 0.14814814814814814, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a kitchen with white cabinets and countertops. There are two stoves on the countertops, one with a pot on it and the other with a pan on it. There is also a sink in the corner of the room with a faucet on it. The walls are painted yellow and there is a window on the left side of the room with curtains on it."}, "414196": {"image_id": 414196, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.49761335150383107, "Bleu_3": 0.42762251761962405, "Bleu_4": 0.3378762084149547, "METEOR": 0.47223568511670205, "ROUGE_L": 0.5514124293785311, "CIDEr": 0.20007391697835214, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.25, "f": 0.2553191489361702, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a person holding a cell phone in their hand, with the screen displaying an image of a flower."}, "543713": {"image_id": 543713, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.269724531227751, "Bleu_3": 1.4091455342736073e-06, "Bleu_4": 3.2526091869227003e-09, "METEOR": 0.24915339759512725, "ROUGE_L": 0.4169921875, "CIDEr": 0.0061725927742191395, "SPICE": {"All": {"pr": 0.12, "re": 0.0967741935483871, "f": 0.10714285714285714, "fn": 28.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a white sheep standing in a green field with a fence in the background. There are several other sheep grazing in the field as well."}, "214753": {"image_id": 214753, "Bleu_1": 0.5312499999833985, "Bleu_2": 0.3702658155769199, "Bleu_3": 0.2393365788083879, "Bleu_4": 0.17535364931183806, "METEOR": 0.2844794380004147, "ROUGE_L": 0.5052710843373494, "CIDEr": 0.019039707305553908, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.17857142857142858, "f": 0.2127659574468085, "fn": 23.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "Two people are riding horses on the beach. The horses are brown and black, and they are walking along the sandy shore. There are waves crashing against the rocks in the background."}, "80163": {"image_id": 80163, "Bleu_1": 0.7999999999466668, "Bleu_2": 0.6324555319900065, "Bleu_3": 0.49742263460378094, "Bleu_4": 0.31823566219589394, "METEOR": 0.35184343680335434, "ROUGE_L": 0.6005625879043601, "CIDEr": 1.124184576343588, "SPICE": {"All": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "A young boy is playing tennis on a court with a net in the background."}, "20147": {"image_id": 20147, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.09087496586948689, "Bleu_4": 1.1854610697110774e-05, "METEOR": 0.17531417577750724, "ROUGE_L": 0.27926749509483323, "CIDEr": 3.2368463852590876e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2222222222222222, "f": 0.21818181818181817, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a herd of zebras grazing in a grassy field. They are standing in a line, with their heads down and their stripes visible. In the background, there is a large body of water, with mountains in the distance."}, "479939": {"image_id": 479939, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.14695129936263138, "Bleu_3": 8.075839294554588e-07, "Bleu_4": 1.904915665082057e-09, "METEOR": 0.20289379415307773, "ROUGE_L": 0.23609856792671913, "CIDEr": 9.848700131527434e-07, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a red jacket and black pants, and they are holding onto a snowboard. The snow is covered in trees and there is a mountain in the background."}, "48037": {"image_id": 48037, "Bleu_1": 0.5499999999725, "Bleu_2": 0.24061325158054672, "Bleu_3": 1.476121796196066e-06, "Bleu_4": 3.708765841904931e-09, "METEOR": 0.20594059405940596, "ROUGE_L": 0.22208737864077668, "CIDEr": 0.1706412477881466, "SPICE": {"All": {"pr": 0.16, "re": 0.14814814814814814, "f": 0.15384615384615383, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a refrigerator in a kitchen. It has an open door and shelves inside for storing food and drinks."}, "321706": {"image_id": 321706, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.23488808779791684, "Bleu_3": 0.18081247989280658, "Bleu_4": 0.12164110620828757, "METEOR": 0.27805822088798526, "ROUGE_L": 0.39757914338919925, "CIDEr": 0.0026783377319294704, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.0967741935483871, "f": 0.12244897959183673, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are white and the floor is made of tile. There is a shower curtain hanging in the shower."}, "295076": {"image_id": 295076, "Bleu_1": 0.1866666666641778, "Bleu_2": 0.16657655221249723, "Bleu_3": 0.10447411736747432, "Bleu_4": 0.0750206647175781, "METEOR": 0.18321431763051826, "ROUGE_L": 0.21602478972996908, "CIDEr": 5.52199689459532e-26, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows an airplane taking off from a runway on a cloudy day. The plane is white with red and blue stripes on the tail and wings, and has the American Airlines logo on the side of the fuselage. The runway is made of asphalt and leads to a body of water in the distance. There are several buildings visible in the background, including a large office building with windows and a clock tower."}, "408363": {"image_id": 408363, "Bleu_1": 0.17777777777382722, "Bleu_2": 0.08989331499307865, "Bleu_3": 5.727900241598122e-07, "Bleu_4": 1.454401325207059e-09, "METEOR": 0.1721757154160463, "ROUGE_L": 0.2053872053872054, "CIDEr": 1.947716319730915e-08, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.15384615384615385, "f": 0.17777777777777778, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This image shows a group of people standing in front of a building with balloons tied to the door. The people are wearing red and white clothing and have balloons tied to their hats. There is a sign on the door that says no parking."}, "301641": {"image_id": 301641, "Bleu_1": 0.340909090901343, "Bleu_2": 0.19909945244613453, "Bleu_3": 0.09809125257770394, "Bleu_4": 1.2317618414994371e-05, "METEOR": 0.25794997603818165, "ROUGE_L": 0.25702247191011235, "CIDEr": 3.7488995916039584e-08, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.08, "f": 0.0784313725490196, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is an image of a speedboat in the water. The boat is white and has a black hull. It is being driven by a person wearing a life jacket and sunglasses. The sky is cloudy and there are some clouds in the background."}, "383112": {"image_id": 383112, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 9.139586978860178e-07, "Bleu_4": 2.0648219347002615e-09, "METEOR": 0.15137873975592947, "ROUGE_L": 0.21585279547062985, "CIDEr": 2.355633795613578e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 30.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a busy street with many cars, buses, and pedestrians crossing the road. There are buildings on either side of the street, some of which have signs and advertisements on them. The sky is cloudy and there are some trees in the background."}, "286660": {"image_id": 286660, "Bleu_1": 0.4999999999285716, "Bleu_2": 0.39223227021925744, "Bleu_3": 0.2948798730646316, "Bleu_4": 3.907380248858279e-05, "METEOR": 0.323596008611534, "ROUGE_L": 0.45252225519287836, "CIDEr": 0.619013018333263, "SPICE": {"All": {"pr": 0.125, "re": 0.15789473684210525, "f": 0.13953488372093023, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The woman is holding a stuffed animal in her arms, smiling at the camera."}, "5033": {"image_id": 5033, "Bleu_1": 0.13461538461279587, "Bleu_2": 0.07265696587798288, "Bleu_3": 0.04726374935529322, "Bleu_4": 6.813136779964552e-06, "METEOR": 0.15208022141013913, "ROUGE_L": 0.15365239294710328, "CIDEr": 6.325865368803382e-13, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3333333333333333, "f": 0.29411764705882354, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A small lighthouse stands on a rocky cliffside, surrounded by trees and greenery. The lighthouse has a rustic, old-fashioned look, with a metal roof and a lantern on top. The scene is peaceful and serene, with a train track running through the background.\""}, "218310": {"image_id": 218310, "Bleu_1": 0.9999999997500004, "Bleu_2": 0.8451542545096824, "Bleu_3": 0.7094917057937421, "Bleu_4": 0.6147881527768917, "METEOR": 0.3455700419625743, "ROUGE_L": 0.75, "CIDEr": 1.9057933835591974, "SPICE": {"All": {"pr": 0.2903225806451613, "re": 0.36, "f": 0.3214285714285714, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 9.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5333333333333333, "re": 0.8, "f": 0.64, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 8.0}}, "caption": "Two colorful parrots perched on a wooden branch."}, "459265": {"image_id": 459265, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.266556994977913, "Bleu_3": 0.1580408005034111, "Bleu_4": 2.1951524425427533e-05, "METEOR": 0.27418023286833765, "ROUGE_L": 0.42558139534883715, "CIDEr": 0.132522712586357, "SPICE": {"All": {"pr": 0.5, "re": 0.1875, "f": 0.2727272727272727, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a woman in white tennis dress and sneakers playing tennis on a court with other players watching."}, "55528": {"image_id": 55528, "Bleu_1": 0.5833333333090278, "Bleu_2": 0.4213504857822543, "Bleu_3": 0.3184012539741897, "Bleu_4": 0.2605892926928462, "METEOR": 0.3167965319655202, "ROUGE_L": 0.4447916666666667, "CIDEr": 0.08351165877923597, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.17647058823529413, "f": 0.15789473684210528, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The man is sitting in a chair, holding a bag of groceries. He is wearing glasses and has a serious expression on his face."}, "205866": {"image_id": 205866, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.10400628679061788, "Bleu_3": 0.055580981441786075, "Bleu_4": 7.254320449841931e-06, "METEOR": 0.15463917525773196, "ROUGE_L": 0.18174595292481877, "CIDEr": 7.03700393154126e-17, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.07142857142857142, "f": 0.05405405405405405, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a person standing on the beach next to a group of kayaks. The person is wearing a hat and sunglasses, and they are looking out at the ocean. There are several kayaks on the sand next to them, some of which are empty and others that have people sitting in them. The sky is blue and there are some clouds in it."}, "290875": {"image_id": 290875, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.15949736033709896, "Bleu_3": 0.10417771493236237, "Bleu_4": 0.0711980257594806, "METEOR": 0.20212160913017935, "ROUGE_L": 0.2501708817498291, "CIDEr": 5.579729371430011e-09, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.06666666666666667, "f": 0.0606060606060606, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows two baseball players standing on a baseball field, one holding a bat and the other holding a ball. They are both wearing baseball uniforms with different numbers on their jerseys. The background is a green grass field with white lines and a dirt infield."}, "153896": {"image_id": 153896, "Bleu_1": 0.4838709677263268, "Bleu_2": 0.2540002539920509, "Bleu_3": 1.3054395556610798e-06, "Bleu_4": 2.985575568232099e-09, "METEOR": 0.2955092896531161, "ROUGE_L": 0.3925985518905873, "CIDEr": 0.0033575265547987525, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.19230769230769232, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court with a blue background. He is wearing a white shirt and black shorts, and has a tennis racket in his hand."}, "69914": {"image_id": 69914, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 7.063108368194853e-07, "Bleu_4": 1.7019021213324188e-09, "METEOR": 0.1601677686418669, "ROUGE_L": 0.168391994478951, "CIDEr": 2.7371459700150014e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5714285714285714, "f": 0.47058823529411764, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a kitchen with a stove, refrigerator, and sink. There are two people standing in the kitchen, one of them is cooking something on the stove while the other is washing dishes in the sink. The room has white walls and a wooden floor."}, "404517": {"image_id": 404517, "Bleu_1": 0.636363636247934, "Bleu_2": 0.504524979015488, "Bleu_3": 0.38387009253436954, "Bleu_4": 5.156626917220543e-05, "METEOR": 0.2969966810501506, "ROUGE_L": 0.6110183639398998, "CIDEr": 1.3493508284779951, "SPICE": {"All": {"pr": 0.3125, "re": 0.29411764705882354, "f": 0.30303030303030304, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The woman is playing fetch with her dog in the grass."}, "455548": {"image_id": 455548, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.2175970699379255, "Bleu_3": 0.16609448625472853, "Bleu_4": 0.11116961408796829, "METEOR": 0.3395680828249574, "ROUGE_L": 0.4118143459915612, "CIDEr": 0.0011245696297148718, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of zebras standing in a grassy field. They are all facing the same direction and appear to be grazing. There is a small stream running through the background."}, "346965": {"image_id": 346965, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.20603150145092247, "Bleu_3": 0.15236855057487514, "Bleu_4": 0.11076550621858337, "METEOR": 0.23314589950078812, "ROUGE_L": 0.29865361077111385, "CIDEr": 7.382164720507984e-09, "SPICE": {"All": {"pr": 0.3125, "re": 0.21739130434782608, "f": 0.2564102564102564, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The man is holding a small dog in his arms while walking down the street. The dog is wearing a red collar and tag. The man is wearing a black shirt and jeans, and has a white t-shirt underneath. There are several storefronts visible in the background of the image."}, "342649": {"image_id": 342649, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.4385290096209864, "Bleu_3": 0.3176497139840096, "Bleu_4": 4.131551590773094e-05, "METEOR": 0.2252273455508018, "ROUGE_L": 0.49061662198391426, "CIDEr": 0.681314567772583, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16666666666666666, "f": 0.186046511627907, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Two birds are sitting on a wooden bench, looking at something in their beaks."}, "545292": {"image_id": 545292, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.11053526637390183, "Bleu_3": 6.056378535716197e-07, "Bleu_4": 1.4241683131101641e-09, "METEOR": 0.12619296335282143, "ROUGE_L": 0.20098846787479405, "CIDEr": 1.9193112476627815e-14, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.1724137931034483, "f": 0.20833333333333334, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThis image shows an elephant standing in a grassy area with trees and rocks in the background. The elephant is wearing a green tarp around its body, which appears to be protecting it from the elements. The elephant looks happy and content as it stands in the sun."}, "172716": {"image_id": 172716, "Bleu_1": 0.2452830188632966, "Bleu_2": 0.18171094607444632, "Bleu_3": 0.12476834639035371, "Bleu_4": 0.07894703307415313, "METEOR": 0.1609609003290945, "ROUGE_L": 0.21721068249258166, "CIDEr": 2.6734956631112535e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.10344827586206896, "f": 0.1395348837209302, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a skateboarder performing a trick on a half pipe. The skateboarder is wearing a helmet and knee pads, and is holding onto the handlebars of the board with one hand while balancing on the other. The background is a concrete half pipe with a metal rail around it."}, "153506": {"image_id": 153506, "Bleu_1": 0.818181818033058, "Bleu_2": 0.756787468523232, "Bleu_3": 0.7254690150137174, "Bleu_4": 0.6989307621403409, "METEOR": 0.4260990818515791, "ROUGE_L": 0.768503937007874, "CIDEr": 2.637383279173201, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.26666666666666666, "f": 0.2051282051282051, "fn": 11.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A plate with a sandwich, fries, and a drink on it."}, "375769": {"image_id": 375769, "Bleu_1": 0.562499999982422, "Bleu_2": 0.3563932224723017, "Bleu_3": 0.2038242586060542, "Bleu_4": 2.3245687973982252e-05, "METEOR": 0.20620129138115695, "ROUGE_L": 0.41780821917808214, "CIDEr": 0.014829425307529965, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A young boy is sitting at a table outside with a cup of coffee in front of him. There are bicycles parked nearby and a few people walking by on the sidewalk."}, "460145": {"image_id": 460145, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2419887570845995, "Bleu_3": 0.17121738615762308, "Bleu_4": 0.11022780716314358, "METEOR": 0.30261161262378045, "ROUGE_L": 0.39071257005604487, "CIDEr": 0.00020605757208316263, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a flock of sheep grazing on the side of the road. The sky is cloudy and there are mountains in the background. A car is driving down the road with the sheep following it."}, "15883": {"image_id": 15883, "Bleu_1": 0.17910447760926712, "Bleu_2": 0.09022811434624856, "Bleu_3": 0.05003302970080243, "Bleu_4": 6.651163256551078e-06, "METEOR": 0.1479574866683932, "ROUGE_L": 0.14475557664926436, "CIDEr": 1.0443913864923682e-20, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.21875, "f": 0.2857142857142857, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This image shows a group of people standing around a table with various food items on it. One person is cutting up meat on a cutting board while another person is preparing a plate of food. There are several other people in the background, some of whom are also preparing food. The atmosphere appears to be festive and social, with people chatting and laughing while they work."}, "562073": {"image_id": 562073, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.16817499303341832, "Bleu_3": 0.1169829962474529, "Bleu_4": 0.08858266023053883, "METEOR": 0.16133141732626669, "ROUGE_L": 0.21095100864553315, "CIDEr": 2.2583913342361232e-13, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.18181818181818182, "f": 0.14285714285714285, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5714285714285714, "f": 0.36363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a store with various electronic devices and gadgets on display. Some of the people are holding shopping bags, while others are looking at the products on the shelves. The store appears to be well lit and organized, with rows of shelves and displays throughout."}, "334469": {"image_id": 334469, "Bleu_1": 0.25806451612486997, "Bleu_2": 0.15932167155870422, "Bleu_3": 0.10826960963770271, "Bleu_4": 0.08098869931445592, "METEOR": 0.18285949442191887, "ROUGE_L": 0.24182358771060455, "CIDEr": 2.3134872780265975e-11, "SPICE": {"All": {"pr": 0.375, "re": 0.2, "f": 0.26086956521739135, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.38461538461538464, "f": 0.4545454545454546, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of people standing on the shore of a lake, looking at something in the water. One person is holding a fishing rod and another is holding a bucket. There are several other people in the background, some of whom are also holding fishing rods or buckets. The sky is cloudy and there are trees in the background."}, "541018": {"image_id": 541018, "Bleu_1": 0.5416666666440973, "Bleu_2": 0.40602348755919476, "Bleu_3": 0.2822281286623285, "Bleu_4": 0.18088201961324035, "METEOR": 0.23315729937064383, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.15176289625481534, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2631578947368421, "f": 0.27777777777777773, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a plate of food, including fries and a bowl of soup. There is also a glass of water on the table."}, "48692": {"image_id": 48692, "Bleu_1": 0.3015873015825145, "Bleu_2": 0.13948922991784782, "Bleu_3": 0.06832566061785036, "Bleu_4": 8.538863419005504e-06, "METEOR": 0.18503961364221386, "ROUGE_L": 0.26406926406926406, "CIDEr": 3.507345411714476e-16, "SPICE": {"All": {"pr": 0.4, "re": 0.16, "f": 0.22857142857142856, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "This image shows a small market stall with a variety of fruits and vegetables on display. The stall is made of wood and has a red and white striped awning above it. There are several baskets of fruit and vegetables on the ground, including bananas, apples, and tomatoes. A small table with a white tablecloth is also visible in front of the stall."}, "292324": {"image_id": 292324, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.14189834119414174, "Bleu_4": 0.11620875224195953, "METEOR": 0.24855489723389323, "ROUGE_L": 0.3100381194409149, "CIDEr": 2.7791339452662946e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee table, and chairs. The walls are painted white and there are large windows on one side of the room that let in natural light. The floor is made of hardwood and there is a rug in the center of the room."}, "375484": {"image_id": 375484, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 7.901769277795583e-07, "Bleu_4": 1.8299115122529755e-09, "METEOR": 0.2061468441978019, "ROUGE_L": 0.2621883826599533, "CIDEr": 5.014561866927e-08, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}}, "caption": "This is a small, cluttered office space with a desk, chair, and computer. The walls are painted a light blue color and there are several shelves and cabinets in the room. There is also a lamp on the desk and a pair of headphones on the chair."}, "245667": {"image_id": 245667, "Bleu_1": 0.3953488372001082, "Bleu_2": 0.23765185737325192, "Bleu_3": 0.14018757444877172, "Bleu_4": 0.09109974122666077, "METEOR": 0.28966556764036067, "ROUGE_L": 0.3400696864111499, "CIDEr": 8.22370907509524e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are wearing ski gear and helmets, and one person is holding a ski pole. The trees in the background are covered in snow, and there is a cloudy sky above."}, "119729": {"image_id": 119729, "Bleu_1": 0.7272727271404961, "Bleu_2": 0.5393598898700768, "Bleu_3": 0.4013422918623043, "Bleu_4": 0.2998221388749698, "METEOR": 0.31143220255200077, "ROUGE_L": 0.5454545454545454, "CIDEr": 1.699063110419746, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2631578947368421, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A person is holding a bunch of bananas on their hand."}, "274014": {"image_id": 274014, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.294392028865574, "Bleu_3": 0.1960580825632673, "Bleu_4": 2.4192619392227976e-05, "METEOR": 0.21159840147501105, "ROUGE_L": 0.3462630085146642, "CIDEr": 0.04192768036058747, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Here is a short caption of the image:\n\n\"A group of skiers on a snowy mountain slope, wearing red and black clothing and carrying skis.\""}, "305412": {"image_id": 305412, "Bleu_1": 0.36956521738327036, "Bleu_2": 0.2219805449057966, "Bleu_3": 0.10384662420360959, "Bleu_4": 1.2703610616458728e-05, "METEOR": 0.25815375392213064, "ROUGE_L": 0.24238410596026488, "CIDEr": 7.618618350706336e-09, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.08823529411764706, "f": 0.09523809523809523, "fn": 31.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a sink in a bathroom. The sink is made of stainless steel and has a drain hole in the bottom. There is water on the floor next to the sink, and the walls are painted with a blue and white pattern."}, "83656": {"image_id": 83656, "Bleu_1": 0.3090909090852893, "Bleu_2": 0.2620817976974896, "Bleu_3": 0.19811454724826918, "Bleu_4": 0.16535941983280275, "METEOR": 0.2833668052051354, "ROUGE_L": 0.27555053642010163, "CIDEr": 8.379772026423164e-13, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.17857142857142858, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3333333333333333, "f": 0.380952380952381, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a brown cow standing on the beach in front of the ocean. The cow is looking out at the water and appears to be enjoying the view. The sky is clear and blue, with a few clouds scattered across it. The sand is white and the waves are crashing against the shore."}, "360480": {"image_id": 360480, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.230960638416735, "Bleu_3": 0.11400515270331847, "Bleu_4": 1.4344200576586565e-05, "METEOR": 0.26528008658047303, "ROUGE_L": 0.3351648351648352, "CIDEr": 5.914343391943119e-06, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.20689655172413793, "f": 0.21052631578947367, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a woman in a white shirt and green shorts holding a tennis racket as she prepares to hit the ball on a tennis court. The background is made up of trees and a blue sky."}, "14226": {"image_id": 14226, "Bleu_1": 0.6086956521474481, "Bleu_2": 0.49901087932565624, "Bleu_3": 0.3899332288522837, "Bleu_4": 0.27748702734311687, "METEOR": 0.3664248733577676, "ROUGE_L": 0.4947139753801593, "CIDEr": 0.19945983439513087, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.3333333333333333, "f": 0.358974358974359, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A man in a suit and tie is sitting at a table on a train with his laptop open in front of him."}, "121417": {"image_id": 121417, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2660221937781222, "Bleu_3": 0.22245410406264268, "Bleu_4": 0.19683619460964766, "METEOR": 0.30556666091776463, "ROUGE_L": 0.35660928873010717, "CIDEr": 1.9201970982968688e-07, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.4, "f": 0.39215686274509803, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 10.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.6363636363636364, "f": 0.5833333333333334, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image shows a woman sitting on a bench under an umbrella. She is wearing black pants and a black jacket, and has her hands in her pockets. The umbrella is pink with white polka dots. There are people walking by on the street in the background."}, "417911": {"image_id": 417911, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.21967782188085846, "Bleu_3": 9.81749639652121e-07, "Bleu_4": 2.085729875019735e-09, "METEOR": 0.2234481270597961, "ROUGE_L": 0.27774615822424586, "CIDEr": 2.2043785379344258e-07, "SPICE": {"All": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}}, "caption": "This image shows a man surfing on a wave in the ocean. He is wearing a black wetsuit and holding onto his surfboard as he rides the wave. The water is choppy and there are whitecaps on the surface of the ocean. The sky is cloudy and there are some birds flying overhead."}, "33005": {"image_id": 33005, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.14555562743244904, "Bleu_3": 0.07148419034913474, "Bleu_4": 8.94723384105085e-06, "METEOR": 0.24766056590239496, "ROUGE_L": 0.23410087719298245, "CIDEr": 3.4480286678529673e-16, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21428571428571427, "f": 0.19672131147540986, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. He is wearing a white shirt and black shorts, and has a racket in his hand. The court is made of concrete and there are lines on it to mark the boundaries of the game. There are also some spectators watching from the sidelines."}, "292435": {"image_id": 292435, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.17472060423831776, "Bleu_3": 0.11070534149073814, "Bleu_4": 0.0745183556152167, "METEOR": 0.15811529368664856, "ROUGE_L": 0.20847573479152426, "CIDEr": 4.219845055846196e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13043478260869565, "f": 0.1333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of bears standing on the ground in front of a fence. They are all looking at each other and appear to be in a playful mood. There is a small pond with water in it nearby, and some trees in the background."}, "328354": {"image_id": 328354, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.19050019049423667, "Bleu_3": 0.10655075333690474, "Bleu_4": 1.4291173573605973e-05, "METEOR": 0.19660537433596068, "ROUGE_L": 0.23828124999999997, "CIDEr": 0.0035725742693007976, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.1875, "f": 0.24489795918367344, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.13333333333333333, "f": 0.2222222222222222, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a room with old furniture and a broken television. The walls are covered in peeling paint and there are broken windows on the side of the building."}, "367610": {"image_id": 367610, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.13965509692979164, "Bleu_3": 7.512513229843848e-07, "Bleu_4": 1.7520068866272228e-09, "METEOR": 0.18222461159897974, "ROUGE_L": 0.20497311827956988, "CIDEr": 1.167227727316193e-09, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a herd of sheep walking along the side of a road, with a man standing on the sidewalk holding a stick. The sheep are all facing the same direction and appear to be following the man. The sky is clear and blue in the background."}, "187352": {"image_id": 187352, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.15585730003579046, "Bleu_3": 8.691288996416392e-07, "Bleu_4": 2.0665100326125144e-09, "METEOR": 0.2560078252490658, "ROUGE_L": 0.2741573033707865, "CIDEr": 3.446018134809049e-06, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.06666666666666667, "f": 0.0689655172413793, "fn": 28.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a man playing tennis on a court at night. He is wearing a yellow shirt and black shorts, and has a racket in his hand. There are lights on the court and buildings in the background."}, "403820": {"image_id": 403820, "Bleu_1": 0.2545454545408265, "Bleu_2": 0.15352206215446232, "Bleu_3": 0.09616829261227482, "Bleu_4": 1.1435972261187565e-05, "METEOR": 0.19815776589321904, "ROUGE_L": 0.22008418520745643, "CIDEr": 3.4332179167319124e-13, "SPICE": {"All": {"pr": 0.08108108108108109, "re": 0.2, "f": 0.11538461538461539, "fn": 12.0, "numImages": 1.0, "fp": 34.0, "tp": 3.0}, "Relation": {"pr": 0.0625, "re": 0.2, "f": 0.09523809523809523, "fn": 4.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.3333333333333333, "f": 0.19047619047619044, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "This is an image of a small airplane flying in the sky. The plane is white and red with a blue tail and wings. It is flying low to the ground and appears to be taking off from a runway. There are clouds in the background and the sun is shining down on the plane."}, "248353": {"image_id": 248353, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.344350221559779, "Bleu_3": 0.2243557191518718, "Bleu_4": 2.7412292652641044e-05, "METEOR": 0.3153262977594623, "ROUGE_L": 0.21205098493626884, "CIDEr": 0.04819111866821684, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.24, "f": 0.28571428571428564, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a ski resort with several people skiing down the slopes. There are trees and mountains in the background."}, "472067": {"image_id": 472067, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.19920476821678648, "Bleu_3": 0.1671322184283994, "Bleu_4": 0.14353141358611074, "METEOR": 0.23527028101530964, "ROUGE_L": 0.32947530864197533, "CIDEr": 0.00018446414280819026, "SPICE": {"All": {"pr": 0.09803921568627451, "re": 0.2631578947368421, "f": 0.14285714285714285, "fn": 14.0, "numImages": 1.0, "fp": 46.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.13333333333333333, "re": 0.5, "f": 0.2105263157894737, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13636363636363635, "re": 0.5, "f": 0.21428571428571427, "fn": 3.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on the grass with umbrellas. They are all smiling and looking at something in front of them. The background is green and there are trees in the distance."}, "318080": {"image_id": 318080, "Bleu_1": 0.5142857142710204, "Bleu_2": 0.3889222341200232, "Bleu_3": 0.2636881004735942, "Bleu_4": 2.7512522086045674e-05, "METEOR": 0.31101821419117703, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.0008119852829872331, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two brown bears standing on a log, looking at each other. They are both growling and their mouths are open. The background is a rocky area with some trees in the distance."}, "491062": {"image_id": 491062, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.19221293610287601, "Bleu_3": 0.11101981187859314, "Bleu_4": 1.5146316522555611e-05, "METEOR": 0.21218024319956852, "ROUGE_L": 0.32649420160570913, "CIDEr": 0.004325523093466744, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.06666666666666667, "f": 0.0606060606060606, "fn": 28.0, "numImages": 1.0, "fp": 34.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a plate of grilled cheese sandwiches with tomato slices on the side. There is a glass of red wine on the table next to the plate."}, "514787": {"image_id": 514787, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.16094080478419465, "Bleu_3": 0.08318402702711739, "Bleu_4": 1.0694655186909581e-05, "METEOR": 0.20342404374102466, "ROUGE_L": 0.27180140038192235, "CIDEr": 5.6596516870250165e-08, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.12, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a collage of images of people playing video games on their computers. The images are arranged in a grid format, with each image showing a different person playing a different game. Some of the people are wearing green shirts, while others are wearing other colors."}, "443963": {"image_id": 443963, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2419887570845995, "Bleu_3": 0.1884491176127898, "Bleu_4": 0.1408585945661569, "METEOR": 0.21791963566388461, "ROUGE_L": 0.31466470154753134, "CIDEr": 6.822433420144544e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23809523809523808, "f": 0.19607843137254902, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a bathroom with a sink, toilet, and shower. The walls are painted white and the floor is made of tile. There is a window on one side of the room that lets in natural light."}, "423173": {"image_id": 423173, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.2302830932288319, "Bleu_3": 0.1506829579238831, "Bleu_4": 0.10333984099207438, "METEOR": 0.23969086983199128, "ROUGE_L": 0.39967239967239965, "CIDEr": 0.002566454479165611, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a person wearing a helmet and riding a motorcycle with a stuffed bear on the back. The person is driving down a street with trees and buildings in the background."}, "392575": {"image_id": 392575, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2663118206400466, "Bleu_3": 0.20992207086893125, "Bleu_4": 0.1693383976147228, "METEOR": 0.26226297827516803, "ROUGE_L": 0.3091216216216216, "CIDEr": 2.777686730024855e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.23809523809523808, "f": 0.21739130434782608, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a food truck parked on the sidewalk in front of a building. There are people standing around the truck, looking at the menu on the side of the truck. The truck has a red and white striped awning over the top of it."}, "29596": {"image_id": 29596, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.11449528240744467, "Bleu_4": 0.07927655972962615, "METEOR": 0.23995258460936425, "ROUGE_L": 0.33493479752916955, "CIDEr": 3.22150435083756e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.3076923076923077, "f": 0.17777777777777778, "fn": 9.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee table, and television. The walls are painted white and there are curtains on the windows. The floor is made of hardwood and there is a rug in the center of the room."}, "571804": {"image_id": 571804, "Bleu_1": 0.18604651162358038, "Bleu_2": 2.1046802246600357e-09, "Bleu_3": 4.762804932845266e-12, "Bleu_4": 2.279723091369041e-13, "METEOR": 0.1556420233463035, "ROUGE_L": 0.21801286633309508, "CIDEr": 2.3909373057953652e-08, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.21739130434782608, "f": 0.27027027027027023, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a display case with several ceramic items on it. There are two sinks, one with a faucet and the other without, as well as a toilet with a tank and handle. There are also several vases and urns on the shelves."}, "530706": {"image_id": 530706, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.24019223070154896, "Bleu_3": 0.11493300756926315, "Bleu_4": 1.4232564071963268e-05, "METEOR": 0.2485172850944776, "ROUGE_L": 0.3139705882352941, "CIDEr": 3.472978237460404e-05, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.19047619047619047, "f": 0.26666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting at desks in a computer lab. They are all wearing casual clothing and are working on their computers. There is a large window behind them with a view of the city outside."}, "475995": {"image_id": 475995, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.09917694073445357, "Bleu_3": 0.055037217324562536, "Bleu_4": 7.3220948858555005e-06, "METEOR": 0.17850402903871423, "ROUGE_L": 0.15443037974683543, "CIDEr": 2.3590244271657427e-13, "SPICE": {"All": {"pr": 0.08, "re": 0.06896551724137931, "f": 0.07407407407407408, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a ledge overlooking a city skyline. They are all wearing sunglasses and looking at their phones. In the foreground, there are several white dogs sitting on the ground, looking up at the people. The dogs are all wearing collars and leashes. The background is a city skyline with tall buildings and trees."}, "558242": {"image_id": 558242, "Bleu_1": 0.20833333333043982, "Bleu_2": 0.12112539577618318, "Bleu_3": 0.05940059466088974, "Bleu_4": 7.4238779240632125e-06, "METEOR": 0.13592014811136208, "ROUGE_L": 0.17058165548098433, "CIDEr": 3.448054672749692e-22, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a baseball player in the process of throwing a ball to another player on the field. The player is wearing a blue and white uniform with the number 10 on the back. The other player is wearing a red and white uniform with the number 2 on the back. The image is in black and white, with the players and the ball in focus while the background is blurred."}, "449191": {"image_id": 449191, "Bleu_1": 0.17241379310047567, "Bleu_2": 0.09525969852473676, "Bleu_3": 5.451844491105067e-07, "Bleu_4": 1.3101376346359472e-09, "METEOR": 0.18388052884645426, "ROUGE_L": 0.2406989853438557, "CIDEr": 2.6231025967329948e-15, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.14285714285714285, "f": 0.17777777777777778, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This image shows a man standing in the back of a truck with several suitcases stacked on top of him. He is wearing a blue shirt and jeans, and has a smile on his face as he holds onto the handle of the suitcase. The truck is parked in front of a building with windows and a door."}, "380993": {"image_id": 380993, "Bleu_1": 0.13861386138476622, "Bleu_2": 0.08325078419551978, "Bleu_3": 4.121422685103128e-07, "Bleu_4": 9.193456997201078e-10, "METEOR": 0.12682759632493182, "ROUGE_L": 0.12560917015581027, "CIDEr": 4.381729292466733e-50, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.23809523809523808, "f": 0.31249999999999994, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a group of people standing under an umbrella on a rainy day. They are all wearing different colored clothing and have their arms around each other. The man in the center is wearing a white shirt and black pants, while the woman on the left is wearing a red dress and the woman on the right is wearing a blue shirt and white pants. The man in the back is wearing a black jacket and the woman in the front is wearing a yellow jacket. The image is blurry and has a lot of reflections from the rain."}, "25069": {"image_id": 25069, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2172062116707298, "Bleu_3": 1.0158836938812301e-06, "Bleu_4": 2.209376971239303e-09, "METEOR": 0.1642514732034496, "ROUGE_L": 0.23404527433175598, "CIDEr": 1.154325145484063e-07, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21739130434782608, "f": 0.18867924528301885, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person skateboarding down the sidewalk on a sunny day. The person is wearing a white shirt and black pants, and has a backpack slung over their shoulder. There are buildings in the background, and a car parked on the side of the road."}, "301963": {"image_id": 301963, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 0.14563421111572247, "Bleu_4": 0.11610083023204879, "METEOR": 0.22716274876630957, "ROUGE_L": 0.31466470154753134, "CIDEr": 0.00026626636807847186, "SPICE": {"All": {"pr": 0.25806451612903225, "re": 0.38095238095238093, "f": 0.30769230769230765, "fn": 13.0, "numImages": 1.0, "fp": 23.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4666666666666667, "re": 0.7, "f": 0.56, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}}, "caption": "This is a living room with a wooden floor, a couch, and a chair. There are windows on the walls and a fireplace in the corner. The room is well lit by natural light from the windows."}, "444304": {"image_id": 444304, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.22629428591537873, "Bleu_3": 0.16220166573112021, "Bleu_4": 0.10508106635508425, "METEOR": 0.23219247116343888, "ROUGE_L": 0.2793893129770992, "CIDEr": 7.533585695810938e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15, "f": 0.15789473684210525, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man sitting on a bed, looking at a television. He is wearing a yellow shirt and blue pants. There are several other objects in the room, including a lamp, a computer, and a bookshelf."}, "505728": {"image_id": 505728, "Bleu_1": 0.1408450704205515, "Bleu_2": 0.08971226080197876, "Bleu_3": 0.04885977963930358, "Bleu_4": 6.435560831383967e-06, "METEOR": 0.14144651813539738, "ROUGE_L": 0.17259266245402244, "CIDEr": 7.623632335116269e-24, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.11764705882352941, "f": 0.09756097560975609, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This image shows a woman in a white apron and gloves mixing something in a bowl on a countertop. There are several other utensils and ingredients on the counter, including a mixing bowl, measuring cups, and a spatula. The woman is wearing a white apron and gloves, and her hair is tied back in a ponytail. The background of the image is a kitchen with stainless steel appliances and white cabinets."}, "170893": {"image_id": 170893, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.4355724051650084, "Bleu_3": 0.3003822218792885, "Bleu_4": 0.19186606564204425, "METEOR": 0.296091511330041, "ROUGE_L": 0.4291457286432161, "CIDEr": 0.21995918153115918, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13043478260869565, "f": 0.12244897959183673, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a dog sitting on the floor next to a toilet, looking up at the toilet paper hanging from the roll."}, "40711": {"image_id": 40711, "Bleu_1": 0.13821138211269746, "Bleu_2": 0.10643684424306898, "Bleu_3": 0.072080789268051, "Bleu_4": 0.04203096280813777, "METEOR": 0.1772057702019195, "ROUGE_L": 0.17217047699689528, "CIDEr": 1.5401322288769305e-74, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14285714285714285, "f": 0.18604651162790697, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.23076923076923078, "f": 0.3, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a building with a clock tower on top. The building has a lot of ornate details, including carvings and statues. There are also some people walking down the street in the background.\n\nThe image is taken from a bird's eye view, so it looks like you are looking down on the scene from above. The sky is blue and there are some clouds in the background.\n\nThe overall mood of the image is one of nostalgia and tradition, as the building and the clock tower seem to be from an older time period. The people in the image are dressed in modern clothing, which adds a contrast to the old building."}, "510734": {"image_id": 510734, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.18091268062725444, "Bleu_3": 0.11987486713703241, "Bleu_4": 1.3243387827062447e-05, "METEOR": 0.20981584132975173, "ROUGE_L": 0.2010326266066132, "CIDEr": 1.3317354440730727e-14, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.3333333333333333, "f": 0.3703703703703704, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "A black and white image of a bench in the middle of a park with people sitting on it. The bench is made of wood and has a backrest. There are trees and buildings in the background.\n\nThe caption for this image could be: \"A peaceful scene in the park\" or \"People relaxing on a bench in the park\"."}, "171067": {"image_id": 171067, "Bleu_1": 0.05199999999979201, "Bleu_2": 0.03231372319648325, "Bleu_3": 0.02034467572048981, "Bleu_4": 2.4163722557408473e-06, "METEOR": 0.0911870350631666, "ROUGE_L": 0.07280787757363912, "CIDEr": 0.0, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.15384615384615385, "f": 0.0975609756097561, "fn": 11.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a wooden clock with a cuckoo bird on top of it. The clock has a red and white design with a cuckoo bird on top of it. The clock has a small window on the front that shows the time.\n\nThe clock is made of wood and has a cuckoo bird on top of it. The bird is made of metal and has a small beak and wings. The clock has a small window on the front that shows the time.\n\nThe clock is a traditional German style clock with a cuckoo bird on top of it. The clock has a red and white design with a cuckoo bird on top of it. The clock has a small window on the front that shows the time.\n\nThe clock is a traditional German style clock with a cuckoo bird on top of it. The clock has a red and white design with a cuckoo bird on top of it. The clock has a small window on the front that shows the time.\n\nThe clock is a traditional German style clock with a cuckoo bird on top of it. The clock has a red and white design with a cuckoo bird on top of it. The clock has a small window on the front that shows the time.\n\nThe clock is a traditional German style clock with a cuckoo bird on top of it. The clock has a red and white design with a cuckoo bird on top of it."}, "41572": {"image_id": 41572, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.11289809419085711, "Bleu_4": 1.3447816950952107e-05, "METEOR": 0.19299676017466366, "ROUGE_L": 0.2046979865771812, "CIDEr": 1.4449244823730529e-08, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.20689655172413793, "f": 0.28571428571428575, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is an image of a baseball player swinging a bat at a ball on a field. The player is wearing a baseball uniform and has a glove on his hand to catch the ball. There are trees in the background and a fence surrounding the field."}, "488720": {"image_id": 488720, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.22496063532707972, "Bleu_3": 0.13985578774299565, "Bleu_4": 0.09336513029742573, "METEOR": 0.26192155385870675, "ROUGE_L": 0.28651949271958665, "CIDEr": 2.3550402513149557e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person snowboarding down a mountain slope. The person is wearing a black and white snowboarding suit and has their hands on the board. The background is a mountain range with snow covered peaks and trees."}, "350675": {"image_id": 350675, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.1883108942847125, "Bleu_3": 9.169191011404368e-07, "Bleu_4": 2.034441173199727e-09, "METEOR": 0.24107984573522773, "ROUGE_L": 0.28018372703412076, "CIDEr": 7.243546120651544e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a person holding a kite in their hand, with the sun shining behind them. The sky is clear and blue, with fluffy white clouds floating in it. The person's hand is outstretched, as if they are about to launch the kite into the air."}, "350309": {"image_id": 350309, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.17807996398101744, "Bleu_3": 0.09105985252795226, "Bleu_4": 1.1649284258883924e-05, "METEOR": 0.2475154780749932, "ROUGE_L": 0.2197406340057637, "CIDEr": 5.858201729137928e-08, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.23076923076923078, "f": 0.12631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 63.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.20689655172413793, "re": 0.5454545454545454, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}}, "caption": "This is an image of a bus parked in front of a building at night. The bus is yellow and has the words \"City Bus\" written on the side. There are other cars parked nearby, and the sky is dark with some stars visible."}, "98261": {"image_id": 98261, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.20159462811746034, "Bleu_3": 1.1460354422397831e-06, "Bleu_4": 2.758387014275457e-09, "METEOR": 0.18372903911600869, "ROUGE_L": 0.22488479262672809, "CIDEr": 0.0029342815453884184, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.09302325581395349, "f": 0.16, "fn": 39.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.06666666666666667, "f": 0.1111111111111111, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.17647058823529413, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows two birds perched on a metal rod. One bird is yellow and the other is brown. They are looking at each other with their beaks open."}, "314412": {"image_id": 314412, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.344350221559779, "Bleu_3": 0.2826704932237456, "Bleu_4": 0.2180019395504151, "METEOR": 0.226355922682909, "ROUGE_L": 0.379746835443038, "CIDEr": 0.11439474716531284, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.23076923076923078, "f": 0.21818181818181817, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This image shows a plate of food with grilled meat, vegetables, and sauce. There are also two forks and knives on the plate."}, "481654": {"image_id": 481654, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.4082482904448645, "Bleu_3": 0.32182979485319485, "Bleu_4": 0.20465920654852296, "METEOR": 0.3131974483818995, "ROUGE_L": 0.43675417661097854, "CIDEr": 0.10539259132914491, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person kite surfing in the ocean with a clear blue sky and a small island in the background."}, "355956": {"image_id": 355956, "Bleu_1": 0.42857142856122454, "Bleu_2": 0.32331040304899006, "Bleu_3": 0.2186484750093861, "Bleu_4": 0.1521602407165563, "METEOR": 0.2548334623546647, "ROUGE_L": 0.34359283846308586, "CIDEr": 0.0006894058133592141, "SPICE": {"All": {"pr": 0.15, "re": 0.11538461538461539, "f": 0.13043478260869565, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of children playing baseball on a dirt field. They are wearing baseball uniforms and helmets, and one child is holding a bat. In the background, there is a large building with a sign that reads \"Baseball Field\"."}, "411754": {"image_id": 411754, "Bleu_1": 0.43478260867674867, "Bleu_2": 0.2811607785452645, "Bleu_3": 1.5555956733899503e-06, "Bleu_4": 3.7039494075864308e-09, "METEOR": 0.25987206226184345, "ROUGE_L": 0.339265850945495, "CIDEr": 0.0657590137784385, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a man sitting at a table in a room with other people. He is using a cell phone to text someone."}, "360767": {"image_id": 360767, "Bleu_1": 0.6428571428112246, "Bleu_2": 0.44474958996367114, "Bleu_3": 0.3670487142632694, "Bleu_4": 0.30793007513209525, "METEOR": 0.2512898544052963, "ROUGE_L": 0.4680306905370844, "CIDEr": 0.5361417329922078, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.17857142857142858, "f": 0.21739130434782608, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A group of people riding bicycles along a canal with boats in the background."}, "477673": {"image_id": 477673, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.10497813183144382, "Bleu_3": 6.123299201527432e-07, "Bleu_4": 1.4866702340294172e-09, "METEOR": 0.19495593798275757, "ROUGE_L": 0.19488817891373802, "CIDEr": 1.8173656529213037e-10, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.17857142857142858, "f": 0.24390243902439027, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a small kitten sitting inside a backpack. The kitten is looking up at the camera with its big eyes and pink nose. The backpack has a zipper open, revealing the kitten inside. The floor is made of wood and there are some toys scattered around the room."}, "484069": {"image_id": 484069, "Bleu_1": 0.5384615383786985, "Bleu_2": 0.36689969279504947, "Bleu_3": 0.23044502514829485, "Bleu_4": 3.326024950007662e-05, "METEOR": 0.2762426961092967, "ROUGE_L": 0.5343065693430658, "CIDEr": 1.1579338562805204, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.35714285714285715, "f": 0.18867924528301885, "fn": 9.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23529411764705882, "re": 0.6666666666666666, "f": 0.3478260869565218, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "This is a bowl of creamy broccoli soup with croutons on the side."}, "88345": {"image_id": 88345, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.25806238489967687, "Bleu_3": 0.1993991835107677, "Bleu_4": 0.15519469839228586, "METEOR": 0.2699144042465427, "ROUGE_L": 0.2924657534246575, "CIDEr": 3.1723469041456064e-07, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13636363636363635, "f": 0.16666666666666663, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The woman in the image is smiling and standing in front of a bar. She is wearing a black and white dress with a white hat on her head. There are lights hanging from the ceiling and a clock on the wall behind her."}, "250258": {"image_id": 250258, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.23055616707626844, "Bleu_3": 0.1373830673570816, "Bleu_4": 1.595639977425073e-05, "METEOR": 0.25236716914756196, "ROUGE_L": 0.3476884103863205, "CIDEr": 1.6601180802881157e-06, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.30434782608695654, "f": 0.3333333333333333, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a baseball player standing on the field, looking out at the crowd. He is wearing a white jersey with the number 27 on the back and black pants. The crowd is seated in the stands behind him, watching the game."}, "545288": {"image_id": 545288, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.15475060698405138, "Bleu_3": 0.12338191667517893, "Bleu_4": 0.09310084703088833, "METEOR": 0.2021611128366572, "ROUGE_L": 0.18908865468071917, "CIDEr": 1.1121066261425924e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.3076923076923077, "f": 0.1951219512195122, "fn": 9.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.21428571428571427, "re": 0.6, "f": 0.3157894736842105, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a black and white ski suit and has a pair of skis on their feet. They are standing on the left side of the image, looking down the slope. There are trees and mountains in the background."}, "195594": {"image_id": 195594, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.18033392692914046, "Bleu_3": 0.11759123766324173, "Bleu_4": 0.08035540036756333, "METEOR": 0.1724413462099962, "ROUGE_L": 0.25957446808510637, "CIDEr": 1.9899232280327228e-07, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13636363636363635, "f": 0.11320754716981131, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a black and white image of a man standing next to a drain pipe. He is wearing a black shirt and jeans, and has his hands in his pockets. The background is a grassy field with trees in the distance."}, "271402": {"image_id": 271402, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.22447181760045806, "Bleu_3": 0.18316251491261745, "Bleu_4": 0.13239450175851494, "METEOR": 0.2928977297214259, "ROUGE_L": 0.39999999999999997, "CIDEr": 1.4370777084417232e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06060606060606061, "f": 0.08333333333333333, "fn": 31.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows two young girls standing on a tennis court, one holding a tennis racket and the other holding a skateboard. They are both wearing white tennis outfits with pink accents and sunglasses. The background is a blue sky with some clouds."}, "121572": {"image_id": 121572, "Bleu_1": 0.3623188405744591, "Bleu_2": 0.2731209538122106, "Bleu_3": 0.20728843613185208, "Bleu_4": 0.15242644479716833, "METEOR": 0.3184436032830806, "ROUGE_L": 0.3084702907711757, "CIDEr": 4.9546014883449396e-17, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.17647058823529413, "f": 0.17647058823529413, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a group of red double decker buses parked on the side of a city street. They are lined up in a row, with one bus in front of the other. The buses are old and have been painted red and white. There are people walking down the street, looking at the buses. The buildings on either side of the street are tall and made of brick."}, "398748": {"image_id": 398748, "Bleu_1": 0.8571428570816327, "Bleu_2": 0.7262730391486911, "Bleu_3": 0.5602211879040704, "Bleu_4": 0.42284283425196, "METEOR": 0.35510078446672155, "ROUGE_L": 0.7359249329758714, "CIDEr": 1.097651720436716, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.19230769230769232, "f": 0.21276595744680848, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A seagull stands on a beach with a body of water in the background."}, "50159": {"image_id": 50159, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.1543033499596618, "Bleu_3": 0.10483189222810438, "Bleu_4": 0.06592309822424215, "METEOR": 0.17866086060055814, "ROUGE_L": 0.2565420560747664, "CIDEr": 5.741110229439078e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 30.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.07142857142857142, "f": 0.08695652173913043, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A man and woman are skiing down a snowy mountain slope. They are both wearing ski gear, including skis, poles, and helmets. The woman is carrying a backpack on her back and the man is holding onto his ski pole with one hand while the other hand is on his hip. The sky is clear and blue, with a few clouds in the distance."}, "71850": {"image_id": 71850, "Bleu_1": 0.37999999999240003, "Bleu_2": 0.1525296893116513, "Bleu_3": 7.855174634741559e-07, "Bleu_4": 1.7920182118967283e-09, "METEOR": 0.24541269915517314, "ROUGE_L": 0.2852466682253917, "CIDEr": 3.5486672497894907e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a green traffic light hanging from a pole in the middle of a busy street. The light is surrounded by tall buildings on either side, with windows and balconies visible on the upper floors. The sky is clear and blue, with a few clouds scattered across it."}, "363321": {"image_id": 363321, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.10924838152488424, "Bleu_3": 0.05626673827527076, "Bleu_4": 7.207801557855388e-06, "METEOR": 0.19180480975959843, "ROUGE_L": 0.17862371888726206, "CIDEr": 4.379329001532452e-22, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.20689655172413793, "f": 0.3, "fn": 23.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3076923076923077, "f": 0.42105263157894735, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a group of children standing near a giraffe at a zoo. The children are looking at the giraffe and one of them is feeding it with a treat. The giraffe is standing on its hind legs and reaching up to eat from the child's hand. The children are all wearing hats and sunglasses, and the giraffe has a long neck and spots on its fur."}, "19102": {"image_id": 19102, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.3333333333212081, "Bleu_3": 0.23404631037963888, "Bleu_4": 0.15048435360920345, "METEOR": 0.22495154418477253, "ROUGE_L": 0.23828124999999997, "CIDEr": 0.014583057354678184, "SPICE": {"All": {"pr": 0.09375, "re": 0.1875, "f": 0.125, "fn": 13.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows two zebras standing in a field with trees in the background. They are both black and white striped, with their heads turned towards each other."}, "223764": {"image_id": 223764, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.24450482345050376, "Bleu_3": 1.3954600049383727e-06, "Bleu_4": 3.3727427827835617e-09, "METEOR": 0.23709628535636032, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.13079250672182902, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.17647058823529413, "f": 0.15, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The woman is standing in front of a mirror, holding a towel over her head. She appears to be applying makeup to her face."}, "115118": {"image_id": 115118, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.4522670168272435, "Bleu_3": 0.2734827537714344, "Bleu_4": 3.8827267771481786e-05, "METEOR": 0.2772935206174219, "ROUGE_L": 0.43821839080459773, "CIDEr": 0.9611382938220997, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A train traveling on a railroad track with several cars carrying cargo."}, "546222": {"image_id": 546222, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.25543596558620163, "ROUGE_L": 0.3057644110275689, "CIDEr": 3.673381396414455e-09, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.125, "f": 0.05555555555555556, "fn": 14.0, "numImages": 1.0, "fp": 54.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 23.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.09523809523809523, "re": 0.2857142857142857, "f": 0.14285714285714285, "fn": 5.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}}, "caption": "This is a man standing next to a horse in a field. The man has a beard and is wearing a green hat and sunglasses. The horse is brown and has a white blaze on its forehead. There are trees and fences in the background of the image."}, "167122": {"image_id": 167122, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.276533159369469, "Bleu_3": 0.19085369914763303, "Bleu_4": 0.12140538257408166, "METEOR": 0.25343722557241616, "ROUGE_L": 0.32670237184391737, "CIDEr": 0.0010772418185241947, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a car parked in front of a building at night. The car's headlights are on, illuminating the area around it. There are no people or other vehicles visible in the image."}, "542605": {"image_id": 542605, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.21821789022984422, "Bleu_3": 0.16136438271820902, "Bleu_4": 0.12632368169568278, "METEOR": 0.272954092584186, "ROUGE_L": 0.3276550030693677, "CIDEr": 0.00014680892273088888, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2777777777777778, "f": 0.2777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\nA group of people on motorcycles ride down a street lined with shops and restaurants. The sun is shining and there are palm trees in the background."}, "356733": {"image_id": 356733, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.1730297489554192, "Bleu_4": 0.12387535527350019, "METEOR": 0.23439280977795712, "ROUGE_L": 0.2749517063747585, "CIDEr": 1.4592313324027729e-08, "SPICE": {"All": {"pr": 0.5, "re": 0.09523809523809523, "f": 0.16, "fn": 19.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}}, "caption": "The image shows a group of teddy bears sitting on top of a couch. They are all wearing blue shirts and jeans, and they appear to be looking at something on the floor. There is a brown couch in the background with a white pillow on it."}, "279846": {"image_id": 279846, "Bleu_1": 0.382352941165225, "Bleu_2": 0.2636640221444497, "Bleu_3": 1.295141607895443e-06, "Bleu_4": 2.8933269905362777e-09, "METEOR": 0.20422383259147917, "ROUGE_L": 0.25206611570247933, "CIDEr": 0.0007769148631229241, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.23076923076923078, "f": 0.3428571428571429, "fn": 20.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "This is an image of a plate with a pizza on it. The pizza has cheese, bacon, and eggs on it. There are two glasses of wine on the table next to the plate."}, "326368": {"image_id": 326368, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.11651034560483009, "Bleu_3": 6.475197095245912e-07, "Bleu_4": 1.5342308957715506e-09, "METEOR": 0.18566043669100582, "ROUGE_L": 0.25176886792452824, "CIDEr": 4.482275269825812e-11, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16129032258064516, "f": 0.1923076923076923, "fn": 26.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man wearing a leather jacket and sunglasses sits on the back of a Harley Davidson motorcycle next to another man wearing a black shirt and jeans. They are parked in front of a body of water with a beach in the background.\""}, "577868": {"image_id": 577868, "Bleu_1": 0.4137931034340072, "Bleu_2": 0.29777500018082764, "Bleu_3": 0.21437689969939125, "Bleu_4": 2.4810764838854463e-05, "METEOR": 0.29363190559340685, "ROUGE_L": 0.3613030602171767, "CIDEr": 0.0036387242731708838, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.2, "f": 0.17647058823529413, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a plate with two halves of an orange on it. The orange slices are cut in half and have a red juice stain on the plate."}, "558107": {"image_id": 558107, "Bleu_1": 0.6874999999570314, "Bleu_2": 0.5664215155622997, "Bleu_3": 0.45088987146905807, "Bleu_4": 0.3446073376795577, "METEOR": 0.46347040922039384, "ROUGE_L": 0.48157894736842105, "CIDEr": 1.5968620957543083, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15789473684210525, "f": 0.18181818181818182, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a red fire hydrant with a leopard print hat on top of it."}, "378311": {"image_id": 378311, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.15430334995774453, "Bleu_3": 0.08880224204971929, "Bleu_4": 1.2069505116085885e-05, "METEOR": 0.19449785209417092, "ROUGE_L": 0.2420634920634921, "CIDEr": 6.628961908687667e-05, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.13043478260869565, "f": 0.16216216216216214, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a kitchen with several ovens and stoves lined up against the walls. There are also several tables and chairs in the room, as well as some utensils and other cooking supplies on the countertops."}, "578168": {"image_id": 578168, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.14104731216518007, "Bleu_4": 1.5891337151933627e-05, "METEOR": 0.2384242810345431, "ROUGE_L": 0.24416277518345564, "CIDEr": 6.656939689308251e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.125, "f": 0.14814814814814814, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a train car with blue seats and a white ceiling. There are no people in the car, but there are some luggage racks on the walls. The windows are open and there is a view of the outside from the train car."}, "81552": {"image_id": 81552, "Bleu_1": 0.5366925751109899, "Bleu_2": 0.42374134735831365, "Bleu_3": 0.2546850737490361, "Bleu_4": 3.6049080423356166e-05, "METEOR": 0.36213454969157133, "ROUGE_L": 0.6224489795918368, "CIDEr": 1.5245293623254907, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.46153846153846156, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.3076923076923077, "re": 0.8, "f": 0.4444444444444444, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a cat sleeping on top of a red couch."}, "51576": {"image_id": 51576, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.12399138853119372, "Bleu_3": 0.06661825222088168, "Bleu_4": 8.725742282618853e-06, "METEOR": 0.16071255770532275, "ROUGE_L": 0.1783625730994152, "CIDEr": 2.3092781665862837e-12, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.09090909090909091, "f": 0.1142857142857143, "fn": 20.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a herd of zebras grazing in a green field. They are standing in a line, with their heads down and their stripes visible. There is a small stream running through the field, and some trees can be seen in the background. The sky is cloudy and there is a light drizzle."}, "270571": {"image_id": 270571, "Bleu_1": 0.6191984997331017, "Bleu_2": 0.4063986276844881, "Bleu_3": 0.3295597275093693, "Bleu_4": 0.2740623716911265, "METEOR": 0.3336538336190373, "ROUGE_L": 0.543026706231454, "CIDEr": 1.181317833360795, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.15789473684210525, "f": 0.14285714285714288, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The woman is holding a knife and cutting up some food on the counter."}, "510559": {"image_id": 510559, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.18824832212957474, "Bleu_3": 0.09525609865690522, "Bleu_4": 1.212424196299872e-05, "METEOR": 0.20941794150224652, "ROUGE_L": 0.28561872909699, "CIDEr": 1.2858098978944582e-06, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.2, "f": 0.16326530612244897, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a woman surfing on a wave in the ocean. She is wearing a pink wetsuit and has her arms outstretched as she rides the wave. The sky is cloudy and there are waves crashing against the shore in the background."}, "529065": {"image_id": 529065, "Bleu_1": 0.23076923076331368, "Bleu_2": 0.13497638119624783, "Bleu_3": 7.896560106821803e-07, "Bleu_4": 1.923104277732444e-09, "METEOR": 0.21952403715545898, "ROUGE_L": 0.28175519630484985, "CIDEr": 1.3762594279873958e-06, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This image shows a person skateboarding on a ramp in a dark room. The person is wearing a black hoodie and jeans, and has a skateboard under their foot. There are graffiti tags on the walls of the room."}, "289659": {"image_id": 289659, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.18312996850378505, "Bleu_3": 0.13714874241676037, "Bleu_4": 0.1079457310875078, "METEOR": 0.18425768461980002, "ROUGE_L": 0.22021660649819497, "CIDEr": 1.3897642762178933e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe stands in a grassy field, looking at something on the ground. The giraffe has spots on its fur and long legs that allow it to reach high into the trees."}, "558585": {"image_id": 558585, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.5577733509080639, "Bleu_3": 0.33879878553311354, "Bleu_4": 4.854917716006407e-05, "METEOR": 0.2798823272502421, "ROUGE_L": 0.4535315985130111, "CIDEr": 0.6847789628059562, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.3181818181818182, "f": 0.3783783783783784, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.75, "f": 0.8571428571428571, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "A mother duck and her babies swimming in a pond."}, "463669": {"image_id": 463669, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.3708990934959662, "Bleu_3": 0.2979678450211434, "Bleu_4": 0.23736810438144632, "METEOR": 0.37748382366030664, "ROUGE_L": 0.49683257918552043, "CIDEr": 0.04012555134148338, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a black and white cat lying on its side on a blue blanket. The cat's eyes are closed and it appears to be sleeping."}, "116046": {"image_id": 116046, "Bleu_1": 0.16326530611911708, "Bleu_2": 0.1010152544531381, "Bleu_3": 0.06010242872773111, "Bleu_4": 8.288569027871298e-06, "METEOR": 0.14380959264701207, "ROUGE_L": 0.16126900198281557, "CIDEr": 1.2514824787044688e-11, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.18518518518518517, "f": 0.17241379310344826, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people standing in front of a whiteboard with diagrams and notes on it. They are all wearing casual clothing and looking at the board intently. There is a laptop on the table next to them, and a projector on the wall behind them."}, "533508": {"image_id": 533508, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.2433792297516304, "Bleu_3": 1.139818437491351e-06, "Bleu_4": 2.482336233740987e-09, "METEOR": 0.16378853741672517, "ROUGE_L": 0.3214756258234519, "CIDEr": 1.4509078672253614e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.14814814814814814, "f": 0.13559322033898305, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is a large, white church with a tall steeple and a spire on top. The building has a lot of windows and a large front door. There are trees and bushes in the foreground, and people are walking around the area."}, "89555": {"image_id": 89555, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.2051356979819005, "Bleu_3": 0.13034957774113842, "Bleu_4": 0.09430673592650911, "METEOR": 0.21969790452097993, "ROUGE_L": 0.23735408560311286, "CIDEr": 6.344774364564556e-15, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a cat lying on top of a bed, with its paws tucked under its body and its head resting on the pillow. The cat is wearing a pink collar with a tag that reads `Bella`. The bed is covered in a blue and white striped blanket, and there are flowers on the wall behind the bed."}, "472295": {"image_id": 472295, "Bleu_1": 0.206349206345931, "Bleu_2": 0.12900025204482843, "Bleu_3": 0.06485603995406472, "Bleu_4": 8.21154747443803e-06, "METEOR": 0.1799914668489922, "ROUGE_L": 0.15762273901808782, "CIDEr": 1.6037335104692757e-17, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.05, "f": 0.05714285714285715, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "This is a photograph of a person skiing down a snowy mountain slope. The person is wearing a red jacket and blue pants, and they are holding a ski pole in their right hand. The snow is deep and powdery, and there are trees on either side of the slope. The sky is cloudy and there are some clouds visible in the background."}, "27221": {"image_id": 27221, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.11644450194595923, "Bleu_3": 0.061603207790807316, "Bleu_4": 8.0026492316705e-06, "METEOR": 0.1629440242985993, "ROUGE_L": 0.19303797468354428, "CIDEr": 3.247304110513796e-14, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.15384615384615385, "f": 0.2285714285714286, "fn": 22.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The woman is sitting on the steps of a building, looking at her phone. She is wearing a black sweater and black pants, and has her hair pulled back in a ponytail. The building behind her has a large window with white shutters and a red door. There are flowers and plants in pots on either side of the steps."}, "435185": {"image_id": 435185, "Bleu_1": 0.340909090901343, "Bleu_2": 0.23557764908855597, "Bleu_3": 0.1097335995735907, "Bleu_4": 1.3398579422657672e-05, "METEOR": 0.22793971224516063, "ROUGE_L": 0.2787206266318538, "CIDEr": 4.573878357207538e-07, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a green glass vase with a red rose in it. The vase has a square shape and is made of clear glass. There are also some other items on the table, such as a small bowl and a plate."}, "393805": {"image_id": 393805, "Bleu_1": 0.7430381995735735, "Bleu_2": 0.7326455450859374, "Bleu_3": 0.6535803740836913, "Bleu_4": 0.4959623816571399, "METEOR": 0.27464711463596864, "ROUGE_L": 0.5700934579439253, "CIDEr": 1.6857686772352376, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.35714285714285715, "f": 0.23255813953488377, "fn": 9.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "Two zebras are fighting in the grass."}, "535151": {"image_id": 535151, "Bleu_1": 0.6666666665555557, "Bleu_2": 0.4264014326385389, "Bleu_3": 2.629535893869793e-06, "Bleu_4": 6.704226836958771e-09, "METEOR": 0.20932842997714965, "ROUGE_L": 0.39713541666666663, "CIDEr": 0.257178321925304, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A wooden cutting board with a knife and various vegetables on it."}, "13490": {"image_id": 13490, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2829297811792259, "Bleu_3": 0.1436584537779676, "Bleu_4": 1.8376172280225525e-05, "METEOR": 0.29212093550760754, "ROUGE_L": 0.3871260199456029, "CIDEr": 0.010257850833952437, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.3333333333333333, "f": 0.2978723404255319, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a slice of green bread on a cutting board with a knife next to it. There is also a jar of peanut butter on the table."}, "504091": {"image_id": 504091, "Bleu_1": 0.2786885245855953, "Bleu_2": 0.22603737782316946, "Bleu_3": 0.15130600583081896, "Bleu_4": 0.10454243843462924, "METEOR": 0.26298387706097115, "ROUGE_L": 0.2912466843501326, "CIDEr": 5.569065392408029e-15, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.08695652173913043, "f": 0.061538461538461535, "fn": 21.0, "numImages": 1.0, "fp": 40.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2222222222222222, "f": 0.14814814814814814, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}}, "caption": "The image shows a man in an orange shirt holding a tennis racket and preparing to hit a ball on a tennis court. There are several other people playing tennis in the background, including one woman in a black dress and another man in a white shirt. The image is taken from above, looking down at the players on the court."}, "555696": {"image_id": 555696, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1923483450237976, "Bleu_3": 0.12077745418377696, "Bleu_4": 1.4397710576737565e-05, "METEOR": 0.20698158445295603, "ROUGE_L": 0.2840606705694519, "CIDEr": 2.6186587118708677e-07, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.13793103448275862, "f": 0.16, "fn": 25.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a soccer game in progress. There are several players on the field, including one who is kicking the ball and another who is trying to block it. The crowd is cheering and there are people on the sidelines watching the game."}, "183437": {"image_id": 183437, "Bleu_1": 0.3103448275755054, "Bleu_2": 0.1823492021500491, "Bleu_3": 0.10718844984969567, "Bleu_4": 1.4752569037512536e-05, "METEOR": 0.20183818411794185, "ROUGE_L": 0.3373271889400921, "CIDEr": 0.004998912733909688, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.19047619047619047, "f": 0.16666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people riding on the back of an elephant. The elephant is walking down a dirt road with trees and buildings in the background."}, "393743": {"image_id": 393743, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.2602575457946004, "Bleu_3": 0.17119495568587, "Bleu_4": 2.095920888284441e-05, "METEOR": 0.2687766993042245, "ROUGE_L": 0.3489037178265014, "CIDEr": 0.010501522358025496, "SPICE": {"All": {"pr": 0.2, "re": 0.13157894736842105, "f": 0.1587301587301587, "fn": 33.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.1875, "f": 0.23076923076923075, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A young girl in a soccer uniform stands on the field, holding a soccer ball. She is surrounded by other children playing soccer. The sky is clear and sunny."}, "441873": {"image_id": 441873, "Bleu_1": 0.32758620689090373, "Bleu_2": 0.21442250696382964, "Bleu_3": 0.13504898427369, "Bleu_4": 1.454714672496805e-05, "METEOR": 0.28874505329774464, "ROUGE_L": 0.2406989853438557, "CIDEr": 4.423227014125163e-14, "SPICE": {"All": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A young boy is holding a kite and flying it in the sky. The kite has a red and white striped tail and a blue body with a yellow wing. The boy is wearing a black shirt and shorts, and his hair is messy. In the background, there are trees and a path leading down to the ocean."}, "454810": {"image_id": 454810, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.11624763874063387, "Bleu_3": 7.28171055578613e-07, "Bleu_4": 1.8357153088490472e-09, "METEOR": 0.19718572987060753, "ROUGE_L": 0.2514427040395713, "CIDEr": 5.6664826015932786e-06, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is a kitchen with a sink, stove, and refrigerator. There are several utensils on the counter, including a kettle, toaster, and blender. The floor is made of hardwood and there are two windows in the background."}, "173598": {"image_id": 173598, "Bleu_1": 0.30645161289828304, "Bleu_2": 0.22413828170744018, "Bleu_3": 0.16116977889894885, "Bleu_4": 0.10914584402060475, "METEOR": 0.28794039068470423, "ROUGE_L": 0.24621594349142278, "CIDEr": 1.1359433507560593e-15, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.21428571428571427, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress on a large field with a crowd of people watching from the stands. There are several players on the field, including one pitcher throwing a ball to a batter at the plate. The batter is swinging his bat and preparing to hit the ball. The crowd is cheering and waving their arms in excitement."}, "262274": {"image_id": 262274, "Bleu_1": 0.12592592592499316, "Bleu_2": 0.08110622670891561, "Bleu_3": 0.03670728393857287, "Bleu_4": 4.399676102769125e-06, "METEOR": 0.12985431469874165, "ROUGE_L": 0.11251646903820815, "CIDEr": 1.0157577718812061e-91, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.06896551724137931, "f": 0.10526315789473684, "fn": 27.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a lifeguard stand on the beach with people walking on the sand. The sky is clear and blue, and there are palm trees in the background.\n\nThe lifeguard stand has a sign that reads \"Lifeguard Station\" in white letters on a blue background. The stand is made of wood and has a red and yellow flag on top. There are two chairs on the stand, one with a person sitting in it.\n\nPeople are walking along the beach, some of them carrying surfboards or boogie boards. They are all wearing swimsuits and sunglasses. The water is calm and clear, with waves gently lapping at the shore.\n\nThe overall mood of the image is peaceful and serene, with the lifeguard stand providing a sense of safety and security for those enjoying the beach."}, "451284": {"image_id": 451284, "Bleu_1": 0.3199999999936, "Bleu_2": 0.19794866371815806, "Bleu_3": 0.0934590374320519, "Bleu_4": 1.1479990094513042e-05, "METEOR": 0.19375945038159953, "ROUGE_L": 0.21759809750297268, "CIDEr": 3.216366431792784e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "A laptop is sitting on a bed with a cup of coffee next to it. There are also some books and papers on the bed.\n\nThe image is in black and white, with the laptop and coffee cup being the only objects in focus. The background is blurry and indistinct."}, "254750": {"image_id": 254750, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2736170867397671, "Bleu_3": 0.2107328047161774, "Bleu_4": 0.17347584065870694, "METEOR": 0.30424819237090794, "ROUGE_L": 0.38065522620904835, "CIDEr": 0.0009707898633473686, "SPICE": {"All": {"pr": 0.16, "re": 0.23529411764705882, "f": 0.19047619047619052, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are white and the floor is tiled. There is a window on one side of the room that lets in natural light."}, "321557": {"image_id": 321557, "Bleu_1": 0.1846153846125444, "Bleu_2": 0.1611258466563742, "Bleu_3": 0.12724868214300986, "Bleu_4": 0.09992458683622235, "METEOR": 0.22449504351979147, "ROUGE_L": 0.1913225300575013, "CIDEr": 1.100390592382661e-19, "SPICE": {"All": {"pr": 0.2, "re": 0.23809523809523808, "f": 0.21739130434782608, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a black motorcycle parked on the side of a building. The bike has a sleek design and is parked next to a window with a view of the street outside. The tires are black and the wheels are shiny. The bike's body is made of metal and has a smooth finish. There are no other vehicles or people in the image."}, "489920": {"image_id": 489920, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.24099009324731976, "Bleu_3": 0.21807377964420252, "Bleu_4": 0.19060593779262325, "METEOR": 0.3125590866908159, "ROUGE_L": 0.32412327311370887, "CIDEr": 8.945070757395832e-14, "SPICE": {"All": {"pr": 0.28, "re": 0.2413793103448276, "f": 0.25925925925925924, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.09090909090909091, "f": 0.10526315789473685, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a black and white photograph of a bench sitting in front of a brick wall. The bench is made of wood and has a smooth, flat surface. The wall behind the bench is made of bricks and has a pattern of squares and rectangles on it. There are no other objects or people in the image."}, "197398": {"image_id": 197398, "Bleu_1": 0.5599999999776001, "Bleu_2": 0.4041451884162355, "Bleu_3": 0.27721884387109635, "Bleu_4": 3.136977406466682e-05, "METEOR": 0.3368644769054085, "ROUGE_L": 0.37821080602302926, "CIDEr": 0.2830396547679437, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a sandwich on a plate with lettuce, tomato, and cheese. There is also a beer bottle on the table next to it."}, "301981": {"image_id": 301981, "Bleu_1": 0.34782608694139894, "Bleu_2": 0.2177862025825042, "Bleu_3": 1.3120402049391552e-06, "Bleu_4": 3.2598893461057542e-09, "METEOR": 0.3334674999023782, "ROUGE_L": 0.407119021134594, "CIDEr": 0.047174940197664814, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23076923076923078, "f": 0.25531914893617025, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe stands in a enclosure at a zoo, looking out at the visitors."}, "5486": {"image_id": 5486, "Bleu_1": 0.18181818181404963, "Bleu_2": 0.06502560887474053, "Bleu_3": 4.65200159363572e-07, "Bleu_4": 1.251797059186196e-09, "METEOR": 0.20089028373424653, "ROUGE_L": 0.17134831460674158, "CIDEr": 2.8983314346803535e-08, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.3157894736842105, "f": 0.39999999999999997, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a living room with a wooden table and chairs, a couch, and a bookshelf. There are also two windows on the wall with curtains. The walls are painted a light yellow color and there is a large chandelier hanging from the ceiling."}, "548485": {"image_id": 548485, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.18625278992847225, "Bleu_3": 0.11552456765769871, "Bleu_4": 0.07693830154425157, "METEOR": 0.2622511587999816, "ROUGE_L": 0.31302116741500957, "CIDEr": 4.5147185304055126e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.17391304347826086, "f": 0.16326530612244897, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a bathroom with a white tiled floor, beige walls, and a white bathtub. There is a toilet in the corner of the room and a sink on the counter next to it. The shower curtain is open and there are towels hanging on the rack."}, "400596": {"image_id": 400596, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.28917761562015887, "Bleu_3": 0.18441526604132946, "Bleu_4": 0.1126111776817302, "METEOR": 0.28921302734397786, "ROUGE_L": 0.308080808080808, "CIDEr": 9.232590723829387e-06, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.21052631578947367, "f": 0.3076923076923077, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a bathroom with a green countertop and white cabinets. There is a sink in the corner of the room and a toilet in the opposite corner. The floor is made of hardwood and there are two windows on the wall."}, "227730": {"image_id": 227730, "Bleu_1": 0.16981132075151303, "Bleu_2": 0.12778110819056318, "Bleu_3": 0.08619148700244574, "Bleu_4": 1.0637896949215623e-05, "METEOR": 0.2218034914863203, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.8624102652875866e-12, "SPICE": {"All": {"pr": 0.05, "re": 0.034482758620689655, "f": 0.04081632653061224, "fn": 28.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a cat lying in a bowl of water. The cat is laying on its side with its paws tucked under its body and its head resting on the edge of the bowl. The bowl is filled with water and there are some papers and other objects on top of it."}, "553998": {"image_id": 553998, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.20498001541675429, "Bleu_3": 0.10838512954087406, "Bleu_4": 1.4123416971967373e-05, "METEOR": 0.2228343640032375, "ROUGE_L": 0.28003060443764344, "CIDEr": 0.00011260508399105525, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A truck is parked in front of a tree with branches hanging down from it. The truck has a large pile of logs on its bed.\""}, "306173": {"image_id": 306173, "Bleu_1": 0.135135135133309, "Bleu_2": 0.09620723035919662, "Bleu_3": 0.050469342008533695, "Bleu_4": 6.523131669149745e-06, "METEOR": 0.2198796856928165, "ROUGE_L": 0.1741198858230257, "CIDEr": 6.253512046117765e-27, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a small kitten sleeping on top of a pile of papers on a desk. The kitten is curled up and has its eyes closed, looking very content. There are several pens and pencils scattered around the desk, as well as a small notebook and a pen lying next to the kitten. The background is a light brown color with a few shadows from the furniture and other objects in the room."}, "418281": {"image_id": 418281, "Bleu_1": 0.6470588234913496, "Bleu_2": 0.4021998332455238, "Bleu_3": 0.3186431519309258, "Bleu_4": 0.26073776109151653, "METEOR": 0.30717337063339945, "ROUGE_L": 0.5133239831697054, "CIDEr": 0.24910787053050798, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.21428571428571427, "f": 0.26666666666666666, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a cow standing in a field with trees and a pagoda in the background."}, "348654": {"image_id": 348654, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.2506402059074552, "Bleu_3": 0.11824223412532588, "Bleu_4": 1.4538815963237528e-05, "METEOR": 0.24668063496717405, "ROUGE_L": 0.34078212290502796, "CIDEr": 3.956918066973815e-06, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.10526315789473684, "f": 0.10810810810810811, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A black and white image of a desk with a phone on it. The phone is charging and there are cables connected to it. There is also a laptop on the desk, with a mouse and keyboard next to it."}, "577821": {"image_id": 577821, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.12483755678422238, "Bleu_3": 0.06608439529502602, "Bleu_4": 8.590238521223447e-06, "METEOR": 0.23054945979961408, "ROUGE_L": 0.21229698375870068, "CIDEr": 6.72541385979904e-14, "SPICE": {"All": {"pr": 0.375, "re": 0.11538461538461539, "f": 0.1764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is a clock tower in the middle of a city. The clock has Roman numerals and hands, and there are two bells on either side of it. The building behind the clock is made of brick and has windows on the upper floors. There are people walking on the street in front of the clock."}, "509819": {"image_id": 509819, "Bleu_1": 0.6874999999570314, "Bleu_2": 0.42817441926118477, "Bleu_3": 0.23570626875117834, "Bleu_4": 3.168053533620014e-05, "METEOR": 0.29110719356849013, "ROUGE_L": 0.4013157894736842, "CIDEr": 0.9947342286127727, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2777777777777778, "f": 0.2380952380952381, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5714285714285714, "f": 0.4210526315789474, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This image shows a table with various sewing tools, including scissors, a ruler, and a pencil."}, "356937": {"image_id": 356937, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.09829463743443755, "Bleu_3": 6.033032403124956e-07, "Bleu_4": 1.5032618275449672e-09, "METEOR": 0.19234116484531483, "ROUGE_L": 0.16968011126564672, "CIDEr": 1.6657623316978598e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.12, "f": 0.15384615384615383, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is an image of a person skiing down a snowy road. The person is wearing a blue jacket and pants, and has a pair of skis on their feet. There are trees on either side of the road, and the sky is clear and blue."}, "145215": {"image_id": 145215, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.17871654962201275, "Bleu_3": 0.0927733381723083, "Bleu_4": 1.1961929431463712e-05, "METEOR": 0.2892763313595142, "ROUGE_L": 0.2663755458515284, "CIDEr": 2.8295014622670877e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.1724137931034483, "f": 0.2173913043478261, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person standing on the beach, looking out at the ocean. The waves are crashing against the shore and the person is holding a surfboard. The sky is cloudy and there is a sense of calmness in the atmosphere."}, "368367": {"image_id": 368367, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.18802535826836297, "Bleu_3": 0.1351124024482053, "Bleu_4": 0.10410380146216555, "METEOR": 0.27037905397490125, "ROUGE_L": 0.21048999309868874, "CIDEr": 6.463178021673498e-08, "SPICE": {"All": {"pr": 0.44, "re": 0.55, "f": 0.48888888888888893, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 11.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.6, "f": 0.6, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6153846153846154, "re": 0.7272727272727273, "f": 0.6666666666666667, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}}, "caption": "The woman is smiling and talking on her cell phone while sitting at a table outside. She is wearing a black tank top and shorts, and has long blonde hair. The background is a restaurant with a patio area and tables set up for dining."}, "190756": {"image_id": 190756, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.1265001431634541, "Bleu_4": 1.5293885404483757e-05, "METEOR": 0.2593925253983704, "ROUGE_L": 0.2764350453172206, "CIDEr": 1.8067040405507025e-06, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.23333333333333334, "f": 0.23728813559322037, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.5833333333333334, "f": 0.5599999999999999, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The image shows a person performing a stunt on a dirt bike in the air. The person is wearing a helmet and has their arms outstretched as they fly through the air. The sky is clear and blue behind them."}, "170849": {"image_id": 170849, "Bleu_1": 0.6153846153609468, "Bleu_2": 0.415099617313932, "Bleu_3": 0.24305681724053524, "Bleu_4": 2.8109226562566195e-05, "METEOR": 0.2803777739190147, "ROUGE_L": 0.45101663585951934, "CIDEr": 0.0457110589207959, "SPICE": {"All": {"pr": 0.09375, "re": 0.15, "f": 0.11538461538461538, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "A group of seagulls are flying over a beach with people walking on it. The sky is cloudy and there are palm trees in the background."}, "22842": {"image_id": 22842, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.24124895480980643, "Bleu_3": 0.13081348353639377, "Bleu_4": 1.729833809317658e-05, "METEOR": 0.24484124652371725, "ROUGE_L": 0.40283018867924525, "CIDEr": 0.005674466562910417, "SPICE": {"All": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This image shows a dish of broccoli and cheese casserole with a fork on the side. The dish is in a white container with a lid on top."}, "307166": {"image_id": 307166, "Bleu_1": 0.34999999998250003, "Bleu_2": 0.2350811729787503, "Bleu_3": 0.14534086178782885, "Bleu_4": 2.061477352044535e-05, "METEOR": 0.2072205963782802, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.06704940174147642, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.08333333333333333, "f": 0.07547169811320754, "fn": 22.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "This image shows a table with several pizzas on it. There are also some drinks and utensils on the table."}, "384401": {"image_id": 384401, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.3291402942887518, "Bleu_3": 0.16762730266737055, "Bleu_4": 2.1510618470053686e-05, "METEOR": 0.2085893720621509, "ROUGE_L": 0.38566912539515275, "CIDEr": 0.052147344251620285, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.2, "f": 0.16326530612244897, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a pizza in a pan on a stove. The crust is golden brown and the cheese is melted. There are no toppings visible."}, "127880": {"image_id": 127880, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.27797972456503717, "Bleu_3": 0.19299197865525713, "Bleu_4": 0.13601901339112243, "METEOR": 0.2527460328770112, "ROUGE_L": 0.2995702885205648, "CIDEr": 5.322261312663147e-07, "SPICE": {"All": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5714285714285714, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a young girl sitting on the floor holding a toy in her hand. She is wearing a pink shirt and has long blonde hair. The background of the image appears to be a bathroom with a sink and toilet in the foreground."}, "98839": {"image_id": 98839, "Bleu_1": 0.7499999999531252, "Bleu_2": 0.5916079782717537, "Bleu_3": 0.464158883330242, "Bleu_4": 0.3521856535578892, "METEOR": 0.3113869639249568, "ROUGE_L": 0.4212707182320442, "CIDEr": 0.815274541589375, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.09523809523809523, "f": 0.0851063829787234, "fn": 19.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The cat is sitting on the couch in front of the television, looking at the screen."}, "114684": {"image_id": 114684, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1642880193591135, "Bleu_3": 0.09001951896101365, "Bleu_4": 1.1931001236118978e-05, "METEOR": 0.19753368104745214, "ROUGE_L": 0.22101449275362312, "CIDEr": 1.7016283043865173e-06, "SPICE": {"All": {"pr": 0.2962962962962963, "re": 0.3333333333333333, "f": 0.3137254901960785, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.6363636363636364, "f": 0.5833333333333334, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "The woman is sitting on a bench in the park, eating a sandwich. She is wearing a pink jacket and has her hair tied back in a ponytail. There are trees and buildings in the background of the image."}, "107781": {"image_id": 107781, "Bleu_1": 0.23214285713871177, "Bleu_2": 0.14527180078437643, "Bleu_3": 0.09211555193837166, "Bleu_4": 0.0619698937576483, "METEOR": 0.2238675409250133, "ROUGE_L": 0.26124197002141325, "CIDEr": 1.694162763010202e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a tennis match in progress on a clay court. There are several people in the stands watching the game, and the players are wearing tennis shoes and playing with rackets. The court is covered in red clay, and there are lines marked on it to indicate where the players should hit the ball."}, "109370": {"image_id": 109370, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.22760466886504874, "Bleu_3": 0.13204641200979725, "Bleu_4": 1.5124526410231296e-05, "METEOR": 0.24728092174334207, "ROUGE_L": 0.33519406890536413, "CIDEr": 1.3586078355226194e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.10526315789473684, "f": 0.10256410256410256, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a man in white tennis attire holding a tennis racket and standing on a tennis court. He is wearing white shoes and has his right hand on the racket. The background is a green grassy field with a few spectators seated in the stands."}, "46252": {"image_id": 46252, "Bleu_1": 0.3442622950763236, "Bleu_2": 0.2512264995900594, "Bleu_3": 0.17488381920326385, "Bleu_4": 0.11653670172197608, "METEOR": 0.26152608478682804, "ROUGE_L": 0.27546412443552437, "CIDEr": 5.743930710869039e-14, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a baseball player in the batter's box, ready to swing at the ball that is being thrown by the pitcher. The catcher is standing behind home plate, ready to catch the ball if it is hit. The umpire is standing on the field, watching the game. There are several fans in the stands, cheering on the players."}, "523517": {"image_id": 523517, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.21072097723733796, "Bleu_3": 0.12543276863982702, "Bleu_4": 0.08183613068414188, "METEOR": 0.23616873495063018, "ROUGE_L": 0.24416277518345564, "CIDEr": 3.341406740574488e-07, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is an image of a baseball player swinging a bat at a ball on a baseball field. The player is wearing a red jersey and white pants, and the ball is flying through the air. There are two umpires standing behind home plate, watching the play."}, "293591": {"image_id": 293591, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 0.10598398329266914, "Bleu_4": 0.07094237342460057, "METEOR": 0.19532962420965141, "ROUGE_L": 0.27128335451080055, "CIDEr": 7.895584172311615e-11, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2, "f": 0.1951219512195122, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of zebras standing next to a large boulder in the middle of a rocky terrain. The zebras are grazing on the grass and seem to be enjoying their surroundings. In the background, there is a large tree with branches that stretch out towards the sky."}, "554340": {"image_id": 554340, "Bleu_1": 0.2051282051229455, "Bleu_2": 0.1469436716703117, "Bleu_3": 8.356671880332698e-07, "Bleu_4": 2.0065472339680166e-09, "METEOR": 0.12605541189798847, "ROUGE_L": 0.18277153558052436, "CIDEr": 1.8298530012385708e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.17391304347826086, "f": 0.24242424242424243, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of a piece of bread that has been dropped on the ground. The bread is lying on its side and appears to be stale. There are no other objects in the image, just the bread."}, "335827": {"image_id": 335827, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2014440620697061, "Bleu_3": 0.12263904310164322, "Bleu_4": 1.4391446615915733e-05, "METEOR": 0.16309909622998237, "ROUGE_L": 0.2367399741267788, "CIDEr": 4.717377086109459e-08, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.21428571428571427, "f": 0.1935483870967742, "fn": 22.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a photograph of a church with a tall steeple and stained glass windows. The building is made of stone and has a red door. There are several people standing outside the church, looking at something on the ground. The sky is clear and blue."}, "529348": {"image_id": 529348, "Bleu_1": 0.5833333332847223, "Bleu_2": 0.39886201757398354, "Bleu_3": 0.25150606040109846, "Bleu_4": 3.6462858615851904e-05, "METEOR": 0.2625515114816112, "ROUGE_L": 0.5187074829931972, "CIDEr": 1.2485178733179227, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.16666666666666666, "f": 0.17142857142857143, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Two zebras are standing under a green umbrella in a grassy area."}, "414529": {"image_id": 414529, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.20314980006762443, "Bleu_3": 1.066722102597253e-06, "Bleu_4": 2.462691352392326e-09, "METEOR": 0.28843794179287413, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.000646490918253397, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.25, "f": 0.3125, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and black shorts, and has a racket in his hand. The court is green and there are lines on it."}, "446881": {"image_id": 446881, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.29514066804336486, "Bleu_3": 0.22164403183852815, "Bleu_4": 0.17012032085747555, "METEOR": 0.3467667390616062, "ROUGE_L": 0.37044534412955465, "CIDEr": 5.196058167740995e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.18181818181818182, "f": 0.2285714285714286, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee table, and television. There are two chairs in front of the television and a rug on the floor. The walls are painted white and there are windows on one side of the room."}, "33835": {"image_id": 33835, "Bleu_1": 0.3214285714170919, "Bleu_2": 0.10910894511402736, "Bleu_3": 7.707540024261883e-07, "Bleu_4": 2.0687206009477373e-09, "METEOR": 0.24198159543510517, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.0027867566563021836, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1, "f": 0.14634146341463417, "fn": 27.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people are gathered around a computer, playing video games. They are all smiling and having fun.\""}, "259452": {"image_id": 259452, "Bleu_1": 0.49999999998076927, "Bleu_2": 0.34641016150018555, "Bleu_3": 0.24662120742317167, "Bleu_4": 0.15980518114464692, "METEOR": 0.30424385489337463, "ROUGE_L": 0.36237623762376237, "CIDEr": 0.08342520888881214, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.17647058823529413, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a city skyline with tall buildings and cars driving on the road. The sky is cloudy and there are trees in the foreground."}, "76648": {"image_id": 76648, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.10241831129827411, "Bleu_3": 5.47257534072173e-07, "Bleu_4": 1.270014485739853e-09, "METEOR": 0.17976671332327976, "ROUGE_L": 0.21631205673758866, "CIDEr": 4.679408776070225e-19, "SPICE": {"All": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.5555555555555556, "f": 0.6666666666666667, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows a street sign with the words \"stop\" written on it in white letters. The sign is mounted on a green and white pole next to a bike lane. There are several bicycles parked along the side of the road, and a few pedestrians can be seen walking in the area. The sky is clear and blue, with some clouds visible in the distance."}, "251582": {"image_id": 251582, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.17131872291347974, "Bleu_3": 0.0826422446045352, "Bleu_4": 1.0256732621419825e-05, "METEOR": 0.25395408301583233, "ROUGE_L": 0.27949599083619703, "CIDEr": 2.60376586160128e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13043478260869565, "f": 0.14634146341463414, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a zebra standing next to its mother, who is nursing her baby. The zebra has a brown and white striped pattern on its body, and its mother has a similar pattern on her back. They are standing in front of a wooden fence, with trees and bushes visible in the background."}, "313182": {"image_id": 313182, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.42874646283026363, "Bleu_3": 0.2904780222281507, "Bleu_4": 3.637499566860159e-05, "METEOR": 0.2604115744362526, "ROUGE_L": 0.4860004552697473, "CIDEr": 0.6792436852208719, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a purple bus parked on the side of a street with people walking by."}, "479099": {"image_id": 479099, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.1188177051548479, "Bleu_3": 6.604735246466958e-07, "Bleu_4": 1.5652411276385143e-09, "METEOR": 0.16208240681863426, "ROUGE_L": 0.21441124780316342, "CIDEr": 3.854165532992819e-10, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2727272727272727, "f": 0.19672131147540986, "fn": 16.0, "numImages": 1.0, "fp": 33.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.5555555555555556, "f": 0.3703703703703704, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "This image shows a garden with a brick wall in the background and various plants and flowers in the foreground. The plants are arranged in different shapes and sizes, with some in pots and others growing directly from the ground. There is also a bench in the center of the garden."}, "88084": {"image_id": 88084, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.19711142525707728, "Bleu_3": 0.13733380275681295, "Bleu_4": 0.08759310373578474, "METEOR": 0.2732461935025022, "ROUGE_L": 0.30367143746110764, "CIDEr": 1.8467171870855217e-08, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.11764705882352941, "f": 0.11764705882352941, "fn": 30.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a red fire hydrant on the side of a city street. The hydrant has a white handle and is surrounded by green grass and yellow flowers. There are buildings in the background, including a tall building with windows and a red roof."}, "147577": {"image_id": 147577, "Bleu_1": 0.2833333333286111, "Bleu_2": 0.19600530374138794, "Bleu_3": 0.14905934861075484, "Bleu_4": 0.10382649644087732, "METEOR": 0.19933703681244047, "ROUGE_L": 0.2667916276163699, "CIDEr": 1.0393015359902033e-14, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.25, "f": 0.23809523809523808, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This image shows a mural on the side of a building depicting people walking through a train station. The mural is painted in bright colors and features people of different races and ages, as well as a train engine and cars. The mural appears to be part of a larger public art project, with other murals visible in the background."}, "6789": {"image_id": 6789, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2804086879058332, "Bleu_3": 0.13787553963788365, "Bleu_4": 1.7338675531051076e-05, "METEOR": 0.21716420371967463, "ROUGE_L": 0.24053627760252363, "CIDEr": 0.0013050217479931283, "SPICE": {"All": {"pr": 0.25, "re": 0.29411764705882354, "f": 0.27027027027027023, "fn": 12.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a street with several cars parked on the side of the road. There are power lines running along the side of the road and a building in the background."}, "408501": {"image_id": 408501, "Bleu_1": 0.6190476190181406, "Bleu_2": 0.4309458036646331, "Bleu_3": 0.3083691961453375, "Bleu_4": 0.23891455817181373, "METEOR": 0.31067945497387023, "ROUGE_L": 0.46362649294245384, "CIDEr": 0.20609319294851564, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.14705882352941177, "f": 0.1639344262295082, "fn": 29.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.4166666666666667, "f": 0.43478260869565216, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a yellow and blue train traveling down the tracks next to a building with windows and a roof."}, "379784": {"image_id": 379784, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.10861276726025744, "Bleu_3": 5.950104277147966e-07, "Bleu_4": 1.3989518286920131e-09, "METEOR": 0.18622174205554207, "ROUGE_L": 0.16850828729281767, "CIDEr": 9.317710486141371e-15, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.17857142857142858, "f": 0.15384615384615385, "fn": 23.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.4166666666666667, "f": 0.35714285714285715, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "This image shows a man skateboarding down a ramp made of graffiti covered concrete. The man is wearing a black shirt and blue jeans, and he is holding onto the handlebars of his skateboard with one hand while he rides it with the other. The sun is shining in the background, casting a warm glow over the scene."}, "209808": {"image_id": 209808, "Bleu_1": 0.382352941165225, "Bleu_2": 0.2152807725945954, "Bleu_3": 0.14254877887623868, "Bleu_4": 0.0983178114346302, "METEOR": 0.24698271515220457, "ROUGE_L": 0.25979557069846676, "CIDEr": 0.00012809935447760187, "SPICE": {"All": {"pr": 0.375, "re": 0.2222222222222222, "f": 0.27906976744186046, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.45454545454545453, "f": 0.5263157894736842, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "There are two plates on the table with a burger and fries on them. The burger has lettuce, tomato, cheese, and bacon on it. The fries are in a bowl next to the burger."}, "82696": {"image_id": 82696, "Bleu_1": 0.6842105262797785, "Bleu_2": 0.38993176788930844, "Bleu_3": 0.20757550605447114, "Bleu_4": 2.734337277990397e-05, "METEOR": 0.2691647408036729, "ROUGE_L": 0.511377245508982, "CIDEr": 0.48853626168493897, "SPICE": {"All": {"pr": 0.11904761904761904, "re": 0.35714285714285715, "f": 0.17857142857142858, "fn": 9.0, "numImages": 1.0, "fp": 37.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.25, "f": 0.125, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "A black and white bird stands on the floor in front of a group of chairs in a cafeteria."}, "531349": {"image_id": 531349, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.1659087424695837, "Bleu_3": 0.12527666086006603, "Bleu_4": 0.10176355452480418, "METEOR": 0.23827959675660737, "ROUGE_L": 0.26961325966850824, "CIDEr": 5.3912809310567014e-15, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.1111111111111111, "f": 0.12, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a red double decker bus parked on the side of a busy street in a city. The bus has a large sign on the front that reads \"Hong Kong\" and the back of the bus has a sign that reads \"City Bus\". There are people standing on the sidewalk next to the bus, looking at it."}, "285114": {"image_id": 285114, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.11722658350807154, "Bleu_3": 6.89076821568532e-07, "Bleu_4": 1.6807563750229034e-09, "METEOR": 0.20576918171222228, "ROUGE_L": 0.2506849315068493, "CIDEr": 4.479695807738568e-08, "SPICE": {"All": {"pr": 0.16, "re": 0.16, "f": 0.16, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a large airport terminal with several planes parked on the tarmac. The terminal has a large glass roof and is illuminated by bright lights at night. There are several people standing around the terminal, waiting to board their flights."}, "228771": {"image_id": 228771, "Bleu_1": 0.1948051948026649, "Bleu_2": 0.14319849852200991, "Bleu_3": 6.490406357856954e-07, "Bleu_4": 1.3864237402707252e-09, "METEOR": 0.20151481249250555, "ROUGE_L": 0.2102542007755278, "CIDEr": 2.094729838993305e-26, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.10526315789473684, "f": 0.08888888888888889, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a street sign with the words \"little italy college st\" written on it. The sign is attached to a pole and is located on a sidewalk in front of a building. The building appears to be made of brick and has a large window on the first floor. There are also several other signs on the street, including one that reads \"little italy college st\" in the same style as the one shown here."}, "147259": {"image_id": 147259, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.2909938476144488, "Bleu_3": 0.22433762449235847, "Bleu_4": 0.18486615215760333, "METEOR": 0.243071097703087, "ROUGE_L": 0.34659090909090906, "CIDEr": 0.003448001945796369, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.11538461538461539, "f": 0.11538461538461539, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a dog playing fetch with a frisbee in a park. The dog is jumping up and down to catch the frisbee, while people watch from the sidelines."}, "525899": {"image_id": 525899, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.1811857688307976, "Bleu_3": 0.09139586978860176, "Bleu_4": 1.1611347030414458e-05, "METEOR": 0.23414560511334892, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.27144348962863e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.29411764705882354, "f": 0.2631578947368421, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a black wetsuit and holding onto the surfboard with one hand while paddling with the other. The water is choppy and whitecapped, and the sky is cloudy and gray."}, "384788": {"image_id": 384788, "Bleu_1": 0.7999999999466668, "Bleu_2": 0.6324555319900065, "Bleu_3": 0.49742263460378094, "Bleu_4": 0.31823566219589394, "METEOR": 0.28401979904030167, "ROUGE_L": 0.4979591836734694, "CIDEr": 1.1224744684189103, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.11538461538461539, "f": 0.16216216216216214, "fn": 23.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "A cup of hot chocolate sits on a saucer next to a plate of cookies."}, "464265": {"image_id": 464265, "Bleu_1": 0.26027397259917434, "Bleu_2": 0.19940932562581873, "Bleu_3": 0.10385343338128018, "Bleu_4": 1.1247114957503192e-05, "METEOR": 0.19008617344174908, "ROUGE_L": 0.22229452723368257, "CIDEr": 1.3696180514745483e-22, "SPICE": {"All": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 15.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a woman standing in front of a display of fresh produce in a market. There are several baskets of fruits and vegetables on the counter, including apples, oranges, carrots, and lettuce. The woman is wearing a white shirt and black pants, and she appears to be looking at the produce with interest. The background of the image is a bright and colorful market filled with people shopping for their groceries."}, "399452": {"image_id": 399452, "Bleu_1": 0.7980538110608693, "Bleu_2": 0.6762057946055686, "Bleu_3": 0.5216010964217963, "Bleu_4": 0.3936932246084364, "METEOR": 0.2988185936409389, "ROUGE_L": 0.4680306905370844, "CIDEr": 1.3537113836948889, "SPICE": {"All": {"pr": 0.5, "re": 0.23809523809523808, "f": 0.3225806451612903, "fn": 16.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.8, "re": 0.4444444444444444, "f": 0.5714285714285714, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "A plate of food with a sandwich, fries, and a drink on the table."}, "540926": {"image_id": 540926, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.2383656473040621, "Bleu_3": 0.12237946382258257, "Bleu_4": 1.5721757596698785e-05, "METEOR": 0.21516651442447093, "ROUGE_L": 0.31853785900783294, "CIDEr": 0.0002505470987479296, "SPICE": {"All": {"pr": 0.2, "re": 0.22727272727272727, "f": 0.21276595744680854, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting at a table with laptops and papers in front of them. They are all wearing business attire and appear to be working on their laptops."}, "507187": {"image_id": 507187, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.20402970888419056, "Bleu_3": 0.12276317177256986, "Bleu_4": 1.4319831453628613e-05, "METEOR": 0.19238240586760136, "ROUGE_L": 0.23843648208469054, "CIDEr": 1.1238257856009322e-09, "SPICE": {"All": {"pr": 0.3125, "re": 0.21739130434782608, "f": 0.2564102564102564, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a group of people standing around a green motorcycle on the grass. There are several other cars and bikes parked nearby, and people are milling around, chatting and taking pictures. The sky is blue and cloudy, with some white clouds visible in the distance."}, "494320": {"image_id": 494320, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.16866980207552001, "Bleu_3": 9.245364897036987e-07, "Bleu_4": 2.1798470960469237e-09, "METEOR": 0.1617982716308728, "ROUGE_L": 0.19709208400646203, "CIDEr": 3.4581796618512503e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.17391304347826086, "f": 0.24242424242424243, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is an image of a train parked in a train station. The train is black and has a number of people standing on the platform next to it. There are also other trains parked in the background."}, "546203": {"image_id": 546203, "Bleu_1": 0.20547945205197976, "Bleu_2": 0.05342173039559917, "Bleu_3": 3.425514823810937e-07, "Bleu_4": 8.70502210822752e-10, "METEOR": 0.1549594808991506, "ROUGE_L": 0.13958810068649882, "CIDEr": 1.2216022347500856e-25, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on a ski slope, wearing various types of clothing and gear. One person is wearing a black jacket with a hood, while another is wearing a red jacket with a hood. Both are holding skis and poles. In the background, there are several other people standing on the slope, some of them wearing helmets and goggles. There are also several ski lifts in the background."}, "157862": {"image_id": 157862, "Bleu_1": 0.5599999999776001, "Bleu_2": 0.43204937987621544, "Bleu_3": 0.3651713767502249, "Bleu_4": 0.30674809497593747, "METEOR": 0.34987871410691684, "ROUGE_L": 0.4954314720812183, "CIDEr": 0.13040801831819776, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.041666666666666664, "f": 0.03846153846153846, "fn": 23.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The woman is sitting on the toilet, holding a bottle of water in her hand. She appears to be taking a drink from the bottle."}, "467966": {"image_id": 467966, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.11527712042367076, "Bleu_4": 1.436255531737259e-05, "METEOR": 0.22706985240999247, "ROUGE_L": 0.2741573033707865, "CIDEr": 4.702276990507187e-06, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.09523809523809523, "f": 0.10526315789473684, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "Sure, here is a short caption for the image:\n\nA small plane sits on the shore of a large body of water with mountains in the background. A group of birds sit on the shore next to the plane."}, "574856": {"image_id": 574856, "Bleu_1": 0.28767123287277163, "Bleu_2": 0.12641888766864096, "Bleu_3": 6.083056640180659e-07, "Bleu_4": 1.3391119486480954e-09, "METEOR": 0.15904161641579492, "ROUGE_L": 0.1922557406573615, "CIDEr": 1.3915703096531611e-24, "SPICE": {"All": {"pr": 0.12, "re": 0.15789473684210525, "f": 0.13636363636363635, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a train traveling along a railroad track through a rural landscape. The train is made up of two locomotives, one black and one red, pulling a series of passenger cars behind it. The train is moving at a slow pace, with smoke billowing from the chimneys of the locomotives. Trees and bushes line the tracks on either side, and a small body of water can be seen in the distance."}, "290957": {"image_id": 290957, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.20140768086634514, "Bleu_4": 0.12273866531520895, "METEOR": 0.280729396570842, "ROUGE_L": 0.3559445660102115, "CIDEr": 2.233203763595886e-05, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.2, "f": 0.2702702702702703, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.06666666666666667, "f": 0.09523809523809522, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a brown horse grazing in a green field. The horse is standing on its hind legs and has a white blaze on its forehead. There are trees in the background and a fence in the foreground."}, "456519": {"image_id": 456519, "Bleu_1": 0.823529411716263, "Bleu_2": 0.641688947880822, "Bleu_3": 0.38006914894428645, "Bleu_4": 4.4500506577976016e-05, "METEOR": 0.3196663544501816, "ROUGE_L": 0.5700934579439252, "CIDEr": 0.7119323304082608, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.09090909090909091, "f": 0.13793103448275862, "fn": 20.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a tennis player hitting a ball with his racket on a blue tennis court."}, "82933": {"image_id": 82933, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.13677530110522793, "Bleu_3": 0.09267924750141882, "Bleu_4": 0.06449817351321535, "METEOR": 0.17913693326044425, "ROUGE_L": 0.24190350297422336, "CIDEr": 8.669274670222879e-11, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13636363636363635, "f": 0.11999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a herd of cows grazing in a green meadow surrounded by mountains. The cows are brown and white with black spots on their coats. One cow is standing in the foreground, looking directly at the camera. The background is a beautiful mountain range with snow-capped peaks."}, "224037": {"image_id": 224037, "Bleu_1": 0.2278481012629386, "Bleu_2": 0.142996176603904, "Bleu_3": 0.08098340640348517, "Bleu_4": 0.05141544894960501, "METEOR": 0.17800504390457003, "ROUGE_L": 0.18476849848550414, "CIDEr": 6.47018276784621e-27, "SPICE": {"All": {"pr": 0.125, "re": 0.15, "f": 0.13636363636363635, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This image shows a small fishing boat docked at a pier in a coastal town. The boat is white with blue stripes and has a small cabin on the front. There are several people standing on the pier, including one man in a yellow shirt and hat who appears to be preparing to cast a line into the water. In the background, there are buildings and trees along the shore, as well as a mountain range in the distance."}, "523660": {"image_id": 523660, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.3038218101131809, "Bleu_3": 0.22596922817698423, "Bleu_4": 0.14965975077438498, "METEOR": 0.3070313668276877, "ROUGE_L": 0.35232961108971894, "CIDEr": 0.036901220435466155, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.05, "f": 0.060606060606060615, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The woman is standing in the kitchen, wearing a white apron and holding a spatula in her hand. She is smiling and looking at the camera."}, "26762": {"image_id": 26762, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.31506301888719, "Bleu_3": 0.18774477833405423, "Bleu_4": 2.6220676434485454e-05, "METEOR": 0.24530360196822068, "ROUGE_L": 0.4277699859747546, "CIDEr": 0.24756692318930634, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.08333333333333333, "f": 0.07843137254901962, "fn": 22.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows two elephants standing in a green field, one of them is suckling its young."}, "554934": {"image_id": 554934, "Bleu_1": 0.7619047618684808, "Bleu_2": 0.6761234037498121, "Bleu_3": 0.621965238045881, "Bleu_4": 0.5718458251064399, "METEOR": 0.4865339418630198, "ROUGE_L": 0.6623235613463625, "CIDEr": 0.7513755070716592, "SPICE": {"All": {"pr": 0.10256410256410256, "re": 0.13793103448275862, "f": 0.11764705882352941, "fn": 25.0, "numImages": 1.0, "fp": 35.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.25, "f": 0.21428571428571427, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and chairs. There are also two trees painted on the wall."}, "197278": {"image_id": 197278, "Bleu_1": 0.6999999999650001, "Bleu_2": 0.47016234595750056, "Bleu_3": 0.3945157956479679, "Bleu_4": 0.3466977830921938, "METEOR": 0.3845839002849535, "ROUGE_L": 0.5922330097087378, "CIDEr": 0.20088387247641953, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4, "f": 0.34782608695652173, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a toilet sitting in the middle of a field with trees and grass around it."}, "37119": {"image_id": 37119, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.32128773155046275, "Bleu_3": 0.24237254658051569, "Bleu_4": 0.1785790714879889, "METEOR": 0.27624479770828103, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.001200338783421337, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This image shows a group of cows standing in a barn. They are all wearing collars and are looking at the camera. The barn has a red roof and white walls."}, "105120": {"image_id": 105120, "Bleu_1": 0.1969696969667126, "Bleu_2": 0.07784989441496369, "Bleu_3": 4.55804589653711e-07, "Bleu_4": 1.1072581435674101e-09, "METEOR": 0.11606490578361674, "ROUGE_L": 0.11996066863323501, "CIDEr": 1.7211295840570707e-19, "SPICE": {"All": {"pr": 0.6363636363636364, "re": 0.2, "f": 0.30434782608695654, "fn": 28.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.0625, "f": 0.1, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.35714285714285715, "f": 0.5263157894736842, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "The image shows a cat and a mouse playing with each other on a bed. The cat is lying on its back, while the mouse is sitting on its hind legs, holding an orange in its paws. The cat is looking at the mouse with a curious expression on its face, while the mouse is looking at the cat with a playful expression on its face."}, "378962": {"image_id": 378962, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.08374629801422223, "Bleu_3": 4.973767271703134e-07, "Bleu_4": 1.2174947255951682e-09, "METEOR": 0.13688265145280334, "ROUGE_L": 0.1630144307856761, "CIDEr": 1.9429086770432437e-15, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.16666666666666666, "f": 0.17142857142857143, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThe image shows a bustling outdoor market with several vendors selling fresh produce, including fruits and vegetables. People are walking by, some carrying bags of groceries, while others are simply enjoying the sunny day. The atmosphere is lively and vibrant, with colorful awnings and umbrellas providing shade from the sun."}, "468902": {"image_id": 468902, "Bleu_1": 0.20289855072169713, "Bleu_2": 0.0946118737228843, "Bleu_3": 0.05112172440574543, "Bleu_4": 6.707615153183908e-06, "METEOR": 0.19081656539915517, "ROUGE_L": 0.17314788532500708, "CIDEr": 5.33502925394154e-19, "SPICE": {"All": {"pr": 0.5, "re": 0.16129032258064516, "f": 0.24390243902439024, "fn": 26.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.08333333333333333, "f": 0.125, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.2857142857142857, "f": 0.4210526315789473, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a brown and white cow lying on its side in the grass, with its head resting on its front legs. The cow is wearing a collar around its neck and has a tag on its ear. In the background, there is a small dog standing on its hind legs, looking at the cow. The dog is wearing a collar and tag on its ear as well."}, "342260": {"image_id": 342260, "Bleu_1": 0.2340425531865098, "Bleu_2": 0.10087498788996685, "Bleu_3": 6.092349727774223e-07, "Bleu_4": 1.5056549290355162e-09, "METEOR": 0.2142099267648894, "ROUGE_L": 0.19869706840390877, "CIDEr": 4.149824766529308e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.12, "f": 0.13636363636363635, "fn": 22.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a man skiing down a snowy hill. He is wearing a blue and white suit with a red hat and goggles on his face. There are other people skiing in the background, and a sign in the distance that reads \"Ski Race.\""}, "373170": {"image_id": 373170, "Bleu_1": 0.33333333331944454, "Bleu_2": 0.17025130614450176, "Bleu_3": 1.096274741670838e-06, "Bleu_4": 2.814392937738109e-09, "METEOR": 0.15417671839182662, "ROUGE_L": 0.2479674796747967, "CIDEr": 0.02704225968974898, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.2631578947368421, "f": 0.35714285714285715, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a classroom with green walls, green chairs, and a whiteboard on the wall. There are no students or teachers in the room."}, "521292": {"image_id": 521292, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1642880193591135, "Bleu_3": 0.09001951896101365, "Bleu_4": 1.1931001236118978e-05, "METEOR": 0.2023471210809452, "ROUGE_L": 0.22846441947565538, "CIDEr": 8.739285092822819e-06, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The woman is holding a cell phone to her ear and looking down at the ground. She has short red hair and is wearing a black shirt and jeans. The background is a blurred image of trees and sky."}, "30925": {"image_id": 30925, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.12830983841207666, "Bleu_3": 0.075015631511707, "Bleu_4": 1.0266394015672685e-05, "METEOR": 0.19960703653335726, "ROUGE_L": 0.25756509500351865, "CIDEr": 2.4784926797985707e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.10344827586206896, "f": 0.14634146341463414, "fn": 26.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in front of a pond with water lilies floating on the surface. The giraffe is looking down at its reflection in the water. The trees in the background are bare and the sky is clear."}, "335450": {"image_id": 335450, "Bleu_1": 0.714285714234694, "Bleu_2": 0.5741692517206252, "Bleu_3": 0.3017399903278499, "Bleu_4": 3.975360175943345e-05, "METEOR": 0.2493774070029477, "ROUGE_L": 0.42957746478873243, "CIDEr": 0.9740379432545726, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.1724137931034483, "f": 0.19999999999999998, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A brown horse standing in a green field with a fence in the background."}, "303944": {"image_id": 303944, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.10777013434966339, "Bleu_3": 0.0662184410884832, "Bleu_4": 9.288980742875092e-06, "METEOR": 0.2007433702348078, "ROUGE_L": 0.21631205673758863, "CIDEr": 9.67817868455934e-07, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a pair of suitcases on wheels in front of a brick wall. The suitcases are black and have the words \"Image Content\" written on them. There is a picture of a man hanging on the wall behind the suitcases."}, "567683": {"image_id": 567683, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2062842492474154, "Bleu_3": 0.12276317177262669, "Bleu_4": 1.4239605151902859e-05, "METEOR": 0.17206852667001932, "ROUGE_L": 0.2401574803149606, "CIDEr": 1.1242535212775034e-09, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.16, "f": 0.2105263157894737, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Here is a caption for the image:\n\n\"A group of motorcyclists parked on the side of the road, with their bikes lined up next to each other. Some of them are wearing helmets and jackets, while others are not. The sky is clear and blue in the background.\""}, "377577": {"image_id": 377577, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.12903971808302675, "Bleu_3": 0.07179233837245348, "Bleu_4": 9.576248453510562e-06, "METEOR": 0.21643556603959252, "ROUGE_L": 0.24416277518345564, "CIDEr": 5.6817531395344595e-09, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.3, "f": 0.3636363636363637, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.4444444444444444, "f": 0.5714285714285714, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The woman is standing on the sidewalk, holding an umbrella over her head. She is wearing a black jacket and jeans, and has a purse slung over her shoulder. The building behind her appears to be made of brick and has a red awning over the entrance."}, "316258": {"image_id": 316258, "Bleu_1": 0.5499999999725, "Bleu_2": 0.41675437671185933, "Bleu_3": 0.26822913133962367, "Bleu_4": 3.2641283464789606e-05, "METEOR": 0.22746174382015505, "ROUGE_L": 0.42558139534883715, "CIDEr": 0.26214391145245525, "SPICE": {"All": {"pr": 0.125, "re": 0.18518518518518517, "f": 0.14925373134328357, "fn": 22.0, "numImages": 1.0, "fp": 35.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.5, "f": 0.38461538461538464, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a group of people in boats on the river, with buildings and trees visible in the background."}, "298689": {"image_id": 298689, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.21926450482120546, "Bleu_3": 0.13626814836267256, "Bleu_4": 1.6171314933054195e-05, "METEOR": 0.28964254351133273, "ROUGE_L": 0.23680124223602486, "CIDEr": 7.119729150484978e-06, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2777777777777778, "f": 0.25, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person performing a trick on a snowboard in the mountains. The person is wearing a green jacket, black pants, and a helmet. The background is a mountainous landscape with trees and a river running through it."}, "144878": {"image_id": 144878, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.26794565081604904, "Bleu_3": 0.1236241378573366, "Bleu_4": 1.5032355086635528e-05, "METEOR": 0.26337058159387, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.00024772347246210756, "SPICE": {"All": {"pr": 0.05128205128205128, "re": 0.08333333333333333, "f": 0.06349206349206349, "fn": 22.0, "numImages": 1.0, "fp": 37.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a truck parked on a dirt road in the middle of a desert. The truck has a blue and white body with a red and white cabin. There are no people or other vehicles in the image."}, "265950": {"image_id": 265950, "Bleu_1": 0.23076923076627218, "Bleu_2": 0.1815682597982978, "Bleu_3": 0.10917650186987135, "Bleu_4": 1.147708413560364e-05, "METEOR": 0.2629427761305507, "ROUGE_L": 0.25608732157850544, "CIDEr": 1.4523803889808743e-27, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.14705882352941177, "f": 0.1754385964912281, "fn": 29.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a baseball player in the process of throwing a pitch on a baseball field. The player is wearing a red and white jersey with the number 7 on the back, and has a glove on his left hand. The ball is in his right hand, and he is standing on the mound, ready to throw the pitch. The background is a green grass field with a dirt infield and a white fence in the distance."}, "440793": {"image_id": 440793, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.23426064282712405, "Bleu_3": 0.11205846904084896, "Bleu_4": 1.3871953183286942e-05, "METEOR": 0.22196265352661634, "ROUGE_L": 0.3083032490974729, "CIDEr": 1.3510553646673227e-05, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.058823529411764705, "f": 0.058823529411764705, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are all wearing black and white clothing and have their skis on their feet. The slope is covered in snow and there are some trees in the background."}, "359592": {"image_id": 359592, "Bleu_1": 0.6470588234913496, "Bleu_2": 0.5320603680596521, "Bleu_3": 0.3839876638293666, "Bleu_4": 0.25217727370918547, "METEOR": 0.33313593599645414, "ROUGE_L": 0.5943970767356882, "CIDEr": 0.8984414409788264, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a plate of food with a piece of meat and some broccoli on it."}, "152176": {"image_id": 152176, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2736170867397671, "Bleu_3": 0.16725873794533458, "Bleu_4": 0.11084119214220596, "METEOR": 0.2298212562795071, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.0002777165222035087, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13043478260869565, "f": 0.13636363636363635, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a bicycle parked next to a river with a bridge in the background. The sky is clear and blue, and there are trees and grass on either side of the river."}, "520478": {"image_id": 520478, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.19438820598718592, "Bleu_3": 1.0070384043317263e-06, "Bleu_4": 2.3078570221283513e-09, "METEOR": 0.24035478520670692, "ROUGE_L": 0.28175519630484985, "CIDEr": 7.697003497656343e-06, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.21739130434782608, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.5555555555555556, "f": 0.6666666666666667, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. He is wearing a white shirt and black shorts, and has a racket in his hand as he prepares to hit the ball."}, "253421": {"image_id": 253421, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.13057679112202067, "Bleu_3": 0.06337029472199883, "Bleu_4": 7.880037991327068e-06, "METEOR": 0.18295120920945657, "ROUGE_L": 0.24629878869448185, "CIDEr": 1.0054391628703336e-19, "SPICE": {"All": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a vase with flowers sitting on a wooden table. The flowers are a mix of different colors, including pink, yellow, and white. The vase is made of a dark red glass and has a handle on the side. The table is made of wood and has a smooth surface. The light from the window behind the table casts a shadow on the wall behind the vase."}, "182175": {"image_id": 182175, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.3086066999098223, "Bleu_3": 1.6823908656597404e-06, "Bleu_4": 3.978842755121578e-09, "METEOR": 0.183254129390619, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.09832798986859939, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and floor tiles. The walls are cracked and there is debris on the floor."}, "401327": {"image_id": 401327, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.14862901964760822, "Bleu_4": 0.09641215953986118, "METEOR": 0.23959916130686862, "ROUGE_L": 0.32520944402132523, "CIDEr": 2.3129607160890832e-06, "SPICE": {"All": {"pr": 0.28, "re": 0.21875, "f": 0.2456140350877193, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.35714285714285715, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This image shows a computer desk with a mouse and keyboard on top of it. The desk is made of metal and has a shiny finish. There are no other objects in the room, just the desk and the computer equipment."}, "391596": {"image_id": 391596, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.23278142562159646, "Bleu_3": 0.1261375218310181, "Bleu_4": 1.666824532264052e-05, "METEOR": 0.28547090422995275, "ROUGE_L": 0.39617739840415667, "CIDEr": 0.006374169616203703, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.15789473684210525, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This image shows a group of people lying on the beach with umbrellas. In the background, there is a boat in the water. The sky is clear and blue."}, "504439": {"image_id": 504439, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.19674775072873343, "Bleu_3": 0.11010503638215555, "Bleu_4": 1.4776306152176402e-05, "METEOR": 0.22550517525454195, "ROUGE_L": 0.22202001819836215, "CIDEr": 0.0008871730147035367, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows two zebras standing in a field with trees in the background. They are both striped with black and white stripes, and their heads are turned towards each other."}, "538858": {"image_id": 538858, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.15755219780890306, "Bleu_3": 0.08141361391768222, "Bleu_4": 1.0464528052553808e-05, "METEOR": 0.18868181705923745, "ROUGE_L": 0.20497311827956988, "CIDEr": 1.9502729140586435e-10, "SPICE": {"All": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a group of young men playing baseball on a field with a fence in the background. They are wearing blue and white uniforms and are standing in a line, ready to catch the ball. The field is green and there are trees in the background."}, "577212": {"image_id": 577212, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.08189821165837179, "Bleu_3": 5.561109032117353e-07, "Bleu_4": 1.4585628855619905e-09, "METEOR": 0.16277493216014285, "ROUGE_L": 0.17617328519855593, "CIDEr": 9.732612137708873e-06, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.35714285714285715, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.75, "f": 0.6, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a kitchen with white cabinets and countertops. There are two sinks on the counter, one on the left and one on the right. The floor is made of wood and there are tools and materials scattered around the room."}, "314495": {"image_id": 314495, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.15191090505870355, "Bleu_3": 0.08468336402372788, "Bleu_4": 1.1318741601733969e-05, "METEOR": 0.20042292668178235, "ROUGE_L": 0.2691176470588235, "CIDEr": 1.4609539998658601e-06, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13793103448275862, "f": 0.1951219512195122, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a brown and white longhorn cow standing behind a wooden fence. The cow has large horns and is looking directly at the camera with its eyes. The background is a dirt road with trees in the distance."}, "250564": {"image_id": 250564, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 0.1272232018279771, "Bleu_4": 0.08821755394408795, "METEOR": 0.2477853514506211, "ROUGE_L": 0.2930344275420336, "CIDEr": 1.4370538397646674e-05, "SPICE": {"All": {"pr": 0.12, "re": 0.17647058823529413, "f": 0.14285714285714282, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows two elephants standing in a grassy field. They are both brown and have large ears. One of them is holding a small branch in its trunk. The sky is clear and blue behind them."}, "230862": {"image_id": 230862, "Bleu_1": 0.3265306122382341, "Bleu_2": 0.27355060221045585, "Bleu_3": 0.22337017141512602, "Bleu_4": 0.18656145762255902, "METEOR": 0.32021454757410545, "ROUGE_L": 0.368135184067592, "CIDEr": 5.07583197980365e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person sitting on a couch with their legs crossed, looking at a laptop. There is a blanket on the couch and a book on the coffee table in front of them. The room is dimly lit and there are no other objects in the room."}, "451571": {"image_id": 451571, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.4696682182853713, "Bleu_3": 0.3086789594799614, "Bleu_4": 0.21409092658369572, "METEOR": 0.2883531297625142, "ROUGE_L": 0.4662420382165604, "CIDEr": 0.8507777014519804, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.08, "f": 0.06349206349206349, "fn": 23.0, "numImages": 1.0, "fp": 36.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.2, "f": 0.16, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a plate with grilled corn on the cob and a side dish of vegetables."}, "361586": {"image_id": 361586, "Bleu_1": 0.2264150943353507, "Bleu_2": 0.0933181271719728, "Bleu_3": 0.05547797716282366, "Bleu_4": 7.644480232985446e-06, "METEOR": 0.1677718373329856, "ROUGE_L": 0.18100890207715134, "CIDEr": 1.0695771122213849e-11, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20833333333333334, "f": 0.25641025641025644, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is an image of a train station with people standing in front of it. There are several signs and advertisements on the walls, as well as a ticket counter and a baggage claim area. The floor is made of white tiles and there are several chairs and tables scattered throughout the room."}, "213162": {"image_id": 213162, "Bleu_1": 0.39999999999111113, "Bleu_2": 0.23354968324320796, "Bleu_3": 1.0825053129131102e-06, "Bleu_4": 2.3442838993077277e-09, "METEOR": 0.2611561891553292, "ROUGE_L": 0.34078212290502796, "CIDEr": 5.524124772547659e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.1, "f": 0.12903225806451613, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The woman is holding a tennis racket and swinging it at the ball on the court. She is wearing black shorts and a white shirt with a black stripe on the sleeves. The background is a green tennis court with a net in the center."}, "549766": {"image_id": 549766, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.28097574345930926, "Bleu_3": 0.16683848808490073, "Bleu_4": 2.321091111608818e-05, "METEOR": 0.2233676265554817, "ROUGE_L": 0.3053817271589487, "CIDEr": 0.15176759017820557, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.05, "f": 0.0625, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The giraffe is standing in the bush, looking around. It has a long neck and spots on its body."}, "537727": {"image_id": 537727, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.4108907017875376, "Bleu_3": 0.20361395690735576, "Bleu_4": 2.5817682616759057e-05, "METEOR": 0.2674119472847316, "ROUGE_L": 0.4969450101832994, "CIDEr": 0.15913810183728544, "SPICE": {"All": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 8.0}, "Relation": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.5, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5714285714285714, "f": 0.7272727272727273, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This is a living room with a wooden table and chairs, a window with curtains, and a wooden wheel in the corner."}, "307523": {"image_id": 307523, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.10314212462370773, "Bleu_3": 6.138158588631339e-07, "Bleu_4": 1.505654929036229e-09, "METEOR": 0.14355570001253923, "ROUGE_L": 0.23036253776435048, "CIDEr": 2.0070703686442443e-09, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15789473684210525, "f": 0.14634146341463414, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person skateboarding on the sidewalk at night. The person is wearing a black jacket and black pants, and has a black hat on their head. The skateboard is black and has white wheels. The background is dark and there are streetlights in the distance."}, "74617": {"image_id": 74617, "Bleu_1": 0.3225806451560874, "Bleu_2": 0.1454401223535526, "Bleu_3": 7.064353188210453e-07, "Bleu_4": 1.5634762918765943e-09, "METEOR": 0.22619252112468613, "ROUGE_L": 0.16594124047878128, "CIDEr": 1.1607621035625518e-15, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.25, "f": 0.1724137931034483, "fn": 15.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.625, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows two young men playing tennis on a court with a net in the background. One of them is holding a racket and swinging it at the ball, while the other is standing behind him, ready to hit the ball back. The players are wearing white shirts and shorts, and their faces are visible as they focus on the game."}, "547854": {"image_id": 547854, "Bleu_1": 0.5517241379120095, "Bleu_2": 0.34384095302468337, "Bleu_3": 0.23595230888365676, "Bleu_4": 0.14992526894743852, "METEOR": 0.324499671112998, "ROUGE_L": 0.44976958525345617, "CIDEr": 0.01719653067658961, "SPICE": {"All": {"pr": 0.25, "re": 0.16129032258064516, "f": 0.19607843137254902, "fn": 26.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a young girl sitting at a table with her hands on the plate of pizza. She is smiling and looks happy to be eating the pizza."}, "360943": {"image_id": 360943, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.392232270247274, "Bleu_3": 0.23404631037024026, "Bleu_4": 3.2857020445327865e-05, "METEOR": 0.2601766366286921, "ROUGE_L": 0.47805642633228845, "CIDEr": 0.7317416206300152, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2222222222222222, "f": 0.2142857142857143, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.07692307692307693, "f": 0.125, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.625, "f": 0.43478260869565216, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "A cat sitting on the steps of a house, looking out at the street."}, "535668": {"image_id": 535668, "Bleu_1": 0.2777777777726338, "Bleu_2": 0.22893427324353557, "Bleu_3": 0.18218943070472146, "Bleu_4": 0.15604229933011285, "METEOR": 0.29336455321062543, "ROUGE_L": 0.29151732377538825, "CIDEr": 8.664835465674159e-13, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a baseball player swinging a bat at a ball on a baseball field. The player is wearing a red and white uniform with the number 23 on the back. The umpire is standing behind the plate, watching the player hit the ball. The stands are filled with people watching the game."}, "558608": {"image_id": 558608, "Bleu_1": 0.2608695652136106, "Bleu_2": 0.13849760170194028, "Bleu_3": 0.08303857727057992, "Bleu_4": 9.651036116248704e-06, "METEOR": 0.17418599272713026, "ROUGE_L": 0.25093046033300687, "CIDEr": 3.458900496004362e-19, "SPICE": {"All": {"pr": 0.125, "re": 0.11538461538461539, "f": 0.12000000000000001, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This image shows a group of people flying kites on the beach. The kites are colorful and shaped like animals, such as butterflies, dragons, and birds. They are flying in the sky above the beach, with the sun shining down on them. There are people standing on the beach, watching the kites fly. The image is taken from a high angle, looking down at the beach and the kites."}, "431746": {"image_id": 431746, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.3099340466837252, "Bleu_3": 0.24233246512615864, "Bleu_4": 0.18189587991473063, "METEOR": 0.290720771017128, "ROUGE_L": 0.3373271889400921, "CIDEr": 0.01780310390572264, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09090909090909091, "f": 0.0975609756097561, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The man is holding a cell phone in his hand and smiling at the camera. He is wearing a red shirt and has a friendly expression on his face."}, "391139": {"image_id": 391139, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.22841609628304363, "Bleu_3": 0.18099097209374854, "Bleu_4": 0.1426119388388802, "METEOR": 0.3688480247637015, "ROUGE_L": 0.3299208035541819, "CIDEr": 5.212444986199425e-08, "SPICE": {"All": {"pr": 0.375, "re": 0.1111111111111111, "f": 0.17142857142857143, "fn": 24.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a photo of a small dog sitting on a wooden bench in front of a pumpkin patch. The dog is wearing a red collar and has its tongue hanging out of its mouth. There are several pumpkins and other fall decorations in the background."}, "426070": {"image_id": 426070, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.15802842456444308, "Bleu_4": 0.11708373934317436, "METEOR": 0.28275401087905433, "ROUGE_L": 0.3561301084236864, "CIDEr": 1.241721969475614e-07, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a man sitting on a couch with his head resting on his hand. He is wearing a pink shirt and jeans. There are several pillows and blankets on the couch, and a laptop is on the coffee table in front of him."}, "242679": {"image_id": 242679, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.2531848417613592, "Bleu_3": 0.17244679591558448, "Bleu_4": 0.12090340629597032, "METEOR": 0.23715602137941044, "ROUGE_L": 0.3663663663663663, "CIDEr": 0.009471225345182148, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is a picture of a train car with seats and tables. There are windows on the sides of the car and a bathroom in the back."}, "437789": {"image_id": 437789, "Bleu_1": 0.6499999999675001, "Bleu_2": 0.18496087778846218, "Bleu_3": 1.2386893876627563e-06, "Bleu_4": 3.251693345813515e-09, "METEOR": 0.16479400749063672, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.08709909698821844, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a table with several containers of food, including a mug of coffee, an orange, and some fruit."}, "189163": {"image_id": 189163, "Bleu_1": 0.26666666665777783, "Bleu_2": 0.16609095970184817, "Bleu_3": 0.099504942383045, "Bleu_4": 1.3821098063238631e-05, "METEOR": 0.2686151012164949, "ROUGE_L": 0.2839851024208566, "CIDEr": 0.0035940988830616997, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.047619047619047616, "f": 0.04545454545454545, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a person sitting on a bed, reading a book by the light of a lamp. The room is dimly lit and there are curtains on the windows."}, "93887": {"image_id": 93887, "Bleu_1": 0.714285714234694, "Bleu_2": 0.5241424183220805, "Bleu_3": 0.35775231709800853, "Bleu_4": 0.25400289713142493, "METEOR": 0.28320163036218726, "ROUGE_L": 0.5669144981412639, "CIDEr": 1.2903347045094484, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.15384615384615385, "f": 0.20512820512820515, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "A white sheep standing in a green field with a fence in the background."}, "236784": {"image_id": 236784, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.6396021490111085, "Bleu_3": 0.5892007318506259, "Bleu_4": 0.46173663089961975, "METEOR": 0.38337558134678534, "ROUGE_L": 0.6224489795918368, "CIDEr": 1.609197580219317, "SPICE": {"All": {"pr": 0.2, "re": 0.5454545454545454, "f": 0.29268292682926833, "fn": 5.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.5, "f": 0.16666666666666669, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "Two dogs are laying on a couch, one black and one brown."}, "430791": {"image_id": 430791, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.12595484068769355, "Bleu_3": 0.06418390826668295, "Bleu_4": 8.181946133422561e-06, "METEOR": 0.1843930283952188, "ROUGE_L": 0.25823142050799625, "CIDEr": 8.086697308128826e-14, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.23076923076923078, "f": 0.24489795918367346, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a woman standing in front of a wall with red ribbons hanging from the ceiling. The woman is wearing a black dress and has her hands in her pockets. There are several red ribbons hanging from the ceiling, some of which are tied to the woman's dress. The overall effect is one of a surreal and dreamlike atmosphere."}, "467297": {"image_id": 467297, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.14793835438670558, "Bleu_4": 0.10952542776957253, "METEOR": 0.21157349507912715, "ROUGE_L": 0.2459677419354839, "CIDEr": 1.8145319782886138e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "A woman is standing in a kitchen, wearing a blue shirt and black pants. She is holding a tray of food in her hands and looking at the oven. There are several pots and pans on the stove and countertops. The walls are covered in a floral pattern."}, "293034": {"image_id": 293034, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.16803361008003348, "Bleu_3": 0.1200160042655936, "Bleu_4": 0.09212480089236007, "METEOR": 0.2542645789321419, "ROUGE_L": 0.27319257837492, "CIDEr": 8.293180502073582e-12, "SPICE": {"All": {"pr": 0.6, "re": 0.13043478260869565, "f": 0.21428571428571427, "fn": 20.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a fence that has a giraffe on the other side. The giraffe is standing on its hind legs and looking at the people with its long neck. The people are looking at the giraffe with their mouths open in amazement."}, "7673": {"image_id": 7673, "Bleu_1": 0.5333333332977779, "Bleu_2": 0.33806170186806433, "Bleu_3": 0.20638725024557966, "Bleu_4": 2.9256127305132916e-05, "METEOR": 0.23389280267589707, "ROUGE_L": 0.5236051502145923, "CIDEr": 0.4966073739504797, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure, here is a caption for the image:\n\n\"Surfer riding a wave in a river\""}, "523529": {"image_id": 523529, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.22941573386460196, "Bleu_3": 0.16220166573123573, "Bleu_4": 0.10434360980506845, "METEOR": 0.2593436513635327, "ROUGE_L": 0.2741573033707865, "CIDEr": 4.5331961682416015e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.15789473684210525, "f": 0.20689655172413793, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a brown bear standing on the ground, looking up at something. The bear is wearing a collar and has a tag on its neck. The background is a rocky terrain with some trees in the distance."}, "232950": {"image_id": 232950, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.20806259463443724, "Bleu_3": 1.2935583035953797e-06, "Bleu_4": 3.2670148297998828e-09, "METEOR": 0.29120535541030274, "ROUGE_L": 0.3639618138424821, "CIDEr": 0.07387492563808971, "SPICE": {"All": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The man is holding a slice of pizza in his hand and looking at it with a surprised expression on his face."}, "529968": {"image_id": 529968, "Bleu_1": 0.24615384615005917, "Bleu_2": 0.17541160385868612, "Bleu_3": 0.09922064100009909, "Bleu_4": 0.063001893022311, "METEOR": 0.2253795389171505, "ROUGE_L": 0.27164769915883225, "CIDEr": 1.1460987974636693e-18, "SPICE": {"All": {"pr": 0.3, "re": 0.11538461538461539, "f": 0.16666666666666669, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on the back of a motorcycle. The cat is looking straight ahead, with its ears perked up and its tail curled around the handlebars. The motorcycle has a helmet on the seat next to the cat, and there are mirrors on the side of the bike. The background is a city street with buildings and trees in the distance."}, "421976": {"image_id": 421976, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.15849534045439814, "Bleu_3": 8.295835031586615e-07, "Bleu_4": 1.908877093760086e-09, "METEOR": 0.2177298898193348, "ROUGE_L": 0.19728331177231562, "CIDEr": 3.266444198833925e-08, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.21739130434782608, "f": 0.25, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a black and white sheep standing in a straw pile, looking up at its mother. The mother sheep is standing on the other side of the pile, looking down at her baby. The background is a barn with wooden beams and a hayloft."}, "104880": {"image_id": 104880, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.23533936215658835, "Bleu_3": 1.3214760629595458e-06, "Bleu_4": 3.164918395250227e-09, "METEOR": 0.227481419433242, "ROUGE_L": 0.3131416837782341, "CIDEr": 0.03755733313660434, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a street sign with the words \"smile\" written on it. The sign is attached to a lamppost and there are buildings in the background."}, "314396": {"image_id": 314396, "Bleu_1": 0.34615384614053263, "Bleu_2": 0.1664100588610404, "Bleu_3": 1.0488562462463889e-06, "Bleu_4": 2.661368533136455e-09, "METEOR": 0.18241531133796718, "ROUGE_L": 0.32515991471215355, "CIDEr": 0.0120187289438985, "SPICE": {"All": {"pr": 0.21875, "re": 0.28, "f": 0.2456140350877193, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5454545454545454, "f": 0.4799999999999999, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a green bag with the words \"inova disc golf\" written on it. There are several plastic discs of different colors inside the bag."}, "206859": {"image_id": 206859, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.1332650098148157, "Bleu_3": 6.701830194835844e-07, "Bleu_4": 1.5093434225110114e-09, "METEOR": 0.21365505577765478, "ROUGE_L": 0.24574478799476282, "CIDEr": 2.6194393414851686e-14, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a man standing in front of a table filled with boxes of apples. He is wearing an orange shirt and has a yellow hat on his head. There are other people in the background, some of whom are also wearing hats. The image appears to be taken at a farmer's market or other outdoor event."}, "498759": {"image_id": 498759, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 8.077421359130519e-07, "Bleu_4": 1.8710588175603566e-09, "METEOR": 0.2053323453333355, "ROUGE_L": 0.2447178389943835, "CIDEr": 1.3989911182154074e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.25, "f": 0.1764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person riding a skateboard down the sidewalk. The person is wearing a helmet and has their arms outstretched to balance themselves on the board. There are cars parked along the side of the road, and trees can be seen in the background."}, "151084": {"image_id": 151084, "Bleu_1": 0.2727272727190084, "Bleu_2": 0.18463723646331667, "Bleu_3": 0.1032188373500798, "Bleu_4": 1.3836903383875294e-05, "METEOR": 0.26652582591100776, "ROUGE_L": 0.3015323776569451, "CIDEr": 0.0007584966316395059, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man in a black shirt and gray pants standing in the middle of a park, holding a frisbee in his hand. There are trees and grass in the background."}, "485452": {"image_id": 485452, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.23546453742246556, "Bleu_3": 0.19480342335629552, "Bleu_4": 0.15026417037436174, "METEOR": 0.2557070472352316, "ROUGE_L": 0.31551724137931036, "CIDEr": 0.0019241827882686626, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.19230769230769232, "f": 0.25, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is a bathroom with a white sink, toilet, and shower. The walls are painted blue and white stripes. There is a window on the left side of the room with curtains."}, "469896": {"image_id": 469896, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.22758963106159172, "Bleu_3": 0.17023095994627138, "Bleu_4": 0.13783619018312754, "METEOR": 0.28070325025022025, "ROUGE_L": 0.29985955056179775, "CIDEr": 2.3127903222741228e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.18518518518518517, "f": 0.2127659574468085, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is a black and white photograph of a woman sitting on a bed, reading a book. She is wearing glasses and has her hair tied back in a ponytail. The room is decorated with floral wallpaper and there are curtains on the windows."}, "310369": {"image_id": 310369, "Bleu_1": 0.19999999999733334, "Bleu_2": 0.15596257347091738, "Bleu_3": 0.13261886958237723, "Bleu_4": 0.11281409616117859, "METEOR": 0.23651267586388794, "ROUGE_L": 0.24563758389261747, "CIDEr": 1.0729980426808316e-26, "SPICE": {"All": {"pr": 0.1875, "re": 0.23076923076923078, "f": 0.20689655172413793, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people sitting on couches in a living room, eating pizza. One person is holding a slice of pizza and another person is taking a bite out of theirs. There are several other people in the background of the image, also eating pizza. The walls of the room are painted a light brown color and there are several windows in the background that allow natural light to enter the room."}, "206381": {"image_id": 206381, "Bleu_1": 0.2075471698074048, "Bleu_2": 1.9978217455490674e-09, "Bleu_3": 4.2774121488863e-12, "Bleu_4": 1.9890391110390992e-13, "METEOR": 0.10036300275882098, "ROUGE_L": 0.14796846573681016, "CIDEr": 5.986939374345871e-12, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people are gathered around a barn with several sheep in it. One person is holding a baby lamb while another person is feeding a sheep from a bucket. The atmosphere is cozy and peaceful, with warm lighting and a wooden floor."}, "345930": {"image_id": 345930, "Bleu_1": 0.340909090901343, "Bleu_2": 0.19909945244613453, "Bleu_3": 0.09809125257770394, "Bleu_4": 1.2317618414994371e-05, "METEOR": 0.2297167938614718, "ROUGE_L": 0.25809961315280466, "CIDEr": 3.5983644651134815e-06, "SPICE": {"All": {"pr": 0.08, "re": 0.09090909090909091, "f": 0.0851063829787234, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is an image of a street with a tall building in the background. There are cars parked on the side of the road and a traffic light at the intersection. The sky is clear and blue, with some clouds visible in the distance."}, "252711": {"image_id": 252711, "Bleu_1": 0.14705882352724917, "Bleu_2": 0.08114630885887751, "Bleu_3": 0.04638004879933218, "Bleu_4": 6.2592177704981e-06, "METEOR": 0.10947649288270743, "ROUGE_L": 0.14805825242718448, "CIDEr": 9.996472414451554e-22, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13636363636363635, "f": 0.11320754716981131, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a table with several types of donuts on it. There are different types of donuts, including chocolate frosted, glazed, and sprinkled. Some of the donuts are stacked on top of each other, while others are arranged in rows. The table is made of wood and has a white cloth covering it. In the background, there is a wall with a few more donuts on it."}, "189744": {"image_id": 189744, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.13187609467625871, "Bleu_3": 7.338824344329119e-07, "Bleu_4": 1.741216427287497e-09, "METEOR": 0.25925680942276635, "ROUGE_L": 0.20691994572591585, "CIDEr": 5.940713415853166e-09, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.19047619047619047, "f": 0.18604651162790697, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The building is a red brick structure with a white facade. It has a large sign on the front that reads \"The Ploughgate\". There are several windows on the first floor, and a door on the ground floor. The building appears to be in good condition."}, "498547": {"image_id": 498547, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.2995723447500538, "Bleu_3": 0.2547451710264738, "Bleu_4": 0.20560990716056962, "METEOR": 0.3536354109850402, "ROUGE_L": 0.3685800604229607, "CIDEr": 9.446793962688496e-06, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.3888888888888889, "f": 0.37837837837837834, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6666666666666666, "f": 0.7058823529411765, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "This is a kitchen with a large stove and several pots and pans hanging from the ceiling. There are also several countertops with various utensils and appliances on them. The walls are painted white and there is a wooden floor."}, "139871": {"image_id": 139871, "Bleu_1": 0.3199999999936, "Bleu_2": 0.13997084244192506, "Bleu_3": 7.417848716778728e-07, "Bleu_4": 1.7166589196261759e-09, "METEOR": 0.24774142469889077, "ROUGE_L": 0.22938079719227877, "CIDEr": 2.799363019236953e-10, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.125, "f": 0.15789473684210525, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a small, white and black airplane sitting on the runway. The plane has a large propeller on the front and a small cockpit on top. There are several people standing around the plane, looking at it. The sky is clear and blue in the background."}, "274792": {"image_id": 274792, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.2300218531057509, "Bleu_3": 0.12672285514146672, "Bleu_4": 1.6891032975685782e-05, "METEOR": 0.13614788666238883, "ROUGE_L": 0.2978515625, "CIDEr": 0.00414033227461726, "SPICE": {"All": {"pr": 0.375, "re": 0.34615384615384615, "f": 0.35999999999999993, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a cake in a mixing bowl with ingredients such as carrots, potatoes, and onions. The cake is being mixed with a wooden spoon."}, "513933": {"image_id": 513933, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.12803687993077956, "Bleu_3": 0.0822146823185309, "Bleu_4": 9.893615743279745e-06, "METEOR": 0.17767178344282938, "ROUGE_L": 0.16495402920497565, "CIDEr": 3.022590846620856e-15, "SPICE": {"All": {"pr": 0.06060606060606061, "re": 0.07692307692307693, "f": 0.06779661016949153, "fn": 24.0, "numImages": 1.0, "fp": 31.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a table with three cakes on it. One of the cakes has the number 18 written on it in blue frosting, while the other two have the letters \"J\" and \"S\" written on them in red and green frosting, respectively. There are also several candles on the table, as well as some decorations such as balloons and streamers."}, "338595": {"image_id": 338595, "Bleu_1": 0.19565217390879022, "Bleu_2": 0.1474419561516563, "Bleu_3": 0.09960317042671256, "Bleu_4": 0.06923692285350443, "METEOR": 0.19249374439705655, "ROUGE_L": 0.27619663648124193, "CIDEr": 1.2029484581059277e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is an image of a group of people standing under umbrellas in the rain. They are all wearing different types of clothing, including hats and jackets. The umbrellas are open and provide protection from the rain. There are buildings in the background of the image."}, "395": {"image_id": 395, "Bleu_1": 0.41860465115305573, "Bleu_2": 0.34583425061440265, "Bleu_3": 0.24432845621635543, "Bleu_4": 0.164332339950243, "METEOR": 0.27121836151331835, "ROUGE_L": 0.41216216216216217, "CIDEr": 3.3267605761343278e-06, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.21052631578947367, "f": 0.15384615384615385, "fn": 15.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.16666666666666666, "f": 0.1, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a man in a red jacket and black pants standing on the sidewalk, talking on his cell phone. He is surrounded by other people walking in the opposite direction. The sky is blue and there are buildings in the background."}, "266922": {"image_id": 266922, "Bleu_1": 0.6666666665185187, "Bleu_2": 0.40824829037030635, "Bleu_3": 0.28768479126408814, "Bleu_4": 4.463236136748592e-05, "METEOR": 0.1732013725321393, "ROUGE_L": 0.3986928104575163, "CIDEr": 0.7229292464143959, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.14285714285714285, "f": 0.19047619047619047, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "A group of people skiing down a snowy slope."}, "502927": {"image_id": 502927, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.12121830534381621, "Bleu_3": 0.08491317075202563, "Bleu_4": 1.0683334564397808e-05, "METEOR": 0.18697466015010622, "ROUGE_L": 0.1852976913730255, "CIDEr": 9.09915922730368e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.17647058823529413, "f": 0.1818181818181818, "fn": 14.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a dirt bike rider racing down a dirt track. The rider is wearing a helmet and gloves, and is holding onto the handlebars as he navigates through the turns. The track is lined with trees and fences, and there are spectators watching from the sidelines."}, "22660": {"image_id": 22660, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.2548235957069542, "Bleu_3": 0.14807546136987573, "Bleu_4": 2.0331710658749725e-05, "METEOR": 0.21588818074719207, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.0709772680306943, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.038461538461538464, "f": 0.03703703703703704, "fn": 25.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "An empty train station platform with a bench and a sign that reads \"Waiting Room\" in white letters on a black background."}, "273354": {"image_id": 273354, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.20320258681677345, "Bleu_3": 0.15239494387941893, "Bleu_4": 0.1201201009191565, "METEOR": 0.30995149076348993, "ROUGE_L": 0.2930344275420336, "CIDEr": 1.4267185718937774e-05, "SPICE": {"All": {"pr": 0.3125, "re": 0.23809523809523808, "f": 0.27027027027027023, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is a blurry image of a train moving down the tracks. The train has a green and yellow paint job and is traveling at a high speed. There are buildings in the background of the image."}, "449839": {"image_id": 449839, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.26208179769640866, "Bleu_3": 0.16859402240403742, "Bleu_4": 0.10335210030169668, "METEOR": 0.23080744917722962, "ROUGE_L": 0.3233929754804506, "CIDEr": 7.396649505734632e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.09375, "f": 0.10909090909090909, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a wedding photo of a bride and groom standing in front of a tree. The bride is wearing a white dress and the groom is wearing a black suit and tie. They are both smiling at each other and holding bouquets of flowers."}, "278172": {"image_id": 278172, "Bleu_1": 0.2499999999958334, "Bleu_2": 0.1594482010331402, "Bleu_3": 0.10955801866311628, "Bleu_4": 0.08241796975804216, "METEOR": 0.16270986054288458, "ROUGE_L": 0.2435129740518962, "CIDEr": 3.029718117598512e-14, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.29411764705882354, "f": 0.3448275862068966, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a woman sitting at a table with two glasses of beer in front of her. She is wearing a white shirt and has a serious expression on her face. There are candles on the table and a vase with flowers in it. The background is dark and there are no other people or objects in the room."}, "446574": {"image_id": 446574, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.2156655464018017, "Bleu_3": 0.1504179432467115, "Bleu_4": 1.7078893747678562e-05, "METEOR": 0.23957411050114752, "ROUGE_L": 0.29387474191328283, "CIDEr": 3.0510651549260384e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This is a bathroom with a bathtub, toilet, and sink. The walls are made of white tiles and the floor is made of wood. There is a shower curtain hanging from the ceiling and a window on the left side of the room."}, "110042": {"image_id": 110042, "Bleu_1": 0.4210526315678671, "Bleu_2": 0.23853512165798602, "Bleu_3": 0.11648429847736043, "Bleu_4": 1.4577516118123882e-05, "METEOR": 0.21442389569975134, "ROUGE_L": 0.22659732540861813, "CIDEr": 3.734266730033249e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This image shows a man standing in front of a toilet at an outdoor event. The toilet is surrounded by a sign that reads \"Boil Water Before Drinking\". There are several people standing around the toilet, looking on."}, "166837": {"image_id": 166837, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.1462544848210594, "Bleu_3": 8.743583640208559e-07, "Bleu_4": 2.1548978018709016e-09, "METEOR": 0.18569344696180407, "ROUGE_L": 0.20783645655877342, "CIDEr": 0.0004143086639454989, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2777777777777778, "f": 0.2777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a yellow and black train traveling on the tracks. The train has a large engine at the front and several cars behind it. There are trees and buildings in the background."}, "422375": {"image_id": 422375, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.12903971808302675, "Bleu_3": 7.17923383724535e-07, "Bleu_4": 1.7029245450294905e-09, "METEOR": 0.20287198314455726, "ROUGE_L": 0.26571250777846916, "CIDEr": 8.683742264376012e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08, "f": 0.1, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The man is standing in front of a mirror, wearing a black shirt and tie. He has a serious expression on his face and is holding a camera in his hand. There are some plants in the background, and a red light is hanging from the ceiling."}, "393836": {"image_id": 393836, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2993592018235193, "Bleu_3": 0.23174884373154778, "Bleu_4": 0.19420534060155806, "METEOR": 0.2881465010109054, "ROUGE_L": 0.4078751857355126, "CIDEr": 3.886739070155896e-05, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.1111111111111111, "f": 0.10344827586206896, "fn": 24.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a bedroom with a bed, nightstand, and lamp. The bed has a quilt on it and there are pillows on the nightstand. The lamp is on the nightstand and there is a window in the background."}, "566298": {"image_id": 566298, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.10767638040926633, "Bleu_3": 6.411053581337095e-07, "Bleu_4": 1.573366652415358e-09, "METEOR": 0.11340318862660888, "ROUGE_L": 0.16158940397350993, "CIDEr": 4.667830918852892e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man and woman holding a toothbrush in their mouths while smiling at the camera. The man is wearing a purple shirt and the woman is wearing a pink dress. They are both sitting on a bed with a white blanket covering it."}, "159240": {"image_id": 159240, "Bleu_1": 0.5135135134996348, "Bleu_2": 0.33780780646376446, "Bleu_3": 0.23538408920524054, "Bleu_4": 2.4886458505008387e-05, "METEOR": 0.29950305547233125, "ROUGE_L": 0.35032304379038054, "CIDEr": 0.0002537310167760346, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.29411764705882354, "f": 0.2631578947368421, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a living room with an orange wall and a brown couch. There is a television on the wall and a chair in front of it. The room appears to be empty except for the furniture."}, "321805": {"image_id": 321805, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.26042109924757323, "Bleu_3": 0.21771959341011354, "Bleu_4": 0.18401893316692927, "METEOR": 0.2962545280123939, "ROUGE_L": 0.3202099737532808, "CIDEr": 9.718868560474111e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.46153846153846156, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.8, "f": 0.5000000000000001, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a clock tower in the middle of a park with palm trees and other plants surrounding it. The clock tower is made of stone and has a large clock face on its front. The sky is clear and blue, with some clouds in the distance."}, "54039": {"image_id": 54039, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.2602575457946004, "Bleu_3": 0.1358775263736997, "Bleu_4": 1.7624523616137678e-05, "METEOR": 0.2552605083203011, "ROUGE_L": 0.2595744680851064, "CIDEr": 0.00783190475483268, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a city street with parked motorcycles on the sidewalk. The street is lined with tall buildings and there are people walking on the sidewalk."}, "253477": {"image_id": 253477, "Bleu_1": 0.35294117646366785, "Bleu_2": 0.2520504151200502, "Bleu_3": 0.10904177641022005, "Bleu_4": 1.2819892373208521e-05, "METEOR": 0.23827444500472253, "ROUGE_L": 0.2501464557703574, "CIDEr": 9.154943070843417e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.125, "f": 0.09523809523809525, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a man on a surfboard jumping off the side of a boat into the water. The man is wearing a life jacket and has his arms outstretched as he jumps. The boat is in the background, with people standing on the deck and looking out at the water."}, "363991": {"image_id": 363991, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.15320195579385062, "Bleu_3": 0.08671123520251264, "Bleu_4": 1.1682600305257854e-05, "METEOR": 0.2568044162983805, "ROUGE_L": 0.2733791455034359, "CIDEr": 1.2382075855015738e-05, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.045454545454545456, "f": 0.05128205128205128, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "A person is standing on the beach holding a surfboard. The sky is clear and blue, with some clouds in the distance. The waves are crashing against the shore, and there are rocks and sand in the foreground."}, "233521": {"image_id": 233521, "Bleu_1": 0.21212121211799817, "Bleu_2": 0.1142524093978523, "Bleu_3": 0.0848966731474613, "Bleu_4": 0.06638811925158628, "METEOR": 0.20434205622069157, "ROUGE_L": 0.20628019323671495, "CIDEr": 7.972439384932562e-19, "SPICE": {"All": {"pr": 0.32, "re": 0.36363636363636365, "f": 0.3404255319148936, "fn": 14.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The woman is holding a baby in her arms while sitting on the couch. She is wearing a white shirt and black pants, and has a look of concentration on her face as she holds the baby. The baby is wearing a white onesie and has a look of contentment on its face. The room is cluttered with various items such as books, magazines, and toys."}, "73182": {"image_id": 73182, "Bleu_1": 0.1739130434744802, "Bleu_2": 1.9658927486887506e-09, "Bleu_3": 4.445176281086092e-12, "Bleu_4": 2.1259332643118572e-13, "METEOR": 0.13805901963812078, "ROUGE_L": 0.16158940397350993, "CIDEr": 8.163074953450493e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.16129032258064516, "f": 0.17543859649122806, "fn": 26.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a woman riding a red motorcycle on the sidewalk. She is wearing a helmet and has her arms stretched out to the sides as she steers the bike. There are trees and buildings in the background, and the sky is a bright blue."}, "84767": {"image_id": 84767, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.12094486170917773, "Bleu_3": 6.825571246936573e-07, "Bleu_4": 1.630426121875635e-09, "METEOR": 0.17847003604522035, "ROUGE_L": 0.20132013201320131, "CIDEr": 9.967209072910958e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.25, "f": 0.2173913043478261, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two people skiing down a snowy slope. One person is wearing a black and white jacket and pants, while the other is wearing a red and black jacket and pants. They are both holding skis and poles. In the background, there are trees and mountains."}, "350874": {"image_id": 350874, "Bleu_1": 0.382352941165225, "Bleu_2": 0.3229211588918931, "Bleu_3": 0.2836048730321632, "Bleu_4": 0.2577701686910811, "METEOR": 0.3457137959834011, "ROUGE_L": 0.44060995184590684, "CIDEr": 0.004039168760766664, "SPICE": {"All": {"pr": 0.2, "re": 0.06666666666666667, "f": 0.1, "fn": 28.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a man riding a red motorcycle with a sidecar on the side of the road. There are people walking in the background, and a building can be seen in the distance."}, "546659": {"image_id": 546659, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1923483450237976, "Bleu_3": 9.586112891268434e-07, "Bleu_4": 2.152959896330039e-09, "METEOR": 0.21920057134374932, "ROUGE_L": 0.20890410958904113, "CIDEr": 1.057531859117395e-07, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a black steam locomotive pulling a train through a city street. The train is moving at a slow pace and the tracks are lined with buildings on either side. There are people standing on the platform watching the train pass by."}, "548843": {"image_id": 548843, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.11531640100118269, "Bleu_3": 6.612130898132252e-07, "Bleu_4": 1.5920362546205505e-09, "METEOR": 0.18017499158618966, "ROUGE_L": 0.22426470588235295, "CIDEr": 4.212104056186859e-09, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1111111111111111, "f": 0.14634146341463417, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a young boy wearing a blue jacket and holding a plate of food. He is standing in front of a group of people who are all wearing glasses. The background appears to be a restaurant or cafe, with tables and chairs set up for customers."}, "6783": {"image_id": 6783, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.18881372800670282, "Bleu_3": 1.036666470236889e-06, "Bleu_4": 2.4484366152439622e-09, "METEOR": 0.15407411582870723, "ROUGE_L": 0.24478330658105937, "CIDEr": 3.405871441046792e-05, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.16129032258064516, "f": 0.1818181818181818, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a person flying a kite on the water. There are other people in the background, also flying kites. The sky is clear and blue, with a few clouds in the distance."}, "78420": {"image_id": 78420, "Bleu_1": 0.8999999998200003, "Bleu_2": 0.774596669082261, "Bleu_3": 0.608220199428375, "Bleu_4": 0.42341975783065045, "METEOR": 0.40549956091586586, "ROUGE_L": 0.8, "CIDEr": 2.652968230250697, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A cat is sleeping on top of a laptop computer."}, "96654": {"image_id": 96654, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.15617376188474938, "Bleu_3": 8.551661700652097e-07, "Bleu_4": 2.014150807982919e-09, "METEOR": 0.1341152622774056, "ROUGE_L": 0.21328671328671328, "CIDEr": 1.382158536646011e-06, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.23809523809523808, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of elephants are standing in a river, surrounded by lush green trees and a small waterfall. The elephants are drinking from the river and seem to be enjoying their surroundings."}, "209548": {"image_id": 209548, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.3468729675368036, "Bleu_3": 0.26590120932469696, "Bleu_4": 0.2065285636291294, "METEOR": 0.34616156667528364, "ROUGE_L": 0.4520378756689996, "CIDEr": 0.0008220927666314774, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person cutting a cake with a knife. The cake is white and has pink roses on it. There are several bottles of alcohol on the table next to the cake."}, "272242": {"image_id": 272242, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.3073547405967436, "Bleu_3": 0.2337129106282684, "Bleu_4": 0.16319013503559496, "METEOR": 0.303225810761526, "ROUGE_L": 0.3756735950731332, "CIDEr": 2.2631679886659108e-05, "SPICE": {"All": {"pr": 0.36, "re": 0.3, "f": 0.3272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "A laptop computer is sitting on a table in front of a couch. There are two cups of soda on the table next to the laptop. The room has a red carpet and a red rug on the floor."}, "486": {"image_id": 486, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.1311312829167715, "Bleu_4": 0.08413498161249076, "METEOR": 0.20314061465341657, "ROUGE_L": 0.3028368794326241, "CIDEr": 1.670668421084064e-07, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.13333333333333333, "f": 0.17777777777777776, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a kitchen with a large wooden table in the center of the room. There are several pots and pans hanging from the ceiling, and a stove and oven on the counter. The walls are painted white and there are windows on one side of the room."}, "120162": {"image_id": 120162, "Bleu_1": 0.29032258064047867, "Bleu_2": 0.2288083308050331, "Bleu_3": 0.17363924490408922, "Bleu_4": 0.11541982525042732, "METEOR": 0.2437406252087123, "ROUGE_L": 0.27511901779002756, "CIDEr": 9.147139469209857e-13, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.4117647058823529, "f": 0.3255813953488372, "fn": 10.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This image shows a group of people playing in the ocean on a sunny day. There are several surfers in the water, and some people are standing on the beach watching them. The sky is clear and blue, with a few clouds scattered across it. The waves are crashing against the shore, creating a white foam on the surface of the water."}, "316522": {"image_id": 316522, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.18516401995076925, "Bleu_3": 0.08939035350783202, "Bleu_4": 1.1103081472064331e-05, "METEOR": 0.250735214968053, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.186547733086499e-10, "SPICE": {"All": {"pr": 0.3125, "re": 0.3125, "f": 0.3125, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a blue and white bus parked on the side of a street in front of a large brick building. The bus has the words \"journey\" written on the side in red letters. There are no people in the image, but there are trees and grass growing around it."}, "292647": {"image_id": 292647, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.07446639778133946, "Bleu_4": 9.43994412057466e-06, "METEOR": 0.18293244944954828, "ROUGE_L": 0.207506520013607, "CIDEr": 3.11567932872706e-12, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.1388888888888889, "f": 0.20833333333333334, "fn": 31.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.15384615384615385, "f": 0.25, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is holding onto the sail of a windsurf board and standing on the board as they ride the wave. The sky is blue and there are clouds in the background. The water is choppy and there are whitecaps on the surface."}, "413260": {"image_id": 413260, "Bleu_1": 0.8749999997812503, "Bleu_2": 0.7071067810034577, "Bleu_3": 0.5503212080006054, "Bleu_4": 0.42728700627504257, "METEOR": 0.28660179721339535, "ROUGE_L": 0.625, "CIDEr": 1.2926427462676053, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}}, "caption": "Two white sheep grazing in a green field."}, "262162": {"image_id": 262162, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.3162277660039253, "Bleu_3": 0.20563674453180716, "Bleu_4": 2.5073783388398014e-05, "METEOR": 0.27394050677466325, "ROUGE_L": 0.3715736040609137, "CIDEr": 0.06454881713864448, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a bedroom with a bed, desk, and chair. The walls are painted white and there are windows on one side of the room."}, "72753": {"image_id": 72753, "Bleu_1": 0.382352941165225, "Bleu_2": 0.28478969316957436, "Bleu_3": 0.17178141833809604, "Bleu_4": 2.010905744323401e-05, "METEOR": 0.24732081107461423, "ROUGE_L": 0.29373996789727125, "CIDEr": 0.00043314722382039586, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.15, "f": 0.14285714285714282, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a teddy bear sitting on a red tablecloth with a white blanket on top of it. There is a small Christmas tree in the background with lights and ornaments on it."}, "51880": {"image_id": 51880, "Bleu_1": 0.16326530611911708, "Bleu_2": 0.13041013273663615, "Bleu_3": 7.125930877508603e-07, "Bleu_4": 1.6747182232396402e-09, "METEOR": 0.1804990921660458, "ROUGE_L": 0.23303196230739842, "CIDEr": 1.9386333405232317e-10, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.24, "f": 0.23529411764705882, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a cat sitting on the hood of a white van. The cat is looking up at the driver's side mirror. There are several other cats in the background, also looking at the mirror. The image appears to be taken in a parking lot or garage."}, "445055": {"image_id": 445055, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 8.383535347317198e-07, "Bleu_4": 1.8260027717725488e-09, "METEOR": 0.1698078025798903, "ROUGE_L": 0.2330786026200873, "CIDEr": 5.592196449854048e-11, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.05555555555555555, "f": 0.06349206349206349, "fn": 34.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.13333333333333333, "f": 0.14814814814814814, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man and a child standing on the beach, watching a surfer ride a wave into the ocean. The man is wearing a wetsuit and holding a surfboard, while the child is wearing a life jacket and standing on the sand. The sky is cloudy and there are waves crashing against the shore."}, "208971": {"image_id": 208971, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1836795895878896, "Bleu_3": 0.1221752840525873, "Bleu_4": 0.08436491880404812, "METEOR": 0.20562950302229566, "ROUGE_L": 0.3519835136527563, "CIDEr": 9.869267350016975e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.32, "f": 0.39024390243902435, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 8.0}, "Relation": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is a bedroom with a large white bed and a wooden headboard. There are two lamps on the nightstands and a large window with white curtains. The walls are painted white and there is a large wooden floor."}, "232357": {"image_id": 232357, "Bleu_1": 0.15873015872763924, "Bleu_2": 0.0876384136735342, "Bleu_3": 0.05012099995186688, "Bleu_4": 6.76825920497433e-06, "METEOR": 0.10269775933585364, "ROUGE_L": 0.15762273901808782, "CIDEr": 3.1780859526282478e-18, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.13333333333333333, "f": 0.17777777777777776, "fn": 26.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a photograph of a room with a window on the left side and a door on the right side. There are two chairs in front of the window, and a table with a lamp on it in the center of the room. The walls are painted a light pink color, and there is a white ceiling fan hanging from the ceiling."}, "356323": {"image_id": 356323, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 8.411954328528159e-07, "Bleu_4": 1.8864626675179613e-09, "METEOR": 0.23518584876748014, "ROUGE_L": 0.22235722964763066, "CIDEr": 4.0428834217754985e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.1935483870967742, "f": 0.21818181818181817, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "This is an image of a dog standing in a bathtub with its head out of the water. The dog has a brown and white coat and is looking up at the person holding its paw. The background is a white tile wall with a shower curtain hanging from it."}, "112915": {"image_id": 112915, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.07284313590699668, "Bleu_3": 4.799308605281424e-07, "Bleu_4": 1.2383960073346406e-09, "METEOR": 0.18225563409376994, "ROUGE_L": 0.15155279503105593, "CIDEr": 2.0520647255628727e-10, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a small room with concrete walls and a wooden floor. There are several pieces of artwork on the walls, including a painting of a man playing a guitar and a sculpture of a woman holding a mirror. The room also has a sink and stove in the corner."}, "365068": {"image_id": 365068, "Bleu_1": 0.3584905660309719, "Bleu_2": 0.28762578493487434, "Bleu_3": 0.2349949240730427, "Bleu_4": 0.19865027594414789, "METEOR": 0.26124894921514075, "ROUGE_L": 0.36686714051394204, "CIDEr": 6.561151614264913e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a black and white photograph of three people sitting on a bench in front of a building. One person is reading a newspaper, while the other two are looking at something else. The building appears to be an old-fashioned general store with a sign that reads \"general store\" in the window."}, "341094": {"image_id": 341094, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.20159462811746034, "Bleu_3": 1.1460354422397831e-06, "Bleu_4": 2.758387014275457e-09, "METEOR": 0.2505404266223129, "ROUGE_L": 0.29075309818875117, "CIDEr": 0.01679096044822371, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14814814814814814, "f": 0.17391304347826086, "fn": 23.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A bear statue stands in front of a car with an 'Entering' sign on it, surrounded by trees and foliage.\""}, "492605": {"image_id": 492605, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.08433490103776005, "Bleu_3": 5.824214923868025e-07, "Bleu_4": 1.5413846635645837e-09, "METEOR": 0.1350597359554155, "ROUGE_L": 0.23282442748091606, "CIDEr": 5.2436682078707014e-06, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.125, "f": 0.17777777777777778, "fn": 28.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of men playing baseball on a field with a fence in the background. One man is throwing a ball while another is catching it. There are trees and buildings visible in the background."}, "253227": {"image_id": 253227, "Bleu_1": 0.5333333333155555, "Bleu_2": 0.30323921742127913, "Bleu_3": 1.4864064036709171e-06, "Bleu_4": 3.320949218222552e-09, "METEOR": 0.3191011137588551, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.005449822518581315, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.23529411764705882, "f": 0.19999999999999998, "fn": 13.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A black and white clock tower with a bird perched on top of it. The clock has Roman numerals and hands, and the bird is looking down at the clock."}, "547435": {"image_id": 547435, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 6.923138992163507e-07, "Bleu_4": 1.6131630585021e-09, "METEOR": 0.1974432599453683, "ROUGE_L": 0.21131639722863746, "CIDEr": 3.215335842977391e-11, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2857142857142857, "f": 0.2790697674418604, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a street with two cars parked on the side of the road. One car is a white truck with a red and blue striped canopy, while the other is a black car with a white stripe down the side. There are also some trees and buildings in the background."}, "344415": {"image_id": 344415, "Bleu_1": 0.38095238093424044, "Bleu_2": 0.19518001458018006, "Bleu_3": 1.260972737339982e-06, "Bleu_4": 3.2487115055976186e-09, "METEOR": 0.22091601253434617, "ROUGE_L": 0.3001230012300123, "CIDEr": 0.03723986454539112, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A train station in the city with tall buildings in the background.\""}, "22192": {"image_id": 22192, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.33733233382016453, "Bleu_3": 0.2899811182739286, "Bleu_4": 0.22814799836309907, "METEOR": 0.3785971326524988, "ROUGE_L": 0.3846846846846847, "CIDEr": 0.0041600486692288195, "SPICE": {"All": {"pr": 0.3, "re": 0.14285714285714285, "f": 0.19354838709677416, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "A dog is sitting on top of a pile of clothes on the floor. The dog is looking up at the camera with its tongue hanging out of its mouth."}, "66960": {"image_id": 66960, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1922322627296484, "Bleu_3": 0.1642900520962339, "Bleu_4": 0.14584848812974716, "METEOR": 0.2537402406018903, "ROUGE_L": 0.2610024449877751, "CIDEr": 2.6490460910713884e-11, "SPICE": {"All": {"pr": 0.05, "re": 0.043478260869565216, "f": 0.046511627906976744, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows three dogs lying on a bed in a room with white walls and a window. One of the dogs is brown and black, another is black and white, and the third is brown and white. They are all looking at the camera with their heads tilted to the side."}, "38693": {"image_id": 38693, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.22041550750546754, "Bleu_3": 0.17382577992832773, "Bleu_4": 0.1306975702128877, "METEOR": 0.2982562927163987, "ROUGE_L": 0.38181818181818183, "CIDEr": 8.589803775493215e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.26666666666666666, "f": 0.2580645161290323, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a wooden table outside, holding a hot dog in his hand. There are other people standing around him, looking at him. The sky is blue and there are trees in the background."}, "215596": {"image_id": 215596, "Bleu_1": 0.4130434782518904, "Bleu_2": 0.2709796148930639, "Bleu_3": 0.14944573335897496, "Bleu_4": 0.09386323681576346, "METEOR": 0.22486608574854303, "ROUGE_L": 0.2794502617801047, "CIDEr": 7.831954650964076e-06, "SPICE": {"All": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a bathroom with a large bathtub in the center of the room. There are two windows on either side of the bathtub, and a chandelier hanging from the ceiling. The walls are painted a light beige color, and there is a white marble floor."}, "493321": {"image_id": 493321, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.279424548087313, "Bleu_3": 0.23743101011446854, "Bleu_4": 0.18538033580953026, "METEOR": 0.3544260561379818, "ROUGE_L": 0.3797665369649806, "CIDEr": 0.00015964212478803747, "SPICE": {"All": {"pr": 0.15, "re": 0.15, "f": 0.15, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a couple sitting on a bench under an umbrella in the park. They are looking at each other and smiling. The trees are green and there is a small stream running through the park."}, "559884": {"image_id": 559884, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.1842190315423256, "Bleu_3": 0.08788194533129833, "Bleu_4": 1.0848650703059748e-05, "METEOR": 0.21944090251932147, "ROUGE_L": 0.25722891566265055, "CIDEr": 5.853281557460421e-11, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08695652173913043, "f": 0.0909090909090909, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "This is an image of a construction worker wearing a hard hat and safety vest standing next to a stop sign on the side of the road. The worker is looking down at the sign and appears to be checking it. The background is a blue sky with some clouds in it."}, "212080": {"image_id": 212080, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.2553769592167526, "Bleu_3": 0.14365262974612145, "Bleu_4": 1.938341802259304e-05, "METEOR": 0.10999090737160053, "ROUGE_L": 0.25416666666666665, "CIDEr": 0.016373039099057428, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.20833333333333334, "f": 0.25641025641025644, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people standing around a table with drinks and snacks, smiling and chatting.\""}, "511453": {"image_id": 511453, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4577377081947216, "Bleu_3": 0.35332952049108113, "Bleu_4": 0.22249323813615754, "METEOR": 0.35138917666010155, "ROUGE_L": 0.5514124293785311, "CIDEr": 0.5192283013429567, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is the caption for the image:\n\n\"A plate of pizza with cheese, pepperoni, and french fries on a table\""}, "340511": {"image_id": 340511, "Bleu_1": 0.3999999999800001, "Bleu_2": 0.25131234496212107, "Bleu_3": 0.15195618441138903, "Bleu_4": 2.1314568969954795e-05, "METEOR": 0.2554383219370725, "ROUGE_L": 0.4644670050761421, "CIDEr": 0.08562742621844055, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a kitchen with a stove, oven, and refrigerator. There is also a table and chairs in the room."}, "288765": {"image_id": 288765, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.20083857809555095, "Bleu_3": 0.13471111906856947, "Bleu_4": 0.09348998462305054, "METEOR": 0.21716563436479833, "ROUGE_L": 0.2998525315418646, "CIDEr": 0.00021216727880541347, "SPICE": {"All": {"pr": 0.1, "re": 0.21428571428571427, "f": 0.13636363636363638, "fn": 11.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.5, "f": 0.3, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a person holding a hamburger in their hand. The hamburger has lettuce, tomato, and cheese on it. There is also a small container of ketchup on the table next to the hamburger."}, "457037": {"image_id": 457037, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.3311896883635246, "Bleu_3": 0.23610849866565936, "Bleu_4": 0.15303152436388562, "METEOR": 0.2175345709399585, "ROUGE_L": 0.38995433789954337, "CIDEr": 0.022941684667865322, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.5, "f": 0.3414634146341463, "fn": 7.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "This is a hotel room with a large bed, a television, and a desk. The walls are painted green and there is a large window with curtains."}, "408955": {"image_id": 408955, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.3459163477621225, "Bleu_3": 0.2675186426257877, "Bleu_4": 0.19985739740594977, "METEOR": 0.25290060640915685, "ROUGE_L": 0.37917637917637914, "CIDEr": 0.27089936036061446, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a living room with a couch, coffee table, and television. The walls are painted white and there are windows on either side of the room."}, "374545": {"image_id": 374545, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.2896048475706757, "Bleu_3": 0.14247474403149546, "Bleu_4": 1.792725954943498e-05, "METEOR": 0.2634978980548692, "ROUGE_L": 0.35376967688483846, "CIDEr": 0.004809126948457905, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.15384615384615385, "f": 0.15384615384615385, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a park with a large tree in the center, surrounded by people sitting on benches and walking on the grass. There is a flag flying in the background."}, "293390": {"image_id": 293390, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.15927956195690762, "Bleu_3": 8.453247893683395e-07, "Bleu_4": 1.959168274713403e-09, "METEOR": 0.1877508212513794, "ROUGE_L": 0.2506849315068493, "CIDEr": 8.295128801863877e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.11538461538461539, "f": 0.11764705882352941, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2727272727272727, "f": 0.23076923076923075, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is an image of a bathroom with a wooden vanity and a sink. The walls are made of wood and there are two windows on the left side of the room. There is also a mirror hanging on the wall above the sink."}, "158994": {"image_id": 158994, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.1344109151128908, "Bleu_4": 0.10192489527760022, "METEOR": 0.21082710598013463, "ROUGE_L": 0.3091216216216216, "CIDEr": 1.559035983483994e-07, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.14285714285714285, "f": 0.12000000000000001, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of buses parked on the side of a street. They are all white with red and blue stripes on the sides and have the words \"express\" written on the front. There is a building in the background with a clock tower on top."}, "486694": {"image_id": 486694, "Bleu_1": 0.5624999999648439, "Bleu_2": 0.2738612787348963, "Bleu_3": 1.7497570118210083e-06, "Bleu_4": 4.505546423100306e-09, "METEOR": 0.23307926249267655, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.1946702282546034, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.17391304347826086, "f": 0.15999999999999998, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a blue and yellow train traveling down the tracks on a sunny day."}, "451798": {"image_id": 451798, "Bleu_1": 0.45454545453168055, "Bleu_2": 0.2919371040515864, "Bleu_3": 0.17650172911257067, "Bleu_4": 2.06909966109537e-05, "METEOR": 0.22947693403110858, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.0037029314874733755, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.06451612903225806, "f": 0.07547169811320754, "fn": 29.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.15384615384615385, "f": 0.17391304347826086, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a photo of a room with a red wall, a white ceiling, and a wooden floor. There are several ties hanging on the wall, and a hat rack in the corner."}, "117407": {"image_id": 117407, "Bleu_1": 0.4999999999687501, "Bleu_2": 0.2581988897304859, "Bleu_3": 1.6823908656274826e-06, "Bleu_4": 4.374811430921123e-09, "METEOR": 0.26111543371544643, "ROUGE_L": 0.4639959432048682, "CIDEr": 0.355695762552001, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2777777777777778, "f": 0.28571428571428575, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.375, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A cat sits on the edge of a wooden boat in front of a blue building."}, "25560": {"image_id": 25560, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.22247460415230486, "Bleu_3": 0.17920665961257645, "Bleu_4": 0.12866510680665702, "METEOR": 0.2688981887053912, "ROUGE_L": 0.35260115606936415, "CIDEr": 3.606182283217131e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.10810810810810811, "f": 0.14285714285714288, "fn": 33.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "A cat is sitting on top of a wooden shelf in front of a television. The cat is looking at the television with its ears perked up and its tail twitching. There are several books and other objects on the shelf next to the cat."}, "387173": {"image_id": 387173, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.1961161351236371, "Bleu_3": 1.4743993654284733e-06, "Bleu_4": 4.131551590773095e-09, "METEOR": 0.17477676909842196, "ROUGE_L": 0.3620178041543027, "CIDEr": 0.10646986087075136, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13043478260869565, "f": 0.14285714285714288, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A man is kayaking on a body of water with boats in the background."}, "345998": {"image_id": 345998, "Bleu_1": 0.1475409836041387, "Bleu_2": 0.04958847036722681, "Bleu_3": 3.467127431742759e-07, "Bleu_4": 9.207046884785164e-10, "METEOR": 0.15306830003574398, "ROUGE_L": 0.19416445623342174, "CIDEr": 6.97569609615736e-17, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.23809523809523808, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a young girl riding on the back of a black horse in a fenced area. The horse is wearing a saddle and bridle, and the girl is holding onto the reins with her hands. The fence in the background is made of wooden posts with horizontal rails. The sky is cloudy and there are trees in the background."}, "341041": {"image_id": 341041, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.19069251784568234, "Bleu_3": 0.08765119647604923, "Bleu_4": 1.0616941372977245e-05, "METEOR": 0.24130200004002536, "ROUGE_L": 0.29967248908296945, "CIDEr": 6.154862771725713e-12, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.7142857142857143, "f": 0.6250000000000001, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a young boy standing next to a skateboard ramp in a park. He is wearing a white shirt and blue shorts, and has his hands on the handlebars of the skateboard. The ramp is made of concrete and has a smooth surface. There are trees and grass in the background of the image."}, "526711": {"image_id": 526711, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.20597146021314577, "Bleu_3": 0.09955166929523299, "Bleu_4": 1.2380098139763797e-05, "METEOR": 0.21981214532823923, "ROUGE_L": 0.21048999309868874, "CIDEr": 2.3816245412777755e-08, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.19230769230769232, "f": 0.18867924528301885, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3076923076923077, "f": 0.33333333333333337, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a large airplane parked on the runway at an airport. The plane has the words \"white house\" written on the side in bold black letters. In the background, there is a city skyline with tall buildings and a river running through it."}, "90476": {"image_id": 90476, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.12451456127000796, "Bleu_3": 7.231340467136466e-07, "Bleu_4": 1.7534731062750036e-09, "METEOR": 0.20938944088649886, "ROUGE_L": 0.24881033310673015, "CIDEr": 4.6892346183035466e-07, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.25, "f": 0.18604651162790697, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a small fishing village with several boats docked at the shore. The boats are painted in different colors and have nets and ropes hanging from them. There are also several people standing on the shore, looking out at the water."}, "572427": {"image_id": 572427, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.27490643727245323, "Bleu_3": 0.18299102222839972, "Bleu_4": 2.0311720520162125e-05, "METEOR": 0.2572820829434868, "ROUGE_L": 0.3843730308758664, "CIDEr": 0.00042749017307567574, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.1111111111111111, "f": 0.1212121212121212, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a stop sign on the side of a road in a residential area. The sign is red and white with the words \"stop\" written in black letters. There are trees and houses visible in the background."}, "350133": {"image_id": 350133, "Bleu_1": 0.6428571428112246, "Bleu_2": 0.5447047793615183, "Bleu_3": 0.46245240143714167, "Bleu_4": 0.3661926362704101, "METEOR": 0.40844249993694226, "ROUGE_L": 0.6335311572700296, "CIDEr": 1.5903625546569653, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2727272727272727, "f": 0.24489795918367346, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "A black cat laying on a wooden bench in front of a red barn."}, "446460": {"image_id": 446460, "Bleu_1": 0.3207547169750801, "Bleu_2": 0.1756183353427233, "Bleu_3": 0.08456484271609976, "Bleu_4": 1.0486966556129234e-05, "METEOR": 0.18429327052893035, "ROUGE_L": 0.2083096186681844, "CIDEr": 4.961231429123219e-11, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.26666666666666666, "f": 0.30769230769230765, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is an image of a large truck driving down the road. The truck has a white and red paint job with a large dump bed in the back. There are two people standing next to the truck, one is holding a camera and the other is looking at something on their phone."}, "95249": {"image_id": 95249, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.21442250696028833, "Bleu_3": 0.14864064036709163, "Bleu_4": 0.10501763523338822, "METEOR": 0.2710714757925212, "ROUGE_L": 0.34078212290502796, "CIDEr": 0.0014487797363226264, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.16129032258064516, "f": 0.20408163265306123, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a man sitting on a couch eating a hamburger from a box. There are other people in the room, but they are not visible in the image."}, "233961": {"image_id": 233961, "Bleu_1": 0.29999999998500004, "Bleu_2": 0.1777046633186087, "Bleu_3": 1.2060770349385636e-06, "Bleu_4": 3.1872714731477548e-09, "METEOR": 0.12144468574869835, "ROUGE_L": 0.2837209302325582, "CIDEr": 0.038542903319986124, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"Surfers ride the waves in a river during a sunny day\""}, "520787": {"image_id": 520787, "Bleu_1": 0.6666666666222223, "Bleu_2": 0.43643578044185, "Bleu_3": 0.2446991428435391, "Bleu_4": 3.324137843193063e-05, "METEOR": 0.3257253463171755, "ROUGE_L": 0.3490701001430615, "CIDEr": 1.2072161294510368, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "There is a plate of pizza on the table with slices of bread and cheese."}, "349199": {"image_id": 349199, "Bleu_1": 0.5499999999725, "Bleu_2": 0.41675437671185933, "Bleu_3": 0.3070457069121754, "Bleu_4": 0.2415725260884915, "METEOR": 0.3909442908800292, "ROUGE_L": 0.4965116279069768, "CIDEr": 0.27605497430054216, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.07407407407407407, "f": 0.07547169811320754, "fn": 25.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people enjoying the beach on a sunny day.\""}, "437119": {"image_id": 437119, "Bleu_1": 0.26785714285235973, "Bleu_2": 0.22068370737221082, "Bleu_3": 0.15336829563872276, "Bleu_4": 0.09083071358441841, "METEOR": 0.2203730447792053, "ROUGE_L": 0.30221767851525644, "CIDEr": 3.754388781008265e-12, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a small dog lying on a bed next to a laptop. The dog is brown and white with a black collar around its neck. The bed has a pattern of black and white stripes on it. There is a window in the background with curtains open, revealing a view of the sky outside."}, "579073": {"image_id": 579073, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.1642880193591135, "Bleu_3": 9.001951896101368e-07, "Bleu_4": 2.121665383933931e-09, "METEOR": 0.16915491320109555, "ROUGE_L": 0.2741573033707865, "CIDEr": 1.1247670441508452e-05, "SPICE": {"All": {"pr": 0.75, "re": 0.18181818181818182, "f": 0.2926829268292683, "fn": 27.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.13333333333333333, "f": 0.2105263157894737, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "The image shows a man standing in front of a wall with a basketball hoop on it. He is wearing a white shirt and black shorts, and has a basketball in his hand. The background is a beige color."}, "260447": {"image_id": 260447, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.05870362244443319, "Bleu_3": 3.9718152379234885e-07, "Bleu_4": 1.0378709071282543e-09, "METEOR": 0.14029871238533945, "ROUGE_L": 0.13950829045168667, "CIDEr": 2.6098033330832207e-14, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a subway train traveling along the tracks at night. The train is painted in red and white, with the words \"Subway\" written on the side. There are people standing on the platform, looking at the train as it passes by. The sky is cloudy and there are some trees in the background."}, "557517": {"image_id": 557517, "Bleu_1": 0.3333333333263889, "Bleu_2": 0.2062842492474154, "Bleu_3": 0.12276317177262669, "Bleu_4": 1.4239605151902859e-05, "METEOR": 0.2771583511514101, "ROUGE_L": 0.27371794871794874, "CIDEr": 4.4549549343019125e-08, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.11538461538461539, "f": 0.12499999999999997, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person standing in a grassy field with a large red kite flying overhead. The person is holding onto the kite and appears to be controlling it as it flies through the air. There are trees and buildings visible in the background of the image."}, "36990": {"image_id": 36990, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.2243088616326247, "Bleu_3": 0.1570060918669648, "Bleu_4": 0.11099472319754804, "METEOR": 0.2394793240353187, "ROUGE_L": 0.24710648148148148, "CIDEr": 7.409763568724308e-12, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11764705882352941, "f": 0.12903225806451615, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a red school bus parked on the side of a dirt road in front of a group of houses. The bus has the words \"School Bus\" written on the side in white letters. There are people standing around the bus, looking at it. The sky is clear and blue."}, "28998": {"image_id": 28998, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.24671758189216153, "Bleu_3": 0.17687610721625666, "Bleu_4": 0.10650862172207926, "METEOR": 0.2894967648620154, "ROUGE_L": 0.3084702907711757, "CIDEr": 4.001858715046792e-08, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.2727272727272727, "f": 0.22641509433962262, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a young boy holding a piece of fruit in his hand. He is standing in front of a table with several other fruits and vegetables on it. There are people in the background, looking at the boy and the food he is holding."}, "242570": {"image_id": 242570, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.16903085094228823, "Bleu_3": 0.08411954328528157, "Bleu_4": 1.0608359163741716e-05, "METEOR": 0.2081731543137176, "ROUGE_L": 0.1852976913730255, "CIDEr": 1.990159477129318e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.12121212121212122, "f": 0.1568627450980392, "fn": 29.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A white truck with the words \"TOYOTA\" written on the side is parked on a dirt road next to a field. The truck has a black and white striped canvas top and is parked in front of a small wooden fence. There are no other vehicles or people in sight."}, "55780": {"image_id": 55780, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.286972021583456, "Bleu_3": 0.23194146337631918, "Bleu_4": 0.1849381946528296, "METEOR": 0.309541649554096, "ROUGE_L": 0.4070058381984987, "CIDEr": 0.00042088435082162365, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a young girl holding a small dog on a leash while standing on a balcony with her parents. The balcony is surrounded by trees and there are other people in the background."}, "402234": {"image_id": 402234, "Bleu_1": 0.340909090901343, "Bleu_2": 0.25184310024886714, "Bleu_3": 0.1654667332087998, "Bleu_4": 0.10252671801486271, "METEOR": 0.30633736223742986, "ROUGE_L": 0.285427807486631, "CIDEr": 1.3369879736884377e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows an elephant standing in a grassy field with its baby next to it. The elephant is looking down at the ground while the baby is looking up at its mother. There are trees and bushes in the background of the image."}, "23821": {"image_id": 23821, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.1650868521781302, "Bleu_3": 0.10158210507506187, "Bleu_4": 0.06733182132555685, "METEOR": 0.24763481175750124, "ROUGE_L": 0.24970760233918127, "CIDEr": 9.768217833059706e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11538461538461539, "f": 0.12765957446808512, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe image shows a red motorcycle parked on the side of a city street. The motorcycle has a sleek design and is parked next to a row of parked cars. The street is lined with tall buildings and there are pedestrians walking on the sidewalk."}, "468501": {"image_id": 468501, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.0645198590415134, "Bleu_3": 4.522633916831482e-07, "Bleu_4": 1.2041494936393691e-09, "METEOR": 0.08651133918542545, "ROUGE_L": 0.11387678904791537, "CIDEr": 3.7628873179099057e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12903225806451613, "f": 0.14545454545454548, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a living room with a fireplace and a television. There are two people in the room, one is sitting on the couch and the other is standing by the fireplace. The walls are painted white and there are windows on either side of the room."}, "466981": {"image_id": 466981, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2662233302496238, "Bleu_3": 0.21808202564524934, "Bleu_4": 0.17945885988638283, "METEOR": 0.26721552613895605, "ROUGE_L": 0.3400696864111499, "CIDEr": 0.00011268582601215078, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 24.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.25, "f": 0.27586206896551724, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This image shows a man standing next to a blue car with the hood up. He is wearing a black jacket and gloves, and appears to be checking something under the hood. The car has a flat tire on the front left side."}, "563295": {"image_id": 563295, "Bleu_1": 0.6428571428112246, "Bleu_2": 0.31448545099324837, "Bleu_3": 0.20199469188293792, "Bleu_4": 2.9420957078790958e-05, "METEOR": 0.332701238650443, "ROUGE_L": 0.543026706231454, "CIDEr": 0.7180022194876252, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a small airplane flying in the sky with a cloudy background."}, "175251": {"image_id": 175251, "Bleu_1": 0.4102564102458909, "Bleu_2": 0.3599370165233275, "Bleu_3": 0.27593122591742014, "Bleu_4": 0.1848342763642756, "METEOR": 0.3396632771986857, "ROUGE_L": 0.4226327944572749, "CIDEr": 0.0008150294502776622, "SPICE": {"All": {"pr": 0.7777777777777778, "re": 0.3333333333333333, "f": 0.4666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}, "Relation": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.8, "f": 0.8000000000000002, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a young boy sitting in a bathtub, brushing his teeth with a toothbrush. He is smiling and has a toothbrush in his hand. The bathroom is well lit and there are towels hanging on the rack."}, "114634": {"image_id": 114634, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.22288685594608834, "Bleu_3": 0.1516298425242195, "Bleu_4": 0.08882628649241174, "METEOR": 0.2713874116484685, "ROUGE_L": 0.293425975414217, "CIDEr": 1.3895354742982609e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 20.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "A group of people are standing on a sand dune, looking up at a kite flying in the sky. The kite is red and white, with a long tail that trails behind it. The people are all wearing sunglasses and hats to protect themselves from the sun. In the background, there is a blue sky with some white clouds."}, "32947": {"image_id": 32947, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.16658955971162087, "Bleu_3": 8.511922922355496e-07, "Bleu_4": 1.9348958476953622e-09, "METEOR": 0.2630793210654184, "ROUGE_L": 0.31063017186505404, "CIDEr": 6.398429036327799e-09, "SPICE": {"All": {"pr": 0.7, "re": 0.21875, "f": 0.3333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5555555555555556, "f": 0.7142857142857143, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "The image shows a woman standing in front of a bathroom sink, wearing a blue dress and white apron. She is holding a toilet brush and cleaning the sink with soap and water. The walls are painted white and there is a green rug on the floor."}, "458510": {"image_id": 458510, "Bleu_1": 0.4324324324207451, "Bleu_2": 0.28997255745928074, "Bleu_3": 0.1687427994150899, "Bleu_4": 0.10903080234359379, "METEOR": 0.293950561244508, "ROUGE_L": 0.3596168017686072, "CIDEr": 0.00026277027718129707, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.21739130434782608, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is an image of a plate of food with beans, rice, and cheese on it. There are also two forks and a knife on the plate. The background is a wooden table with a white tablecloth."}, "429074": {"image_id": 429074, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.36037498506145293, "Bleu_3": 1.8656339075280162e-06, "Bleu_4": 4.299633317430035e-09, "METEOR": 0.22138364779874214, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.07051908665512932, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.16666666666666666, "f": 0.12903225806451615, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are white and there is black tile on the floor."}, "483179": {"image_id": 483179, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.15755219780890306, "Bleu_3": 0.102574725922902, "Bleu_4": 0.06998051681299158, "METEOR": 0.2032350390174619, "ROUGE_L": 0.2401574803149606, "CIDEr": 4.1316113849340473e-10, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.11538461538461539, "f": 0.12499999999999997, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of tile. There is a wooden vanity with a mirror above it and a towel rack on the wall. The shower has a glass door and a curtain."}, "386227": {"image_id": 386227, "Bleu_1": 0.6428571428112246, "Bleu_2": 0.49724515806196345, "Bleu_3": 0.3953912414701941, "Bleu_4": 0.2737928561695718, "METEOR": 0.2747132981169992, "ROUGE_L": 0.49539794260963715, "CIDEr": 0.8751032389711153, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "A group of sheep grazing in a field with a fence in the background."}, "403315": {"image_id": 403315, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.4696682182853713, "Bleu_3": 0.3533492012932546, "Bleu_4": 0.23693055762206497, "METEOR": 0.34333892505818947, "ROUGE_L": 0.6686967113276492, "CIDEr": 1.0150194845613996, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.25, "f": 0.24390243902439024, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "A black and white dog is running through a park with a red ball in its mouth."}, "77648": {"image_id": 77648, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.12903971808302675, "Bleu_3": 0.09045267833662955, "Bleu_4": 0.06404023311330644, "METEOR": 0.26733763178293873, "ROUGE_L": 0.2781758957654723, "CIDEr": 1.3135101870725535e-08, "SPICE": {"All": {"pr": 0.125, "re": 0.08823529411764706, "f": 0.10344827586206896, "fn": 31.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a living room with a large window that looks out onto a patio. There are two couches in the room, one brown and one black, and a coffee table in front of them. The walls are painted white and there are curtains on the windows."}, "248919": {"image_id": 248919, "Bleu_1": 0.5652173912797732, "Bleu_2": 0.32057261019905153, "Bleu_3": 0.16977660468584396, "Bleu_4": 2.2240824547977345e-05, "METEOR": 0.24380295625356424, "ROUGE_L": 0.3534183082271147, "CIDEr": 0.05318574566019357, "SPICE": {"All": {"pr": 0.2, "re": 0.13333333333333333, "f": 0.16, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is a kitchen with wooden cabinets and a white refrigerator. There is a table with chairs in the center of the room."}, "386661": {"image_id": 386661, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.09550351820629131, "Bleu_4": 1.2224986162514046e-05, "METEOR": 0.2407941906641232, "ROUGE_L": 0.22197962154294032, "CIDEr": 3.0010943717775873e-07, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.16129032258064516, "f": 0.17241379310344826, "fn": 26.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a beach with wooden benches and umbrellas set up on the sand. The sky is clear and blue, with a few clouds visible in the distance. The ocean is visible in the background, with waves crashing against the shore."}, "435308": {"image_id": 435308, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 7.926525909642893e-07, "Bleu_4": 1.7765182019941675e-09, "METEOR": 0.18993858337598238, "ROUGE_L": 0.2507339988256019, "CIDEr": 1.4913221432009429e-09, "SPICE": {"All": {"pr": 0.1, "re": 0.05405405405405406, "f": 0.07017543859649122, "fn": 35.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.13333333333333333, "f": 0.1739130434782609, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a person performing a trick on a jet ski in the middle of a lake. The person is wearing a life jacket and has their arms outstretched as they jump off the back of the boat. The water is calm and clear, with trees and houses visible in the background."}, "12570": {"image_id": 12570, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.12183925606190008, "Bleu_3": 0.07375490665399664, "Bleu_4": 1.0274662450505877e-05, "METEOR": 0.22475932621105488, "ROUGE_L": 0.24148851939825808, "CIDEr": 3.751704181087508e-05, "SPICE": {"All": {"pr": 0.08, "re": 0.09523809523809523, "f": 0.08695652173913043, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a kitchen with a table and chairs in it. There are several pots and pans on the stove, and a blender on the counter. The walls are painted white and there are some posters on the wall."}, "336232": {"image_id": 336232, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.2431867285489846, "Bleu_3": 0.18289464893778182, "Bleu_4": 0.1445835022636036, "METEOR": 0.21673382422739856, "ROUGE_L": 0.3125533731853117, "CIDEr": 0.003232763405443474, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.08, "f": 0.10526315789473685, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a busy street with cars, buses, and pedestrians. There are buildings on either side of the road, and trees and other vegetation can be seen in the background."}, "412584": {"image_id": 412584, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.17287295181501847, "Bleu_3": 1.0219555847537585e-06, "Bleu_4": 2.507454579933253e-09, "METEOR": 0.17094017094017097, "ROUGE_L": 0.21981981981981977, "CIDEr": 0.0014276668963504099, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a snowy street with cars parked on the side of the road. There are traffic lights at the intersection and people walking in the background."}, "264683": {"image_id": 264683, "Bleu_1": 0.10344827586028539, "Bleu_2": 1.3471755760125499e-09, "Bleu_3": 3.188257999593864e-12, "Bleu_4": 1.5580249967419036e-13, "METEOR": 0.09682135218907807, "ROUGE_L": 0.09723698193411263, "CIDEr": 2.3810861217477004e-16, "SPICE": {"All": {"pr": 0.12, "re": 0.1111111111111111, "f": 0.11538461538461538, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"The Air and Space Museum is filled with various aircraft, including a Boeing 747 jumbo jet, a Lockheed SR-71 Blackbird supersonic spy plane, and a North American XB-70 Valkyrie supersonic bomber. The museum also features interactive exhibits and educational displays that explore the history of aviation and space exploration.\""}, "172702": {"image_id": 172702, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.16222142112654833, "Bleu_3": 0.1124643536532053, "Bleu_4": 0.07928399829959643, "METEOR": 0.19496720898870426, "ROUGE_L": 0.2669584245076586, "CIDEr": 8.435632496644658e-06, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.17857142857142858, "f": 0.2380952380952381, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"Warring Rd\" written in Chinese characters. The sign is mounted on a pole and is surrounded by buildings and trees. There are also other signs and lights in the background."}, "66959": {"image_id": 66959, "Bleu_1": 0.21153846153439354, "Bleu_2": 0.1288070335219516, "Bleu_3": 0.08722608547574774, "Bleu_4": 0.06066465987455706, "METEOR": 0.19343862407234486, "ROUGE_L": 0.22048192771084338, "CIDEr": 3.850326293036263e-10, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.037037037037037035, "f": 0.05, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a train carrying military personnel on the tracks. The train is painted in camouflage colors and has a large cargo car attached to the back. There are several soldiers standing on the platform, looking out at the landscape. The sky is cloudy and there are trees in the background."}, "35160": {"image_id": 35160, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.1259881576661928, "Bleu_3": 7.757590387941911e-07, "Bleu_4": 1.939396682572253e-09, "METEOR": 0.19437468144250347, "ROUGE_L": 0.21180555555555555, "CIDEr": 1.0103925603486867e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.21428571428571427, "f": 0.20689655172413796, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "Two women are standing in front of a body of water, one is holding up a plate of food and the other is holding up a drink. They are both smiling and looking at each other."}, "88225": {"image_id": 88225, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.12253577034561024, "Bleu_3": 7.541989245962001e-07, "Bleu_4": 1.884710726818381e-09, "METEOR": 0.1935691044393163, "ROUGE_L": 0.23088569265707795, "CIDEr": 3.3465438342336996e-05, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a street with several buses parked on the side of the road. There are people walking on the sidewalk and in the grass. The sky is cloudy and there are trees in the background."}, "455698": {"image_id": 455698, "Bleu_1": 0.692307692254438, "Bleu_2": 0.6354889092513221, "Bleu_3": 0.527587404866211, "Bleu_4": 0.458143076612076, "METEOR": 0.4196674606844863, "ROUGE_L": 0.696574225122349, "CIDEr": 1.6011552501407234, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "A herd of zebras grazing in a field with trees in the background."}, "22801": {"image_id": 22801, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.23371317621462567, "Bleu_3": 0.11829075901056599, "Bleu_4": 1.5080843018301503e-05, "METEOR": 0.23920550255560358, "ROUGE_L": 0.2963562753036437, "CIDEr": 8.141642264885178e-05, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.11538461538461539, "f": 0.0967741935483871, "fn": 23.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The woman is holding a frisbee in her hand and smiling at the camera. She is wearing sunglasses and has a blue shirt on. There are trees and buildings in the background of the image."}, "542717": {"image_id": 542717, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.18625278992847225, "Bleu_3": 0.13224261796258371, "Bleu_4": 0.08514622725147454, "METEOR": 0.20770919681229963, "ROUGE_L": 0.20346897931954633, "CIDEr": 7.898831796471042e-09, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.18518518518518517, "f": 0.16129032258064516, "fn": 22.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.1875, "re": 0.25, "f": 0.21428571428571427, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "This image shows a street market in India with various fruits and vegetables on display. There are several people shopping for produce, while others are sitting on the sidewalk and watching the activity. The market is set up on a bustling street with buildings in the background."}, "397151": {"image_id": 397151, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.12595484068769355, "Bleu_3": 6.418390826668297e-07, "Bleu_4": 1.4549786343112914e-09, "METEOR": 0.19542301956996055, "ROUGE_L": 0.21543895055499496, "CIDEr": 1.3204372968981148e-16, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.21428571428571427, "f": 0.1395348837209302, "fn": 11.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a young girl standing on the beach holding a colorful kite. She is wearing a white shirt and black pants, and her hair is tied back in a ponytail. The kite has brightly colored feathers and is flying high in the air. In the background, there are people standing on the beach and watching the girl fly the kite."}, "374041": {"image_id": 374041, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.20597146021314577, "Bleu_3": 0.14357835226443494, "Bleu_4": 0.09162297751166115, "METEOR": 0.22210369821418735, "ROUGE_L": 0.28073635765943455, "CIDEr": 5.523410109223848e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of elephants standing in a fenced area. They are wearing harnesses and ropes around their necks, and one of them is sitting on top of a wooden fence post. There is a tree in the background with leaves and branches."}, "321543": {"image_id": 321543, "Bleu_1": 0.5999999999600001, "Bleu_2": 0.2070196677884122, "Bleu_3": 1.488309614918075e-06, "Bleu_4": 4.0712207752494026e-09, "METEOR": 0.2175732217573222, "ROUGE_L": 0.3490701001430615, "CIDEr": 0.5049409143622796, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.13333333333333333, "f": 0.13559322033898305, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.08333333333333333, "f": 0.08695652173913043, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a black and white image of a plate with steak, broccoli, and mushrooms."}, "225378": {"image_id": 225378, "Bleu_1": 0.2830188679191884, "Bleu_2": 0.16496470132732644, "Bleu_3": 8.110929465213236e-07, "Bleu_4": 1.8074257588841565e-09, "METEOR": 0.1905703266914544, "ROUGE_L": 0.21721068249258166, "CIDEr": 6.866747670630483e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.041666666666666664, "f": 0.058823529411764705, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image shows a group of people playing soccer on a field. There are two players in blue and white uniforms, one is kicking the ball while the other is trying to block it. There are several spectators watching from the sidelines. The sky is cloudy and there are umbrellas in the background."}, "124659": {"image_id": 124659, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.16695677422191285, "Bleu_3": 0.0886576127354113, "Bleu_4": 1.1561678083377593e-05, "METEOR": 0.16861521317701428, "ROUGE_L": 0.2531120331950207, "CIDEr": 2.0970614639105212e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.13793103448275862, "f": 0.16326530612244897, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a small room with a wooden floor and white walls. There are several pieces of furniture in the room, including a couch, a coffee table, and a bookshelf. The room also has a large window that lets in natural light."}, "398304": {"image_id": 398304, "Bleu_1": 0.28767123287277163, "Bleu_2": 0.14134061323349553, "Bleu_3": 0.06552774123517004, "Bleu_4": 7.962407285587371e-06, "METEOR": 0.17674418604651163, "ROUGE_L": 0.1891891891891892, "CIDEr": 1.0210769786007264e-22, "SPICE": {"All": {"pr": 0.2, "re": 0.07407407407407407, "f": 0.10810810810810811, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a bicycle with a handlebar mounted on the front wheel. The bike has a black frame and silver components, including the seat, handlebars, and pedals. The tires are black and have a smooth surface. There is a small mirror attached to the handlebar, which allows the rider to see behind them while riding. The bike is parked in front of a doorway, with a rug on the floor."}, "77951": {"image_id": 77951, "Bleu_1": 0.9285714285051022, "Bleu_2": 0.8017837256778003, "Bleu_3": 0.6446159946448665, "Bleu_4": 0.46976984507372527, "METEOR": 0.3106926977162979, "ROUGE_L": 0.5965770171149144, "CIDEr": 1.8253732497054003, "SPICE": {"All": {"pr": 0.2, "re": 0.20689655172413793, "f": 0.20338983050847456, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "A plate with a piece of toast and a slice of ham on it."}, "136411": {"image_id": 136411, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.33968311021818254, "Bleu_3": 0.212645185125073, "Bleu_4": 3.0576902882039146e-05, "METEOR": 0.2339095284108899, "ROUGE_L": 0.4680306905370844, "CIDEr": 1.1508245619058775, "SPICE": {"All": {"pr": 0.125, "re": 0.18181818181818182, "f": 0.14814814814814814, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a red and white stop sign on the side of the road."}, "254789": {"image_id": 254789, "Bleu_1": 0.24590163934023115, "Bleu_2": 0.16937687147073976, "Bleu_3": 0.13446483876750195, "Bleu_4": 0.1058960758381783, "METEOR": 0.2852075417904673, "ROUGE_L": 0.3117015840572304, "CIDEr": 4.840542903304458e-13, "SPICE": {"All": {"pr": 0.4, "re": 0.1875, "f": 0.25531914893617025, "fn": 26.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "This is an image of a group of people standing around a large truck in a parking lot. The truck has the words \"Appliance Mart\" written on the side in white letters. There are several cones set up in front of the truck, and some people are standing near them. The sky is cloudy and there are trees in the background."}, "252573": {"image_id": 252573, "Bleu_1": 0.29629629628532245, "Bleu_2": 0.21350420506538995, "Bleu_3": 0.12216804360518721, "Bleu_4": 1.660219092499284e-05, "METEOR": 0.16486007194880628, "ROUGE_L": 0.31671858774662515, "CIDEr": 0.010312031007353176, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.20833333333333334, "f": 0.2702702702702703, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "A cat is sitting on the floor next to a computer with a keyboard and mouse. The cat is looking at the keyboard and mouse with interest."}, "411184": {"image_id": 411184, "Bleu_1": 0.32812499999487305, "Bleu_2": 0.16137430608943423, "Bleu_3": 7.489032156527425e-07, "Bleu_4": 1.619894805520497e-09, "METEOR": 0.18452079030778198, "ROUGE_L": 0.2522977941176471, "CIDEr": 1.9970338252103463e-15, "SPICE": {"All": {"pr": 0.375, "re": 0.16666666666666666, "f": 0.23076923076923078, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a view of the city from a high vantage point, with a bridge crossing over a river in the foreground. The sky is clear and blue, with a few clouds scattered across it. In the distance, there are several buildings and towers visible, including a large cathedral with a tall spire. The water is calm and reflects the sky above it."}, "1584": {"image_id": 1584, "Bleu_1": 0.46428571426913273, "Bleu_2": 0.3469443332317352, "Bleu_3": 0.28499599110221785, "Bleu_4": 0.2466942681547693, "METEOR": 0.38334940346330604, "ROUGE_L": 0.4603773584905661, "CIDEr": 0.035641529435269735, "SPICE": {"All": {"pr": 0.4, "re": 0.125, "f": 0.19047619047619047, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a red double decker bus driving down the street. It has a large number 12 on the side and is surrounded by buildings and trees."}, "422676": {"image_id": 422676, "Bleu_1": 0.37421358067360916, "Bleu_2": 0.20322618501079454, "Bleu_3": 0.1055990117550308, "Bleu_4": 1.3651512237476987e-05, "METEOR": 0.21147317075939848, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.06971997209603349, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows three young girls sitting on a bench in a park, smiling and looking at the camera. One of them is holding a sign that reads \"We are the future.\""}, "104589": {"image_id": 104589, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.23452078798159529, "Bleu_3": 0.13372469554821612, "Bleu_4": 1.8157374167807726e-05, "METEOR": 0.23389240640629927, "ROUGE_L": 0.38566912539515275, "CIDEr": 0.014445705831556962, "SPICE": {"All": {"pr": 0.1, "re": 0.06666666666666667, "f": 0.08, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a tray with several dishes on it, including meat, vegetables, and bread. There are also two glasses of beer on the table."}, "311922": {"image_id": 311922, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 7.777190244898269e-07, "Bleu_4": 1.7882473253246786e-09, "METEOR": 0.22131658684320918, "ROUGE_L": 0.23303196230739842, "CIDEr": 8.428950667316874e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.16, "f": 0.1568627450980392, "fn": 21.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows two women wearing hats and sunglasses, smiling at the camera. One of them is wearing a striped shirt and the other is wearing a polka dot shirt. They are both wearing white pants and black shoes. The background is a blue sky with fluffy white clouds."}, "422783": {"image_id": 422783, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.24445060351331568, "Bleu_3": 1.1528492999775239e-06, "Bleu_4": 2.519901157311033e-09, "METEOR": 0.15982068754724169, "ROUGE_L": 0.23884103367267032, "CIDEr": 3.477188336449258e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a microwave oven in a kitchen. It has a digital display and a door that opens to reveal the interior. The microwave is mounted on the wall and has a shelf above it for storing food."}, "433151": {"image_id": 433151, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.24019223070154896, "Bleu_3": 0.16576208078090784, "Bleu_4": 0.10533275933494715, "METEOR": 0.2880135994335273, "ROUGE_L": 0.3932664756446992, "CIDEr": 6.462743919941523e-06, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.15384615384615385, "f": 0.14285714285714288, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is an image of a large, ornate building with a clock tower on top. The building has a large, arched entrance with columns on either side. There are several cars parked on the street in front of the building."}, "306421": {"image_id": 306421, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.15939996379066856, "Bleu_3": 0.1313972082572321, "Bleu_4": 0.10547007257131018, "METEOR": 0.22503684521424974, "ROUGE_L": 0.2643553629469122, "CIDEr": 6.374449606381716e-14, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.18181818181818182, "f": 0.18750000000000003, "fn": 27.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a small bird perched on a branch of a tree. The bird is looking up at the sky with its beak open, as if it is singing. The sky is blue and cloudless, with a few white clouds in the distance. The tree is old and has a lot of moss growing on its trunk."}, "470513": {"image_id": 470513, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.2431867285489846, "Bleu_3": 0.2013016083348928, "Bleu_4": 0.15536508417020944, "METEOR": 0.2621129692288361, "ROUGE_L": 0.39753287559641576, "CIDEr": 0.007787154457886065, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.25, "f": 0.23809523809523808, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A person is standing on the beach holding a surfboard while looking out at the ocean. The sun is setting in the background, casting a warm orange glow over the scene."}, "43605": {"image_id": 43605, "Bleu_1": 0.5135135134996348, "Bleu_2": 0.396114764807256, "Bleu_3": 0.3154210590891077, "Bleu_4": 0.24649793352637586, "METEOR": 0.29116359992288926, "ROUGE_L": 0.3596168017686072, "CIDEr": 0.0003748022685959326, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.2, "f": 0.25806451612903225, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a fence, holding a tennis racket and looking up at the sky. He is wearing a green shirt and white pants. There are palm trees in the background."}, "574785": {"image_id": 574785, "Bleu_1": 0.4999999999642858, "Bleu_2": 0.33968311021818254, "Bleu_3": 0.2679161448978716, "Bleu_4": 0.20448007358569298, "METEOR": 0.2547089533431044, "ROUGE_L": 0.42957746478873243, "CIDEr": 0.7679152582142789, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.13333333333333333, "f": 0.1951219512195122, "fn": 26.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a small plane flying in the sky with a cloudy background."}, "52368": {"image_id": 52368, "Bleu_1": 0.24999999998958336, "Bleu_2": 0.14744195614862018, "Bleu_3": 9.960317042459069e-07, "Bleu_4": 2.6190877432817172e-09, "METEOR": 0.1946264738284518, "ROUGE_L": 0.2364341085271318, "CIDEr": 0.029765057525704495, "SPICE": {"All": {"pr": 0.1891891891891892, "re": 0.23333333333333334, "f": 0.208955223880597, "fn": 23.0, "numImages": 1.0, "fp": 30.0, "tp": 7.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A beautiful outdoor seating area with red umbrellas and white tables surrounded by lush greenery.\""}, "579900": {"image_id": 579900, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.14383899044073797, "Bleu_3": 9.040623994640335e-07, "Bleu_4": 2.2872196012666833e-09, "METEOR": 0.17135232347372573, "ROUGE_L": 0.321390937829294, "CIDEr": 0.007239252922621747, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.17391304347826086, "f": 0.1951219512195122, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a pizza with various toppings on it. There are slices of cheese, vegetables, and meat on the pizza. The crust of the pizza is golden brown and crispy."}, "208867": {"image_id": 208867, "Bleu_1": 0.5624999999648439, "Bleu_2": 0.19364916729786447, "Bleu_3": 1.3887830606267012e-06, "Bleu_4": 3.788697835944244e-09, "METEOR": 0.26700375413474803, "ROUGE_L": 0.4013157894736842, "CIDEr": 0.41911257827652604, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.20689655172413793, "f": 0.23076923076923075, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A small boat is floating on a lake surrounded by palm trees and a blue sky."}, "421535": {"image_id": 421535, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.26375218935251743, "Bleu_3": 0.16801713501101306, "Bleu_4": 0.12187245684565591, "METEOR": 0.20339165995295894, "ROUGE_L": 0.2378476735118274, "CIDEr": 1.9124364323003847e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.08823529411764706, "f": 0.12244897959183675, "fn": 31.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a group of people skiing through a tunnel in the snow. They are all wearing ski gear and helmets, and one person is holding a ski pole. The tunnel is made of snow and has a large opening at the end."}, "230877": {"image_id": 230877, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.08383535347317195, "Bleu_4": 1.0268368184798258e-05, "METEOR": 0.19979969645567497, "ROUGE_L": 0.2426136363636364, "CIDEr": 2.644028418405029e-13, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.25, "f": 0.25641025641025644, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a surfer riding a wave on a surfboard. The surfer is wearing a wetsuit and has his arms outstretched as he rides the wave. The wave is large and white, with foamy white water crashing against the shore. The sky is blue and cloudy, with some clouds visible in the distance."}, "258815": {"image_id": 258815, "Bleu_1": 0.15686274509496353, "Bleu_2": 0.09701425001261196, "Bleu_3": 0.07269451760681336, "Bleu_4": 0.05318827859424478, "METEOR": 0.17920177610424073, "ROUGE_L": 0.2238532110091743, "CIDEr": 2.2860965720016893e-11, "SPICE": {"All": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image shows a young child sitting in a bathtub, being fed a bottle of formula by an adult. The child is smiling and looking up at the adult with a curious expression on their face. The background of the image is a white bathroom with a shower curtain hanging open."}, "157866": {"image_id": 157866, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.15249857032909853, "Bleu_3": 0.08211593041013024, "Bleu_4": 1.0780144922571383e-05, "METEOR": 0.24900491350693169, "ROUGE_L": 0.2636887608069164, "CIDEr": 2.2837145678444047e-08, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.25925925925925924, "f": 0.27999999999999997, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "This is a kitchen with wooden cabinets and a large island in the center. There is a stove, oven, and refrigerator on the countertops. The floor is made of hardwood and there are windows on one side of the room that provide natural light."}, "154057": {"image_id": 154057, "Bleu_1": 0.27906976743537054, "Bleu_2": 0.1996674976872179, "Bleu_3": 0.1428841479853578, "Bleu_4": 0.09241086581925062, "METEOR": 0.2772329906373408, "ROUGE_L": 0.29756097560975614, "CIDEr": 1.0867591607082258e-07, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.3333333333333333, "f": 0.2553191489361702, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.8571428571428571, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "This is a black and white image of a cat sitting on the porch of a house. The cat has long, fluffy fur and piercing green eyes. It looks like it is waiting for something or someone to come out of the house."}, "132219": {"image_id": 132219, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.22712838128334978, "Bleu_3": 0.14477646336505703, "Bleu_4": 0.09792531732726797, "METEOR": 0.18170827524750996, "ROUGE_L": 0.31213450292397665, "CIDEr": 0.00016128559536190886, "SPICE": {"All": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "A young girl is sitting on the grass, holding an egg in her hand. She is wearing a pink dress and black shoes. The background is green and there are flowers and trees in the distance."}, "147586": {"image_id": 147586, "Bleu_1": 0.9999999999230771, "Bleu_2": 0.8660254037150458, "Bleu_3": 0.6985747127120858, "Bleu_4": 0.5109955810843175, "METEOR": 0.4239092924616945, "ROUGE_L": 0.6062111801242235, "CIDEr": 2.393444398310672, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1935483870967742, "f": 0.21052631578947367, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4166666666666667, "f": 0.45454545454545453, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A plate of doughnuts and a cup of coffee on a wooden table."}, "134691": {"image_id": 134691, "Bleu_1": 0.7142857142517007, "Bleu_2": 0.49999999997559524, "Bleu_3": 0.40369385376370687, "Bleu_4": 0.32359461840727294, "METEOR": 0.376753536242961, "ROUGE_L": 0.5252152521525214, "CIDEr": 0.2575169779368105, "SPICE": {"All": {"pr": 0.4, "re": 0.16, "f": 0.22857142857142856, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.3333333333333333, "f": 0.47058823529411764, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet, sink, and bathtub. The walls are painted white and there is a wooden floor."}, "181030": {"image_id": 181030, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.11926756082899304, "Bleu_3": 7.33805098169319e-07, "Bleu_4": 1.8330256088670778e-09, "METEOR": 0.2096754014111667, "ROUGE_L": 0.30112834978843445, "CIDEr": 4.5026594014864226e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.18518518518518517, "f": 0.1923076923076923, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a tray with food on it. There are two plates with eggs, bacon, and toast on them. There is also a glass of orange juice and a knife and fork on the tray."}, "227230": {"image_id": 227230, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.15007505629280368, "Bleu_3": 8.633422507036765e-07, "Bleu_4": 2.085775285235154e-09, "METEOR": 0.12822983530400592, "ROUGE_L": 0.2697126013264554, "CIDEr": 0.008325082258192356, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.16666666666666666, "f": 0.19607843137254902, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a person on a windsurfing board in the water, with their arms outstretched and their face looking determined. The sky is cloudy and there are trees in the background.\n\nPerson: Windsurfing on the water."}, "337502": {"image_id": 337502, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2908872369299581, "Bleu_3": 0.1521993147229894, "Bleu_4": 1.9786891108517274e-05, "METEOR": 0.19928710175953757, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.03686023050186147, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.0967741935483871, "f": 0.12244897959183673, "fn": 28.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a pizza baking in an oven. The pizza has cheese, vegetables, and meat on it. It looks like it's ready to be served."}, "488151": {"image_id": 488151, "Bleu_1": 0.1999999999966667, "Bleu_2": 0.1646773939157558, "Bleu_3": 0.11194045746119324, "Bleu_4": 0.07043225514233839, "METEOR": 0.215154837089634, "ROUGE_L": 0.25258799171842644, "CIDEr": 4.1523948543366535e-15, "SPICE": {"All": {"pr": 0.2, "re": 0.10344827586206896, "f": 0.13636363636363635, "fn": 26.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young boy is flying a kite in a park on a sunny day. The kite has a red and yellow tail and is being held by the boy with one hand while he runs with the other. In the background, there are several people watching the boy fly the kite."}, "510861": {"image_id": 510861, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.18609684207103389, "Bleu_3": 1.2008331555190807e-06, "Bleu_4": 3.089751861772178e-09, "METEOR": 0.18219139833101208, "ROUGE_L": 0.3472485768500949, "CIDEr": 0.04972198939720029, "SPICE": {"All": {"pr": 0.15, "re": 0.1111111111111111, "f": 0.12765957446808512, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people taking a photo with their phones. They are all smiling and looking at the camera."}, "310524": {"image_id": 310524, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 1.1558994996382842e-06, "Bleu_4": 2.596093486430237e-09, "METEOR": 0.22645849092162992, "ROUGE_L": 0.31466470154753134, "CIDEr": 6.740048232658327e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 24.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a park with benches, trees, and a fountain in the center. People are sitting on the benches and walking around the park. There is a building in the background with windows and a door."}, "234889": {"image_id": 234889, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1177966073469684, "Bleu_3": 0.08511922922355492, "Bleu_4": 0.06118677913919605, "METEOR": 0.16915627379011572, "ROUGE_L": 0.22775357809583074, "CIDEr": 5.517625378940876e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.10526315789473684, "f": 0.125, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a train station with several people standing on the platform. The train is parked in front of the station and has a large sign on the side that reads \"train\". There are also several other signs on the platform that read \"train\" and \"station\"."}, "502402": {"image_id": 502402, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.18837162993777626, "Bleu_3": 1.0695743954365786e-06, "Bleu_4": 2.5710986510668226e-09, "METEOR": 0.15802234895632203, "ROUGE_L": 0.2869238005644403, "CIDEr": 0.0005769769361911948, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.16666666666666666, "f": 0.1276595744680851, "fn": 15.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a bus stop with several people standing around it. The bus is parked in front of the stop and there are pedestrians walking on the sidewalk."}, "346707": {"image_id": 346707, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.1516196087106396, "Bleu_3": 9.363773583417624e-07, "Bleu_4": 2.34826571218133e-09, "METEOR": 0.2056457807765517, "ROUGE_L": 0.26614310645724254, "CIDEr": 0.004098420169780039, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.14285714285714285, "f": 0.1951219512195122, "fn": 24.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a bunch of bananas hanging from the tree. The leaves are yellow and the fruit is green. There are no other plants or objects in the image."}, "58754": {"image_id": 58754, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.17230672835218738, "Bleu_3": 0.09292535942640182, "Bleu_4": 1.2218701690392882e-05, "METEOR": 0.15662050888021803, "ROUGE_L": 0.25363825363825365, "CIDEr": 1.4295261200270351e-05, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.13636363636363635, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A skier jumps off a ramp on a snowy mountain slope. The skier is wearing a helmet and goggles, and has their arms outstretched as they fly through the air.\""}, "504900": {"image_id": 504900, "Bleu_1": 0.2656249999958496, "Bleu_2": 0.1298656204102847, "Bleu_3": 6.47936183178679e-07, "Bleu_4": 1.4531709793942733e-09, "METEOR": 0.2062415196743555, "ROUGE_L": 0.263183125599233, "CIDEr": 1.0017538552697148e-15, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.11764705882352941, "f": 0.0909090909090909, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The man is sitting on the bed with his dog, a small white and brown dog with a collar. The man is holding the dog's leash in one hand and petting it with the other. The dog is looking up at the man with its big brown eyes. The room is dimly lit by a window on the left side of the image."}, "150013": {"image_id": 150013, "Bleu_1": 0.6499999999675001, "Bleu_2": 0.4893604849044811, "Bleu_3": 0.34174500986495016, "Bleu_4": 0.2201224844786047, "METEOR": 0.31256975347310617, "ROUGE_L": 0.4765625, "CIDEr": 0.3671067134398421, "SPICE": {"All": {"pr": 0.24, "re": 0.24, "f": 0.24, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a bench sitting on top of a snow covered beach with the sun shining in the background."}, "363853": {"image_id": 363853, "Bleu_1": 0.4999999999166667, "Bleu_2": 0.21320071631926954, "Bleu_3": 1.656503812070342e-06, "Bleu_4": 4.7406042590263856e-09, "METEOR": 0.21052631578947367, "ROUGE_L": 0.4149659863945578, "CIDEr": 0.5885895219693478, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The cat is sitting on the couch and looking at the camera."}, "278636": {"image_id": 278636, "Bleu_1": 0.19298245613696527, "Bleu_2": 0.11740724488886634, "Bleu_3": 0.06304863686903067, "Bleu_4": 8.253883526780069e-06, "METEOR": 0.18190301408823925, "ROUGE_L": 0.17438536306460833, "CIDEr": 1.423280530358661e-14, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.1875, "f": 0.24000000000000005, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a group of young men playing soccer in an indoor court. They are wearing orange shirts and black shorts, and one of them is kicking the ball with his left foot while another player watches. The walls of the court are made of concrete and there are windows on either side of the room."}, "126995": {"image_id": 126995, "Bleu_1": 0.39999999999200003, "Bleu_2": 0.20203050890636035, "Bleu_3": 9.473945732893256e-07, "Bleu_4": 2.0624038231270056e-09, "METEOR": 0.21148658206002868, "ROUGE_L": 0.22732919254658387, "CIDEr": 3.533395586934648e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.23076923076923078, "f": 0.25531914893617025, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing white shorts and a white shirt with a black stripe on the sleeves. He has his racket in hand and is about to hit the ball. There are trees and buildings in the background of the image."}, "100489": {"image_id": 100489, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.24574815738953795, "Bleu_3": 0.18333757735331024, "Bleu_4": 0.12658603758897227, "METEOR": 0.288848396629544, "ROUGE_L": 0.3216168717047452, "CIDEr": 6.634110816148017e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.13636363636363635, "f": 0.1935483870967742, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a bird perched on a branch with its beak open and looking up at the sky. The bird has a blue and white plumage with a black stripe on its head and neck. The background is a clear blue sky with some clouds in the distance."}, "120475": {"image_id": 120475, "Bleu_1": 0.3235294117551904, "Bleu_2": 0.22140372137841335, "Bleu_3": 1.1527627951838045e-06, "Bleu_4": 2.651334604141866e-09, "METEOR": 0.20672265872450507, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.00020594178972763058, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.4, "f": 0.25000000000000006, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a plate with several types of cookies and a glass of milk on it. There are also some other food items on the plate, such as a sandwich and some fruit."}, "409099": {"image_id": 409099, "Bleu_1": 0.7058823528581315, "Bleu_2": 0.6301260377373137, "Bleu_3": 0.4730871964340148, "Bleu_4": 0.3506964630890884, "METEOR": 0.36522427174318517, "ROUGE_L": 0.6686967113276492, "CIDEr": 1.2072778851821788, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A cake sits on a plate next to a bowl of fruit and a cup of coffee."}, "67868": {"image_id": 67868, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.4082482904490128, "Bleu_3": 0.3375531905770685, "Bleu_4": 0.29615165358996703, "METEOR": 0.4295279860747683, "ROUGE_L": 0.5388692579505301, "CIDEr": 0.025314136094598774, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.08695652173913043, "f": 0.1081081081081081, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a red bench sitting in the middle of a flooded field. The water is up to the bench and there are trees in the background."}, "310177": {"image_id": 310177, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.4134491152817542, "Bleu_3": 0.3245572960433175, "Bleu_4": 0.23103257619688175, "METEOR": 0.3340414377246123, "ROUGE_L": 0.5020576131687242, "CIDEr": 0.2994319210039481, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.25, "f": 0.18604651162790697, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a plate with a slice of cheese, a sausage, and some fruit on it. There is also a glass of milk on the table."}, "312724": {"image_id": 312724, "Bleu_1": 0.6315789473351802, "Bleu_2": 0.4188539082690383, "Bleu_3": 0.21771686610170493, "Bleu_4": 2.8339296174426832e-05, "METEOR": 0.147925580500319, "ROUGE_L": 0.3817271589486859, "CIDEr": 0.19993938039370773, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.22727272727272727, "f": 0.23255813953488372, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A herd of zebras grazing in a grassy field with a backdrop of trees and mountains in the distance."}, "128180": {"image_id": 128180, "Bleu_1": 0.49999999998437505, "Bleu_2": 0.33601075250545387, "Bleu_3": 0.24691550508786966, "Bleu_4": 0.15094258116594791, "METEOR": 0.3062253393014372, "ROUGE_L": 0.40970149253731347, "CIDEr": 0.01407160653960138, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.03225806451612903, "f": 0.046511627906976744, "fn": 30.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is an image of a plate with a slice of pizza on it. The pizza has cheese, tomato sauce, and pepperoni on it. There are also two forks on the plate."}, "9668": {"image_id": 9668, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.2094269541404072, "Bleu_3": 0.15263761139761006, "Bleu_4": 0.09969434990083754, "METEOR": 0.20861895539611655, "ROUGE_L": 0.24148851939825808, "CIDEr": 3.036098233707155e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.7142857142857143, "f": 0.5555555555555556, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This image shows a kitchen with wooden cabinets, a stainless steel refrigerator, and a white sink. There is also a microwave oven on the countertop. The floor is made of hardwood and there are no windows in the room."}, "184700": {"image_id": 184700, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.2613286875248416, "Bleu_3": 0.20610721293670228, "Bleu_4": 0.12320376900697154, "METEOR": 0.2944628039056893, "ROUGE_L": 0.32520944402132523, "CIDEr": 1.0029038311703915e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a bathroom with a white sink, toilet, and shower. The walls are painted white and the floor is tiled in black and white. There is a large window on one side of the room that lets in natural light."}, "446909": {"image_id": 446909, "Bleu_1": 0.17808219177838244, "Bleu_2": 0.1315809500750691, "Bleu_3": 0.0901051569021727, "Bleu_4": 0.06761533815463536, "METEOR": 0.21909631854838568, "ROUGE_L": 0.22334096109839816, "CIDEr": 2.203888586367998e-24, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.07142857142857142, "f": 0.09302325581395349, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man sitting on a bench in the middle of a grassy field. He is wearing a blue shirt and jeans, and has his arms crossed over his chest. The bench is made of wood and has a green seat cushion. In the background, there are trees and bushes, and a small stream runs through the field. The sky is clear and blue, with a few white clouds scattered about."}, "49445": {"image_id": 49445, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.25354627640617955, "Bleu_3": 0.18914591060099717, "Bleu_4": 0.13924499400783444, "METEOR": 0.162517494205297, "ROUGE_L": 0.3446327683615819, "CIDEr": 0.12811796381023782, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.28, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a red bandana, a watch, a knife, a lighter, and other items laid out on a wooden surface."}, "398007": {"image_id": 398007, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.20080483221924839, "Bleu_3": 0.13904403212693783, "Bleu_4": 1.744876789010848e-05, "METEOR": 0.22653830476946413, "ROUGE_L": 0.21034482758620687, "CIDEr": 0.0005621595359586483, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.26666666666666666, "f": 0.3809523809523809, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a train station with a large building in the background. There are people standing on the platform and others walking around the area. The sky is clear and blue."}, "335976": {"image_id": 335976, "Bleu_1": 0.36734693876801333, "Bleu_2": 0.27664166758053954, "Bleu_3": 0.18675222022958107, "Bleu_4": 0.10908370302144318, "METEOR": 0.23403695848648315, "ROUGE_L": 0.3078864353312303, "CIDEr": 9.145096797985437e-10, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.75, "f": 0.8571428571428571, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Object": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "This image shows a bowl of broccoli and chicken stir fry with soy sauce and sesame seeds. The broccoli is cooked to a tender, slightly crispy texture and the chicken is cooked through and tender. The dish is served in a white bowl with a spoon on the side."}, "513189": {"image_id": 513189, "Bleu_1": 0.24561403508341031, "Bleu_2": 0.2387834664662331, "Bleu_3": 0.1730634166457273, "Bleu_4": 0.09898183824655712, "METEOR": 0.24816661572193432, "ROUGE_L": 0.2697622996130459, "CIDEr": 4.963175049429219e-13, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.02857142857142857, "f": 0.0425531914893617, "fn": 34.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a surfer riding a wave on a surfboard in the ocean. The surfer is wearing a wetsuit and standing on the board, balancing on the waves as they approach the shore. The sky is clear and blue, with no clouds in sight. The water is choppy and white, with waves crashing against the shore."}, "195211": {"image_id": 195211, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.1458649914948234, "Bleu_3": 0.0974371940074102, "Bleu_4": 0.06733493543965263, "METEOR": 0.22968528002130312, "ROUGE_L": 0.27799479166666663, "CIDEr": 1.3452331707915465e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.045454545454545456, "f": 0.06451612903225805, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is a living room with wooden floors, a red couch, and a wooden table with chairs. There are two windows on the opposite side of the room, one with curtains and the other with blinds. The walls are painted white and there are several paintings on them."}, "240185": {"image_id": 240185, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.3872983346018379, "Bleu_3": 0.3404885830458579, "Bleu_4": 0.30603689507726295, "METEOR": 0.29189657108729644, "ROUGE_L": 0.39739413680781754, "CIDEr": 0.2745793087349414, "SPICE": {"All": {"pr": 0.2, "re": 0.19230769230769232, "f": 0.19607843137254902, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is a man wearing a suit and tie, holding a sign that says 5K. He is running in a race."}, "411871": {"image_id": 411871, "Bleu_1": 0.3333333333232324, "Bleu_2": 0.22821773228679554, "Bleu_3": 0.1497806431282426, "Bleu_4": 1.829411709689116e-05, "METEOR": 0.2330457246642907, "ROUGE_L": 0.39967239967239965, "CIDEr": 0.0007911192746313477, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is a plate of food with a lobster on it. The lobster has been cooked and is being served on the plate. There are also some carrots and potatoes on the plate."}, "256035": {"image_id": 256035, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1593710424504603, "Bleu_3": 0.09986796846096184, "Bleu_4": 1.1880293241977446e-05, "METEOR": 0.2676904875610459, "ROUGE_L": 0.22195269860521533, "CIDEr": 1.6166326399276864e-10, "SPICE": {"All": {"pr": 0.5384615384615384, "re": 0.2916666666666667, "f": 0.3783783783783784, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This is an image of a person skiing down a snowy hill. The person is wearing black and white clothing and has a pair of skis on their feet. They are holding onto the poles and appear to be in mid-stride. The background is a winter landscape with trees and snow covered hills."}, "562241": {"image_id": 562241, "Bleu_1": 0.23611111110783178, "Bleu_2": 0.14125527120300443, "Bleu_3": 0.08291767080822496, "Bleu_4": 9.533953905365032e-06, "METEOR": 0.17723290902552194, "ROUGE_L": 0.17528735632183903, "CIDEr": 1.2593364494922002e-23, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.23809523809523808, "f": 0.20833333333333334, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a black and white ski suit and has a pair of skis on their feet. They are holding onto the ski poles and appear to be in control of their movements. There are other people in the background, also skiing down the slope. The sky is clear and blue, with some clouds visible in the distance."}, "275657": {"image_id": 275657, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2530600894303559, "Bleu_3": 0.1333606949819784, "Bleu_4": 1.7379110739620047e-05, "METEOR": 0.2857146846765161, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.002552641647199607, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.21052631578947367, "f": 0.24242424242424243, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "There are several plates of food on the table, including pizza and pasta. A man is sitting at the table with a glass of wine in front of him."}, "310705": {"image_id": 310705, "Bleu_1": 0.4285714285510205, "Bleu_2": 0.327326835338012, "Bleu_3": 0.256710495921116, "Bleu_4": 0.20821983208077133, "METEOR": 0.3816630930185533, "ROUGE_L": 0.5029446407538279, "CIDEr": 0.15901979109122744, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.625, "f": 0.3846153846153846, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "The image shows a man sitting on a couch, wearing a suit and tie, holding a cell phone to his ear."}, "62170": {"image_id": 62170, "Bleu_1": 0.27083333332769105, "Bleu_2": 0.18594210949553755, "Bleu_3": 0.09092135343040635, "Bleu_4": 1.1368320017948453e-05, "METEOR": 0.20334290232548705, "ROUGE_L": 0.23680124223602486, "CIDEr": 3.897632814087403e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13793103448275862, "f": 0.1702127659574468, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a grassy field. One of the elephants is holding its trunk up in the air, while the other two are grazing on the grass. The sun is setting in the background, casting a warm orange glow over the scene."}, "426777": {"image_id": 426777, "Bleu_1": 0.2352941176401385, "Bleu_2": 0.1462544848210594, "Bleu_3": 8.743583640208559e-07, "Bleu_4": 2.154897801870901e-09, "METEOR": 0.17295156063884828, "ROUGE_L": 0.20783645655877342, "CIDEr": 0.0012154334287613228, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This image shows a slice of pizza with broccoli and nuts on top. The crust is golden brown and the cheese is melted. There are also some nuts scattered on top of the pizza."}, "176312": {"image_id": 176312, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.3042903097136056, "Bleu_3": 0.2231443166854656, "Bleu_4": 0.17443918989183035, "METEOR": 0.3769543237416115, "ROUGE_L": 0.4556489262371616, "CIDEr": 0.021265799776383452, "SPICE": {"All": {"pr": 0.4, "re": 0.24, "f": 0.3, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a woman standing in front of a sign that reads \"tour stop\" in green letters. She is wearing a black coat and carrying a purse."}, "540694": {"image_id": 540694, "Bleu_1": 0.4090909090816116, "Bleu_2": 0.21810252258335, "Bleu_3": 0.10423751011355298, "Bleu_4": 1.28920522667564e-05, "METEOR": 0.23412179703099278, "ROUGE_L": 0.2506849315068493, "CIDEr": 2.771814097749319e-07, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.19230769230769232, "f": 0.27027027027027023, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.8, "re": 0.3333333333333333, "f": 0.47058823529411764, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The giraffe is standing next to a car with its head peeking out of the window. The car has a license plate on it and there are other cars parked in the background. The giraffe appears to be looking at something in the distance."}, "30478": {"image_id": 30478, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.15240998561606448, "Bleu_3": 0.10511522304355243, "Bleu_4": 0.07387254484889373, "METEOR": 0.16082584910414258, "ROUGE_L": 0.22344322344322343, "CIDEr": 5.147204125012043e-07, "SPICE": {"All": {"pr": 0.35, "re": 0.2692307692307692, "f": 0.3043478260869565, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "This is an image of a train in a factory. The train is parked on the tracks and there are people standing around it. The train has green and white stripes on it and it looks like it is made of metal."}, "345139": {"image_id": 345139, "Bleu_1": 0.27142857142469384, "Bleu_2": 0.177397799578125, "Bleu_3": 0.11155856855741485, "Bleu_4": 0.08023539556204218, "METEOR": 0.25730230690744244, "ROUGE_L": 0.25339575365950145, "CIDEr": 8.642969799181026e-21, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.19047619047619047, "f": 0.16326530612244897, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The man is wearing a green shirt and black pants, and he is holding a beer in his hand. He is sitting at a table with several other people, all of whom are also holding beers. There are several beer glasses on the table, as well as a sign that reads \"Guinness Beer\". The background of the image appears to be a park or outdoor area with trees and grass."}, "299688": {"image_id": 299688, "Bleu_1": 0.4999999999583334, "Bleu_2": 0.30151134455149564, "Bleu_3": 0.2087064022232446, "Bleu_4": 3.170233138218017e-05, "METEOR": 0.15167385834140784, "ROUGE_L": 0.3505747126436781, "CIDEr": 0.49361623969258817, "SPICE": {"All": {"pr": 0.21212121212121213, "re": 0.30434782608695654, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4375, "re": 0.7, "f": 0.5384615384615384, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}}, "caption": "A dog and a cat are playing with toys on the floor."}, "337446": {"image_id": 337446, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.21110016545407168, "Bleu_3": 0.14069728646721347, "Bleu_4": 0.09735849856724987, "METEOR": 0.20263757275888516, "ROUGE_L": 0.2680140597539543, "CIDEr": 0.0001455927254921233, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.058823529411764705, "f": 0.05263157894736842, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.2, "f": 0.12500000000000003, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "Two horses are running in a field of tall grass. One horse is white with brown spots and the other is brown with white spots. They are both wearing collars and are running together."}, "386589": {"image_id": 386589, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.17149858513917848, "Bleu_3": 0.10556671919572966, "Bleu_4": 0.06999971125159092, "METEOR": 0.20736448407291344, "ROUGE_L": 0.25722891566265055, "CIDEr": 1.1078383682335806e-11, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1, "f": 0.13636363636363638, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a woman riding a brown horse in a green field. The woman is wearing a black and white outfit and has a helmet on her head. The horse is running with its mane flowing in the wind. There are several other horses in the background, grazing in the field."}, "438495": {"image_id": 438495, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.2641352718914714, "Bleu_3": 0.20414855750042327, "Bleu_4": 0.15893701509678138, "METEOR": 0.2942249105190533, "ROUGE_L": 0.3642999336429994, "CIDEr": 6.955520382268632e-07, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.2, "f": 0.16326530612244897, "fn": 16.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a kitchen with white cabinets and a white countertop. There is a sink in the corner of the room and a stove on the wall. The floor is made of tiles and there are no chairs or tables in the room."}, "451150": {"image_id": 451150, "Bleu_1": 0.4117647058581315, "Bleu_2": 0.16042223697020558, "Bleu_3": 1.197142802926342e-06, "Bleu_4": 3.3271889137551674e-09, "METEOR": 0.23737081019674716, "ROUGE_L": 0.2566619915848527, "CIDEr": 0.2614232954100386, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.2, "f": 0.29411764705882354, "fn": 20.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.2727272727272727, "f": 0.42857142857142855, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "The image shows a box filled with different types of donuts, including chocolate frosted, glazed, and sprinkled."}, "308799": {"image_id": 308799, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.3086066999129581, "Bleu_3": 0.24469914285200606, "Bleu_4": 0.18503199560693423, "METEOR": 0.2407154202317231, "ROUGE_L": 0.38959854014598544, "CIDEr": 0.01324771861575833, "SPICE": {"All": {"pr": 0.2, "re": 0.13636363636363635, "f": 0.16216216216216214, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This image shows a kitchen with black cabinets and a stainless steel oven. There is a wooden floor and a white refrigerator in the corner of the room."}, "218874": {"image_id": 218874, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.15649215928402857, "Bleu_3": 0.10067569617030046, "Bleu_4": 0.06826042950277836, "METEOR": 0.20504676488085521, "ROUGE_L": 0.2130384167636787, "CIDEr": 1.871391664156441e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08333333333333333, "f": 0.10256410256410255, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on the shore of a body of water, looking out at a large ship in the distance. One person is holding an umbrella while another is fishing from the rocks. The sky is cloudy and there are waves crashing against the shore."}, "197444": {"image_id": 197444, "Bleu_1": 0.36363636362534446, "Bleu_2": 0.3535533905823927, "Bleu_3": 0.30447299999386296, "Bleu_4": 0.24768304255349338, "METEOR": 0.33057029422489065, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.0026241955648745856, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a white plate topped with a slice of cake, a scoop of ice cream, and a sprinkle of red berries. There is also a glass of wine on the table."}, "98683": {"image_id": 98683, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.20100756304732487, "Bleu_3": 0.09794571638096426, "Bleu_4": 1.2230008607068681e-05, "METEOR": 0.24052751873097156, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.2078693424443022e-08, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.041666666666666664, "f": 0.05405405405405406, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of people playing with kites in a green field on a sunny day. The sky is clear and blue, with fluffy white clouds floating in it. The grass is lush and green, and there are several trees in the background."}, "539768": {"image_id": 539768, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.11891767799944002, "Bleu_3": 6.902527228627572e-07, "Bleu_4": 1.6727990522975117e-09, "METEOR": 0.20618550143582928, "ROUGE_L": 0.26804770872567485, "CIDEr": 1.222171645864778e-07, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a street with tall buildings on either side. The street is lined with streetlights and there are cars parked along the side of the road. In the distance, there is a tall building with a sign that reads \"Hastings Street\"."}, "201301": {"image_id": 201301, "Bleu_1": 0.47826086954442354, "Bleu_2": 0.39009474878540096, "Bleu_3": 0.2790920009871206, "Bleu_4": 0.21592878550037442, "METEOR": 0.304886887906666, "ROUGE_L": 0.47490615876546644, "CIDEr": 0.25531286121644947, "SPICE": {"All": {"pr": 0.25, "re": 0.28, "f": 0.2641509433962264, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a person holding a hamburger in their hand while sitting at a table with a laptop and other food items."}, "211260": {"image_id": 211260, "Bleu_1": 0.33333333332407417, "Bleu_2": 0.23904572186014378, "Bleu_3": 0.14979742339353158, "Bleu_4": 0.10046152640266261, "METEOR": 0.30632716748013367, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.0005039798046675616, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.1875, "f": 0.21818181818181817, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a bedroom with a desk, chair, and laptop on it. There are also some speakers and a lamp on the desk. The walls are painted blue and there is a window in the background."}, "32812": {"image_id": 32812, "Bleu_1": 0.47499999998812503, "Bleu_2": 0.24677405839016386, "Bleu_3": 0.11702315519115573, "Bleu_4": 1.4426248920984584e-05, "METEOR": 0.22446336532789668, "ROUGE_L": 0.2691176470588235, "CIDEr": 4.296210434336604e-06, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This image shows a woman playing tennis on a blue court. She is wearing a black and white striped shirt and shorts, and has a yellow racket in her hand. She is running towards the net to hit the ball."}, "16838": {"image_id": 16838, "Bleu_1": 0.30434782607372407, "Bleu_2": 0.11761799221901122, "Bleu_3": 8.70113839085501e-07, "Bleu_4": 2.395656561164293e-09, "METEOR": 0.1451403887688985, "ROUGE_L": 0.25128733264675596, "CIDEr": 0.04926489902988159, "SPICE": {"All": {"pr": 0.125, "re": 0.2727272727272727, "f": 0.17142857142857143, "fn": 8.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a toy car with a clock on the dashboard. The clock is displaying the time in red numbers."}, "219771": {"image_id": 219771, "Bleu_1": 0.4838709677263268, "Bleu_2": 0.3592106040417693, "Bleu_3": 0.2372141099289385, "Bleu_4": 0.14776306152176402, "METEOR": 0.25034570938900486, "ROUGE_L": 0.4292415949960907, "CIDEr": 0.004772156807914275, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The man is sitting at a table in a large room with high ceilings and large windows. He is holding a hot dog in his hand and looking at the camera."}, "151432": {"image_id": 151432, "Bleu_1": 0.22580645160926122, "Bleu_2": 0.13604677703436896, "Bleu_3": 0.08513048093983516, "Bleu_4": 0.05686575535105517, "METEOR": 0.18673821531244664, "ROUGE_L": 0.25412884987353074, "CIDEr": 1.6477474810008479e-16, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.09090909090909091, "f": 0.10714285714285714, "fn": 30.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.23076923076923078, "f": 0.24000000000000002, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a small bird standing on the beach at sunset. The bird is looking out to sea, with its head tilted back and beak pointing upwards. The sky is orange and pink, with clouds in the distance. The waves are crashing against the shore, creating a foamy surf. The sand is wet and there are shells scattered along the beach."}, "5934": {"image_id": 5934, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.17504208247906033, "Bleu_3": 0.0833047357546191, "Bleu_4": 1.0268368184794732e-05, "METEOR": 0.22769040309527921, "ROUGE_L": 0.24610951008645532, "CIDEr": 3.9958288837053994e-13, "SPICE": {"All": {"pr": 0.2, "re": 0.11428571428571428, "f": 0.14545454545454545, "fn": 31.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.21428571428571427, "f": 0.2727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a baseball glove sitting on top of a bench. The glove is made of leather and has a white stitching pattern on the palm. There is a baseball inside the glove, with the words \"Baseball\" written on the ball in black letters. The glove is open, revealing the inside of the hand."}, "271471": {"image_id": 271471, "Bleu_1": 0.7999999998400004, "Bleu_2": 0.6666666665296299, "Bleu_3": 0.5503212080324162, "Bleu_4": 0.3928146508141954, "METEOR": 0.3715208482395866, "ROUGE_L": 0.6, "CIDEr": 2.653212034468198, "SPICE": {"All": {"pr": 0.25, "re": 0.12121212121212122, "f": 0.163265306122449, "fn": 29.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A plate of bananas on a counter in a restaurant."}, "473754": {"image_id": 473754, "Bleu_1": 0.387755102032903, "Bleu_2": 0.25421614885264626, "Bleu_3": 0.17651819096861232, "Bleu_4": 0.12435410952935055, "METEOR": 0.25458091330930344, "ROUGE_L": 0.25221500295333726, "CIDEr": 2.2131558447792452e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 14.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a couple standing on the beach at sunset, holding surfboards. The man is wearing a black shirt and shorts, while the woman is wearing a green bikini top and white shorts. They are standing in front of the ocean, with the sun setting in the background."}, "140043": {"image_id": 140043, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.269724531227751, "Bleu_3": 0.1409145534273607, "Bleu_4": 1.8290765605004157e-05, "METEOR": 0.22974577724473758, "ROUGE_L": 0.37014563106796117, "CIDEr": 0.03409693534163259, "SPICE": {"All": {"pr": 0.3, "re": 0.12, "f": 0.17142857142857143, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a plate of food with two slices of bacon, one fried egg, and toast. There are also two glasses of orange juice on the table."}, "283904": {"image_id": 283904, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.14580296087694455, "Bleu_3": 0.0967137615427347, "Bleu_4": 0.06659271909376246, "METEOR": 0.17284690376789077, "ROUGE_L": 0.23091482649842268, "CIDEr": 2.120018971251212e-10, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.09523809523809523, "f": 0.1, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a cat standing on the edge of a staircase, looking down at something on the floor. The cat has a curious expression on its face and is balancing itself on its hind legs. The background is a white wall with a window on the left side."}, "335851": {"image_id": 335851, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.1923131632828435, "Bleu_3": 0.12713013434655676, "Bleu_4": 0.08753250723793518, "METEOR": 0.20331617111329484, "ROUGE_L": 0.2733791455034359, "CIDEr": 1.949947729216724e-05, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.08695652173913043, "f": 0.07547169811320756, "fn": 21.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows two horses grazing in a green field surrounded by trees. One horse is brown and the other is white. They are both standing on their hind legs, eating grass. The sky is clear and blue."}, "544065": {"image_id": 544065, "Bleu_1": 0.35087719297630043, "Bleu_2": 0.15831189671252371, "Bleu_3": 0.07695227639190864, "Bleu_4": 9.584460320245995e-06, "METEOR": 0.2294410419686325, "ROUGE_L": 0.23448654585392636, "CIDEr": 4.0036269095886036e-11, "SPICE": {"All": {"pr": 0.24242424242424243, "re": 0.47058823529411764, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 25.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of children playing soccer on a field. One girl is wearing a yellow shirt and black shorts, while the other two are wearing black shirts and white shorts. They are all holding soccer balls and running towards the goal. In the background, there are several people watching the game from the sidelines."}, "145567": {"image_id": 145567, "Bleu_1": 0.2931034482708086, "Bleu_2": 0.24840690229653717, "Bleu_3": 0.1876852661328498, "Bleu_4": 0.13780414367148194, "METEOR": 0.1938929726428522, "ROUGE_L": 0.23131094257854823, "CIDEr": 6.535509559502057e-14, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.3888888888888889, "f": 0.2978723404255319, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 1.0, "f": 0.7368421052631579, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "A dog is swimming in the water next to a sailboat on the shore of a body of water. The dog is looking up at the sailboat with its head tilted back and its ears perked up. The sailboat has a white hull and a red sail. The sky is cloudy and there are trees in the background."}, "559388": {"image_id": 559388, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.2963188789875593, "Bleu_3": 0.1890275464255135, "Bleu_4": 0.11546435231399294, "METEOR": 0.2933178586328744, "ROUGE_L": 0.36771600803750837, "CIDEr": 1.9452313551374805e-05, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The man is lying on his back on a bed with his laptop open in front of him. He has two cats sitting on the bed next to him, one on either side. The cats are looking at the laptop screen."}, "169361": {"image_id": 169361, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.2717786532439402, "Bleu_3": 0.19263273100143882, "Bleu_4": 0.1477490668198833, "METEOR": 0.23647541034205535, "ROUGE_L": 0.2654482158398608, "CIDEr": 0.0005611409974090601, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A small dog is standing on the grass, looking up at something in its mouth. The dog has a green collar around its neck and is wearing a tag that reads \"Barking Mad\"."}, "549738": {"image_id": 549738, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.189320611412659, "Bleu_3": 0.14322274352926753, "Bleu_4": 0.08365100805849542, "METEOR": 0.21273027502345013, "ROUGE_L": 0.24910668708524755, "CIDEr": 1.9105552278351487e-17, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2608695652173913, "f": 0.2926829268292683, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a kite flying in the sky with a rainbow colored tail. The kite is made of lightweight materials and has a long, thin body with a large, colorful tail. The kite is flying high in the sky, with the sun shining down on it. There are buildings and trees in the background, with a small church visible in the distance."}, "545407": {"image_id": 545407, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.23204774044025303, "Bleu_3": 0.19206446983541856, "Bleu_4": 0.16636035584894696, "METEOR": 0.255432926249835, "ROUGE_L": 0.2981843575418994, "CIDEr": 8.365050300392309e-06, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.07692307692307693, "f": 0.0851063829787234, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a plane flying in the sky. The plane is white and has a blue tail. It is flying low to the ground and appears to be landing. There are no other objects in the image."}, "54204": {"image_id": 54204, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.18802535826836297, "Bleu_3": 9.368170754206349e-07, "Bleu_4": 2.103433449500824e-09, "METEOR": 0.23825460214030691, "ROUGE_L": 0.2053872053872054, "CIDEr": 9.77515478690978e-09, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.05555555555555555, "f": 0.05405405405405406, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "This is an image of a horse and carriage on the side of the road. The horse is pulling a cart with some people in it. There are buildings in the background, including a red brick building with a sign that reads \"Baker's Delight.\""}, "441323": {"image_id": 441323, "Bleu_1": 0.4090909090723141, "Bleu_2": 0.19738550847874506, "Bleu_3": 1.2489168104898057e-06, "Bleu_4": 3.182084683852089e-09, "METEOR": 0.22267509988974787, "ROUGE_L": 0.2791762013729977, "CIDEr": 0.1521146430265616, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.13636363636363635, "f": 0.11320754716981131, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a red and white Chinese New Year's card with an orange and a duck figurine on the table."}, "465489": {"image_id": 465489, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.16222142112654833, "Bleu_3": 0.08926301664901087, "Bleu_4": 1.1855723022764683e-05, "METEOR": 0.2174463480078686, "ROUGE_L": 0.2959112959112959, "CIDEr": 0.00014532084926776679, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person standing on top of a snow covered mountain. They are wearing a backpack and have their skis on their feet. The sky is cloudy and there is a lot of snow on the ground."}, "24566": {"image_id": 24566, "Bleu_1": 0.43333333331888896, "Bleu_2": 0.2733361367859988, "Bleu_3": 0.2000410424732145, "Bleu_4": 0.15604716741454921, "METEOR": 0.28998884640216027, "ROUGE_L": 0.3652694610778443, "CIDEr": 0.0035845661318512244, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.07692307692307693, "f": 0.12121212121212123, "fn": 24.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an image of a blue school bus parked in the woods. The bus has a white roof and windows, and there are trees and bushes growing around it."}, "328301": {"image_id": 328301, "Bleu_1": 0.4999999999791667, "Bleu_2": 0.41702882809639563, "Bleu_3": 0.3619819441797855, "Bleu_4": 0.30830129953647895, "METEOR": 0.2218034914863203, "ROUGE_L": 0.43660531697341515, "CIDEr": 0.1766808391517311, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.24, "f": 0.27906976744186046, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A yellow car parked in front of a building with a boat in the background.\""}, "244181": {"image_id": 244181, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.16049166880688226, "Bleu_3": 0.08429701120201874, "Bleu_4": 1.0928154087524093e-05, "METEOR": 0.17859582683833952, "ROUGE_L": 0.24646464646464644, "CIDEr": 2.612061598582019e-07, "SPICE": {"All": {"pr": 0.4375, "re": 0.22580645161290322, "f": 0.2978723404255319, "fn": 24.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07142857142857142, "f": 0.09523809523809523, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a table with two sandwiches on it. One of the sandwiches is a ham and cheese sandwich, while the other is a meatball sub. There are also two beers on the table, one of which is open and the other is closed."}, "43585": {"image_id": 43585, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.2799063742426443, "Bleu_3": 0.18437633933234043, "Bleu_4": 0.1271235700058349, "METEOR": 0.3226286647805576, "ROUGE_L": 0.4714975845410628, "CIDEr": 0.007919741137788762, "SPICE": {"All": {"pr": 0.2, "re": 0.17647058823529413, "f": 0.18750000000000003, "fn": 14.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A black and white dog is lying on its back with its paws in the air while a brown and white dog is standing over it, barking."}, "176730": {"image_id": 176730, "Bleu_1": 0.255813953482423, "Bleu_2": 0.22074072421921875, "Bleu_3": 0.16814360466153025, "Bleu_4": 0.12416602164079053, "METEOR": 0.1846531358173086, "ROUGE_L": 0.2902787219578518, "CIDEr": 2.3202093595444995e-07, "SPICE": {"All": {"pr": 0.4375, "re": 0.25925925925925924, "f": 0.3255813953488372, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of people in a swimming pool, some of them are holding surfboards and others are standing on the water. There are also several other people in the background, some of them are watching the activity in the pool."}, "273246": {"image_id": 273246, "Bleu_1": 0.2549019607793157, "Bleu_2": 0.18890811128268284, "Bleu_3": 0.08997082661376077, "Bleu_4": 1.1098543117770438e-05, "METEOR": 0.16378853741672517, "ROUGE_L": 0.2858816637375513, "CIDEr": 2.6213843757888764e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08333333333333333, "f": 0.10256410256410255, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A group of people are standing on the beach, looking out at the ocean. One person is holding a kite and another is holding a surfboard. There are several other people in the background, walking along the beach. The sky is clear and blue, with a few clouds scattered across it."}, "479562": {"image_id": 479562, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.2626128657105405, "Bleu_3": 1.350489842713993e-06, "Bleu_4": 3.0904914793092257e-09, "METEOR": 0.2732017035001245, "ROUGE_L": 0.39757914338919925, "CIDEr": 0.03095999981471602, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15, "f": 0.1764705882352941, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The woman is standing outside, smiling and talking on her cell phone. She is wearing a black leather jacket and has long red hair. There are trees in the background."}, "114147": {"image_id": 114147, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.17902871850532517, "Bleu_3": 0.13626814836267256, "Bleu_4": 0.1081441008020043, "METEOR": 0.17751885717255533, "ROUGE_L": 0.2691176470588235, "CIDEr": 1.0169547937010925e-06, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a group of people riding motorcycles on the sidewalk. They are wearing helmets and are stopped at a red light. There are other people walking on the sidewalk and cars driving by in the background."}, "236123": {"image_id": 236123, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.13093073413895012, "Bleu_3": 7.094917059707092e-07, "Bleu_4": 1.660297934705131e-09, "METEOR": 0.19147207902595656, "ROUGE_L": 0.30310559006211185, "CIDEr": 1.233329933327469e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.625, "f": 0.5882352941176471, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "A black bear cub is standing in the middle of a forest, surrounded by trees and debris. The cub is looking up at something in the distance, possibly a bird or other animal. The image is taken from a low angle, with the ground and trees visible in the foreground."}, "278853": {"image_id": 278853, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.2148344622063902, "Bleu_3": 0.10669435290940496, "Bleu_4": 1.3460328045659332e-05, "METEOR": 0.17457977495232205, "ROUGE_L": 0.22426470588235295, "CIDEr": 2.8647945597833216e-06, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a person snowboarding down a mountain. The person is wearing a blue jacket and black pants, and has their arms outstretched as they jump off a ramp. In the background, there are trees and mountains."}, "353001": {"image_id": 353001, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.23555849565513073, "Bleu_3": 0.17853812773859593, "Bleu_4": 0.11062475782768397, "METEOR": 0.27423712503170067, "ROUGE_L": 0.3768016472203157, "CIDEr": 0.0011751429244690865, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.15789473684210525, "f": 0.18181818181818182, "fn": 16.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a group of people walking down a street with pink umbrellas. They are all wearing pink tutus and some of them have pink hats on their heads. There are also some people standing on the sidewalk watching them."}, "426542": {"image_id": 426542, "Bleu_1": 0.23529411764244526, "Bleu_2": 0.15339299776643633, "Bleu_3": 0.0986616396109014, "Bleu_4": 0.06688071957169267, "METEOR": 0.23880198733838456, "ROUGE_L": 0.2238532110091743, "CIDEr": 1.2646585007739854e-10, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.23529411764705882, "f": 0.15686274509803924, "fn": 13.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows two baseball players standing on the field, one holding a bat and the other holding a glove. They are wearing uniforms with numbers on their backs and helmets on their heads. The background is a green field with a dirt infield and a white fence in the distance."}, "136212": {"image_id": 136212, "Bleu_1": 0.6153846153609468, "Bleu_2": 0.4437601569627743, "Bleu_3": 0.2908945214032075, "Bleu_4": 0.1808713155857089, "METEOR": 0.2797571833440275, "ROUGE_L": 0.41536964980544744, "CIDEr": 0.04920324705706935, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2962962962962963, "f": 0.3137254901960785, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.5833333333333334, "f": 0.5833333333333334, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "This image shows a hot dog on a bun with ketchup, mustard, and relish. There is also a cup of soda next to the hot dog."}, "350111": {"image_id": 350111, "Bleu_1": 0.3399999999932, "Bleu_2": 0.28855728394737223, "Bleu_3": 0.21833567275910276, "Bleu_4": 0.1450696483913034, "METEOR": 0.24645272650887817, "ROUGE_L": 0.34957020057306587, "CIDEr": 2.1082038759030766e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.11904761904761904, "f": 0.15151515151515152, "fn": 37.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.05263157894736842, "f": 0.06896551724137931, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.1875, "f": 0.23076923076923075, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people flying kites on a beach with a clear blue sky in the background. The kites are flying high in the air and there are some people standing on the sand watching them. There are also some plants and trees visible in the foreground."}, "53909": {"image_id": 53909, "Bleu_1": 0.5999999999200001, "Bleu_2": 0.292770021844827, "Bleu_3": 1.8751526124712048e-06, "Bleu_4": 4.841524712350714e-09, "METEOR": 0.1982859156275115, "ROUGE_L": 0.4535315985130111, "CIDEr": 0.24798185252200763, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A hand is holding a smartphone with an image of a tree on the screen."}, "210299": {"image_id": 210299, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.25819888973988653, "Bleu_3": 0.15769573215932156, "Bleu_4": 0.10440864748108529, "METEOR": 0.3403242313287627, "ROUGE_L": 0.3721132897603485, "CIDEr": 0.000261679773170039, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.125, "f": 0.14634146341463414, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a young boy riding a bicycle on a concrete floor. He is wearing a helmet and has a big smile on his face. The background is a blurred image of buildings and trees."}, "517318": {"image_id": 517318, "Bleu_1": 0.555555555432099, "Bleu_2": 0.5270462765739486, "Bleu_3": 0.49193407328629696, "Bleu_4": 0.44632361367485907, "METEOR": 0.3179771979400107, "ROUGE_L": 0.5213675213675214, "CIDEr": 2.0908463808341233, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14285714285714285, "f": 0.16326530612244897, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The woman is feeding a giraffe at the zoo."}, "36962": {"image_id": 36962, "Bleu_1": 0.6153846153372783, "Bleu_2": 0.4529108136215475, "Bleu_3": 0.3341085298955855, "Bleu_4": 0.24712442543084054, "METEOR": 0.3096007068663221, "ROUGE_L": 0.563944530046225, "CIDEr": 1.2285549767157615, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.12903225806451613, "f": 0.125, "fn": 27.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.3333333333333333, "f": 0.2962962962962963, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The cat is sitting on top of the television, looking at the camera."}, "161854": {"image_id": 161854, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.3027650353973863, "Bleu_3": 0.19975816178722908, "Bleu_4": 2.4534246786431042e-05, "METEOR": 0.156312931506023, "ROUGE_L": 0.321390937829294, "CIDEr": 0.018040997560076655, "SPICE": {"All": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 21.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a bedroom with a blue wall and a white bedspread. There are two lamps on the nightstand and a window in the background."}, "101913": {"image_id": 101913, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.38430756911713254, "Bleu_3": 0.33299110173098667, "Bleu_4": 0.2993195015487699, "METEOR": 0.35914680707857843, "ROUGE_L": 0.45101663585951934, "CIDEr": 0.06869491298857738, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.21739130434782608, "f": 0.19230769230769232, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A family sits on a bench in front of a train station, watching the trains go by.\""}, "334884": {"image_id": 334884, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.14199045855725748, "Bleu_3": 0.08759225146949404, "Bleu_4": 1.2338142098445797e-05, "METEOR": 0.26095059062683895, "ROUGE_L": 0.36810344827586206, "CIDEr": 0.0006513961224503219, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a bowl of vegetable soup with chicken, carrots, and other vegetables. There is a spoon in the bowl and a glass of wine on the table next to it."}, "560440": {"image_id": 560440, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.10523401123300179, "Bleu_3": 6.464120807060151e-07, "Bleu_4": 1.6120076571346083e-09, "METEOR": 0.16654846698863188, "ROUGE_L": 0.17003484320557494, "CIDEr": 2.0221692961517943e-07, "SPICE": {"All": {"pr": 0.375, "re": 0.08571428571428572, "f": 0.1395348837209302, "fn": 32.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.07142857142857142, "f": 0.11764705882352941, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a street with a few trees on either side. There are no cars or people in the image, but there is a stop sign at the intersection. The sky is clear and blue, with some clouds visible in the distance."}, "224222": {"image_id": 224222, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.22247460415230486, "Bleu_3": 0.1511487505568587, "Bleu_4": 0.09522283308577018, "METEOR": 0.19922209882674766, "ROUGE_L": 0.24646464646464644, "CIDEr": 0.0011494367453518072, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.22727272727272727, "f": 0.18181818181818182, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.25, "f": 0.14285714285714288, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a group of people surfing on the ocean. One person is standing on the board, while another is sitting on the board and holding onto the rope. The waves are crashing against the shore and the sun is shining down on them."}, "168093": {"image_id": 168093, "Bleu_1": 0.2295081967175491, "Bleu_2": 0.13829563644409393, "Bleu_3": 0.06869444951521007, "Bleu_4": 8.646378385553579e-06, "METEOR": 0.14753150154551037, "ROUGE_L": 0.2214500570480241, "CIDEr": 2.895208606023224e-15, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.15625, "f": 0.19999999999999998, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This image shows a surfer riding a wave on the ocean. The surfer is wearing a wetsuit and standing on top of the wave, with their arms outstretched to balance themselves. The wave is large and white, with foamy white water crashing against the shore in the background. The sky is clear and blue, with a few clouds scattered across it."}, "152398": {"image_id": 152398, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.09983374884360895, "Bleu_3": 6.241040020024952e-07, "Bleu_4": 1.5701014973153738e-09, "METEOR": 0.21000711393680685, "ROUGE_L": 0.21254355400696864, "CIDEr": 1.7480435842678402e-07, "SPICE": {"All": {"pr": 0.47619047619047616, "re": 0.3225806451612903, "f": 0.3846153846153846, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 10.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 8.0}}, "caption": "This is a bedroom with a large bed and a red carpet on the floor. There are two lamps on the nightstands and a green curtain on the window. The walls are painted white and there is a floral pattern on the wallpaper."}, "138838": {"image_id": 138838, "Bleu_1": 0.7647058823079586, "Bleu_2": 0.535504160439078, "Bleu_3": 0.38564280352678415, "Bleu_4": 0.2529920735774518, "METEOR": 0.32729217583011194, "ROUGE_L": 0.45963401506996776, "CIDEr": 1.1766143259346424, "SPICE": {"All": {"pr": 0.25, "re": 0.13793103448275862, "f": 0.17777777777777778, "fn": 25.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "A person is flying a kite on the beach with a clear blue sky in the background."}, "546826": {"image_id": 546826, "Bleu_1": 0.6666666666296297, "Bleu_2": 0.4428074427447238, "Bleu_3": 2.3055255903015828e-06, "Bleu_4": 5.346316257038189e-09, "METEOR": 0.2282276333422393, "ROUGE_L": 0.3765432098765432, "CIDEr": 0.49945525679303704, "SPICE": {"All": {"pr": 0.05128205128205128, "re": 0.18181818181818182, "f": 0.08, "fn": 9.0, "numImages": 1.0, "fp": 37.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.11764705882352941, "re": 0.4, "f": 0.1818181818181818, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}}, "caption": "The image shows a red scissors, a pink marker, and a white piece of paper on a table."}, "373193": {"image_id": 373193, "Bleu_1": 0.29487179486801446, "Bleu_2": 0.18564895492473155, "Bleu_3": 0.07682875727723489, "Bleu_4": 8.818151186017548e-06, "METEOR": 0.1933922524048418, "ROUGE_L": 0.2237163814180929, "CIDEr": 5.190333215963157e-24, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.125, "f": 0.14814814814814814, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a woman sitting on the steps of a house, looking at her dog. The dog is standing next to her and appears to be looking up at her. The woman is wearing a white shirt and jeans, and the dog is wearing a collar and leash. There are plants and flowers in pots on the steps, and a small table with a watering can on it. The background is a fence and a small shed."}, "268259": {"image_id": 268259, "Bleu_1": 0.18749999999765626, "Bleu_2": 0.04871773518400952, "Bleu_3": 3.121954189063746e-07, "Bleu_4": 7.928612872351773e-10, "METEOR": 0.18305826496025088, "ROUGE_L": 0.2046979865771812, "CIDEr": 2.9880190751973986e-28, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.23809523809523808, "f": 0.22727272727272724, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a bicycle chain hanging from the rear wheel of a motorcycle. The chain is made of metal links and has a small sprocket on the end that connects to the gear on the bike's rear wheel. The chain is attached to the bike's frame with screws and is held in place by a small metal clip on the end. The chain is dirty and worn, indicating that it has been used for a long time."}, "109539": {"image_id": 109539, "Bleu_1": 0.26388888888522377, "Bleu_2": 0.1612985257117011, "Bleu_3": 0.09058666068874602, "Bleu_4": 0.05729093567175286, "METEOR": 0.14585333191521388, "ROUGE_L": 0.1938090050835149, "CIDEr": 7.37534855008671e-20, "SPICE": {"All": {"pr": 0.15, "re": 0.14285714285714285, "f": 0.14634146341463414, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people standing under umbrellas in the rain. They are all wearing different colored coats and hats, and some of them have their arms around each other. The statue is made of bronze and has a lot of details, including the umbrellas and the people's faces. The statue is in a public space, possibly a park or square, and there are flowers and trees around it."}, "358685": {"image_id": 358685, "Bleu_1": 0.2424242424205693, "Bleu_2": 0.1365577483976988, "Bleu_3": 0.09561469818904189, "Bleu_4": 0.06103210604904399, "METEOR": 0.1913933625029263, "ROUGE_L": 0.21243781094527364, "CIDEr": 1.685479658416717e-19, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.2413793103448276, "f": 0.23728813559322037, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a zebra and its baby standing in a field of tall grass. The zebra has a brown and white striped pattern on its back, while the baby has a similar pattern on its back but with a lighter color. They are both looking at each other, with the mother zebra nuzzling her baby. The background is a clear blue sky with some clouds."}, "21029": {"image_id": 21029, "Bleu_1": 0.34693877550312374, "Bleu_2": 0.170034010199895, "Bleu_3": 0.08504678729142533, "Bleu_4": 1.0753602435385096e-05, "METEOR": 0.2306048367921274, "ROUGE_L": 0.2576946288473144, "CIDEr": 4.87659839496729e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of men playing baseball in a dirt field. One man is swinging a bat while another man is catching the ball. There are several other men standing around the field watching the game. The sky is cloudy and there are trees in the background."}, "367509": {"image_id": 367509, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.19674775072873343, "Bleu_3": 1.1010503638215559e-06, "Bleu_4": 2.627640098684675e-09, "METEOR": 0.14469362658598012, "ROUGE_L": 0.1665150136487716, "CIDEr": 0.0006711791469432245, "SPICE": {"All": {"pr": 0.08, "re": 0.11764705882352941, "f": 0.09523809523809526, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of animals, including a zebra, standing in a grassy area. The zebra is looking at the camera while the other animals are grazing in the background."}, "312263": {"image_id": 312263, "Bleu_1": 0.5555555555349795, "Bleu_2": 0.3580574370062001, "Bleu_3": 0.2172693481609701, "Bleu_4": 2.556795749388759e-05, "METEOR": 0.3061476518622994, "ROUGE_L": 0.40550807217473883, "CIDEr": 0.148427104061862, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is an image of a tall building with many windows on each floor. The building has a clock tower on top and is surrounded by trees."}, "264753": {"image_id": 264753, "Bleu_1": 0.16666666666435187, "Bleu_2": 0.11867816581772543, "Bleu_3": 0.09301818636164205, "Bleu_4": 0.06949781119418232, "METEOR": 0.2919979886084122, "ROUGE_L": 0.22975517890772126, "CIDEr": 7.246017986787261e-25, "SPICE": {"All": {"pr": 0.6, "re": 0.10344827586206896, "f": 0.17647058823529413, "fn": 26.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This is a black and white photograph of a train station with a large clock tower in the background. The train station has a long platform with several cars parked on it, and there are people standing on the platform waiting for the train to arrive. The clock tower is made of stone and has a large clock face on it. There are also some trees and buildings visible in the background."}, "278570": {"image_id": 278570, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.08219949365042624, "Bleu_3": 5.779497498191423e-07, "Bleu_4": 1.5436464226375294e-09, "METEOR": 0.1713520492249021, "ROUGE_L": 0.2081911262798635, "CIDEr": 5.623664046627015e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This image shows a group of three red lanterns hanging from wooden poles in the middle of a dirt path. The poles are surrounded by tall trees and greenery, with a mountain range visible in the background."}, "463452": {"image_id": 463452, "Bleu_1": 0.3913043478175804, "Bleu_2": 0.2797514424659451, "Bleu_3": 0.174744862265968, "Bleu_4": 0.10554464364996075, "METEOR": 0.2962243223270049, "ROUGE_L": 0.44701240135287484, "CIDEr": 6.526170630988454e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 30.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The man in the image is wearing a suit and tie, sitting at a desk with his hands folded in front of him. He appears to be looking down at something on the desk. The background is a dark room with a window in the background."}, "383046": {"image_id": 383046, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.14674773886538112, "Bleu_4": 0.0942786957423983, "METEOR": 0.2703454630711732, "ROUGE_L": 0.21254355400696864, "CIDEr": 4.098632455259822e-07, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a person snowboarding down a mountain. The person is wearing a red jacket and black pants, and has their arms outstretched as they ride the snowboard. The background is a white snowy slope with trees in the distance."}, "291346": {"image_id": 291346, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.15227739752202907, "Bleu_3": 0.1017691319923899, "Bleu_4": 0.0703630957666405, "METEOR": 0.24012488960532258, "ROUGE_L": 0.25452016689847007, "CIDEr": 5.107612406595942e-09, "SPICE": {"All": {"pr": 0.23333333333333334, "re": 0.25, "f": 0.2413793103448276, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5454545454545454, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a group of men playing baseball on a field. One man is pitching the ball while another is catching it. There are two other men standing on the sidelines watching the game. The field is green and there are trees in the background."}, "506540": {"image_id": 506540, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.21501265303422734, "Bleu_3": 0.15676493616836654, "Bleu_4": 0.12180838504699394, "METEOR": 0.27831261349413844, "ROUGE_L": 0.3259541984732824, "CIDEr": 9.267147322173669e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The giraffe is standing in the grass, looking at the camera. It has a brown coat with white spots and long legs. The background is a zoo or wildlife park with trees and other animals in the distance."}, "533536": {"image_id": 533536, "Bleu_1": 0.8461538460236689, "Bleu_2": 0.7510676160808549, "Bleu_3": 0.6352994279150247, "Bleu_4": 0.5659119255720565, "METEOR": 0.43532835807932774, "ROUGE_L": 0.725231175693527, "CIDEr": 1.4605700456130384, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.19230769230769232, "f": 0.2564102564102564, "fn": 21.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "A cat is sitting in front of a television, looking at the screen."}, "168353": {"image_id": 168353, "Bleu_1": 0.9090909090082646, "Bleu_2": 0.6741998623988867, "Bleu_3": 0.46571647513349596, "Bleu_4": 5.9609942726317344e-05, "METEOR": 0.4064279764884334, "ROUGE_L": 0.5763779527559055, "CIDEr": 1.5240688116075969, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.18181818181818182, "f": 0.1509433962264151, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The bride and groom cutting their wedding cake at their reception."}, "241": {"image_id": 241, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.20159462811746034, "Bleu_3": 0.11460354422397828, "Bleu_4": 1.551155008995511e-05, "METEOR": 0.19006750949579446, "ROUGE_L": 0.22488479262672809, "CIDEr": 0.005825631769490943, "SPICE": {"All": {"pr": 0.3684210526315789, "re": 0.3684210526315789, "f": 0.3684210526315789, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a picture of a group of people sitting around a table with drinks and snacks. They are all wearing casual clothing and seem to be enjoying themselves."}, "182078": {"image_id": 182078, "Bleu_1": 0.33333333331944454, "Bleu_2": 0.20851441404819784, "Bleu_3": 0.12549213105420826, "Bleu_4": 1.7514895362022248e-05, "METEOR": 0.13177094124753808, "ROUGE_L": 0.27853881278538817, "CIDEr": 0.013348344222026957, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a water fountain in the middle of a park. There is a bench nearby and some plants growing on the ground."}, "370337": {"image_id": 370337, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.13351146745465192, "Bleu_3": 8.228027226970989e-07, "Bleu_4": 2.0588815727345863e-09, "METEOR": 0.19203513655927276, "ROUGE_L": 0.20783645655877342, "CIDEr": 0.00047502355741286205, "SPICE": {"All": {"pr": 0.10810810810810811, "re": 0.16666666666666666, "f": 0.13114754098360656, "fn": 20.0, "numImages": 1.0, "fp": 33.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.36363636363636365, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This image shows a harbor with several boats docked at the pier. There are buildings in the background, including a large building with windows on the top floor. The sky is clear and blue."}, "26767": {"image_id": 26767, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.19034674689861678, "Bleu_3": 1.1809261666306976e-06, "Bleu_4": 2.9758582163943454e-09, "METEOR": 0.20484845665426632, "ROUGE_L": 0.3177083333333333, "CIDEr": 0.02909399065576005, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.1794871794871795, "f": 0.2295081967213115, "fn": 32.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.0625, "f": 0.08, "fn": 15.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.35714285714285715, "f": 0.41666666666666663, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is an image of a street with trees on both sides and a blue sign in the background that reads \"Bank of America\"."}, "311746": {"image_id": 311746, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.10174919922777484, "Bleu_4": 1.2738938828213386e-05, "METEOR": 0.18558734550603823, "ROUGE_L": 0.21801286633309508, "CIDEr": 2.8397470290045773e-07, "SPICE": {"All": {"pr": 0.24, "re": 0.20689655172413793, "f": 0.22222222222222224, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a hummingbird perched on a pink flower. The bird is looking down and has its beak open as if it is about to take a drink from the flower. The flower is surrounded by other pink flowers and green leaves."}, "243569": {"image_id": 243569, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.14664711501900682, "Bleu_3": 0.08900527285720658, "Bleu_4": 0.058549607676204825, "METEOR": 0.22702865342115058, "ROUGE_L": 0.2456670262495505, "CIDEr": 1.527446906384832e-16, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.23529411764705882, "f": 0.19512195121951217, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a young woman sitting on a bed in a room with white walls and a white ceiling. She is wearing a green shirt and has a laptop on her lap. There are several photos hanging on the wall, including one of a man and one of a woman. The woman is holding a teddy bear and smiling at the camera."}, "7207": {"image_id": 7207, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.286909520871417, "Bleu_3": 0.20362375169536936, "Bleu_4": 0.12208868808859313, "METEOR": 0.19689115342476976, "ROUGE_L": 0.3413754508145753, "CIDEr": 0.07002116573640332, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.2, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 36.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a group of men standing in front of a brick wall, each holding a carrot in their hand. They are all wearing black clothing and have long hair. One of them is holding a book in his hand."}, "573756": {"image_id": 573756, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.15585730003579046, "Bleu_3": 8.691288996416392e-07, "Bleu_4": 2.0665100326125144e-09, "METEOR": 0.22546003239047407, "ROUGE_L": 0.22846441947565538, "CIDEr": 1.300361651105444e-05, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.15384615384615385, "f": 0.21621621621621623, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows two giraffes standing in a clearing surrounded by trees. They are both brown and have spots on their backs. One of the giraffes is eating leaves from a tree while the other stands nearby, looking around."}, "513098": {"image_id": 513098, "Bleu_1": 0.25396825396422273, "Bleu_2": 0.19200614429185545, "Bleu_3": 0.13421059543538602, "Bleu_4": 1.4167795832880416e-05, "METEOR": 0.24148179398192243, "ROUGE_L": 0.25219638242894055, "CIDEr": 4.457520396266137e-18, "SPICE": {"All": {"pr": 0.4, "re": 0.24, "f": 0.3, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of four blue and yellow airplanes flying in formation in the sky. They are all flying in a line, with their wings spread out to the sides. The planes are flying low to the ground, with their engines roaring as they soar through the air. The sky is cloudy and there are some white clouds in the background."}, "132540": {"image_id": 132540, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1799372899254913, "Bleu_3": 0.11289809419085711, "Bleu_4": 0.07562263205115649, "METEOR": 0.2137205952508036, "ROUGE_L": 0.24416277518345564, "CIDEr": 5.389959482869443e-09, "SPICE": {"All": {"pr": 0.05714285714285714, "re": 0.08695652173913043, "f": 0.06896551724137931, "fn": 21.0, "numImages": 1.0, "fp": 33.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.2, "f": 0.16, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "This is a living room with a couch, coffee table, and television. There are several pieces of artwork on the walls, including a painting of a woman in a black dress and a man in a suit. The room is well lit by lamps and overhead lighting."}, "309933": {"image_id": 309933, "Bleu_1": 0.34782608694896033, "Bleu_2": 0.19658927486887504, "Bleu_3": 9.576841983278788e-07, "Bleu_4": 2.1259332643118567e-09, "METEOR": 0.17433570853110766, "ROUGE_L": 0.20691994572591585, "CIDEr": 9.545421954026062e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.21739130434782608, "f": 0.21739130434782608, "fn": 18.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.625, "f": 0.5263157894736842, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This image shows a kitchen with white cabinets and a stove. There is a microwave oven on the counter next to the stove, and a sink in the corner of the room. The walls are painted a light color and there are plants on the windowsills."}, "68409": {"image_id": 68409, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.326269233756791, "Bleu_3": 0.2637797288420401, "Bleu_4": 0.21058230202082015, "METEOR": 0.28476157964297977, "ROUGE_L": 0.33970670131798775, "CIDEr": 0.013839868475437743, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.21052631578947367, "f": 0.2, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a black and white photograph of a group of children sitting on the ground, wearing school uniforms. They are all looking at the camera with smiles on their faces."}, "72737": {"image_id": 72737, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.14285714285419707, "Bleu_3": 0.09540665858824407, "Bleu_4": 0.06591656331231212, "METEOR": 0.13177094124753808, "ROUGE_L": 0.19690122659780504, "CIDEr": 1.2973397601485727e-10, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a skateboarder performing a trick on a half pipe. The skateboarder is wearing a black shirt and pants, and has his arms extended as he jumps off the half pipe. The background is a dark blue sky with clouds and trees in the distance."}, "339426": {"image_id": 339426, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.1659087424695837, "Bleu_3": 0.11382140012503704, "Bleu_4": 1.279608953828509e-05, "METEOR": 0.2506952463158366, "ROUGE_L": 0.2406989853438557, "CIDEr": 3.660994864521921e-13, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.125, "f": 0.14634146341463414, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a baseball player hitting a ball on a field. The player is wearing a white jersey and black pants, and has a bat in his hand. There are several people watching from the stands, including a catcher and umpire. The field is covered in grass and there are some trees in the background."}, "508101": {"image_id": 508101, "Bleu_1": 0.387755102032903, "Bleu_2": 0.3240632759175129, "Bleu_3": 0.23755873797126636, "Bleu_4": 0.15538042251583314, "METEOR": 0.2582807234045538, "ROUGE_L": 0.23091482649842268, "CIDEr": 9.440123803805072e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A man is standing on a small boat in the ocean, holding a fishing rod. There are two other people in the background, one of whom is standing on the shore and looking out at the water. The sky is cloudy and there are some waves in the distance."}, "25005": {"image_id": 25005, "Bleu_1": 0.22807017543459532, "Bleu_2": 0.1276351315918384, "Bleu_3": 0.08398516678948022, "Bleu_4": 0.0575510831581648, "METEOR": 0.2348930383354101, "ROUGE_L": 0.20926243567753, "CIDEr": 7.975393183987445e-15, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.1875, "f": 0.23529411764705882, "fn": 26.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.2, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a man skiing down a snowy hill. He is wearing a black and orange suit with white gloves and goggles on his face. He has a pair of skis on his feet and is holding onto the handlebars of a snowboard. The sun is shining in the background, casting a warm glow over the scene."}, "345937": {"image_id": 345937, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.24331962586375616, "Bleu_3": 0.17394044861887759, "Bleu_4": 0.12436402493891653, "METEOR": 0.279246791008508, "ROUGE_L": 0.38547394337299956, "CIDEr": 5.768342598393125e-07, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.07407407407407407, "f": 0.07407407407407407, "fn": 25.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "A young boy is standing in front of a fence, looking at some sheep grazing in the field beyond. The fence is made of wooden posts and rails, and there are some trees in the background. The sky is blue and there are some clouds in it."}, "389419": {"image_id": 389419, "Bleu_1": 0.3999999999800001, "Bleu_2": 0.25131234496212107, "Bleu_3": 1.5195618441138907e-06, "Bleu_4": 3.790325913312514e-09, "METEOR": 0.28366366952196514, "ROUGE_L": 0.37014563106796117, "CIDEr": 0.15258029853544794, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.21052631578947367, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The man in the image is wearing a black suit and tie, and is pointing to something on the wall."}, "425964": {"image_id": 425964, "Bleu_1": 0.15476190476006238, "Bleu_2": 0.11424626398718135, "Bleu_3": 0.07816226550010634, "Bleu_4": 0.0492749961852932, "METEOR": 0.1826277195875578, "ROUGE_L": 0.21378504672897194, "CIDEr": 4.7553604225171766e-31, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.16666666666666666, "f": 0.2325581395348837, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a table with two women and a plate of food in front of him. The man is wearing a gray shirt and black pants, while the women are wearing dresses and heels. The table has a white tablecloth and a vase of flowers on it. There are several bottles of beer and glasses on the table as well. The background is a dimly lit bar with a wooden floor and a long wooden bar in the center."}, "84866": {"image_id": 84866, "Bleu_1": 0.47368421050138515, "Bleu_2": 0.32444284224397485, "Bleu_3": 0.23135869341855983, "Bleu_4": 0.1667955161284029, "METEOR": 0.2796234279446681, "ROUGE_L": 0.3817271589486859, "CIDEr": 0.22223351555644086, "SPICE": {"All": {"pr": 0.05, "re": 0.06666666666666667, "f": 0.05714285714285715, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of children playing tennis on a sunny day\""}, "25134": {"image_id": 25134, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.15760480727682824, "Bleu_3": 0.07581492126210977, "Bleu_4": 9.392236277521492e-06, "METEOR": 0.21494724354179748, "ROUGE_L": 0.20760068065796938, "CIDEr": 1.2705768895560083e-12, "SPICE": {"All": {"pr": 0.04, "re": 0.034482758620689655, "f": 0.03703703703703704, "fn": 28.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "This is an image of a bus stop with several buses parked in front of it. The buses are white and have red and blue stripes on them. There are people standing around the bus stop, looking at their phones or talking to each other. The sky is cloudy and there is a lot of fog in the air."}, "250260": {"image_id": 250260, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.23644230070621639, "Bleu_3": 0.1751750854322906, "Bleu_4": 0.133349693903898, "METEOR": 0.3206384618938622, "ROUGE_L": 0.3690869086908691, "CIDEr": 3.110713277744265e-11, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2857142857142857, "f": 0.24000000000000002, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two trains parked on a train platform. One of the trains is blue and yellow, while the other is red and white. The trains are parked next to each other on the platform, with their engines facing away from the camera. There are buildings and other structures visible in the background."}, "128699": {"image_id": 128699, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.13401187884939042, "Bleu_3": 7.205793047605259e-07, "Bleu_4": 1.6797199261809358e-09, "METEOR": 0.12525542276327598, "ROUGE_L": 0.22235722964763066, "CIDEr": 1.3638653920831146e-10, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.03571428571428571, "f": 0.0392156862745098, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "This is an image of a skateboarder jumping over a brick wall. The skateboarder is wearing a black shirt and jeans, and has a backpack on his back. The brick wall is painted with a mural of a city skyline. There are people watching the skateboarder from behind the wall."}, "383066": {"image_id": 383066, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.20412414522772235, "Bleu_3": 0.12103388266975182, "Bleu_4": 0.07879356782644797, "METEOR": 0.23259538775594135, "ROUGE_L": 0.2663755458515284, "CIDEr": 2.1514197111756397e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.625, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is an image of a woman in a blue and white uniform standing behind a counter at a market. She is holding a tray with food on it and looking at something on her phone. There are other people in the background shopping and talking to each other."}, "567812": {"image_id": 567812, "Bleu_1": 0.20833333332899312, "Bleu_2": 0.11531640100118269, "Bleu_3": 0.0661213089813225, "Bleu_4": 8.952677771744006e-06, "METEOR": 0.24398529766884836, "ROUGE_L": 0.3028368794326241, "CIDEr": 3.176799912692159e-09, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The man is sitting on the bed with his arms around a teddy bear. He is wearing a black shirt and blue jeans. The teddy bear is sitting on his lap and looking up at him. The room is dimly lit and there are curtains on the windows."}, "477085": {"image_id": 477085, "Bleu_1": 0.6666666665185187, "Bleu_2": 0.40824829037030635, "Bleu_3": 2.8768479126408824e-06, "Bleu_4": 7.936880924121685e-09, "METEOR": 0.17472946830148467, "ROUGE_L": 0.4911433172302737, "CIDEr": 0.6108634016434757, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23529411764705882, "f": 0.20512820512820512, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A group of sheep grazing in a green field."}, "186412": {"image_id": 186412, "Bleu_1": 0.2786885245855953, "Bleu_2": 0.2155181835255634, "Bleu_3": 0.1677859887689728, "Bleu_4": 0.13434600859354054, "METEOR": 0.27992445584054454, "ROUGE_L": 0.27617678763923825, "CIDEr": 2.423417665275121e-12, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.19047619047619047, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5, "f": 0.5333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This image shows a group of people sitting in a garage with chairs and tables around them. There are several tools and equipment on the walls, including a tool bench, a workbench, and a shelf with various tools and supplies. The garage has a large window that lets in natural light, and there is a door leading out to the street."}, "364567": {"image_id": 364567, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.15291943545714587, "Bleu_3": 0.09983569293155374, "Bleu_4": 0.06819851521727724, "METEOR": 0.15559272378577377, "ROUGE_L": 0.19242902208201892, "CIDEr": 2.4612173988153065e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1875, "f": 0.17647058823529413, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a horse jumping over a barrel in a competition. The horse is wearing a black and white striped saddle and bridle, and the rider is wearing a blue shirt and pants. The background is a green field with white fences and a blue sky."}, "402823": {"image_id": 402823, "Bleu_1": 0.8181818181074382, "Bleu_2": 0.7006490496784906, "Bleu_3": 0.6020134378481848, "Bleu_4": 0.4832697830390307, "METEOR": 0.32586199822889694, "ROUGE_L": 0.6539050535987749, "CIDEr": 1.9985660389248092, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.15384615384615385, "f": 0.10810810810810811, "fn": 22.0, "numImages": 1.0, "fp": 44.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 25.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.36363636363636365, "f": 0.33333333333333337, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A woman riding a horse over a jump in a field."}, "375763": {"image_id": 375763, "Bleu_1": 0.5624999999648439, "Bleu_2": 0.433012701864254, "Bleu_3": 0.2992042402742815, "Bleu_4": 0.2130541361810694, "METEOR": 0.2564220811433084, "ROUGE_L": 0.5618421052631578, "CIDEr": 0.8011247920493437, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.15, "f": 0.13043478260869565, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "A flock of sheep grazing in a green field with a stone wall in the background."}, "328283": {"image_id": 328283, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.15613914506966814, "Bleu_3": 0.08092609555849525, "Bleu_4": 1.0417495275554298e-05, "METEOR": 0.16554722271614689, "ROUGE_L": 0.27371794871794874, "CIDEr": 3.3812456546137036e-10, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people skiing down a snowy slope. They are all wearing ski gear and helmets, and some of them are carrying skis on their backs. The trees in the background are covered in snow, and there is a mountain range in the distance."}, "566264": {"image_id": 566264, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2822385621600037, "Bleu_3": 0.23678843319704615, "Bleu_4": 0.19736418685234536, "METEOR": 0.32367065287609165, "ROUGE_L": 0.3830455259026687, "CIDEr": 8.077064095588997e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.3157894736842105, "f": 0.22641509433962262, "fn": 13.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.625, "f": 0.4166666666666667, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a dog swimming in the ocean. The dog is swimming in the water and appears to be enjoying itself. The background of the image is a body of water with waves and a clear sky."}, "145208": {"image_id": 145208, "Bleu_1": 0.37999999999240003, "Bleu_2": 0.19691498216873898, "Bleu_3": 0.13432159682352965, "Bleu_4": 0.08473930935411031, "METEOR": 0.19404626273115097, "ROUGE_L": 0.1937738246505718, "CIDEr": 8.19575788080397e-09, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.10714285714285714, "f": 0.1276595744680851, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people surfing on a large wave in the ocean. One person is standing on the board, while another person is sitting on the board and paddling. The waves are crashing against the shore and there are other people in the background watching the surfers."}, "412621": {"image_id": 412621, "Bleu_1": 0.21739130434310025, "Bleu_2": 0.1390096093683277, "Bleu_3": 7.601144519394984e-07, "Bleu_4": 1.7876896610284684e-09, "METEOR": 0.1676919728270867, "ROUGE_L": 0.24238410596026488, "CIDEr": 1.430043068705985e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.15, "f": 0.18749999999999997, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a person in a black and white jumpsuit jumping off a bridge into the air. The person is wearing a helmet and has their arms outstretched as they fly through the air. There are buildings and trees in the background of the image."}, "289263": {"image_id": 289263, "Bleu_1": 0.41666666665509267, "Bleu_2": 0.28867513458667965, "Bleu_3": 0.16987257791700947, "Bleu_4": 1.9631974133116808e-05, "METEOR": 0.26225001052206104, "ROUGE_L": 0.33888888888888885, "CIDEr": 0.0001817384836565728, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.14814814814814814, "f": 0.16666666666666666, "fn": 23.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The woman is standing on the beach holding a surfboard. She is wearing a bikini and has her hair tied back in a ponytail. The sky is blue and there are waves crashing on the shore."}, "315491": {"image_id": 315491, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.21733262130578967, "Bleu_3": 0.10847992362433123, "Bleu_4": 1.3722599955620144e-05, "METEOR": 0.1978475944452242, "ROUGE_L": 0.3146357188910381, "CIDEr": 0.00014084819154675738, "SPICE": {"All": {"pr": 0.075, "re": 0.23076923076923078, "f": 0.11320754716981132, "fn": 10.0, "numImages": 1.0, "fp": 37.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.6, "f": 0.2857142857142857, "fn": 2.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a street with a red traffic light on the corner. There are buildings on either side of the street, and a car is parked on the side of the road. The sky is clear and blue."}, "509037": {"image_id": 509037, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.2014440620697061, "Bleu_3": 0.15451551194272492, "Bleu_4": 0.1144509623825141, "METEOR": 0.27260509118351095, "ROUGE_L": 0.2367399741267788, "CIDEr": 3.172216850581549e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.14285714285714285, "f": 0.17777777777777778, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a group of people standing under an umbrella on the sidewalk at night. They are dressed in casual clothing and appear to be socializing with each other. The surrounding buildings are dark and there are no streetlights visible in the image."}, "157019": {"image_id": 157019, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.08157154566934656, "Bleu_4": 1.042232377987996e-05, "METEOR": 0.19313697777813438, "ROUGE_L": 0.19690122659780504, "CIDEr": 1.8574466303395946e-09, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.15789473684210525, "f": 0.125, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 6.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a city street with tall buildings on either side of the road. There are cars parked on the side of the road and pedestrians walking in the rain. The sky is overcast with clouds and there is a light drizzle of rain falling from the sky."}, "352290": {"image_id": 352290, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.3523321316968753, "Bleu_3": 0.2809132075025285, "Bleu_4": 0.2227760460531123, "METEOR": 0.26903033567396883, "ROUGE_L": 0.4128595600676818, "CIDEr": 0.011303946315339208, "SPICE": {"All": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 12.0, "numImages": 1.0, "fp": 28.0, "tp": 4.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a brown horse standing in a field with mountains in the background. The horse is looking up at the sky and appears to be enjoying the view."}, "293768": {"image_id": 293768, "Bleu_1": 0.22448979591378598, "Bleu_2": 0.16751484856166823, "Bleu_3": 0.10609125460399942, "Bleu_4": 1.2693173928949333e-05, "METEOR": 0.20335521829527547, "ROUGE_L": 0.23303196230739842, "CIDEr": 1.8335301544392163e-10, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a young man performing a trick on a skateboard in a park. He is wearing a red hoodie and blue jeans, and has his arms outstretched as he jumps off the ramp. The sky is a bright pink color, and there are trees in the background."}, "14338": {"image_id": 14338, "Bleu_1": 0.1126760563364412, "Bleu_2": 0.06949081840733604, "Bleu_3": 4.1209934167233974e-07, "Bleu_4": 1.007219702132267e-09, "METEOR": 0.15856314792214757, "ROUGE_L": 0.17259266245402244, "CIDEr": 1.2933496344737339e-23, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.13793103448275862, "f": 0.1702127659574468, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a large boat in the middle of the ocean, with a group of people on board. The boat is white and has a large deck with windows on the sides. There are several people standing on the deck, looking out at the water. In the background, there is a large mountain range with snow covered peaks. The sky is clear and blue, with a few clouds scattered about."}, "154230": {"image_id": 154230, "Bleu_1": 0.065843621398906, "Bleu_2": 0.043641351504250074, "Bleu_3": 0.025095919468203186, "Bleu_4": 2.8487184190350934e-06, "METEOR": 0.07530246053112583, "ROUGE_L": 0.07541338278473188, "CIDEr": 3.44535147e-316, "SPICE": {"All": {"pr": 0.34615384615384615, "re": 0.2727272727272727, "f": 0.3050847457627119, "fn": 24.0, "numImages": 1.0, "fp": 17.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.5833333333333334, "f": 0.5833333333333334, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "This is a black and white image of a desk with a laptop on it. There are two books on the desk and a small pile of papers in the corner. The wall behind the desk has a large window with blinds open.\n\nThe laptop on the desk has a black case with a white screen. There is a small pile of papers on the desk next to the laptop. The papers have different colors and patterns on them.\n\nThere is a small pile of books on the desk next to the laptop. The books have different colors and patterns on their covers.\n\nThere is a small pile of papers on the desk next to the laptop. The papers have different colors and patterns on them.\n\nThere is a small pile of books on the desk next to the laptop. The books have different colors and patterns on their covers.\n\nThere is a small pile of papers on the desk next to the laptop. The papers have different colors and patterns on them.\n\nThere is a small pile of books on the desk next to the laptop. The books have different colors and patterns on their covers.\n\nThere is a small pile of papers on the desk next to the laptop. The papers have different colors and patterns on them.\n\nThere is a small pile of books on the desk next to the laptop. The books have different colors and patterns on their"}, "219458": {"image_id": 219458, "Bleu_1": 0.18421052631336565, "Bleu_2": 0.09911892555535753, "Bleu_3": 0.06427426944847772, "Bleu_4": 0.043671403237955035, "METEOR": 0.178547426934366, "ROUGE_L": 0.23817787418655098, "CIDEr": 1.900859007895425e-25, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13636363636363635, "f": 0.13636363636363635, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This image shows a woman wearing a black and white striped dress, a black hat with a white feather on it, and a pair of black boots. She is standing in front of a window with curtains open, looking out at something outside. The room appears to be dimly lit, with only a small amount of light coming from the window. The woman's face is expressionless, and she is holding a phone to her ear."}, "495183": {"image_id": 495183, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.253320198544886, "Bleu_3": 0.1818738688549909, "Bleu_4": 0.11802861352029913, "METEOR": 0.4171495518160909, "ROUGE_L": 0.37521968365553604, "CIDEr": 0.00014192474959833277, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.2777777777777778, "f": 0.2777777777777778, "fn": 13.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a woman riding a bicycle down the street. She is wearing a blue shirt and jeans, and has a helmet on her head. There are trees and houses in the background."}, "58772": {"image_id": 58772, "Bleu_1": 0.3142857142767348, "Bleu_2": 0.16652655174285833, "Bleu_3": 0.09436646347668316, "Bleu_4": 1.272992265798798e-05, "METEOR": 0.2233676265554817, "ROUGE_L": 0.2469635627530364, "CIDEr": 0.00014004049722239658, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.17647058823529413, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of blue umbrellas lined up against a fence in front of a building. There are several trees and plants visible in the background, and the sky is clear and blue."}, "104486": {"image_id": 104486, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.12399138853119372, "Bleu_3": 0.06661825222088168, "Bleu_4": 8.725742282618853e-06, "METEOR": 0.17508052043073416, "ROUGE_L": 0.1783625730994152, "CIDEr": 5.741523866494381e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.15, "f": 0.16666666666666663, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This image shows a man carrying luggage through a hotel lobby. The man is wearing a suit and tie, and he appears to be checking in at the front desk. There are other people in the background, some of whom are also carrying luggage. The overall atmosphere is one of busy activity and travel."}, "190326": {"image_id": 190326, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.25303041366748835, "Bleu_3": 0.14862901964760822, "Bleu_4": 0.09641215953986118, "METEOR": 0.25872274781395677, "ROUGE_L": 0.3413754508145753, "CIDEr": 0.00020356107605887973, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.22727272727272727, "f": 0.25641025641025644, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on the back of a motorcycle parked on the side of a narrow street lined with buildings. The cat is looking out of the window of the motorcycle, and there are other cars parked nearby."}, "113828": {"image_id": 113828, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.21381869073854032, "Bleu_3": 0.17520942675548123, "Bleu_4": 0.13403120253766126, "METEOR": 0.24275268823799723, "ROUGE_L": 0.25707405177603854, "CIDEr": 2.5186050110027594e-11, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23529411764705882, "f": 0.20512820512820512, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Here is a short caption for the image:\n\n\"A group of red double decker buses are parked on the side of a city street. They are lined up in a row, with one in the front and the others behind it. The buses have the words 'London' written on them in white letters.\""}, "148392": {"image_id": 148392, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.23045544793969702, "Bleu_3": 0.145243695343206, "Bleu_4": 1.565598596670107e-05, "METEOR": 0.2642794020758571, "ROUGE_L": 0.24124293785310735, "CIDEr": 4.096958777789365e-11, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.2222222222222222, "f": 0.16666666666666669, "fn": 14.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This image shows a tree that has been cut down and lying on the ground. There is a fire hydrant nearby, and a person in a yellow safety vest is standing next to it. The tree appears to have been cut down by a chainsaw, and there are branches and debris scattered around it."}, "221155": {"image_id": 221155, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.21060588478687045, "Bleu_3": 1.139217330716798e-06, "Bleu_4": 2.6721168024330813e-09, "METEOR": 0.22909500159536583, "ROUGE_L": 0.2629310344827586, "CIDEr": 0.0007414442909317032, "SPICE": {"All": {"pr": 0.2, "re": 0.07407407407407407, "f": 0.10810810810810811, "fn": 25.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.16666666666666666, "f": 0.23529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is an image of a small barn with two cows standing in front of it. The barn has a windmill on top of it and there are trees in the background."}, "469877": {"image_id": 469877, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.09618052714368557, "Bleu_3": 5.901837724618786e-07, "Bleu_4": 1.470202913098025e-09, "METEOR": 0.13798959656109855, "ROUGE_L": 0.22775357809583074, "CIDEr": 5.1560762818232945e-08, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a trash can on the side of a street with graffiti on it. The trash can is painted with the words \"stop\" and \"all ways\" in bold, colorful letters. The background is a cityscape with tall buildings and a mountain range in the distance."}, "494456": {"image_id": 494456, "Bleu_1": 0.5789473683905818, "Bleu_2": 0.4744957310725266, "Bleu_3": 0.29809079441887354, "Bleu_4": 3.587000421109487e-05, "METEOR": 0.30428811177584986, "ROUGE_L": 0.511377245508982, "CIDEr": 0.3318000140199762, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16, "f": 0.15384615384615383, "fn": 21.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Here is a short caption for the image:\n\n\"Two men standing on skis in front of a mountain range\""}, "553248": {"image_id": 553248, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.2661770133303563, "Bleu_3": 0.1790964078865936, "Bleu_4": 0.1336586376746963, "METEOR": 0.323517492266165, "ROUGE_L": 0.3756735950731332, "CIDEr": 2.5104917144147553e-05, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.14814814814814814, "f": 0.19047619047619047, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a person holding a slice of pizza in their hand. The pizza appears to be topped with cheese, pepperoni, and other toppings. There is also a box of pizza on the table next to the person."}, "300233": {"image_id": 300233, "Bleu_1": 0.6666666666111113, "Bleu_2": 0.3481553118810641, "Bleu_3": 2.2971111883989787e-06, "Bleu_4": 6.057952803035667e-09, "METEOR": 0.16169603476850677, "ROUGE_L": 0.2932692307692307, "CIDEr": 0.41164517219722335, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "Image of a kitchen with various ingredients and spices on the countertop."}, "316359": {"image_id": 316359, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.15328483486852826, "Bleu_3": 7.531449419024147e-07, "Bleu_4": 1.6771058848033942e-09, "METEOR": 0.2207152107235104, "ROUGE_L": 0.24247586598523563, "CIDEr": 8.890986883783332e-14, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2608695652173913, "f": 0.28571428571428575, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThis giraffe is lying down on the grass, looking up at the camera with its long neck stretched out. Its spots are visible on its brown fur, and it has a long, curved horn on its head. The background is green and there are trees in the distance."}, "389410": {"image_id": 389410, "Bleu_1": 0.6666666665777778, "Bleu_2": 0.5773502691112712, "Bleu_3": 0.42529037022415583, "Bleu_4": 0.2829559627926664, "METEOR": 0.23061110973906804, "ROUGE_L": 0.43416370106761565, "CIDEr": 1.3150554414584181, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A dog is sitting on a windowsill looking out the window at the city below."}, "415856": {"image_id": 415856, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.20391006635932993, "Bleu_3": 0.09281638782109244, "Bleu_4": 1.1189893497623519e-05, "METEOR": 0.22369659213214657, "ROUGE_L": 0.20962199312714777, "CIDEr": 2.5148593921012888e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1724137931034483, "f": 0.16949152542372883, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a group of horses standing in a river, with one horse drinking from the water. There are two people standing on the bank of the river, one of them holding a bucket and the other looking at the horses. The sky is cloudy and there are some trees in the background."}, "494810": {"image_id": 494810, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.26437184629550714, "Bleu_3": 0.16892248770152052, "Bleu_4": 0.1145449886714462, "METEOR": 0.1909202029898692, "ROUGE_L": 0.3224669603524229, "CIDEr": 0.0014663901539242817, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.20833333333333334, "f": 0.19607843137254902, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "A person is holding a plate of food in their hand, with a hamburger and fries on the plate. There are also glasses of soda and other drinks on the table."}, "13637": {"image_id": 13637, "Bleu_1": 0.42857142856268227, "Bleu_2": 0.31339158525754207, "Bleu_3": 0.18438801389646708, "Bleu_4": 0.10804633922009936, "METEOR": 0.29095262026391044, "ROUGE_L": 0.314901915796719, "CIDEr": 2.5990720370531976e-08, "SPICE": {"All": {"pr": 0.15625, "re": 0.2, "f": 0.17543859649122806, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.36363636363636365, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man stands next to a fire hydrant on a street with a yellow line down the middle. The man is wearing a black shirt and blue jeans, and he is crouching down to look at something on the ground.\""}, "18295": {"image_id": 18295, "Bleu_1": 0.5142857142710204, "Bleu_2": 0.347862621381384, "Bleu_3": 0.2447863485429599, "Bleu_4": 0.17400446793518276, "METEOR": 0.2951540947209632, "ROUGE_L": 0.4452554744525547, "CIDEr": 0.002757413106691095, "SPICE": {"All": {"pr": 0.12, "re": 0.16666666666666666, "f": 0.13953488372093023, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.42857142857142855, "f": 0.3157894736842105, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a train traveling down a railroad track. The train is blue and white with a number on the side. There are trees and greenery on either side of the track."}, "303744": {"image_id": 303744, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.19758299278252553, "Bleu_3": 0.10370754607930319, "Bleu_4": 1.3458232889827183e-05, "METEOR": 0.2699186714646607, "ROUGE_L": 0.3277052954719877, "CIDEr": 6.569312824179966e-05, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.23809523809523808, "f": 0.1923076923076923, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4444444444444444, "f": 0.33333333333333337, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a person standing on the shore of a lake, holding a kite. The sky is clear and blue, with no clouds in sight. The trees are bare and there is snow on the ground."}, "385236": {"image_id": 385236, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.142442462319253, "Bleu_3": 7.725775597136251e-07, "Bleu_4": 1.8096286076349793e-09, "METEOR": 0.20933910927620075, "ROUGE_L": 0.2019867549668874, "CIDEr": 1.0442066170180017e-07, "SPICE": {"All": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a street with tall, colorful buildings on either side. In the center of the street is a large clock tower with a red and white striped flag flying from it. There are people walking on the street and bicycles parked along the side."}, "525971": {"image_id": 525971, "Bleu_1": 0.378378378368152, "Bleu_2": 0.22924343512884385, "Bleu_3": 0.1442730640873472, "Bleu_4": 0.09694361543381819, "METEOR": 0.2493887075920261, "ROUGE_L": 0.32323996971990915, "CIDEr": 2.207268242774073e-05, "SPICE": {"All": {"pr": 0.375, "re": 0.25, "f": 0.3, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.4166666666666667, "f": 0.5, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is an image of a group of people gathered in a parking lot. They are all riding motorcycles and there are several cars parked nearby. The sky is clear and there are trees in the background."}, "84533": {"image_id": 84533, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.17351520647985194, "Bleu_3": 1.0125714893868398e-06, "Bleu_4": 2.4676284196864047e-09, "METEOR": 0.294346102621196, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.0008734203937062442, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.15789473684210525, "f": 0.16216216216216214, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The woman is sitting on the back of a black motorcycle, wearing a leather jacket and sunglasses. She is parked in front of a white building with a garage door open."}, "162732": {"image_id": 162732, "Bleu_1": 0.305555555547068, "Bleu_2": 0.2288688541020835, "Bleu_3": 0.18333757735173692, "Bleu_4": 0.13901690971710404, "METEOR": 0.34898241923000356, "ROUGE_L": 0.4107744107744108, "CIDEr": 5.076807769419536e-05, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.045454545454545456, "f": 0.04, "fn": 21.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a group of soccer players in orange and blue uniforms standing on a field with a referee in the background. One player is holding a ball while another player is talking to him."}, "556091": {"image_id": 556091, "Bleu_1": 0.6499999999675001, "Bleu_2": 0.41358509591303216, "Bleu_3": 0.26686753869549923, "Bleu_4": 0.18285615451974122, "METEOR": 0.2975044747483014, "ROUGE_L": 0.46923076923076923, "CIDEr": 0.47347859637513584, "SPICE": {"All": {"pr": 0.25, "re": 0.11538461538461539, "f": 0.15789473684210525, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "A desk with a computer, keyboard, and headphones on it. There is also a monitor and speakers on the desk."}, "11494": {"image_id": 11494, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.2201927530212316, "Bleu_3": 0.14000723407827462, "Bleu_4": 0.08523383334872278, "METEOR": 0.2209958381666248, "ROUGE_L": 0.2363032650802435, "CIDEr": 2.327664985543002e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.15789473684210525, "f": 0.12244897959183673, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.6, "f": 0.33333333333333337, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people on a bus, waving and taking pictures. They are all wearing colorful clothing and hats, and some are holding signs that say \"LGBTQ+ Pride\" and \"Equality Now\". The bus is decorated with rainbow flags and banners, and there are people standing on the sidewalk watching the parade."}, "284954": {"image_id": 284954, "Bleu_1": 0.34615384614053263, "Bleu_2": 0.23533936215658835, "Bleu_3": 1.3214760629595458e-06, "Bleu_4": 3.164918395250227e-09, "METEOR": 0.21388193821895174, "ROUGE_L": 0.24158415841584158, "CIDEr": 0.046616475838788037, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.1, "f": 0.08333333333333333, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A pair of bicycles parked on the sidewalk outside a business with a blue and white awning.\""}, "304063": {"image_id": 304063, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.17205295744403565, "Bleu_3": 0.08697022430943882, "Bleu_4": 1.105769924492212e-05, "METEOR": 0.17235717787809288, "ROUGE_L": 0.23843648208469054, "CIDEr": 8.780106781784247e-10, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2, "f": 0.19607843137254902, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a military aircraft flying in the sky. The plane has a distinctive design with a large propeller on the front and a small cockpit on top. It appears to be flying at a high altitude, with the sun shining brightly behind it."}, "205035": {"image_id": 205035, "Bleu_1": 0.3863636363548554, "Bleu_2": 0.2681074537606562, "Bleu_3": 1.1961606057428295e-06, "Bleu_4": 2.541827987369499e-09, "METEOR": 0.2582051186308048, "ROUGE_L": 0.35012755102040816, "CIDEr": 6.937097065543081e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.12, "f": 0.1935483870967742, "fn": 22.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "A man is sitting on a boat in the water, looking out at the horizon. The boat is covered with a green tarp and has a small dog sitting on top of it. There are trees and grass on the shore in the background."}, "138784": {"image_id": 138784, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.2506402059074552, "Bleu_3": 0.11824223412532588, "Bleu_4": 1.4538815963237528e-05, "METEOR": 0.19546660842609362, "ROUGE_L": 0.2621776504297994, "CIDEr": 2.664263559563348e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.13636363636363635, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.25, "f": 0.35294117647058826, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a train on a railroad track. The train is red and has windows on the sides. There are people standing on the platform next to the train. In the background, there are trees and buildings."}, "529069": {"image_id": 529069, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.23570226038887507, "Bleu_3": 0.14839736556269426, "Bleu_4": 1.7739491161500994e-05, "METEOR": 0.2726660138854184, "ROUGE_L": 0.308080808080808, "CIDEr": 4.350755499575606e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.10526315789473684, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.18181818181818182, "f": 0.26666666666666666, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted white and the floor is made of wood. There is a light fixture above the sink and a window in the background."}, "197245": {"image_id": 197245, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.3578810105677576, "Bleu_3": 0.26672138996395667, "Bleu_4": 0.16436148153932637, "METEOR": 0.29437354694436724, "ROUGE_L": 0.44976958525345617, "CIDEr": 0.009184654566328394, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.125, "f": 0.13043478260869565, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A cat is laying on a couch next to a television with the remote control in its paw. The cat appears to be sleeping or relaxing while watching television."}, "434066": {"image_id": 434066, "Bleu_1": 0.5333333332977779, "Bleu_2": 0.39036002915245993, "Bleu_3": 0.2271585618034379, "Bleu_4": 3.1437754723697544e-05, "METEOR": 0.2827642819582477, "ROUGE_L": 0.4979591836734694, "CIDEr": 0.7366075996602004, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.2692307692307692, "f": 0.2641509433962264, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows three zebras standing in a grassy field with mountains in the background."}, "511463": {"image_id": 511463, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 0.07777190244898266, "Bleu_4": 1.0056053706911773e-05, "METEOR": 0.2640898435876501, "ROUGE_L": 0.27354260089686094, "CIDEr": 7.894270790969335e-09, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.17857142857142858, "f": 0.1923076923076923, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The woman is walking her dog on a leash through the woods. The dog is wearing a red collar and is pulling on the leash. The woman is smiling and looking down at the dog. The trees in the background are tall and green, with leaves on the ground."}, "320524": {"image_id": 320524, "Bleu_1": 0.4313725490111496, "Bleu_2": 0.24574815738953795, "Bleu_3": 0.10721646565241055, "Bleu_4": 1.2658603758897227e-05, "METEOR": 0.2081231987107028, "ROUGE_L": 0.28549141965678626, "CIDEr": 7.211036780799544e-06, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.125, "f": 0.07999999999999999, "fn": 21.0, "numImages": 1.0, "fp": 48.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 19.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.375, "f": 0.20689655172413796, "fn": 5.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}}, "caption": "The image shows a baseball game in progress at a stadium. There are several players on the field, including one who is running towards home plate with a bat in his hand. The crowd is cheering and waving their arms in the air. The sky is pink and orange during sunset."}, "290231": {"image_id": 290231, "Bleu_1": 0.25641025640368187, "Bleu_2": 0.20121090914115636, "Bleu_3": 0.12983061254080153, "Bleu_4": 0.08829928855227857, "METEOR": 0.23020631974824124, "ROUGE_L": 0.2741573033707865, "CIDEr": 5.204445605551752e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.20689655172413793, "f": 0.20338983050847456, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.4166666666666667, "f": 0.3846153846153846, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a person riding a motorcycle on a race track. The person is wearing a helmet and has their arms outstretched as they ride the bike. The background is a green field with trees in the distance."}, "317999": {"image_id": 317999, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.14869042853022912, "Bleu_3": 0.07777190244898266, "Bleu_4": 1.0056053706911773e-05, "METEOR": 0.21485214519119644, "ROUGE_L": 0.3010487353485503, "CIDEr": 1.1743434961889206e-07, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.13636363636363635, "f": 0.1818181818181818, "fn": 19.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a man sitting in bed with his daughter, holding a bottle of milk. The man is wearing glasses and has a beard. The child is wearing a onesie and has a pacifier in her mouth. The bed is covered in a blue and white striped blanket."}, "463670": {"image_id": 463670, "Bleu_1": 0.3199999999936, "Bleu_2": 0.22857142856681054, "Bleu_3": 0.1483569743355745, "Bleu_4": 0.0912970008870191, "METEOR": 0.25964403916801104, "ROUGE_L": 0.2594167679222357, "CIDEr": 8.596729804775461e-10, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.21428571428571427, "f": 0.1276595744680851, "fn": 11.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.6666666666666666, "f": 0.23529411764705882, "fn": 1.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "This is a picture of a dog lying on a blue blanket. The dog is white and has spots on its fur. It is looking up at the camera with its tongue hanging out of its mouth. There are some books and toys on the floor next to the dog."}, "255338": {"image_id": 255338, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 0.09105491676695633, "Bleu_4": 1.1795365411101286e-05, "METEOR": 0.22180349148632028, "ROUGE_L": 0.22197962154294032, "CIDEr": 1.5244721937474775e-07, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16666666666666666, "f": 0.2285714285714286, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.21428571428571427, "f": 0.3157894736842105, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing blue and orange clothing and has a backpack on their back. They are holding a pair of skis and appear to be enjoying the snowy conditions."}, "146315": {"image_id": 146315, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.32816506164407266, "Bleu_3": 0.20781065557855458, "Bleu_4": 2.4993029414165317e-05, "METEOR": 0.20246129697639723, "ROUGE_L": 0.2772727272727273, "CIDEr": 0.03642944259320782, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.16, "f": 0.19047619047619052, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A group of people are gathered around a table, looking at their phones. One man is holding up his phone to show something to the others."}, "306154": {"image_id": 306154, "Bleu_1": 0.4285714285561225, "Bleu_2": 0.28171808489925787, "Bleu_3": 0.2092148242246677, "Bleu_4": 0.16451929399311177, "METEOR": 0.21848558452606756, "ROUGE_L": 0.2951612903225806, "CIDEr": 0.044390098681979205, "SPICE": {"All": {"pr": 0.16, "re": 0.17391304347826086, "f": 0.16666666666666666, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a small pond with a green bench on the side and some plants growing around it. There is also a small bridge over the pond."}, "418959": {"image_id": 418959, "Bleu_1": 0.3199999999936, "Bleu_2": 0.29137254362798654, "Bleu_3": 0.24186999746942658, "Bleu_4": 0.17335738578671664, "METEOR": 0.22817499408449043, "ROUGE_L": 0.30310559006211185, "CIDEr": 3.1863913411770405e-08, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bird sitting on top of a small puddle of water in the middle of a forest. The bird is looking down at its reflection in the water, and its feathers are ruffled up. The sky above is cloudy and there are some trees in the background."}, "521819": {"image_id": 521819, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.21271781490162775, "Bleu_3": 0.16540015368980918, "Bleu_4": 0.12901292604257925, "METEOR": 0.31389989028239185, "ROUGE_L": 0.330722891566265, "CIDEr": 1.845797085819428e-07, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.0625, "f": 0.0784313725490196, "fn": 30.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people playing frisbee in a park. They are standing in a circle and throwing the frisbee around, laughing and having fun. The sky is clear and blue, with some clouds in the distance. The grass is green and lush, and there are trees in the background."}, "31151": {"image_id": 31151, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.12909944487031175, "Bleu_3": 7.597809220775179e-07, "Bleu_4": 1.855520928856175e-09, "METEOR": 0.16912475761851992, "ROUGE_L": 0.17039106145251398, "CIDEr": 7.234048181095537e-06, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.05, "f": 0.07407407407407408, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This image shows a group of people skiing down a snowy slope. One person is sitting on a sled while the others are standing on skis. They all have helmets on and appear to be enjoying themselves in the snow."}, "100974": {"image_id": 100974, "Bleu_1": 0.13043478260586014, "Bleu_2": 0.053838190204633186, "Bleu_3": 4.0387106795652607e-07, "Bleu_4": 1.1125382292156776e-09, "METEOR": 0.11313131313131314, "ROUGE_L": 0.16968011126564672, "CIDEr": 1.0310476455716562e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.09090909090909091, "f": 0.14285714285714288, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a large airport with several planes parked on the tarmac. There are also several people standing around the airport, looking at the planes or walking towards the terminal building. The sky is clear and blue, with a few clouds scattered in the distance."}, "16439": {"image_id": 16439, "Bleu_1": 0.7199999999712, "Bleu_2": 0.4898979485366315, "Bleu_3": 0.2753200250744422, "Bleu_4": 3.120848453597625e-05, "METEOR": 0.27805822088798526, "ROUGE_L": 0.44162895927601814, "CIDEr": 0.27598829783112855, "SPICE": {"All": {"pr": 0.2, "re": 0.13793103448275862, "f": 0.16326530612244897, "fn": 25.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a desk with a laptop on it and a lamp next to it. There is also a vase of flowers on the table."}, "456578": {"image_id": 456578, "Bleu_1": 0.39999999998666674, "Bleu_2": 0.3107277331223966, "Bleu_3": 0.21789189983999352, "Bleu_4": 0.13990713818737435, "METEOR": 0.2950077316238698, "ROUGE_L": 0.34078212290502796, "CIDEr": 0.015463065601547383, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2727272727272727, "f": 0.18749999999999997, "fn": 8.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The woman is standing in front of a small pizza oven made out of wood. She is holding a plate of pizza in her hand and smiling at the camera."}, "267351": {"image_id": 267351, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.30662207032435856, "Bleu_3": 0.19592909694603244, "Bleu_4": 2.3660362390767172e-05, "METEOR": 0.31344466478253824, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.01636216693043742, "SPICE": {"All": {"pr": 0.25, "re": 0.18518518518518517, "f": 0.2127659574468085, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a white clock tower with a blue sky in the background. The clock has a red hand pointing to the top of the hour."}, "249658": {"image_id": 249658, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.12499999999806191, "Bleu_3": 0.09061503108215828, "Bleu_4": 0.05885756087030317, "METEOR": 0.195021481053517, "ROUGE_L": 0.21128154379020286, "CIDEr": 4.536383825644962e-19, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2, "f": 0.22727272727272727, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a bus driving down the street in front of a group of buildings. The bus is orange and white, with the words \"City Bus\" written on the side. There are people standing on the sidewalk and in the street, looking at the bus as it passes by. The sky is clear and blue, with some clouds visible in the distance."}, "472732": {"image_id": 472732, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.23278142562159646, "Bleu_3": 0.1261375218310181, "Bleu_4": 1.666824532264052e-05, "METEOR": 0.13700549971364057, "ROUGE_L": 0.34743694060211555, "CIDEr": 0.004510140884600181, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.2631578947368421, "f": 0.2631578947368421, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a group of people herding cattle on a dirt road in the middle of nowhere. The sky is cloudy and there are mountains in the background."}, "231991": {"image_id": 231991, "Bleu_1": 0.1475409836041387, "Bleu_2": 0.12146644952482957, "Bleu_3": 0.0908644437936542, "Bleu_4": 0.059970612019828395, "METEOR": 0.2626128743044012, "ROUGE_L": 0.22652519893899206, "CIDEr": 4.970290901260978e-16, "SPICE": {"All": {"pr": 0.22580645161290322, "re": 0.3333333333333333, "f": 0.2692307692307692, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 7.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.1111111111111111, "f": 0.08695652173913043, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.7142857142857143, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a man sitting at a desk in a room. He is wearing a white shirt and black pants, and has a laptop open in front of him. There are several books and papers on the desk, as well as a cup of coffee on the edge. The walls are painted blue and there is a window in the background."}, "433504": {"image_id": 433504, "Bleu_1": 0.30645161289828304, "Bleu_2": 0.21263624430958952, "Bleu_3": 0.14445340243186364, "Bleu_4": 0.10054033494054361, "METEOR": 0.21389965054571342, "ROUGE_L": 0.2821171634121274, "CIDEr": 2.6338805006944814e-16, "SPICE": {"All": {"pr": 0.07317073170731707, "re": 0.125, "f": 0.0923076923076923, "fn": 21.0, "numImages": 1.0, "fp": 38.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.16666666666666666, "f": 0.1, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "This is a black and white image of a room with a table and chairs in it. There are shelves on the walls with various items on them, such as plates, cups, and utensils. The floor is made of wood and there is a rug on it. The windows are open and there is a view of the outside from the room."}, "530033": {"image_id": 530033, "Bleu_1": 0.153846153843787, "Bleu_2": 0.08492077755952802, "Bleu_3": 0.04855445959841509, "Bleu_4": 6.55501849330504e-06, "METEOR": 0.1883099658396171, "ROUGE_L": 0.18778860954335555, "CIDEr": 6.354592772272551e-20, "SPICE": {"All": {"pr": 0.32, "re": 0.2857142857142857, "f": 0.30188679245283023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.06666666666666667, "f": 0.08695652173913045, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5384615384615384, "re": 0.7, "f": 0.608695652173913, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 7.0}}, "caption": "This is a man standing in front of a bathroom sink. He is wearing a black coat and hat, and has his hands in his pockets. There are two toilets on the wall behind him, one with a sign that says \"men\" and the other with a sign that says \"women\". The floor is made of tiles and there are no windows in the room."}, "362352": {"image_id": 362352, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.16094080478419465, "Bleu_3": 0.08318402702711739, "Bleu_4": 1.0694655186909581e-05, "METEOR": 0.1838363928861027, "ROUGE_L": 0.27180140038192235, "CIDEr": 4.411739563144317e-09, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a train on the tracks with people standing next to it. The train has a number 12 written on the side and is pulling into a station. There are people standing on the platform looking at the train as it pulls in."}, "452179": {"image_id": 452179, "Bleu_1": 0.1692307692281657, "Bleu_2": 0.10284416889933573, "Bleu_3": 0.0551661825394365, "Bleu_4": 7.213678400167124e-06, "METEOR": 0.20487913082800321, "ROUGE_L": 0.18438287153652394, "CIDEr": 4.676697944463363e-19, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a bedroom with two beds, one with blue and white striped sheets and the other with yellow and white striped sheets. There is a large window on the left side of the room with curtains open to reveal a view of the ocean. The walls are painted a light blue color and there is a painting on the wall above the beds."}, "540782": {"image_id": 540782, "Bleu_1": 0.7999999999466668, "Bleu_2": 0.5345224837879413, "Bleu_3": 0.28011059395359145, "Bleu_4": 3.678763249653386e-05, "METEOR": 0.3260257977556322, "ROUGE_L": 0.5520361990950226, "CIDEr": 1.1089339773912428, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.2857142857142857, "f": 0.17777777777777778, "fn": 10.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.6, "f": 0.2727272727272727, "fn": 2.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "This is a garden with a bench in the middle surrounded by flowers and trees."}, "26393": {"image_id": 26393, "Bleu_1": 0.34042553190765057, "Bleu_2": 0.21072097723733796, "Bleu_3": 9.955605444507264e-07, "Bleu_4": 2.1761437901966275e-09, "METEOR": 0.20232630152576864, "ROUGE_L": 0.23843648208469054, "CIDEr": 1.37752800257742e-08, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.2222222222222222, "f": 0.2962962962962963, "fn": 14.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5714285714285714, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "This is an image of a train on a railroad track. The train is black and has two smokestacks on the front. There are people standing on the platform next to the train, looking at it. The sky is cloudy and there are trees in the background."}, "382728": {"image_id": 382728, "Bleu_1": 0.20967741935145687, "Bleu_2": 0.14361061402438519, "Bleu_3": 0.07004986068930465, "Bleu_4": 8.736600035760076e-06, "METEOR": 0.2061827973283316, "ROUGE_L": 0.1953041622198506, "CIDEr": 2.42073350378591e-17, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.4117647058823529, "f": 0.36842105263157887, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.8333333333333334, "f": 0.6666666666666667, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a train traveling down the tracks on a sunny day. The train is made up of several black and white locomotives with red and yellow stripes on the sides. There are several cars attached to the back of the train, including one with a large tank on top. The train is moving quickly and appears to be carrying cargo."}, "519611": {"image_id": 519611, "Bleu_1": 0.12658227847941037, "Bleu_2": 0.09007912422071496, "Bleu_3": 0.07497892200835213, "Bleu_4": 0.06386770486484364, "METEOR": 0.18160720780139028, "ROUGE_L": 0.20274200249272956, "CIDEr": 1.369724575112991e-27, "SPICE": {"All": {"pr": 0.3, "re": 0.10344827586206896, "f": 0.15384615384615385, "fn": 26.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a polar bear standing on a rocky outcropping, looking out over a body of water. The bear is white and has a distinctive white fur pattern on its face and chest. It appears to be in a state of agitation or excitement, as it is pawing at the ground with one foot and bending its head down towards the ground with the other. The background is a rocky cliff face with some vegetation growing on it."}, "250313": {"image_id": 250313, "Bleu_1": 0.3953488372001082, "Bleu_2": 0.29106289349457565, "Bleu_3": 0.24364787203296664, "Bleu_4": 0.20620513225749598, "METEOR": 0.33663421023710366, "ROUGE_L": 0.43486714193130266, "CIDEr": 2.5766454435484723e-06, "SPICE": {"All": {"pr": 0.35, "re": 0.2916666666666667, "f": 0.31818181818181823, "fn": 17.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a group of young people playing tennis on a court. They are wearing tennis shoes and holding rackets, and one of them is hitting the ball with his racket. The background is a green field with trees in the distance."}, "256223": {"image_id": 256223, "Bleu_1": 0.47999999998080006, "Bleu_2": 0.34641016149963044, "Bleu_3": 0.250144843590915, "Bleu_4": 0.16331948281263942, "METEOR": 0.35593920709245785, "ROUGE_L": 0.5193945127719962, "CIDEr": 0.07408924603560026, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a plate of pancakes with syrup and butter on the side. There are also cups of coffee and tea on the table."}, "456199": {"image_id": 456199, "Bleu_1": 0.49999999997222233, "Bleu_2": 0.3429971702654019, "Bleu_3": 0.24499865250037733, "Bleu_4": 0.1769497514845518, "METEOR": 0.23915428163122796, "ROUGE_L": 0.4518518518518518, "CIDEr": 0.1352647444844625, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.10526315789473684, "f": 0.10810810810810811, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people skiing down a snowy slope\""}, "148358": {"image_id": 148358, "Bleu_1": 0.5714285713877553, "Bleu_2": 0.4193139346576645, "Bleu_3": 2.4469914284217973e-06, "Bleu_4": 6.041241049999893e-09, "METEOR": 0.2382420187039628, "ROUGE_L": 0.47805642633228845, "CIDEr": 0.7884852149201091, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21739130434782608, "f": 0.18867924528301885, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "There are three zebras standing in a green field with trees in the background."}, "353807": {"image_id": 353807, "Bleu_1": 0.2343749999963379, "Bleu_2": 0.16137430608943423, "Bleu_3": 0.09435589257348495, "Bleu_4": 0.06091781416114966, "METEOR": 0.17925343393588333, "ROUGE_L": 0.21866038508807864, "CIDEr": 3.0315874682118273e-16, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.14285714285714285, "f": 0.12121212121212122, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a white horse pulling a carriage with people inside. The horse is wearing a harness and has a long mane and tail. The carriage is decorated with red and green streamers and has a sign on the side that reads \"Happy Holidays\". People are standing around the carriage, looking at it. There are buildings in the background with windows and balconies."}, "448365": {"image_id": 448365, "Bleu_1": 0.16666666666269844, "Bleu_2": 0.11043152607218519, "Bleu_3": 0.06730418227629331, "Bleu_4": 9.402977292158486e-06, "METEOR": 0.16614596939906975, "ROUGE_L": 0.22197962154294032, "CIDEr": 5.014628216588179e-08, "SPICE": {"All": {"pr": 0.375, "re": 0.15789473684210525, "f": 0.22222222222222218, "fn": 16.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a young boy skateboarding on a concrete skate park. He is wearing a white shirt and shorts, and has his arms outstretched as he jumps off the ramp. The sky is cloudy and there are trees in the background."}, "385535": {"image_id": 385535, "Bleu_1": 0.39999999999, "Bleu_2": 0.267945650816049, "Bleu_3": 0.17829685970436743, "Bleu_4": 1.9783691882995226e-05, "METEOR": 0.2463625764011994, "ROUGE_L": 0.3043044469783352, "CIDEr": 3.4839801871385755e-05, "SPICE": {"All": {"pr": 0.45454545454545453, "re": 0.15625, "f": 0.2325581395348837, "fn": 27.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a street sign with the words \"us 1st st\" written on it. The sign is mounted on a pole and has two traffic lights at the intersection. There are trees and buildings in the background."}, "104320": {"image_id": 104320, "Bleu_1": 0.5555555555246915, "Bleu_2": 0.3615507630104168, "Bleu_3": 0.2014062116637086, "Bleu_4": 2.7166383721925095e-05, "METEOR": 0.22055858621304036, "ROUGE_L": 0.4728682170542636, "CIDEr": 0.20733835854238947, "SPICE": {"All": {"pr": 0.2, "re": 0.11538461538461539, "f": 0.14634146341463417, "fn": 23.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image is a black and white photograph of a cell phone with a keypad on the front."}, "99581": {"image_id": 99581, "Bleu_1": 0.545454545355372, "Bleu_2": 0.40451991740255755, "Bleu_3": 0.3313007624084907, "Bleu_4": 0.2596535888827098, "METEOR": 0.233378895338336, "ROUGE_L": 0.5091819699499166, "CIDEr": 0.6106458037702196, "SPICE": {"All": {"pr": 0.5, "re": 0.11764705882352941, "f": 0.19047619047619047, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "A hand holding a smartphone with an image on the screen."}, "64599": {"image_id": 64599, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.3216337604400496, "Bleu_3": 0.24839327180107798, "Bleu_4": 0.15581581441734033, "METEOR": 0.33520608494924375, "ROUGE_L": 0.42152023692003954, "CIDEr": 0.021220237232296848, "SPICE": {"All": {"pr": 0.09375, "re": 0.09375, "f": 0.09375, "fn": 29.0, "numImages": 1.0, "fp": 29.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "There are several plates of food on a table, with different types of meat and vegetables on them. Some people are holding forks and knives to eat the food."}, "144058": {"image_id": 144058, "Bleu_1": 0.5384615383786985, "Bleu_2": 0.29957234471059097, "Bleu_3": 0.2013122721652155, "Bleu_4": 3.005402808883257e-05, "METEOR": 0.17564421674031128, "ROUGE_L": 0.4093959731543623, "CIDEr": 0.768334279868827, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.2777777777777778, "f": 0.22222222222222224, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A foggy day at the marina with many boats docked in the water."}, "20632": {"image_id": 20632, "Bleu_1": 0.6315789473351802, "Bleu_2": 0.49559462775654367, "Bleu_3": 0.38662335331712344, "Bleu_4": 4.3594938245572526e-05, "METEOR": 0.28495135161540736, "ROUGE_L": 0.4643196955280685, "CIDEr": 0.5253991762429755, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.0625, "f": 0.07142857142857144, "fn": 15.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a suitcase with various items inside, including a stuffed animal, a wallet, and other miscellaneous items."}, "502084": {"image_id": 502084, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.15971914124669148, "Bleu_3": 0.13948538102782226, "Bleu_4": 0.12394301593895299, "METEOR": 0.2842286641933639, "ROUGE_L": 0.27566171723692706, "CIDEr": 4.664962277447051e-10, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.23529411764705882, "f": 0.26666666666666666, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows two polar bears playing in the snow. One of the bears is on its back, while the other is standing on its hind legs and pawing at its face. They are both covered in white fur and appear to be enjoying themselves in the winter weather."}, "223959": {"image_id": 223959, "Bleu_1": 0.5294117646903115, "Bleu_2": 0.45667948248215234, "Bleu_3": 0.4024306103866064, "Bleu_4": 0.32019926682074423, "METEOR": 0.3872506979773755, "ROUGE_L": 0.46763202725724023, "CIDEr": 0.0006831176206461052, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.20833333333333334, "f": 0.23255813953488372, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man standing on a tennis court, holding a tennis racket in his hand. He is wearing a white shirt and black shorts, and has a determined look on his face."}, "5247": {"image_id": 5247, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.26967994497923586, "Bleu_3": 0.18913109886682938, "Bleu_4": 0.11265744222457877, "METEOR": 0.25543279427771076, "ROUGE_L": 0.2053872053872054, "CIDEr": 3.050650803140557e-08, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.1724137931034483, "f": 0.14705882352941177, "fn": 24.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4166666666666667, "f": 0.3703703703703704, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "An older man is walking through the woods on skis, with a backpack on his back. He is wearing a black and white jacket and pants, and has a pair of goggles on his face. The trees in the background are bare and snow covered."}, "543364": {"image_id": 543364, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.3478041718090821, "Bleu_3": 0.2721694910356964, "Bleu_4": 0.19310235945030582, "METEOR": 0.26375512895699393, "ROUGE_L": 0.36810344827586206, "CIDEr": 0.001970384622667909, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2777777777777778, "f": 0.2272727272727273, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and TV. The walls are painted green and there are windows on one side of the room that let in natural light."}, "349021": {"image_id": 349021, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.15512630699387414, "Bleu_3": 9.093693442749552e-07, "Bleu_4": 2.2192938453856764e-09, "METEOR": 0.15396693976198123, "ROUGE_L": 0.24478330658105937, "CIDEr": 0.00012299227727361812, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.24, "f": 0.20338983050847456, "fn": 19.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5714285714285714, "f": 0.36363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a blue and yellow train on the tracks, with people standing next to it. There are buildings in the background, and trees and plants growing along the sides of the tracks."}, "238310": {"image_id": 238310, "Bleu_1": 0.30952380951644, "Bleu_2": 0.2128289624210096, "Bleu_3": 0.13132391458151957, "Bleu_4": 1.5523573890829092e-05, "METEOR": 0.17363235190317616, "ROUGE_L": 0.2543786488740617, "CIDEr": 6.830980073194277e-06, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people standing under an umbrella, taking pictures with their phones. They are all wearing colorful clothing and have their arms raised in the air. In the background, there is a stage with a band playing music."}, "334767": {"image_id": 334767, "Bleu_1": 0.26315789472991696, "Bleu_2": 0.16866980207552001, "Bleu_3": 0.09245364897036984, "Bleu_4": 1.2258181047033617e-05, "METEOR": 0.1415398821737706, "ROUGE_L": 0.19709208400646203, "CIDEr": 2.2185975522714802e-06, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a group of people skiing down a snowy hill. They are wearing ski gear and holding their skis in front of them. The sky is cloudy and there are trees in the background."}, "48910": {"image_id": 48910, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.1490022319427778, "Bleu_3": 0.07901769277795581, "Bleu_4": 1.0290348647814142e-05, "METEOR": 0.2416403269708757, "ROUGE_L": 0.2781758957654723, "CIDEr": 1.0899839452860107e-08, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.35714285714285715, "f": 0.23255813953488377, "fn": 9.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.6666666666666666, "f": 0.42105263157894735, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a kitchen with white cabinets and countertops. There is a stove, sink, and refrigerator in the room. The floor is made of hardwood and there are no rugs or carpets. The walls are painted white and there are windows on either side of the room."}, "35313": {"image_id": 35313, "Bleu_1": 0.30188679244713423, "Bleu_2": 0.25270668299793647, "Bleu_3": 0.21556806421831623, "Bleu_4": 0.18620169406177664, "METEOR": 0.3077227690919813, "ROUGE_L": 0.3124644280022766, "CIDEr": 3.593187201504863e-11, "SPICE": {"All": {"pr": 0.6, "re": 0.13636363636363635, "f": 0.22222222222222218, "fn": 19.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "The woman is sitting on a bench in front of a building. She is wearing a black and white striped shirt and black pants. Her hair is pulled back into a bun and she has a cigarette in her hand. There are several cars parked along the sidewalk in front of the building."}, "368602": {"image_id": 368602, "Bleu_1": 0.18965517241052324, "Bleu_2": 0.08157553219491781, "Bleu_3": 4.916362924056044e-07, "Bleu_4": 1.2123898134874344e-09, "METEOR": 0.16759689394051416, "ROUGE_L": 0.17192784667418262, "CIDEr": 6.154185239597395e-16, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person on a jet ski, riding on the water with a smile on their face. They are wearing a life jacket and holding onto the handlebars of the jet ski as they ride through the water. In the background, there is a large body of water with trees and houses visible on the shore."}, "377832": {"image_id": 377832, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.3079962013899118, "Bleu_3": 0.20827340015449858, "Bleu_4": 0.14578668354039617, "METEOR": 0.2239532834461445, "ROUGE_L": 0.4291457286432161, "CIDEr": 0.07581722249857037, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.19047619047619047, "f": 0.2857142857142857, "fn": 17.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.1, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people on bicycles ride down the street on a sunny day.\""}, "189939": {"image_id": 189939, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.19703687322485355, "Bleu_3": 0.16814478213014897, "Bleu_4": 0.14917455049317407, "METEOR": 0.32647778878803413, "ROUGE_L": 0.33577981651376143, "CIDEr": 1.446666208054769e-10, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.2, "f": 0.21276595744680854, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a black and white cat sitting in a bathtub. The cat is looking up at the camera with its eyes. The bathtub is filled with water and there are some toys on the side of it. There is a sink in the background with a faucet turned on."}, "552573": {"image_id": 552573, "Bleu_1": 0.24590163934023115, "Bleu_2": 0.16937687147073976, "Bleu_3": 0.09907454029581565, "Bleu_4": 0.0639903596428197, "METEOR": 0.17667376704318286, "ROUGE_L": 0.21819110884006135, "CIDEr": 2.1818450399895175e-15, "SPICE": {"All": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man is sitting on top of an inflatable raft in the middle of a river, surrounded by other people on rafts. The rafts are being pulled by a rope attached to a bicycle, which is being pedaled by another person. The image is taken from above, looking down at the scene.\""}, "139192": {"image_id": 139192, "Bleu_1": 0.24999999999218758, "Bleu_2": 0.20080483221924839, "Bleu_3": 0.1591656839177488, "Bleu_4": 0.10858943671066813, "METEOR": 0.22085216870943586, "ROUGE_L": 0.2803308823529412, "CIDEr": 0.0004184251809550735, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 18.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows three elephants standing in a field with their trunks entwined. They are standing in a circle and looking at each other. The sky is clear and blue behind them."}, "214363": {"image_id": 214363, "Bleu_1": 0.11764705882006925, "Bleu_2": 0.05970814340087053, "Bleu_3": 4.81177951243232e-07, "Bleu_4": 1.376857090860863e-09, "METEOR": 0.06687653489685082, "ROUGE_L": 0.15587734241908005, "CIDEr": 9.957312393132247e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.09523809523809523, "f": 0.14285714285714285, "fn": 19.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image shows a group of people walking across a bridge over a river. They are all wearing raincoats and carrying umbrellas. The sky is cloudy and there are some buildings in the background."}, "56091": {"image_id": 56091, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.2241462600435509, "Bleu_3": 0.1787283477483194, "Bleu_4": 0.12765430498436262, "METEOR": 0.2496442465842779, "ROUGE_L": 0.25452016689847007, "CIDEr": 1.2608140366807194e-08, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.17857142857142858, "f": 0.17857142857142858, "fn": 23.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "A woman in a pink shirt and black shorts is holding a tennis racket and standing on a tennis court. The court is made of red clay and has white lines marking the boundaries of the court. There are trees in the background of the image."}, "242073": {"image_id": 242073, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.28867513458302535, "Bleu_3": 0.19351158546623434, "Bleu_4": 2.3956565611738468e-05, "METEOR": 0.20334858178610937, "ROUGE_L": 0.321390937829294, "CIDEr": 0.036110276508156756, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.05, "f": 0.07692307692307691, "fn": 19.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This is a bathroom with a toilet and sink. The walls are made of green tiles and there is a wooden barrel in the corner."}, "372087": {"image_id": 372087, "Bleu_1": 0.5714285714081633, "Bleu_2": 0.46004370621150176, "Bleu_3": 0.36553196675181654, "Bleu_4": 0.2766873691177593, "METEOR": 0.43020596608117734, "ROUGE_L": 0.5361328125, "CIDEr": 0.0429144688498144, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07407407407407407, "f": 0.10256410256410256, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a green and yellow train traveling on the tracks at a train station. There are people standing on the platform waiting to board the train."}, "416862": {"image_id": 416862, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.14118624159718107, "Bleu_3": 0.09907033493163236, "Bleu_4": 0.0702170735914276, "METEOR": 0.21119063282629738, "ROUGE_L": 0.21801286633309508, "CIDEr": 7.07081003306811e-08, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13043478260869565, "f": 0.12, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is a laboratory with several scientists working at their desks. There are several large windows on the walls, allowing natural light to enter the room. The walls are painted white and there are several shelves and cabinets filled with various scientific equipment."}, "437651": {"image_id": 437651, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.19847906537508855, "Bleu_3": 0.14007503420163694, "Bleu_4": 0.08994110735166029, "METEOR": 0.24375124342804222, "ROUGE_L": 0.26212400245549416, "CIDEr": 8.737990429263473e-07, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.15625, "f": 0.16666666666666666, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people standing around a table filled with small cups of food. They are all wearing white shirts and black pants, and some of them have aprons on. There is a banner in the background that reads \"Parker Technical School\"."}, "218751": {"image_id": 218751, "Bleu_1": 0.24999999999375005, "Bleu_2": 0.16012815380103265, "Bleu_3": 0.08771030046935029, "Bleu_4": 1.1620839902592802e-05, "METEOR": 0.24788687999992406, "ROUGE_L": 0.22426470588235295, "CIDEr": 1.4521518645813476e-05, "SPICE": {"All": {"pr": 0.08, "re": 0.125, "f": 0.09756097560975609, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a fire hydrant on the side of the road. The hydrant is red and has a small handle on top. There are trees in the background and a house with a fence in the distance."}, "103307": {"image_id": 103307, "Bleu_1": 0.5833333332361111, "Bleu_2": 0.398862017540745, "Bleu_3": 0.2515060603801396, "Bleu_4": 3.646285861281333e-05, "METEOR": 0.3081739754982745, "ROUGE_L": 0.6224489795918368, "CIDEr": 0.9398378107469009, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.16666666666666666, "f": 0.1851851851851852, "fn": 25.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "A giraffe is standing in a zoo enclosure, looking at the camera."}, "418471": {"image_id": 418471, "Bleu_1": 0.3399999999932, "Bleu_2": 0.22038926600328315, "Bleu_3": 0.12649010267330832, "Bleu_4": 1.4405155287574939e-05, "METEOR": 0.2096964900716125, "ROUGE_L": 0.2744656917885265, "CIDEr": 4.774059269982425e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is a photo of a pizza restaurant with a large table and chairs in front of it. There are several people sitting at the table, eating pizzas and drinking soda. The restaurant has a yellow and black color scheme and a sign that reads \"Pizza Hut\" in white letters."}, "28978": {"image_id": 28978, "Bleu_1": 0.09677419354682625, "Bleu_2": 0.05632871717456784, "Bleu_3": 3.7534977255921687e-07, "Bleu_4": 9.73002855643511e-10, "METEOR": 0.14457918108427278, "ROUGE_L": 0.18807810894141827, "CIDEr": 3.663465117261213e-17, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a computer mouse, a keyboard, and a camera. The mouse has a black body with a white button on the top and a silver scroll wheel on the side. The keyboard has a black body with white keys and a silver scroll wheel on the side. The camera has a black body with a silver lens on the front."}, "491203": {"image_id": 491203, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.22742941306595937, "Bleu_3": 1.227001451803117e-06, "Bleu_4": 2.8760263876588012e-09, "METEOR": 0.22419818245173126, "ROUGE_L": 0.26614310645724254, "CIDEr": 0.003574361176565695, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.125, "f": 0.16, "fn": 28.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a bathroom with a toilet, sink, and bathtub. The walls are painted pink and there is a window on the left side of the room."}, "309316": {"image_id": 309316, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.2956263824122027, "Bleu_3": 0.17431475287720166, "Bleu_4": 0.11342612980194997, "METEOR": 0.21492417675441536, "ROUGE_L": 0.31470335339638866, "CIDEr": 0.0001585923536603511, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15789473684210525, "f": 0.21428571428571427, "fn": 16.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a firefighter standing in front of a red fire truck. The firefighter is wearing a helmet and carrying a hose. The truck has the words \"Bombo Fire Department\" written on the side."}, "333630": {"image_id": 333630, "Bleu_1": 0.253731343279795, "Bleu_2": 0.13864368525215742, "Bleu_3": 0.08394063987487221, "Bleu_4": 9.804697816198125e-06, "METEOR": 0.14098158335118016, "ROUGE_L": 0.14987714987714987, "CIDEr": 4.2032770218861076e-20, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.15625, "f": 0.18518518518518515, "fn": 27.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of people in a room with a red carpet on the floor. There are several tables set up with drinks and snacks on them, and a man in a suit is standing at one of the tables. Another man is holding a microphone and speaking into it. There are also several chairs set up around the room for people to sit in."}, "581886": {"image_id": 581886, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.35405666968249755, "Bleu_3": 0.29267919501420286, "Bleu_4": 0.23660362390767173, "METEOR": 0.31019307238657323, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.037130906755896184, "SPICE": {"All": {"pr": 0.2413793103448276, "re": 0.25925925925925924, "f": 0.25, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "Two people sit on the beach next to a group of surfboards. The sun is setting in the background, casting a warm orange glow over the scene."}, "363560": {"image_id": 363560, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.1275153426095946, "Bleu_3": 7.407783780755458e-07, "Bleu_4": 1.7968013758108315e-09, "METEOR": 0.21538447336276786, "ROUGE_L": 0.28985507246376807, "CIDEr": 5.909216925281422e-05, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of children playing tennis on a court. They are wearing white tennis outfits and holding rackets. The coach is standing at the net, watching them play. There are trees in the background and a blue sky above."}, "324818": {"image_id": 324818, "Bleu_1": 0.6666666665777778, "Bleu_2": 0.5773502691112712, "Bleu_3": 0.5042374901047999, "Bleu_4": 0.42311785410129055, "METEOR": 0.26481603978178997, "ROUGE_L": 0.5538261997405965, "CIDEr": 0.9817652753148427, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.4, "f": 0.24242424242424243, "fn": 6.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.18181818181818182, "re": 1.0, "f": 0.3076923076923077, "fn": 0.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "Two blue and yellow macaws perched on a wooden branch in a tropical jungle environment."}, "532043": {"image_id": 532043, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.22281245492303936, "Bleu_3": 0.12923605637746155, "Bleu_4": 1.4799077495755305e-05, "METEOR": 0.2308977218234806, "ROUGE_L": 0.31282051282051276, "CIDEr": 8.445773518731077e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "The image shows a brown and white cow standing on the side of a dirt road in front of a mountain range. The cow is looking directly at the camera with its head tilted to the side. The background is a green valley with mountains in the distance."}, "226567": {"image_id": 226567, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.32897584746457503, "Bleu_3": 0.2532054772355419, "Bleu_4": 0.17096862608918384, "METEOR": 0.2228137727201015, "ROUGE_L": 0.3351648351648352, "CIDEr": 0.11173315019791194, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.17391304347826086, "f": 0.17391304347826086, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Here is a caption for the image:\n\nA group of fire trucks are parked in a field with mountains in the background."}, "272727": {"image_id": 272727, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.3450327796586264, "Bleu_3": 0.33210783206157946, "Bleu_4": 0.30620490881207335, "METEOR": 0.4207187086375199, "ROUGE_L": 0.5179245283018868, "CIDEr": 0.015038050657179614, "SPICE": {"All": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a horse grazing in a green field with trees in the background. The sky is clear and blue, with fluffy white clouds scattered across it."}, "555900": {"image_id": 555900, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.16222142112654833, "Bleu_3": 0.08926301664901087, "Bleu_4": 1.1855723022764683e-05, "METEOR": 0.1553758594701587, "ROUGE_L": 0.23682750970604546, "CIDEr": 0.006892208984313315, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2222222222222222, "f": 0.19999999999999998, "fn": 14.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A sleek and modern kitchen with a stainless steel oven, microwave, and other appliances. The countertops are made of marble and there are several bowls of fruit on the table.\""}, "41212": {"image_id": 41212, "Bleu_1": 0.6666666666296297, "Bleu_2": 0.485071250044925, "Bleu_3": 0.3086789594811046, "Bleu_4": 3.742031645854287e-05, "METEOR": 0.36187095607751935, "ROUGE_L": 0.6024691358024692, "CIDEr": 0.7106942326544905, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a soccer player in red and black uniform kicking a ball on a grass field."}, "247880": {"image_id": 247880, "Bleu_1": 0.3999999999885715, "Bleu_2": 0.286972021583456, "Bleu_3": 0.19562700664947694, "Bleu_4": 0.12367562469392218, "METEOR": 0.20867480115651083, "ROUGE_L": 0.2543786488740617, "CIDEr": 8.732510144563161e-05, "SPICE": {"All": {"pr": 0.391304347826087, "re": 0.36, "f": 0.37499999999999994, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 9.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a group of surfboards lying on the sand next to the ocean. The sky is clear and blue, with a few clouds in the distance. There are no people in the image."}, "220528": {"image_id": 220528, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.3474041668780458, "Bleu_3": 0.23471693384611736, "Bleu_4": 2.6306760830615268e-05, "METEOR": 0.3339489150084867, "ROUGE_L": 0.4543761638733706, "CIDEr": 0.005402488733301046, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.18181818181818182, "f": 0.2285714285714286, "fn": 18.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a stuffed animal wearing a green shirt with the words \"Brasil\" written on it. The animal is sitting on a desk in front of a computer monitor."}, "98674": {"image_id": 98674, "Bleu_1": 0.49999999998076927, "Bleu_2": 0.28284271246352294, "Bleu_3": 0.14938015821259065, "Bleu_4": 1.9511368321629798e-05, "METEOR": 0.22028926945423036, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.037910057506679605, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3125, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.6, "f": 0.4615384615384615, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a black bird perched on a branch with an apple in its beak. The bird is surrounded by snow covered trees and branches."}, "513611": {"image_id": 513611, "Bleu_1": 0.32659343212783404, "Bleu_2": 0.1780287301896033, "Bleu_3": 0.09286966990484151, "Bleu_4": 1.205553968931007e-05, "METEOR": 0.2438321069611496, "ROUGE_L": 0.35232961108971894, "CIDEr": 0.026121696693149073, "SPICE": {"All": {"pr": 0.16, "re": 0.16666666666666666, "f": 0.16326530612244897, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of cows grazing in a green field. There are several trees in the background, and the sky is clear and blue."}, "327005": {"image_id": 327005, "Bleu_1": 0.23880597014568944, "Bleu_2": 0.18045622869249706, "Bleu_3": 0.14432023117432013, "Bleu_4": 0.11707533690839138, "METEOR": 0.22889879326176388, "ROUGE_L": 0.23859747153733327, "CIDEr": 2.8996233387715544e-19, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.17647058823529413, "f": 0.21428571428571427, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a man standing on a surfboard in the water, holding onto the handlebars with his left hand and paddling with his right hand. He is wearing a white shirt and black shorts, and has a fishing rod slung over his shoulder. Behind him, there are several boats moored in the water, and in the background, there are palm trees and houses on the shore."}, "50434": {"image_id": 50434, "Bleu_1": 0.23287671232557702, "Bleu_2": 0.08042883540440904, "Bleu_3": 4.499750189440454e-07, "Bleu_4": 1.0681119966502285e-09, "METEOR": 0.1560506866950196, "ROUGE_L": 0.1373255290409725, "CIDEr": 3.4035866465123964e-24, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.16, "f": 0.18604651162790697, "fn": 21.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress on a field. There are two players on the field, one pitching and the other catching. The pitcher is wearing a white jersey with red sleeves and pants, while the catcher is wearing a black jersey with white sleeves and pants. The umpire is standing behind home plate, watching the game. In the background, there are several people sitting in the stands, watching the game."}, "64152": {"image_id": 64152, "Bleu_1": 0.37142857141795926, "Bleu_2": 0.276533159369469, "Bleu_3": 0.19085369914763303, "Bleu_4": 0.14437614475672528, "METEOR": 0.2581998173093651, "ROUGE_L": 0.3839496459480724, "CIDEr": 0.0003131538699015559, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.25, "f": 0.2631578947368421, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a kitchen with a refrigerator, sink, and cabinets. The refrigerator has an open door revealing the inside of the fridge. The sink is filled with water and there are dishes on the counter."}, "360610": {"image_id": 360610, "Bleu_1": 0.2222222222191358, "Bleu_2": 0.1582375544236339, "Bleu_3": 0.08943695954056846, "Bleu_4": 1.0090797649061763e-05, "METEOR": 0.21095821035686302, "ROUGE_L": 0.22344322344322343, "CIDEr": 9.675676120788743e-24, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.19444444444444445, "f": 0.2641509433962264, "fn": 29.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.15384615384615385, "f": 0.2666666666666667, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.3333333333333333, "f": 0.43478260869565216, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a group of people playing on the beach. There are two people in the foreground, one is throwing a frisbee and the other is watching. In the background, there are several people standing on the sand, some of them are also playing frisbee. The sky is clear and blue, with a few clouds scattered across it. The ocean is visible in the distance, with waves crashing against the shore."}, "514518": {"image_id": 514518, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.12183925606190008, "Bleu_3": 0.07375490665399664, "Bleu_4": 1.0274662450505877e-05, "METEOR": 0.2211264023901704, "ROUGE_L": 0.2771467514766015, "CIDEr": 4.8120563372596516e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.16666666666666666, "f": 0.14634146341463414, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an image of a skier on a snowy slope. The skier is wearing a helmet and has their skis pointed down the slope. The sun is shining in the background, casting a warm glow on the snow."}, "353108": {"image_id": 353108, "Bleu_1": 0.6666666666222223, "Bleu_2": 0.4879500364405749, "Bleu_3": 0.3321078320500879, "Bleu_4": 0.23505204105206395, "METEOR": 0.23958578085265353, "ROUGE_L": 0.5371069182389938, "CIDEr": 0.7059630042536001, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.18181818181818182, "f": 0.1568627450980392, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "A group of sheep grazing in a green field with a mountain in the background."}, "66556": {"image_id": 66556, "Bleu_1": 0.28571428570918367, "Bleu_2": 0.2279211529151689, "Bleu_3": 0.1793806467708401, "Bleu_4": 0.14447001557342332, "METEOR": 0.2798204716673956, "ROUGE_L": 0.3329694323144105, "CIDEr": 5.428729943945314e-12, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.047619047619047616, "f": 0.047619047619047616, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a cat sitting on top of a wooden chair in the middle of a garden. The cat is white and has blue eyes. There are leaves and branches on the ground around the chair, and a small table with a vase of flowers nearby. The sky is clear and blue in the background."}, "146126": {"image_id": 146126, "Bleu_1": 0.4473684210408588, "Bleu_2": 0.29092485085203773, "Bleu_3": 0.19177565064778895, "Bleu_4": 0.11914562164868793, "METEOR": 0.2804665905452186, "ROUGE_L": 0.3830455259026687, "CIDEr": 0.0009315861510079918, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2608695652173913, "f": 0.2727272727272727, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a table with a plate of food, a drink, and a remote control. The food appears to be french fries and a soda can. The remote control is on the table next to the food."}, "229653": {"image_id": 229653, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.16256402218685123, "Bleu_3": 0.12358723393320391, "Bleu_4": 0.08237287895426529, "METEOR": 0.2813980845278901, "ROUGE_L": 0.29735376044568246, "CIDEr": 4.928510660827803e-08, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.07692307692307693, "f": 0.1142857142857143, "fn": 24.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "A woman is sitting on a bed with her laptop open in front of her. She is wearing a green shirt and has a serious expression on her face. The room is dimly lit and there are lamps on the nightstand next to her."}, "193911": {"image_id": 193911, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.2236067977408484, "Bleu_3": 1.2954303153373922e-06, "Bleu_4": 3.1528613441200328e-09, "METEOR": 0.18050336475923767, "ROUGE_L": 0.321390937829294, "CIDEr": 0.020130641639400444, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 21.0, "numImages": 1.0, "fp": 30.0, "tp": 9.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.07692307692307693, "f": 0.07142857142857144, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.5454545454545454, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"Two brown cows standing in a barn with their heads down and looking at each other.\""}, "124684": {"image_id": 124684, "Bleu_1": 0.19148936169805347, "Bleu_2": 0.1442707907155283, "Bleu_3": 0.07733595213406046, "Bleu_4": 1.0125649926309211e-05, "METEOR": 0.19668750789154582, "ROUGE_L": 0.24069446271208733, "CIDEr": 1.528001940924641e-08, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.2222222222222222, "f": 0.24489795918367346, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a woman playing frisbee on the beach. She is wearing a white shirt and shorts, and has a frisbee in her hand. There are several other people in the background, also playing frisbee. The sky is blue and there are some clouds in it."}, "331386": {"image_id": 331386, "Bleu_1": 0.3181818181673554, "Bleu_2": 0.1740776559475969, "Bleu_3": 0.11485555942497074, "Bleu_4": 1.6804500805879955e-05, "METEOR": 0.24590190343643578, "ROUGE_L": 0.2612419700214133, "CIDEr": 0.12156198899848225, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.058823529411764705, "f": 0.0816326530612245, "fn": 32.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A busy street scene with several buses and people walking on the sidewalk.\""}, "508586": {"image_id": 508586, "Bleu_1": 0.378378378368152, "Bleu_2": 0.20504156173746327, "Bleu_3": 0.10630130250063007, "Bleu_4": 1.3709897573198736e-05, "METEOR": 0.23361432641028193, "ROUGE_L": 0.2930344275420336, "CIDEr": 1.8892219592502508e-05, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.2777777777777778, "f": 0.20408163265306123, "fn": 13.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a herd of zebras grazing in a grassy field. They are standing in a line, with their heads down and their stripes visible. In the background, there is a large, open sky with clouds."}, "363673": {"image_id": 363673, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.20498001541675429, "Bleu_3": 0.15631840650803838, "Bleu_4": 0.12430185040655492, "METEOR": 0.28969943637581086, "ROUGE_L": 0.35260115606936415, "CIDEr": 0.0005587024345821831, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white shirt and shorts, and has a racket in her hand. There are other people watching her play from the sidelines."}, "445953": {"image_id": 445953, "Bleu_1": 0.18309859154671693, "Bleu_2": 0.1143611421094537, "Bleu_3": 0.07237345254234366, "Bleu_4": 0.048591156987728965, "METEOR": 0.22968528002130312, "ROUGE_L": 0.1714285714285714, "CIDEr": 5.8599243239687e-23, "SPICE": {"All": {"pr": 0.15555555555555556, "re": 0.21212121212121213, "f": 0.17948717948717946, "fn": 26.0, "numImages": 1.0, "fp": 38.0, "tp": 7.0}, "Relation": {"pr": 0.06666666666666667, "re": 0.08333333333333333, "f": 0.07407407407407407, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2631578947368421, "re": 0.35714285714285715, "f": 0.30303030303030304, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}}, "caption": "The image shows a man sitting on the steps of a building, wearing a red robe and holding a phone to his ear. He appears to be talking on the phone while looking down at the ground. The building behind him is made of stone and has a large archway with a sign that reads \"Vatican Museums\" in Italian. The street is empty and there are no other people in sight."}, "435257": {"image_id": 435257, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.1732917482985969, "Bleu_3": 0.11972161662972919, "Bleu_4": 0.08428682606177874, "METEOR": 0.19992346339842154, "ROUGE_L": 0.2848249027237354, "CIDEr": 1.0229705071210361e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.13043478260869565, "f": 0.14634146341463414, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a couple standing on the sidewalk in front of a building. The man is wearing a hat and the woman is wearing a scarf. There are trees and buildings in the background."}, "436617": {"image_id": 436617, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.31745108882110745, "Bleu_3": 0.28071832567692717, "Bleu_4": 0.24000809421509064, "METEOR": 0.3471061508135939, "ROUGE_L": 0.43925932853268496, "CIDEr": 2.2506831424763924e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.10344827586206896, "f": 0.15, "fn": 26.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting at a table in a restaurant. They are all wearing casual clothing and appear to be enjoying their meals. There is a large mirror on the wall behind them, reflecting the image of the room."}, "309160": {"image_id": 309160, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.21666028366574688, "Bleu_3": 1.0924931049403102e-06, "Bleu_4": 2.470569169008323e-09, "METEOR": 0.1754103665874609, "ROUGE_L": 0.2733791455034359, "CIDEr": 1.4679209724025597e-05, "SPICE": {"All": {"pr": 0.14705882352941177, "re": 0.35714285714285715, "f": 0.20833333333333334, "fn": 9.0, "numImages": 1.0, "fp": 29.0, "tp": 5.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a cat sitting on the steps of a brick building. The cat has green eyes and is looking up at the camera. The background is a brick wall with a window on the left side."}, "100430": {"image_id": 100430, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.12371791482379726, "Bleu_3": 6.880010617668035e-07, "Bleu_4": 1.631181823642126e-09, "METEOR": 0.10925683608434053, "ROUGE_L": 0.184067592033796, "CIDEr": 5.708412218797346e-10, "SPICE": {"All": {"pr": 0.1875, "re": 0.24, "f": 0.21052631578947367, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This image shows a room with a blue desk and chair, a white wall with a painting on it, and a wooden floor. The walls are painted a light blue color and there is a window on one side of the room with a view of the city outside."}, "302038": {"image_id": 302038, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.16666666666404184, "Bleu_3": 0.11035932143591104, "Bleu_4": 1.2183562832229927e-05, "METEOR": 0.21091499670310973, "ROUGE_L": 0.21785714285714283, "CIDEr": 9.788482469304247e-18, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.19230769230769232, "f": 0.20408163265306123, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5, "f": 0.45454545454545453, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "This is a dining room with a large wooden table and chairs. There is a fireplace in the corner of the room, with a wood burning stove inside. The walls are made of stone and there are windows on either side of the room, allowing natural light to enter. The floor is made of tiles and there is a rug on top of it."}, "287667": {"image_id": 287667, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.358248860405223, "Bleu_3": 0.22914671579622262, "Bleu_4": 0.14036046697224608, "METEOR": 0.3075016552287821, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.0052262947581741504, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a carrot and a knife on a wooden cutting board. The carrot has a face made out of cheese and the knife has a handle shaped like a beak."}, "154431": {"image_id": 154431, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.304997140658197, "Bleu_3": 0.20691917851085118, "Bleu_4": 0.1212424196300561, "METEOR": 0.2430455189597667, "ROUGE_L": 0.37602739726027395, "CIDEr": 2.643432652991029e-06, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16666666666666666, "f": 0.2285714285714286, "fn": 20.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a living room with a large window that looks out onto a garden. There is a television on the wall, and a wooden statue of a man standing in the corner. The room is well lit and has a comfortable seating area."}, "39726": {"image_id": 39726, "Bleu_1": 0.3214285714170919, "Bleu_2": 0.21821789022805463, "Bleu_3": 0.17645861681644845, "Bleu_4": 0.1447953615723005, "METEOR": 0.20207424054223436, "ROUGE_L": 0.34528301886792445, "CIDEr": 0.002459702647495967, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.14285714285714285, "f": 0.11538461538461538, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This image shows a close up of a cinnamon roll with cream cheese frosting on top. The roll is cut in half and there are sprinkles on top."}, "85007": {"image_id": 85007, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.1229880092500526, "Bleu_3": 0.07710286831404463, "Bleu_4": 1.0939951744794564e-05, "METEOR": 0.2627996568632128, "ROUGE_L": 0.2469635627530364, "CIDEr": 7.103134588484727e-05, "SPICE": {"All": {"pr": 0.6153846153846154, "re": 0.4444444444444444, "f": 0.5161290322580646, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.42857142857142855, "f": 0.6, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.8333333333333334, "re": 0.8333333333333334, "f": 0.8333333333333334, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows two people playing frisbee in a grassy field. One person is throwing the frisbee while the other person is catching it. The sky is cloudy and there are trees in the background."}, "412873": {"image_id": 412873, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4281744192679387, "Bleu_3": 0.33794752877070244, "Bleu_4": 0.25590356076152615, "METEOR": 0.29024173501771766, "ROUGE_L": 0.4959349593495934, "CIDEr": 0.07699711096393984, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "A black and white image of a herd of cows grazing in a field with a few trees in the background."}, "471566": {"image_id": 471566, "Bleu_1": 0.5757575757401286, "Bleu_2": 0.40240752747911024, "Bleu_3": 0.2966972362669776, "Bleu_4": 0.22606593527996122, "METEOR": 0.31310071722156296, "ROUGE_L": 0.5659377070907886, "CIDEr": 0.03164638806793581, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.1935483870967742, "f": 0.20338983050847456, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4444444444444444, "f": 0.380952380952381, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A horse standing in a field with a fence behind it. The horse is white and has a brown mane and tail. The sky is blue and there are clouds in the background."}, "10534": {"image_id": 10534, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.13730875909260604, "Bleu_3": 7.224517156389943e-07, "Bleu_4": 1.6655497133613283e-09, "METEOR": 0.21229352609332613, "ROUGE_L": 0.19652061855670103, "CIDEr": 1.719242854621373e-09, "SPICE": {"All": {"pr": 0.25, "re": 0.20833333333333334, "f": 0.22727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a woman sitting on a bench in front of a building with a sign that reads, \"Welcome to the park.\" The woman is wearing jeans and a black shirt, and her hair is tied back in a ponytail. She appears to be relaxing and enjoying the scenery around her."}, "15567": {"image_id": 15567, "Bleu_1": 0.4493981746973232, "Bleu_2": 0.3078084890009808, "Bleu_3": 0.17421473584478553, "Bleu_4": 2.3662970827341347e-05, "METEOR": 0.22347118691102946, "ROUGE_L": 0.29221556886227545, "CIDEr": 0.7527501288683625, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.13793103448275862, "f": 0.18181818181818182, "fn": 25.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an old rocking chair with a cat sitting on it. The cat is looking at the camera."}, "88250": {"image_id": 88250, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.3944053187922357, "Bleu_3": 2.689047742804065e-06, "Bleu_4": 7.259795289559491e-09, "METEOR": 0.21898895680106617, "ROUGE_L": 0.42508710801393734, "CIDEr": 1.2479171705384773, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.125, "f": 0.1276595744680851, "fn": 21.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "Two elephants are standing in the dirt, their trunks entwined."}, "58937": {"image_id": 58937, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.13308032829543895, "Bleu_4": 0.08166132649572909, "METEOR": 0.24351431858174805, "ROUGE_L": 0.32037815126050423, "CIDEr": 3.738659810201505e-11, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14814814814814814, "f": 0.14545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a table set with several bottles of wine, glasses, and plates of food. There are also two people sitting at the table, one holding a glass of wine and the other holding a plate of food. The background is a dark brown color with some lighting coming from the windows in the room."}, "112110": {"image_id": 112110, "Bleu_1": 0.222222222217284, "Bleu_2": 0.12309149097656633, "Bleu_3": 0.08898958910777319, "Bleu_4": 0.0640017838161299, "METEOR": 0.15068070718227927, "ROUGE_L": 0.2053872053872054, "CIDEr": 4.240258320203412e-08, "SPICE": {"All": {"pr": 0.32142857142857145, "re": 0.2903225806451613, "f": 0.3050847457627119, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 9.0}, "Relation": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5333333333333333, "re": 0.5333333333333333, "f": 0.5333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 8.0}}, "caption": "The image shows a person standing on the sidewalk, holding a laptop in their hands. They are wearing a pair of sneakers and have their arms stretched out to the side. There is a streetlight in the background, casting a yellow glow over the scene."}, "380142": {"image_id": 380142, "Bleu_1": 0.31481481480898493, "Bleu_2": 0.17233546016556184, "Bleu_3": 0.10453426005393707, "Bleu_4": 0.06879413955125327, "METEOR": 0.20609224702541054, "ROUGE_L": 0.2684268426842684, "CIDEr": 8.100693385425544e-11, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows two horses grazing in a green field. One of the horses is lying down while the other stands nearby, looking at it. The sky is blue and cloudy, with some white clouds visible in the distance. The grass is tall and green, and there are no other objects in the scene."}, "77282": {"image_id": 77282, "Bleu_1": 0.7777777776049386, "Bleu_2": 0.6236095643194133, "Bleu_3": 0.38157141409384626, "Bleu_4": 5.51625153137941e-05, "METEOR": 0.2887675538674008, "ROUGE_L": 0.6256410256410255, "CIDEr": 1.7192116701966418, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.4444444444444444, "f": 0.3902439024390244, "fn": 10.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "A vase filled with flowers sits on a windowsill."}, "186038": {"image_id": 186038, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.20159462811746034, "Bleu_3": 1.1460354422397831e-06, "Bleu_4": 2.758387014275457e-09, "METEOR": 0.2161424499651244, "ROUGE_L": 0.28110599078341014, "CIDEr": 0.003335266033792185, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21428571428571427, "f": 0.21818181818181817, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3076923076923077, "f": 0.3076923076923077, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a woman holding a toothbrush in her mouth, with a red light shining behind her. She is wearing a red shirt and has long, curly hair."}, "448974": {"image_id": 448974, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.26130213377863615, "Bleu_3": 0.21166601750481703, "Bleu_4": 0.16885023000536672, "METEOR": 0.3372858286278551, "ROUGE_L": 0.41908396946564885, "CIDEr": 4.185964992199104e-05, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.10526315789473684, "f": 0.0816326530612245, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.3333333333333333, "f": 0.19047619047619044, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "A person is holding a cell phone in their hand. The phone has a small screen and a keypad on the front. The person is standing in a room with a bed and a dresser in the background."}, "457766": {"image_id": 457766, "Bleu_1": 0.14285714285487533, "Bleu_2": 0.09600307214592775, "Bleu_3": 0.05326151009485258, "Bleu_4": 7.0838979164402095e-06, "METEOR": 0.18538443984136632, "ROUGE_L": 0.15762273901808782, "CIDEr": 1.1633786052446714e-17, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.09523809523809523, "f": 0.08888888888888889, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1, "f": 0.10000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "A dump truck is driving down the street in the snow. The truck has a yellow and black body with a large bucket on the back. There are two men standing next to the truck, one is wearing a hard hat and the other is holding a shovel. The scene is set in a small town with houses and trees in the background."}, "131611": {"image_id": 131611, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.20225995873532804, "Bleu_3": 0.09116091793048703, "Bleu_4": 1.0934213504423326e-05, "METEOR": 0.25226280232789167, "ROUGE_L": 0.2469635627530364, "CIDEr": 0.000550914104947589, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of elephants standing in a small pond surrounded by trees and rocks. The elephants are standing on the shore, looking out into the water. There is a small stream running through the pond and some plants growing around the edges. The sky is cloudy and there are some birds flying overhead."}, "434187": {"image_id": 434187, "Bleu_1": 0.30769230768757394, "Bleu_2": 0.20801257358123573, "Bleu_3": 0.11116196288357212, "Bleu_4": 0.0686071269445815, "METEOR": 0.20693068619151347, "ROUGE_L": 0.17792902284880896, "CIDEr": 9.921709560478953e-18, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.25, "f": 0.1739130434782609, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people standing in front of a wooden fence, looking at something on their phones. One person is holding a baby while another person is taking a photo with a camera. There are several other people in the background, some of whom are also taking photos. The scene appears to be outdoors, with trees and buildings visible in the background."}, "526446": {"image_id": 526446, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.35948681369506397, "Bleu_3": 0.2208317739180072, "Bleu_4": 2.615858282472591e-05, "METEOR": 0.24992268777557214, "ROUGE_L": 0.38193202146690514, "CIDEr": 0.052247309371375, "SPICE": {"All": {"pr": 0.47368421052631576, "re": 0.2727272727272727, "f": 0.34615384615384615, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.7777777777777778, "re": 0.5833333333333334, "f": 0.6666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and wearing a helmet. The crowd is cheering in the background."}, "345356": {"image_id": 345356, "Bleu_1": 0.338235294112673, "Bleu_2": 0.20096343889883242, "Bleu_3": 0.14517329210247892, "Bleu_4": 0.11713905140106581, "METEOR": 0.20933650959538144, "ROUGE_L": 0.22889305816135083, "CIDEr": 2.1524759328828658e-17, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.038461538461538464, "f": 0.03703703703703704, "fn": 25.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows two men sitting at a table in a restaurant, both of them holding cell phones and looking at their screens. The table is set with white linen tablecloths and has a vase of flowers in the center. There are several plates of food on the table, including steak, chicken, and vegetables. The background is a beige color with a few windows visible through the walls."}, "506574": {"image_id": 506574, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.11651034560483009, "Bleu_3": 0.0647519709524591, "Bleu_4": 8.627614350761504e-06, "METEOR": 0.22669802529779423, "ROUGE_L": 0.1920654911838791, "CIDEr": 1.586414373057818e-12, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.19230769230769232, "f": 0.2439024390243902, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe eating leaves from a tree in a zoo enclosure. The giraffe has a long neck and spotted fur, and it is standing on its hind legs to reach the leaves. There are trees and bushes in the background of the image."}, "486910": {"image_id": 486910, "Bleu_1": 0.22222222221869492, "Bleu_2": 0.05986843400796705, "Bleu_3": 3.8876633813289837e-07, "Bleu_4": 9.947837396031269e-10, "METEOR": 0.10202347899507985, "ROUGE_L": 0.12609819121447027, "CIDEr": 3.0608069690247086e-18, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2222222222222222, "f": 0.1951219512195122, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a foal nursing from its mother in a green pasture. The foal is brown and black, while the mother is black and white. The foal is standing on its hind legs and nursing from its mother's udder. The mother is standing next to the foal, looking down at it. There are some trees in the background of the image."}, "98443": {"image_id": 98443, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.18666334823214084, "Bleu_3": 0.09550351820629131, "Bleu_4": 1.2224986162514046e-05, "METEOR": 0.1810482677511633, "ROUGE_L": 0.21631205673758863, "CIDEr": 4.457941457251703e-07, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.2, "f": 0.14634146341463417, "fn": 12.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a tall building with a clock tower in the center. The building is made of brick and has several windows on each floor. There are palm trees in front of the building, and the sky is clear and blue."}, "292926": {"image_id": 292926, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.09618052714368557, "Bleu_3": 0.05901837724618784, "Bleu_4": 8.267558544502552e-06, "METEOR": 0.2031183261936631, "ROUGE_L": 0.24416277518345564, "CIDEr": 9.503008016731243e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.2608695652173913, "f": 0.2553191489361702, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a small plant growing out of a mug on a windowsill. The mug is blue and has a white handle. The plant is a small, brown tree with green leaves. The window is open and there is a view of the outside through it."}, "27530": {"image_id": 27530, "Bleu_1": 0.5384615384408284, "Bleu_2": 0.4150996173139321, "Bleu_3": 0.19291432368783407, "Bleu_4": 2.363694785201641e-05, "METEOR": 0.23885828373272414, "ROUGE_L": 0.3382624768946396, "CIDEr": 0.08031055834372593, "SPICE": {"All": {"pr": 0.25, "re": 0.08163265306122448, "f": 0.12307692307692307, "fn": 45.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 20.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.07692307692307693, "f": 0.1111111111111111, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.1875, "f": 0.26086956521739124, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A car with a large backpack on top of it, parked on the side of the road.\""}, "331289": {"image_id": 331289, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.15249857032909853, "Bleu_3": 0.11843166534940335, "Bleu_4": 0.079781998871299, "METEOR": 0.19880202051974363, "ROUGE_L": 0.31853785900783294, "CIDEr": 3.509363573374195e-07, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of people riding bicycles on the sidewalk. There are several bicycles parked on the side of the road, and some people are walking in the street. The sky is cloudy and there are trees and buildings in the background."}, "27874": {"image_id": 27874, "Bleu_1": 0.4999999999583334, "Bleu_2": 0.21320071633703627, "Bleu_3": 1.656503812208384e-06, "Bleu_4": 4.740604259421436e-09, "METEOR": 0.1985490013826504, "ROUGE_L": 0.3315217391304348, "CIDEr": 0.8123250025437572, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.12, "f": 0.15384615384615383, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "A train is parked at a platform with people standing on it."}, "99416": {"image_id": 99416, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.15694120513807777, "Bleu_3": 9.69847388558379e-07, "Bleu_4": 2.4337962273104214e-09, "METEOR": 0.19552748248664362, "ROUGE_L": 0.32649420160570913, "CIDEr": 0.005468527636461416, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.25, "f": 0.2127659574468085, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.5555555555555556, "f": 0.4761904761904762, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows two men standing next to each other, one wearing a suit and the other wearing a tie. They are both smiling and looking at each other."}, "206831": {"image_id": 206831, "Bleu_1": 0.3571428571343538, "Bleu_2": 0.26398183866786545, "Bleu_3": 0.2057560926437255, "Bleu_4": 0.16088986597188545, "METEOR": 0.2454611814730183, "ROUGE_L": 0.35328185328185324, "CIDEr": 8.998491799984034e-06, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2, "f": 0.25641025641025644, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.36363636363636365, "f": 0.4444444444444444, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a brown and white dog sitting in the grass with its mouth open, chewing on a bone. The dog is wearing a collar and tag around its neck. The background is a wooden fence with greenery growing on it."}, "171382": {"image_id": 171382, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.2690691175932999, "Bleu_3": 0.20557469361389563, "Bleu_4": 0.16318987755896144, "METEOR": 0.28807013606920373, "ROUGE_L": 0.4227078891257996, "CIDEr": 7.020318741733441e-09, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man in a black and white striped shirt and jeans standing on a skateboard, doing a trick in the middle of a busy street. There are several people walking by, looking at him as he skates. The sky is blue and there are tall buildings in the background."}, "113159": {"image_id": 113159, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.17204158993311794, "Bleu_3": 0.11211985653831963, "Bleu_4": 1.3616513966805827e-05, "METEOR": 0.20100022362194236, "ROUGE_L": 0.20890410958904113, "CIDEr": 3.321080674799239e-07, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.02857142857142857, "f": 0.03389830508474576, "fn": 34.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.08333333333333333, "f": 0.0909090909090909, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The woman in the image is wearing a white tennis outfit and holding a tennis racket. She is standing on a tennis court with several tennis balls at her feet. The sun is setting in the background, casting a warm glow over the scene."}, "367569": {"image_id": 367569, "Bleu_1": 0.35999999998560006, "Bleu_2": 0.29999999998775007, "Bleu_3": 0.22727167323991315, "Bleu_4": 0.1519859042914841, "METEOR": 0.37720889387522405, "ROUGE_L": 0.5142255005268704, "CIDEr": 0.04184379826019821, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a living room with a fireplace, couches, and a piano. The walls are painted white and there are green curtains on the windows."}, "412151": {"image_id": 412151, "Bleu_1": 0.21311475409486702, "Bleu_2": 0.1332650098148157, "Bleu_3": 0.09665711718775206, "Bleu_4": 0.07470090771476545, "METEOR": 0.21434011314657975, "ROUGE_L": 0.24936126724578436, "CIDEr": 2.17571651187743e-15, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.2, "f": 0.2380952380952381, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA man is working on his bicycle in a bike shop. He is wearing a blue shirt and jeans, and has a tool belt around his waist. There are several bicycles on the walls and shelves behind him, as well as various tools and accessories on the counter in front of him."}, "383406": {"image_id": 383406, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.11531640100118269, "Bleu_3": 6.612130898132252e-07, "Bleu_4": 1.5920362546205505e-09, "METEOR": 0.219805366473991, "ROUGE_L": 0.2881241565452092, "CIDEr": 4.909329211283775e-06, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of cats sleeping on top of a computer desk. The cats are all different colors and sizes, with some lying on their backs and others curled up in the fetal position. There is a keyboard and mouse on the desk next to them."}, "301102": {"image_id": 301102, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.1647705109111272, "Bleu_3": 0.11766213984418193, "Bleu_4": 1.3502946183195832e-05, "METEOR": 0.21161756409625204, "ROUGE_L": 0.22048192771084338, "CIDEr": 1.266282041036072e-11, "SPICE": {"All": {"pr": 0.04, "re": 0.043478260869565216, "f": 0.041666666666666664, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "A pair of tennis rackets on a table\n\nThe image shows two tennis rackets, one pink and one white, lying on a table. The pink racket has a black handle and the white racket has a black handle with white accents. There is a small amount of space between the two rackets."}, "499268": {"image_id": 499268, "Bleu_1": 0.4705882352802769, "Bleu_2": 0.26702293490930384, "Bleu_3": 0.18837479909660562, "Bleu_4": 0.12117880855538533, "METEOR": 0.3061972664817751, "ROUGE_L": 0.391653290529695, "CIDEr": 0.0016382439263105337, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.18518518518518517, "f": 0.21739130434782608, "fn": 22.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.45454545454545453, "f": 0.47619047619047616, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The woman is sitting on a bench in the park, looking at her phone. She is wearing black pants and a white shirt with a black jacket. Her hair is blowing in the wind."}, "201220": {"image_id": 201220, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.20412414522676303, "Bleu_3": 0.14872208731093572, "Bleu_4": 0.09710267030091763, "METEOR": 0.2636816125463451, "ROUGE_L": 0.3139705882352941, "CIDEr": 1.9123074450456137e-06, "SPICE": {"All": {"pr": 0.3103448275862069, "re": 0.4090909090909091, "f": 0.35294117647058826, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.8571428571428571, "f": 0.5714285714285714, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "This image shows a bride and groom sitting in the back seat of a car. The bride is wearing a white wedding dress and the groom is wearing a black tuxedo. They are both smiling and looking at each other."}, "24157": {"image_id": 24157, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.10182666119201575, "Bleu_4": 1.2115660853589845e-05, "METEOR": 0.22482322739405564, "ROUGE_L": 0.30049261083743845, "CIDEr": 5.5485166712847235e-12, "SPICE": {"All": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a group of people skiing down a snowy mountain slope. They are wearing winter clothing and carrying skis on their backs. The sky is clear and blue, with a few clouds in the distance. The mountains in the background are covered in snow and have a rugged, rocky appearance."}, "356478": {"image_id": 356478, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.22918388364562542, "Bleu_3": 0.13468210525873764, "Bleu_4": 1.552995150861287e-05, "METEOR": 0.2900460945866113, "ROUGE_L": 0.30219391365888176, "CIDEr": 2.1069666982893858e-08, "SPICE": {"All": {"pr": 0.21875, "re": 0.15217391304347827, "f": 0.1794871794871795, "fn": 39.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.08333333333333333, "f": 0.08, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.3333333333333333, "f": 0.41379310344827586, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a baby elephant walking on the dirt path. The elephant is small and has big ears, a trunk, and tusks. It is walking towards the camera with its head down and its tail up. There are trees in the background."}, "384010": {"image_id": 384010, "Bleu_1": 0.7499999999375001, "Bleu_2": 0.4522670168272435, "Bleu_3": 0.3445666782598466, "Bleu_4": 0.25965358890901935, "METEOR": 0.24613184043879158, "ROUGE_L": 0.46212121212121204, "CIDEr": 0.9598201195855995, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "This is a bowl of food with broccoli and fish on it."}, "184746": {"image_id": 184746, "Bleu_1": 0.39999999999200003, "Bleu_2": 0.27105237086609907, "Bleu_3": 0.18293988070876474, "Bleu_4": 0.14060058991881091, "METEOR": 0.20753526962656313, "ROUGE_L": 0.2820809248554913, "CIDEr": 2.0395095420444066e-08, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08333333333333333, "f": 0.0930232558139535, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a person sitting at a table with a plate of food in front of them. There is a glass of water on the table and a fork and knife next to the plate. The person is wearing a black hoodie and has their hands on the table."}, "280810": {"image_id": 280810, "Bleu_1": 0.692307692254438, "Bleu_2": 0.537086155486539, "Bleu_3": 0.37431888793482826, "Bleu_4": 4.785543920673609e-05, "METEOR": 0.3666246852422277, "ROUGE_L": 0.657935285053929, "CIDEr": 1.528484664456537, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a plate of food that includes a meat pie and broccoli."}, "402528": {"image_id": 402528, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.18057877962096616, "Bleu_3": 1.1401716778849578e-06, "Bleu_4": 2.8984970515985937e-09, "METEOR": 0.22145156727971688, "ROUGE_L": 0.24497991967871482, "CIDEr": 0.08160299844962866, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13636363636363635, "f": 0.1395348837209302, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a sandwich with lettuce, tomato, and ham on a plate. There is also a glass of orange juice on the table."}, "57403": {"image_id": 57403, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.3246172270214718, "Bleu_3": 0.2628885743171875, "Bleu_4": 0.21004850228556196, "METEOR": 0.28668626801754293, "ROUGE_L": 0.37621145374449333, "CIDEr": 0.006438118236405551, "SPICE": {"All": {"pr": 0.25, "re": 0.34782608695652173, "f": 0.2909090909090909, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.36363636363636365, "f": 0.27586206896551724, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a cluttered desk with a laptop, papers, and other office supplies. There is a window in the background with blinds open, revealing a view of the sky outside."}, "156928": {"image_id": 156928, "Bleu_1": 0.5848076807365695, "Bleu_2": 0.44401909271299045, "Bleu_3": 0.3657155988043964, "Bleu_4": 0.31632090284112546, "METEOR": 0.43431531815758084, "ROUGE_L": 0.6742522756827047, "CIDEr": 0.16957083519783278, "SPICE": {"All": {"pr": 0.6666666666666666, "re": 0.17391304347826086, "f": 0.27586206896551724, "fn": 19.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a white pickup truck parked in front of a house with a sign that reads \"Karaoke\" on it. There is also a statue of a horse on the porch of the house."}, "2261": {"image_id": 2261, "Bleu_1": 0.41463414633135043, "Bleu_2": 0.24938949847206418, "Bleu_3": 0.16850171435572697, "Bleu_4": 0.12596933671327445, "METEOR": 0.1865567763927448, "ROUGE_L": 0.25756509500351865, "CIDEr": 1.1597067611661303e-05, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.14814814814814814, "f": 0.16326530612244897, "fn": 23.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a person surfing on a wave in the ocean. The person is wearing a wetsuit and holding onto the board as they ride the wave. The water is blue and there are clouds in the sky."}, "416101": {"image_id": 416101, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2236067977443172, "Bleu_3": 0.17394640854448745, "Bleu_4": 0.10920968859307914, "METEOR": 0.3168621306947432, "ROUGE_L": 0.263536866359447, "CIDEr": 5.753379255528242e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1875, "f": 0.17142857142857143, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man in a white shirt and black pants holding a tennis racket while standing on a tennis court. He is looking down at the ball in his hand and appears to be ready to hit it."}, "34080": {"image_id": 34080, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.6236095643341374, "Bleu_3": 0.5793377740249008, "Bleu_4": 0.5372849657937071, "METEOR": 0.36339386936543017, "ROUGE_L": 0.7000000000000001, "CIDEr": 3.3543980642792413, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.14285714285714285, "f": 0.14814814814814817, "fn": 24.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A small pair of scissors sitting on a wooden table."}, "178084": {"image_id": 178084, "Bleu_1": 0.25714285713918367, "Bleu_2": 0.14953343588161638, "Bleu_3": 0.08696261070377034, "Bleu_4": 0.0559732760301525, "METEOR": 0.17568276696407423, "ROUGE_L": 0.22867853795688844, "CIDEr": 1.3041011603000162e-20, "SPICE": {"All": {"pr": 0.25, "re": 0.08695652173913043, "f": 0.12903225806451613, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This is an image of a motorcycle parked in a garage. The motorcycle has a sleek, black body with red accents and a white stripe running down the side. It has a large front wheel and a small rear wheel, and it appears to be in good condition. There are several other motorcycles parked nearby, and there are tools and equipment hanging from the walls and ceiling of the garage."}, "133999": {"image_id": 133999, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.13206763594580717, "Bleu_3": 0.0746072740739093, "Bleu_4": 1.0032055246769756e-05, "METEOR": 0.2014265231418192, "ROUGE_L": 0.18047337278106512, "CIDEr": 1.0851779234529487e-07, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.13333333333333333, "f": 0.10810810810810811, "fn": 13.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a city street with several buses parked on the side of the road. The buildings on either side of the street are tall and modern, with large windows and balconies. There are also several pedestrians walking down the sidewalk."}, "280911": {"image_id": 280911, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.20892772350173638, "Bleu_3": 0.11885193737704458, "Bleu_4": 1.6097917483901073e-05, "METEOR": 0.2633292356599742, "ROUGE_L": 0.2978515625, "CIDEr": 0.0051180744668195815, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.3, "f": 0.3636363636363637, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.8333333333333334, "re": 0.625, "f": 0.7142857142857143, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows two elephants standing in a green field with trees in the background. They are both looking down and appear to be grazing on the grass."}, "409496": {"image_id": 409496, "Bleu_1": 0.34146341462581803, "Bleu_2": 0.22631728213415833, "Bleu_3": 0.10951079799876592, "Bleu_4": 1.3634738359895023e-05, "METEOR": 0.2722984434553055, "ROUGE_L": 0.2713120830244626, "CIDEr": 3.586405284032479e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The man is standing in front of a wooden fence, holding a large surfboard. He is wearing a white shirt and shorts, and has a friendly smile on his face. The background is a green field with trees in the distance."}, "467437": {"image_id": 467437, "Bleu_1": 0.21999999999560005, "Bleu_2": 0.06700593942469525, "Bleu_3": 4.5393651709319995e-07, "Bleu_4": 1.187741350296707e-09, "METEOR": 0.22169446643324406, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.8549737788081682e-10, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.0967741935483871, "f": 0.10344827586206896, "fn": 28.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2727272727272727, "f": 0.23076923076923075, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a man and woman sleeping in bed together. The man is lying on his back with his arms folded under his head, while the woman is lying on her side with her head resting on her arm. Both are wearing pajamas and the room is dimly lit."}, "293964": {"image_id": 293964, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2993592018235193, "Bleu_3": 0.2462698946894911, "Bleu_4": 0.21492353915298706, "METEOR": 0.3470866078380649, "ROUGE_L": 0.3830455259026687, "CIDEr": 1.0634406705032648e-05, "SPICE": {"All": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a black and white image of a restaurant with a long counter and several tables. There are several people standing behind the counter, preparing food. The lighting in the image is dim, creating a moody atmosphere."}, "436426": {"image_id": 436426, "Bleu_1": 0.378378378368152, "Bleu_2": 0.34002296335582893, "Bleu_3": 0.2848932528151002, "Bleu_4": 0.22837938098282545, "METEOR": 0.26489708944523466, "ROUGE_L": 0.36941710825132484, "CIDEr": 7.680563009968079e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.15, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "A cell phone is sitting on top of a table next to a vase. The phone has a black case and is turned off. There is a book lying open on the table next to the phone."}, "80213": {"image_id": 80213, "Bleu_1": 0.6923076922011837, "Bleu_2": 0.4803844613398166, "Bleu_3": 0.2758005147163744, "Bleu_4": 3.805803001048077e-05, "METEOR": 0.3096184922551231, "ROUGE_L": 0.5150784077201447, "CIDEr": 1.6439145580158008, "SPICE": {"All": {"pr": 0.5625, "re": 0.3333333333333333, "f": 0.4186046511627907, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 9.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8571428571428571, "re": 0.5, "f": 0.631578947368421, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 6.0}}, "caption": "The cat is sitting on top of the couch wearing a black hat."}, "167583": {"image_id": 167583, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.32444284224487613, "Bleu_3": 0.18016397830290895, "Bleu_4": 2.4218026051569858e-05, "METEOR": 0.2689742109894843, "ROUGE_L": 0.40848214285714285, "CIDEr": 0.19796942217281457, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.14285714285714285, "f": 0.1702127659574468, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.36363636363636365, "f": 0.4210526315789474, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A colorful display of fresh fruits and vegetables in a market\""}, "547227": {"image_id": 547227, "Bleu_1": 0.3061224489733445, "Bleu_2": 0.23957871187003724, "Bleu_3": 0.15416056119190602, "Bleu_4": 1.679927363038273e-05, "METEOR": 0.2201136001803434, "ROUGE_L": 0.28110599078341014, "CIDEr": 1.1574723694164004e-09, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2857142857142857, "f": 0.2727272727272727, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.5, "f": 0.37499999999999994, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a street with a clock tower in the center. The clock tower has a large clock face on it and is surrounded by buildings with windows and doors. There are cars parked along the side of the street and people walking on the sidewalk."}, "223374": {"image_id": 223374, "Bleu_1": 0.22222222221810703, "Bleu_2": 0.19425717246782156, "Bleu_3": 0.129605673244496, "Bleu_4": 0.08083053722301232, "METEOR": 0.25505169522563376, "ROUGE_L": 0.3202099737532808, "CIDEr": 2.2475986572204538e-12, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.17647058823529413, "f": 0.15, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a black and white image of a microwave oven with a plate on top of it. There are several toy cars and trucks on the plate, as well as a small toy robot in the corner. The microwave has a digital display on the front that shows the time and other information."}, "106901": {"image_id": 106901, "Bleu_1": 0.6071428571211734, "Bleu_2": 0.4241393401714729, "Bleu_3": 0.2748242215724415, "Bleu_4": 0.20186626686264555, "METEOR": 0.2760628865802841, "ROUGE_L": 0.4452554744525547, "CIDEr": 0.0095946553779862, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.13513513513513514, "f": 0.136986301369863, "fn": 32.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3076923076923077, "f": 0.27586206896551724, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "This is a small, white building with a blue door and a bench in front of it. There are no windows or other details visible on the building."}, "420852": {"image_id": 420852, "Bleu_1": 0.2903225806357961, "Bleu_2": 0.19674775072873343, "Bleu_3": 0.11010503638215555, "Bleu_4": 1.4776306152176402e-05, "METEOR": 0.17218334479138217, "ROUGE_L": 0.24537409493161708, "CIDEr": 0.002218907946436549, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.25, "f": 0.32, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5714285714285714, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "This is an image of a street with a power line in the foreground and a building in the background. The sky is blue and there are clouds in the sky."}, "215151": {"image_id": 215151, "Bleu_1": 0.2295081967175491, "Bleu_2": 0.10712333936022626, "Bleu_3": 0.05793914264605009, "Bleu_4": 7.609779097882417e-06, "METEOR": 0.19521479900541722, "ROUGE_L": 0.21424987456096337, "CIDEr": 1.8901002720708143e-15, "SPICE": {"All": {"pr": 0.4375, "re": 0.1590909090909091, "f": 0.23333333333333334, "fn": 37.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.047619047619047616, "f": 0.07142857142857142, "fn": 20.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.25, "f": 0.34782608695652173, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on a skateboard ramp, with one person jumping over the railing while another person watches. There are several other people in the background, including one person sitting on a bench and another person standing on the sidewalk. The image is taken from a low angle, looking up at the people on the ramp."}, "549568": {"image_id": 549568, "Bleu_1": 0.25714285713551027, "Bleu_2": 0.1229880092500526, "Bleu_3": 0.07710286831404463, "Bleu_4": 1.0939951744794564e-05, "METEOR": 0.22203950563853014, "ROUGE_L": 0.1919748229740362, "CIDEr": 7.820912402708085e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.23529411764705882, "f": 0.21052631578947367, "fn": 13.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1, "f": 0.125, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.6666666666666666, "f": 0.36363636363636365, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a street with several parked cars and pedestrians walking on the sidewalk. There are buildings in the background, including a tall building with a clock tower. The sky is clear and blue."}, "124940": {"image_id": 124940, "Bleu_1": 0.6297017414153193, "Bleu_2": 0.4882583110666058, "Bleu_3": 0.371323010438372, "Bleu_4": 0.2750918124632971, "METEOR": 0.3140962751881377, "ROUGE_L": 0.52876280535855, "CIDEr": 0.3981797938887813, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.13333333333333333, "f": 0.18181818181818182, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a piece of toast with peanut butter and jelly on it. There is also a knife on the cutting board next to the toast."}, "372428": {"image_id": 372428, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.19871830896102974, "Bleu_3": 0.09957231203386964, "Bleu_4": 1.2613563322945842e-05, "METEOR": 0.19830065770773136, "ROUGE_L": 0.21631205673758863, "CIDEr": 3.402142538307638e-06, "SPICE": {"All": {"pr": 0.3125, "re": 0.21739130434782608, "f": 0.2564102564102564, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a group of cows standing in a field next to a river. They are all wearing white sunglasses and looking at the camera. In the background, there is a group of people sitting on lawn chairs, enjoying the view."}, "79356": {"image_id": 79356, "Bleu_1": 0.21052631578670358, "Bleu_2": 0.19102677317383746, "Bleu_3": 0.1702102017622488, "Bleu_4": 0.15246879627466906, "METEOR": 0.316368193488852, "ROUGE_L": 0.29224738675958184, "CIDEr": 3.882290575238807e-24, "SPICE": {"All": {"pr": 0.4, "re": 0.125, "f": 0.19047619047619047, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a group of people riding on the back of an elephant. The elephant is standing in the middle of a forest, surrounded by trees and a lake in the background. The people are sitting on the elephant's back, with one person holding onto the elephant's ears while another person sits on its back. The elephant is wearing a harness and appears to be happy to have the people on its back."}, "13465": {"image_id": 13465, "Bleu_1": 0.1555555555520988, "Bleu_2": 0.05945883899972003, "Bleu_3": 4.348319676410201e-07, "Bleu_4": 1.1828475534420008e-09, "METEOR": 0.11790863768677172, "ROUGE_L": 0.17681159420289855, "CIDEr": 4.946121426825378e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.22727272727272727, "f": 0.17543859649122806, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.42857142857142855, "f": 0.3, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a skateboarder jumping off a staircase in front of a building. The skateboarder is wearing a red shirt and black pants, and the building has a blue roof and white walls. The sky is cloudy and there are trees in the background."}, "558213": {"image_id": 558213, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.22522130822577494, "Bleu_3": 0.15122694444080373, "Bleu_4": 0.09470104449999896, "METEOR": 0.23843207412918782, "ROUGE_L": 0.28968792401628224, "CIDEr": 2.3505967914353963e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man standing on top of a skateboard, wearing a black shirt and jeans, and holding a piece of paper in his hand. There is a fence in the background, and a building with a sign that reads \"Skate Park\" in the distance."}, "517296": {"image_id": 517296, "Bleu_1": 0.32608695651465036, "Bleu_2": 0.1474419561516563, "Bleu_3": 7.905508875736573e-07, "Bleu_4": 1.8411122136444459e-09, "METEOR": 0.18981051755339756, "ROUGE_L": 0.2794502617801047, "CIDEr": 9.449588440353033e-09, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.29411764705882354, "f": 0.25, "fn": 12.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of people are standing in front of a bus stop on a city street. The bus stop has a sign that reads \"Bus Stop\" and there are several people waiting for the bus to arrive."}, "134722": {"image_id": 134722, "Bleu_1": 0.22727272726756204, "Bleu_2": 0.16256402218685123, "Bleu_3": 0.10796339325484196, "Bleu_4": 0.07443229846618533, "METEOR": 0.23434999633678855, "ROUGE_L": 0.2924657534246575, "CIDEr": 6.840738686956323e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A train is pulling into a station with a brick building in the background. The train has a white and blue striped body and a red and white striped roof. There are people standing on the platform looking at the train as it approaches."}, "414661": {"image_id": 414661, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.15191090505870355, "Bleu_3": 0.08468336402372788, "Bleu_4": 1.1318741601733969e-05, "METEOR": 0.1923832988196065, "ROUGE_L": 0.263536866359447, "CIDEr": 2.059429509262857e-06, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.21739130434782608, "f": 0.18518518518518517, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a group of people skateboarding on a concrete ramp in the middle of a park. One person is doing a trick on the ramp while another person watches. There are trees and houses visible in the background."}, "167353": {"image_id": 167353, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.21808478994970526, "Bleu_3": 0.10683872974718221, "Bleu_4": 1.3384453330858416e-05, "METEOR": 0.2679930937668944, "ROUGE_L": 0.30049261083743845, "CIDEr": 9.455595228817258e-07, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.10344827586206896, "f": 0.15789473684210528, "fn": 26.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.23076923076923078, "f": 0.3529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a large, ornate clock hanging on the wall of a room. It has a large face with Roman numerals and hands that are pointing to the time. The clock is surrounded by intricate carvings and has a wooden frame."}, "260150": {"image_id": 260150, "Bleu_1": 0.31034482758085613, "Bleu_2": 0.23333765443696047, "Bleu_3": 0.14287874532628775, "Bleu_4": 0.08533654358724539, "METEOR": 0.27910660566400164, "ROUGE_L": 0.2973997833152763, "CIDEr": 3.57573534715197e-09, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person holding a plate with pancakes on it. The person is wearing a white shirt and has a fork in their hand. There are several pancakes on the plate, with different toppings such as chocolate chips, strawberries, and whipped cream. The background of the image is a kitchen with a wooden table and chairs."}, "541991": {"image_id": 541991, "Bleu_1": 0.46874999998535166, "Bleu_2": 0.3253410121500613, "Bleu_3": 0.19180597090826104, "Bleu_4": 0.12489558670696722, "METEOR": 0.3051720124358853, "ROUGE_L": 0.3798932384341636, "CIDEr": 0.0037326049625366394, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.30434782608695654, "f": 0.31818181818181823, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5555555555555556, "f": 0.5882352941176471, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "The image shows a sheep standing on top of a grassy hill, looking out over the mountains in the distance. The sky is cloudy and there are some clouds in the background."}, "439132": {"image_id": 439132, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.22794037622152502, "Bleu_3": 0.17775981771709612, "Bleu_4": 0.14708889510753856, "METEOR": 0.33384797757972273, "ROUGE_L": 0.3756735950731332, "CIDEr": 5.1098114158293725e-06, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.05263157894736842, "f": 0.041666666666666664, "fn": 18.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "The image shows a black cat sitting in a flower pot on a windowsill. The cat is looking up at the camera with its eyes. The background of the image is a greenhouse with plants and flowers growing inside."}, "256713": {"image_id": 256713, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.1725163898320312, "Bleu_3": 0.12384962799919483, "Bleu_4": 0.08016440471257022, "METEOR": 0.2848312016479297, "ROUGE_L": 0.35442220787604906, "CIDEr": 3.659357506021222e-09, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.22727272727272727, "f": 0.19607843137254902, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a bathroom with a white bathtub, a white sink, and a white toilet. There is a large mirror on the wall above the sink and a window in the background. The floor is made of hardwood and there are two wooden chairs in front of the sink."}, "149832": {"image_id": 149832, "Bleu_1": 0.9090909090082646, "Bleu_2": 0.5222329678172442, "Bleu_3": 0.3117659538504856, "Bleu_4": 4.4116293588517445e-05, "METEOR": 0.3044066648555698, "ROUGE_L": 0.5897518530454399, "CIDEr": 1.9549233868320854, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.21052631578947367, "f": 0.1951219512195122, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A field of cows grazing on green grass in the countryside."}, "285212": {"image_id": 285212, "Bleu_1": 0.23376623376319783, "Bleu_2": 0.15686609568275003, "Bleu_3": 0.11793851048710507, "Bleu_4": 0.09030548151139896, "METEOR": 0.2480032925003153, "ROUGE_L": 0.2356223175965665, "CIDEr": 5.312713884882121e-22, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.29411764705882354, "f": 0.25641025641025644, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A small dog is sitting on the floor next to a woman who is wearing sneakers and has her feet up on a chair. The dog is looking at the woman with its head tilted to the side. There are several other people in the background, some of whom are also sitting on chairs and looking at the dog. The room appears to be a classroom or meeting space, with tables and chairs set up in rows."}, "120747": {"image_id": 120747, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.2594372608248164, "Bleu_3": 0.1745021516446632, "Bleu_4": 0.1301840138373459, "METEOR": 0.3500805899605018, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.00044830371995116064, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a living room with a couch, coffee table, and TV. There are two people sitting on the couch watching TV. The walls are painted a light brown color and there are windows on one side of the room."}, "327314": {"image_id": 327314, "Bleu_1": 0.28947368420290864, "Bleu_2": 0.1769023808359136, "Bleu_3": 0.1376455059779305, "Bleu_4": 0.11048721210035554, "METEOR": 0.2593990919612488, "ROUGE_L": 0.39725036179450074, "CIDEr": 2.8000721072931687e-05, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.32, "f": 0.2711864406779661, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 8.0}, "Relation": {"pr": 0.23076923076923078, "re": 0.25, "f": 0.24000000000000002, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.4166666666666667, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a gray scooter parked on the sidewalk in front of a building with a sign that reads \"Fashion Show\" in French. There are people walking by on the street and a few bicycles parked nearby."}, "431236": {"image_id": 431236, "Bleu_1": 0.7692307691715977, "Bleu_2": 0.5661385170269343, "Bleu_3": 0.3077165870249426, "Bleu_4": 4.131551590743584e-05, "METEOR": 0.3434039550281654, "ROUGE_L": 0.657935285053929, "CIDEr": 0.7170369418924922, "SPICE": {"All": {"pr": 0.15, "re": 0.0967741935483871, "f": 0.11764705882352941, "fn": 28.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "A small kitchen with white appliances and a washing machine in the corner."}, "186991": {"image_id": 186991, "Bleu_1": 0.35135135134185547, "Bleu_2": 0.2613777310992162, "Bleu_3": 0.15745859536234952, "Bleu_4": 0.10351542044576124, "METEOR": 0.2320992819151619, "ROUGE_L": 0.2930344275420336, "CIDEr": 5.5769783089220606e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a zebra standing in the dirt, looking at something on the ground. The zebra has a long mane and stripes on its body. There are trees in the background, and the sky is cloudy."}, "170974": {"image_id": 170974, "Bleu_1": 0.35294117646020773, "Bleu_2": 0.3102526139877483, "Bleu_3": 0.26230750920625656, "Bleu_4": 0.2196760025101482, "METEOR": 0.3450391150579131, "ROUGE_L": 0.36371379897785344, "CIDEr": 0.0006422253663382936, "SPICE": {"All": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 15.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a group of people standing around a table with a video game console on it. They are all looking at the screen and have their hands on their hips."}, "453622": {"image_id": 453622, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.27715276610008205, "Bleu_3": 0.22014152945079551, "Bleu_4": 0.17389607800310708, "METEOR": 0.32737562779550045, "ROUGE_L": 0.3830455259026687, "CIDEr": 4.292983671820575e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 24.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3, "f": 0.4285714285714285, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and chairs. There is a ceiling fan in the corner of the room. The walls are painted white and there are windows on one side of the room."}, "116068": {"image_id": 116068, "Bleu_1": 0.30645161289828304, "Bleu_2": 0.17361676646009247, "Bleu_3": 0.079495770947552, "Bleu_4": 9.606053834475527e-06, "METEOR": 0.21518375444443819, "ROUGE_L": 0.21159563924677896, "CIDEr": 5.23049601269634e-12, "SPICE": {"All": {"pr": 0.3076923076923077, "re": 0.19047619047619047, "f": 0.23529411764705882, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a group of people standing on the beach, holding kites. One person is holding a kite and another person is holding a stick to help launch it into the air. The sky is clear and blue, with a few clouds scattered in the distance. The beach is sandy and there are some rocks and driftwood scattered along the shoreline."}, "324139": {"image_id": 324139, "Bleu_1": 0.7692307691715977, "Bleu_2": 0.6698641270034087, "Bleu_3": 0.49647875636294664, "Bleu_4": 0.3326024950263509, "METEOR": 0.30280999531998726, "ROUGE_L": 0.6446499339498017, "CIDEr": 1.5007386750500307, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.25, "f": 0.21818181818181817, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5555555555555556, "f": 0.43478260869565216, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "A group of seagulls perched on a bench in front of a park."}, "410576": {"image_id": 410576, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.21915646613065012, "Bleu_3": 1.211662325630794e-06, "Bleu_4": 2.876026387655114e-09, "METEOR": 0.2002006862492211, "ROUGE_L": 0.33771626297577856, "CIDEr": 0.05425624409575017, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.13793103448275862, "f": 0.17391304347826086, "fn": 25.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a room with a desk, chair, and computer in the center. The walls are painted red and there are some books on the shelf."}, "201463": {"image_id": 201463, "Bleu_1": 0.49999999998611117, "Bleu_2": 0.33806170188188195, "Bleu_3": 0.21604526952247782, "Bleu_4": 0.15723078586343264, "METEOR": 0.30063125581824685, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.00020813805227173866, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.1935483870967742, "f": 0.23076923076923075, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5, "re": 0.3076923076923077, "f": 0.380952380952381, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows two men standing in a bathroom, one with a toothbrush in his mouth and the other with a toothbrush in his hand. They are both wearing white robes and looking at each other."}, "12670": {"image_id": 12670, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.21070705493664102, "Bleu_3": 0.16170481491531974, "Bleu_4": 0.13262535616921253, "METEOR": 0.2177768205957767, "ROUGE_L": 0.29985955056179775, "CIDEr": 3.88509660029188e-07, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.4444444444444444, "f": 0.3404255319148936, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.3333333333333333, "f": 0.16666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3, "re": 0.42857142857142855, "f": 0.3529411764705882, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a large crowd of people standing on a street. They are all wearing different colored t-shirts and hoodies, and some of them are holding signs and banners. There are also several police officers standing on the sidewalk, looking at the crowd."}, "410023": {"image_id": 410023, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.13819269959596528, "Bleu_3": 0.09740171167974562, "Bleu_4": 0.06238676739153563, "METEOR": 0.2645329819904662, "ROUGE_L": 0.20792754187767823, "CIDEr": 7.014254948412192e-17, "SPICE": {"All": {"pr": 0.5, "re": 0.19047619047619047, "f": 0.27586206896551724, "fn": 17.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1, "f": 0.15384615384615383, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a group of teddy bears sitting in a room with a table and chairs. One of the bears is holding a cup of tea, while another is holding a plate of food. The bears are all wearing different outfits, including dresses and suits. There is a vase of flowers on the table, and a window in the background with trees outside."}, "71301": {"image_id": 71301, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.24643202903867023, "Bleu_3": 0.1486189512948787, "Bleu_4": 0.09771922616320827, "METEOR": 0.23103695472607785, "ROUGE_L": 0.2601279317697228, "CIDEr": 7.125816437591287e-05, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.3125, "f": 0.2857142857142857, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.8333333333333334, "f": 0.625, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people are standing on a snowy slope, watching as someone jumps off a ramp and lands on the ground below. The crowd is cheering and taking photos.\""}, "435533": {"image_id": 435533, "Bleu_1": 0.1538461538431953, "Bleu_2": 0.10984700727408482, "Bleu_3": 0.07844142656278796, "Bleu_4": 0.05602219133569573, "METEOR": 0.17244392130769876, "ROUGE_L": 0.23047858942065497, "CIDEr": 1.3414411197898928e-11, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1111111111111111, "f": 0.13043478260869565, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A bathroom with a toilet, sink, and shower\n\nThe bathroom has a toilet, sink, and shower. The toilet is on the left side of the room and the sink is on the right side. The shower is in the back of the room. There are no curtains or towels in the bathroom."}, "546378": {"image_id": 546378, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.2936101097470465, "Bleu_3": 0.23374701809645237, "Bleu_4": 0.17704094594288783, "METEOR": 0.2809821541307797, "ROUGE_L": 0.4190382728164868, "CIDEr": 0.006271315815134586, "SPICE": {"All": {"pr": 0.08108108108108109, "re": 0.15, "f": 0.10526315789473685, "fn": 17.0, "numImages": 1.0, "fp": 34.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "This is a picture of a cat sitting on top of a bookshelf. The cat has its paws up and is looking down at the books on the shelf."}, "518203": {"image_id": 518203, "Bleu_1": 0.6399999999744, "Bleu_2": 0.46188021533284057, "Bleu_3": 0.3817924868797279, "Bleu_4": 0.3171610602601282, "METEOR": 0.3223410650215608, "ROUGE_L": 0.433502538071066, "CIDEr": 0.14392251856015179, "SPICE": {"All": {"pr": 0.12, "re": 0.1875, "f": 0.14634146341463414, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a red and white airplane taking off from an airport runway. The plane is surrounded by buildings and trees in the background."}, "121016": {"image_id": 121016, "Bleu_1": 0.5429024507129954, "Bleu_2": 0.4046555949795809, "Bleu_3": 0.26457606599748784, "Bleu_4": 3.933517112506113e-05, "METEOR": 0.25867829462890474, "ROUGE_L": 0.5366568914956013, "CIDEr": 1.3743896458193174, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.16129032258064516, "f": 0.18867924528301885, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.06666666666666667, "f": 0.11764705882352941, "fn": 14.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a pan with broccoli and beef in it."}, "381031": {"image_id": 381031, "Bleu_1": 0.5714285714122449, "Bleu_2": 0.42996970773429194, "Bleu_3": 0.2819295448934807, "Bleu_4": 0.162673925998196, "METEOR": 0.32219509029884885, "ROUGE_L": 0.3733741392501913, "CIDEr": 0.0031065511439689075, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.21428571428571427, "f": 0.2857142857142857, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.07692307692307693, "f": 0.11764705882352941, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This image shows a table with several items on it, including a plate of food, a glass of juice, and a jar of peanut butter. There is also a cup of coffee on the table."}, "381630": {"image_id": 381630, "Bleu_1": 0.3846153846005918, "Bleu_2": 0.2148344622034018, "Bleu_3": 1.2435565865487868e-06, "Bleu_4": 3.0238984686568405e-09, "METEOR": 0.1718852181095524, "ROUGE_L": 0.2601279317697228, "CIDEr": 0.010698207658641656, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.175, "f": 0.2222222222222222, "fn": 33.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.058823529411764705, "f": 0.10526315789473684, "fn": 16.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a train on the tracks, with buildings in the background. The sky is clear and blue, with clouds in the distance."}, "241837": {"image_id": 241837, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.24867513640166544, "Bleu_3": 0.19453383472884356, "Bleu_4": 0.13766004133743878, "METEOR": 0.31899672690128295, "ROUGE_L": 0.34269662921348315, "CIDEr": 1.6500190926586733e-07, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.09090909090909091, "f": 0.10810810810810811, "fn": 20.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a man standing next to a dog on a skateboard in a park. The man is wearing a blue shirt and jeans, and the dog is wearing a red collar. The sky is cloudy and there are trees in the background."}, "91495": {"image_id": 91495, "Bleu_1": 0.35294117644982703, "Bleu_2": 0.21004201259146, "Bleu_3": 1.432760811493401e-06, "Bleu_4": 3.8071348661994064e-09, "METEOR": 0.21949415731346034, "ROUGE_L": 0.21353558926487748, "CIDEr": 0.41223629337184775, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a baseball player sliding into home plate while another player is tagging him out."}, "132024": {"image_id": 132024, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.3216337604400496, "Bleu_3": 0.19714987047942706, "Bleu_4": 2.3299898818396168e-05, "METEOR": 0.2792004803100398, "ROUGE_L": 0.3286047764410127, "CIDEr": 0.013112595943133906, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.23076923076923078, "f": 0.3529411764705882, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a person skiing down a snowy slope with mountains in the background. The person is wearing red and white clothing and has skis on their feet."}, "356400": {"image_id": 356400, "Bleu_1": 0.18571428571163268, "Bleu_2": 0.11600671073446796, "Bleu_3": 0.0925065394428158, "Bleu_4": 0.06972172513162021, "METEOR": 0.21699826898636282, "ROUGE_L": 0.23529411764705882, "CIDEr": 1.6620469743917924e-23, "SPICE": {"All": {"pr": 0.125, "re": 0.07692307692307693, "f": 0.09523809523809525, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is a kitchen with a large island in the center of the room. The walls are made of stone and there is a large window above the sink. There are two wooden beams on either side of the window, and a wooden floor. The cabinets are made of wood and have glass doors. There is a large stove in one corner of the room and a refrigerator in another."}, "146112": {"image_id": 146112, "Bleu_1": 0.33898305084171215, "Bleu_2": 0.2162320116770706, "Bleu_3": 0.13500881503154163, "Bleu_4": 1.4478533901560594e-05, "METEOR": 0.18519599148859192, "ROUGE_L": 0.3048614266242617, "CIDEr": 1.0715683639928723e-08, "SPICE": {"All": {"pr": 0.12, "re": 0.2, "f": 0.15, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a man standing on a stage in front of a group of people. He is wearing a black shirt and pants, and has a microphone in his hand. There are several bicycles parked on the stage behind him. The room appears to be a school auditorium with wooden chairs and a large window at the back."}, "413810": {"image_id": 413810, "Bleu_1": 0.5698222021537606, "Bleu_2": 0.3631918160063906, "Bleu_3": 2.230954526496004e-06, "Bleu_4": 5.662604394362829e-09, "METEOR": 0.20760470263747868, "ROUGE_L": 0.39804241435562804, "CIDEr": 0.3442202729446681, "SPICE": {"All": {"pr": 0.19444444444444445, "re": 0.30434782608695654, "f": 0.23728813559322037, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.14285714285714285, "f": 0.1, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}}, "caption": "A person skiing down a snowy mountain slope with trees in the background."}, "534444": {"image_id": 534444, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.30662207032435856, "Bleu_3": 0.22428282780473585, "Bleu_4": 0.14724623770370476, "METEOR": 0.2887675538674008, "ROUGE_L": 0.31671858774662515, "CIDEr": 0.009912281256296387, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.07692307692307693, "f": 0.11320754716981134, "fn": 36.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.23076923076923078, "f": 0.2857142857142857, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people are flying kites on a beach with a clear blue sky in the background.\""}, "527164": {"image_id": 527164, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.10350983389948797, "Bleu_3": 0.05832523373020616, "Bleu_4": 7.822100624658515e-06, "METEOR": 0.1694930499607991, "ROUGE_L": 0.20795454545454545, "CIDEr": 6.884862865210121e-14, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.16666666666666666, "f": 0.13559322033898305, "fn": 20.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"Juice Theory\" written on it. The sign is red and white, with the word \"Juice\" in bold black letters. The word \"Theory\" is written in smaller letters underneath. There are also some other signs and lights on the street, but they are not visible in the image."}, "193717": {"image_id": 193717, "Bleu_1": 0.35185185184533607, "Bleu_2": 0.19958027235629977, "Bleu_3": 0.11527999738977694, "Bleu_4": 0.07403258679339508, "METEOR": 0.24279322338105697, "ROUGE_L": 0.2684268426842684, "CIDEr": 7.341418918695054e-11, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.1, "f": 0.16216216216216217, "fn": 27.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.2727272727272727, "f": 0.39999999999999997, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is an image of a red fire hydrant on the side of a city street. The hydrant has a large, round body with a spout on top and a handle on the side. It is located on the corner of a busy intersection, surrounded by parked cars and pedestrians walking down the sidewalk."}, "456768": {"image_id": 456768, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.25440640194528097, "Bleu_3": 0.15320085491945573, "Bleu_4": 1.7903126508956717e-05, "METEOR": 0.252645976244034, "ROUGE_L": 0.3584470094438615, "CIDEr": 8.228387406189599e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a stop sign on the side of a road in a city. The sign is red and white, with the words \"stop\" written in black letters. There are trees and buildings visible in the background."}, "278350": {"image_id": 278350, "Bleu_1": 0.255813953482423, "Bleu_2": 0.17451086522195614, "Bleu_3": 0.1306153185181404, "Bleu_4": 0.0863934042964332, "METEOR": 0.21069646527509603, "ROUGE_L": 0.2616154395997141, "CIDEr": 1.5100339939190942e-06, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.375, "f": 0.34285714285714286, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a man standing in the water, looking out at the sky. He is wearing an orange shirt and has his arms stretched out to the side. There are buildings in the background, with trees and a river running through them."}, "251250": {"image_id": 251250, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.1923131632828435, "Bleu_3": 0.12713013434655676, "Bleu_4": 0.08753250723793518, "METEOR": 0.222476280941905, "ROUGE_L": 0.23282442748091606, "CIDEr": 7.1290578175453705e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A group of people stand on top of their surfboards in the water. They are wearing wetsuits and paddles, and one person is holding a surfboard leash. The water is calm and there are boats in the background."}, "428357": {"image_id": 428357, "Bleu_1": 0.29787234041919425, "Bleu_2": 0.1138023344325244, "Bleu_3": 0.06602320600489865, "Bleu_4": 8.993097209046812e-06, "METEOR": 0.24195925291092607, "ROUGE_L": 0.23843648208469054, "CIDEr": 5.4931423359754255e-09, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.05555555555555555, "f": 0.06779661016949153, "fn": 34.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.18181818181818182, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a group of airplanes parked on a runway. The planes are all different sizes and colors, with some having propellers and others having jet engines. There are also several people standing around the planes, looking at them or talking to each other."}, "76873": {"image_id": 76873, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.18257418583043256, "Bleu_3": 0.09572639770340008, "Bleu_4": 1.2408616318534126e-05, "METEOR": 0.18085575126753084, "ROUGE_L": 0.25558659217877094, "CIDEr": 7.794931990674951e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a man sitting in the driver's seat of a truck, wearing a pair of boots and holding onto the steering wheel. The truck is parked on the side of the road with its hazard lights on."}, "518375": {"image_id": 518375, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1456862718139933, "Bleu_3": 0.0761842752874376, "Bleu_4": 9.848600952552255e-06, "METEOR": 0.17108725054153157, "ROUGE_L": 0.26725082146768897, "CIDEr": 9.889228698747881e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "The image shows a table set with a white plate on top of it, containing a slice of pizza. There are two glasses of wine on the table, one red and one white. Two people are sitting at the table, one holding a knife and the other holding a fork."}, "191474": {"image_id": 191474, "Bleu_1": 0.24999999999218758, "Bleu_2": 0.12700012699615779, "Bleu_3": 8.131344326636123e-07, "Bleu_4": 2.0750198922948024e-09, "METEOR": 0.15801702926515432, "ROUGE_L": 0.24756493506493507, "CIDEr": 0.0010215238680674533, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.3125, "f": 0.3448275862068966, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5714285714285714, "f": 0.6153846153846153, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is an image of a yellow taxi driving down the street. The car is parked at the side of the road and there are trees on either side of the road."}, "261471": {"image_id": 261471, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.19577417125493551, "Bleu_3": 0.1421861682321534, "Bleu_4": 0.11018801516138978, "METEOR": 0.24767818707215225, "ROUGE_L": 0.27354260089686094, "CIDEr": 6.2275476566340255e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 4.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 1.0, "f": 0.4615384615384615, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a city street with tall buildings on either side. There are people walking on the sidewalk and cars driving down the street. The sky is blue and there are red and white lanterns hanging from the buildings."}, "87581": {"image_id": 87581, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.13794014695833945, "Bleu_3": 0.07680285411963501, "Bleu_4": 1.0252671801486271e-05, "METEOR": 0.15143658762259227, "ROUGE_L": 0.2506849315068493, "CIDEr": 1.1225747821499513e-07, "SPICE": {"All": {"pr": 0.4, "re": 0.2727272727272727, "f": 0.3243243243243243, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5555555555555556, "f": 0.6250000000000001, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a herd of zebras grazing in a dry, grassy area. There are several trees in the background, and a small body of water is visible in the distance. The sky is clear and blue, with a few white clouds scattered about."}, "376310": {"image_id": 376310, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.24913643955277223, "Bleu_3": 0.18805255721546232, "Bleu_4": 0.12527617695817345, "METEOR": 0.27050355289298267, "ROUGE_L": 0.4328287606433302, "CIDEr": 0.0429798104216743, "SPICE": {"All": {"pr": 0.375, "re": 0.2222222222222222, "f": 0.27906976744186046, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a purple bathroom with two sinks and a mirror on the wall. There are also two lights hanging from the ceiling, one of which is a large mirror."}, "451856": {"image_id": 451856, "Bleu_1": 0.370370370356653, "Bleu_2": 0.2387049580041334, "Bleu_3": 0.1658075448734274, "Bleu_4": 0.11739521785616198, "METEOR": 0.29854353876395345, "ROUGE_L": 0.4884884884884884, "CIDEr": 0.0051789921744911345, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.30434782608695654, "f": 0.31818181818181823, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.6666666666666666, "f": 0.631578947368421, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a group of people standing outside a building holding up signs with numbers on them. They are all smiling and looking at the camera."}, "81512": {"image_id": 81512, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.18650096164396338, "Bleu_3": 0.13335528843258257, "Bleu_4": 0.10248211207967507, "METEOR": 0.2882698300349757, "ROUGE_L": 0.28968792401628224, "CIDEr": 6.324120013857055e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.16666666666666666, "f": 0.13043478260869565, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a display case filled with various ceramic vases and other decorative items. The vases are of different shapes and sizes, some have flowers and other designs painted on them. There are also other decorative items such as figurines and sculptures displayed in the case."}, "268641": {"image_id": 268641, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.22340741580642487, "Bleu_3": 0.14611396602549223, "Bleu_4": 0.1001563233022011, "METEOR": 0.25937523246145805, "ROUGE_L": 0.3275544645596809, "CIDEr": 0.0029789830885959784, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.23809523809523808, "f": 0.23809523809523808, "fn": 16.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is an old fire hydrant on the side of a brick building. It has a red handle and a black body with white letters on it. There are other buildings in the background."}, "103837": {"image_id": 103837, "Bleu_1": 0.3157894736759004, "Bleu_2": 0.13065106688931807, "Bleu_3": 7.797842756795139e-07, "Bleu_4": 1.9185090136458934e-09, "METEOR": 0.2694645599395771, "ROUGE_L": 0.24636510500807754, "CIDEr": 1.5359965256502833e-05, "SPICE": {"All": {"pr": 0.23809523809523808, "re": 0.2631578947368421, "f": 0.25, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a horse racing on a dirt track. The horse is wearing a blue and white jockey's cap and riding on a brown and white saddle. There are people in the stands watching the race."}, "84060": {"image_id": 84060, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.14695129936263138, "Bleu_3": 8.075839294554588e-07, "Bleu_4": 1.904915665082057e-09, "METEOR": 0.16117674186582434, "ROUGE_L": 0.2317922735908803, "CIDEr": 1.043880898349189e-06, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.20833333333333334, "f": 0.2777777777777778, "fn": 19.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.08333333333333333, "f": 0.13333333333333333, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a young girl sitting on the ground, being helped by an adult to put her hair in a ponytail. The adult is holding a comb and smiling at the child. The background is a rocky terrain with trees and bushes."}, "110972": {"image_id": 110972, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.2691909510176227, "Bleu_3": 0.1487873735709676, "Bleu_4": 1.9900763311981462e-05, "METEOR": 0.3110407101540724, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.06015352119160307, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.1935483870967742, "f": 0.19999999999999998, "fn": 25.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.08333333333333333, "f": 0.10526315789473685, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a black bear standing on the grass, looking at something in its paw. The bear is surrounded by trees and foliage."}, "16451": {"image_id": 16451, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.2324952774812677, "Bleu_3": 0.11558994996382839, "Bleu_4": 1.4598906514772134e-05, "METEOR": 0.2050000926422131, "ROUGE_L": 0.24419535628502803, "CIDEr": 1.7462108654410078e-05, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08, "f": 0.08163265306122448, "fn": 23.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a beach scene with several surfboards and umbrellas on the sand. There are also some chairs and tables set up on the beach. The sky is blue and there are palm trees in the background."}, "525762": {"image_id": 525762, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.21808478994970526, "Bleu_3": 0.15408811207006284, "Bleu_4": 0.11779814467051919, "METEOR": 0.29909941382279315, "ROUGE_L": 0.3951061532925513, "CIDEr": 8.819399927201603e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.22727272727272727, "f": 0.22222222222222224, "fn": 17.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.1, "f": 0.0909090909090909, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.6666666666666666, "f": 0.6153846153846153, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a young boy playing tennis on a court with a net in the background. He is wearing white tennis shoes and holding a racket. The sun is shining down on him, casting a warm glow over the scene."}, "557321": {"image_id": 557321, "Bleu_1": 0.20833333333043982, "Bleu_2": 0.15321285325683098, "Bleu_3": 0.10020080375068616, "Bleu_4": 0.07348498842874635, "METEOR": 0.2046876493729207, "ROUGE_L": 0.2647569444444445, "CIDEr": 4.473914801957731e-18, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a person sitting at a desk with a computer, mouse, and keyboard in front of them. There are also several other electronic devices on the desk, including a monitor, speakers, and a printer. The person is wearing a black t-shirt and jeans, and has their hands on the keyboard and mouse. The background of the image appears to be a wooden floor with a red and white checkered pattern."}, "172094": {"image_id": 172094, "Bleu_1": 0.4999999999000002, "Bleu_2": 0.23570226034706615, "Bleu_3": 1.907857070517686e-06, "Bleu_4": 5.612222323072491e-09, "METEOR": 0.23693874629632286, "ROUGE_L": 0.31881533101045295, "CIDEr": 0.8765895935477599, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.30434782608695654, "f": 0.35, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.09090909090909091, "f": 0.12500000000000003, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.4, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5714285714285714, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "How to remove frizz from hair using a blow dryer."}, "570448": {"image_id": 570448, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2253202848508038, "Bleu_3": 0.12836987367391073, "Bleu_4": 1.741467509925889e-05, "METEOR": 0.18967039738961788, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.060980598200283224, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.38461538461538464, "f": 0.38461538461538464, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.7142857142857143, "f": 0.7142857142857143, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a small boat floating in the water next to a rocky shoreline. The sky is cloudy and there are no people in sight."}, "342397": {"image_id": 342397, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.12851660015582167, "Bleu_3": 7.785445529592332e-07, "Bleu_4": 1.930158055298998e-09, "METEOR": 0.18181818181818182, "ROUGE_L": 0.19535628502802244, "CIDEr": 1.4466337076082588e-05, "SPICE": {"All": {"pr": 0.12, "re": 0.13043478260869565, "f": 0.12499999999999997, "fn": 20.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a person skiing down a snowy slope. The person is wearing a helmet and goggles, and has their skis pointed towards the ground. There are trees in the background, and the sky is blue."}, "69842": {"image_id": 69842, "Bleu_1": 0.3333333333247864, "Bleu_2": 0.18731716231147263, "Bleu_3": 0.09824666233063457, "Bleu_4": 1.2739803480291042e-05, "METEOR": 0.23536597798111067, "ROUGE_L": 0.24148851939825808, "CIDEr": 5.9760904202075e-06, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.08, "f": 0.0851063829787234, "fn": 23.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a train with red and white stripes on the side. The train has a large window on the front and a door on the side. There are people standing outside the train, looking in."}, "199989": {"image_id": 199989, "Bleu_1": 0.357142857117347, "Bleu_2": 0.16574838602065456, "Bleu_3": 1.3179708049006483e-06, "Bleu_4": 3.7982292265213524e-09, "METEOR": 0.09890817335887275, "ROUGE_L": 0.2577464788732394, "CIDEr": 0.17279021718132737, "SPICE": {"All": {"pr": 0.11904761904761904, "re": 0.16129032258064516, "f": 0.136986301369863, "fn": 26.0, "numImages": 1.0, "fp": 37.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.2857142857142857, "f": 0.2758620689655172, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "Here is a short caption for the image:\n\n\"Skiing in the mountains with friends\""}, "290768": {"image_id": 290768, "Bleu_1": 0.382352941165225, "Bleu_2": 0.24069122088509454, "Bleu_3": 0.1535560171163264, "Bleu_4": 1.8486713289327748e-05, "METEOR": 0.21759798138952002, "ROUGE_L": 0.3117546848381601, "CIDEr": 0.00023546710478569873, "SPICE": {"All": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5555555555555556, "f": 0.4166666666666667, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "This is a kitchen with black and white checkered flooring. There is a stove, refrigerator, and sink in the room. The walls are white and there are windows on one side of the room."}, "38714": {"image_id": 38714, "Bleu_1": 0.2682926829235574, "Bleu_2": 0.19087904230595415, "Bleu_3": 0.13156251610585953, "Bleu_4": 0.08713644831558118, "METEOR": 0.20292475090695472, "ROUGE_L": 0.22444807849550288, "CIDEr": 1.6713545979918895e-13, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.12121212121212122, "f": 0.1702127659574468, "fn": 29.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on the beach with kites flying in the sky. The sky is clear and blue, with a few clouds scattered across it. The people are wearing red and black clothing and have their kites lined up on the sand. There are several other kites in the background, some of which are also flying in the sky. The image is taken from a low angle, looking down at the people and kites on the beach."}, "551215": {"image_id": 551215, "Bleu_1": 0.5135135134996348, "Bleu_2": 0.2925501419943171, "Bleu_3": 1.3472375969184147e-06, "Bleu_4": 2.91214782247913e-09, "METEOR": 0.2636978924613325, "ROUGE_L": 0.32323996971990915, "CIDEr": 0.0001146784673284324, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The woman in white is playing tennis on a green court. She is wearing a white shirt and shorts, and has a white racket in her hand. She is running towards the net to hit the ball."}, "48636": {"image_id": 48636, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.18881372800670282, "Bleu_3": 0.10366664702368887, "Bleu_4": 1.376857090860863e-05, "METEOR": 0.21912432388609987, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.000340476699817768, "SPICE": {"All": {"pr": 0.5, "re": 0.13513513513513514, "f": 0.21276595744680854, "fn": 32.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a baseball player in the middle of a swing, holding a bat and wearing a red jersey with white pants. The background is a blue sky with trees in the distance."}, "189427": {"image_id": 189427, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.19215378455856627, "Bleu_3": 1.1544156732180946e-06, "Bleu_4": 2.85982660320976e-09, "METEOR": 0.16527977044476327, "ROUGE_L": 0.2900158478605389, "CIDEr": 0.14437509143674013, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.2, "f": 0.18750000000000003, "fn": 12.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an image of a sign that reads, \"Stop, Don't Feed the Wildlife.\" It is sitting on the sidewalk in front of a park."}, "444755": {"image_id": 444755, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.15191090505870355, "Bleu_3": 8.468336402372791e-07, "Bleu_4": 2.012788513791449e-09, "METEOR": 0.25704261244665444, "ROUGE_L": 0.3139705882352941, "CIDEr": 6.283099401364268e-07, "SPICE": {"All": {"pr": 0.1875, "re": 0.23076923076923078, "f": 0.20689655172413793, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a man sitting in an armchair, wearing glasses and a suit. He is holding a small dog in his lap. The room appears to be a home office or study, with bookshelves and a desk in the background."}, "211498": {"image_id": 211498, "Bleu_1": 0.8333333331944446, "Bleu_2": 0.6154574547917563, "Bleu_3": 0.48436465299109077, "Bleu_4": 0.3352113418479386, "METEOR": 0.3415445263265626, "ROUGE_L": 0.5865384615384615, "CIDEr": 1.7248024537883109, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.16666666666666666, "f": 0.14634146341463414, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a plate of food with broccoli and cheese on it."}, "554900": {"image_id": 554900, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.16351748503705, "Bleu_3": 9.418739954830287e-07, "Bleu_4": 2.278527011349529e-09, "METEOR": 0.23167886352823483, "ROUGE_L": 0.21441124780316342, "CIDEr": 0.00010813224722055852, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is a bathroom with a toilet and sink. The walls are white and the floor is gray. There is a man standing in front of the toilet, wearing a black shirt and pants."}, "56684": {"image_id": 56684, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.17460757393808263, "Bleu_3": 0.13286000608093418, "Bleu_4": 0.10540405058349624, "METEOR": 0.23049903478322392, "ROUGE_L": 0.30049261083743845, "CIDEr": 6.989789124677558e-07, "SPICE": {"All": {"pr": 0.375, "re": 0.24, "f": 0.2926829268292683, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a doughnut sitting on top of a red and white striped tablecloth. The doughnut appears to be made of chocolate and has a hole in the middle. There is a small puddle of chocolate sauce next to it."}, "575051": {"image_id": 575051, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.20304239863369572, "Bleu_3": 0.14333375493847259, "Bleu_4": 1.637063006100509e-05, "METEOR": 0.296706995792097, "ROUGE_L": 0.33190827827438785, "CIDEr": 7.557203305641171e-07, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.10526315789473684, "f": 0.1, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and wearing a helmet. There are two umpires standing behind him, one holding a ball and the other with his arms crossed. The crowd is watching from the stands."}, "137294": {"image_id": 137294, "Bleu_1": 0.28813559321545534, "Bleu_2": 0.18648052280995095, "Bleu_3": 0.08481331406069398, "Bleu_4": 1.0216473629963139e-05, "METEOR": 0.17918939521098395, "ROUGE_L": 0.2724565756823822, "CIDEr": 1.709011325314139e-11, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 18.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This image shows a man in a white shirt and black pants standing next to an open window with a view of the surrounding area. The man is holding a small tool in his hand and appears to be working on something inside the window. The background is a green field with trees and buildings visible in the distance."}, "168953": {"image_id": 168953, "Bleu_1": 0.6086956521474481, "Bleu_2": 0.5260036519575005, "Bleu_3": 0.42917705119894006, "Bleu_4": 0.32998954723738916, "METEOR": 0.4148996114112808, "ROUGE_L": 0.5162460329454436, "CIDEr": 0.29051829829128945, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.13333333333333333, "f": 0.1212121212121212, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The man is sitting at a table with several cell phones in front of him. He is smiling and looking at the camera."}, "552752": {"image_id": 552752, "Bleu_1": 0.16304347825909737, "Bleu_2": 0.1036827827825654, "Bleu_3": 0.04924818846224826, "Bleu_4": 6.0526448748033915e-06, "METEOR": 0.17201583924997454, "ROUGE_L": 0.17862371888726206, "CIDEr": 5.736821301128046e-40, "SPICE": {"All": {"pr": 0.058823529411764705, "re": 0.09090909090909091, "f": 0.07142857142857142, "fn": 20.0, "numImages": 1.0, "fp": 32.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a man standing on the platform of an old train car. He is wearing a blue shirt and jeans, and has his arms stretched out to the side as if he is about to climb onto the train. The train car appears to be old and rusted, with peeling paint and rust spots on the sides. There are windows on either side of the train car, but they are covered in grime and dust. The man's face is obscured by shadows, making it difficult to see his expression."}, "61418": {"image_id": 61418, "Bleu_1": 0.23188405796765385, "Bleu_2": 0.11679143249305168, "Bleu_3": 0.05882777047287611, "Bleu_4": 7.452479808923815e-06, "METEOR": 0.19138601598891328, "ROUGE_L": 0.20063903768442817, "CIDEr": 3.727212100421538e-21, "SPICE": {"All": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 18.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.1111111111111111, "f": 0.19999999999999998, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}}, "caption": "This is a black and white photograph of a group of children playing tic tac toe on a wooden board on the deck of a ship. The children are sitting in chairs around the board, which has a large X marked in the center. There are several other people standing nearby, watching the game. The ship is in the background, with a large white building visible in the distance."}, "367905": {"image_id": 367905, "Bleu_1": 0.24999999999479172, "Bleu_2": 0.12632278815731815, "Bleu_3": 7.026437559457351e-07, "Bleu_4": 1.6662810872720655e-09, "METEOR": 0.16800300116993494, "ROUGE_L": 0.19551282051282048, "CIDEr": 8.440854788682846e-10, "SPICE": {"All": {"pr": 0.45, "re": 0.4090909090909091, "f": 0.4285714285714286, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 9.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.8571428571428571, "f": 0.7999999999999999, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}}, "caption": "The image shows a surfer riding a wave on a large, green wave. The surfer is lying on the board and appears to be in mid-air as they are being pulled by the force of the water. The sky is blue and there are clouds in the background."}, "159500": {"image_id": 159500, "Bleu_1": 0.17647058823183395, "Bleu_2": 0.10289915108346752, "Bleu_3": 0.06000800213279682, "Bleu_4": 8.191181829040966e-06, "METEOR": 0.14314567842965334, "ROUGE_L": 0.15259537210756724, "CIDEr": 9.922912714489426e-12, "SPICE": {"All": {"pr": 0.1, "re": 0.17647058823529413, "f": 0.12765957446808512, "fn": 14.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a bathroom with red walls and white tiles on the floor. There are two toilets in the room, one on each side of the room. The toilets have white seats and red handles. There is also a sink in the corner of the room with a mirror above it."}, "415768": {"image_id": 415768, "Bleu_1": 0.6956521738827978, "Bleu_2": 0.5897678245933637, "Bleu_3": 0.4876186398530248, "Bleu_4": 0.3902273664303574, "METEOR": 0.4107688788029887, "ROUGE_L": 0.5451837140019861, "CIDEr": 0.30923370289832547, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.1111111111111111, "f": 0.15, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a pot filled with vegetables, including carrots and onions. The pot is being stirred by a wooden spoon."}, "521141": {"image_id": 521141, "Bleu_1": 0.49999999998076927, "Bleu_2": 0.3162277660044321, "Bleu_3": 1.609148974278283e-06, "Bleu_4": 3.668725603033444e-09, "METEOR": 0.20588556755798226, "ROUGE_L": 0.29158699808795413, "CIDEr": 0.04079221131863285, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.23333333333333334, "f": 0.26415094339622636, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is an image of a street with people walking on it. There are tall buildings in the background and a stop sign at the corner."}, "210654": {"image_id": 210654, "Bleu_1": 0.423076923060651, "Bleu_2": 0.2908872369299581, "Bleu_3": 0.1521993147229894, "Bleu_4": 1.9786891108517274e-05, "METEOR": 0.20354708421785725, "ROUGE_L": 0.34990439770554493, "CIDEr": 0.040035919990295696, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.21739130434782608, "f": 0.2127659574468085, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.6, "f": 0.35294117647058826, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a skateboard with two shoes on it, one black and one white. The skateboard is lying on the ground next to a road."}, "52664": {"image_id": 52664, "Bleu_1": 0.3928571428431123, "Bleu_2": 0.20892772350173638, "Bleu_3": 0.11885193737704458, "Bleu_4": 1.6097917483901073e-05, "METEOR": 0.25138339046032676, "ROUGE_L": 0.2978515625, "CIDEr": 0.005293801888363184, "SPICE": {"All": {"pr": 0.02857142857142857, "re": 0.03225806451612903, "f": 0.030303030303030307, "fn": 30.0, "numImages": 1.0, "fp": 34.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.0625, "f": 0.06666666666666667, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "This image shows a pizza on a wooden cutting board with fresh basil leaves and tomatoes on top. The pizza appears to be cooked and ready to eat."}, "306139": {"image_id": 306139, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.23553456043175583, "Bleu_3": 0.18335338163444456, "Bleu_4": 0.1516107498499942, "METEOR": 0.2782392648807478, "ROUGE_L": 0.4078751857355126, "CIDEr": 4.0445286636278105e-05, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.15625, "f": 0.16666666666666666, "fn": 27.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.07142857142857142, "f": 0.08333333333333333, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people sitting at tables in a large room. They are all wearing casual clothing and appear to be working on laptops. There is a whiteboard on the wall with writing on it."}, "487222": {"image_id": 487222, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.11527712042367076, "Bleu_4": 1.436255531737259e-05, "METEOR": 0.2649121175860384, "ROUGE_L": 0.2741573033707865, "CIDEr": 9.297755293794644e-06, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.2608695652173913, "f": 0.2105263157894737, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.4166666666666667, "f": 0.3703703703703704, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a large airplane flying over a garden with trees and flowers. The plane is white with blue stripes on the wings and tail. The sky is clear and blue, with a few clouds in the distance."}, "331049": {"image_id": 331049, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.2241462600435509, "Bleu_3": 0.10452097182751273, "Bleu_4": 1.2765430498436265e-05, "METEOR": 0.2899678171461777, "ROUGE_L": 0.31812255541069095, "CIDEr": 2.451392925964851e-08, "SPICE": {"All": {"pr": 0.1935483870967742, "re": 0.25, "f": 0.21818181818181817, "fn": 18.0, "numImages": 1.0, "fp": 25.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.21428571428571427, "re": 0.3, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a black horse standing on top of a hill with trees in the background. The horse is looking out into the distance, its mane and tail blowing in the wind. The sky is clear and blue, with a few clouds scattered across it."}, "107558": {"image_id": 107558, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1922322627296484, "Bleu_3": 0.11391235988457692, "Bleu_4": 1.317889860975062e-05, "METEOR": 0.2644537921230868, "ROUGE_L": 0.2688916876574307, "CIDEr": 3.5648352534326974e-12, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.22727272727272727, "f": 0.29411764705882354, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.4444444444444444, "f": 0.5714285714285714, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image shows a person riding a skateboard on a half pipe. The person is wearing a black shirt and pants, and has a helmet on their head. The half pipe is made of wood and has a green surface. There are several other people in the background watching the person ride."}, "528714": {"image_id": 528714, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.22758963106159172, "Bleu_3": 0.1948658043740226, "Bleu_4": 0.17331983335639942, "METEOR": 0.31604728030976825, "ROUGE_L": 0.37602739726027395, "CIDEr": 1.2917765113807113e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.24, "f": 0.23076923076923075, "fn": 19.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This image shows a group of people playing tennis on a court at night. The players are wearing white shirts and black shorts, and they are holding rackets in their hands. The court is illuminated by floodlights, and there are trees in the background."}, "316806": {"image_id": 316806, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.43033148289569056, "Bleu_3": 0.35421952304723314, "Bleu_4": 0.2933705789196043, "METEOR": 0.37710620523073635, "ROUGE_L": 0.5304347826086957, "CIDEr": 0.10539934188888395, "SPICE": {"All": {"pr": 0.041666666666666664, "re": 0.08333333333333333, "f": 0.05555555555555555, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a sign on a pole in the middle of a field with trees and water in the background. The sign reads, \"No Fishing Allowed\"."}, "446473": {"image_id": 446473, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.16408253082431878, "Bleu_3": 0.08914842985218376, "Bleu_4": 1.1763453574139755e-05, "METEOR": 0.20973486061547578, "ROUGE_L": 0.32670237184391737, "CIDEr": 0.00023582369231406574, "SPICE": {"All": {"pr": 0.1282051282051282, "re": 0.23809523809523808, "f": 0.16666666666666666, "fn": 16.0, "numImages": 1.0, "fp": 34.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.23529411764705882, "re": 0.5714285714285714, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}}, "caption": "This is an image of a skier in mid-air, performing a trick on a snowboard. The skier is wearing a red and black outfit with a helmet and goggles. The background is blue and there are clouds in the sky."}, "364126": {"image_id": 364126, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.2199928503447174, "Bleu_3": 0.15120391375656378, "Bleu_4": 0.10588613616169155, "METEOR": 0.19238240586760136, "ROUGE_L": 0.2105868814729574, "CIDEr": 3.24241890631111e-15, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.21052631578947367, "f": 0.21621621621621623, "fn": 15.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5714285714285714, "f": 0.5333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a surfer riding a wave on a surfboard in the ocean. The surfer is wearing a wetsuit and standing on the board, with his arms outstretched to balance himself. The wave is large and white, with a lot of foam on top. The sky is blue and cloudy, with some clouds visible in the distance."}, "83331": {"image_id": 83331, "Bleu_1": 0.714285714234694, "Bleu_2": 0.4688072309037214, "Bleu_3": 0.2635941609801295, "Bleu_4": 3.5921434200531924e-05, "METEOR": 0.18793560473009527, "ROUGE_L": 0.3824451410658307, "CIDEr": 0.6568747966641277, "SPICE": {"All": {"pr": 0.06666666666666667, "re": 0.09090909090909091, "f": 0.07692307692307691, "fn": 20.0, "numImages": 1.0, "fp": 28.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is an old traffic light with three red and green lights on it."}, "347768": {"image_id": 347768, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.2836543144559696, "Bleu_3": 0.17912254476139916, "Bleu_4": 2.1479380273480794e-05, "METEOR": 0.24804975949769378, "ROUGE_L": 0.2839851024208566, "CIDEr": 0.004497009186173826, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.17857142857142858, "f": 0.2702702702702703, "fn": 23.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.3333333333333333, "f": 0.47058823529411764, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "This image shows a group of cars driving down a city street. The cars are parked on the side of the road and there are other vehicles in the background."}, "491017": {"image_id": 491017, "Bleu_1": 0.22535211267288235, "Bleu_2": 0.17021704690637807, "Bleu_3": 0.13607220455194347, "Bleu_4": 0.09278063413204765, "METEOR": 0.1917903869309031, "ROUGE_L": 0.2274755277352334, "CIDEr": 1.6264657229707487e-21, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.12903225806451613, "f": 0.19047619047619047, "fn": 27.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a group of men in leather outfits standing on the sidewalk. They are wearing leather harnesses, chaps, and boots, and they are holding umbrellas. One of them is holding an umbrella over his head while the others are standing around him. The men are dressed in leather outfits with different colors and designs. The background of the image is a city street with buildings and cars passing by."}, "525077": {"image_id": 525077, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.19908326484038252, "Bleu_3": 0.10053909397198176, "Bleu_4": 1.2788079462564404e-05, "METEOR": 0.19564671775544631, "ROUGE_L": 0.25756509500351865, "CIDEr": 8.671388997652687e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.375, "f": 0.27906976744186046, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a white and red airplane flying in the sky. The plane has a large wing and a long tail, and it is flying at a high altitude. There are clouds in the background of the image."}, "29306": {"image_id": 29306, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.16408253082431878, "Bleu_3": 8.914842985218379e-07, "Bleu_4": 2.0918707281841494e-09, "METEOR": 0.20635650016907198, "ROUGE_L": 0.27199762187871585, "CIDEr": 2.8449177722073504e-06, "SPICE": {"All": {"pr": 0.28, "re": 0.21875, "f": 0.2456140350877193, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "A brown and white dog is standing on the beach, looking out at the ocean. The dog is wearing a black collar with a tag that reads \"Buddy\". The sky is cloudy and there are waves crashing in the distance."}, "81303": {"image_id": 81303, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.14679516868082104, "Bleu_3": 0.0933381560521831, "Bleu_4": 0.06288449487585455, "METEOR": 0.22663785361552527, "ROUGE_L": 0.207506520013607, "CIDEr": 7.934270426142361e-13, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.15, "f": 0.19354838709677416, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a black and white jacket, black pants, and black ski boots. They are holding onto a pair of skis with red bindings and are wearing a black helmet. The background is a snowy mountain with trees in the distance."}, "297520": {"image_id": 297520, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.15617376188474938, "Bleu_3": 0.08551661700652094, "Bleu_4": 1.1326402344943274e-05, "METEOR": 0.189244859616775, "ROUGE_L": 0.2588767859668977, "CIDEr": 1.4655611957054304e-06, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This image shows a barbecue grill with several sausages and hot dogs on it. The grill is made of metal and has two racks for cooking the food. There are also some condiments, such as mustard and ketchup, on the grill."}, "300341": {"image_id": 300341, "Bleu_1": 0.19999999999692308, "Bleu_2": 0.0968245836536842, "Bleu_3": 0.05299199164658822, "Bleu_4": 6.999383015867027e-06, "METEOR": 0.1726731206970414, "ROUGE_L": 0.15365239294710328, "CIDEr": 2.0515347020728688e-19, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.19047619047619047, "f": 0.2, "fn": 17.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a group of men playing video games in a living room. They are all wearing casual clothing and are gathered around a large screen displaying the game. One man is holding a controller and another is standing next to him, watching the game. The room has a couch, coffee table, and chairs, and there are several other objects scattered around the room."}, "357": {"image_id": 357, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.1704985848636984, "Bleu_3": 0.11144846405416943, "Bleu_4": 0.07622713576923955, "METEOR": 0.1750764120945939, "ROUGE_L": 0.2787206266318538, "CIDEr": 1.2046152394327409e-06, "SPICE": {"All": {"pr": 0.4, "re": 0.2727272727272727, "f": 0.3243243243243243, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a baseball game in progress on a green field. There are several players on the field, including a pitcher throwing a ball to a batter at the plate. The crowd is seated in the stands behind home plate, watching the game."}, "188718": {"image_id": 188718, "Bleu_1": 0.6666666665555557, "Bleu_2": 0.49236596383340503, "Bleu_3": 0.3646436716648588, "Bleu_4": 0.27091988541888634, "METEOR": 0.27983161214044694, "ROUGE_L": 0.4149659863945578, "CIDEr": 1.1558670863533267, "SPICE": {"All": {"pr": 0.1875, "re": 0.1111111111111111, "f": 0.13953488372093023, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Two zebras grazing in a field with a fence in the background."}, "554749": {"image_id": 554749, "Bleu_1": 0.255813953482423, "Bleu_2": 0.2064840403341673, "Bleu_3": 0.17324194153709652, "Bleu_4": 0.140525486513859, "METEOR": 0.2927794663652461, "ROUGE_L": 0.34882058613295214, "CIDEr": 1.4135356786404685e-07, "SPICE": {"All": {"pr": 0.10256410256410256, "re": 0.21052631578947367, "f": 0.13793103448275865, "fn": 15.0, "numImages": 1.0, "fp": 35.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.6666666666666666, "f": 0.3809523809523809, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a bathroom with a large walk in shower, a double sink, and a toilet. The walls are beige and the floors are white tile. There is a large window on one side of the room and a mirror on the other."}, "439709": {"image_id": 439709, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.33333333332075027, "Bleu_3": 0.23712622029020833, "Bleu_4": 0.1535259783805314, "METEOR": 0.26842461560315395, "ROUGE_L": 0.3948220064724919, "CIDEr": 0.038145401231784434, "SPICE": {"All": {"pr": 0.24, "re": 0.21428571428571427, "f": 0.2264150943396226, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a group of three ceramic plates with birds on them. The plates are painted with different colors and designs, including red cardinals perched on branches."}, "122354": {"image_id": 122354, "Bleu_1": 0.4090909090723141, "Bleu_2": 4.41367414731835e-09, "Bleu_3": 9.912659293961434e-12, "Bleu_4": 4.758326453740933e-13, "METEOR": 0.17817371937639198, "ROUGE_L": 0.20938215102974828, "CIDEr": 0.04296569082886664, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a street with cars parked on the side of the road. There are trees and buildings in the background."}, "184400": {"image_id": 184400, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.21501265303422734, "Bleu_3": 0.10869473591519455, "Bleu_4": 1.3840104608852469e-05, "METEOR": 0.27748584718116787, "ROUGE_L": 0.2793893129770992, "CIDEr": 2.2401981690733808e-05, "SPICE": {"All": {"pr": 0.38095238095238093, "re": 0.22857142857142856, "f": 0.2857142857142857, "fn": 27.0, "numImages": 1.0, "fp": 13.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7, "re": 0.4666666666666667, "f": 0.56, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 7.0}}, "caption": "The image shows a blue and yellow train traveling on the tracks. It is passing underneath a bridge with buildings on either side. There are people standing on the platform looking at the train as it goes by."}, "196430": {"image_id": 196430, "Bleu_1": 0.3499999999912501, "Bleu_2": 0.26794565081604904, "Bleu_3": 0.17829685970436746, "Bleu_4": 1.978369188299523e-05, "METEOR": 0.31016910385797947, "ROUGE_L": 0.34078212290502796, "CIDEr": 1.0660903818088452e-05, "SPICE": {"All": {"pr": 0.13636363636363635, "re": 0.13636363636363635, "f": 0.13636363636363635, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is an image of a young boy playing baseball in a park. He is wearing a blue shirt and white pants, and has a bat in his hand. The background is a green field with trees in the distance."}, "501116": {"image_id": 501116, "Bleu_1": 0.5185185184993142, "Bleu_2": 0.3736323588644323, "Bleu_3": 0.22352510977339834, "Bleu_4": 2.6118120858614525e-05, "METEOR": 0.23889585727859006, "ROUGE_L": 0.3857271906052394, "CIDEr": 0.015264618609495718, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.18518518518518517, "f": 0.17857142857142858, "fn": 22.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.07692307692307693, "f": 0.08695652173913043, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a street with a red light at the intersection. There are trees on both sides of the road and a house in the background."}, "460967": {"image_id": 460967, "Bleu_1": 0.3902439024295063, "Bleu_2": 0.2613286875248416, "Bleu_3": 0.15186109291115854, "Bleu_4": 1.742364410651411e-05, "METEOR": 0.21796330522437268, "ROUGE_L": 0.29550173010380626, "CIDEr": 2.1632572357647424e-05, "SPICE": {"All": {"pr": 0.12, "re": 0.1, "f": 0.1090909090909091, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a red and yellow bus parked in front of a tall building. The bus has the words \"City Bus\" written on the side in white letters. There are other cars and buildings visible in the background."}, "107216": {"image_id": 107216, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.32566947362944193, "Bleu_3": 0.2173224313183697, "Bleu_4": 0.1360028792323118, "METEOR": 0.30791043143799907, "ROUGE_L": 0.38822593476531425, "CIDEr": 0.004824352234028097, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.24, "f": 0.2727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4444444444444444, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This image shows a red and white boat docked at a pier on a body of water. The reflection of the boat in the water creates an interesting pattern of colors and shapes."}, "172935": {"image_id": 172935, "Bleu_1": 0.1224489795893378, "Bleu_2": 0.05050762722656906, "Bleu_3": 3.7862157551937406e-07, "Bleu_4": 1.042232377987996e-09, "METEOR": 0.12840957201839587, "ROUGE_L": 0.15752098127824402, "CIDEr": 4.838876785172372e-10, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.17647058823529413, "f": 0.23076923076923078, "fn": 14.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is an old black and white photograph of a man jumping off a cliff into the water below. The man is wearing a pair of sunglasses and has his arms outstretched as he jumps. There are several boats in the background, and the water is choppy and turbulent."}, "277032": {"image_id": 277032, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.282038037400203, "Bleu_3": 0.19745053261647894, "Bleu_4": 2.2506782730688327e-05, "METEOR": 0.2687082425191655, "ROUGE_L": 0.30886075949367087, "CIDEr": 0.0018041668929942509, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2, "f": 0.25641025641025644, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a man standing in the snow with skis and poles. He is wearing a black jacket and pants, and has a backpack on his back. There are mountains in the background."}, "475613": {"image_id": 475613, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.18802535826836297, "Bleu_3": 0.1351124024482053, "Bleu_4": 0.08754051346381944, "METEOR": 0.22291250894375186, "ROUGE_L": 0.32635903315181036, "CIDEr": 1.2197335505374707e-07, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.2, "f": 0.25531914893617025, "fn": 24.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.125, "re": 0.07142857142857142, "f": 0.09090909090909091, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.45454545454545453, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a person holding a pizza in their hands, with the toppings visible on the surface of the pizza. The person is standing in front of a wooden table with a white cloth covering it. There are trees and grass in the background."}, "551288": {"image_id": 551288, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.24099009324731976, "Bleu_3": 0.2105479193073048, "Bleu_4": 0.17067308717449073, "METEOR": 0.31484161964424534, "ROUGE_L": 0.3565356004250797, "CIDEr": 1.5723870442458779e-13, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.24, "f": 0.2553191489361702, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a woman sitting at a table with two plates of food in front of her. One plate has a piece of chicken on it, while the other has a salad with lettuce, tomatoes, and olives. There are also two glasses of wine on the table. The woman is smiling and looking directly at the camera."}, "169438": {"image_id": 169438, "Bleu_1": 0.19230769230399414, "Bleu_2": 0.12281268769488378, "Bleu_3": 0.08449846526122942, "Bleu_4": 0.05923625523333362, "METEOR": 0.2675724439161268, "ROUGE_L": 0.22536945812807885, "CIDEr": 9.272783703310007e-12, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 16.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA group of children are sitting in front of a television playing video games. One child is holding a controller and another is watching the screen intently. The room has a blue and white color scheme with a Christmas tree in the corner."}, "468965": {"image_id": 468965, "Bleu_1": 0.2444444444390124, "Bleu_2": 0.10540925533657697, "Bleu_3": 6.369368049040698e-07, "Bleu_4": 1.5749252146545933e-09, "METEOR": 0.17839949013411185, "ROUGE_L": 0.22467771639042353, "CIDEr": 8.983124991652928e-08, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.22727272727272727, "f": 0.21739130434782608, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe children are playing soccer in the middle of a small town. They are wearing school uniforms and holding signs with their names on them. The buildings in the background are old and made of wood."}, "568559": {"image_id": 568559, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.16749259602844443, "Bleu_3": 0.12533108165793935, "Bleu_4": 0.09157028861779119, "METEOR": 0.2541975963715559, "ROUGE_L": 0.24220079410096426, "CIDEr": 3.980719548560995e-15, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a black cat sitting on top of a wooden desk. The cat is looking directly at the camera with its eyes and appears to be purring. There are several items on the desk, including a laptop, a keyboard, and a mouse. The background is a messy room with a cluttered desk and various objects scattered around."}, "503392": {"image_id": 503392, "Bleu_1": 0.16666666666452992, "Bleu_2": 0.09304842103864643, "Bleu_3": 0.061077062248229286, "Bleu_4": 0.04174873194091566, "METEOR": 0.15712956732380043, "ROUGE_L": 0.21031892624061077, "CIDEr": 1.326227899343777e-27, "SPICE": {"All": {"pr": 0.42857142857142855, "re": 0.12, "f": 0.1875, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a woman standing on top of a horse, wearing a black and white outfit. The horse is white with brown mane and tail. The woman is holding the reins of the horse with one hand and has the other hand on its back. There are two other horses in the background, one white and one brown. The image is taken in a dark room with a spotlight shining down on the woman and the horses."}, "317310": {"image_id": 317310, "Bleu_1": 0.2826086956460303, "Bleu_2": 0.19411635536098795, "Bleu_3": 0.1369612187156522, "Bleu_4": 0.08791866703176521, "METEOR": 0.2786608357004765, "ROUGE_L": 0.37821080602302926, "CIDEr": 1.8025764165518599e-07, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.17647058823529413, "f": 0.13636363636363638, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a toy bear sitting in a bathtub filled with water. The bear is wearing a red and white striped bathrobe and has its paws on the edge of the tub. There is a rubber ducky floating in the water next to the bear."}, "244925": {"image_id": 244925, "Bleu_1": 0.3888888888780865, "Bleu_2": 0.27888667550350105, "Bleu_3": 0.13176261473117587, "Bleu_4": 1.6226156799009994e-05, "METEOR": 0.2473881445184496, "ROUGE_L": 0.4236111111111111, "CIDEr": 0.0009770556391944373, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.25, "f": 0.17777777777777778, "fn": 12.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.75, "f": 0.4285714285714285, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a person wearing a backpack and holding a camera. They are standing near a body of water, possibly a lake or river. The sky is cloudy and there are trees in the background."}, "14821": {"image_id": 14821, "Bleu_1": 0.6249999999609376, "Bleu_2": 0.40824829043749705, "Bleu_3": 0.22833557018287956, "Bleu_4": 3.0934588292167495e-05, "METEOR": 0.25623795607354893, "ROUGE_L": 0.4212707182320442, "CIDEr": 0.5063721222099921, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.1, "f": 0.0975609756097561, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a backpack on a chair with various items inside, including food and drinks."}, "28903": {"image_id": 28903, "Bleu_1": 0.36842105262188374, "Bleu_2": 0.2993592018235193, "Bleu_3": 0.215136569053405, "Bleu_4": 0.15444582275065438, "METEOR": 0.3028041234816226, "ROUGE_L": 0.37251908396946565, "CIDEr": 4.2875538668654196e-05, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.05555555555555555, "f": 0.06666666666666667, "fn": 34.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.14285714285714285, "f": 0.17391304347826086, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on top of a toilet in a bathroom. The cat is looking directly at the camera with its eyes. There is a sink and a mirror in the background of the image."}, "204804": {"image_id": 204804, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.14505284310643746, "Bleu_3": 0.09037934933366287, "Bleu_4": 1.0715313974803593e-05, "METEOR": 0.1294086711631142, "ROUGE_L": 0.2667379263434069, "CIDEr": 1.0772322083952611e-12, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.19047619047619047, "f": 0.1568627450980392, "fn": 17.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.4, "f": 0.32, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a bathroom with a large mirror on the wall. There is a sink in the corner of the room and a toilet in the opposite corner. The floor is made of white tiles and there are two chairs in front of the sink. The walls are made of wood and there is a skylight in the ceiling."}, "377486": {"image_id": 377486, "Bleu_1": 0.3448275862009513, "Bleu_2": 0.19051939704947346, "Bleu_3": 0.10903688982210127, "Bleu_4": 0.06967699606717573, "METEOR": 0.18742665098409106, "ROUGE_L": 0.30262225372076546, "CIDEr": 0.016875846302443837, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.2631578947368421, "f": 0.23255813953488372, "fn": 14.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.6666666666666666, "f": 0.4444444444444444, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a man riding a horse in a rodeo arena. The man is wearing a cowboy hat and holding onto the reins of the horse as it gallops around the arena. There are other riders in the arena, some of whom are also riding horses. The crowd is cheering and waving their hats in the air."}, "488522": {"image_id": 488522, "Bleu_1": 0.5416666666440973, "Bleu_2": 0.43405736612273677, "Bleu_3": 0.3247709612094161, "Bleu_4": 0.2009685362352922, "METEOR": 0.35631574788692394, "ROUGE_L": 0.5187074829931972, "CIDEr": 0.2573106143563201, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.4, "f": 0.3636363636363636, "fn": 12.0, "numImages": 1.0, "fp": 16.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5833333333333334, "re": 0.7777777777777778, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 7.0}}, "caption": "The image shows a chocolate cake with a knife cutting into it. There are also some chocolate chips on the side of the cake."}, "223751": {"image_id": 223751, "Bleu_1": 0.24324324323666918, "Bleu_2": 0.11624763874063387, "Bleu_3": 7.28171055578613e-07, "Bleu_4": 1.8357153088490472e-09, "METEOR": 0.18445711054635608, "ROUGE_L": 0.2514427040395713, "CIDEr": 1.9855771964750504e-05, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.28, "f": 0.30434782608695654, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This image shows a group of people surfing on the ocean. They are standing on their surfboards and paddling through the waves. The sun is setting in the background, casting a warm orange glow over the scene."}, "237011": {"image_id": 237011, "Bleu_1": 0.33333333331944454, "Bleu_2": 0.2691909510176227, "Bleu_3": 0.18746034392063415, "Bleu_4": 2.3666129324593467e-05, "METEOR": 0.22232149323872896, "ROUGE_L": 0.3177083333333333, "CIDEr": 0.057917246556114715, "SPICE": {"All": {"pr": 0.125, "re": 0.1875, "f": 0.15, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a pizza with toppings such as sausage, mushrooms, and onions. There are also glasses of wine on the table."}, "431140": {"image_id": 431140, "Bleu_1": 0.41176470587024233, "Bleu_2": 0.2497770842103635, "Bleu_3": 0.15739649855173027, "Bleu_4": 0.10590241811161, "METEOR": 0.30758632446295225, "ROUGE_L": 0.43345364313106244, "CIDEr": 0.0014312178733944883, "SPICE": {"All": {"pr": 0.5, "re": 0.2608695652173913, "f": 0.3428571428571428, "fn": 17.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.5555555555555556, "f": 0.6666666666666667, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "This is a bathroom with a toilet, sink, and mirror. The walls are painted white and the floor is made of tile. There is a window in the background that lets in natural light."}, "494393": {"image_id": 494393, "Bleu_1": 0.1868131868111339, "Bleu_2": 0.12054009511193119, "Bleu_3": 0.06886010536217355, "Bleu_4": 0.04388894021958863, "METEOR": 0.181565377749161, "ROUGE_L": 0.19016279875303083, "CIDEr": 1.0792411812326016e-34, "SPICE": {"All": {"pr": 0.25, "re": 0.17391304347826086, "f": 0.20512820512820512, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a street scene with a car parked on the side of the road. There are two people standing outside of a building, one of them is looking at their phone and the other is looking at something else. The building has a sign that reads \"Luxury Apartments\" in large letters. There are also several other signs on the building, including one that reads \"Parking Only\" and another that reads \"No Parking\". The street is lined with trees and there are cars parked along both sides of the road."}, "179392": {"image_id": 179392, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.16666666666404184, "Bleu_3": 0.09640774730796577, "Bleu_4": 1.1009091786309399e-05, "METEOR": 0.2573482316841687, "ROUGE_L": 0.24448897795591185, "CIDEr": 3.450439789933042e-18, "SPICE": {"All": {"pr": 0.25, "re": 0.15789473684210525, "f": 0.1935483870967742, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.4, "f": 0.3076923076923077, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a black and white cat sitting on top of a wooden desk. The cat has a collar around its neck and is looking up at the camera with its eyes. There are several other objects on the desk, including a laptop, a mouse, and a cup of coffee. The background is a messy office space with papers and books scattered around."}, "187565": {"image_id": 187565, "Bleu_1": 0.17333333333102224, "Bleu_2": 0.12804841426568395, "Bleu_3": 0.060786692916430934, "Bleu_4": 7.473486651460866e-06, "METEOR": 0.1604452107901632, "ROUGE_L": 0.18952507767421217, "CIDEr": 4.533212330890647e-26, "SPICE": {"All": {"pr": 0.4666666666666667, "re": 0.2916666666666667, "f": 0.35897435897435903, "fn": 17.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}, "Relation": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.8, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a vase with red roses sitting on a table in front of a red wall. The table is made of wood and has a smooth surface. The vase is made of metal and has a round shape with a handle on the side. The roses are arranged in a bouquet and are placed in the vase. The wall behind the table is red and has a pattern of red and white stripes."}, "405740": {"image_id": 405740, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.27588029391667884, "Bleu_3": 0.15360570823926997, "Bleu_4": 0.09696378326119115, "METEOR": 0.29482744085066315, "ROUGE_L": 0.285427807486631, "CIDEr": 7.383279553162837e-07, "SPICE": {"All": {"pr": 0.36, "re": 0.32142857142857145, "f": 0.33962264150943394, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 9.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.6, "f": 0.5217391304347826, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The man in the image is sitting at a desk with a laptop in front of him. He is holding a glass of wine and looking at the screen. The room is dimly lit and there are some books on the shelf behind him."}, "484614": {"image_id": 484614, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.1234482786556696, "Bleu_3": 6.685490874553478e-07, "Bleu_4": 1.563534520202163e-09, "METEOR": 0.21358389728587426, "ROUGE_L": 0.21266705403834982, "CIDEr": 4.707922939861188e-12, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.10526315789473684, "f": 0.0975609756097561, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a man standing on the beach holding a surfboard. He is wearing black shorts and a white shirt, and his hair is tied back in a ponytail. The background is a rocky beach with trees and bushes growing along the shore. There are several surfboards lying on the sand nearby."}, "384242": {"image_id": 384242, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.16195526603310612, "Bleu_3": 0.07632135028174301, "Bleu_4": 9.35680407190854e-06, "METEOR": 0.2287626172236829, "ROUGE_L": 0.22228006246746487, "CIDEr": 1.2594667481938224e-15, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.038461538461538464, "f": 0.0425531914893617, "fn": 25.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a person standing on a surfboard in the ocean, with a windsurfer in the background. The person is wearing a wetsuit and holding onto the board as they paddle through the water. The sky is clear and blue, with some clouds in the distance. The beach is sandy and there are some palm trees visible in the background."}, "393971": {"image_id": 393971, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.29417420269982747, "Bleu_3": 0.16576208078090784, "Bleu_4": 1.873110771279216e-05, "METEOR": 0.2907554464483721, "ROUGE_L": 0.3043044469783352, "CIDEr": 2.617417090474377e-05, "SPICE": {"All": {"pr": 0.09523809523809523, "re": 0.08, "f": 0.08695652173913043, "fn": 23.0, "numImages": 1.0, "fp": 19.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "A cat is sitting on a desk in front of a laptop computer. The laptop has an image of a person on the screen. There are several other objects on the desk, including a cup of coffee and a pen."}, "418623": {"image_id": 418623, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.19611613513078086, "Bleu_3": 0.11544156732198758, "Bleu_4": 1.591178311035633e-05, "METEOR": 0.17519029533763267, "ROUGE_L": 0.34173669467787116, "CIDEr": 0.01550919461466567, "SPICE": {"All": {"pr": 0.4444444444444444, "re": 0.2857142857142857, "f": 0.34782608695652173, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5, "f": 0.5454545454545454, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a room with a bed, a desk, and a bookshelf. There are several suitcases on the floor and a guitar hanging on the wall."}, "161635": {"image_id": 161635, "Bleu_1": 0.22857142856816326, "Bleu_2": 0.18200630207469712, "Bleu_3": 0.11348237021191852, "Bleu_4": 0.06834041280576725, "METEOR": 0.21552409596335761, "ROUGE_L": 0.20236966824644548, "CIDEr": 1.4679113609940713e-22, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.10344827586206896, "f": 0.12000000000000001, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "This is an image of a surfer riding a wave on a surfboard in the ocean. The surfer is wearing a wetsuit and standing on the board, with his arms outstretched to balance himself. The wave is large and white, with a lot of foam on top. There are other surfers in the background, also riding waves. The sky is blue and cloudy, with some clouds visible in the distance."}, "308194": {"image_id": 308194, "Bleu_1": 0.423240862374767, "Bleu_2": 0.3609410201956994, "Bleu_3": 0.28044004082583596, "Bleu_4": 3.795104906811203e-05, "METEOR": 0.4043557340594044, "ROUGE_L": 0.44202898550724634, "CIDEr": 0.9837863981078756, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2222222222222222, "f": 0.21621621621621623, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "A couple walks through a park holding umbrellas on a sunny day."}, "449338": {"image_id": 449338, "Bleu_1": 0.5833333332847223, "Bleu_2": 0.32566947361109216, "Bleu_3": 2.1971078112918733e-06, "Bleu_4": 5.859059369587253e-09, "METEOR": 0.3205009345182055, "ROUGE_L": 0.5187074829931972, "CIDEr": 0.9749783982674984, "SPICE": {"All": {"pr": 0.07407407407407407, "re": 0.06896551724137931, "f": 0.07142857142857142, "fn": 27.0, "numImages": 1.0, "fp": 25.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.18181818181818182, "f": 0.17391304347826086, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "A pair of ducks swimming in a body of water at sunset."}, "56592": {"image_id": 56592, "Bleu_1": 0.382352941165225, "Bleu_2": 0.28478969316957436, "Bleu_3": 0.13634300208924155, "Bleu_4": 1.690963431814651e-05, "METEOR": 0.24567793858443376, "ROUGE_L": 0.3024793388429752, "CIDEr": 0.00022213034096192657, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.5, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 28.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.8, "f": 0.38095238095238093, "fn": 1.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The image shows a man holding a tennis racket and preparing to hit the ball. He is wearing a white shirt and black shorts, and his hair is cut short. The background is black."}, "506945": {"image_id": 506945, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.36037498506145293, "Bleu_3": 0.29615092273975135, "Bleu_4": 0.2530618805525521, "METEOR": 0.4314343094876418, "ROUGE_L": 0.5583524027459954, "CIDEr": 0.25496509034047116, "SPICE": {"All": {"pr": 0.125, "re": 0.13043478260869565, "f": 0.1276595744680851, "fn": 20.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man holding a cell phone in his hand, looking at it with a serious expression on his face."}, "364745": {"image_id": 364745, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.15939996379066856, "Bleu_3": 0.12197836292293229, "Bleu_4": 0.09974743613527262, "METEOR": 0.20876999675688926, "ROUGE_L": 0.28357438016528924, "CIDEr": 1.7023861524798541e-12, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.125, "f": 0.11320754716981132, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "The image shows a man sitting on a couch with his two children. The man is holding one of the children in his lap while the other child is sitting next to him. They are all smiling and looking at something off camera. The room appears to be a living room with a large window in the background."}, "311846": {"image_id": 311846, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.2896048475706757, "Bleu_3": 0.17950692908366503, "Bleu_4": 2.131922460868855e-05, "METEOR": 0.28437242574551197, "ROUGE_L": 0.36464560204953034, "CIDEr": 0.0070209268724399235, "SPICE": {"All": {"pr": 0.037037037037037035, "re": 0.043478260869565216, "f": 0.039999999999999994, "fn": 22.0, "numImages": 1.0, "fp": 26.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.1111111111111111, "f": 0.09523809523809525, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "The image shows a table with three cakes on it. The cakes are decorated with flowers and other decorations. There are also several other tables nearby with more cakes on them."}, "124766": {"image_id": 124766, "Bleu_1": 0.3541666666592882, "Bleu_2": 0.27450794146236435, "Bleu_3": 0.21420737289180708, "Bleu_4": 0.1719244646066003, "METEOR": 0.26298387706097115, "ROUGE_L": 0.39377934272300463, "CIDEr": 1.9214473703438896e-07, "SPICE": {"All": {"pr": 0.375, "re": 0.14285714285714285, "f": 0.20689655172413796, "fn": 18.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This is a man wearing a blue shirt and a black hat. He is sitting in the driver's seat of a car with his hands on the steering wheel. The car is parked in front of a building with a sign that reads \"Welcome to the city\"."}, "466921": {"image_id": 466921, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.16817499303272468, "Bleu_3": 8.696639352820399e-07, "Bleu_4": 1.98930453496201e-09, "METEOR": 0.19546660842609362, "ROUGE_L": 0.21048999309868874, "CIDEr": 3.646356261520949e-08, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21052631578947367, "f": 0.186046511627907, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a narrow street with buildings on either side. There are several bicycles parked along the sidewalk, and a few people can be seen walking down the street. The sky is clear and there are some tall buildings in the background."}, "163138": {"image_id": 163138, "Bleu_1": 0.22666666666364443, "Bleu_2": 0.12375506177487912, "Bleu_3": 5.942023442036288e-07, "Bleu_4": 1.306524766111911e-09, "METEOR": 0.16570265352685642, "ROUGE_L": 0.18802289740202555, "CIDEr": 4.8249956400236846e-26, "SPICE": {"All": {"pr": 0.25, "re": 0.13636363636363635, "f": 0.1764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This is a display case filled with various ceramic vases and other decorative items. The vases are arranged on shelves in front of the glass case, and they appear to be made of different colors and designs. Some of the vases have floral patterns, while others have more abstract designs. The display case itself appears to be made of wood or metal, and it has a clear glass front that allows you to see inside."}, "482436": {"image_id": 482436, "Bleu_1": 0.25423728813128416, "Bleu_2": 0.16217400875780294, "Bleu_3": 0.07727325671842705, "Bleu_4": 9.527411106747781e-06, "METEOR": 0.19938793127328383, "ROUGE_L": 0.20344635908838243, "CIDEr": 4.565368728184688e-13, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 24.0, "numImages": 1.0, "fp": 32.0, "tp": 4.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.125, "f": 0.09090909090909091, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.17647058823529413, "re": 0.3333333333333333, "f": 0.23076923076923078, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}}, "caption": "This image shows a man standing in front of a window at night. He is wearing a black shirt and pants, and has a cigarette in his hand. There are other people in the background, but they are not visible because they are behind him. The window is open, and there is a streetlight outside that illuminates the scene."}, "469424": {"image_id": 469424, "Bleu_1": 0.18421052631336565, "Bleu_2": 0.14017532880823577, "Bleu_3": 0.09269953749388958, "Bleu_4": 0.05747479891064196, "METEOR": 0.2035022881421207, "ROUGE_L": 0.1919964028776978, "CIDEr": 7.085576947410188e-27, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.21428571428571427, "f": 0.1875, "fn": 22.0, "numImages": 1.0, "fp": 30.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3125, "re": 0.45454545454545453, "f": 0.3703703703703703, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}}, "caption": "The image shows a orange tabby cat sitting on top of a bench in front of some bushes. The cat is looking up at the camera with its eyes closed, as if it is sleeping. The bench is made of metal and has a smooth surface. The bushes are tall and green, with leaves and branches that are swaying in the breeze. There is a small puddle of water on the ground next to the bench."}, "547744": {"image_id": 547744, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.19278507708010587, "Bleu_3": 0.12294351069421963, "Bleu_4": 1.4774508969778744e-05, "METEOR": 0.25153862345259614, "ROUGE_L": 0.2543786488740617, "CIDEr": 5.50648771721231e-07, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.22727272727272727, "f": 0.25641025641025644, "fn": 17.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a purple and white bus driving down the street. There are buildings on either side of the road, with trees and plants in the foreground. The sky is clear and blue, with a few clouds visible in the distance."}, "268941": {"image_id": 268941, "Bleu_1": 0.35087719297630043, "Bleu_2": 0.19389168357893838, "Bleu_3": 0.12704540914145687, "Bleu_4": 1.3959529865204303e-05, "METEOR": 0.2433301216627643, "ROUGE_L": 0.2136602451838879, "CIDEr": 7.198111804140268e-14, "SPICE": {"All": {"pr": 0.1, "re": 0.15384615384615385, "f": 0.12121212121212123, "fn": 22.0, "numImages": 1.0, "fp": 36.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.125, "f": 0.1, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is an image of a large white yacht docked at a marina in a small town. The yacht has several decks and a large cabin on the top deck. There are people standing on the dock and on the yacht, looking out at the water. The town in the background appears to be surrounded by mountains."}, "388085": {"image_id": 388085, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.21931085605462405, "Bleu_3": 0.15089125644562476, "Bleu_4": 0.09567579772168915, "METEOR": 0.2628013846236742, "ROUGE_L": 0.25702247191011235, "CIDEr": 4.0070439894119064e-08, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.19230769230769232, "f": 0.2439024390243902, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.5, "f": 0.6153846153846154, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "A group of people are walking down the street on a rainy day. They are carrying umbrellas and wearing raincoats. The buildings on either side of the street are tall and white, with windows and balconies. There is a traffic light at the intersection."}, "359149": {"image_id": 359149, "Bleu_1": 0.3999999999200002, "Bleu_2": 0.2981423969386873, "Bleu_3": 2.2314431664674195e-06, "Bleu_4": 6.311969076838887e-09, "METEOR": 0.21202398483714188, "ROUGE_L": 0.42508710801393734, "CIDEr": 0.460407138462266, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.1111111111111111, "f": 0.12903225806451615, "fn": 32.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3076923076923077, "f": 0.32, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "Two people walking under an umbrella on a rainy day."}, "567308": {"image_id": 567308, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.25503068521918915, "Bleu_3": 0.11759123766324174, "Bleu_4": 1.4289435395907194e-05, "METEOR": 0.25778586038275336, "ROUGE_L": 0.2952973720608575, "CIDEr": 1.6623750252529803e-06, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 14.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.8, "f": 0.5000000000000001, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man playing tennis on a green court with a net in the background. He is wearing a yellow shirt and white shorts, and has a racket in his hand. There are several people watching him from the sidelines."}, "304657": {"image_id": 304657, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.11314714295768938, "Bleu_3": 7.084810326519695e-07, "Bleu_4": 1.7853738103300445e-09, "METEOR": 0.1369780567030132, "ROUGE_L": 0.22659732540861813, "CIDEr": 7.877954124136379e-06, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.10714285714285714, "f": 0.14634146341463414, "fn": 25.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.25, "f": 0.3157894736842105, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a large, modern hotel with several floors and balconies. There are several lounge chairs on the balcony, and a swimming pool in the background. The building is surrounded by greenery and has a white roof."}, "269280": {"image_id": 269280, "Bleu_1": 0.24999999999305564, "Bleu_2": 0.1195228609300719, "Bleu_3": 7.489871169676584e-07, "Bleu_4": 1.8889796346301667e-09, "METEOR": 0.1809253219452407, "ROUGE_L": 0.2824074074074074, "CIDEr": 7.557462396629849e-05, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.5, "f": 0.42857142857142855, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The man is sitting on a bench, wearing a white shirt and black pants. He has a hat on his head and is holding a pen in his hand. There are plants and flowers around him."}, "245026": {"image_id": 245026, "Bleu_1": 0.18181818181542703, "Bleu_2": 0.10577717706797403, "Bleu_3": 5.591581470772566e-07, "Bleu_4": 1.2906719016703225e-09, "METEOR": 0.19743693785278954, "ROUGE_L": 0.1888544891640867, "CIDEr": 2.6970703385290493e-20, "SPICE": {"All": {"pr": 0.32142857142857145, "re": 0.32142857142857145, "f": 0.32142857142857145, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 9.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.875, "f": 0.6363636363636364, "fn": 1.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The image shows a woman standing in front of a table with a cake on it. The cake has the words \"Happy Birthday\" written on it in white frosting. The woman is smiling and holding a fork in her hand. There are several other items on the table, including plates, cups, and utensils. The background of the image appears to be a kitchen or dining room."}, "409725": {"image_id": 409725, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.17107978454943554, "Bleu_3": 0.11449528240744467, "Bleu_4": 0.07927655972962615, "METEOR": 0.23663427736649773, "ROUGE_L": 0.26703633445206476, "CIDEr": 7.97858654337939e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.23809523809523808, "f": 0.21739130434782608, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a group of people standing on a bridge over a river, holding kites. The sky is clear and blue, with some clouds in the distance. There are tall buildings in the background, with people walking on the sidewalk."}, "448555": {"image_id": 448555, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 9.166878867586852e-07, "Bleu_4": 2.1980503399202124e-09, "METEOR": 0.24997433135985586, "ROUGE_L": 0.2420634920634921, "CIDEr": 6.313551646903296e-05, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a kitchen with stainless steel appliances and white countertops. The refrigerator, stove, and dishwasher are all stainless steel. There is a microwave on the wall above the stove. The floor is made of hardwood."}, "512938": {"image_id": 512938, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.24671758189216153, "Bleu_3": 0.16070260840132272, "Bleu_4": 0.0991174409108344, "METEOR": 0.282384368335655, "ROUGE_L": 0.2827814569536423, "CIDEr": 0.0021590940235573525, "SPICE": {"All": {"pr": 0.21875, "re": 0.3181818181818182, "f": 0.25925925925925924, "fn": 15.0, "numImages": 1.0, "fp": 25.0, "tp": 7.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.2, "f": 0.17391304347826086, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.5, "f": 0.41666666666666663, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "This is a picture of a sheep and its lamb standing in a field. The sheep has a thick, fluffy coat and the lamb is suckling on its mother's teats. The grass in the background is green and there are some trees in the distance."}, "124983": {"image_id": 124983, "Bleu_1": 0.27999999999440006, "Bleu_2": 0.13093073413895012, "Bleu_3": 7.094917059707092e-07, "Bleu_4": 1.660297934705131e-09, "METEOR": 0.20421954813848564, "ROUGE_L": 0.1813317479191439, "CIDEr": 6.0794174740372e-10, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2631578947368421, "f": 0.18518518518518517, "fn": 14.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5714285714285714, "f": 0.38095238095238093, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a street sign with the words \"fouth and twenty-second\" written on it. The sign is attached to a pole in the middle of the street, and there are buildings and trees visible in the background. The sky is clear and blue, with some clouds in the distance."}, "74789": {"image_id": 74789, "Bleu_1": 0.23809523808956923, "Bleu_2": 0.10777013434966339, "Bleu_3": 6.621844108848321e-07, "Bleu_4": 1.6518403195302827e-09, "METEOR": 0.16859379903936947, "ROUGE_L": 0.17758369723435224, "CIDEr": 7.661017084158012e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.16, "f": 0.1702127659574468, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a train station with tracks leading up to it. There are several cars parked on the platform, and people can be seen walking around the area. The sky is cloudy and there are trees in the background."}, "519758": {"image_id": 519758, "Bleu_1": 0.30769230768441824, "Bleu_2": 0.26995276239249566, "Bleu_3": 0.2277762084194072, "Bleu_4": 0.20127885137900514, "METEOR": 0.3512011864085976, "ROUGE_L": 0.4080917489646385, "CIDEr": 3.776599957888017e-05, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.13636363636363635, "f": 0.15384615384615383, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a tall clock tower with a white face and black hands. The clock is mounted on top of a brick building with a red roof. The sky is blue and there are clouds in the background."}, "442306": {"image_id": 442306, "Bleu_1": 0.4999999999895834, "Bleu_2": 0.3994677309600699, "Bleu_3": 0.25885617292270746, "Bleu_4": 0.14011697930921418, "METEOR": 0.35998644804025853, "ROUGE_L": 0.4475169300225733, "CIDEr": 3.4535956539878256e-06, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.25, "f": 0.24242424242424243, "fn": 12.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a young girl standing on a rock in the middle of a forest, holding an umbrella. She is wearing rain boots and a raincoat with a hood. The umbrella is open and the girl is smiling. The background is made up of trees and foliage."}, "565582": {"image_id": 565582, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.23186944787247984, "Bleu_3": 0.177175406364313, "Bleu_4": 0.14117915208501983, "METEOR": 0.23082385036258443, "ROUGE_L": 0.3266107442441549, "CIDEr": 0.0021282086285677906, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.24, "f": 0.2264150943396226, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a living room with a blue couch, a pink armchair, and a wooden coffee table. There are also two lamps on the table and a fireplace in the background."}, "485916": {"image_id": 485916, "Bleu_1": 0.6249999999739584, "Bleu_2": 0.46625240410030744, "Bleu_3": 0.30949020883935, "Bleu_4": 0.23050898625539615, "METEOR": 0.31238661969876436, "ROUGE_L": 0.4518518518518518, "CIDEr": 0.11100571551372004, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.42857142857142855, "f": 0.15789473684210525, "fn": 4.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.3333333333333333, "f": 0.18181818181818182, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.15384615384615385, "re": 0.6666666666666666, "f": 0.25, "fn": 1.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is a bathroom with a sink, toilet, and mirror. The walls are painted white and there is a red rug on the floor."}, "345434": {"image_id": 345434, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.21438189279304845, "Bleu_3": 0.14746071444525918, "Bleu_4": 0.09347488245300105, "METEOR": 0.19684245112002124, "ROUGE_L": 0.3134232498394348, "CIDEr": 4.3557556672757417e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 15.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A group of people are sitting on the grassy bank of a river, looking out at the water. There is a large boat in the distance, and several trees along the shore. The sky is clear and blue, with a few clouds scattered across it."}, "495612": {"image_id": 495612, "Bleu_1": 0.5517241379120095, "Bleu_2": 0.3713906763410685, "Bleu_3": 0.27339217086735623, "Bleu_4": 0.16743498907547102, "METEOR": 0.33993332648338576, "ROUGE_L": 0.5113160100586757, "CIDEr": 0.014775128058074925, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"Walking Man\" written on it. The sign is attached to a utility pole and there are buildings in the background."}, "17953": {"image_id": 17953, "Bleu_1": 0.24999999999431824, "Bleu_2": 0.0762492851645493, "Bleu_3": 5.172979462771284e-07, "Bleu_4": 1.3555314602468016e-09, "METEOR": 0.1607927814995781, "ROUGE_L": 0.214185393258427, "CIDEr": 6.9755609811495925e-09, "SPICE": {"All": {"pr": 0.2, "re": 0.21739130434782608, "f": 0.20833333333333331, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a kitchen with various food items on the countertop. There are several pots and pans on the stove, as well as a blender and other kitchen appliances. The image appears to be taken in a home or apartment kitchen."}, "464857": {"image_id": 464857, "Bleu_1": 0.339622641503026, "Bleu_2": 0.2555622163811263, "Bleu_3": 0.21718893759224345, "Bleu_4": 0.18725075919606604, "METEOR": 0.26148717421798906, "ROUGE_L": 0.33351558228540185, "CIDEr": 3.237927433051116e-10, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.09090909090909091, "f": 0.0784313725490196, "fn": 20.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a group of people in a room, with some sitting at tables and others standing around. There is a man in a suit and tie standing in the center of the room, holding a glass of wine. The room appears to be dimly lit, with only a few lights on."}, "20395": {"image_id": 20395, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.14695129936263138, "Bleu_3": 0.08075839294554585, "Bleu_4": 1.0712127994780991e-05, "METEOR": 0.21910268583654258, "ROUGE_L": 0.2576376179079263, "CIDEr": 3.202350904167559e-07, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.10526315789473684, "f": 0.10810810810810811, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a harbor at night with many boats docked in the water. The sky is full of stars and the moon is visible in the background. There are buildings and trees in the background, and the water is calm and peaceful."}, "115924": {"image_id": 115924, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.23783535599888, "Bleu_3": 0.1580284245644431, "Bleu_4": 1.750810269276388e-05, "METEOR": 0.235444298613429, "ROUGE_L": 0.25902335456475584, "CIDEr": 3.2395911096697264e-08, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.11538461538461539, "f": 0.13333333333333333, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a surfer riding a wave on a surfboard. The surfer is wearing a yellow shirt and has his arms outstretched as he jumps off the wave. The wave is large and white, with foam on top. The sky is blue and cloudy."}, "437497": {"image_id": 437497, "Bleu_1": 0.25333333332995556, "Bleu_2": 0.14331971441497185, "Bleu_3": 0.06552841590254674, "Bleu_4": 7.906588344673861e-06, "METEOR": 0.1966598091559338, "ROUGE_L": 0.163758389261745, "CIDEr": 1.9081470311478404e-26, "SPICE": {"All": {"pr": 0.13513513513513514, "re": 0.25, "f": 0.1754385964912281, "fn": 15.0, "numImages": 1.0, "fp": 32.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is an image of a young boy playing baseball. He is wearing a green and white jersey with the number 23 on the back, and red and black cleats. He is holding a bat and running towards home plate to hit the ball. There are other players on the field, including one who is catching the ball and another who is pitching it. The sky is cloudy and there are trees in the background."}, "403104": {"image_id": 403104, "Bleu_1": 0.4242424242295685, "Bleu_2": 0.282038037400203, "Bleu_3": 0.13690455291617346, "Bleu_4": 1.710145668798399e-05, "METEOR": 0.18392958632654785, "ROUGE_L": 0.25738396624472576, "CIDEr": 0.000584835292955085, "SPICE": {"All": {"pr": 0.28, "re": 0.21212121212121213, "f": 0.2413793103448276, "fn": 26.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.4666666666666667, "f": 0.5384615384615385, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "This is an image of a street with a sign that reads \"Roman Avenue\" and a house in the background. The house has been damaged by a tornado, with debris scattered around it."}, "184139": {"image_id": 184139, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.35823642098878333, "Bleu_3": 0.28155108805655055, "Bleu_4": 0.23487811399113218, "METEOR": 0.36619615284795815, "ROUGE_L": 0.5142255005268704, "CIDEr": 0.07457562847113706, "SPICE": {"All": {"pr": 0.25, "re": 0.2777777777777778, "f": 0.2631578947368421, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.5, "f": 0.5555555555555556, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is a bedroom with a large bed, a desk, and a chair. The walls are painted green and there are curtains on the windows."}, "281179": {"image_id": 281179, "Bleu_1": 0.1971830985887721, "Bleu_2": 0.13000541700338772, "Bleu_3": 0.09023984771946048, "Bleu_4": 0.05733522711237291, "METEOR": 0.20134954363272914, "ROUGE_L": 0.19037004012483277, "CIDEr": 9.501079881841263e-22, "SPICE": {"All": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a nighttime image of a city street with a Christmas tree in the foreground. The street is empty and there are no cars or people visible. The tree is decorated with lights and ornaments, and its branches stretch up towards the sky. The buildings on either side of the street are dark and have no windows or signs visible. The sky is cloudy and there are no stars visible."}, "470350": {"image_id": 470350, "Bleu_1": 0.3809523809433107, "Bleu_2": 0.21554026869932671, "Bleu_3": 1.0511522304355248e-06, "Bleu_4": 2.3360549827544327e-09, "METEOR": 0.22553613004222395, "ROUGE_L": 0.33614988978692134, "CIDEr": 3.0262688818431028e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.3157894736842105, "f": 0.3870967741935484, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.5555555555555556, "f": 0.7142857142857143, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a black shirt and shorts, and has a racket in his hand. The court is made of blue and white tiles, and there are spectators seated in the stands."}, "162902": {"image_id": 162902, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.3450327796551204, "Bleu_3": 0.26137897927488973, "Bleu_4": 0.20821983208129713, "METEOR": 0.3053596012928108, "ROUGE_L": 0.4692307692307692, "CIDEr": 0.15540244062528233, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.12, "f": 0.13043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.18181818181818182, "f": 0.19999999999999998, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people standing on a snowy slope with skis and snowboards\""}, "425727": {"image_id": 425727, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.23260756692519305, "Bleu_3": 0.10713507226754851, "Bleu_4": 1.300413999698558e-05, "METEOR": 0.26879938234197515, "ROUGE_L": 0.28968792401628224, "CIDEr": 5.619544556082877e-08, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4, "f": 0.380952380952381, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a person flying a kite in a park on a sunny day. The person is standing on the grass and holding the kite with both hands, while the kite flies high in the sky. There are trees and buildings visible in the background."}, "347506": {"image_id": 347506, "Bleu_1": 0.31818181817699726, "Bleu_2": 0.2617851571983711, "Bleu_3": 0.18590330248105646, "Bleu_4": 0.13225451431423244, "METEOR": 0.24312739841590134, "ROUGE_L": 0.26565740356698464, "CIDEr": 2.6175808295934002e-18, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.3, "f": 0.25531914893617025, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.14285714285714285, "f": 0.10526315789473685, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people standing in front of a bus stop on a sidewalk. The bus is parked at the curb, and there are several people waiting to board it. The building behind them appears to be a university or college campus, with tall trees and a large stone facade. The sky is clear and blue, with a few clouds scattered across it."}, "48133": {"image_id": 48133, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.16968474448956103, "Bleu_3": 0.11198948449446593, "Bleu_4": 1.3688880628137528e-05, "METEOR": 0.19353473017419165, "ROUGE_L": 0.25505226480836235, "CIDEr": 3.322928114953634e-06, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.05, "f": 0.041666666666666664, "fn": 19.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.16666666666666666, "f": 0.10526315789473684, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "This is an image of a ski resort with a large mountain in the background. There are several people on skis and snowboards on the slopes, and a chairlift in the foreground. The sky is cloudy and there is snow on the ground."}, "373486": {"image_id": 373486, "Bleu_1": 0.14516129032023936, "Bleu_2": 0.04878210003576457, "Bleu_3": 3.4102790061610655e-07, "Bleu_4": 9.054811853820702e-10, "METEOR": 0.09264967394042996, "ROUGE_L": 0.13275299238302501, "CIDEr": 1.192264380859789e-18, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.19047619047619047, "f": 0.14545454545454542, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.16666666666666666, "f": 0.15384615384615383, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This image shows a skateboarder jumping over a set of stairs. The skateboarder is wearing a purple shirt and black pants, and has his arms extended to the side as he jumps. The stairs are made of concrete and have a smooth surface. There is a large window on the wall behind the stairs, which allows natural light to enter the space."}, "279388": {"image_id": 279388, "Bleu_1": 0.32432432431555885, "Bleu_2": 0.189831599145298, "Bleu_3": 1.0097712220824676e-06, "Bleu_4": 2.3458352758968296e-09, "METEOR": 0.2315252316967738, "ROUGE_L": 0.3017312448474856, "CIDEr": 8.076301215181539e-05, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.08333333333333333, "f": 0.08333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a giraffe eating leaves from a tree. The giraffe has a long neck and spotted fur, and its eyes are looking up towards the sky. The background is a blue sky with some clouds."}, "90374": {"image_id": 90374, "Bleu_1": 0.4634146341350387, "Bleu_2": 0.2847763349922257, "Bleu_3": 0.18408630482539004, "Bleu_4": 2.012890781837401e-05, "METEOR": 0.27806705083317446, "ROUGE_L": 0.27875095201827876, "CIDEr": 2.124148316268122e-06, "SPICE": {"All": {"pr": 0.24, "re": 0.2, "f": 0.2181818181818182, "fn": 24.0, "numImages": 1.0, "fp": 19.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.38461538461538464, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a woman in black and white tennis outfit playing tennis on a court. She is holding a tennis racket and swinging it to hit the ball. The background is a green grass field with trees in the distance."}, "519491": {"image_id": 519491, "Bleu_1": 0.4838709677263268, "Bleu_2": 0.33601075250510387, "Bleu_3": 0.26900444252673095, "Bleu_4": 0.22963869978186033, "METEOR": 0.38650432795603146, "ROUGE_L": 0.48370044052863437, "CIDEr": 0.02596332586011038, "SPICE": {"All": {"pr": 0.047619047619047616, "re": 0.05555555555555555, "f": 0.05128205128205128, "fn": 17.0, "numImages": 1.0, "fp": 20.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a large clock tower with a statue of an angel on top. The clock has four faces and is surrounded by buildings. The sky is clear and blue."}, "460972": {"image_id": 460972, "Bleu_1": 0.5714285713877553, "Bleu_2": 0.46880723090372134, "Bleu_3": 0.3321078320482429, "Bleu_4": 4.2718025132374636e-05, "METEOR": 0.25440373202518574, "ROUGE_L": 0.5545454545454546, "CIDEr": 0.8509833910107036, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1875, "f": 0.17647058823529413, "fn": 13.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A group of ducks swimming in a pond surrounded by tall grass and trees."}, "32901": {"image_id": 32901, "Bleu_1": 0.11711711711606201, "Bleu_2": 0.06525951469883282, "Bleu_3": 0.04275271756961367, "Bleu_4": 5.186410113591698e-06, "METEOR": 0.1394523752633898, "ROUGE_L": 0.13620414673046252, "CIDEr": 2.240636588075894e-62, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.3157894736842105, "f": 0.2926829268292683, "fn": 13.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.6, "f": 0.37499999999999994, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Here are the captions for the image:\n\n1. A group of men in suits and ties standing in a room with tables and chairs.\n2. A group of men in suits and ties standing in a room with tables and chairs, looking at something on a table.\n3. A group of men in suits and ties standing in a room with tables and chairs, talking to each other.\n4. A group of men in suits and ties standing in a room with tables and chairs, smiling and laughing.\n5. A group of men in suits and ties standing in a room with tables and chairs, looking at something on a table."}, "9395": {"image_id": 9395, "Bleu_1": 0.18840579709871877, "Bleu_2": 0.15791156189572084, "Bleu_3": 0.10374283298561139, "Bleu_4": 0.06413315327749546, "METEOR": 0.23958615120582916, "ROUGE_L": 0.21212121212121215, "CIDEr": 1.122344905147278e-21, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a baseball player pitching a ball on a green field. The player is wearing a white jersey with the number 24 on the back and a black cap with the letters \"SF\" on it. The ball is flying through the air as the player throws it. In the background, there are spectators sitting in the stands and a large scoreboard with the score displayed on it."}, "16606": {"image_id": 16606, "Bleu_1": 0.49999999998437505, "Bleu_2": 0.4751909632964023, "Bleu_3": 0.374890449867467, "Bleu_4": 0.27171217383965246, "METEOR": 0.35347648690105055, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.004644663307429801, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2692307692307692, "f": 0.2978723404255319, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.36363636363636365, "f": 0.36363636363636365, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image is a book with a mouse on top of it. The book has a picture of a tree on the cover and the mouse is sitting on top of it."}, "478586": {"image_id": 478586, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.27174648818404223, "Bleu_3": 0.1454472607016038, "Bleu_4": 1.9124813148101802e-05, "METEOR": 0.28537480665362336, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.030148730205103023, "SPICE": {"All": {"pr": 0.2, "re": 0.13043478260869565, "f": 0.15789473684210528, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A white swan is standing in the water next to a black cat. The cat is looking at the swan, while the swan is looking away."}, "190664": {"image_id": 190664, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.2431867285489846, "Bleu_3": 0.18289464893778182, "Bleu_4": 0.12157974875829161, "METEOR": 0.29869387299606187, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.0028253099038464376, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.18181818181818182, "f": 0.17777777777777776, "fn": 18.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a fire hydrant on the sidewalk. It is made of metal and has a large handle on top. There are no other objects in the image."}, "255479": {"image_id": 255479, "Bleu_1": 0.22033898304711294, "Bleu_2": 0.08716591057868225, "Bleu_3": 0.05108258061208208, "Bleu_4": 6.984858539537387e-06, "METEOR": 0.14132162068501145, "ROUGE_L": 0.13840045377197957, "CIDEr": 4.028050271080415e-15, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 6.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person standing on the beach holding a surfboard. The person is wearing a black wetsuit and has their hair tied back in a ponytail. The sky is clear and blue, with a few clouds scattered across it. The waves are crashing against the shore, and there are people in the distance walking along the beach."}, "68852": {"image_id": 68852, "Bleu_1": 0.255813953482423, "Bleu_2": 0.17451086522195614, "Bleu_3": 0.1141029906527568, "Bleu_4": 0.07806525322093243, "METEOR": 0.2605830692271044, "ROUGE_L": 0.31946132984195263, "CIDEr": 2.6475148091106364e-06, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.12, "f": 0.09999999999999999, "fn": 22.0, "numImages": 1.0, "fp": 32.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.375, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a blue car parked on the side of the road with surfboards on top of it. There are people standing in front of the car, looking at it. The sky is cloudy and there are palm trees in the background."}, "438432": {"image_id": 438432, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.17614871215260033, "Bleu_3": 0.1264855137960998, "Bleu_4": 0.09738340653916804, "METEOR": 0.3034346370130784, "ROUGE_L": 0.3028368794326241, "CIDEr": 5.144539956264148e-09, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 12.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.25, "f": 0.15384615384615383, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a photograph of a group of young women in white shirts and black skirts, sitting on the ground with their legs crossed. They are all wearing sneakers and have their hands on their knees. The background is a grassy field with some trees in the distance."}, "581632": {"image_id": 581632, "Bleu_1": 0.5769230769008876, "Bleu_2": 0.3038218101131809, "Bleu_3": 0.19740230336695266, "Bleu_4": 0.1352328506594843, "METEOR": 0.2942074724763883, "ROUGE_L": 0.38193202146690514, "CIDEr": 0.08546309118519435, "SPICE": {"All": {"pr": 0.32, "re": 0.2857142857142857, "f": 0.30188679245283023, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of people standing in front of a bar with a clock hanging on the wall.\""}, "121849": {"image_id": 121849, "Bleu_1": 0.2608695652136106, "Bleu_2": 0.17518714873957753, "Bleu_3": 0.13181552491326118, "Bleu_4": 0.09127386425128811, "METEOR": 0.22017091706459505, "ROUGE_L": 0.2047961630695444, "CIDEr": 1.5188207588509776e-21, "SPICE": {"All": {"pr": 0.7142857142857143, "re": 0.22727272727272727, "f": 0.3448275862068965, "fn": 17.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "The image shows a young boy sitting on the toilet in a bathroom. He is wearing a gray shirt and blue jeans, and has his hands on his hips as he looks up at the camera. The toilet seat is covered in water, and there is a towel on the floor next to it. The walls are white, and there is a window in the background with blinds closed."}, "391375": {"image_id": 391375, "Bleu_1": 0.2888888888824692, "Bleu_2": 0.22918388364562542, "Bleu_3": 0.20448709776883991, "Bleu_4": 0.18694976490600204, "METEOR": 0.28750525514015157, "ROUGE_L": 0.3588235294117647, "CIDEr": 1.9630934184535234e-07, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a woman sitting on a bench in front of an old stone archway. She is wearing a black coat and has her hands folded in her lap. The archway is covered in moss and vines, giving it a mysterious and ancient appearance."}, "337160": {"image_id": 337160, "Bleu_1": 0.3728813559258834, "Bleu_2": 0.1133930235522716, "Bleu_3": 6.087410726083202e-07, "Bleu_4": 1.4166985426338212e-09, "METEOR": 0.19498303460368155, "ROUGE_L": 0.2531683094938116, "CIDEr": 2.571152771935095e-10, "SPICE": {"All": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.4, "f": 0.5714285714285715, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}}, "caption": "The image shows a baseball player in the middle of a game, holding a bat and running towards home plate. There are several people in the stands watching the game, including some with their arms raised in excitement. The field is green and there are white lines drawn on it to mark the bases and the pitcher's mound."}, "376773": {"image_id": 376773, "Bleu_1": 0.30434782607372407, "Bleu_2": 0.20372033840756823, "Bleu_3": 0.12549213105395926, "Bleu_4": 1.7729842263868143e-05, "METEOR": 0.131372869834205, "ROUGE_L": 0.2423038728897716, "CIDEr": 0.016867756425638324, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.14285714285714285, "f": 0.15, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of children playing tennis on a sunny day at an outdoor court.\""}, "93435": {"image_id": 93435, "Bleu_1": 0.7999999998400004, "Bleu_2": 0.6666666665296299, "Bleu_3": 0.5503212080324162, "Bleu_4": 0.3928146508141954, "METEOR": 0.3033502192537088, "ROUGE_L": 0.6609907120743034, "CIDEr": 1.2650888015420128, "SPICE": {"All": {"pr": 0.2, "re": 0.17391304347826086, "f": 0.18604651162790697, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "Two men sitting at a table outside, enjoying their meals."}, "215579": {"image_id": 215579, "Bleu_1": 0.8571428570816327, "Bleu_2": 0.7262730391486911, "Bleu_3": 0.6034799806556997, "Bleu_4": 0.37596635291638075, "METEOR": 0.3054431913360709, "ROUGE_L": 0.49061662198391426, "CIDEr": 1.3248714198361977, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.23076923076923078, "f": 0.17647058823529413, "fn": 10.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "A cat is sitting on top of a television set, looking at the screen."}, "350851": {"image_id": 350851, "Bleu_1": 0.5199999999792001, "Bleu_2": 0.36055512753167634, "Bleu_3": 0.25690876632139, "Bleu_4": 0.19814632477890462, "METEOR": 0.29174025692950056, "ROUGE_L": 0.49414941494149406, "CIDEr": 0.09886116883296509, "SPICE": {"All": {"pr": 0.11428571428571428, "re": 0.19047619047619047, "f": 0.14285714285714285, "fn": 17.0, "numImages": 1.0, "fp": 31.0, "tp": 4.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.2857142857142857, "f": 0.17391304347826086, "fn": 5.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}}, "caption": "The image shows a black and white cat sitting on top of a refrigerator with various food items such as cheese, bread, and drinks inside."}, "380414": {"image_id": 380414, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.1968748077349065, "Bleu_3": 0.14154870398533734, "Bleu_4": 0.10912441388233995, "METEOR": 0.2350722092265889, "ROUGE_L": 0.28561872909699, "CIDEr": 1.3483873817452972e-06, "SPICE": {"All": {"pr": 0.3125, "re": 0.625, "f": 0.4166666666666667, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of two people skateboarding in a parking lot. One person is standing on the sidewalk and the other is on the ground, holding onto their skateboard. The building behind them has a sign that reads \"Buddy's Skate Shop.\""}, "332058": {"image_id": 332058, "Bleu_1": 0.24999999999519235, "Bleu_2": 0.1565560727682472, "Bleu_3": 0.0788478660803684, "Bleu_4": 1.0001000249876893e-05, "METEOR": 0.23380028393957006, "ROUGE_L": 0.22048192771084338, "CIDEr": 4.560002340684326e-12, "SPICE": {"All": {"pr": 0.25, "re": 0.2727272727272727, "f": 0.2608695652173913, "fn": 16.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.7142857142857143, "f": 0.5263157894736842, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a man walking on the beach with a surfboard under his arm. He is wearing a black and white wetsuit and sunglasses, and has a look of determination on his face as he walks towards the ocean. The sky is cloudy and there are waves crashing against the shore."}, "531896": {"image_id": 531896, "Bleu_1": 0.24615384615005917, "Bleu_2": 0.10741723110424946, "Bleu_3": 5.678964045404228e-07, "Bleu_4": 1.3110036986610077e-09, "METEOR": 0.21107004545729072, "ROUGE_L": 0.21128154379020286, "CIDEr": 6.3142687655894475e-18, "SPICE": {"All": {"pr": 0.15, "re": 0.12, "f": 0.1333333333333333, "fn": 22.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man carrying two children in a stroller as they walk through an airport terminal. The man is wearing a backpack and has a suitcase in his hand, while the children are dressed in casual clothing and are holding onto the handle of the stroller. The background is a busy airport with many people walking around and luggage carts on the floor."}, "160703": {"image_id": 160703, "Bleu_1": 0.33333333331746035, "Bleu_2": 0.12909944486727937, "Bleu_3": 9.572639770106142e-07, "Bleu_4": 2.642138995361506e-09, "METEOR": 0.17605989572510003, "ROUGE_L": 0.33116178067318125, "CIDEr": 0.06757791785069366, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.07692307692307693, "f": 0.05555555555555555, "fn": 12.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.2, "f": 0.13333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "There are two plates of pizza on the table, one with pepperoni and mushrooms, and the other with sausage and onions."}, "13985": {"image_id": 13985, "Bleu_1": 0.36585365852766216, "Bleu_2": 0.13525044519677484, "Bleu_3": 0.0776970028959442, "Bleu_4": 1.0540405058349627e-05, "METEOR": 0.227062516908967, "ROUGE_L": 0.26425992779783397, "CIDEr": 8.570211274283557e-07, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.21052631578947367, "f": 0.11940298507462688, "fn": 15.0, "numImages": 1.0, "fp": 44.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.05555555555555555, "re": 0.125, "f": 0.07692307692307691, "fn": 7.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "The man is sitting at a table with his laptop open in front of him. He is wearing a blue shirt and tie, and has his hair slicked back. There are books and other items on the table next to him."}, "47511": {"image_id": 47511, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.20378478648001003, "Bleu_3": 0.14484170833539137, "Bleu_4": 0.11102294159028528, "METEOR": 0.23525826948187745, "ROUGE_L": 0.3138263665594855, "CIDEr": 0.0002103851864108458, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.08, "f": 0.1, "fn": 23.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting at a table with laptops and papers in front of them. One woman is writing on a whiteboard while another woman looks on. There are several posters on the walls with words written on them."}, "262425": {"image_id": 262425, "Bleu_1": 0.3999999999800001, "Bleu_2": 0.14509525001455675, "Bleu_3": 1.053605336689408e-06, "Bleu_4": 2.8800248891848133e-09, "METEOR": 0.15390140282326978, "ROUGE_L": 0.3096446700507614, "CIDEr": 0.016148616549727636, "SPICE": {"All": {"pr": 0.30434782608695654, "re": 0.2692307692307692, "f": 0.28571428571428575, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.5454545454545454, "f": 0.5714285714285713, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A marina filled with sailboats and yachts on a sunny day\""}, "349402": {"image_id": 349402, "Bleu_1": 0.1891891891866326, "Bleu_2": 0.1439897976538201, "Bleu_3": 0.10482470428144693, "Bleu_4": 1.1285820725312872e-05, "METEOR": 0.22129384658742052, "ROUGE_L": 0.19321266968325795, "CIDEr": 7.305534744316415e-26, "SPICE": {"All": {"pr": 0.4, "re": 0.2727272727272727, "f": 0.3243243243243243, "fn": 16.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.625, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "This image shows a bunch of bananas hanging from a wooden rack in a room. The bananas are yellow and ripe, and they are arranged in a row on the rack. There is a wooden floor underneath the rack, and the walls of the room are made of wood as well. The lighting in the room is dim, and there is a window on one side of the room that lets in natural light."}, "11987": {"image_id": 11987, "Bleu_1": 0.4090909090816116, "Bleu_2": 0.2926152399363322, "Bleu_3": 0.1828753971355031, "Bleu_4": 0.11051481410645939, "METEOR": 0.27818064411581933, "ROUGE_L": 0.3639618138424821, "CIDEr": 6.947834820330121e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "This is a bedroom with a striped tent ceiling and a wooden floor. There is a bed with a white sheet on it, a table with chairs, and a fireplace with a mantle. The walls are painted in a red and white striped pattern."}, "292209": {"image_id": 292209, "Bleu_1": 0.19999999999714288, "Bleu_2": 0.1424424623203343, "Bleu_3": 6.682259607346889e-07, "Bleu_4": 1.4526928780743356e-09, "METEOR": 0.19789684220371614, "ROUGE_L": 0.20588235294117646, "CIDEr": 1.7133453740312144e-22, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15151515151515152, "f": 0.20833333333333331, "fn": 28.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.0625, "f": 0.1111111111111111, "fn": 15.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is an image of a blue and white truck parked in a parking lot. The truck has a large tank on the back of it, which appears to be filled with fuel. There are two people standing next to the truck, one of whom is holding a hose. The image appears to be taken in a parking lot, as there are other cars and buildings visible in the background."}, "92134": {"image_id": 92134, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2823724831943621, "Bleu_3": 0.19814066986326467, "Bleu_4": 2.0999803083172398e-05, "METEOR": 0.3708611375622942, "ROUGE_L": 0.3953337653920933, "CIDEr": 3.7980204113382435e-06, "SPICE": {"All": {"pr": 0.1, "re": 0.07407407407407407, "f": 0.0851063829787234, "fn": 25.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.18181818181818182, "f": 0.2105263157894737, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a beach with lounge chairs and umbrellas on the sand. In the background, there is a cruise ship docked at the pier. The sky is clear and blue, with a few clouds scattered about. The water is calm and turquoise."}, "43098": {"image_id": 43098, "Bleu_1": 0.22727272726928377, "Bleu_2": 0.19611613513518975, "Bleu_3": 0.15334371344677084, "Bleu_4": 0.12300686288273006, "METEOR": 0.21742558783770294, "ROUGE_L": 0.2522398345968298, "CIDEr": 1.3219573389584716e-16, "SPICE": {"All": {"pr": 0.6363636363636364, "re": 0.22580645161290322, "f": 0.3333333333333333, "fn": 24.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.14285714285714285, "f": 0.23529411764705882, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3333333333333333, "f": 0.4210526315789474, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a man walking down the sidewalk with an empty suitcase in his hand. The suitcase is blue and has the word \"Luggage\" written on it in white letters. The man is wearing a black jacket and jeans, and he is walking towards a building with a red awning. There are other buildings in the background, and there are people walking on the sidewalk."}, "476735": {"image_id": 476735, "Bleu_1": 0.20454545454080583, "Bleu_2": 0.09753841331211074, "Bleu_3": 6.095846571183441e-07, "Bleu_4": 1.5331320282613667e-09, "METEOR": 0.1590507538107259, "ROUGE_L": 0.2197406340057637, "CIDEr": 1.594094114554743e-08, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.26666666666666666, "f": 0.26666666666666666, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a person riding a jet ski on a lake. The person is wearing a life jacket and has their arms outstretched as they jump off the back of the boat. The water is calm and there are trees in the background."}, "263359": {"image_id": 263359, "Bleu_1": 0.21951219511927422, "Bleu_2": 0.11640504929350137, "Bleu_3": 0.07979793176853724, "Bleu_4": 0.05988864023176349, "METEOR": 0.16564038402344797, "ROUGE_L": 0.21847640704945992, "CIDEr": 2.1751931716198016e-29, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.18181818181818182, "f": 0.1951219512195122, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a group of people riding horses along a dirt path in the mountains. The horses are brown and white, and they are all wearing saddles and bridles. The riders are wearing blue shirts and pants, and they are all smiling and looking happy. In the background, there is a mountain range with green trees and a blue sky.\n\nThe caption for this image could be: \"A group of friends ride their horses through the mountains on a sunny day.\""}, "39068": {"image_id": 39068, "Bleu_1": 0.2166666666630556, "Bleu_2": 0.10496165562800558, "Bleu_3": 5.748366509372991e-07, "Bleu_4": 1.3511066263448826e-09, "METEOR": 0.15843303658731925, "ROUGE_L": 0.13646532438478748, "CIDEr": 5.673000756680204e-16, "SPICE": {"All": {"pr": 0.6, "re": 0.16666666666666666, "f": 0.2608695652173913, "fn": 15.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is an image of a street with a tree growing out of the sidewalk. The tree has branches that are reaching up towards the sky and its leaves are a deep green color. There are buildings on either side of the street, with windows and doors visible through the trees. The sky is clear and blue in the background."}, "439427": {"image_id": 439427, "Bleu_1": 0.1730769230735947, "Bleu_2": 0.11651034560483009, "Bleu_3": 0.0647519709524591, "Bleu_4": 8.627614350761504e-06, "METEOR": 0.19230116063227792, "ROUGE_L": 0.22536945812807885, "CIDEr": 3.071654168642457e-12, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.13636363636363635, "f": 0.14634146341463414, "fn": 19.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3, "f": 0.28571428571428564, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a person snowboarding down a hill in the snow. The person is wearing a black and white jacket, black pants, and black boots. They are holding their arms out to the side as they ride down the hill. There are trees in the background of the image."}, "177420": {"image_id": 177420, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.2877424176573564, "Bleu_3": 0.17873650359777302, "Bleu_4": 2.1250562768192664e-05, "METEOR": 0.2502306195349713, "ROUGE_L": 0.3330300272975432, "CIDEr": 0.0025037870320317466, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is a bathroom with a green wall and a white sink. There is a mirror on the wall above the sink and a toilet in the corner of the room."}, "82994": {"image_id": 82994, "Bleu_1": 0.4047619047522676, "Bleu_2": 0.3142012345469511, "Bleu_3": 0.27028083790982066, "Bleu_4": 0.2439887492492662, "METEOR": 0.4097311604254181, "ROUGE_L": 0.43262411347517726, "CIDEr": 6.130970358178018e-06, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.125, "f": 0.13953488372093023, "fn": 21.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of an airplane. They are all wearing military uniforms and some are holding their hands up in the air. The plane is painted with the words \"US Air Force\" on the side."}, "548780": {"image_id": 548780, "Bleu_1": 0.43902439023319456, "Bleu_2": 0.3312945782163583, "Bleu_3": 0.282369647927117, "Bleu_4": 0.2441773761771862, "METEOR": 0.40104542489353867, "ROUGE_L": 0.44043321299638993, "CIDEr": 7.775655766746266e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.2413793103448276, "f": 0.24561403508771928, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows two women sitting on a bench in the park. One of them is smoking a cigarette while the other is looking at her phone. There are pigeons walking around the bench and people walking by in the background."}, "78381": {"image_id": 78381, "Bleu_1": 0.3829787233961069, "Bleu_2": 0.24141120717629194, "Bleu_3": 0.15720795999973383, "Bleu_4": 1.7238232342610575e-05, "METEOR": 0.2239164880102366, "ROUGE_L": 0.22775357809583074, "CIDEr": 1.8569568611190093e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.3076923076923077, "f": 0.21621621621621623, "fn": 9.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.8, "f": 0.5333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a baseball game in progress. There are several players on the field, including one who is sliding into home plate while another player is catching the ball. The crowd is cheering and there are people standing on the sidelines watching the game."}, "335658": {"image_id": 335658, "Bleu_1": 0.6874999999570314, "Bleu_2": 0.6055300707803913, "Bleu_3": 0.47141253750235657, "Bleu_4": 0.2996160046293989, "METEOR": 0.4336893699634929, "ROUGE_L": 0.5319767441860466, "CIDEr": 1.1847797602535701, "SPICE": {"All": {"pr": 0.3, "re": 0.17647058823529413, "f": 0.22222222222222224, "fn": 14.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.25, "f": 0.3076923076923077, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "A white mouse sitting on a wooden desk next to a keyboard and a computer monitor."}, "101022": {"image_id": 101022, "Bleu_1": 0.45454545452479345, "Bleu_2": 0.1471224715772784, "Bleu_3": 1.0266979059547529e-06, "Bleu_4": 2.747221058959446e-09, "METEOR": 0.2900077210889455, "ROUGE_L": 0.3224101479915434, "CIDEr": 0.079135039917167, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13636363636363635, "f": 0.1333333333333333, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a road sign with the number 60 on it, surrounded by snow covered trees and mountains in the background."}, "147482": {"image_id": 147482, "Bleu_1": 0.1710526315766967, "Bleu_2": 0.11697953037157091, "Bleu_3": 0.05697215874989177, "Bleu_4": 7.094410133732758e-06, "METEOR": 0.1750962334340957, "ROUGE_L": 0.164568345323741, "CIDEr": 1.7928605608637887e-28, "SPICE": {"All": {"pr": 0.1, "re": 0.10714285714285714, "f": 0.10344827586206898, "fn": 25.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a group of people flying kites on a sunny day at the beach. There are several kites in the air, with different colors and designs. Some of the kites have long, flowing tails that resemble jellyfish. A young girl is standing on the sand, watching the kites fly. She is wearing a pink dress and has a big smile on her face. In the background, there are palm trees and a blue ocean."}, "530836": {"image_id": 530836, "Bleu_1": 0.24999999999609374, "Bleu_2": 0.1543033499596618, "Bleu_3": 0.07268637438786686, "Bleu_4": 8.907530052595531e-06, "METEOR": 0.21224833605872725, "ROUGE_L": 0.23680124223602486, "CIDEr": 5.320442812727989e-16, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.04, "f": 0.052631578947368425, "fn": 24.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.09090909090909091, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "This is an image of a kitchen with white appliances and a black and white checkered floor. There are two stoves on the countertops, one with a pot on it and the other with a pan on it. There is also a refrigerator in the corner of the room. The walls are painted a light green color and there are curtains on the windows."}, "376284": {"image_id": 376284, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.29361010974739604, "Bleu_3": 0.18328967100476723, "Bleu_4": 2.1853074822187985e-05, "METEOR": 0.31632740767728484, "ROUGE_L": 0.2839851024208566, "CIDEr": 0.006659818749222978, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 35.0, "tp": 7.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.1, "f": 0.08333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Object": {"pr": 0.29411764705882354, "re": 0.45454545454545453, "f": 0.35714285714285715, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "This is an image of a fire hydrant on the sidewalk. It has several old, rusted pipes attached to it. There are cars parked along the street in the background."}, "134346": {"image_id": 134346, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.2123976976176771, "Bleu_3": 0.14859321195525235, "Bleu_4": 1.5700041046866486e-05, "METEOR": 0.2172006403137329, "ROUGE_L": 0.2492702860478692, "CIDEr": 4.064187120472758e-14, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.4444444444444444, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 1.0, "f": 0.6153846153846153, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe two bears are standing on the edge of a small pond in a zoo. They are looking down into the water and appear to be curious about something. The pond is surrounded by rocks and plants, and there is a fence around it to keep people out."}, "571215": {"image_id": 571215, "Bleu_1": 0.22857142856816326, "Bleu_2": 0.15227739752318503, "Bleu_3": 0.1109023265003588, "Bleu_4": 0.07988114675434649, "METEOR": 0.18478577179968142, "ROUGE_L": 0.2897594077729796, "CIDEr": 7.557266546329163e-19, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16, "f": 0.17391304347826086, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This image shows a graffiti mural of a person running on the side of a building. The person is wearing a black and white striped shirt and has a determined expression on their face. The mural is painted in black and white, with the person's legs and arms blurred together to create a sense of movement. The background is a dark gray concrete wall with some cracks and stains."}, "104313": {"image_id": 104313, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.17390208590454106, "Bleu_3": 1.0026809779444285e-06, "Bleu_4": 2.4281336212346506e-09, "METEOR": 0.28409746172946754, "ROUGE_L": 0.2970779220779221, "CIDEr": 0.0022745763653247517, "SPICE": {"All": {"pr": 0.1875, "re": 0.2, "f": 0.19354838709677422, "fn": 24.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a box filled with various types of donuts, including chocolate frosted, sprinkled, and glazed. There are also cups of coffee and tea on the table next to the box."}, "82678": {"image_id": 82678, "Bleu_1": 0.333333333325926, "Bleu_2": 0.15075567228549366, "Bleu_3": 8.08524074577027e-07, "Bleu_4": 1.883464306778211e-09, "METEOR": 0.17294640014169846, "ROUGE_L": 0.21048999309868874, "CIDEr": 1.6277157902805008e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.3333333333333333, "f": 0.16666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.1111111111111111, "f": 0.09999999999999999, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is a view of the ocean from a bench on the beach. The water is calm and clear, with a few boats in the distance. There are people walking along the beach and some buildings in the background. The sky is blue and cloudy."}, "127781": {"image_id": 127781, "Bleu_1": 0.3437499999892579, "Bleu_2": 0.332997142280758, "Bleu_3": 0.30923115916279004, "Bleu_4": 0.290661457416434, "METEOR": 0.4935510127386804, "ROUGE_L": 0.5258620689655172, "CIDEr": 0.0017947954844725982, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.19230769230769232, "f": 0.23255813953488372, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.1111111111111111, "f": 0.14285714285714285, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a black cat sitting under an umbrella on the floor. The cat is looking up at the umbrella with its eyes. There are no other objects in the image."}, "235791": {"image_id": 235791, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.2431867285489846, "Bleu_3": 0.15977319241684967, "Bleu_4": 1.9536125064112438e-05, "METEOR": 0.25951971898615417, "ROUGE_L": 0.36464560204953034, "CIDEr": 0.0016756158809004057, "SPICE": {"All": {"pr": 0.16, "re": 0.26666666666666666, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.18181818181818182, "re": 0.5, "f": 0.26666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is a photograph of a boat floating on a river surrounded by buildings and other boats. The sky is clear and blue, with a few clouds visible in the distance."}, "281448": {"image_id": 281448, "Bleu_1": 0.15714285714061227, "Bleu_2": 0.08265771673866477, "Bleu_3": 0.046489259876401, "Bleu_4": 6.222942289398482e-06, "METEOR": 0.1958505853174358, "ROUGE_L": 0.1496565260058881, "CIDEr": 8.653013386483283e-23, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2222222222222222, "f": 0.17391304347826086, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "A white sheep and a black sheep grazing in a green field\n\nThe white sheep is standing on the left side of the image, looking directly at the camera. The black sheep is standing on the right side of the image, looking towards the camera. Both sheep are grazing in a green field with tall grass and flowers growing around them. The sky is blue and cloudy in the background."}, "291589": {"image_id": 291589, "Bleu_1": 0.3225806451508845, "Bleu_2": 0.20739033893928357, "Bleu_3": 1.1404064937195537e-06, "Bleu_4": 2.697772065383126e-09, "METEOR": 0.1973571148368296, "ROUGE_L": 0.3451899757477768, "CIDEr": 0.0034229891330360657, "SPICE": {"All": {"pr": 0.5, "re": 0.3125, "f": 0.38461538461538464, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.75, "re": 0.6, "f": 0.6666666666666665, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a dining table with several vases of flowers on it. The walls are painted a light green color and there is a white lamp hanging from the ceiling."}, "161567": {"image_id": 161567, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.29301635765725875, "Bleu_3": 0.21532531602230645, "Bleu_4": 0.14766123494817676, "METEOR": 0.30867183329390985, "ROUGE_L": 0.28754208754208754, "CIDEr": 2.009745229804043e-07, "SPICE": {"All": {"pr": 0.2, "re": 0.1875, "f": 0.19354838709677422, "fn": 26.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.38461538461538464, "f": 0.3571428571428571, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "The image shows a man and woman standing in a kitchen, both wearing jeans and white shirts. The man is holding a spatula and the woman is holding a frying pan. They are both smiling at each other as they stand next to a stove."}, "85556": {"image_id": 85556, "Bleu_1": 0.24999999999553577, "Bleu_2": 0.17837651699995472, "Bleu_3": 0.10562592656622659, "Bleu_4": 1.2211216504829663e-05, "METEOR": 0.24972738537895303, "ROUGE_L": 0.2401574803149606, "CIDEr": 3.8311581086471037e-13, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.4, "f": 0.29629629629629634, "fn": 12.0, "numImages": 1.0, "fp": 26.0, "tp": 8.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.08333333333333333, "re": 0.3333333333333333, "f": 0.13333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.6666666666666666, "f": 0.5217391304347826, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 6.0}}, "caption": "The image shows a plate of pizza on a table with a beer glass next to it. The pizza has cheese, pepperoni, and other toppings on it. There is a white napkin on the table and a red and white checkered tablecloth underneath the plate. The background is a wooden deck with chairs and umbrellas nearby."}, "183204": {"image_id": 183204, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.21751282250452736, "Bleu_3": 0.11772189470040113, "Bleu_4": 1.5536508417020945e-05, "METEOR": 0.17445015350475787, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.0018733042485830657, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.19047619047619047, "f": 0.16666666666666666, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A collection of items laid out on a red carpet, including clothing, gear, and other supplies for a camping or hiking trip.\""}, "264787": {"image_id": 264787, "Bleu_1": 0.30232558138831805, "Bleu_2": 0.20782052056698208, "Bleu_3": 0.14674773886538112, "Bleu_4": 0.0942786957423983, "METEOR": 0.2995364530843389, "ROUGE_L": 0.34882058613295214, "CIDEr": 1.1185567986136018e-07, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.14285714285714285, "f": 0.17777777777777778, "fn": 24.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a cat hiding under a blanket. The cat has its head peeking out from under the blanket, looking curiously at the camera. The background is a blue and white striped blanket with a small white pillow on top of it."}, "251140": {"image_id": 251140, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.28097574346008974, "Bleu_3": 0.16368983753038932, "Bleu_4": 2.253741272145215e-05, "METEOR": 0.26501895833657013, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.07625089344790473, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.15384615384615385, "f": 0.186046511627907, "fn": 22.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2222222222222222, "f": 0.25, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The book is titled \"the ten-speed bicycle\" and shows a group of people working on a bicycle in a garage."}, "5644": {"image_id": 5644, "Bleu_1": 0.17999999999640004, "Bleu_2": 0.10497813183144382, "Bleu_3": 6.123299201527432e-07, "Bleu_4": 1.4866702340294172e-09, "METEOR": 0.11527472989980704, "ROUGE_L": 0.22235722964763066, "CIDEr": 1.5813040894473198e-10, "SPICE": {"All": {"pr": 0.0625, "re": 0.16666666666666666, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image shows a person skateboarding on a ramp in front of a park. The person is wearing a red hoodie and blue jeans, and has their arms outstretched as they jump off the ramp. The sun is setting in the background, casting a warm orange glow over the scene."}, "246535": {"image_id": 246535, "Bleu_1": 0.37777777776938276, "Bleu_2": 0.22696949467458388, "Bleu_3": 0.10620757885664733, "Bleu_4": 1.2995838594729719e-05, "METEOR": 0.2859188047642841, "ROUGE_L": 0.24063116370808676, "CIDEr": 4.247466742217166e-08, "SPICE": {"All": {"pr": 0.23529411764705882, "re": 0.21052631578947367, "f": 0.2222222222222222, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The man is holding a tennis racket and swinging it at the ball on the court. He is wearing white shorts and a white shirt with a red stripe on the sleeve. The background is a green tennis court with a net in the center."}, "102555": {"image_id": 102555, "Bleu_1": 0.5333333332977779, "Bleu_2": 0.33806170186806433, "Bleu_3": 0.20638725024557966, "Bleu_4": 2.9256127305132916e-05, "METEOR": 0.34358694987570787, "ROUGE_L": 0.6108726752503576, "CIDEr": 0.8732430467412632, "SPICE": {"All": {"pr": 0.1875, "re": 0.0967741935483871, "f": 0.12765957446808507, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The man is kneeling down next to a small dog, both of them are smiling."}, "80328": {"image_id": 80328, "Bleu_1": 0.44999999997750006, "Bleu_2": 0.266556994977913, "Bleu_3": 0.1580408005034111, "Bleu_4": 2.1951524425427533e-05, "METEOR": 0.2275841544219835, "ROUGE_L": 0.4117911791179118, "CIDEr": 0.13325196962127803, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a herd of zebras grazing in a green field with a group of wildebeest in the background."}, "366493": {"image_id": 366493, "Bleu_1": 0.3870967741810615, "Bleu_2": 0.19674775072873346, "Bleu_3": 1.1010503638215559e-06, "Bleu_4": 2.627640098684675e-09, "METEOR": 0.19100050152786174, "ROUGE_L": 0.26872246696035246, "CIDEr": 0.009771624345698126, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.17391304347826086, "f": 0.1702127659574468, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a plate of sliced apples with some of them cut in half and others whole. There are also some slices of apple on the side of the plate."}, "455624": {"image_id": 455624, "Bleu_1": 0.32692307691678996, "Bleu_2": 0.21182963642996727, "Bleu_3": 0.09645716184588765, "Bleu_4": 1.1633270842064559e-05, "METEOR": 0.17416542052002365, "ROUGE_L": 0.25176886792452824, "CIDEr": 2.79821914153973e-10, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 26.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a motorcycle racing down a dirt track in the middle of a field. The rider is wearing a helmet and is leaning forward on the bike, with his arms outstretched to steer it. The background is made up of tall grasses and trees, with people watching from the sidelines."}, "2142": {"image_id": 2142, "Bleu_1": 0.5238095237845806, "Bleu_2": 0.4577377081947216, "Bleu_3": 0.4044613344206799, "Bleu_4": 0.368198599768179, "METEOR": 0.42771513399513755, "ROUGE_L": 0.574793875147232, "CIDEr": 0.31122652111944527, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA man sitting on a bench surrounded by pigeons in a park."}, "137538": {"image_id": 137538, "Bleu_1": 0.2666666666607408, "Bleu_2": 0.13483997248961796, "Bleu_3": 7.505672632527668e-07, "Bleu_4": 1.7812705639924762e-09, "METEOR": 0.1562011374513858, "ROUGE_L": 0.21048999309868874, "CIDEr": 4.305934601535742e-09, "SPICE": {"All": {"pr": 0.1891891891891892, "re": 0.2413793103448276, "f": 0.21212121212121213, "fn": 22.0, "numImages": 1.0, "fp": 30.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.5454545454545454, "f": 0.4444444444444444, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}}, "caption": "The image shows a white pelican standing on a rock in the middle of a pond. There are two other pelicans standing next to it, one with its beak open and the other with its beak closed. The pond is surrounded by trees and greenery."}, "114891": {"image_id": 114891, "Bleu_1": 0.29268292682212976, "Bleu_2": 0.12097167577883941, "Bleu_3": 7.212750820939888e-07, "Bleu_4": 1.7726777657776637e-09, "METEOR": 0.2528067570882917, "ROUGE_L": 0.30049261083743845, "CIDEr": 7.582873771955216e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.1, "f": 0.08695652173913043, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a small brown dog sitting in a large, fluffy pillow. The dog is wearing a blue collar and has its paws on the edge of the pillow. There is a banana peel on the floor next to the dog."}, "15953": {"image_id": 15953, "Bleu_1": 0.33333333332222226, "Bleu_2": 0.23973165073456326, "Bleu_3": 0.12708595986317403, "Bleu_4": 1.6604746091112762e-05, "METEOR": 0.2955058094508318, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.0035390572979708806, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.23529411764705882, "f": 0.186046511627907, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a plate with a cupcake topped with whipped cream and sprinkled with cinnamon. There are several apples on the table, including one that has been bitten into."}, "566155": {"image_id": 566155, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.2823298512746205, "Bleu_3": 0.1935115854658825, "Bleu_4": 0.13629358171800737, "METEOR": 0.21579584260444845, "ROUGE_L": 0.3546511627906977, "CIDEr": 0.06637525690815066, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.125, "f": 0.11538461538461538, "fn": 21.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted white and there is a blue bucket in the corner."}, "137321": {"image_id": 137321, "Bleu_1": 0.255813953482423, "Bleu_2": 0.19116707482361836, "Bleu_3": 0.12125252078651538, "Bleu_4": 0.08170583718657062, "METEOR": 0.2714432765735724, "ROUGE_L": 0.33174711080897346, "CIDEr": 5.556897933314396e-07, "SPICE": {"All": {"pr": 0.125, "re": 0.11538461538461539, "f": 0.12000000000000001, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.23076923076923078, "f": 0.23076923076923078, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a black and white image of a bedroom with a bed, nightstand, and chair. The bed has a quilt on it and there are some books on the nightstand. The chair is empty and there is a window in the background."}, "166259": {"image_id": 166259, "Bleu_1": 0.20408163264889634, "Bleu_2": 0.11293848786082757, "Bleu_3": 0.06474337870309639, "Bleu_4": 8.764094705114603e-06, "METEOR": 0.2209730144210293, "ROUGE_L": 0.19242902208201892, "CIDEr": 3.485302367820788e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.11538461538461539, "f": 0.16666666666666669, "fn": 23.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "Four ducks walking on a wooden walkway\n\nThe image shows four ducks walking in a row on a wooden walkway. They are all facing the same direction and appear to be in a line. The walkway is surrounded by greenery and there are some buildings visible in the background."}, "56669": {"image_id": 56669, "Bleu_1": 0.30952380951644, "Bleu_2": 0.1504928025607928, "Bleu_3": 8.272888216792643e-07, "Bleu_4": 1.9519860758481695e-09, "METEOR": 0.22098662969495153, "ROUGE_L": 0.2469635627530364, "CIDEr": 6.925147241924016e-07, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.34782608695652173, "f": 0.3137254901960784, "fn": 15.0, "numImages": 1.0, "fp": 20.0, "tp": 8.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.125, "f": 0.10526315789473685, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5, "f": 0.4347826086956522, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows a man playing frisbee in a park. He is standing next to a metal pole with a frisbee on top of it, and he is holding another frisbee in his hand. There are trees and grass in the background."}, "4979": {"image_id": 4979, "Bleu_1": 0.2089552238774783, "Bleu_2": 0.15914743455098193, "Bleu_3": 0.07304020373374781, "Bleu_4": 8.833371352548777e-06, "METEOR": 0.21414566781847638, "ROUGE_L": 0.2370082564351627, "CIDEr": 4.57450620089008e-19, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3076923076923077, "f": 0.34782608695652173, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a red chair with a white horse on it. The horse is standing on the seat of the chair and looks like it is about to jump off. The chair is made of metal and has a red and white striped pattern on it. There are buildings in the background of the image, which appear to be made of brick and stone."}, "197350": {"image_id": 197350, "Bleu_1": 0.39999999999, "Bleu_2": 0.33588764909534785, "Bleu_3": 0.27493762130851285, "Bleu_4": 0.2177159240018686, "METEOR": 0.3202995683576807, "ROUGE_L": 0.40234518138512276, "CIDEr": 5.308354863515425e-06, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a woman in a red dress playing tennis on a court. She is holding a racket and appears to be preparing to hit the ball. The background of the image is a blue sky with some clouds."}, "7888": {"image_id": 7888, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.12666009927244304, "Bleu_3": 7.944072943886587e-07, "Bleu_4": 2.0053583652894944e-09, "METEOR": 0.16593877858205655, "ROUGE_L": 0.20783645655877342, "CIDEr": 0.00015798421857165777, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.22727272727272727, "f": 0.3225806451612903, "fn": 17.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}}, "caption": "This is an image of a clock tower in the middle of a field. The clock has two hands and is surrounded by grass. There are no people or other objects in the image."}, "248457": {"image_id": 248457, "Bleu_1": 0.30952380951644, "Bleu_2": 0.24575371749023728, "Bleu_3": 0.21945530326099916, "Bleu_4": 0.20080809726025192, "METEOR": 0.39874497312550694, "ROUGE_L": 0.39956331877729256, "CIDEr": 5.15492054140066e-07, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2, "f": 0.25641025641025644, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.1111111111111111, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a person sitting on the ground with an umbrella over their head. The person is wearing black pants and a white shirt, and has a backpack on their back. There is a fence in the background of the image."}, "61735": {"image_id": 61735, "Bleu_1": 0.21052631578393358, "Bleu_2": 0.15086285727691914, "Bleu_3": 0.08582636493752485, "Bleu_4": 1.1593071866873806e-05, "METEOR": 0.19567796290600617, "ROUGE_L": 0.19709208400646203, "CIDEr": 6.292062784501629e-06, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.15, "f": 0.10714285714285714, "fn": 17.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.2, "f": 0.1111111111111111, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is an image of a dog sitting on the floor next to a desk with a computer and other office supplies. The dog is looking up at the camera with its tongue hanging out of its mouth."}, "9236": {"image_id": 9236, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 0.12358624423715978, "Bleu_4": 0.08631929237934717, "METEOR": 0.2148708836250225, "ROUGE_L": 0.2880528883991815, "CIDEr": 4.550033072778204e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.38461538461538464, "f": 0.4347826086956522, "fn": 16.0, "numImages": 1.0, "fp": 10.0, "tp": 10.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.5714285714285714, "re": 0.4, "f": 0.47058823529411764, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Size": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.625, "f": 0.625, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This image shows a kitchen with a refrigerator, stove, and sink. There is also a table with chairs in the corner of the room. The walls are painted white and there are wooden cabinets above the countertops."}, "228335": {"image_id": 228335, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.16817499303272468, "Bleu_3": 8.696639352820399e-07, "Bleu_4": 1.98930453496201e-09, "METEOR": 0.2286876245490606, "ROUGE_L": 0.25902335456475584, "CIDEr": 2.9608358674806404e-08, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.2, "f": 0.2105263157894737, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is a kitchen with a stove, refrigerator, and sink. There are several pots and pans on the countertops, as well as a microwave oven. The walls are painted white and there are windows on one side of the room that let in natural light."}, "451449": {"image_id": 451449, "Bleu_1": 0.19047619047316708, "Bleu_2": 0.14664711501900682, "Bleu_3": 7.064353188212321e-07, "Bleu_4": 1.556920691360494e-09, "METEOR": 0.17817764430437266, "ROUGE_L": 0.21664129883307962, "CIDEr": 8.0276381676684e-18, "SPICE": {"All": {"pr": 0.17142857142857143, "re": 0.3333333333333333, "f": 0.22641509433962265, "fn": 12.0, "numImages": 1.0, "fp": 29.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.6666666666666666, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5714285714285714, "f": 0.36363636363636365, "fn": 3.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "The image shows a dog lying on top of a pile of books on a bed. The dog is wearing a collar and appears to be sleeping. There are several books stacked on the bed, including some that are open and have pages turned down. The room appears to be cluttered with other items such as a lamp, a vase, and a clock."}, "254033": {"image_id": 254033, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.13862658669016847, "Bleu_3": 0.07176233678698053, "Bleu_4": 9.226349141829447e-06, "METEOR": 0.20221204385462235, "ROUGE_L": 0.22344322344322343, "CIDEr": 6.326960047942874e-13, "SPICE": {"All": {"pr": 0.5333333333333333, "re": 0.3333333333333333, "f": 0.4102564102564102, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 8.0}, "Relation": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows two zebras standing in a clearing surrounded by trees. They are both black and white with distinctive stripes on their backs. One of the zebras is looking directly at the camera while the other is looking away. The trees in the background are tall and green, providing shade for the zebras."}, "515555": {"image_id": 515555, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.15149527936992757, "Bleu_3": 0.11587828529210012, "Bleu_4": 0.07196884728190052, "METEOR": 0.23041161315455835, "ROUGE_L": 0.2540343571056741, "CIDEr": 3.6805967743345344e-16, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.07407407407407407, "f": 0.11764705882352941, "fn": 25.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This image shows a large, ornate building with a clock tower in the center. The building has a lot of intricate details and carvings on the facade, including arches, columns, and other architectural elements. The clock tower is tall and slender, with a large clock face on the front. The sky is cloudy and there are some trees in the background."}, "69213": {"image_id": 69213, "Bleu_1": 0.47058823526643606, "Bleu_2": 0.2425356250216204, "Bleu_3": 0.1576957321539479, "Bleu_4": 2.300556723830808e-05, "METEOR": 0.21626241690308226, "ROUGE_L": 0.35589264877479576, "CIDEr": 0.6483407867558453, "SPICE": {"All": {"pr": 0.1388888888888889, "re": 0.19230769230769232, "f": 0.16129032258064516, "fn": 21.0, "numImages": 1.0, "fp": 31.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.625, "f": 0.43478260869565216, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}}, "caption": "Two men in hats and suits stand on the sidewalk, looking at something in front of them."}, "579362": {"image_id": 579362, "Bleu_1": 0.47368421051385046, "Bleu_2": 0.357802682486979, "Bleu_3": 0.2773609469111094, "Bleu_4": 0.22221939979111432, "METEOR": 0.3477622009809476, "ROUGE_L": 0.46435986159169546, "CIDEr": 0.0007120975372596588, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.29411764705882354, "f": 0.29411764705882354, "fn": 12.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6666666666666666, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A man sits on a bench overlooking the beach, looking out at the ocean. The sky is clear and blue, with a few clouds scattered in it. The sand is white and the water is clear and blue."}, "244496": {"image_id": 244496, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.26940795303160764, "Bleu_3": 0.13424553701132266, "Bleu_4": 1.6995165295471083e-05, "METEOR": 0.23732328341130698, "ROUGE_L": 0.39610389610389607, "CIDEr": 0.004308663158679243, "SPICE": {"All": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2727272727272727, "f": 0.3157894736842105, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A man is standing in front of a door wearing a red shirt and black pants. He has a red tie around his neck and is holding a cigarette in his hand."}, "121041": {"image_id": 121041, "Bleu_1": 0.305555555547068, "Bleu_2": 0.2288688541020835, "Bleu_3": 1.1549543647109152e-06, "Bleu_4": 2.6139371033672662e-09, "METEOR": 0.22008280851790107, "ROUGE_L": 0.25673400673400676, "CIDEr": 2.847670926238319e-05, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.125, "f": 0.12903225806451615, "fn": 28.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a black bird swimming in the ocean. The bird has its beak open and appears to be diving under the water. There are waves crashing on the shore in the background."}, "27235": {"image_id": 27235, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.23807595834181774, "Bleu_3": 0.18299102222839972, "Bleu_4": 0.1142211983420398, "METEOR": 0.3376978088823398, "ROUGE_L": 0.36274822130190076, "CIDEr": 4.160963034713544e-05, "SPICE": {"All": {"pr": 0.1875, "re": 0.13636363636363635, "f": 0.15789473684210525, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a child's bedroom with a teddy bear sitting on the bed. There is a tree sticker on the wall and a blue blanket on the bed. The room has a yellow and green color scheme."}, "229599": {"image_id": 229599, "Bleu_1": 0.7857142856581634, "Bleu_2": 0.6953534953135371, "Bleu_3": 0.586228166010131, "Bleu_4": 0.4374811430871823, "METEOR": 0.3459991554700024, "ROUGE_L": 0.6224489795918368, "CIDEr": 1.6867787360540887, "SPICE": {"All": {"pr": 0.05660377358490566, "re": 0.13043478260869565, "f": 0.07894736842105263, "fn": 20.0, "numImages": 1.0, "fp": 50.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.12, "re": 0.3333333333333333, "f": 0.1764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}}, "caption": "The image shows a clear glass bowl filled with oranges on a wooden surface."}, "435312": {"image_id": 435312, "Bleu_1": 0.2592592592496571, "Bleu_2": 0.14121975761738967, "Bleu_3": 9.274353348178416e-07, "Bleu_4": 2.4010981784314084e-09, "METEOR": 0.1891968259613107, "ROUGE_L": 0.20695504664970313, "CIDEr": 0.001809960534464469, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13043478260869565, "f": 0.13636363636363635, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a woman standing at an intersection, looking down at her phone. The streetlights are yellow and there are buildings in the background."}, "41257": {"image_id": 41257, "Bleu_1": 0.5320358740405796, "Bleu_2": 0.3904075975431099, "Bleu_3": 0.2870481455547405, "Bleu_4": 3.761513537918254e-05, "METEOR": 0.23751027314658532, "ROUGE_L": 0.4039735099337749, "CIDEr": 0.2968895794522584, "SPICE": {"All": {"pr": 0.17073170731707318, "re": 0.23333333333333334, "f": 0.1971830985915493, "fn": 23.0, "numImages": 1.0, "fp": 34.0, "tp": 7.0}, "Relation": {"pr": 0.07692307692307693, "re": 0.07142857142857142, "f": 0.07407407407407408, "fn": 13.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.29411764705882354, "re": 0.5555555555555556, "f": 0.3846153846153846, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}}, "caption": "The image shows a white ferret sleeping in a bed with a grey background."}, "502419": {"image_id": 502419, "Bleu_1": 0.19999999999500007, "Bleu_2": 0.07161148740213011, "Bleu_3": 5.129329487927214e-07, "Bleu_4": 1.381958549447089e-09, "METEOR": 0.13160409484373153, "ROUGE_L": 0.18944099378881987, "CIDEr": 7.71205397438889e-07, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2727272727272727, "f": 0.2926829268292683, "fn": 16.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5, "f": 0.5263157894736842, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows two elephants standing next to each other in a zoo enclosure. One of the elephants is looking directly at the camera while the other is looking away. The enclosure has wooden fencing and trees in the background."}, "382309": {"image_id": 382309, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.23452078798159529, "Bleu_3": 0.13372469554821612, "Bleu_4": 1.8157374167807726e-05, "METEOR": 0.228482322174804, "ROUGE_L": 0.3462630085146642, "CIDEr": 0.04848972237914545, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.3181818181818182, "f": 0.30434782608695654, "fn": 15.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.7142857142857143, "f": 0.588235294117647, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a pizza with meat and cheese on top of it. There is also a beer can on the table next to it."}, "24601": {"image_id": 24601, "Bleu_1": 0.4857142857004082, "Bleu_2": 0.29277002187607215, "Bleu_3": 0.17319011025899111, "Bleu_4": 2.007265508069645e-05, "METEOR": 0.33414020454565396, "ROUGE_L": 0.34574898785425096, "CIDEr": 0.0018992099391195315, "SPICE": {"All": {"pr": 0.2, "re": 0.058823529411764705, "f": 0.0909090909090909, "fn": 32.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a woman in a white tennis outfit standing on the court, holding a tennis racket and ready to hit the ball. She is surrounded by a crowd of people watching her play."}, "9527": {"image_id": 9527, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.19034674689861678, "Bleu_3": 1.1809261666306976e-06, "Bleu_4": 2.9758582163943454e-09, "METEOR": 0.2524978136068765, "ROUGE_L": 0.27477477477477474, "CIDEr": 0.0396422906853643, "SPICE": {"All": {"pr": 0.15, "re": 0.23076923076923078, "f": 0.18181818181818185, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.4, "f": 0.23529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a cluttered office space with a desk, chair, and computer. There are papers and other office supplies on the desk and floor."}, "548538": {"image_id": 548538, "Bleu_1": 0.3333333333277778, "Bleu_2": 0.2812401912868807, "Bleu_3": 0.21213301860260525, "Bleu_4": 0.16088015938543238, "METEOR": 0.238151278261195, "ROUGE_L": 0.33971243418388014, "CIDEr": 1.2034337688868146e-13, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.17647058823529413, "f": 0.15, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.25, "f": 0.2105263157894737, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on the side of a train track in the middle of a forest. The train is an old, wooden passenger car with windows on the sides and a roof. The people are dressed in casual clothing and are looking out at the scenery. In the background, there are tall trees and mountains."}, "284623": {"image_id": 284623, "Bleu_1": 0.37499999999062505, "Bleu_2": 0.31008683646516966, "Bleu_3": 0.24761565853691753, "Bleu_4": 0.1873110771279216, "METEOR": 0.347419620634635, "ROUGE_L": 0.40367647058823536, "CIDEr": 4.279467306613775e-06, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.19047619047619047, "f": 0.1702127659574468, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "This is a black cat sitting on the edge of a bathroom sink. The cat has green eyes and is looking directly at the camera. There are several bottles of shampoo and conditioner on the counter next to the sink."}, "376236": {"image_id": 376236, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.15149527936992757, "Bleu_3": 0.09197265598647544, "Bleu_4": 1.0761852806888608e-05, "METEOR": 0.24295266131906373, "ROUGE_L": 0.22944653412144012, "CIDEr": 1.640841879456166e-16, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.14285714285714285, "f": 0.12000000000000001, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a young boy feeding a giraffe at an animal enclosure. The giraffe is standing on its hind legs and reaching out to take the food from the boy's hand. The boy is wearing a green shirt and blue pants, and the giraffe has a brown coat with white spots. The background is a wooden fence and trees."}, "308678": {"image_id": 308678, "Bleu_1": 0.2786885245855953, "Bleu_2": 0.15239436903993275, "Bleu_3": 0.09233618804983319, "Bleu_4": 1.0793740127583288e-05, "METEOR": 0.19344844002785702, "ROUGE_L": 0.22944653412144012, "CIDEr": 3.031697074116606e-16, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.2631578947368421, "f": 0.2127659574468085, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.2222222222222222, "re": 0.2222222222222222, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people in a small boat, surrounded by a large ship. They are wearing life jackets and helmets, and appear to be preparing to jump into the water. The ship is a large, white vessel with a red and blue stripe on its side. There are several other boats in the background, also filled with people."}, "293625": {"image_id": 293625, "Bleu_1": 0.1846153846125444, "Bleu_2": 0.09302605094046401, "Bleu_3": 5.159681256428669e-07, "Bleu_4": 1.2200264122747586e-09, "METEOR": 0.13212688133004502, "ROUGE_L": 0.20056364490371065, "CIDEr": 9.970503572592692e-18, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.25, "f": 0.3125, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows two women sitting on a couch, one holding a microphone and the other holding a camera. They are both smiling and looking at each other. There is a table in front of them with various items on it, including a laptop, a phone, and a bottle of water. The room appears to be well lit and there are plants on the walls."}, "313420": {"image_id": 313420, "Bleu_1": 0.2535211267569926, "Bleu_2": 0.20847245522200808, "Bleu_3": 0.12362980250170183, "Bleu_4": 1.2911156739222086e-05, "METEOR": 0.25280465714580636, "ROUGE_L": 0.19668355596499307, "CIDEr": 3.80597203489072e-23, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.42857142857142855, "f": 0.3870967741935484, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.8, "f": 0.5333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a stuffed bear sitting on top of a shelf in a store. The bear is wearing a black and white striped shirt and has a big smile on its face. There are other stuffed animals on the shelf next to the bear, including a giraffe and a monkey. The wall behind the shelf is made of wood and has a large window with a view of the outside."}, "398884": {"image_id": 398884, "Bleu_1": 0.4666666666511112, "Bleu_2": 0.2836543144559696, "Bleu_3": 0.17912254476139916, "Bleu_4": 2.1479380273480794e-05, "METEOR": 0.19925022165266898, "ROUGE_L": 0.25803722504230114, "CIDEr": 0.004487372342630302, "SPICE": {"All": {"pr": 0.12, "re": 0.10714285714285714, "f": 0.1132075471698113, "fn": 25.0, "numImages": 1.0, "fp": 22.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a green truck parked on grass. The truck has a flatbed with a trailer attached to it. There are other trucks and cars parked nearby."}, "24021": {"image_id": 24021, "Bleu_1": 0.1948051948026649, "Bleu_2": 0.12401353750384897, "Bleu_3": 0.08504838303636154, "Bleu_4": 0.05369596056855117, "METEOR": 0.146414047627877, "ROUGE_L": 0.17579250720461098, "CIDEr": 8.556559228104724e-25, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.23809523809523808, "f": 0.25, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is a group photo of a large number of people standing in front of a brick building. They are all wearing suits and ties, and some of them are holding hats. The building appears to be an old school or church, with tall windows and a steeple on top.\n\nThe caption for this image could be: \"A group of men standing in front of an old school or church, wearing suits and ties and holding hats.\""}, "245701": {"image_id": 245701, "Bleu_1": 0.5151515151359045, "Bleu_2": 0.31079078024446555, "Bleu_3": 0.18402133843647953, "Bleu_4": 2.1348670051455563e-05, "METEOR": 0.2986820220716332, "ROUGE_L": 0.36033755274261603, "CIDEr": 0.001618374500044445, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.20833333333333334, "f": 0.23255813953488372, "fn": 19.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a red shirt and white shorts, and has a tennis racket in his hand. The crowd is watching him play."}, "284991": {"image_id": 284991, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.10846522890718008, "Bleu_3": 0.06215293828145826, "Bleu_4": 8.409805259069613e-06, "METEOR": 0.18890027921215505, "ROUGE_L": 0.22889305816135083, "CIDEr": 2.6559484426192124e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.13043478260869565, "f": 0.20689655172413793, "fn": 20.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.16666666666666666, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The man in the image is drinking from a red plastic cup while sitting on a train. He is wearing a blue shirt and has his hair tied back in a ponytail. The train window behind him shows a view of the countryside with trees and fields visible in the distance."}, "238488": {"image_id": 238488, "Bleu_1": 0.253731343279795, "Bleu_2": 0.13864368525215742, "Bleu_3": 0.08394063987487221, "Bleu_4": 0.05513586763051777, "METEOR": 0.20913923899340728, "ROUGE_L": 0.21360680340170085, "CIDEr": 1.3374661482809961e-18, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.12903225806451613, "f": 0.14035087719298245, "fn": 27.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.2727272727272727, "f": 0.24999999999999994, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a woman sitting at a desk in front of two large screens displaying video footage. She is wearing a blue shirt and black pants, and has a laptop open in front of her. There are several other people in the room, some of whom are also watching the footage on their computers. The room is dimly lit, with only a few overhead lights on."}, "330455": {"image_id": 330455, "Bleu_1": 0.4594594594470417, "Bleu_2": 0.1597670977520923, "Bleu_3": 9.001237398752377e-07, "Bleu_4": 2.1520726721492366e-09, "METEOR": 0.23811758480956513, "ROUGE_L": 0.23735408560311286, "CIDEr": 0.00013460715991209075, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.09523809523809523, "f": 0.1111111111111111, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a busy street with cars driving by at night. There are several buildings on either side of the road, including a red bus and a white car. The streetlights are on, illuminating the area."}, "130984": {"image_id": 130984, "Bleu_1": 0.45161290321123837, "Bleu_2": 0.30053715350890803, "Bleu_3": 0.249721603324861, "Bleu_4": 0.21717887342109382, "METEOR": 0.3039916543815362, "ROUGE_L": 0.37033824804856896, "CIDEr": 0.0029143436068200866, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.2, "f": 0.18604651162790697, "fn": 16.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.375, "f": 0.33333333333333326, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of two blue and yellow trains parked on a train track. The trains are parked next to each other and have their engines facing the same direction."}, "534428": {"image_id": 534428, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.24643202903867023, "Bleu_3": 0.11795893981395056, "Bleu_4": 1.4612432574503429e-05, "METEOR": 0.1782816244635428, "ROUGE_L": 0.2741573033707865, "CIDEr": 3.7191483700947626e-05, "SPICE": {"All": {"pr": 0.15, "re": 0.125, "f": 0.13636363636363635, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a busy street with people walking in the rain. There are several cars parked on the side of the road and pedestrians crossing the street. The buildings in the background are tall and modern."}, "367429": {"image_id": 367429, "Bleu_1": 0.16666666666388893, "Bleu_2": 0.0531494003443801, "Bleu_3": 3.651933955437213e-07, "Bleu_4": 9.6144284585873e-10, "METEOR": 0.10790003138519644, "ROUGE_L": 0.16721491228070173, "CIDEr": 3.9331260220923115e-13, "SPICE": {"All": {"pr": 0.03571428571428571, "re": 0.07692307692307693, "f": 0.04878048780487805, "fn": 12.0, "numImages": 1.0, "fp": 27.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.2, "f": 0.1111111111111111, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a group of people walking down the street with their luggage. They are all wearing blue shirts and jeans, and one person is carrying a large suitcase. There are several cars parked on the side of the road, and some people are standing on the sidewalk. The sky is cloudy and there are trees in the background."}, "260106": {"image_id": 260106, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.17978662998615724, "Bleu_3": 9.092474869081761e-07, "Bleu_4": 2.056834079241225e-09, "METEOR": 0.21243578383507267, "ROUGE_L": 0.26804770872567485, "CIDEr": 6.1240777552205016e-06, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.13043478260869565, "f": 0.13043478260869565, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a horse jumping over a bar at an equestrian competition. The horse is wearing a blue and white saddle and bridle, and the rider is wearing a white shirt and pants. The background is a green field with trees in the distance."}, "566941": {"image_id": 566941, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.15149527936992757, "Bleu_3": 0.1326475235765253, "Bleu_4": 0.11909947923859779, "METEOR": 0.3133342634777993, "ROUGE_L": 0.26916712630998346, "CIDEr": 6.975069113221333e-16, "SPICE": {"All": {"pr": 0.07692307692307693, "re": 0.10526315789473684, "f": 0.08888888888888889, "fn": 17.0, "numImages": 1.0, "fp": 24.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a group of people standing around an elephant in the wild. The elephant is standing on its hind legs and appears to be interacting with one of the people. The people are dressed in casual clothing and appear to be observing the elephant from a safe distance. The background is a dense forest with tall trees and underbrush."}, "555009": {"image_id": 555009, "Bleu_1": 0.382352941165225, "Bleu_2": 0.2152807725945954, "Bleu_3": 0.14254877887623868, "Bleu_4": 1.7483653971429217e-05, "METEOR": 0.24923304100934376, "ROUGE_L": 0.34072773699329717, "CIDEr": 0.001191280569227553, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.13333333333333333, "f": 0.13559322033898305, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.3333333333333333, "f": 0.32, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a desk with a computer, headphones, and other office supplies. The computer has a monitor and keyboard on it, and there are papers and other items on the desk."}, "299492": {"image_id": 299492, "Bleu_1": 0.4482758620535078, "Bleu_2": 0.2530600894303559, "Bleu_3": 0.19233940503365562, "Bleu_4": 0.15295559336971712, "METEOR": 0.26671575423766847, "ROUGE_L": 0.3373271889400921, "CIDEr": 0.008563998622331146, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.125, "f": 0.11764705882352941, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.36363636363636365, "f": 0.39999999999999997, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a bridge over a river with train tracks running along the side. The sky is cloudy and there are trees on both sides of the river."}, "16064": {"image_id": 16064, "Bleu_1": 0.21951219511659734, "Bleu_2": 0.1656472891081792, "Bleu_3": 0.11205846904084894, "Bleu_4": 1.387195318328694e-05, "METEOR": 0.15534634885814896, "ROUGE_L": 0.18583396801218582, "CIDEr": 1.2867800821374362e-06, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.15384615384615385, "f": 0.15384615384615385, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.16666666666666666, "f": 0.10526315789473684, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.25, "f": 0.2727272727272727, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "This is an image of a group of people playing frisbee in a park. They are all wearing different colored shirts and pants, and some of them are holding frisbees. The grass is green and there are trees in the background."}, "386553": {"image_id": 386553, "Bleu_1": 0.5999999999700001, "Bleu_2": 0.43528575004367004, "Bleu_3": 0.27612271190213306, "Bleu_4": 3.3359103225784816e-05, "METEOR": 0.285650109784724, "ROUGE_L": 0.37014563106796117, "CIDEr": 0.21702935037581716, "SPICE": {"All": {"pr": 0.05555555555555555, "re": 0.03571428571428571, "f": 0.043478260869565216, "fn": 27.0, "numImages": 1.0, "fp": 17.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "There is a plate with a piece of toast on it. The toast has banana slices on top of it."}, "530384": {"image_id": 530384, "Bleu_1": 0.7333333332844446, "Bleu_2": 0.4577377081854579, "Bleu_3": 0.3182536122341727, "Bleu_4": 4.048411918358003e-05, "METEOR": 0.2314148671731944, "ROUGE_L": 0.4979591836734694, "CIDEr": 0.7256597692857382, "SPICE": {"All": {"pr": 0.0967741935483871, "re": 0.11538461538461539, "f": 0.10526315789473684, "fn": 23.0, "numImages": 1.0, "fp": 28.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is a kitchen with wooden floors, a refrigerator, and a dining table with chairs."}, "75412": {"image_id": 75412, "Bleu_1": 0.1960784313687044, "Bleu_2": 0.10846522890718008, "Bleu_3": 0.06215293828145826, "Bleu_4": 8.409805259069613e-06, "METEOR": 0.13922914174217613, "ROUGE_L": 0.20998278829604128, "CIDEr": 1.2963120635602296e-10, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.16666666666666666, "f": 0.15686274509803924, "fn": 20.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is a small room with a wooden door and a window on the left side. There are two chairs in front of the window, and a bookshelf on the right side of the room. The walls are painted a warm yellow color, and there is a rug on the floor."}, "417339": {"image_id": 417339, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.210720977237338, "Bleu_3": 0.17023845844710978, "Bleu_4": 0.1354286043960901, "METEOR": 0.32410718415889384, "ROUGE_L": 0.37958929682638454, "CIDEr": 2.1881909913750577e-08, "SPICE": {"All": {"pr": 0.12121212121212122, "re": 0.2, "f": 0.15094339622641512, "fn": 16.0, "numImages": 1.0, "fp": 29.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.23076923076923078, "re": 0.5, "f": 0.3157894736842105, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "This is a picture of a man and a boy standing on a snowboard in the snow. The man is wearing a black jacket and pants, while the boy is wearing a red jacket and pants. They are both holding their skis and smiling at the camera."}, "547258": {"image_id": 547258, "Bleu_1": 0.3548387096716962, "Bleu_2": 0.20178998040330562, "Bleu_3": 0.12674273274885656, "Bleu_4": 0.07664420031181063, "METEOR": 0.21775738394611083, "ROUGE_L": 0.32586374358262804, "CIDEr": 4.133172291575027e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.19047619047619047, "f": 0.19047619047619047, "fn": 17.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a young girl standing on a carpeted floor, wearing a pink dress and white sandals. She is jumping up in the air with her arms outstretched. There are two adults sitting on a couch in the background, watching her. The room appears to be a living room with a large window on one wall and a television on another."}, "210520": {"image_id": 210520, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 9.166878867586852e-07, "Bleu_4": 2.1980503399202124e-09, "METEOR": 0.20457478856598835, "ROUGE_L": 0.2824074074074074, "CIDEr": 5.4237678485799623e-05, "SPICE": {"All": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "This image shows a table set with plates, glasses, and utensils. There are several dishes on the table, including a salad, grilled chicken, and corn on the cob. The table is surrounded by flowers and candles."}, "404608": {"image_id": 404608, "Bleu_1": 0.4999999999772728, "Bleu_2": 0.3086066999098223, "Bleu_3": 0.168239086565974, "Bleu_4": 2.2374677076390884e-05, "METEOR": 0.28327038178150493, "ROUGE_L": 0.38689217758985195, "CIDEr": 0.14963385309509455, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.2608695652173913, "f": 0.21428571428571427, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.18181818181818182, "re": 0.3333333333333333, "f": 0.23529411764705885, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet and sink in the corner. The walls are white and there is a tile floor."}, "133087": {"image_id": 133087, "Bleu_1": 0.255813953482423, "Bleu_2": 0.07804363148971961, "Bleu_3": 5.296191672956597e-07, "Bleu_4": 1.388218324422588e-09, "METEOR": 0.13773314203730272, "ROUGE_L": 0.13426265590608952, "CIDEr": 2.0140968015172041e-07, "SPICE": {"All": {"pr": 0.3181818181818182, "re": 0.2692307692307692, "f": 0.2916666666666667, "fn": 19.0, "numImages": 1.0, "fp": 15.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.42857142857142855, "re": 0.3, "f": 0.3529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a street scene at night with tall buildings on either side of the road. There are streetlights on the corners and a few people walking down the sidewalk. The sky is dark and there are stars visible in the sky."}, "560819": {"image_id": 560819, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.3468729675368036, "Bleu_3": 0.26590120932469696, "Bleu_4": 0.18661962389794468, "METEOR": 0.3435350284647512, "ROUGE_L": 0.48956661316211875, "CIDEr": 0.0005384327674605008, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1111111111111111, "f": 0.13636363636363638, "fn": 24.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man in white tennis attire holding a tennis racket and waving it in the air while standing on a tennis court. He is surrounded by other people watching him play."}, "358572": {"image_id": 358572, "Bleu_1": 0.34285714284734703, "Bleu_2": 0.17393131069069204, "Bleu_3": 9.71435267961373e-07, "Bleu_4": 2.3135181196744457e-09, "METEOR": 0.23877765425633277, "ROUGE_L": 0.20980223559759242, "CIDEr": 0.00017773427006979853, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.17391304347826086, "f": 0.2105263157894737, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The woman in the image is playing tennis on a court. She is wearing an orange and white dress and has a racket in her hand. The other players are watching her from the sidelines."}, "67164": {"image_id": 67164, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.34256998744096767, "Bleu_3": 0.26943196865265767, "Bleu_4": 0.21743769222041257, "METEOR": 0.36876489513434424, "ROUGE_L": 0.45319465081723626, "CIDEr": 4.4580544874572616e-05, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.14285714285714285, "f": 0.14035087719298248, "fn": 24.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.25, "f": 0.27586206896551724, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a white cat sitting in the back seat of a car, looking out the window. The car is parked on the side of the road, and there are trees and buildings visible in the background."}, "482777": {"image_id": 482777, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.1539536764846181, "Bleu_4": 0.10884267615297269, "METEOR": 0.30832467181881157, "ROUGE_L": 0.3613030602171767, "CIDEr": 0.0018981885471150393, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.42105263157894735, "f": 0.326530612244898, "fn": 11.0, "numImages": 1.0, "fp": 22.0, "tp": 8.0}, "Relation": {"pr": 0.08333333333333333, "re": 0.2, "f": 0.11764705882352941, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.5, "f": 0.22222222222222224, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.5, "f": 0.5217391304347826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "This is an image of a large military aircraft flying in the sky. The plane has a white body and black wings, and it is flying through the clouds."}, "151516": {"image_id": 151516, "Bleu_1": 0.30769230768639055, "Bleu_2": 0.19026059765810294, "Bleu_3": 0.11313211375448105, "Bleu_4": 1.311113853149677e-05, "METEOR": 0.22013006563033635, "ROUGE_L": 0.25722891566265055, "CIDEr": 1.881035984119385e-10, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.1875, "f": 0.2222222222222222, "fn": 13.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a bird flying over the water with its wings spread wide. The bird is a brown and white color with a red beak and legs. It appears to be flying low over the water, with its wings tucked in. There are some boats in the background of the image."}, "121692": {"image_id": 121692, "Bleu_1": 0.38461538455621314, "Bleu_2": 0.25318484173115374, "Bleu_3": 0.1799537517468085, "Bleu_4": 2.7629350706071527e-05, "METEOR": 0.2630819185755134, "ROUGE_L": 0.37596302003081655, "CIDEr": 0.7605243590033085, "SPICE": {"All": {"pr": 0.4375, "re": 0.2916666666666667, "f": 0.35000000000000003, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The giraffe is standing on the ground, looking up at a rock wall."}, "407943": {"image_id": 407943, "Bleu_1": 0.1964285714250638, "Bleu_2": 0.11952286093128565, "Bleu_3": 0.09258553737962033, "Bleu_4": 0.0739768603054929, "METEOR": 0.2014269659130288, "ROUGE_L": 0.2426136363636364, "CIDEr": 5.130684566555543e-14, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.5454545454545454, "f": 0.37499999999999994, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.4, "re": 0.8, "f": 0.5333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a person standing in front of a large white umbrella. The person is wearing a black shirt and pants, and has their hands in their pockets. The umbrella is open and appears to be made of white fabric with a silver handle. There are no other objects or people visible in the image."}, "401935": {"image_id": 401935, "Bleu_1": 0.8461538460887575, "Bleu_2": 0.5937710859477767, "Bleu_3": 0.40021356113894074, "Bleu_4": 5.031747626088394e-05, "METEOR": 0.28364421193260997, "ROUGE_L": 0.6073968705547652, "CIDEr": 1.0354309431431266, "SPICE": {"All": {"pr": 0.7777777777777778, "re": 0.28, "f": 0.4117647058823529, "fn": 18.0, "numImages": 1.0, "fp": 2.0, "tp": 7.0}, "Relation": {"pr": 0.6666666666666666, "re": 0.18181818181818182, "f": 0.28571428571428575, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.625, "f": 0.7692307692307693, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 5.0}}, "caption": "A red and yellow train traveling down the tracks on a sunny day."}, "492805": {"image_id": 492805, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.11497181007363187, "Bleu_4": 1.3481992110749651e-05, "METEOR": 0.19966527419118504, "ROUGE_L": 0.23091482649842268, "CIDEr": 1.0959127732608793e-09, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.05555555555555555, "f": 0.0425531914893617, "fn": 17.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.16666666666666666, "f": 0.1111111111111111, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "A train is traveling on the tracks next to a bridge over a river. The train has two cars, one with a blue and yellow striped awning on top and the other with a red and white striped awning on top. There are trees and buildings in the background."}, "166165": {"image_id": 166165, "Bleu_1": 0.28124999999560546, "Bleu_2": 0.13363062095410766, "Bleu_3": 6.603995385924977e-07, "Bleu_4": 1.4740852891680107e-09, "METEOR": 0.2650544595517552, "ROUGE_L": 0.21785714285714283, "CIDEr": 1.614052943126603e-16, "SPICE": {"All": {"pr": 0.1, "re": 0.10714285714285714, "f": 0.10344827586206898, "fn": 25.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.18181818181818182, "f": 0.14814814814814814, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}}, "caption": "The image shows a woman playing tennis on a court. She is wearing a white shirt and white shorts, and has a racket in her hand. There are other people on the court, including one who is holding a racket and another who is standing near the net. The image appears to be taken from above, with the sun shining down on the players."}, "314649": {"image_id": 314649, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.22794037622152502, "Bleu_3": 0.1410880608208969, "Bleu_4": 0.09398143524016507, "METEOR": 0.21992404769590315, "ROUGE_L": 0.3155949741315595, "CIDEr": 0.00016752007950856883, "SPICE": {"All": {"pr": 0.4, "re": 0.3, "f": 0.34285714285714286, "fn": 14.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.5714285714285714, "f": 0.5714285714285714, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "The image shows a river with a bridge in the background. There is a white boat on the water, and a train crossing the bridge. The sky is clear and blue, with trees on either side of the river."}, "446260": {"image_id": 446260, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2236067977443172, "Bleu_3": 0.13806135595480482, "Bleu_4": 0.09183403564889472, "METEOR": 0.23293076563075943, "ROUGE_L": 0.34078212290502796, "CIDEr": 1.4767322380107779e-05, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.16666666666666666, "f": 0.17777777777777778, "fn": 20.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The man in the image is wearing a white shirt with black and yellow stripes, a black tie, and sunglasses. He has long blonde hair and is standing in front of a window with a view of the city outside."}, "188852": {"image_id": 188852, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.08989331499344942, "Bleu_3": 5.342275830329977e-07, "Bleu_4": 1.3085607656499974e-09, "METEOR": 0.16255739377276246, "ROUGE_L": 0.21542083578575633, "CIDEr": 2.0788516246751566e-13, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.14285714285714285, "f": 0.12903225806451615, "fn": 24.0, "numImages": 1.0, "fp": 30.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.09090909090909091, "f": 0.09090909090909091, "fn": 10.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows two people skiing down a snowy mountain slope. One person is wearing a black and white jacket and pants, while the other person is wearing a red and white jacket and pants. They are both holding ski poles and smiling at each other. In the background, there are trees and mountains visible."}, "284749": {"image_id": 284749, "Bleu_1": 0.7333333332844446, "Bleu_2": 0.6473388749254526, "Bleu_3": 0.5442060218634078, "Bleu_4": 0.4048411918358003, "METEOR": 0.40975442428725944, "ROUGE_L": 0.6639455782312924, "CIDEr": 1.6515058136871164, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.10344827586206896, "f": 0.10526315789473684, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.21428571428571427, "f": 0.21428571428571427, "fn": 11.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "A group of people are gathered in a park, flying kites on a sunny day."}, "410004": {"image_id": 410004, "Bleu_1": 0.2857142857074831, "Bleu_2": 2.6398183866786545e-09, "Bleu_3": 5.585079625938629e-12, "Bleu_4": 2.5852698128401774e-13, "METEOR": 0.13099415204678364, "ROUGE_L": 0.16874135546334715, "CIDEr": 8.975988735577875e-07, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.21052631578947367, "f": 0.14035087719298245, "fn": 15.0, "numImages": 1.0, "fp": 34.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 15.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.5, "f": 0.2727272727272727, "fn": 3.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "The image shows a street market with various fruits and vegetables on display. There are several people walking around the market, some of them carrying baskets or bags of produce. The sky is clear and blue, with a few clouds scattered about."}, "561928": {"image_id": 561928, "Bleu_1": 0.2075471698074048, "Bleu_2": 0.17869060919900012, "Bleu_3": 0.16364790162348092, "Bleu_4": 0.14468810567798146, "METEOR": 0.28257809123056854, "ROUGE_L": 0.25894481503941785, "CIDEr": 1.00322045959662e-11, "SPICE": {"All": {"pr": 0.5, "re": 0.18518518518518517, "f": 0.2702702702702703, "fn": 22.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.2222222222222222, "f": 0.30769230769230765, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2727272727272727, "f": 0.3529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of bicycles are hanging from a tree in a park. The bicycles are all different colors and styles, and they are all hanging from the branches of the tree. There are also some people walking by the tree, looking at the bicycles.\""}, "313491": {"image_id": 313491, "Bleu_1": 0.5599999999776001, "Bleu_2": 0.4041451884162355, "Bleu_3": 0.3286792832145262, "Bleu_4": 0.2637873055829728, "METEOR": 0.38335958138994203, "ROUGE_L": 0.5573604060913705, "CIDEr": 0.044172821765955814, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.29411764705882354, "f": 0.25641025641025644, "fn": 12.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a bathroom with a toilet and sink. The walls are painted white and there is a window on the side of the room."}, "493117": {"image_id": 493117, "Bleu_1": 0.14666666666471112, "Bleu_2": 0.13355836865340542, "Bleu_3": 0.11360310471219216, "Bleu_4": 0.1004504825559818, "METEOR": 0.24576888637872746, "ROUGE_L": 0.24965893587994542, "CIDEr": 4.484947904963242e-26, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.26666666666666666, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.6, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a motorcycle parked on the side of a dirt road in front of a large grain silo. The sun is setting in the background, casting a warm orange glow over the scene. The motorcycle's engine is visible through the open side panel, and the rider is wearing a black leather jacket and helmet. The road is lined with tall grasses and trees, giving the impression of being in a rural area."}, "201141": {"image_id": 201141, "Bleu_1": 0.33333333332098775, "Bleu_2": 0.19611613513078086, "Bleu_3": 0.11544156732198758, "Bleu_4": 1.591178311035633e-05, "METEOR": 0.17825741277893756, "ROUGE_L": 0.41391009329940626, "CIDEr": 0.015872440493973492, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.11764705882352941, "f": 0.15384615384615383, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}}, "caption": "The image shows a man sitting at a small wooden table in front of a bakery with various types of bread and pastries hanging from the ceiling."}, "253810": {"image_id": 253810, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.183339699400327, "Bleu_3": 0.10061584140131913, "Bleu_4": 1.3357103091691184e-05, "METEOR": 0.24180942855104354, "ROUGE_L": 0.2543786488740617, "CIDEr": 9.23786516807517e-05, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.21739130434782608, "f": 0.22222222222222224, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.4444444444444444, "f": 0.4210526315789474, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "A banana is hanging from a metal stand on a red table.\n\nThe banana is yellow and has a few brown spots on it. It looks like it has been sitting there for a while."}, "412136": {"image_id": 412136, "Bleu_1": 0.4473684210408588, "Bleu_2": 0.31101174776760976, "Bleu_3": 0.220683752156973, "Bleu_4": 0.1574230264310077, "METEOR": 0.2522050980565774, "ROUGE_L": 0.3479323691179466, "CIDEr": 0.0029730285294626317, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.09090909090909091, "f": 0.10256410256410256, "fn": 20.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2857142857142857, "f": 0.2857142857142857, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a person holding a sandwich in their hand, with the bread cut in half and the meat and cheese visible inside. There are also two cups of coffee on the table next to the sandwich."}, "153734": {"image_id": 153734, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.09875106606632027, "Bleu_3": 5.962685701989571e-07, "Bleu_4": 1.4732563104646528e-09, "METEOR": 0.11354816059397566, "ROUGE_L": 0.1601049868766404, "CIDEr": 9.305657548533365e-11, "SPICE": {"All": {"pr": 0.28, "re": 0.1794871794871795, "f": 0.21875, "fn": 32.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.07692307692307693, "f": 0.1, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07142857142857142, "f": 0.1, "fn": 13.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a group of people standing next to a herd of cows in a field. The people are wearing hats and sunglasses, while the cows are standing in the dirt with their heads down. There is a small stream running through the field in the background."}, "391825": {"image_id": 391825, "Bleu_1": 0.714285714234694, "Bleu_2": 0.6629935440826179, "Bleu_3": 0.6034799806556997, "Bleu_4": 0.531696715290295, "METEOR": 0.43340645367844094, "ROUGE_L": 0.6692789968652038, "CIDEr": 1.951605992922796, "SPICE": {"All": {"pr": 0.5, "re": 0.23529411764705882, "f": 0.31999999999999995, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.6666666666666666, "f": 0.8, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "A flock of sheep grazing in a green field with trees in the background."}, "206300": {"image_id": 206300, "Bleu_1": 0.2142857142818878, "Bleu_2": 0.13957263155725563, "Bleu_3": 0.08969032338542007, "Bleu_4": 0.060742159103670014, "METEOR": 0.1611466516923922, "ROUGE_L": 0.22858672376873657, "CIDEr": 4.086214400136558e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.21052631578947367, "f": 0.20512820512820512, "fn": 15.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a red stop sign on the side of a building. The sign is made of metal and has the words \"stop\" written in white letters on it. The building behind the sign appears to be made of brick and has several windows on each floor. There are also some trees in the background."}, "535809": {"image_id": 535809, "Bleu_1": 0.2653061224435652, "Bleu_2": 0.19669894811330474, "Bleu_3": 0.1351686025680867, "Bleu_4": 0.08559874749328851, "METEOR": 0.1739446519945844, "ROUGE_L": 0.236281471917366, "CIDEr": 1.3166571368158141e-10, "SPICE": {"All": {"pr": 0.0625, "re": 0.07692307692307693, "f": 0.06896551724137931, "fn": 24.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}}, "caption": "This is a black and white image of a cat lying on top of a couch. The cat has its eyes closed and is looking up at the camera. The background is a beige color with a few scattered objects on it, such as a book and a vase."}, "132554": {"image_id": 132554, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2175844552512906, "Bleu_3": 0.1291053828237431, "Bleu_4": 1.4956884792307707e-05, "METEOR": 0.22548574661180068, "ROUGE_L": 0.2827814569536423, "CIDEr": 1.1713887278453821e-08, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.2777777777777778, "f": 0.18867924528301885, "fn": 13.0, "numImages": 1.0, "fp": 30.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.09090909090909091, "re": 0.25, "f": 0.13333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.42857142857142855, "f": 0.2857142857142857, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a woman standing next to a brown horse in a barn. The woman is wearing a white shirt and blue jeans, while the horse is wearing a saddle and bridle. The barn appears to be made of wood and has a wooden door."}, "469464": {"image_id": 469464, "Bleu_1": 0.3617021276518787, "Bleu_2": 0.2660221937781222, "Bleu_3": 0.1465157820982506, "Bleu_4": 1.6351219050554547e-05, "METEOR": 0.3026636944705769, "ROUGE_L": 0.24416277518345564, "CIDEr": 5.152914371255683e-09, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.06666666666666667, "f": 0.08888888888888888, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.15384615384615385, "f": 0.2, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a child holding a video game controller in their hand. The controller has a white and black design with buttons on it. The child is wearing a green shirt and blue pants. There is a table in the background with a lamp on it."}, "335844": {"image_id": 335844, "Bleu_1": 0.3124999999902345, "Bleu_2": 0.17390208590454106, "Bleu_3": 1.0026809779444285e-06, "Bleu_4": 2.4281336212346506e-09, "METEOR": 0.16800185589343605, "ROUGE_L": 0.2713523131672598, "CIDEr": 0.00035933388729771857, "SPICE": {"All": {"pr": 0.3, "re": 0.16666666666666666, "f": 0.21428571428571427, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.3333333333333333, "f": 0.46153846153846156, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "This is an image of a toaster on a kitchen counter. The toaster has a black body and a silver dial on the front. There are no other objects in the image."}, "493751": {"image_id": 493751, "Bleu_1": 0.15476190476006238, "Bleu_2": 0.08636205792237611, "Bleu_3": 0.044972190080930556, "Bleu_4": 5.7887763846782034e-06, "METEOR": 0.18894226433515965, "ROUGE_L": 0.17615511551155114, "CIDEr": 1.3416524516807883e-31, "SPICE": {"All": {"pr": 0.13043478260869565, "re": 0.14285714285714285, "f": 0.13636363636363635, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a garden. They are all looking at something on the ground, possibly a bird or a small animal. The woman in the middle is holding a camera and taking pictures of the other people. The man on the left is wearing a hat and sunglasses, while the woman on the right is wearing a white shirt and black pants. The trees in the background are lush and green, with leaves covering the ground."}, "274629": {"image_id": 274629, "Bleu_1": 0.5312499999833985, "Bleu_2": 0.4139697666871967, "Bleu_3": 0.34195687912017897, "Bleu_4": 0.30158991976618316, "METEOR": 0.3413364820324761, "ROUGE_L": 0.546268656716418, "CIDEr": 0.014715054612861853, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.21428571428571427, "f": 0.30769230769230765, "fn": 22.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.1111111111111111, "f": 0.15384615384615383, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2222222222222222, "f": 0.3636363636363636, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a stop sign on the side of the road. It has a pink ribbon attached to it and is surrounded by a white background with blue letters that read \"stop\"."}, "264382": {"image_id": 264382, "Bleu_1": 0.2833333333286111, "Bleu_2": 0.2078950191360966, "Bleu_3": 0.13075565381529075, "Bleu_4": 0.0791364644516525, "METEOR": 0.21861025612740434, "ROUGE_L": 0.26236559139784943, "CIDEr": 1.921445094729474e-15, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.06896551724137931, "f": 0.09523809523809525, "fn": 27.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows a baseball player pitching a ball on a green field in front of a large crowd of people. The player is wearing a white jersey with the number 23 on the back, and he is holding the ball in his right hand as he prepares to throw it. The crowd is standing behind him, watching the game."}, "301376": {"image_id": 301376, "Bleu_1": 0.2972972972892623, "Bleu_2": 0.1817499189304432, "Bleu_3": 0.09809046705543314, "Bleu_4": 1.2907744865533497e-05, "METEOR": 0.17801353864186042, "ROUGE_L": 0.2514427040395713, "CIDEr": 1.9969501165432472e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.09523809523809523, "f": 0.13793103448275862, "fn": 19.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2857142857142857, "f": 0.4, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This is an image of a street with several people walking on the sidewalk. There are several buildings on either side of the street, including a restaurant and a convenience store. The sky is clear and blue."}, "125870": {"image_id": 125870, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.1398811515077607, "Bleu_3": 7.219465044848078e-07, "Bleu_4": 1.6481100947130725e-09, "METEOR": 0.1830105599907671, "ROUGE_L": 0.17115600448933782, "CIDEr": 1.2271294684719956e-11, "SPICE": {"All": {"pr": 0.034482758620689655, "re": 0.06666666666666667, "f": 0.045454545454545456, "fn": 14.0, "numImages": 1.0, "fp": 28.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a view of an airport terminal from inside the building. There are several large windows on the walls that allow passengers to see the planes on the runway outside. The terminal is filled with people waiting to board their flights, and there are several buses parked in front of the building."}, "56092": {"image_id": 56092, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1624659147420524, "Bleu_3": 0.11656242933815306, "Bleu_4": 0.08966592262802167, "METEOR": 0.19862068965517238, "ROUGE_L": 0.22048192771084338, "CIDEr": 2.2383537996200824e-10, "SPICE": {"All": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 24.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.08333333333333333, "f": 0.14285714285714285, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6, "re": 0.375, "f": 0.4615384615384615, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows two horses running in a field with a fence in the background. One horse is brown and the other is black. They are running towards each other, their manes and tails flowing in the wind. The sky is blue and cloudy, with some white clouds visible in the distance."}, "312341": {"image_id": 312341, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.09891091079132044, "Bleu_3": 5.730093203419742e-07, "Bleu_4": 1.3858898705876826e-09, "METEOR": 0.1773088756533436, "ROUGE_L": 0.17468499427262313, "CIDEr": 1.526034735354993e-12, "SPICE": {"All": {"pr": 0.12903225806451613, "re": 0.18181818181818182, "f": 0.1509433962264151, "fn": 18.0, "numImages": 1.0, "fp": 27.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.5, "f": 0.28571428571428575, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "This is an image of a woman riding a motorcycle on the sidewalk. She is wearing a helmet and has her arms outstretched as she rides. There are other vehicles parked on the side of the road, including a bus and a car. The sky is cloudy and there are trees in the background."}, "249356": {"image_id": 249356, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.1448065155642414, "Bleu_4": 0.09517889238081183, "METEOR": 0.29673418398356594, "ROUGE_L": 0.3588235294117647, "CIDEr": 1.0934354809582138e-05, "SPICE": {"All": {"pr": 0.037037037037037035, "re": 0.038461538461538464, "f": 0.03773584905660377, "fn": 25.0, "numImages": 1.0, "fp": 26.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}}, "caption": "This is a bathroom with a white toilet, sink, and shower. The walls are painted white and there is a blue rug on the floor. There is a window on one side of the room that lets in natural light."}, "330055": {"image_id": 330055, "Bleu_1": 0.4117647058581315, "Bleu_2": 0.27785946509625026, "Bleu_3": 0.1726578693117122, "Bleu_4": 2.4623953023675646e-05, "METEOR": 0.2648784244109252, "ROUGE_L": 0.34221598877980364, "CIDEr": 0.38297412981064494, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.24242424242424243, "f": 0.28571428571428575, "fn": 25.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.058823529411764705, "f": 0.07692307692307691, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6363636363636364, "re": 0.4666666666666667, "f": 0.5384615384615385, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 7.0}}, "caption": "The image shows a baseball player running towards home plate while another player is catching the ball."}, "46048": {"image_id": 46048, "Bleu_1": 0.29999999999250004, "Bleu_2": 0.19611613513321832, "Bleu_3": 0.1448065155642414, "Bleu_4": 0.11318741601733968, "METEOR": 0.2499953371331797, "ROUGE_L": 0.32250755287009064, "CIDEr": 1.1436490050744064e-05, "SPICE": {"All": {"pr": 0.34782608695652173, "re": 0.47058823529411764, "f": 0.39999999999999997, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.14285714285714285, "f": 0.11764705882352941, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.8571428571428571, "f": 0.7058823529411764, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 6.0}}, "caption": "The image shows a young girl sitting on a bed, surrounded by toys and books. She is wearing a white shirt and pink pajamas. The walls are painted orange and there is a window in the background with curtains open."}, "403295": {"image_id": 403295, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.14021847959482642, "Bleu_3": 0.07054628688135094, "Bleu_4": 8.938506241154746e-06, "METEOR": 0.1616835037316719, "ROUGE_L": 0.19447396386822527, "CIDEr": 7.294688023660728e-13, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2727272727272727, "f": 0.33333333333333326, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a bicycle parked next to a street sign. The bicycle has a red and white striped seat and handlebars, and the tires are black. There is a small red and white striped basket on the front of the bike. The street sign has the words \"No Parking\" written on it in white letters."}, "116361": {"image_id": 116361, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.3336705446737535, "Bleu_3": 0.2623383336508901, "Bleu_4": 0.1969477416362651, "METEOR": 0.293484761031456, "ROUGE_L": 0.3287143956889915, "CIDEr": 3.725811589705745e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.08695652173913043, "f": 0.11428571428571427, "fn": 21.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a group of people sitting in a room with laptops on their laps. They are all looking at their screens and typing away. The room is dimly lit and there are curtains hanging from the ceiling."}, "204100": {"image_id": 204100, "Bleu_1": 0.20338983050502735, "Bleu_2": 0.10256784899095028, "Bleu_3": 5.693542235064205e-07, "Bleu_4": 1.3473794001466769e-09, "METEOR": 0.17547702249857808, "ROUGE_L": 0.17300056721497448, "CIDEr": 3.525229044550746e-16, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.23809523809523808, "f": 0.21276595744680848, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.1, "f": 0.11764705882352941, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 1.0, "f": 0.4, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5714285714285714, "f": 0.4444444444444444, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This image shows a woman standing next to a pile of bananas on the side of the road. She is wearing a black and white striped shirt and has a basket in her hand. There are several other baskets filled with bananas on the ground nearby. The sky is clear and blue, and there are trees in the background."}, "508899": {"image_id": 508899, "Bleu_1": 0.5499999999725, "Bleu_2": 0.2946898458621287, "Bleu_3": 0.16897376438490427, "Bleu_4": 2.3080872884585063e-05, "METEOR": 0.1871639247348058, "ROUGE_L": 0.2837209302325582, "CIDEr": 0.2287298803643016, "SPICE": {"All": {"pr": 0.20689655172413793, "re": 0.2608695652173913, "f": 0.23076923076923075, "fn": 17.0, "numImages": 1.0, "fp": 23.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.14285714285714285, "f": 0.1111111111111111, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is a living room with a couch, coffee table, and TV. There is also a dog on the floor."}, "388395": {"image_id": 388395, "Bleu_1": 0.19999999999600004, "Bleu_2": 0.12777531299740644, "Bleu_3": 6.980462899277689e-07, "Bleu_4": 1.6401693914301652e-09, "METEOR": 0.1639106379549425, "ROUGE_L": 0.15155279503105593, "CIDEr": 1.632531839245411e-09, "SPICE": {"All": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 14.0, "numImages": 1.0, "fp": 14.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThe image shows several buses parked on a street. The buses are different colors and have different designs. Some of them have advertisements on their sides, while others do not. There are people walking around the buses and looking at them."}, "52827": {"image_id": 52827, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.21852940772098994, "Bleu_3": 0.0998296419167968, "Bleu_4": 1.2062023507020694e-05, "METEOR": 0.19147207902595656, "ROUGE_L": 0.22732919254658387, "CIDEr": 2.5825551381623296e-10, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17391304347826086, "f": 0.17777777777777776, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a lighthouse on a rocky coastline with a bird flying overhead. The sky is blue and there are clouds in the distance. The lighthouse is white with red and white stripes, and has a green roof. There are some small boats in the water near the shore."}, "505080": {"image_id": 505080, "Bleu_1": 0.305555555547068, "Bleu_2": 0.18687063685519775, "Bleu_3": 0.10089455706733778, "Bleu_4": 1.3282270438373226e-05, "METEOR": 0.15693459121883385, "ROUGE_L": 0.29901960784313725, "CIDEr": 9.659123496952011e-06, "SPICE": {"All": {"pr": 0.17073170731707318, "re": 0.5, "f": 0.2545454545454546, "fn": 7.0, "numImages": 1.0, "fp": 34.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.3333333333333333, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.8333333333333334, "f": 0.3846153846153846, "fn": 1.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}}, "caption": "This image shows a group of people standing on the shore of a river, looking at something in the water. There is a bridge in the background with a sign that reads \"Welcome to the City\"."}, "66271": {"image_id": 66271, "Bleu_1": 0.6111111110771605, "Bleu_2": 0.536266444329227, "Bleu_3": 0.4158152548596851, "Bleu_4": 0.2631191750191554, "METEOR": 0.33688232201810353, "ROUGE_L": 0.5785907859078591, "CIDEr": 0.5326125169826122, "SPICE": {"All": {"pr": 0.1590909090909091, "re": 0.2916666666666667, "f": 0.20588235294117646, "fn": 17.0, "numImages": 1.0, "fp": 37.0, "tp": 7.0}, "Relation": {"pr": 0.11764705882352941, "re": 0.18181818181818182, "f": 0.14285714285714285, "fn": 9.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.23809523809523808, "re": 0.625, "f": 0.3448275862068965, "fn": 3.0, "numImages": 1.0, "fp": 16.0, "tp": 5.0}}, "caption": "A black and white cat sitting on top of a red suitcase in a room with wooden floors."}, "6471": {"image_id": 6471, "Bleu_1": 0.3157894736786704, "Bleu_2": 0.2123976976176771, "Bleu_3": 0.11793851048655062, "Bleu_4": 0.0742409104053971, "METEOR": 0.19147927074026055, "ROUGE_L": 0.2908059023836549, "CIDEr": 2.962023417412444e-08, "SPICE": {"All": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a baseball player in the middle of a swing, with his bat raised and ready to hit the ball. The player is wearing a black and orange jersey with the number 10 on the back, and has a determined look on his face. Behind him, two umpires are watching the game from the sidelines."}, "351297": {"image_id": 351297, "Bleu_1": 0.5999999999600001, "Bleu_2": 0.462910049854313, "Bleu_3": 0.36704871426530855, "Bleu_4": 0.25336549462596675, "METEOR": 0.39377191922356436, "ROUGE_L": 0.6108726752503576, "CIDEr": 1.471672317512482, "SPICE": {"All": {"pr": 0.25, "re": 0.15384615384615385, "f": 0.1904761904761905, "fn": 22.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "A giraffe standing on the side of a dirt road, looking out into the distance."}, "146831": {"image_id": 146831, "Bleu_1": 0.18181818181487608, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.11509584372581778, "Bleu_4": 0.09684433212908221, "METEOR": 0.2127808790413089, "ROUGE_L": 0.28126801152737757, "CIDEr": 4.1018338846649397e-13, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.1111111111111111, "f": 0.13043478260869565, "fn": 24.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.3333333333333333, "f": 0.3, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA young girl in a black shirt and pants is riding a skateboard on a concrete skate park. The girl is wearing a helmet and has her arms outstretched as she jumps off the ramp. There are trees and buildings in the background of the image."}, "434417": {"image_id": 434417, "Bleu_1": 0.29999999999000004, "Bleu_2": 0.2690981105443468, "Bleu_3": 0.21789189983999352, "Bleu_4": 0.16637856417209446, "METEOR": 0.2901606875963262, "ROUGE_L": 0.42582897033158806, "CIDEr": 0.005174573975171369, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.2, "f": 0.1951219512195122, "fn": 16.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a hotel room with a large bed, a couch, and a bathroom. The walls are painted a light green color and there are two paintings on the wall."}, "188345": {"image_id": 188345, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.26261286571022785, "Bleu_3": 0.17222627547611902, "Bleu_4": 0.11839441618316109, "METEOR": 0.24433230793980848, "ROUGE_L": 0.31633535004321517, "CIDEr": 0.007410460356099923, "SPICE": {"All": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 25.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.3333333333333333, "f": 0.47058823529411764, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "The image is a cake with strawberries on top. There are candles on the side of the cake and a plate with a fork and knife next to it."}, "271772": {"image_id": 271772, "Bleu_1": 0.3636363636198348, "Bleu_2": 0.22792115290866924, "Bleu_3": 0.13746108160529513, "Bleu_4": 1.9228544752192987e-05, "METEOR": 0.27530656303412493, "ROUGE_L": 0.41876430205949655, "CIDEr": 0.12978241273505203, "SPICE": {"All": {"pr": 0.3, "re": 0.1, "f": 0.15, "fn": 27.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a man holding a kite in his hand while standing on a beach with the sun shining behind him."}, "10104": {"image_id": 10104, "Bleu_1": 0.12380952380834469, "Bleu_2": 0.0845154254720429, "Bleu_3": 0.041084522758441835, "Bleu_4": 5.106327225313076e-06, "METEOR": 0.12195739847539656, "ROUGE_L": 0.14134392585236677, "CIDEr": 2.1372937907179298e-54, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.13333333333333333, "f": 0.1568627450980392, "fn": 26.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.4, "f": 0.4000000000000001, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This image shows a group of people riding motorcycles on a wet road. They are wearing red and white clothing and have their arms outstretched as they ride. The sky is cloudy and there is water on the ground.\n\nThe image is taken from a low angle, looking up at the riders. The lighting is dim, with shadows cast by the trees and buildings in the background. The colors are muted, with a focus on the greens and blues of the environment.\n\nThe overall mood of the image is one of excitement and energy, as the riders perform their acrobatic stunts on the wet road."}, "506127": {"image_id": 506127, "Bleu_1": 0.2916666666605903, "Bleu_2": 0.19296124624292718, "Bleu_3": 0.09319532338930898, "Bleu_4": 1.1580903993958116e-05, "METEOR": 0.21259771996927576, "ROUGE_L": 0.3396076352067869, "CIDEr": 1.7019498813150235e-08, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.3333333333333333, "f": 0.21052631578947367, "fn": 8.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.6666666666666666, "f": 0.4705882352941177, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a small wooden bench sitting in the middle of a green field. The bench is empty and there is no one sitting on it. The sky above is a bright green color, giving the impression that the bench is sitting in a field of grass."}, "500175": {"image_id": 500175, "Bleu_1": 0.24390243901844147, "Bleu_2": 0.07808688094237472, "Bleu_3": 5.387209294115685e-07, "Bleu_4": 1.4242196946570861e-09, "METEOR": 0.14917522848780757, "ROUGE_L": 0.2667083073079326, "CIDEr": 7.535511878116437e-06, "SPICE": {"All": {"pr": 0.08108108108108109, "re": 0.07894736842105263, "f": 0.08, "fn": 35.0, "numImages": 1.0, "fp": 34.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.21428571428571427, "f": 0.20689655172413796, "fn": 11.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "The image shows a bird flying in the sky with its wings spread out. There are buildings and trees in the background, and the sky is cloudy.\n\nThe caption reads: `A bird flying in the sky with its wings spread out.`."}, "209221": {"image_id": 209221, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.08492077755952802, "Bleu_3": 4.85544595984151e-07, "Bleu_4": 1.1656654419068713e-09, "METEOR": 0.18203592814371256, "ROUGE_L": 0.1913225300575013, "CIDEr": 2.2166771782634875e-18, "SPICE": {"All": {"pr": 0.2571428571428571, "re": 0.3103448275862069, "f": 0.28125, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 9.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.08333333333333333, "f": 0.08695652173913043, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6153846153846154, "f": 0.5517241379310345, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 8.0}}, "caption": "The image shows a green and yellow train traveling down the tracks at high speed. The train has a large cargo car attached to the front of it, with the words \"Fruit Express\" written on the side. The train is traveling through a station with a platform and a building in the background. There are people standing on the platform watching the train go by."}, "338108": {"image_id": 338108, "Bleu_1": 0.41999999999160004, "Bleu_2": 0.2777460299261539, "Bleu_3": 0.18593942826853238, "Bleu_4": 0.12860612501711083, "METEOR": 0.20806847405168155, "ROUGE_L": 0.2594167679222357, "CIDEr": 2.0042829011628613e-07, "SPICE": {"All": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a photograph of a man standing on a snowy slope, wearing ski gear and holding skis. He is standing in front of a group of people who are also skiing down the slope. The image appears to be taken at a ski resort, with mountains in the background."}, "45648": {"image_id": 45648, "Bleu_1": 0.20930232557652792, "Bleu_2": 0.17291712530720135, "Bleu_3": 0.15391728253765205, "Bleu_4": 0.13818647557441413, "METEOR": 0.36026560364370364, "ROUGE_L": 0.34882058613295214, "CIDEr": 1.8667800932261357e-07, "SPICE": {"All": {"pr": 0.27586206896551724, "re": 0.38095238095238093, "f": 0.32, "fn": 13.0, "numImages": 1.0, "fp": 21.0, "tp": 8.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2, "f": 0.22222222222222224, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.3333333333333333, "re": 1.0, "f": 0.5, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.8571428571428571, "f": 0.5454545454545455, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}}, "caption": "The image shows a person walking on the beach with a surfboard. The person is wearing a wetsuit and sunglasses, and the waves are crashing against the shore. The sky is clear and blue, and there are rocks and trees in the background."}, "313762": {"image_id": 313762, "Bleu_1": 0.26190476189852613, "Bleu_2": 0.19577417125493551, "Bleu_3": 0.12421105892331817, "Bleu_4": 1.4888606314394972e-05, "METEOR": 0.30221630637616376, "ROUGE_L": 0.31077147016011636, "CIDEr": 2.13061905238381e-07, "SPICE": {"All": {"pr": 0.3, "re": 0.23076923076923078, "f": 0.2608695652173913, "fn": 20.0, "numImages": 1.0, "fp": 14.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6, "f": 0.631578947368421, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a man standing on the beach holding a surfboard. He is wearing a black wetsuit and has his hands on his hips, looking out at the ocean. The sky is cloudy and there are waves crashing against the shore."}, "553935": {"image_id": 553935, "Bleu_1": 0.35897435896515456, "Bleu_2": 0.3073547405967436, "Bleu_3": 0.24835702720773914, "Bleu_4": 0.20311720520162124, "METEOR": 0.3029108849851952, "ROUGE_L": 0.4124408384043272, "CIDEr": 7.964715499838853e-05, "SPICE": {"All": {"pr": 0.2631578947368421, "re": 0.21739130434782608, "f": 0.23809523809523808, "fn": 18.0, "numImages": 1.0, "fp": 14.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.375, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a surveillance camera mounted on the side of a building. The camera is pointed towards the sky and there is a plane flying in the distance. The sky is clear and blue with some white clouds."}, "554255": {"image_id": 554255, "Bleu_1": 0.26923076922559175, "Bleu_2": 0.1922322627296484, "Bleu_3": 0.130397100762736, "Bleu_4": 0.08201663209189095, "METEOR": 0.2425676369442875, "ROUGE_L": 0.23047858942065497, "CIDEr": 1.734022322093382e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a group of people playing tennis on a court with a net in the center. There are several players in pink shirts and white shorts, while one player is standing at the net with a racket in hand. The background is green and there are trees in the distance."}, "580608": {"image_id": 580608, "Bleu_1": 0.37209302324716065, "Bleu_2": 0.2662233302496238, "Bleu_3": 0.17309181846231234, "Bleu_4": 0.10670687651358146, "METEOR": 0.2426144448343444, "ROUGE_L": 0.35699024616813746, "CIDEr": 2.7912586269903894e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.3157894736842105, "f": 0.27906976744186046, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a green plant growing out of the neck of a beer bottle. The plant has long, thin leaves and is surrounded by a clear glass bottle. There is a wooden table in the background with a white cloth on it."}, "55955": {"image_id": 55955, "Bleu_1": 0.222222222217284, "Bleu_2": 0.15891043153736062, "Bleu_3": 0.12077745418384085, "Bleu_4": 0.09570498942543387, "METEOR": 0.18485596680453656, "ROUGE_L": 0.27941368930768223, "CIDEr": 4.03217392230992e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.2, "f": 0.20833333333333331, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "The image shows a motorcycle parked on a dirt road. The motorcycle has a black and white paint job with a blue helmet on the handlebars. The rider is wearing a black helmet and sunglasses. The background is a scenic view of mountains and trees."}, "356708": {"image_id": 356708, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.25425669045977695, "Bleu_3": 0.19589143276192844, "Bleu_4": 0.15222275337401533, "METEOR": 0.2943929856228683, "ROUGE_L": 0.3609467455621302, "CIDEr": 6.074888773114528e-08, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.17647058823529413, "f": 0.20000000000000004, "fn": 14.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.16666666666666666, "f": 0.1818181818181818, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.5, "f": 0.36363636363636365, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a man and a girl on skis in the snow. The man is wearing a helmet and goggles, while the girl is wearing a helmet and a pair of skis. They are standing on a slope with a mountain in the background."}, "420229": {"image_id": 420229, "Bleu_1": 0.222222222217284, "Bleu_2": 0.1421338109005459, "Bleu_3": 0.09794571638096423, "Bleu_4": 0.06877439247188379, "METEOR": 0.25780767692118495, "ROUGE_L": 0.25258799171842644, "CIDEr": 1.2555262545424837e-08, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.16666666666666666, "f": 0.11764705882352942, "fn": 10.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.4, "f": 0.2857142857142857, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a person holding an apple slicer on a cutting board. The slicer has a white handle and a red blade that is cutting through the apple. The person's hand is visible in the foreground, with the apple slicer in the background."}, "480726": {"image_id": 480726, "Bleu_1": 0.339622641503026, "Bleu_2": 0.24244760629354595, "Bleu_3": 0.151215262126857, "Bleu_4": 0.09119147048897473, "METEOR": 0.2460546184860102, "ROUGE_L": 0.24811156304474144, "CIDEr": 1.0407161248409418e-11, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.21739130434782608, "f": 0.19230769230769232, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.625, "f": 0.45454545454545453, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "The image shows a group of people watching a tennis match on a court. There are several people in the stands, including some in suits and dresses, and others in casual clothing. The players are standing on the court, holding their rackets and looking at each other. The crowd is cheering and clapping."}, "210607": {"image_id": 210607, "Bleu_1": 0.21276595744228163, "Bleu_2": 0.1520747661648476, "Bleu_3": 0.10092000550287245, "Bleu_4": 0.06952160342972413, "METEOR": 0.1559380920228309, "ROUGE_L": 0.23843648208469054, "CIDEr": 2.000873329120714e-09, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.23076923076923078, "f": 0.24999999999999994, "fn": 20.0, "numImages": 1.0, "fp": 16.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.4, "f": 0.4210526315789474, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is an image of a train on the tracks. The train has a large engine on the front and several cars behind it. There are people standing on the platform next to the train, looking at it. The sky is clear and blue in the background."}, "238691": {"image_id": 238691, "Bleu_1": 0.3199999999872001, "Bleu_2": 3.651483716552006e-09, "Bleu_3": 8.33816145303051e-12, "Bleu_4": 4.028998028940258e-13, "METEOR": 0.1541818181818182, "ROUGE_L": 0.2571127502634352, "CIDEr": 0.01415703450770151, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.15384615384615385, "f": 0.24242424242424246, "fn": 22.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "A group of people are standing in a line at an airport, waiting to board a plane. They are all wearing sunglasses and carrying luggage."}, "260486": {"image_id": 260486, "Bleu_1": 0.28205128204405006, "Bleu_2": 0.12183925606190008, "Bleu_3": 7.375490665399666e-07, "Bleu_4": 1.827122068083466e-09, "METEOR": 0.2089989488238425, "ROUGE_L": 0.24148851939825808, "CIDEr": 2.4696251970424205e-06, "SPICE": {"All": {"pr": 0.35714285714285715, "re": 0.2777777777777778, "f": 0.31250000000000006, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.6666666666666666, "re": 0.6666666666666666, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "This is a desk with a computer, keyboard, and mouse on it. There are also some papers and pens on the desk. The window behind the desk is open and there is a view of the night sky outside."}, "400123": {"image_id": 400123, "Bleu_1": 0.5517241378929845, "Bleu_2": 0.280744962517904, "Bleu_3": 0.18006531235543413, "Bleu_4": 0.12241346948603216, "METEOR": 0.27246873641556535, "ROUGE_L": 0.4049792531120332, "CIDEr": 0.17297105115590317, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.2, "f": 0.20512820512820512, "fn": 16.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a bathroom with a toilet, sink, and shower. The walls are painted blue and green, and there is a window on the left side of the room."}, "227187": {"image_id": 227187, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.3321055820573897, "Bleu_3": 1.9445555935422507e-06, "Bleu_4": 4.787218652070603e-09, "METEOR": 0.2002974674221306, "ROUGE_L": 0.33701657458563533, "CIDEr": 0.37177096923034125, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 18.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.125, "f": 0.13333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a bird feeder with several birds perched on it, surrounded by plants and trees."}, "461275": {"image_id": 461275, "Bleu_1": 0.41666666664930563, "Bleu_2": 0.2691909510176227, "Bleu_3": 1.4878737357096765e-06, "Bleu_4": 3.5389117641754623e-09, "METEOR": 0.22404395646430816, "ROUGE_L": 0.38705583756345174, "CIDEr": 0.021662391164132735, "SPICE": {"All": {"pr": 0.25, "re": 0.23333333333333334, "f": 0.2413793103448276, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.07142857142857142, "re": 0.0625, "f": 0.06666666666666667, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.46153846153846156, "f": 0.5454545454545455, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 6.0}}, "caption": "The image shows a street with trees on either side. There is a sign in the middle of the street that reads \"Firestone Street\"."}, "121534": {"image_id": 121534, "Bleu_1": 0.26315789473222534, "Bleu_2": 0.20565318641151553, "Bleu_3": 0.1566604610064578, "Bleu_4": 0.10923922468551896, "METEOR": 0.21873276049868476, "ROUGE_L": 0.2392156862745098, "CIDEr": 9.865775833826589e-15, "SPICE": {"All": {"pr": 0.2, "re": 0.20833333333333334, "f": 0.20408163265306126, "fn": 19.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.3333333333333333, "f": 0.34782608695652173, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "The image shows a man and woman standing next to each other, both wearing glasses and smiling at the camera. The man is wearing a gray sweater and blue jeans, while the woman is wearing a black dress with red accents. They are both standing in front of a white wall with a large window behind them."}, "500657": {"image_id": 500657, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.18725633517633355, "Bleu_3": 0.10910293277568511, "Bleu_4": 1.2511470357171807e-05, "METEOR": 0.2545794706550507, "ROUGE_L": 0.26940063091482647, "CIDEr": 5.064749351370961e-11, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.05405405405405406, "f": 0.07142857142857144, "fn": 35.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.15384615384615385, "f": 0.18181818181818185, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a young boy in a red baseball uniform, kneeling on the ground and reaching for a baseball that is lying on the ground. The boy is wearing a white helmet and has his glove outstretched to catch the ball. The background of the image is a green field with trees in the distance."}, "162021": {"image_id": 162021, "Bleu_1": 0.1935483870936525, "Bleu_2": 0.0975642000715291, "Bleu_3": 5.413480481885139e-07, "Bleu_4": 1.2805437728409903e-09, "METEOR": 0.1081081081081081, "ROUGE_L": 0.15968586387434555, "CIDEr": 3.730662068287431e-18, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.21052631578947367, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.42857142857142855, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The image shows a group of people skateboarding on the sidewalk. They are all wearing helmets and knee pads, and some of them are holding their boards while others are riding. There are several people watching from the sidelines, including some who are taking photos or videos. The scene is set in a busy urban area with tall buildings in the background."}, "511844": {"image_id": 511844, "Bleu_1": 0.4827586206730084, "Bleu_2": 0.37139067634106854, "Bleu_3": 0.21699150981735554, "Bleu_4": 2.5037370684779395e-05, "METEOR": 0.3707286929128496, "ROUGE_L": 0.40705433746425174, "CIDEr": 0.040609458565132206, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.10714285714285714, "f": 0.13333333333333333, "fn": 25.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.23076923076923078, "f": 0.27272727272727276, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man riding a horse down the street with an American flag on his back. There are people standing on the sidewalk watching him pass by."}, "299001": {"image_id": 299001, "Bleu_1": 0.2909090909038017, "Bleu_2": 0.164121987969432, "Bleu_3": 0.07980300087819454, "Bleu_4": 9.942911665844388e-06, "METEOR": 0.21200852045181942, "ROUGE_L": 0.21095100864553315, "CIDEr": 2.419525383680602e-10, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.35714285714285715, "f": 0.27027027027027023, "fn": 9.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a market stall with various fruits and vegetables on display. There are apples, oranges, bananas, and other fruits arranged in neat rows on the table. A man is standing behind the stall, wearing a hat and looking at the fruit. The background is a bustling market with people walking around and shopping."}, "341111": {"image_id": 341111, "Bleu_1": 0.2181818181778513, "Bleu_2": 0.14213381090113214, "Bleu_3": 0.10457151389178666, "Bleu_4": 0.08143605172498536, "METEOR": 0.1827794348034788, "ROUGE_L": 0.24110671936758893, "CIDEr": 5.131385628633016e-13, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 21.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a person standing on a surfboard in the ocean, holding onto a paddle. The person is wearing a yellow life jacket and has a look of concentration on their face as they paddle through the waves. The sky is cloudy and there are some waves crashing against the shore in the background."}, "526972": {"image_id": 526972, "Bleu_1": 0.36666666665444453, "Bleu_2": 0.2514326764768464, "Bleu_3": 0.16528691241294277, "Bleu_4": 0.11372027709677378, "METEOR": 0.24924126489266085, "ROUGE_L": 0.29383429672447015, "CIDEr": 0.0036072470286497033, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.29411764705882354, "f": 0.2173913043478261, "fn": 12.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This image shows a tray filled with mini pizzas and olives. The pizzas are topped with cheese, pepperoni, and other toppings. The tray is sitting on top of a refrigerator."}, "2299": {"image_id": 2299, "Bleu_1": 0.46153846152071015, "Bleu_2": 0.27174648818404223, "Bleu_3": 0.18325206540749794, "Bleu_4": 0.12789533377278686, "METEOR": 0.2518042160621238, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.024940968676812683, "SPICE": {"All": {"pr": 0.1, "re": 0.06666666666666667, "f": 0.08, "fn": 28.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.07692307692307693, "f": 0.10526315789473684, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "This is a group of children sitting on the ground in front of a building. They are all wearing school uniforms and smiling at the camera."}, "527480": {"image_id": 527480, "Bleu_1": 0.28124999999121103, "Bleu_2": 0.2333141313069371, "Bleu_3": 0.15367277821608147, "Bleu_4": 1.880824215481622e-05, "METEOR": 0.17593726041337954, "ROUGE_L": 0.21708185053380782, "CIDEr": 0.00025859065006902016, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.16666666666666666, "f": 0.1935483870967742, "fn": 15.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "A person is kiteboarding on a body of water. The sun is shining down on the water and the person is holding onto the kite as they ride it across the water."}, "152618": {"image_id": 152618, "Bleu_1": 0.382352941165225, "Bleu_2": 0.18643861801326042, "Bleu_3": 1.0279545754105056e-06, "Bleu_4": 2.4329882944987743e-09, "METEOR": 0.27424655200437914, "ROUGE_L": 0.44060995184590684, "CIDEr": 0.00018666077056014895, "SPICE": {"All": {"pr": 0.03225806451612903, "re": 0.07142857142857142, "f": 0.044444444444444446, "fn": 13.0, "numImages": 1.0, "fp": 30.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.16666666666666666, "f": 0.10526315789473684, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "This is a sign that reads \"stop report all business here\" in red letters on a white background. The sign is attached to a fence post and is located in front of a building."}, "547457": {"image_id": 547457, "Bleu_1": 0.31372549018992696, "Bleu_2": 0.17712297710451136, "Bleu_3": 0.08618888098293648, "Bleu_4": 1.0746774156673132e-05, "METEOR": 0.1967456099212661, "ROUGE_L": 0.2238532110091743, "CIDEr": 1.5181913277848887e-09, "SPICE": {"All": {"pr": 0.03125, "re": 0.04, "f": 0.03508771929824561, "fn": 24.0, "numImages": 1.0, "fp": 31.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.0625, "re": 0.1111111111111111, "f": 0.08, "fn": 8.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}}, "caption": "The image shows a young woman sitting in the driver's seat of a car, looking at her phone. She is wearing a pink shirt and shorts, and has her hair tied back in a ponytail. The car is parked in front of a house with a tree in the background."}, "210766": {"image_id": 210766, "Bleu_1": 0.5999999999700001, "Bleu_2": 0.30779350560975166, "Bleu_3": 1.7394640853977765e-06, "Bleu_4": 4.194685158034568e-09, "METEOR": 0.20312505908357764, "ROUGE_L": 0.4328287606433302, "CIDEr": 0.15622036934548583, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.23529411764705882, "f": 0.20512820512820512, "fn": 13.0, "numImages": 1.0, "fp": 18.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a red and white sign on the side of a building that reads, \"like a brick fitchen.\""}, "115721": {"image_id": 115721, "Bleu_1": 0.2553191489307379, "Bleu_2": 0.2235033479141667, "Bleu_3": 0.20708493833807012, "Bleu_4": 0.1938754083896553, "METEOR": 0.37508431026973055, "ROUGE_L": 0.42711648631444943, "CIDEr": 1.4300598014865027e-08, "SPICE": {"All": {"pr": 0.10526315789473684, "re": 0.08695652173913043, "f": 0.09523809523809525, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2222222222222222, "f": 0.2105263157894737, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "A small dog is sleeping on a couch next to a person wearing pajamas. The dog's head is resting on the person's lap, and the person is holding a remote control in their hand. The room is dimly lit, with a fireplace in the background."}, "545730": {"image_id": 545730, "Bleu_1": 0.3571428571301021, "Bleu_2": 0.25717224992746507, "Bleu_3": 0.19687868737142367, "Bleu_4": 0.13217947625877616, "METEOR": 0.24805301747124275, "ROUGE_L": 0.28773584905660377, "CIDEr": 0.013905346016598687, "SPICE": {"All": {"pr": 0.3888888888888889, "re": 0.3684210526315789, "f": 0.37837837837837834, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.625, "re": 0.8333333333333334, "f": 0.7142857142857143, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "A herd of zebras are standing in the water, looking up at the camera. The river is flowing through the valley and there are trees on both sides."}, "93639": {"image_id": 93639, "Bleu_1": 0.49999999997222233, "Bleu_2": 0.4537426064605658, "Bleu_3": 0.33796635278204396, "Bleu_4": 0.22523313613545354, "METEOR": 0.3441241952964072, "ROUGE_L": 0.5157004830917875, "CIDEr": 0.3790155985001125, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 18.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a group of zebras standing in a field with a mountain range in the background."}, "449879": {"image_id": 449879, "Bleu_1": 0.5714285714013606, "Bleu_2": 0.41403933558520356, "Bleu_3": 0.26229289922503723, "Bleu_4": 3.1642571775070466e-05, "METEOR": 0.3989530539266678, "ROUGE_L": 0.5514124293785311, "CIDEr": 0.34190212863338243, "SPICE": {"All": {"pr": 0.15625, "re": 0.3125, "f": 0.20833333333333334, "fn": 11.0, "numImages": 1.0, "fp": 27.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.3333333333333333, "f": 0.15384615384615383, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 4.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}}, "caption": "The man is sitting on the back of a motorcycle, wearing a leather jacket and holding a cat in his arms."}, "378244": {"image_id": 378244, "Bleu_1": 0.24074074073628263, "Bleu_2": 0.15070298814247132, "Bleu_3": 0.10942600553008858, "Bleu_4": 0.08466528301619354, "METEOR": 0.24288227770839357, "ROUGE_L": 0.2445589919816724, "CIDEr": 2.6147423828896135e-12, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.375, "f": 0.375, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This image shows a person skiing down a snowy slope. The person is wearing a black jacket and pants, and has a pair of skis on their feet. They are holding onto the handlebars of their snowboard as they turn around a tree. The sky is cloudy and there are trees in the background."}, "9003": {"image_id": 9003, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.26940795303160764, "Bleu_3": 0.16913877793500667, "Bleu_4": 0.11365352022818037, "METEOR": 0.27497561814181476, "ROUGE_L": 0.35, "CIDEr": 0.00147565653661482, "SPICE": {"All": {"pr": 0.17391304347826086, "re": 0.16666666666666666, "f": 0.1702127659574468, "fn": 20.0, "numImages": 1.0, "fp": 19.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.14285714285714285, "f": 0.125, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.2727272727272727, "f": 0.28571428571428564, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows a man playing tennis on a court with a net in the background. He is wearing a white shirt and black shorts, and has a racket in his hand."}, "202653": {"image_id": 202653, "Bleu_1": 0.18749999999765626, "Bleu_2": 0.12889501173519066, "Bleu_3": 0.07524353737881434, "Bleu_4": 8.62440657784898e-06, "METEOR": 0.2063785878593304, "ROUGE_L": 0.2006578947368421, "CIDEr": 7.002664566327501e-29, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.15789473684210525, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a couple sitting on a bench in front of a building with a large window on the side. The man is leaning back on his elbows, looking at the woman who is sitting next to him. They are both wearing casual clothing and appear to be enjoying each other's company. The bench is made of wood and has a rustic look to it. In the background, there are several trees and a few people walking by."}, "179174": {"image_id": 179174, "Bleu_1": 0.34210526314889206, "Bleu_2": 0.16654808488508724, "Bleu_3": 0.09167669081722231, "Bleu_4": 1.2180838504699395e-05, "METEOR": 0.17372405818057904, "ROUGE_L": 0.23282442748091606, "CIDEr": 2.5351496324389833e-05, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.06896551724137931, "f": 0.0784313725490196, "fn": 27.0, "numImages": 1.0, "fp": 20.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.15384615384615385, "f": 0.16, "fn": 11.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This image shows a group of old suitcases stacked up on the sidewalk. The suitcases are various colors and sizes, and some of them have wheels on the bottom. There is a person walking by in the background."}, "500100": {"image_id": 500100, "Bleu_1": 0.28070175438104034, "Bleu_2": 0.20025046972515906, "Bleu_3": 0.11339784404794893, "Bleu_4": 1.2819029835191442e-05, "METEOR": 0.23509244366902013, "ROUGE_L": 0.26798462383305877, "CIDEr": 8.300610490046191e-14, "SPICE": {"All": {"pr": 0.25, "re": 0.13636363636363635, "f": 0.1764705882352941, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "A woman is riding a skateboard down the sidewalk while her dog runs alongside her. The woman is wearing a black jacket and jeans, and the dog is wearing a red collar. There are cars parked on both sides of the street, and a building with a graffiti mural on it can be seen in the background."}, "576052": {"image_id": 576052, "Bleu_1": 0.7333333332844446, "Bleu_2": 0.5606119105426793, "Bleu_3": 0.45900113549351607, "Bleu_4": 0.3563054844721135, "METEOR": 0.2500888282839401, "ROUGE_L": 0.6047087980173481, "CIDEr": 1.1680331972162623, "SPICE": {"All": {"pr": 0.19230769230769232, "re": 0.2631578947368421, "f": 0.2222222222222222, "fn": 14.0, "numImages": 1.0, "fp": 21.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.5, "f": 0.4210526315789474, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "A woman is riding a horse through a grassy field with mountains in the background."}, "544140": {"image_id": 544140, "Bleu_1": 0.2954545454478306, "Bleu_2": 0.14357265694226845, "Bleu_3": 0.09938207498160093, "Bleu_4": 0.06994957511587065, "METEOR": 0.1746506990940861, "ROUGE_L": 0.29985955056179775, "CIDEr": 1.2625392559480515e-07, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.04, "f": 0.05555555555555555, "fn": 24.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}}, "caption": "The image shows a group of people playing music on the street in front of a large building with a lot of windows. There are several people standing around, watching them play. The sky is cloudy and there are some trees in the background."}, "349647": {"image_id": 349647, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.13427153888031182, "Bleu_3": 0.06589854024909178, "Bleu_4": 8.242499385671624e-06, "METEOR": 0.18882601317939407, "ROUGE_L": 0.20401337792642138, "CIDEr": 1.855445785258046e-14, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15789473684210525, "f": 0.13043478260869565, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The woman is standing in the kitchen, holding a plate of pizza in one hand and a glass of wine in the other. She is wearing a white shirt and black pants. There are several other plates of food on the counter, including salads and bread. The walls are painted a light blue color and there is a window to the left of the image."}, "240915": {"image_id": 240915, "Bleu_1": 0.30952380951644, "Bleu_2": 0.17377412013914983, "Bleu_3": 9.105491676695635e-07, "Bleu_4": 2.0975455444446706e-09, "METEOR": 0.16001301717458014, "ROUGE_L": 0.25957446808510637, "CIDEr": 5.399996183989703e-07, "SPICE": {"All": {"pr": 0.5263157894736842, "re": 0.3448275862068966, "f": 0.4166666666666667, "fn": 19.0, "numImages": 1.0, "fp": 9.0, "tp": 10.0}, "Relation": {"pr": 0.4, "re": 0.2857142857142857, "f": 0.3333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6, "f": 0.5714285714285713, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a red umbrella with the words \"Kindergarten\" written on it. There are several people standing around the umbrella, some of them holding flowers and other items. The background is a city street with buildings and trees in the distance."}, "235964": {"image_id": 235964, "Bleu_1": 0.255813953482423, "Bleu_2": 0.2064840403341673, "Bleu_3": 0.18409703371622854, "Bleu_4": 0.16711390840150003, "METEOR": 0.32779832015871746, "ROUGE_L": 0.3732154996600952, "CIDEr": 5.020747664134697e-07, "SPICE": {"All": {"pr": 0.11764705882352941, "re": 0.125, "f": 0.12121212121212122, "fn": 14.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a woman standing in front of a mirror in a bathroom. She is wearing a red dress and has her hair tied back in a ponytail. There are green tiles on the walls and a green and white checkered floor."}, "358039": {"image_id": 358039, "Bleu_1": 0.6666666665777778, "Bleu_2": 0.43643578041275427, "Bleu_3": 0.24469914282722582, "Bleu_4": 3.324137842971454e-05, "METEOR": 0.26243365642949984, "ROUGE_L": 0.3469852104664391, "CIDEr": 0.5414055619048666, "SPICE": {"All": {"pr": 0.09090909090909091, "re": 0.15, "f": 0.11320754716981132, "fn": 17.0, "numImages": 1.0, "fp": 30.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.375, "f": 0.2727272727272727, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "There are two pizzas on a plate with a fork and knife next to them."}, "514292": {"image_id": 514292, "Bleu_1": 0.5882352940830451, "Bleu_2": 0.3321055820573897, "Bleu_3": 0.194455559354225, "Bleu_4": 2.6920508807813403e-05, "METEOR": 0.3019368560969552, "ROUGE_L": 0.4277699859747546, "CIDEr": 0.37737945207658485, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 20.0, "numImages": 1.0, "fp": 20.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.1111111111111111, "f": 0.11764705882352941, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3, "f": 0.3157894736842105, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a stuffed animal wearing sunglasses and sitting on the floor next to a box."}, "558362": {"image_id": 558362, "Bleu_1": 0.3749999999765626, "Bleu_2": 0.22360679773553777, "Bleu_3": 1.528553543562194e-06, "Bleu_4": 4.071220775270606e-09, "METEOR": 0.17429193899782136, "ROUGE_L": 0.2527624309392265, "CIDEr": 0.22567223473656914, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.15384615384615385, "f": 0.1509433962264151, "fn": 22.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.09090909090909091, "f": 0.09999999999999999, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"Fresh produce on display at a market\""}, "436865": {"image_id": 436865, "Bleu_1": 0.27027027026296574, "Bleu_2": 0.08664587414929849, "Bleu_3": 5.986080831486464e-07, "Bleu_4": 1.5848464939717996e-09, "METEOR": 0.07597538318213662, "ROUGE_L": 0.1465172137710168, "CIDEr": 1.358778059012643e-06, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.17647058823529413, "f": 0.17910447761194032, "fn": 28.0, "numImages": 1.0, "fp": 27.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.42857142857142855, "f": 0.4444444444444445, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe stands in front of a rocky cliff, looking out at the landscape. The sun shines down on its back, casting a warm glow over its fur."}, "80733": {"image_id": 80733, "Bleu_1": 0.2711864406733697, "Bleu_2": 0.22678604710454314, "Bleu_3": 0.18484964278101854, "Bleu_4": 0.15410241900606322, "METEOR": 0.2610445768304439, "ROUGE_L": 0.293425975414217, "CIDEr": 6.226460686694027e-12, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 27.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 9.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a man standing in front of a mirror, looking at his hair with a concerned expression on his face. He is wearing a striped shirt and has a pair of glasses on his face. The mirror is reflecting the image of the man, making it appear as if he is looking at himself in the mirror."}, "383001": {"image_id": 383001, "Bleu_1": 0.33333333332716053, "Bleu_2": 0.19425717246782156, "Bleu_3": 0.129605673244496, "Bleu_4": 0.08083053722301232, "METEOR": 0.21356740663161222, "ROUGE_L": 0.21863799283154117, "CIDEr": 2.1248967275028363e-10, "SPICE": {"All": {"pr": 0.25, "re": 0.1388888888888889, "f": 0.17857142857142858, "fn": 31.0, "numImages": 1.0, "fp": 15.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.2, "f": 0.26086956521739135, "fn": 12.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a woman holding an umbrella while walking on the sidewalk. She is wearing black and white striped pants and a black shirt with white stripes. There are people in the background, some of whom are also holding umbrellas. The sky is cloudy and there are trees in the distance."}, "312627": {"image_id": 312627, "Bleu_1": 0.43589743588625907, "Bleu_2": 0.23948888444560104, "Bleu_3": 0.14581414798571096, "Bleu_4": 0.09633278659838447, "METEOR": 0.19332330334799008, "ROUGE_L": 0.3034825870646766, "CIDEr": 1.3665092270465535e-05, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.42857142857142855, "f": 0.33333333333333326, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a parking lot with several cars parked in it. There are also some trash cans and recycling bins on the ground. The building in the background appears to be a warehouse or storage facility."}, "482590": {"image_id": 482590, "Bleu_1": 0.2153846153813018, "Bleu_2": 0.15348515337635035, "Bleu_3": 0.10390532779181415, "Bleu_4": 0.06521994679790882, "METEOR": 0.23022730043073, "ROUGE_L": 0.18778860954335555, "CIDEr": 5.46054137866086e-19, "SPICE": {"All": {"pr": 0.21428571428571427, "re": 0.3157894736842105, "f": 0.2553191489361702, "fn": 13.0, "numImages": 1.0, "fp": 22.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.625, "f": 0.4761904761904762, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "The image shows two women walking down a street in a city. One of them is carrying an umbrella and the other is holding onto her arm. They are both wearing casual clothing, such as t-shirts and shorts. The street is lined with buildings and there are cars parked along the side. The sky is cloudy and there are drops of rain on the ground."}, "334521": {"image_id": 334521, "Bleu_1": 0.5454545454297521, "Bleu_2": 0.16116459279757608, "Bleu_3": 1.0910293277246606e-06, "Bleu_4": 2.8753380959849475e-09, "METEOR": 0.21839393559019726, "ROUGE_L": 0.3489702517162472, "CIDEr": 0.054401908717327974, "SPICE": {"All": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of giraffes standing in a fenced enclosure, looking at each other.\""}, "418219": {"image_id": 418219, "Bleu_1": 0.4999999999750001, "Bleu_2": 0.28097574346008974, "Bleu_3": 0.16368983753038932, "Bleu_4": 2.253741272145215e-05, "METEOR": 0.18736857217857883, "ROUGE_L": 0.3519230769230769, "CIDEr": 0.1434845866955288, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.11764705882352941, "f": 0.14285714285714285, "fn": 15.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A man walks down a tree-lined sidewalk on a sunny day.\""}, "575012": {"image_id": 575012, "Bleu_1": 0.2448979591786756, "Bleu_2": 0.17496355305233346, "Bleu_3": 0.13760021235336062, "Bleu_4": 0.10316499681152426, "METEOR": 0.2247968385215726, "ROUGE_L": 0.31344561804167853, "CIDEr": 3.2134204701799813e-07, "SPICE": {"All": {"pr": 0.06896551724137931, "re": 0.1111111111111111, "f": 0.0851063829787234, "fn": 16.0, "numImages": 1.0, "fp": 27.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.1111111111111111, "f": 0.09090909090909093, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "The image shows a woman sitting on a bench, wearing a pink floral dress and white sunglasses. She is holding a cell phone in her hand and has a serious expression on her face. There are other people in the background, walking down the street and crossing the road."}, "182696": {"image_id": 182696, "Bleu_1": 0.45714285712979597, "Bleu_2": 0.3845765979038375, "Bleu_3": 0.26172020548862257, "Bleu_4": 0.15384750051639745, "METEOR": 0.28168726655942383, "ROUGE_L": 0.3876092136616362, "CIDEr": 0.0005449198101528563, "SPICE": {"All": {"pr": 0.07142857142857142, "re": 0.09523809523809523, "f": 0.08163265306122448, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.15384615384615385, "re": 0.2857142857142857, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}}, "caption": "A black cat is sitting on top of a laptop computer, looking at the screen. The laptop has a pink keyboard and a black screen. There is a white table in front of the cat."}, "343972": {"image_id": 343972, "Bleu_1": 0.11111111110956792, "Bleu_2": 0.0395593886059085, "Bleu_3": 2.8170876990939605e-07, "Bleu_4": 7.544630983037233e-10, "METEOR": 0.172615987640453, "ROUGE_L": 0.1460727969348659, "CIDEr": 5.003161706571483e-26, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.14285714285714285, "f": 0.08888888888888889, "fn": 12.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.2, "f": 0.14285714285714285, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "The image shows a mother elephant and her baby standing on the ground. The mother elephant is looking down at her baby while the baby is looking up at her. The mother elephant has a large body with a long trunk and tusks, while the baby elephant has a smaller body with a shorter trunk and tusks. The background of the image is a dirt path with some trees in the distance."}, "7260": {"image_id": 7260, "Bleu_1": 0.24590163934023115, "Bleu_2": 0.1568125120442029, "Bleu_3": 0.10773171058195409, "Bleu_4": 0.08103230024506472, "METEOR": 0.2447050678344229, "ROUGE_L": 0.22652519893899206, "CIDEr": 1.2023908800550406e-16, "SPICE": {"All": {"pr": 0.13157894736842105, "re": 0.23809523809523808, "f": 0.1694915254237288, "fn": 16.0, "numImages": 1.0, "fp": 33.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2777777777777778, "re": 0.5, "f": 0.35714285714285715, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}}, "caption": "The image shows a group of people playing tennis on a green grass court. There are four players in total, two men and two women, all wearing white tennis outfits and holding rackets. They are standing on the court, ready to hit the ball back and forth. The crowd is watching from the sidelines, cheering and clapping as the players play."}, "64084": {"image_id": 64084, "Bleu_1": 0.5217391304120984, "Bleu_2": 0.4074406768151364, "Bleu_3": 0.2873052594916728, "Bleu_4": 0.18556675929243677, "METEOR": 0.33617091784605624, "ROUGE_L": 0.407119021134594, "CIDEr": 0.12140931977133546, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.11538461538461539, "f": 0.11320754716981132, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3, "f": 0.2608695652173913, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "A table with a white plate and two glasses of water on it. There are also several pieces of bread on the plate."}, "324527": {"image_id": 324527, "Bleu_1": 0.23529411763321803, "Bleu_2": 0.12126781251081024, "Bleu_3": 9.934208620967142e-07, "Bleu_4": 2.8927969314267103e-09, "METEOR": 0.13126385809312638, "ROUGE_L": 0.2566619915848527, "CIDEr": 0.17588886368524964, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.2222222222222222, "f": 0.24, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.45454545454545453, "f": 0.45454545454545453, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"Surfer riding a wave at an aquatic park\""}, "91617": {"image_id": 91617, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.24112141107953186, "Bleu_3": 0.16203281746698117, "Bleu_4": 0.10155170980557418, "METEOR": 0.21431351493497994, "ROUGE_L": 0.35169762972453555, "CIDEr": 8.331038566234571e-05, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.21739130434782608, "f": 0.3125, "fn": 18.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.4444444444444444, "f": 0.6153846153846153, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 4.0}}, "caption": "This is a modern office space with a large window overlooking the ocean. There is a desk with a computer and other office supplies, as well as a comfortable chair and a couch. The walls are painted white and there are hardwood floors."}, "541593": {"image_id": 541593, "Bleu_1": 0.23728813558919856, "Bleu_2": 0.18091268062725444, "Bleu_3": 0.11987486713703241, "Bleu_4": 0.07447304260680035, "METEOR": 0.2499953371331797, "ROUGE_L": 0.2644576914144151, "CIDEr": 6.8407382885167785e-15, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.18181818181818182, "f": 0.2222222222222222, "fn": 18.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a black and white image of a clock tower in the city. The clock face is visible on the front of the tower, with the hands pointing to 12 o'clock. The tower is made of brick and has a steep roof. There are buildings in the background, but they are not as tall as the clock tower."}, "468354": {"image_id": 468354, "Bleu_1": 0.31818181817458685, "Bleu_2": 0.1923483450237976, "Bleu_3": 0.13825567198350197, "Bleu_4": 0.10655498021900175, "METEOR": 0.24488004340518862, "ROUGE_L": 0.29735376044568246, "CIDEr": 5.050638893632533e-08, "SPICE": {"All": {"pr": 0.13793103448275862, "re": 0.19047619047619047, "f": 0.16, "fn": 17.0, "numImages": 1.0, "fp": 25.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a river with a bridge in the background. There are several swans swimming in the water, and some buildings can be seen on the opposite side of the river. The sky is clear and blue, with a few clouds scattered about."}, "276893": {"image_id": 276893, "Bleu_1": 0.3199999999936, "Bleu_2": 0.19794866371815806, "Bleu_3": 0.0934590374320519, "Bleu_4": 1.1479990094513042e-05, "METEOR": 0.2585316981202684, "ROUGE_L": 0.2692307692307692, "CIDEr": 3.39079570349625e-09, "SPICE": {"All": {"pr": 0.16, "re": 0.15384615384615385, "f": 0.1568627450980392, "fn": 22.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.36363636363636365, "f": 0.34782608695652173, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a young boy sleeping in bed with his head resting on a pillow. The bed is covered in white sheets and there are two pillows on the bed. The room is dimly lit and there is a window on one side of the room with curtains open."}, "3156": {"image_id": 3156, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.15802842456444308, "Bleu_4": 0.09845529669817563, "METEOR": 0.2531037506305356, "ROUGE_L": 0.3233929754804506, "CIDEr": 3.215436307280896e-08, "SPICE": {"All": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 24.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3333333333333333, "f": 0.42857142857142855, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This image shows a man in a white shirt and black pants standing next to a toilet. He is holding a wrench in his hand and appears to be working on the toilet. The walls of the bathroom are checkered with black and white tiles."}, "340704": {"image_id": 340704, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.06982754846489585, "Bleu_3": 4.732586777946994e-07, "Bleu_4": 1.2388559502196402e-09, "METEOR": 0.15381499008977692, "ROUGE_L": 0.19110275689223058, "CIDEr": 3.466645814854822e-10, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.05128205128205128, "f": 0.08333333333333333, "fn": 37.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.14285714285714285, "f": 0.21052631578947364, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "This image shows an older woman sitting at a table with a hamburger in her hand. She is wearing a white shirt and has a smile on her face. The background of the image appears to be a restaurant or cafeteria, with tables and chairs arranged in rows."}, "452515": {"image_id": 452515, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.18898223650071672, "Bleu_3": 0.11497181007363187, "Bleu_4": 1.3481992110749651e-05, "METEOR": 0.2585880877113341, "ROUGE_L": 0.3078864353312303, "CIDEr": 3.4455524762409454e-10, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.25, "f": 0.2692307692307692, "fn": 21.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.08333333333333333, "f": 0.1, "fn": 11.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows a woman in a white tennis dress playing a tennis match on a blue court. She is holding a tennis racket in her right hand and is about to hit the ball with her left hand. There are several people in the background watching the match."}, "553072": {"image_id": 553072, "Bleu_1": 0.34883720929421314, "Bleu_2": 0.18227065413983304, "Bleu_3": 9.322875456397681e-07, "Bleu_4": 2.1215213862352894e-09, "METEOR": 0.16571323144765257, "ROUGE_L": 0.20734194425560842, "CIDEr": 1.6190101328263847e-07, "SPICE": {"All": {"pr": 0.28, "re": 0.25, "f": 0.2641509433962264, "fn": 21.0, "numImages": 1.0, "fp": 18.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.6, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 6.0}}, "caption": "The image shows a line of several small planes parked on the runway. They are all painted in red and white colors with the words \"Canadian Air Force\" written on their sides. There are several people standing near the planes, looking at them."}, "543215": {"image_id": 543215, "Bleu_1": 0.6315789473019391, "Bleu_2": 0.4955946277304597, "Bleu_3": 0.38662335329677483, "Bleu_4": 0.322638641567532, "METEOR": 0.2543287743448505, "ROUGE_L": 0.47368421052631576, "CIDEr": 0.9194626983859724, "SPICE": {"All": {"pr": 0.35, "re": 0.2, "f": 0.2545454545454545, "fn": 28.0, "numImages": 1.0, "fp": 13.0, "tp": 7.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4444444444444444, "re": 0.3076923076923077, "f": 0.3636363636363637, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "This is a street sign with the name of a town on it. The town is called greenville cemetery."}, "503808": {"image_id": 503808, "Bleu_1": 0.2592592592544582, "Bleu_2": 0.18504536999744126, "Bleu_3": 0.12547526428859127, "Bleu_4": 0.07889074281873733, "METEOR": 0.21062599270275767, "ROUGE_L": 0.1821983273596177, "CIDEr": 4.842002286655395e-12, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.02631578947368421, "f": 0.04, "fn": 37.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 17.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.07142857142857142, "f": 0.10526315789473682, "fn": 13.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}}, "caption": "This is an image of a person skiing down a snowy slope. The person is wearing a red and white jacket and pants, and has a pair of skis on their feet. They are holding onto the rope as they go down the slope. In the background, there are trees and a mountain range."}, "424975": {"image_id": 424975, "Bleu_1": 0.3913043478175804, "Bleu_2": 0.2467175818921615, "Bleu_3": 0.11142496535261215, "Bleu_4": 1.339275015027965e-05, "METEOR": 0.24160616959427159, "ROUGE_L": 0.30160692212608153, "CIDEr": 7.647223347985877e-08, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.45454545454545453, "f": 0.29411764705882354, "fn": 6.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 1.0, "f": 0.5714285714285715, "fn": 0.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a street with a group of people standing in front of a store. The store has brightly colored graffiti on the walls and a sign that reads \"Graffiti City.\" There are also several cars parked on the side of the road."}, "450886": {"image_id": 450886, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.14757569038041785, "Bleu_3": 0.11586898532647615, "Bleu_4": 0.0959765300160311, "METEOR": 0.1902220414472886, "ROUGE_L": 0.2105868814729574, "CIDEr": 2.3031577846976096e-14, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.20833333333333334, "f": 0.20833333333333334, "fn": 19.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This image shows a group of stop signs in front of a building. The signs are made of metal and have the words \"stop\" written on them in white letters. There are several other signs in the background, including one that says \"do not enter.\" The image is taken from a low angle, looking up at the signs."}, "170640": {"image_id": 170640, "Bleu_1": 0.48717948716699544, "Bleu_2": 0.3580574370104147, "Bleu_3": 0.2402082328127251, "Bleu_4": 0.18435104536393854, "METEOR": 0.3544260561379818, "ROUGE_L": 0.4280701754385964, "CIDEr": 8.60698461479481e-05, "SPICE": {"All": {"pr": 0.043478260869565216, "re": 0.05, "f": 0.046511627906976744, "fn": 19.0, "numImages": 1.0, "fp": 22.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}}, "caption": "The image shows a man sitting on a bed in a room with a red wall. He is holding a dog in his lap and looking at it. There are books and other items on the shelves behind him."}, "97857": {"image_id": 97857, "Bleu_1": 0.4594594594470417, "Bleu_2": 0.29889687073377524, "Bleu_3": 0.17218747703610435, "Bleu_4": 0.1106958763197879, "METEOR": 0.22417191905334707, "ROUGE_L": 0.3174721189591078, "CIDEr": 4.36460647064638e-05, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.16, "f": 0.2222222222222222, "fn": 21.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.4444444444444444, "f": 0.5333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a yellow school bus driving down the street with palm trees on either side. There are several cars parked on the side of the road, and people can be seen walking in the distance."}, "120478": {"image_id": 120478, "Bleu_1": 0.4074074073923183, "Bleu_2": 0.2168145451878124, "Bleu_3": 1.2342759676459987e-06, "Bleu_4": 2.97513306285635e-09, "METEOR": 0.16859379903936947, "ROUGE_L": 0.2533748701973001, "CIDEr": 0.006475394666256504, "SPICE": {"All": {"pr": 0.14814814814814814, "re": 0.21052631578947367, "f": 0.17391304347826086, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 4.0}, "Relation": {"pr": 0.125, "re": 0.2, "f": 0.15384615384615385, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.18181818181818182, "re": 0.2857142857142857, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}}, "caption": "This is an image of a road with a sign on the side that reads, \"Welcome to the city.\" There are trees and buildings in the background."}, "280370": {"image_id": 280370, "Bleu_1": 0.18867924527945892, "Bleu_2": 0.10433283794475068, "Bleu_3": 0.07529519927190921, "Bleu_4": 0.05405463811390528, "METEOR": 0.17904677078777342, "ROUGE_L": 0.18496058217101274, "CIDEr": 8.594104546831917e-11, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 15.0, "numImages": 1.0, "fp": 24.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3, "re": 0.3333333333333333, "f": 0.3157894736842105, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "The image shows two men riding horses in a rodeo competition. One man is riding a brown horse and the other is riding a black horse. They are both wearing cowboy hats and riding boots, and their horses are wearing saddles and bridles. The crowd is cheering and waving flags in the background."}, "396608": {"image_id": 396608, "Bleu_1": 0.8461538460236689, "Bleu_2": 0.5937710859021021, "Bleu_3": 0.40021356110815515, "Bleu_4": 0.2829559627860283, "METEOR": 0.30280999531998726, "ROUGE_L": 0.5641618497109826, "CIDEr": 2.4124313149537135, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.3, "re": 0.3, "f": 0.3, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}}, "caption": "A cup of coffee, a banana, and an orange on a white tablecloth."}, "416534": {"image_id": 416534, "Bleu_1": 0.27272727272107444, "Bleu_2": 0.19507682662422146, "Bleu_3": 0.13956004780907147, "Bleu_4": 0.09023496785978731, "METEOR": 0.2692004318409603, "ROUGE_L": 0.3802992518703242, "CIDEr": 1.3649258723027165e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.0967741935483871, "f": 0.13953488372093023, "fn": 28.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "This is a living room with hardwood floors, a couch, and a coffee table. There are two windows on the opposite side of the room, one of which has blinds. The walls are painted white and there are two lamps on the coffee table."}, "159627": {"image_id": 159627, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.12541522083027962, "Bleu_3": 6.548937148826446e-07, "Bleu_4": 1.5032715711819957e-09, "METEOR": 0.15474572900846742, "ROUGE_L": 0.14039125431530494, "CIDEr": 4.166611909027885e-15, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.08, "f": 0.10526315789473685, "fn": 23.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2222222222222222, "f": 0.26666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nThis is a bus stop sign on a street in a city. The sign has the words \"Bus Stop\" written on it in white letters, with an arrow pointing to the right. The background of the sign is blue and there are trees and buildings visible in the distance."}, "509719": {"image_id": 509719, "Bleu_1": 0.2727272727223141, "Bleu_2": 0.20100756304815393, "Bleu_3": 0.15620909290310706, "Bleu_4": 0.13085607656499973, "METEOR": 0.29361255158056365, "ROUGE_L": 0.25676488274203246, "CIDEr": 1.8260395672312977e-12, "SPICE": {"All": {"pr": 0.2, "re": 0.14814814814814814, "f": 0.1702127659574468, "fn": 23.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.36363636363636365, "f": 0.380952380952381, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "This is an image of a bird standing on the ground, looking up at something. The bird has a long, curved beak and is covered in feathers. It appears to be a young bird, as it has a small body and short legs. The background is a dirt road with some trees in the distance."}, "77400": {"image_id": 77400, "Bleu_1": 0.4193548386961499, "Bleu_2": 0.2896048475706757, "Bleu_3": 0.14247474403149546, "Bleu_4": 1.792725954943498e-05, "METEOR": 0.3322919387981395, "ROUGE_L": 0.3443085606773283, "CIDEr": 0.0020646897208194547, "SPICE": {"All": {"pr": 0.16, "re": 0.2, "f": 0.17777777777777778, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The man in the image is wearing a black tuxedo with a white shirt and bow tie. He is standing in front of a wooden door with a window on it."}, "207431": {"image_id": 207431, "Bleu_1": 0.370370370356653, "Bleu_2": 0.11935247900206675, "Bleu_3": 8.290377243671376e-07, "Bleu_4": 2.2073840969171685e-09, "METEOR": 0.24844505366890246, "ROUGE_L": 0.2946859903381643, "CIDEr": 0.01714962893457427, "SPICE": {"All": {"pr": 0.0625, "re": 0.045454545454545456, "f": 0.052631578947368425, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}}, "caption": "The image shows a pizza with various toppings, including mushrooms, onions, and cheese. There are also two glasses of wine on the table next to the pizza."}, "541813": {"image_id": 541813, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.07446639778133946, "Bleu_4": 9.43994412057466e-06, "METEOR": 0.17167506600553142, "ROUGE_L": 0.24110671936758893, "CIDEr": 1.9317585505127524e-11, "SPICE": {"All": {"pr": 0.23076923076923078, "re": 0.21428571428571427, "f": 0.22222222222222224, "fn": 22.0, "numImages": 1.0, "fp": 20.0, "tp": 6.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.45454545454545453, "f": 0.41666666666666663, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "This is a small, dimly lit room with a wooden table and chairs in the center. There are several paintings on the walls, including one of a woman in a green dress and another of a man holding a guitar. The room appears to be unfinished, with exposed concrete walls and a lack of furniture."}, "306582": {"image_id": 306582, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.15041420939612582, "Bleu_3": 0.0767719506444456, "Bleu_4": 9.802862511748142e-06, "METEOR": 0.15927123619241007, "ROUGE_L": 0.21131639722863746, "CIDEr": 1.0463591883338392e-10, "SPICE": {"All": {"pr": 0.15151515151515152, "re": 0.23809523809523808, "f": 0.18518518518518517, "fn": 16.0, "numImages": 1.0, "fp": 28.0, "tp": 5.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.1875, "re": 0.375, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 13.0, "tp": 3.0}}, "caption": "This is a small village with several houses made of wood and thatch. There are clothes hanging on a line in front of one of the houses, and a small path leads to the door. The surrounding trees are lush and green, and there is a small stream running through the area."}, "458223": {"image_id": 458223, "Bleu_1": 0.3255813953412656, "Bleu_2": 0.23294541396842086, "Bleu_3": 0.13833056672829191, "Bleu_4": 1.6038864534634092e-05, "METEOR": 0.23796774928195336, "ROUGE_L": 0.25505226480836235, "CIDEr": 2.586589962874528e-07, "SPICE": {"All": {"pr": 0.25925925925925924, "re": 0.3333333333333333, "f": 0.2916666666666667, "fn": 14.0, "numImages": 1.0, "fp": 20.0, "tp": 7.0}, "Relation": {"pr": 0.18181818181818182, "re": 0.2, "f": 0.1904761904761905, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.38461538461538464, "re": 0.5555555555555556, "f": 0.4545454545454546, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}}, "caption": "A man is walking along a pier with a red lighthouse in the background. The pier is made of wooden planks and there are rocks and seaweed on the ground. The sky is cloudy and there is a small boat in the water."}, "198397": {"image_id": 198397, "Bleu_1": 0.29411764705017307, "Bleu_2": 0.13351146745465192, "Bleu_3": 8.228027226970989e-07, "Bleu_4": 2.0588815727345863e-09, "METEOR": 0.17145946059668996, "ROUGE_L": 0.27618472683368545, "CIDEr": 0.0005423732911440652, "SPICE": {"All": {"pr": 0.32, "re": 0.2962962962962963, "f": 0.30769230769230765, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 8.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.18181818181818182, "f": 0.23529411764705885, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5454545454545454, "re": 0.6666666666666666, "f": 0.6, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}}, "caption": "The image shows a man playing tennis on a court. He is wearing a white shirt and shorts, and has a racket in his hand. There are several people watching him from the stands."}, "413551": {"image_id": 413551, "Bleu_1": 0.31249999999348965, "Bleu_2": 0.18233123936852927, "Bleu_3": 8.974042296560842e-07, "Bleu_4": 2.0018796078270936e-09, "METEOR": 0.26373635769111786, "ROUGE_L": 0.2459677419354839, "CIDEr": 6.518875288300753e-10, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.13636363636363635, "f": 0.12499999999999997, "fn": 19.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This image shows a table with various types of pastries and bread on it. There are several plates and cups on the table, as well as a few utensils such as forks and knives. The table is surrounded by chairs and there are some people sitting at it."}, "526622": {"image_id": 526622, "Bleu_1": 0.39393939392745647, "Bleu_2": 0.1921765286905374, "Bleu_3": 1.0600987725377332e-06, "Bleu_4": 2.5103220166185564e-09, "METEOR": 0.19820409763055358, "ROUGE_L": 0.25738396624472576, "CIDEr": 0.0008219370845337717, "SPICE": {"All": {"pr": 0.17857142857142858, "re": 0.3125, "f": 0.22727272727272727, "fn": 11.0, "numImages": 1.0, "fp": 23.0, "tp": 5.0}, "Relation": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.25, "f": 0.16666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "The image shows a bicycle parked next to a canal in a city. There are buildings on either side of the canal, with windows and balconies visible. The sky is clear and blue."}, "401850": {"image_id": 401850, "Bleu_1": 0.3636363636280992, "Bleu_2": 0.26010243549896195, "Bleu_3": 0.20044867222824783, "Bleu_4": 2.1052633193896276e-05, "METEOR": 0.2463988942078973, "ROUGE_L": 0.2924657534246575, "CIDEr": 4.181971349846295e-07, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.2857142857142857, "f": 0.3, "fn": 15.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5555555555555556, "re": 0.5555555555555556, "f": 0.5555555555555556, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}}, "caption": "The image shows a horse and carriage on the street in front of a large building. The building has tall windows and a clock tower on top. There are people walking on the sidewalk and cars driving by. The sky is clear and blue."}, "224368": {"image_id": 224368, "Bleu_1": 0.23076923076479294, "Bleu_2": 0.0951302988290515, "Bleu_3": 5.656605687724057e-07, "Bleu_4": 1.3863341114193003e-09, "METEOR": 0.148632615177758, "ROUGE_L": 0.17609699769053117, "CIDEr": 1.4620793287946333e-11, "SPICE": {"All": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 12.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.625, "re": 0.7142857142857143, "f": 0.6666666666666666, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 5.0}}, "caption": "This is an image of a person snowboarding down a hill. The person is wearing a helmet and gloves, and they are holding onto the handlebars of their snowboard as they ride down the hill. There are trees in the background, and the sky is cloudy with snow falling from the clouds."}, "552235": {"image_id": 552235, "Bleu_1": 0.30434782608034033, "Bleu_2": 0.2175844552512906, "Bleu_3": 0.1291053828237431, "Bleu_4": 1.4956884792307707e-05, "METEOR": 0.27690994899844956, "ROUGE_L": 0.24830393487109906, "CIDEr": 1.1512154160618677e-08, "SPICE": {"All": {"pr": 0.5714285714285714, "re": 0.2222222222222222, "f": 0.32, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2, "f": 0.33333333333333337, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.3, "f": 0.4, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "The living room is decorated for Christmas with a large tree in the center of the room. There are presents under the tree and a fireplace in the corner. The walls are painted a warm color and there are windows on either side of the room."}, "130043": {"image_id": 130043, "Bleu_1": 0.2647058823451558, "Bleu_2": 0.08956221510130578, "Bleu_3": 6.30521487401884e-07, "Bleu_4": 1.686298660670985e-09, "METEOR": 0.11194444656217054, "ROUGE_L": 0.20783645655877342, "CIDEr": 8.37690484350393e-05, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.15384615384615385, "f": 0.16666666666666669, "fn": 11.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.5, "f": 0.4444444444444445, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows two women standing in a living room, one holding a plate of food and the other holding a drink. They are both wearing casual clothing and appear to be enjoying themselves."}, "576449": {"image_id": 576449, "Bleu_1": 0.5294117646747406, "Bleu_2": 0.3638034375324306, "Bleu_3": 0.20663986647296506, "Bleu_4": 2.8175950488572184e-05, "METEOR": 0.2029469048218942, "ROUGE_L": 0.40720961281708945, "CIDEr": 0.2641010886899074, "SPICE": {"All": {"pr": 0.15789473684210525, "re": 0.15, "f": 0.15384615384615385, "fn": 17.0, "numImages": 1.0, "fp": 16.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2727272727272727, "f": 0.3, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a green bus parked in front of a building with people standing around it."}, "274678": {"image_id": 274678, "Bleu_1": 0.1692307692281657, "Bleu_2": 0.11498327637419221, "Bleu_3": 0.07487202886266836, "Bleu_4": 9.070720371351856e-06, "METEOR": 0.1572133548140691, "ROUGE_L": 0.21128154379020286, "CIDEr": 3.258552279362269e-19, "SPICE": {"All": {"pr": 0.26666666666666666, "re": 0.19047619047619047, "f": 0.2222222222222222, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.14285714285714285, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a giraffe standing in a grassy field surrounded by trees. The giraffe is looking down at the ground with its long neck stretched out in front of it. There are some small plants and flowers growing in the field, and a few birds can be seen flying overhead. The sky is clear and blue, with a few white clouds scattered across it."}, "573943": {"image_id": 573943, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.26940795303160764, "Bleu_3": 0.16913877793500667, "Bleu_4": 2.0210771490021534e-05, "METEOR": 0.22706251690896695, "ROUGE_L": 0.34659090909090906, "CIDEr": 0.0026311967427288317, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.15384615384615385, "f": 0.21621621621621623, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.23076923076923078, "f": 0.33333333333333337, "fn": 10.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is an image of a large parking lot with many trucks and cars parked in it. The parking lot is surrounded by buildings and there are people walking around the area."}, "515355": {"image_id": 515355, "Bleu_1": 0.2187499999931641, "Bleu_2": 0.11879774082410059, "Bleu_3": 7.777351060140797e-07, "Bleu_4": 2.006893275222866e-09, "METEOR": 0.1507994624681301, "ROUGE_L": 0.22426470588235295, "CIDEr": 0.0002903015418680937, "SPICE": {"All": {"pr": 0.045454545454545456, "re": 0.038461538461538464, "f": 0.04166666666666667, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.1111111111111111, "re": 0.1, "f": 0.10526315789473685, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}}, "caption": "This image shows a plate with a doughnut on it. The doughnut is topped with chocolate frosting and sprinkles. There is a fork on the plate, but no one is eating it."}, "559440": {"image_id": 559440, "Bleu_1": 0.3170731707239739, "Bleu_2": 0.23555849565513073, "Bleu_3": 0.14170580589433998, "Bleu_4": 0.09302396229560975, "METEOR": 0.27267350889891034, "ROUGE_L": 0.36771600803750837, "CIDEr": 2.0796062992539437e-05, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.18518518518518517, "f": 0.18518518518518517, "fn": 22.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.16666666666666666, "f": 0.14285714285714288, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.3333333333333333, "f": 0.3333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "The image shows a bathroom with a sink, toilet, and shower. The walls are painted white and there is a green tiled floor. There is a mirror on the wall above the sink and a window with curtains in the background."}, "511647": {"image_id": 511647, "Bleu_1": 0.305555555547068, "Bleu_2": 0.16183471873797783, "Bleu_3": 0.0916687886758685, "Bleu_4": 1.2360545409858299e-05, "METEOR": 0.16200169586873442, "ROUGE_L": 0.25416666666666665, "CIDEr": 0.00035921162303783336, "SPICE": {"All": {"pr": 0.75, "re": 0.23076923076923078, "f": 0.3529411764705882, "fn": 20.0, "numImages": 1.0, "fp": 2.0, "tp": 6.0}, "Relation": {"pr": 0.5, "re": 0.1, "f": 0.16666666666666669, "fn": 9.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2222222222222222, "f": 0.3636363636363636, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.75, "re": 0.42857142857142855, "f": 0.5454545454545454, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 3.0}}, "caption": "The image shows a man standing on a balcony with his hands up in the air, looking at something in the sky. There are several buildings in the background, and the sky is clear and blue."}, "356280": {"image_id": 356280, "Bleu_1": 0.24137931034066593, "Bleu_2": 0.06507476271754215, "Bleu_3": 4.2287536579724314e-07, "Bleu_4": 1.0828507894183901e-09, "METEOR": 0.1509433962264151, "ROUGE_L": 0.21852610030706246, "CIDEr": 1.7887477352660046e-12, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.24, "f": 0.24999999999999994, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.4166666666666667, "f": 0.4166666666666667, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The image shows a large room with tables set up for a meeting or conference. There are people sitting at the tables, some of them talking and others listening to a speaker at the front of the room. The walls are painted white and there are windows on one side of the room that let in natural light."}, "78465": {"image_id": 78465, "Bleu_1": 0.19999999999636367, "Bleu_2": 0.10540925533701173, "Bleu_3": 0.05940557542491761, "Bleu_4": 7.968371423587569e-06, "METEOR": 0.1378033606452062, "ROUGE_L": 0.17951736315479697, "CIDEr": 4.161579835561962e-13, "SPICE": {"All": {"pr": 0.4166666666666667, "re": 0.21739130434782608, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA white bus with the words \"City Bus\" written on the side is parked at the curb in front of a row of shops. The bus has a large windshield and a small driver's seat in the front. There are no passengers on the bus."}, "365511": {"image_id": 365511, "Bleu_1": 0.305555555547068, "Bleu_2": 0.18687063685519775, "Bleu_3": 0.10089455706733778, "Bleu_4": 1.3282270438373226e-05, "METEOR": 0.28657792290601525, "ROUGE_L": 0.2420634920634921, "CIDEr": 9.770865683643148e-05, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.14814814814814814, "f": 0.14545454545454545, "fn": 23.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.2727272727272727, "f": 0.23999999999999996, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "The image shows a street sign with the words \"Oakland\" written on it. The sign is mounted on a pole next to a tree. The sky is cloudy and there are some clouds in the background."}, "322511": {"image_id": 322511, "Bleu_1": 0.339622641503026, "Bleu_2": 0.1979576415927917, "Bleu_3": 0.09159212225374062, "Bleu_4": 1.1133996756281149e-05, "METEOR": 0.20637646693251363, "ROUGE_L": 0.226906385616863, "CIDEr": 2.7412941088358907e-11, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.30434782608695654, "f": 0.31818181818181823, "fn": 16.0, "numImages": 1.0, "fp": 14.0, "tp": 7.0}, "Relation": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows two horses racing down a dirt track, with one horse in the lead and the other following closely behind. The horses are wearing jockey caps and riding on the backs of their respective riders. The track is lined with fences and trees, and there are people watching from the stands."}, "477924": {"image_id": 477924, "Bleu_1": 0.35483870966597303, "Bleu_2": 0.21751282250452736, "Bleu_3": 0.11772189470040113, "Bleu_4": 1.5536508417020945e-05, "METEOR": 0.1793001595944871, "ROUGE_L": 0.2775250227479527, "CIDEr": 0.000486840368019825, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.19230769230769232, "f": 0.2, "fn": 21.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.25, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a young girl standing on a snowy slope, wearing a blue and white jacket and holding ski poles. She is smiling and appears to be enjoying the snow."}, "469634": {"image_id": 469634, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.20597146021314577, "Bleu_3": 0.14357835226443494, "Bleu_4": 0.10895869675460172, "METEOR": 0.26261980588989065, "ROUGE_L": 0.28073635765943455, "CIDEr": 1.0682196148580732e-07, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.08333333333333333, "f": 0.1142857142857143, "fn": 22.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a young man riding a skateboard down a road lined with trees. He is wearing a black shirt and jeans, and has his arms outstretched as he jumps off the board. The sky is blue and there are clouds in the background."}, "251343": {"image_id": 251343, "Bleu_1": 0.35555555554765433, "Bleu_2": 0.23783535599888, "Bleu_3": 0.13805054457255134, "Bleu_4": 1.5820356672588363e-05, "METEOR": 0.28117141375359483, "ROUGE_L": 0.28073635765943455, "CIDEr": 3.693876922731223e-07, "SPICE": {"All": {"pr": 0.1, "re": 0.09090909090909091, "f": 0.09523809523809525, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.3333333333333333, "f": 0.26666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is a kitchen with white cabinets and a black stove. There are no appliances in the kitchen, but there is a microwave on the counter. The floor is made of hardwood and there is a window on one wall that lets in natural light."}, "49682": {"image_id": 49682, "Bleu_1": 0.7857142856581634, "Bleu_2": 0.6504436355397438, "Bleu_3": 0.5205143345346209, "Bleu_4": 0.4001601601599777, "METEOR": 0.3747557453386353, "ROUGE_L": 0.6240409207161125, "CIDEr": 2.0502456167402285, "SPICE": {"All": {"pr": 0.375, "re": 0.24, "f": 0.2926829268292683, "fn": 19.0, "numImages": 1.0, "fp": 10.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.16666666666666666, "f": 0.26666666666666666, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.42857142857142855, "f": 0.42857142857142855, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a woman wearing an umbrella and holding a box of chicken."}, "324155": {"image_id": 324155, "Bleu_1": 0.23636363635933888, "Bleu_2": 0.14793756076371775, "Bleu_3": 0.07446639778133946, "Bleu_4": 9.43994412057466e-06, "METEOR": 0.20256084072012873, "ROUGE_L": 0.18340348767288037, "CIDEr": 1.0494530887029639e-13, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.11764705882352941, "f": 0.12903225806451615, "fn": 30.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a person doing a trick on a skateboard in the middle of a city street. The person is wearing a black shirt and pants, and has their arms outstretched as they jump off the ground. There are several people watching from the sidewalk, and there are buildings in the background."}, "467096": {"image_id": 467096, "Bleu_1": 0.3030303030211204, "Bleu_2": 0.19462473603439093, "Bleu_3": 0.13469602876696646, "Bleu_4": 0.09500266321174516, "METEOR": 0.3503707228495226, "ROUGE_L": 0.37162750217580504, "CIDEr": 0.001201072565913862, "SPICE": {"All": {"pr": 0.3, "re": 0.10344827586206896, "f": 0.15384615384615385, "fn": 26.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6, "re": 0.2727272727272727, "f": 0.37499999999999994, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 3.0}}, "caption": "This is a small dining room with a table and chairs. There are two stuffed bears sitting on the table. The walls are painted white and there are some windows in the background."}, "91349": {"image_id": 91349, "Bleu_1": 0.33928571427965565, "Bleu_2": 0.2604940361211699, "Bleu_3": 0.2064270549346078, "Bleu_4": 0.16051698467281286, "METEOR": 0.2692963079522758, "ROUGE_L": 0.31031976744186046, "CIDEr": 7.873119337589028e-10, "SPICE": {"All": {"pr": 0.3, "re": 0.0967741935483871, "f": 0.14634146341463414, "fn": 28.0, "numImages": 1.0, "fp": 7.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.1, "f": 0.18181818181818182, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.15384615384615385, "f": 0.2222222222222222, "fn": 11.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a group of people standing on a baseball field, watching a man in a wheelchair throw a ball. The man in the wheelchair is wearing a baseball cap and has his arm extended to throw the ball. The people standing around him are wearing baseball uniforms and have their arms raised in excitement."}, "32992": {"image_id": 32992, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.15430334995774453, "Bleu_3": 8.880224204971932e-07, "Bleu_4": 2.1462952437294962e-09, "METEOR": 0.2211868365958956, "ROUGE_L": 0.2420634920634921, "CIDEr": 1.7484406551954212e-05, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.05, "f": 0.0625, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.125, "re": 0.14285714285714285, "f": 0.13333333333333333, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}}, "caption": "This is a wooden bowl with a cross design on it. The bowl has a round shape and is made of wood. It has a smooth finish and the cross design is carved into the wood."}, "310227": {"image_id": 310227, "Bleu_1": 0.4399999999824001, "Bleu_2": 0.3027650353973863, "Bleu_3": 0.15854815808014064, "Bleu_4": 2.0630760173659833e-05, "METEOR": 0.2219077074276681, "ROUGE_L": 0.33406352683461116, "CIDEr": 0.05527067002969255, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.24, "f": 0.3157894736842105, "fn": 19.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.5, "f": 0.5714285714285715, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "The image shows a person lying in bed with their head covered by a pillow. There are stuffed animals on the bed next to them."}, "573206": {"image_id": 573206, "Bleu_1": 0.378378378368152, "Bleu_2": 0.20504156173746327, "Bleu_3": 1.063013025006301e-06, "Bleu_4": 2.43800285681619e-09, "METEOR": 0.14012172584390997, "ROUGE_L": 0.26139122982431084, "CIDEr": 6.90741911967177e-05, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.12, "f": 0.13953488372093023, "fn": 22.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3, "f": 0.33333333333333326, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is an image of a dish made with olives and cheese. The dish is on a countertop next to a stove. There are several utensils, including a spatula and a whisk, on the countertop as well."}, "576939": {"image_id": 576939, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.3098662125759413, "Bleu_3": 0.22014152945079551, "Bleu_4": 0.17389607800310708, "METEOR": 0.2329262488320174, "ROUGE_L": 0.3024079320113314, "CIDEr": 0.00010474414807736687, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.21212121212121213, "f": 0.23728813559322037, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 13.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4666666666666667, "re": 0.4666666666666667, "f": 0.4666666666666667, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 7.0}}, "caption": "This image shows a group of scissors hanging on a wall. The scissors are made of metal and have sharp blades. They are arranged in a row on the wall, with each one labeled with a different name."}, "479213": {"image_id": 479213, "Bleu_1": 0.32499999999187507, "Bleu_2": 0.2236067977443172, "Bleu_3": 0.13806135595480482, "Bleu_4": 0.09183403564889472, "METEOR": 0.3032025780084087, "ROUGE_L": 0.3588235294117647, "CIDEr": 2.3684967498000106e-06, "SPICE": {"All": {"pr": 0.25, "re": 0.13043478260869565, "f": 0.1714285714285714, "fn": 20.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.2, "re": 0.125, "f": 0.15384615384615385, "fn": 7.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.2857142857142857, "f": 0.30769230769230765, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "The image shows two women standing next to a cake with a photo on it. One of the women is holding a camera and smiling at the other woman, who is also smiling. They are both wearing wigs and dresses."}, "45094": {"image_id": 45094, "Bleu_1": 0.2745098039161861, "Bleu_2": 0.20957473279408317, "Bleu_3": 0.15305490466093202, "Bleu_4": 0.12235041385584791, "METEOR": 0.2454902988341397, "ROUGE_L": 0.26704190118824267, "CIDEr": 2.0523837710803104e-11, "SPICE": {"All": {"pr": 0.4, "re": 0.2, "f": 0.26666666666666666, "fn": 24.0, "numImages": 1.0, "fp": 9.0, "tp": 6.0}, "Relation": {"pr": 0.2, "re": 0.08333333333333333, "f": 0.11764705882352941, "fn": 11.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.4166666666666667, "f": 0.5263157894736842, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a man and a woman sitting at a table in a restaurant, both holding glasses of wine. The man is wearing a black hat and the woman is wearing a white shirt and black pants. There are other people in the background of the image, also drinking wine."}, "127517": {"image_id": 127517, "Bleu_1": 0.17187499999731448, "Bleu_2": 0.10446386175302294, "Bleu_3": 5.604198220001128e-07, "Bleu_4": 1.3033247937689006e-09, "METEOR": 0.20018616822732457, "ROUGE_L": 0.21587462082912032, "CIDEr": 7.583179730589031e-17, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.1, "f": 0.12121212121212123, "fn": 18.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.2222222222222222, "f": 0.2857142857142857, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a group of surfboards leaning against a wooden fence in front of a beach. The surfboards are all different colors and have various designs on them, such as stripes, polka dots, and floral patterns. Some of the surfboards have umbrellas on top of them, while others do not. The background is a sandy beach with palm trees and a blue sky."}, "504732": {"image_id": 504732, "Bleu_1": 0.16494845360654692, "Bleu_2": 0.10966992025476004, "Bleu_3": 0.05021311339265519, "Bleu_4": 6.058022738651276e-06, "METEOR": 0.19441565164022898, "ROUGE_L": 0.1901063566658422, "CIDEr": 4.470029644067878e-42, "SPICE": {"All": {"pr": 0.3125, "re": 0.4, "f": 0.3508771929824561, "fn": 15.0, "numImages": 1.0, "fp": 22.0, "tp": 10.0}, "Relation": {"pr": 0.1, "re": 0.125, "f": 0.11111111111111112, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.6363636363636364, "f": 0.56, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 7.0}}, "caption": "The woman in the image is wearing a black coat and holding a phone to her ear. She is standing on the sidewalk in front of a group of people who are also wearing costumes. There are bicycles parked along the sidewalk.\n\nThe woman's face is painted with a red nose and she has a black hat on her head. She is smiling and talking on the phone. The people around her are also smiling and some of them are taking pictures of each other. The streetlights are on and there are buildings in the background."}, "86215": {"image_id": 86215, "Bleu_1": 0.35087719297630043, "Bleu_2": 0.23746784506878557, "Bleu_3": 0.14543068929524094, "Bleu_4": 0.08687475782560027, "METEOR": 0.24278000611045766, "ROUGE_L": 0.2492702860478692, "CIDEr": 2.5935563688885267e-12, "SPICE": {"All": {"pr": 0.3125, "re": 0.20833333333333334, "f": 0.25, "fn": 19.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.16666666666666666, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5, "re": 0.4444444444444444, "f": 0.47058823529411764, "fn": 5.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a dog lying on a bed next to a cat. The dog is looking directly at the camera with its brown eyes, while the cat is looking away from the camera with its green eyes. The background of the image is a messy room with a window open and curtains blowing in the wind."}, "82180": {"image_id": 82180, "Bleu_1": 0.6999999998600002, "Bleu_2": 0.5577733509080639, "Bleu_3": 0.33879878553311354, "Bleu_4": 4.854917716006407e-05, "METEOR": 0.33750272502130596, "ROUGE_L": 0.4178082191780822, "CIDEr": 1.454049704265909, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.18181818181818182, "f": 0.15384615384615383, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.5, "f": 0.4, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}}, "caption": "A wooden chair with a stuffed animal sitting on it."}, "253835": {"image_id": 253835, "Bleu_1": 0.2857142857074831, "Bleu_2": 0.20447945297237122, "Bleu_3": 0.12786640387212753, "Bleu_4": 1.5216024071655628e-05, "METEOR": 0.23538745729952135, "ROUGE_L": 0.2279521674140508, "CIDEr": 4.1543152964800296e-07, "SPICE": {"All": {"pr": 0.2608695652173913, "re": 0.375, "f": 0.30769230769230765, "fn": 10.0, "numImages": 1.0, "fp": 17.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Object": {"pr": 0.4, "re": 0.6666666666666666, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "A woman is standing on the platform of a train station, looking at a train that is pulling into the station. The train has a red and white striped body and black wheels. There are buildings in the background of the image."}, "91406": {"image_id": 91406, "Bleu_1": 0.49999999998076927, "Bleu_2": 0.4242640686952843, "Bleu_3": 0.2823108086530041, "Bleu_4": 3.1449494590736615e-05, "METEOR": 0.3027775902414319, "ROUGE_L": 0.4782973956874825, "CIDEr": 0.03142336348832728, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.26666666666666666, "f": 0.2424242424242424, "fn": 11.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.2, "f": 0.16666666666666666, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.42857142857142855, "f": 0.39999999999999997, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "This is a group of people standing in front of a table with pizza boxes on it. They are all smiling and looking at the camera."}, "252133": {"image_id": 252133, "Bleu_1": 0.5999999999700001, "Bleu_2": 0.5026246899242421, "Bleu_3": 0.3478928170795551, "Bleu_4": 0.22308576864951288, "METEOR": 0.25433326430473235, "ROUGE_L": 0.4765625, "CIDEr": 0.3899051992593908, "SPICE": {"All": {"pr": 0.32142857142857145, "re": 0.42857142857142855, "f": 0.3673469387755102, "fn": 12.0, "numImages": 1.0, "fp": 19.0, "tp": 9.0}, "Relation": {"pr": 0.1, "re": 0.16666666666666666, "f": 0.125, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.8, "re": 0.5, "f": 0.6153846153846154, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5714285714285714, "f": 0.4, "fn": 3.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "This is an image of a sign on the side of the road that reads, \"No parking for senior citizens.\""}, "533137": {"image_id": 533137, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.16658955971162087, "Bleu_3": 8.511922922355496e-07, "Bleu_4": 1.9348958476953622e-09, "METEOR": 0.17608804402201098, "ROUGE_L": 0.23297262889879056, "CIDEr": 1.263529003188756e-09, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.10344827586206896, "f": 0.10526315789473684, "fn": 26.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.23076923076923078, "f": 0.22222222222222224, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This image shows a group of people standing at the base of a mountain, looking up at the snow covered peaks. There is a sign in the foreground that reads \"ski resort\". The sky is cloudy and there is a light dusting of snow on the ground."}, "580704": {"image_id": 580704, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.2236067977408484, "Bleu_3": 0.12954303153373917, "Bleu_4": 1.772984226393885e-05, "METEOR": 0.20544931699884972, "ROUGE_L": 0.3715736040609137, "CIDEr": 0.0313825396344425, "SPICE": {"All": {"pr": 0.8333333333333334, "re": 0.20833333333333334, "f": 0.33333333333333337, "fn": 19.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}, "Relation": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.15384615384615385, "f": 0.2666666666666667, "fn": 11.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A group of motorcyclists ride down a winding road in a park on a sunny day.\""}, "359086": {"image_id": 359086, "Bleu_1": 0.22368421052337256, "Bleu_2": 0.16383560437965497, "Bleu_3": 0.10285735923711141, "Bleu_4": 0.07389300212150142, "METEOR": 0.20500279301459123, "ROUGE_L": 0.2563025210084034, "CIDEr": 4.0837875238033704e-23, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.17391304347826086, "f": 0.15094339622641512, "fn": 19.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.4444444444444444, "f": 0.3636363636363637, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "Sure, here is a short caption for the image:\n\nA black motorcycle is parked in front of a large building with a blue and white striped awning. The building has a sign that reads \"Welcome to the Harley Davidson Museum\" in red letters. There are several other motorcycles parked nearby, and a person is standing next to one of them, looking at their phone. The sky is clear and sunny, with a few clouds scattered about."}, "581205": {"image_id": 581205, "Bleu_1": 0.3947368420948754, "Bleu_2": 0.27327631272580527, "Bleu_3": 0.1839391791659364, "Bleu_4": 2.0534714635877452e-05, "METEOR": 0.2500381289156741, "ROUGE_L": 0.295638126009693, "CIDEr": 2.2773659129923402e-05, "SPICE": {"All": {"pr": 0.18518518518518517, "re": 0.22727272727272727, "f": 0.20408163265306123, "fn": 17.0, "numImages": 1.0, "fp": 22.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.625, "f": 0.5555555555555556, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a table with three plates of food on it. There are two plates with eggs and bacon, and one plate with pancakes and maple syrup. There is also a cup of coffee on the table."}, "171050": {"image_id": 171050, "Bleu_1": 0.4411764705752596, "Bleu_2": 0.2585438449897902, "Bleu_3": 0.18436560134874677, "Bleu_4": 0.11923932180662465, "METEOR": 0.2864223858678465, "ROUGE_L": 0.33622047244094483, "CIDEr": 0.0009522550994189439, "SPICE": {"All": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 18.0, "numImages": 1.0, "fp": 16.0, "tp": 4.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.2, "f": 0.20000000000000004, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.2222222222222222, "re": 0.25, "f": 0.23529411764705882, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "This is an old fire hydrant on the side of a brick building. The hydrant has a large, rusty handle and a small spout on top. There are no other objects in the image."}, "509404": {"image_id": 509404, "Bleu_1": 0.18749999999707034, "Bleu_2": 0.16366341767441678, "Bleu_3": 0.12000256010732703, "Bleu_4": 0.07295590089539716, "METEOR": 0.1972313443188957, "ROUGE_L": 0.15561224489795916, "CIDEr": 2.8202269918182503e-18, "SPICE": {"All": {"pr": 0.6428571428571429, "re": 0.28125, "f": 0.391304347826087, "fn": 23.0, "numImages": 1.0, "fp": 5.0, "tp": 9.0}, "Relation": {"pr": 0.25, "re": 0.09090909090909091, "f": 0.13333333333333333, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.7142857142857143, "re": 0.5555555555555556, "f": 0.6250000000000001, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows a train traveling down the tracks on the left side of the image, while another train is parked on the right side. The train on the left has a blue and yellow livery, while the one on the right has a red and white livery. There are buildings in the background of the image, with windows and doors visible on them."}, "407083": {"image_id": 407083, "Bleu_1": 0.31147540983095945, "Bleu_2": 0.19062737949467357, "Bleu_3": 0.10719705309345501, "Bleu_4": 0.06788598698017166, "METEOR": 0.2574844021984323, "ROUGE_L": 0.24485699949824388, "CIDEr": 1.8099858413948365e-13, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.2608695652173913, "f": 0.33333333333333337, "fn": 17.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.14285714285714285, "f": 0.22222222222222224, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8333333333333334, "re": 0.625, "f": 0.7142857142857143, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 5.0}}, "caption": "The image shows a man sitting in the back of a pickup truck with his dog sitting on the passenger seat. The man is wearing a red shirt and sunglasses, while the dog is wearing a blue collar and looking up at him. The truck is parked in front of a house with a white fence and trees in the background."}, "214447": {"image_id": 214447, "Bleu_1": 0.29824561402985533, "Bleu_2": 0.1264019129936606, "Bleu_3": 6.62290005598477e-07, "Bleu_4": 1.5229572441258354e-09, "METEOR": 0.18955179464090885, "ROUGE_L": 0.17438536306460833, "CIDEr": 7.330540839952502e-15, "SPICE": {"All": {"pr": 0.03225806451612903, "re": 0.09090909090909091, "f": 0.047619047619047616, "fn": 10.0, "numImages": 1.0, "fp": 30.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.07142857142857142, "re": 0.2, "f": 0.10526315789473682, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 1.0}}, "caption": "This is an image of a person snowboarding down a snowy hill. The person is wearing a black and white snowboarding suit, goggles, and gloves. They are standing on the board with their arms outstretched and their feet strapped to the board. The snow around them is deep and powdery, and there are trees in the background."}, "567390": {"image_id": 567390, "Bleu_1": 0.38461538460552275, "Bleu_2": 0.28455519660484385, "Bleu_3": 0.1635763216609011, "Bleu_4": 0.10500614219604798, "METEOR": 0.2706244197512065, "ROUGE_L": 0.37223493516399697, "CIDEr": 5.26609659882916e-06, "SPICE": {"All": {"pr": 0.08695652173913043, "re": 0.1, "f": 0.09302325581395349, "fn": 18.0, "numImages": 1.0, "fp": 21.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.3333333333333333, "f": 0.2222222222222222, "fn": 4.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This image shows a plate of food with broccoli, carrots, and rice on it. The dish is topped with a sauce made from soy sauce, butter, and cream. The plate is on a white marble countertop in a kitchen."}, "7873": {"image_id": 7873, "Bleu_1": 0.23684210525692528, "Bleu_2": 0.11314714295768938, "Bleu_3": 7.084810326519695e-07, "Bleu_4": 1.7853738103300445e-09, "METEOR": 0.184368942237325, "ROUGE_L": 0.30112834978843445, "CIDEr": 9.660539992015849e-05, "SPICE": {"All": {"pr": 0.2692307692307692, "re": 0.2916666666666667, "f": 0.27999999999999997, "fn": 17.0, "numImages": 1.0, "fp": 19.0, "tp": 7.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.125, "f": 0.125, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5555555555555556, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "Sure, here is a short caption for the image:\n\nThe woman in the image is smiling and looking at something on her phone while walking down the street. There are other people in the background shopping and socializing."}, "576463": {"image_id": 576463, "Bleu_1": 0.4999999999821429, "Bleu_2": 0.27216552696600854, "Bleu_3": 0.1417634567557415, "Bleu_4": 1.8373344524129676e-05, "METEOR": 0.2712321179602277, "ROUGE_L": 0.37720848056537104, "CIDEr": 0.017181766756347423, "SPICE": {"All": {"pr": 0.05263157894736842, "re": 0.1, "f": 0.06896551724137931, "fn": 18.0, "numImages": 1.0, "fp": 36.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "The image is a magazine cover featuring a soccer player in blue and white uniform, with the words \"Chelsea FC\" written in bold black letters at the top."}, "282680": {"image_id": 282680, "Bleu_1": 0.6249999999609376, "Bleu_2": 0.5400617248324427, "Bleu_3": 0.2751606040561537, "Bleu_4": 3.557982867691925e-05, "METEOR": 0.2918120536013436, "ROUGE_L": 0.49087982832618027, "CIDEr": 0.614524291609022, "SPICE": {"All": {"pr": 0.46153846153846156, "re": 0.2727272727272727, "f": 0.3428571428571428, "fn": 16.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.8333333333333334, "f": 0.7692307692307692, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "A surfer rides a wave on a lake, with the water and sky in the background."}, "488386": {"image_id": 488386, "Bleu_1": 0.7999999998400004, "Bleu_2": 0.6666666665296299, "Bleu_3": 0.4807498566671996, "Bleu_4": 0.35494810552300854, "METEOR": 0.31743352242512857, "ROUGE_L": 0.6, "CIDEr": 2.0242780589191085, "SPICE": {"All": {"pr": 0.3125, "re": 0.22727272727272727, "f": 0.2631578947368421, "fn": 17.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The cat is sleeping on top of a laptop computer."}, "293002": {"image_id": 293002, "Bleu_1": 0.2608695652117203, "Bleu_2": 0.17025130614800751, "Bleu_3": 0.08701138391057635, "Bleu_4": 1.1125382292156774e-05, "METEOR": 0.193301430099453, "ROUGE_L": 0.24238410596026488, "CIDEr": 5.949248101930497e-08, "SPICE": {"All": {"pr": 0.25, "re": 0.2857142857142857, "f": 0.26666666666666666, "fn": 15.0, "numImages": 1.0, "fp": 18.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.6666666666666666, "re": 1.0, "f": 0.8, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a woman standing on the sidewalk holding an umbrella. She is wearing a pink dress and has a white scarf around her neck. There are several buildings in the background, including a small restaurant with a sign that reads \"Cafe\" in Chinese characters."}, "105974": {"image_id": 105974, "Bleu_1": 0.16393442622682078, "Bleu_2": 0.09053574604102199, "Bleu_3": 5.179200443176849e-07, "Bleu_4": 1.2440563176037333e-09, "METEOR": 0.1907177155377743, "ROUGE_L": 0.16180371352785144, "CIDEr": 1.5664717112927123e-17, "SPICE": {"All": {"pr": 0.16, "re": 0.19047619047619047, "f": 0.17391304347826086, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.375, "f": 0.35294117647058826, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a man playing handball in an indoor court. He is wearing a red shirt and white shorts, and has his arms outstretched as he jumps to hit the ball with his hand. The court is made of wood and has lines on it for the players to follow. There are spectators seated in the stands watching the game."}, "274399": {"image_id": 274399, "Bleu_1": 0.2857142857061225, "Bleu_2": 0.12964074470667444, "Bleu_3": 7.985884624255978e-07, "Bleu_4": 1.9973527828806605e-09, "METEOR": 0.23492923274531574, "ROUGE_L": 0.2543786488740617, "CIDEr": 5.76923149643226e-05, "SPICE": {"All": {"pr": 0.25, "re": 0.30434782608695654, "f": 0.27450980392156865, "fn": 16.0, "numImages": 1.0, "fp": 21.0, "tp": 7.0}, "Relation": {"pr": 0.1, "re": 0.1111111111111111, "f": 0.10526315789473685, "fn": 8.0, "numImages": 1.0, "fp": 9.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5, "f": 0.48000000000000004, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "The image shows two elephants standing in a jungle clearing, surrounded by trees and foliage. One of the elephants is riding on the back of the other, both with their trunks raised in the air."}, "91267": {"image_id": 91267, "Bleu_1": 0.5357142856951531, "Bleu_2": 0.34503277965862633, "Bleu_3": 0.23949118904326894, "Bleu_4": 0.1531024544060367, "METEOR": 0.31527700719281454, "ROUGE_L": 0.4121621621621622, "CIDEr": 0.06086723992628772, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.18181818181818182, "f": 0.16666666666666669, "fn": 18.0, "numImages": 1.0, "fp": 22.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.36363636363636365, "re": 0.4444444444444444, "f": 0.39999999999999997, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}}, "caption": "This is a living room with black couches, a coffee table, and a television. There are no people in the room, but there are books on the bookshelf."}, "115791": {"image_id": 115791, "Bleu_1": 0.333333333325926, "Bleu_2": 0.23028309323074364, "Bleu_3": 0.15466509142805826, "Bleu_4": 0.09687950349169154, "METEOR": 0.272954092584186, "ROUGE_L": 0.32635903315181036, "CIDEr": 1.5776190236418632e-06, "SPICE": {"All": {"pr": 0.2, "re": 0.3, "f": 0.24, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 6.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.25, "f": 0.1904761904761905, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.26666666666666666, "re": 0.5, "f": 0.3478260869565218, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 4.0}}, "caption": "This is an image of a baseball player at the plate, holding a bat and ready to swing. The player is wearing a white jersey with black pants and black cleats. The background is a green field with a dirt infield and a blue sky."}, "135680": {"image_id": 135680, "Bleu_1": 0.6666666666419753, "Bleu_2": 0.5063696835227183, "Bleu_3": 0.3948046067345145, "Bleu_4": 0.29615165358952633, "METEOR": 0.30753259282712503, "ROUGE_L": 0.41256038647342996, "CIDEr": 0.10964852832558775, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.15384615384615385, "f": 0.21052631578947367, "fn": 22.0, "numImages": 1.0, "fp": 8.0, "tp": 4.0}, "Relation": {"pr": 0.2, "re": 0.1, "f": 0.13333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.375, "f": 0.42857142857142855, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a vase with a red flower in it sitting on a windowsill. The window is covered with lace curtains, and there is snow outside."}, "197528": {"image_id": 197528, "Bleu_1": 0.2419354838670656, "Bleu_2": 0.17812704394707876, "Bleu_3": 0.11662990143983855, "Bleu_4": 0.0720102682183652, "METEOR": 0.21797720435277804, "ROUGE_L": 0.24182358771060455, "CIDEr": 8.118013945482872e-16, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 18.0, "numImages": 1.0, "fp": 15.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.14285714285714285, "f": 0.15384615384615383, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2857142857142857, "re": 0.25, "f": 0.26666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.375, "re": 0.3333333333333333, "f": 0.35294117647058826, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}}, "caption": "The image shows a gray and white cat sitting on the windowsill of a house. The cat is looking out the window with its eyes closed, seemingly lost in thought. The window is open, allowing fresh air to enter the room. The cat's fur is fluffy and well groomed, and it appears to be enjoying the sunlight streaming through the window."}, "292485": {"image_id": 292485, "Bleu_1": 0.3111111111041976, "Bleu_2": 0.20597146021314577, "Bleu_3": 0.12542724369723712, "Bleu_4": 0.08279070605623677, "METEOR": 0.2168617733548366, "ROUGE_L": 0.28073635765943455, "CIDEr": 4.357411436767938e-08, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.23809523809523808, "f": 0.2631578947368421, "fn": 16.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.2, "f": 0.28571428571428575, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3333333333333333, "f": 0.4, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a man standing on skis, holding a flag in his hand. He is wearing a red shirt and blue pants, and has a determined look on his face. The background is a snowy mountain slope with trees in the distance."}, "45721": {"image_id": 45721, "Bleu_1": 0.3953488372001082, "Bleu_2": 0.32178213603889433, "Bleu_3": 0.24745548504430984, "Bleu_4": 0.18360653274385214, "METEOR": 0.3128005090545071, "ROUGE_L": 0.3400696864111499, "CIDEr": 2.358171910671924e-07, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.16666666666666666, "f": 0.13636363636363638, "fn": 15.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.16666666666666666, "f": 0.16666666666666666, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.2857142857142857, "f": 0.23529411764705882, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a cat sitting on top of a computer keyboard, looking up at the camera. The cat is brown and has a white patch on its forehead. There are papers and other office supplies on the desk next to the cat."}, "157657": {"image_id": 157657, "Bleu_1": 0.22413793103061835, "Bleu_2": 0.20797761524680117, "Bleu_3": 0.17551506547154064, "Bleu_4": 0.1488975764674337, "METEOR": 0.2561701864178274, "ROUGE_L": 0.2973997833152763, "CIDEr": 6.306962902142541e-14, "SPICE": {"All": {"pr": 0.11538461538461539, "re": 0.17647058823529413, "f": 0.13953488372093026, "fn": 14.0, "numImages": 1.0, "fp": 23.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.375, "f": 0.3157894736842105, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a group of people riding on the back of an elephant through a jungle. The elephant is wearing a saddle and the people are sitting on its back, holding onto the sides for support. The jungle is filled with trees and greenery, and there are other animals in the background, such as monkeys and birds."}, "494566": {"image_id": 494566, "Bleu_1": 0.18644067796294173, "Bleu_2": 0.13887752404723028, "Bleu_3": 0.10050093675833767, "Bleu_4": 0.06525000895100286, "METEOR": 0.1617141187731994, "ROUGE_L": 0.20344635908838243, "CIDEr": 2.227363142652641e-16, "SPICE": {"All": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 28.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.2, "f": 0.27272727272727276, "fn": 12.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "This is an image of a person skiing down a snowy hill. The person is wearing black and white clothing and has a red and black helmet on their head. They are holding onto a pair of skis with black and yellow bindings and are wearing black gloves. The background is a snowy landscape with trees in the distance."}, "46345": {"image_id": 46345, "Bleu_1": 0.2777777777700618, "Bleu_2": 0.2672612419048945, "Bleu_3": 0.24499865250781863, "Bleu_4": 0.22739562220170637, "METEOR": 0.366572239001113, "ROUGE_L": 0.4236111111111111, "CIDEr": 0.00047006211935439197, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.2631578947368421, "f": 0.20833333333333334, "fn": 14.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.5, "f": 0.47619047619047616, "fn": 5.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "This is a black and white image of a dog sitting on a bench in front of some pink flowers. The dog is looking up at the camera with its tongue hanging out of its mouth."}, "403177": {"image_id": 403177, "Bleu_1": 0.6874999999570314, "Bleu_2": 0.3708099243308351, "Bleu_3": 0.21415335740369643, "Bleu_4": 2.948206012282362e-05, "METEOR": 0.27834380497358935, "ROUGE_L": 0.505524861878453, "CIDEr": 0.43375183485656443, "SPICE": {"All": {"pr": 0.4117647058823529, "re": 0.2413793103448276, "f": 0.3043478260869565, "fn": 22.0, "numImages": 1.0, "fp": 10.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2727272727272727, "f": 0.42857142857142855, "fn": 8.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "This is an image of a chicken sandwich with lettuce, tomato, and cheese on a bun."}, "147721": {"image_id": 147721, "Bleu_1": 0.23333333332944448, "Bleu_2": 0.1886616557167528, "Bleu_3": 0.14531254128144008, "Bleu_4": 0.1127298484678521, "METEOR": 0.21753851667242224, "ROUGE_L": 0.22736954206602766, "CIDEr": 1.5741140743769872e-14, "SPICE": {"All": {"pr": 0.5, "re": 0.15384615384615385, "f": 0.23529411764705882, "fn": 22.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.07692307692307693, "f": 0.13333333333333336, "fn": 12.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.25, "f": 0.36363636363636365, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "The image shows a person surfing on a wave in the ocean. The person is wearing a wetsuit and standing on a surfboard, holding onto the handlebars with one hand and paddling with the other. The water is choppy and there are waves crashing against the shore. In the background, there is a mountain range with trees and houses visible."}, "229111": {"image_id": 229111, "Bleu_1": 0.49805493606340595, "Bleu_2": 0.3015872407051041, "Bleu_3": 2.097493871297004e-06, "Bleu_4": 5.696822650199491e-09, "METEOR": 0.2825207150661588, "ROUGE_L": 0.4803149606299213, "CIDEr": 0.8978163044113213, "SPICE": {"All": {"pr": 0.2777777777777778, "re": 0.19230769230769232, "f": 0.2272727272727273, "fn": 21.0, "numImages": 1.0, "fp": 13.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.14285714285714285, "f": 0.14285714285714285, "fn": 6.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.1, "f": 0.14285714285714288, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.3333333333333333, "f": 0.375, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The boy is holding a white game controller in his hand."}, "327917": {"image_id": 327917, "Bleu_1": 0.39999999998400004, "Bleu_2": 0.1825741858276003, "Bleu_3": 1.1316626169059293e-06, "Bleu_4": 2.8489318276508903e-09, "METEOR": 0.17092823559025488, "ROUGE_L": 0.2571127502634352, "CIDEr": 0.010757527928199683, "SPICE": {"All": {"pr": 0.25, "re": 0.10714285714285714, "f": 0.15, "fn": 25.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A group of people are kite surfing in the ocean with the sky in the background.\""}, "496264": {"image_id": 496264, "Bleu_1": 0.21568627450557482, "Bleu_2": 0.14686261420159358, "Bleu_3": 0.0958411776672495, "Bleu_4": 0.06544158309931196, "METEOR": 0.20882241352597014, "ROUGE_L": 0.24497991967871488, "CIDEr": 1.9596548230393825e-10, "SPICE": {"All": {"pr": 0.5454545454545454, "re": 0.20689655172413793, "f": 0.3, "fn": 23.0, "numImages": 1.0, "fp": 5.0, "tp": 6.0}, "Relation": {"pr": 0.25, "re": 0.14285714285714285, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.09090909090909091, "f": 0.16666666666666669, "fn": 10.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.36363636363636365, "f": 0.4705882352941177, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA giraffe stands in front of a rocky outcropping, looking out into the distance. Its long neck and legs are visible as it stands on its hind legs. The sun shines down on its back, casting a warm glow over its fur."}, "492282": {"image_id": 492282, "Bleu_1": 0.29629629629080934, "Bleu_2": 0.18314741859482844, "Bleu_3": 0.10886194393769152, "Bleu_4": 0.0709193129947971, "METEOR": 0.21497245535945175, "ROUGE_L": 0.24355464293862653, "CIDEr": 5.090965497628127e-12, "SPICE": {"All": {"pr": 0.15, "re": 0.13636363636363635, "f": 0.14285714285714282, "fn": 19.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "The image shows a group of people riding horses down a dirt road. The horses are wearing saddles and bridles, and the riders are wearing cowboy hats and boots. The trees on either side of the road are tall and green, and there is a small stream running through the center of the image."}, "79545": {"image_id": 79545, "Bleu_1": 0.20689655172057078, "Bleu_2": 0.12049504662365988, "Bleu_3": 6.376515999187724e-07, "Bleu_4": 1.4734890672858558e-09, "METEOR": 0.15067591644770248, "ROUGE_L": 0.20383158832702158, "CIDEr": 5.7630761340358365e-15, "SPICE": {"All": {"pr": 0.21052631578947367, "re": 0.16, "f": 0.1818181818181818, "fn": 21.0, "numImages": 1.0, "fp": 15.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA herd of bison graze in a grassy meadow next to a river. The bison are standing in a line, looking out at the viewer. The sky is clear and blue, with a few clouds scattered about. The landscape is surrounded by tall trees and mountains in the distance."}, "21563": {"image_id": 21563, "Bleu_1": 0.5555555555246915, "Bleu_2": 0.4042260417041042, "Bleu_3": 0.3129079638912492, "Bleu_4": 0.21258844129769464, "METEOR": 0.23020224675774723, "ROUGE_L": 0.48412698412698413, "CIDEr": 0.421991906137538, "SPICE": {"All": {"pr": 0.10714285714285714, "re": 0.13043478260869565, "f": 0.11764705882352941, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.375, "f": 0.3, "fn": 5.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a pizza on a plate with a glass of wine and two forks."}, "437221": {"image_id": 437221, "Bleu_1": 0.22916666666189242, "Bleu_2": 0.13965509692979164, "Bleu_3": 0.07512513229843845, "Bleu_4": 9.852258743685704e-06, "METEOR": 0.17569458833005078, "ROUGE_L": 0.23680124223602486, "CIDEr": 5.0621378351783125e-09, "SPICE": {"All": {"pr": 0.22727272727272727, "re": 0.10869565217391304, "f": 0.14705882352941177, "fn": 41.0, "numImages": 1.0, "fp": 17.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 14.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.45454545454545453, "re": 0.2777777777777778, "f": 0.3448275862068966, "fn": 13.0, "numImages": 1.0, "fp": 6.0, "tp": 5.0}}, "caption": "The image shows a person skateboarding on a ramp. The person is wearing a black shirt and pants, and has their arms outstretched as they perform a trick on the board. The background is a concrete skate park with ramps and obstacles for skaters to perform tricks on."}, "213843": {"image_id": 213843, "Bleu_1": 0.49999999998076927, "Bleu_2": 0.34641016150018555, "Bleu_3": 0.24662120742317167, "Bleu_4": 0.15980518114464692, "METEOR": 0.2712835998822808, "ROUGE_L": 0.43839835728952764, "CIDEr": 0.02144249974276479, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13043478260869565, "f": 0.13636363636363635, "fn": 20.0, "numImages": 1.0, "fp": 18.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.2857142857142857, "f": 0.25, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a chocolate cake with white frosting and sprinkles on top. There are also two glasses of wine on the table next to it."}, "351127": {"image_id": 351127, "Bleu_1": 0.47058823526643606, "Bleu_2": 0.2425356250216204, "Bleu_3": 1.5769573215394795e-06, "Bleu_4": 4.091032653614925e-09, "METEOR": 0.13449077986046568, "ROUGE_L": 0.3257676902536716, "CIDEr": 0.07501064381996511, "SPICE": {"All": {"pr": 0.3157894736842105, "re": 0.24, "f": 0.2727272727272727, "fn": 19.0, "numImages": 1.0, "fp": 13.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.3333333333333333, "f": 0.5, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.4444444444444444, "re": 0.5, "f": 0.47058823529411764, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 4.0}}, "caption": "The image shows a group of people flying kites on a beach with mountains in the background."}, "439897": {"image_id": 439897, "Bleu_1": 0.32142857142283165, "Bleu_2": 0.2756338621637189, "Bleu_3": 0.24141104001529012, "Bleu_4": 0.19977295353080474, "METEOR": 0.31447576458815424, "ROUGE_L": 0.3396436525612472, "CIDEr": 6.657485987481601e-12, "SPICE": {"All": {"pr": 0.2727272727272727, "re": 0.15789473684210525, "f": 0.19999999999999998, "fn": 16.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.42857142857142855, "f": 0.4615384615384615, "fn": 4.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a person sitting at a table with a plate of pizza in front of them. The person is wearing a black hoodie and has a slice of pizza on their plate. There are other plates of food on the table, including a salad and some bread. The background is a dark brown color."}, "112093": {"image_id": 112093, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.24253562503152987, "Bleu_3": 0.193123630168691, "Bleu_4": 0.15652411276385142, "METEOR": 0.33181551570169293, "ROUGE_L": 0.3730886850152905, "CIDEr": 1.0198421668022648e-10, "SPICE": {"All": {"pr": 0.13333333333333333, "re": 0.16, "f": 0.14545454545454545, "fn": 21.0, "numImages": 1.0, "fp": 26.0, "tp": 4.0}, "Relation": {"pr": 0.09090909090909091, "re": 0.1, "f": 0.09523809523809525, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.3, "f": 0.2727272727272727, "fn": 7.0, "numImages": 1.0, "fp": 9.0, "tp": 3.0}}, "caption": "This is an image of a white truck with a sign on the side that reads \"Good Humor Ice Cream.\" The truck is parked on the side of the road in front of a building. There are people walking by on the sidewalk and other cars driving by in the background."}, "10092": {"image_id": 10092, "Bleu_1": 0.29999999999400007, "Bleu_2": 0.17496355305240635, "Bleu_3": 0.10844960613620269, "Bleu_4": 1.2835019116177698e-05, "METEOR": 0.24985719438888648, "ROUGE_L": 0.18944099378881987, "CIDEr": 1.6449893069443278e-09, "SPICE": {"All": {"pr": 0.03333333333333333, "re": 0.038461538461538464, "f": 0.03571428571428572, "fn": 25.0, "numImages": 1.0, "fp": 29.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.07692307692307693, "re": 0.09090909090909091, "f": 0.08333333333333334, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}}, "caption": "This is a bedroom with a large bed and a mosquito net hanging from the ceiling. The walls are made of wood and there are windows on either side of the room. There is a table and chairs in the corner of the room and a lamp on the nightstand."}, "452695": {"image_id": 452695, "Bleu_1": 0.4814814814636489, "Bleu_2": 0.2721655269656347, "Bleu_3": 0.14362897932992935, "Bleu_4": 1.8744710838941805e-05, "METEOR": 0.30867790200186573, "ROUGE_L": 0.4269466316710411, "CIDEr": 0.03399585687418758, "SPICE": {"All": {"pr": 0.125, "re": 0.23076923076923078, "f": 0.16216216216216217, "fn": 10.0, "numImages": 1.0, "fp": 21.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.4, "f": 0.26666666666666666, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "This is a kitchen in a hospital. It has white walls, a white refrigerator, and a white sink. There is also a microwave oven on the counter."}, "392511": {"image_id": 392511, "Bleu_1": 0.20454545454080583, "Bleu_2": 2.1810252258335e-09, "Bleu_3": 4.838276629866671e-12, "Bleu_4": 2.292567109911852e-13, "METEOR": 0.14975369458128082, "ROUGE_L": 0.214185393258427, "CIDEr": 4.208936596366132e-09, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.1111111111111111, "f": 0.13333333333333333, "fn": 24.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.125, "f": 0.2222222222222222, "fn": 7.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.18181818181818182, "f": 0.1904761904761905, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 2.0}}, "caption": "The image shows a group of people standing in front of a pool with umbrellas. One person is holding up a sign that reads \"Green Clean\". The people are all wearing swimsuits and sunglasses, and they appear to be enjoying themselves in the sun."}, "577864": {"image_id": 577864, "Bleu_1": 0.7999999999200001, "Bleu_2": 0.5163977794398137, "Bleu_3": 3.2182979483248667e-06, "Bleu_4": 8.307018473418093e-09, "METEOR": 0.18952895878603665, "ROUGE_L": 0.4535315985130111, "CIDEr": 0.7187842517073042, "SPICE": {"All": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 20.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.14285714285714285, "f": 0.25, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.3, "f": 0.37499999999999994, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "A group of people playing soccer on a sandy beach."}, "259567": {"image_id": 259567, "Bleu_1": 0.2765957446749661, "Bleu_2": 0.20516007603198386, "Bleu_3": 0.14104731216518007, "Bleu_4": 0.10627177653467242, "METEOR": 0.28556307106751116, "ROUGE_L": 0.32555036691127415, "CIDEr": 7.1203361917731996e-06, "SPICE": {"All": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 20.0, "numImages": 1.0, "fp": 25.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.35714285714285715, "re": 0.7142857142857143, "f": 0.4761904761904762, "fn": 2.0, "numImages": 1.0, "fp": 9.0, "tp": 5.0}}, "caption": "A man and woman are sitting on a couch with their dogs. The man is holding a remote control and the woman is holding a book. There are several electronic devices on the coffee table in front of them, including a television, a computer, and a stereo."}, "517945": {"image_id": 517945, "Bleu_1": 0.25999999999480006, "Bleu_2": 0.1927248223279925, "Bleu_3": 0.13240928541024866, "Bleu_4": 1.4907827774178394e-05, "METEOR": 0.283764155656827, "ROUGE_L": 0.19830949284785435, "CIDEr": 3.536517833669138e-11, "SPICE": {"All": {"pr": 0.5555555555555556, "re": 0.16129032258064516, "f": 0.25, "fn": 26.0, "numImages": 1.0, "fp": 4.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 11.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.25, "f": 0.4, "fn": 6.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.25, "f": 0.3333333333333333, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 3.0}}, "caption": "The image shows a baseball game being played on a field with a large crowd of people watching from the stands. The players are wearing uniforms and helmets, and the umpire is standing behind home plate. The field is surrounded by a fence, and there are trees in the background."}, "384596": {"image_id": 384596, "Bleu_1": 0.20370370369993146, "Bleu_2": 0.10737969231852026, "Bleu_3": 6.052669898452478e-07, "Bleu_4": 1.4440016772249673e-09, "METEOR": 0.15681605651759525, "ROUGE_L": 0.2738496071829405, "CIDEr": 5.305373804684805e-11, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.08695652173913043, "f": 0.1111111111111111, "fn": 21.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.16666666666666666, "f": 0.2105263157894737, "fn": 10.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "The image shows a small child standing in front of a wooden crib with a white sheet on it. The child is wearing a blue shirt and pants, and has a toy in their hand. There is a window in the background with blinds open, and a wooden floor with a rug on it."}, "546674": {"image_id": 546674, "Bleu_1": 0.40624999998730477, "Bleu_2": 0.2289527349375426, "Bleu_3": 0.1204453779926304, "Bleu_4": 1.5667261949798743e-05, "METEOR": 0.26001901528562205, "ROUGE_L": 0.2970779220779221, "CIDEr": 0.005334346478553567, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.20689655172413793, "f": 0.2142857142857143, "fn": 23.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.14285714285714285, "re": 0.09090909090909091, "f": 0.1111111111111111, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a wooden table with a vase on it containing a bamboo plant. There is also a window in the background with blinds open, revealing a view of the outside."}, "330265": {"image_id": 330265, "Bleu_1": 0.27586206896076104, "Bleu_2": 0.13913569520837307, "Bleu_3": 7.018263976910165e-07, "Bleu_4": 1.5833670465760963e-09, "METEOR": 0.2413422651936039, "ROUGE_L": 0.23131094257854823, "CIDEr": 5.1607766906285803e-14, "SPICE": {"All": {"pr": 0.3333333333333333, "re": 0.125, "f": 0.18181818181818182, "fn": 21.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.6666666666666666, "re": 0.2222222222222222, "f": 0.3333333333333333, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}}, "caption": "This image shows a bathroom with a toilet, sink, and mirror. The toilet is white and has a seat cover on it. The sink is made of marble and has a faucet on it. The mirror is large and has a frame around it. There are also some toilet paper rolls on the counter next to the sink."}, "296797": {"image_id": 296797, "Bleu_1": 0.31914893616342244, "Bleu_2": 0.16658955971162087, "Bleu_3": 0.08511922922355493, "Bleu_4": 1.0880718950983141e-05, "METEOR": 0.12054754877535029, "ROUGE_L": 0.23297262889879056, "CIDEr": 2.371898107895148e-09, "SPICE": {"All": {"pr": 0.15384615384615385, "re": 0.08333333333333333, "f": 0.10810810810810811, "fn": 22.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.2, "f": 0.23529411764705882, "fn": 8.0, "numImages": 1.0, "fp": 5.0, "tp": 2.0}}, "caption": "This is an image of a group of people standing on the sidewalk in front of a cable car. They are all wearing umbrellas and looking at the camera. The cable car is in the background, with people standing on it and looking out at the city."}, "53315": {"image_id": 53315, "Bleu_1": 0.2941176470530566, "Bleu_2": 0.26568446565676707, "Bleu_3": 0.23492338576087834, "Bleu_4": 0.2085253645774918, "METEOR": 0.34728794523615686, "ROUGE_L": 0.3650508677438659, "CIDEr": 5.277588832412309e-10, "SPICE": {"All": {"pr": 0.38461538461538464, "re": 0.2, "f": 0.2631578947368421, "fn": 20.0, "numImages": 1.0, "fp": 8.0, "tp": 5.0}, "Relation": {"pr": 0.3333333333333333, "re": 0.1111111111111111, "f": 0.16666666666666666, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.4, "f": 0.4444444444444445, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 4.0}}, "caption": "The image shows a young boy standing in front of a birthday cake with Captain America on it. He is smiling and holding a sword in one hand and a shield in the other. There are balloons and streamers hanging from the ceiling, and a table with chairs set up nearby."}, "35105": {"image_id": 35105, "Bleu_1": 0.3220338982996266, "Bleu_2": 0.24713436528343966, "Bleu_3": 0.2046572515217593, "Bleu_4": 0.16632818458890083, "METEOR": 0.2667191006216031, "ROUGE_L": 0.3233623627413858, "CIDEr": 3.882182688785876e-14, "SPICE": {"All": {"pr": 0.08571428571428572, "re": 0.16666666666666666, "f": 0.11320754716981132, "fn": 15.0, "numImages": 1.0, "fp": 32.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.07692307692307693, "re": 0.25, "f": 0.11764705882352941, "fn": 3.0, "numImages": 1.0, "fp": 12.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": 0.25, "re": 0.5, "f": 0.3333333333333333, "fn": 1.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Object": {"pr": 0.14285714285714285, "re": 0.25, "f": 0.18181818181818182, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "Sure! Here is a short caption for the image:\n\nA red fire hydrant sits on the side of the road in front of a small building with a green awning. The building has a sign that reads \"The Green House\" in white letters. The hydrant is surrounded by grass and trees, and there are cars parked along the street."}, "324135": {"image_id": 324135, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.5032362797167775, "Bleu_3": 0.39856084559347915, "Bleu_4": 0.3162007437609143, "METEOR": 0.31624872799727566, "ROUGE_L": 0.4966399586456449, "CIDEr": 0.46745078095105175, "SPICE": {"All": {"pr": 0.2, "re": 0.23809523809523808, "f": 0.21739130434782608, "fn": 16.0, "numImages": 1.0, "fp": 20.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.25, "re": 0.125, "f": 0.16666666666666666, "fn": 7.0, "numImages": 1.0, "fp": 3.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.3076923076923077, "re": 0.5, "f": 0.380952380952381, "fn": 4.0, "numImages": 1.0, "fp": 9.0, "tp": 4.0}}, "caption": "The image shows a young boy wearing a baseball cap and sunglasses, holding a bat and standing in front of a building."}, "40011": {"image_id": 40011, "Bleu_1": 0.48717948716699544, "Bleu_2": 0.3202563076018546, "Bleu_3": 0.14047462672183486, "Bleu_4": 1.6657997395842427e-05, "METEOR": 0.2751714982168728, "ROUGE_L": 0.3155949741315595, "CIDEr": 0.0001257377340678662, "SPICE": {"All": {"pr": 0.08333333333333333, "re": 0.13043478260869565, "f": 0.10169491525423728, "fn": 20.0, "numImages": 1.0, "fp": 33.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 14.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.2, "re": 0.375, "f": 0.26086956521739135, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 3.0}}, "caption": "A purple train is traveling down the tracks at a slow pace. There are people standing on the platform, looking at the train as it passes by. The sky is clear and blue, with some clouds in the distance."}, "146448": {"image_id": 146448, "Bleu_1": 0.23255813952947546, "Bleu_2": 0.19687480773490648, "Bleu_3": 0.12365418261033179, "Bleu_4": 1.4744892493104462e-05, "METEOR": 0.2849655983695067, "ROUGE_L": 0.26852531181217903, "CIDEr": 9.746576456889787e-08, "SPICE": {"All": {"pr": 0.4375, "re": 0.2916666666666667, "f": 0.35000000000000003, "fn": 17.0, "numImages": 1.0, "fp": 9.0, "tp": 7.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.375, "f": 0.5454545454545454, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 3.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 1.0, "re": 0.5, "f": 0.6666666666666666, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "Sure! Here is a short caption for the image:\n\n\"A young boy is skateboarding on a blue skateboard in the park. He is wearing a black shirt and yellow pants, and has a serious expression on his face as he rides the board.\""}, "274593": {"image_id": 274593, "Bleu_1": 0.3333333333253969, "Bleu_2": 0.18033392692914046, "Bleu_3": 0.11759123766324173, "Bleu_4": 1.4289435395907192e-05, "METEOR": 0.2688587908234234, "ROUGE_L": 0.29383429672447015, "CIDEr": 4.205658880353932e-06, "SPICE": {"All": {"pr": 0.05, "re": 0.037037037037037035, "f": 0.0425531914893617, "fn": 26.0, "numImages": 1.0, "fp": 19.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.08333333333333333, "re": 0.09090909090909091, "f": 0.08695652173913043, "fn": 10.0, "numImages": 1.0, "fp": 11.0, "tp": 1.0}}, "caption": "This is an image of a fire hydrant on the sidewalk in front of a building. The hydrant is red and has a sign on it that says \"Fire Hydrant\". There are cars parked on the street and buildings in the background."}, "524742": {"image_id": 524742, "Bleu_1": 0.12380952380834469, "Bleu_2": 0.06900655593357506, "Bleu_3": 0.05176325504824583, "Bleu_4": 0.040609125737977605, "METEOR": 0.13409672848225396, "ROUGE_L": 0.12410986775178028, "CIDEr": 3.852660046963378e-56, "SPICE": {"All": {"pr": 0.3125, "re": 0.2631578947368421, "f": 0.2857142857142857, "fn": 14.0, "numImages": 1.0, "fp": 11.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.42857142857142855, "re": 0.5, "f": 0.4615384615384615, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 3.0}}, "caption": "The image shows a graffiti mural on the side of a yellow train. The mural appears to be made up of different colors and shapes, including purple, pink, blue, and green. There are also some words written in black on the side of the train, but they are not easily visible. The train is parked on the platform of a train station.\n\nThe image is taken from a low angle, looking up at the train from the ground. The lighting is bright and sunny, with shadows cast by the train on the platform. The background is a concrete platform with a few people walking around."}, "22793": {"image_id": 22793, "Bleu_1": 0.423076923060651, "Bleu_2": 0.26017745422498945, "Bleu_3": 0.14128932794034893, "Bleu_4": 1.8713286234139762e-05, "METEOR": 0.18490438529896475, "ROUGE_L": 0.30198019801980197, "CIDEr": 0.020065302647308075, "SPICE": {"All": {"pr": 0.18181818181818182, "re": 0.08, "f": 0.1111111111111111, "fn": 23.0, "numImages": 1.0, "fp": 9.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.18181818181818182, "f": 0.25000000000000006, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 2.0}}, "caption": "The image shows a bathroom with several stalls and sinks. There are also several posters on the walls, including one of a woman in a bikini."}, "384616": {"image_id": 384616, "Bleu_1": 0.5416666666440973, "Bleu_2": 0.4603873605140388, "Bleu_3": 0.40704339729190725, "Bleu_4": 0.3366593727525654, "METEOR": 0.4216417272277327, "ROUGE_L": 0.6282771535580524, "CIDEr": 0.29813828220635713, "SPICE": {"All": {"pr": 0.1724137931034483, "re": 0.19230769230769232, "f": 0.18181818181818185, "fn": 21.0, "numImages": 1.0, "fp": 24.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.2, "re": 0.14285714285714285, "f": 0.16666666666666666, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.36363636363636365, "f": 0.32, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "This is an image of a red fire hydrant in the middle of a dirt road surrounded by trees and mountains in the background."}, "89405": {"image_id": 89405, "Bleu_1": 0.2749999999931251, "Bleu_2": 0.16794382454767393, "Bleu_3": 0.09054159909521357, "Bleu_4": 1.1901061222904039e-05, "METEOR": 0.2283049986416773, "ROUGE_L": 0.31961077844311375, "CIDEr": 4.094736707885765e-06, "SPICE": {"All": {"pr": 0.0625, "re": 0.1, "f": 0.07692307692307693, "fn": 18.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.14285714285714285, "re": 0.2857142857142857, "f": 0.19047619047619047, "fn": 5.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}}, "caption": "A vase filled with white roses sits on a desk in an office. The desk has a computer and other office supplies on it. There are bookshelves behind the desk, and a window with blinds is visible in the background."}, "432120": {"image_id": 432120, "Bleu_1": 0.4054054053944486, "Bleu_2": 0.280764721474242, "Bleu_3": 0.16515143127759593, "Bleu_4": 1.907840338688821e-05, "METEOR": 0.25876955078145386, "ROUGE_L": 0.3065326633165829, "CIDEr": 0.0001334270009411391, "SPICE": {"All": {"pr": 0.19047619047619047, "re": 0.18181818181818182, "f": 0.18604651162790697, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.125, "f": 0.2, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.5, "f": 0.3529411764705882, "fn": 3.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a person sitting in the driver's seat of a car, looking out the side mirror at a dog running alongside the road. The sky is cloudy and there are trees in the background."}, "6673": {"image_id": 6673, "Bleu_1": 0.5909090908822315, "Bleu_2": 0.5032362797167775, "Bleu_3": 0.4235340979105781, "Bleu_4": 0.35562549054537307, "METEOR": 0.3481763706482848, "ROUGE_L": 0.5550861228469288, "CIDEr": 0.5144446641363184, "SPICE": {"All": {"pr": 0.1, "re": 0.15, "f": 0.12, "fn": 17.0, "numImages": 1.0, "fp": 27.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.23076923076923078, "re": 0.3333333333333333, "f": 0.27272727272727276, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 3.0}}, "caption": "The image shows a vase with sunflowers and other flowers in it. The vase is sitting on top of a brick wall."}, "500492": {"image_id": 500492, "Bleu_1": 0.49999999998437505, "Bleu_2": 0.3810003809884732, "Bleu_3": 0.2684910740226452, "Bleu_4": 0.16073034971813757, "METEOR": 0.3586050064852612, "ROUGE_L": 0.38485804416403785, "CIDEr": 0.006805663346793028, "SPICE": {"All": {"pr": 0.25, "re": 0.3333333333333333, "f": 0.28571428571428575, "fn": 16.0, "numImages": 1.0, "fp": 24.0, "tp": 8.0}, "Relation": {"pr": 0.15384615384615385, "re": 0.2222222222222222, "f": 0.18181818181818185, "fn": 7.0, "numImages": 1.0, "fp": 11.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.46153846153846156, "re": 0.5454545454545454, "f": 0.4999999999999999, "fn": 5.0, "numImages": 1.0, "fp": 7.0, "tp": 6.0}}, "caption": "A glass of beer sits on a wooden table next to a bottle of wine. The walls of the room are made of stone and there is a fireplace in the background."}, "295412": {"image_id": 295412, "Bleu_1": 0.25806451612486997, "Bleu_2": 0.20568339354559642, "Bleu_3": 0.15219687571317925, "Bleu_4": 0.11571019188492289, "METEOR": 0.2760936860996863, "ROUGE_L": 0.26040554962646745, "CIDEr": 3.2209788410436695e-16, "SPICE": {"All": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 20.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.4444444444444444, "f": 0.5, "fn": 5.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "This image shows a man standing next to a wooden boat that he is building. The boat has a wooden frame and is being constructed on the ground. The man is wearing a white shirt and pants, and he appears to be working on the boat with some tools. There are trees and a small house in the background of the image."}, "564352": {"image_id": 564352, "Bleu_1": 0.20833333333043982, "Bleu_2": 0.16250677125426688, "Bleu_3": 0.09103847195685184, "Bleu_4": 0.05750511112834743, "METEOR": 0.20432112710781555, "ROUGE_L": 0.22344322344322343, "CIDEr": 3.693020839663024e-22, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.13793103448275862, "f": 0.14035087719298248, "fn": 25.0, "numImages": 1.0, "fp": 24.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 15.0, "numImages": 1.0, "fp": 12.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.4, "re": 0.3333333333333333, "f": 0.3636363636363636, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 4.0}}, "caption": "The image shows a man sitting at a table on the edge of a river, looking out at the boats passing by. There are several people standing on the riverbank, and a few boats are moored along the shore. The sky is clear and blue, with some clouds visible in the distance. The buildings on either side of the river are tall and made of brick or stone, with windows and balconies."}, "524621": {"image_id": 524621, "Bleu_1": 0.1525423728787705, "Bleu_2": 0.10256784899095028, "Bleu_3": 0.056935422350642036, "Bleu_4": 7.576871174126601e-06, "METEOR": 0.15625238433906957, "ROUGE_L": 0.169538632573652, "CIDEr": 1.1860824482006348e-15, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3333333333333333, "f": 0.34285714285714286, "fn": 12.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.3333333333333333, "re": 0.2, "f": 0.25, "fn": 4.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.7142857142857143, "re": 0.8333333333333334, "f": 0.7692307692307692, "fn": 1.0, "numImages": 1.0, "fp": 2.0, "tp": 5.0}}, "caption": "The image shows two giraffes standing in a clearing surrounded by trees. They are both looking up at the sky, with their long necks stretched out in front of them. The sky is blue and cloudy, with a few white clouds visible in the distance. The ground is dry and cracked, with some small bushes growing in the foreground."}, "248793": {"image_id": 248793, "Bleu_1": 0.6249999999739584, "Bleu_2": 0.2855201203479251, "Bleu_3": 0.15474510441967504, "Bleu_4": 2.0495469204345803e-05, "METEOR": 0.18439488319360478, "ROUGE_L": 0.264069264069264, "CIDEr": 0.10655566981789852, "SPICE": {"All": {"pr": 0.2, "re": 0.05, "f": 0.08000000000000002, "fn": 19.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.16666666666666666, "f": 0.2222222222222222, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 1.0}}, "caption": "This is a photograph of a city street with tall buildings on either side. The sky is cloudy and there are birds flying overhead."}, "488756": {"image_id": 488756, "Bleu_1": 0.14772727272559402, "Bleu_2": 0.10093605784882721, "Bleu_3": 0.06187873224979854, "Bleu_4": 7.266099223496934e-06, "METEOR": 0.14267460963229722, "ROUGE_L": 0.14296875, "CIDEr": 7.48576531039459e-36, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.13333333333333333, "f": 0.08695652173913043, "fn": 13.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 9.0, "tp": 0.0}, "Cardinality": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.13333333333333333, "re": 0.3333333333333333, "f": 0.19047619047619044, "fn": 4.0, "numImages": 1.0, "fp": 13.0, "tp": 2.0}}, "caption": "The image shows a group of people playing in a swimming pool. One person is jumping off the side of the pool and another person is trying to catch the water with their hands. There are several other people in the pool, including one who is standing on the edge of the pool and another who is sitting on the side of the pool. The image appears to be taken during the summer months, as there are no leaves on the trees and the sun is shining brightly."}, "460783": {"image_id": 460783, "Bleu_1": 0.45238095237018144, "Bleu_2": 0.2572976692260223, "Bleu_3": 0.17059946145426558, "Bleu_4": 0.10622263980385173, "METEOR": 0.23337628495795987, "ROUGE_L": 0.3214756258234519, "CIDEr": 7.270304927776945e-06, "SPICE": {"All": {"pr": 0.1875, "re": 0.25, "f": 0.21428571428571427, "fn": 18.0, "numImages": 1.0, "fp": 26.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.25, "f": 0.2, "fn": 6.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.3333333333333333, "f": 0.30769230769230765, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a white poodle standing on its hind legs in front of a kitchen counter with a bowl of fruit on it. The poodle is wearing a pink bow in its hair and has a curious expression on its face."}, "367872": {"image_id": 367872, "Bleu_1": 0.28571428570845486, "Bleu_2": 0.2182178902314926, "Bleu_3": 0.18250637225757121, "Bleu_4": 0.14110726692117728, "METEOR": 0.31230784547798623, "ROUGE_L": 0.31504196255648803, "CIDEr": 1.0385689071583397e-09, "SPICE": {"All": {"pr": 0.1111111111111111, "re": 0.15384615384615385, "f": 0.12903225806451615, "fn": 22.0, "numImages": 1.0, "fp": 32.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 7.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a baseball player swinging a bat at a ball on a field. There are several people in the stands watching the game, and some are holding up signs with the names of players on them. The sky is blue and there are trees in the background."}, "398525": {"image_id": 398525, "Bleu_1": 0.4999999999833334, "Bleu_2": 0.3474041668780458, "Bleu_3": 0.20504412815077033, "Bleu_4": 2.3770841795028944e-05, "METEOR": 0.3113453190645873, "ROUGE_L": 0.42582897033158806, "CIDEr": 0.005515570810089241, "SPICE": {"All": {"pr": 0.0625, "re": 0.08333333333333333, "f": 0.07142857142857144, "fn": 22.0, "numImages": 1.0, "fp": 30.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2, "f": 0.1818181818181818, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This is an image of a street with a stop sign on the corner. There are palm trees on either side of the street and cars parked along the sidewalk."}, "548722": {"image_id": 548722, "Bleu_1": 0.222222222217284, "Bleu_2": 0.15891043153736062, "Bleu_3": 0.10550882455558673, "Bleu_4": 0.07272006626035298, "METEOR": 0.1754103665874609, "ROUGE_L": 0.21048999309868874, "CIDEr": 2.19818888606462e-08, "SPICE": {"All": {"pr": 0.35294117647058826, "re": 0.3157894736842105, "f": 0.33333333333333337, "fn": 13.0, "numImages": 1.0, "fp": 11.0, "tp": 6.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "The image shows a zebra standing in the middle of a dry, barren landscape with no trees or vegetation in sight. The zebra is looking around and appears to be searching for something. The sky is clear and blue, with a few clouds scattered about."}, "82367": {"image_id": 82367, "Bleu_1": 0.2641509433912425, "Bleu_2": 0.18857036045053577, "Bleu_3": 0.11172119198541168, "Bleu_4": 1.2922875770638225e-05, "METEOR": 0.248948358057238, "ROUGE_L": 0.2896142433234421, "CIDEr": 5.723697599805546e-12, "SPICE": {"All": {"pr": 0.14634146341463414, "re": 0.2608695652173913, "f": 0.1875, "fn": 17.0, "numImages": 1.0, "fp": 35.0, "tp": 6.0}, "Relation": {"pr": 0.11764705882352941, "re": 0.2222222222222222, "f": 0.15384615384615383, "fn": 7.0, "numImages": 1.0, "fp": 15.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.16666666666666666, "re": 0.125, "f": 0.14285714285714288, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.5, "f": 0.25, "fn": 3.0, "numImages": 1.0, "fp": 15.0, "tp": 3.0}}, "caption": "The image shows a clock hanging on the wall in a room with white walls and a wooden floor. The clock has two hands, one pointing to the hour and the other pointing to the minute. There is a window on the left side of the room with a view of the outside."}, "181462": {"image_id": 181462, "Bleu_1": 0.3749999999882814, "Bleu_2": 0.19050019049423667, "Bleu_3": 0.10655075333690474, "Bleu_4": 1.4291173573605973e-05, "METEOR": 0.20505624679469, "ROUGE_L": 0.3060200668896321, "CIDEr": 0.0009305501069142232, "SPICE": {"All": {"pr": 0.06451612903225806, "re": 0.10526315789473684, "f": 0.07999999999999999, "fn": 17.0, "numImages": 1.0, "fp": 29.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 11.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2857142857142857, "f": 0.2105263157894737, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "The image shows a dead seal lying on the beach with its body covered in sand. The sky is blue and there are rocks and pebbles scattered around the seal's body."}, "332377": {"image_id": 332377, "Bleu_1": 0.42857142854081637, "Bleu_2": 0.3144854509932483, "Bleu_3": 0.2019946918829379, "Bleu_4": 2.9420957078790955e-05, "METEOR": 0.2303067207651421, "ROUGE_L": 0.3620178041543027, "CIDEr": 0.29507858195606296, "SPICE": {"All": {"pr": 0.36363636363636365, "re": 0.15384615384615385, "f": 0.21621621621621623, "fn": 22.0, "numImages": 1.0, "fp": 7.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 12.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.8, "re": 0.36363636363636365, "f": 0.5000000000000001, "fn": 7.0, "numImages": 1.0, "fp": 1.0, "tp": 4.0}}, "caption": "There are two doughnuts on a table with white paper bags next to them."}, "205504": {"image_id": 205504, "Bleu_1": 0.22499999999437506, "Bleu_2": 0.15191090505870358, "Bleu_3": 0.08468336402372789, "Bleu_4": 1.131874160173397e-05, "METEOR": 0.21118456519465226, "ROUGE_L": 0.23680124223602486, "CIDEr": 6.051781385132701e-07, "SPICE": {"All": {"pr": 0.2222222222222222, "re": 0.2608695652173913, "f": 0.24, "fn": 17.0, "numImages": 1.0, "fp": 21.0, "tp": 6.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.6666666666666666, "re": 0.3333333333333333, "f": 0.4444444444444444, "fn": 4.0, "numImages": 1.0, "fp": 1.0, "tp": 2.0}, "Size": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2857142857142857, "re": 0.4444444444444444, "f": 0.34782608695652173, "fn": 5.0, "numImages": 1.0, "fp": 10.0, "tp": 4.0}}, "caption": "The image shows a young man in a red jersey and white pants throwing a baseball on a green field. There are several people watching from the stands, including a woman with a camera. The sky is clear and blue."}, "149014": {"image_id": 149014, "Bleu_1": 0.19672131147218494, "Bleu_2": 0.12803687993077956, "Bleu_3": 0.06525383659983366, "Bleu_4": 8.319506012421654e-06, "METEOR": 0.20729625929169535, "ROUGE_L": 0.23552123552123558, "CIDEr": 1.3635817951253148e-16, "SPICE": {"All": {"pr": 0.10344827586206896, "re": 0.13043478260869565, "f": 0.11538461538461538, "fn": 20.0, "numImages": 1.0, "fp": 26.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": 1.0, "re": 1.0, "f": 1.0, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 1.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.1111111111111111, "f": 0.1111111111111111, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Object": {"pr": 0.16666666666666666, "re": 0.2222222222222222, "f": 0.1904761904761905, "fn": 7.0, "numImages": 1.0, "fp": 10.0, "tp": 2.0}}, "caption": "This image shows a person snowboarding down a mountain covered in trees. The person is wearing a yellow jacket and black pants, and has a snowboard under their feet. The snowboard is pointed towards the ground and the person is leaning forward to maintain balance. The trees in the background are tall and green, and there is snow on the ground."}, "136920": {"image_id": 136920, "Bleu_1": 0.3793103448145066, "Bleu_2": 0.2602575457946004, "Bleu_3": 0.1959693040269019, "Bleu_4": 0.13043606865671686, "METEOR": 0.3365141584364032, "ROUGE_L": 0.4652049571020019, "CIDEr": 0.004058777679678463, "SPICE": {"All": {"pr": 0.075, "re": 0.13043478260869565, "f": 0.09523809523809523, "fn": 20.0, "numImages": 1.0, "fp": 37.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 10.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 16.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Object": {"pr": 0.21428571428571427, "re": 0.3333333333333333, "f": 0.2608695652173913, "fn": 6.0, "numImages": 1.0, "fp": 11.0, "tp": 3.0}}, "caption": "This is a bathroom with white walls, a white sink, and a white toilet. There is a window on the wall with curtains and a rug on the floor."}, "312889": {"image_id": 312889, "Bleu_1": 0.26229508196291323, "Bleu_2": 0.16195526603310612, "Bleu_3": 0.07632135028174301, "Bleu_4": 9.35680407190854e-06, "METEOR": 0.2659392042221039, "ROUGE_L": 0.22652519893899206, "CIDEr": 9.283364270006948e-14, "SPICE": {"All": {"pr": 0.21739130434782608, "re": 0.20833333333333334, "f": 0.2127659574468085, "fn": 19.0, "numImages": 1.0, "fp": 18.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 8.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.4166666666666667, "re": 0.45454545454545453, "f": 0.43478260869565216, "fn": 6.0, "numImages": 1.0, "fp": 7.0, "tp": 5.0}}, "caption": "The man in the image is standing at a podium, wearing a blue suit and tie. He is looking down at his notes on the podium. There are several chairs set up in front of him, with people sitting in them. The walls behind him are painted a light gray color and there are windows on either side of the room."}, "514416": {"image_id": 514416, "Bleu_1": 0.5499999999725, "Bleu_2": 0.4501461750660246, "Bleu_3": 0.3832376860180962, "Bleu_4": 0.2852636438992374, "METEOR": 0.4317237292971595, "ROUGE_L": 0.5674418604651164, "CIDEr": 0.5394398485523814, "SPICE": {"All": {"pr": 0.29411764705882354, "re": 0.20833333333333334, "f": 0.24390243902439027, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 5.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 1.0, "re": 0.2857142857142857, "f": 0.4444444444444445, "fn": 5.0, "numImages": 1.0, "fp": 0.0, "tp": 2.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.42857142857142855, "f": 0.375, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 3.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A woman takes a photo of herself in a bathroom mirror.\""}, "424270": {"image_id": 424270, "Bleu_1": 0.23076923076568048, "Bleu_2": 0.10400628679061788, "Bleu_3": 0.055580981441786075, "Bleu_4": 7.254320449841931e-06, "METEOR": 0.21246630105235367, "ROUGE_L": 0.242906918865107, "CIDEr": 1.4032364573877069e-18, "SPICE": {"All": {"pr": 0.16, "re": 0.13793103448275862, "f": 0.14814814814814817, "fn": 25.0, "numImages": 1.0, "fp": 21.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.125, "re": 0.1, "f": 0.11111111111111112, "fn": 9.0, "numImages": 1.0, "fp": 7.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.2727272727272727, "f": 0.2727272727272727, "fn": 8.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "The image shows a small girl lying on a bed in a room with white walls and a blue ceiling. The bed is covered in blue sheets and has a few pillows on it. There is a window on the wall opposite the bed, which has curtains that are open. The floor is made of wood and there are two chairs next to the bed."}, "254407": {"image_id": 254407, "Bleu_1": 0.26829268292028563, "Bleu_2": 0.11582156166137168, "Bleu_3": 7.006558330325156e-07, "Bleu_4": 1.7345333611892186e-09, "METEOR": 0.15801641359394544, "ROUGE_L": 0.18583396801218582, "CIDEr": 7.191343377723225e-07, "SPICE": {"All": {"pr": 0.16129032258064516, "re": 0.23809523809523808, "f": 0.1923076923076923, "fn": 16.0, "numImages": 1.0, "fp": 26.0, "tp": 5.0}, "Relation": {"pr": 0.14285714285714285, "re": 0.1111111111111111, "f": 0.125, "fn": 8.0, "numImages": 1.0, "fp": 6.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 4.0, "numImages": 1.0, "fp": 6.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.5, "f": 0.30769230769230765, "fn": 4.0, "numImages": 1.0, "fp": 14.0, "tp": 4.0}}, "caption": "The image shows a train traveling down the tracks at high speed. It is painted in blue and green colors with the words \"British Rail\" written on the side. There are people standing on the platform watching the train go by."}, "146601": {"image_id": 146601, "Bleu_1": 0.2833333333286111, "Bleu_2": 0.19600530374138794, "Bleu_3": 0.1098278670897678, "Bleu_4": 1.23471208293296e-05, "METEOR": 0.18653006819283174, "ROUGE_L": 0.1967741935483871, "CIDEr": 4.1235096051530244e-16, "SPICE": {"All": {"pr": 0.20833333333333334, "re": 0.18518518518518517, "f": 0.19607843137254902, "fn": 22.0, "numImages": 1.0, "fp": 19.0, "tp": 5.0}, "Relation": {"pr": 0.25, "re": 0.16666666666666666, "f": 0.2, "fn": 10.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Object": {"pr": 0.2727272727272727, "re": 0.25, "f": 0.2608695652173913, "fn": 9.0, "numImages": 1.0, "fp": 8.0, "tp": 3.0}}, "caption": "This is an image of a donut machine in a bakery. The machine has a conveyor belt that moves the doughnuts through the machine, and there are several trays on the conveyor belt with different types of doughnuts on them. The machine has a large window on the front so you can see inside and watch the doughnuts being made."}, "357109": {"image_id": 357109, "Bleu_1": 0.4583333333142362, "Bleu_2": 0.3992747047353472, "Bleu_3": 0.2790920009876744, "Bleu_4": 0.17937244103128644, "METEOR": 0.3067871495520835, "ROUGE_L": 0.38125000000000003, "CIDEr": 0.046585991727488715, "SPICE": {"All": {"pr": 0.14285714285714285, "re": 0.09523809523809523, "f": 0.11428571428571427, "fn": 19.0, "numImages": 1.0, "fp": 12.0, "tp": 2.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.25, "re": 0.2222222222222222, "f": 0.23529411764705882, "fn": 7.0, "numImages": 1.0, "fp": 6.0, "tp": 2.0}}, "caption": "Sure, here is a short caption for the image:\n\n\"A skateboarder performing a trick on a ramp in front of a crowd of people.\""}, "168175": {"image_id": 168175, "Bleu_1": 0.37499999998437505, "Bleu_2": 0.12768847960837637, "Bleu_3": 9.049548604494648e-07, "Bleu_4": 2.437335780312719e-09, "METEOR": 0.19783193862231085, "ROUGE_L": 0.30622489959839355, "CIDEr": 0.03753131124125162, "SPICE": {"All": {"pr": 0.15, "re": 0.14285714285714285, "f": 0.14634146341463414, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 7.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.1111111111111111, "re": 0.16666666666666666, "f": 0.13333333333333333, "fn": 5.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 3.0, "tp": 0.0}, "Object": {"pr": 0.3333333333333333, "re": 0.25, "f": 0.28571428571428575, "fn": 6.0, "numImages": 1.0, "fp": 4.0, "tp": 2.0}}, "caption": "This is a table set with food on it, including sandwiches, meat, and drinks. There are also some plates and utensils on the table."}, "214966": {"image_id": 214966, "Bleu_1": 0.49999999998684214, "Bleu_2": 0.4191368221312758, "Bleu_3": 0.33923426009259433, "Bleu_4": 0.2732752307483863, "METEOR": 0.4284708454396029, "ROUGE_L": 0.45319465081723626, "CIDEr": 0.0004265928355739422, "SPICE": {"All": {"pr": 0.17647058823529413, "re": 0.1, "f": 0.12765957446808512, "fn": 27.0, "numImages": 1.0, "fp": 14.0, "tp": 3.0}, "Relation": {"pr": 0.16666666666666666, "re": 0.08333333333333333, "f": 0.1111111111111111, "fn": 11.0, "numImages": 1.0, "fp": 5.0, "tp": 1.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.2222222222222222, "re": 0.16666666666666666, "f": 0.1904761904761905, "fn": 10.0, "numImages": 1.0, "fp": 7.0, "tp": 2.0}}, "caption": "The image shows a man standing on a tennis court at sunset. He is holding a tennis racket and looking down at the ground. The court is covered in shadows, and the sun is setting in the background."}, "261487": {"image_id": 261487, "Bleu_1": 0.28846153845599115, "Bleu_2": 0.10635890745081387, "Bleu_3": 6.093393760732184e-07, "Bleu_4": 1.465869850942177e-09, "METEOR": 0.20116130444968333, "ROUGE_L": 0.22241127856101123, "CIDEr": 1.1184329480724125e-09, "SPICE": {"All": {"pr": 0.375, "re": 0.125, "f": 0.1875, "fn": 21.0, "numImages": 1.0, "fp": 5.0, "tp": 3.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 6.0, "numImages": 1.0, "fp": 2.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.5, "re": 0.09090909090909091, "f": 0.15384615384615385, "fn": 10.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 2.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.2857142857142857, "f": 0.36363636363636365, "fn": 5.0, "numImages": 1.0, "fp": 2.0, "tp": 2.0}}, "caption": "The image shows a group of people playing tennis on a court. They are all wearing tennis shoes and holding rackets. One person is hitting the ball with their racket while another person watches from the sidelines. There are several other people in the background, some of whom are also playing tennis."}, "246626": {"image_id": 246626, "Bleu_1": 0.34482758619500603, "Bleu_2": 0.22194838080144763, "Bleu_3": 0.1539536764846181, "Bleu_4": 0.10884267615297269, "METEOR": 0.232733712354962, "ROUGE_L": 0.34186437511675694, "CIDEr": 0.009255683615628077, "SPICE": {"All": {"pr": 0.25, "re": 0.16, "f": 0.19512195121951217, "fn": 21.0, "numImages": 1.0, "fp": 12.0, "tp": 4.0}, "Relation": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 9.0, "numImages": 1.0, "fp": 4.0, "tp": 0.0}, "Cardinality": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Attribute": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 3.0, "numImages": 1.0, "fp": 5.0, "tp": 0.0}, "Size": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5714285714285714, "re": 0.3076923076923077, "f": 0.4, "fn": 9.0, "numImages": 1.0, "fp": 3.0, "tp": 4.0}}, "caption": "A person is holding a cell phone in their hand and looking at it. There are several other electronic devices on the desk, including a laptop and a printer."}, "987": {"image_id": 987, "Bleu_1": 0.36111111110108035, "Bleu_2": 0.20314980006762443, "Bleu_3": 1.066722102597253e-06, "Bleu_4": 2.462691352392326e-09, "METEOR": 0.14415201470247221, "ROUGE_L": 0.21180555555555555, "CIDEr": 0.00014404207184533615, "SPICE": {"All": {"pr": 0.2916666666666667, "re": 0.28, "f": 0.2857142857142857, "fn": 18.0, "numImages": 1.0, "fp": 17.0, "tp": 7.0}, "Relation": {"pr": 0.1111111111111111, "re": 0.08333333333333333, "f": 0.09523809523809525, "fn": 11.0, "numImages": 1.0, "fp": 8.0, "tp": 1.0}, "Cardinality": {"pr": 0.5, "re": 1.0, "f": 0.6666666666666666, "fn": 0.0, "numImages": 1.0, "fp": 1.0, "tp": 1.0}, "Attribute": {"pr": 0.2, "re": 0.25, "f": 0.22222222222222224, "fn": 3.0, "numImages": 1.0, "fp": 4.0, "tp": 1.0}, "Size": {"pr": 0.0, "re": 0.0, "f": 0.0, "fn": 1.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Color": {"pr": NaN, "re": NaN, "f": NaN, "fn": 0.0, "numImages": 1.0, "fp": 0.0, "tp": 0.0}, "Object": {"pr": 0.5, "re": 0.5555555555555556, "f": 0.5263157894736842, "fn": 4.0, "numImages": 1.0, "fp": 5.0, "tp": 5.0}}, "caption": "This is a kitchen with a stove, refrigerator, and sink. The countertops are made of wood and the cabinets are made of wood as well. There is a microwave on the counter next to the stove."}}}